{"mode": "train", "epochs": 1, "timestep": 1, "ep_reward": 0.615426778793335, "reward": 0.615426778793335, "action": -0.18225903809070587}
{"mode": "train", "epochs": 1, "timestep": 2, "ep_reward": 1.2378385066986084, "reward": 0.6224116683006287, "action": 0.31866034865379333}
{"mode": "train", "epochs": 1, "timestep": 3, "ep_reward": 1.8565611839294434, "reward": 0.618722677230835, "action": 0.5453863143920898}
{"mode": "train", "epochs": 1, "timestep": 4, "ep_reward": 2.4593372344970703, "reward": 0.6027759909629822, "action": 0.7099354267120361}
{"mode": "train", "epochs": 1, "timestep": 5, "ep_reward": 3.0333919525146484, "reward": 0.5740545988082886, "action": 0.5911401510238647}
{"mode": "train", "epochs": 1, "timestep": 6, "ep_reward": 3.5676276683807373, "reward": 0.5342357158660889, "action": -0.05698147788643837}
{"mode": "train", "epochs": 1, "timestep": 7, "ep_reward": 4.056591510772705, "reward": 0.48896366357803345, "action": 0.1623353809118271}
{"mode": "train", "epochs": 1, "timestep": 8, "ep_reward": 4.493418216705322, "reward": 0.4368267059326172, "action": -0.04671274125576019}
{"mode": "train", "epochs": 1, "timestep": 9, "ep_reward": 4.875888824462891, "reward": 0.3824707269668579, "action": -0.11478977650403976}
{"mode": "train", "epochs": 1, "timestep": 10, "ep_reward": 5.222914695739746, "reward": 0.34702610969543457, "action": 0.5481086373329163}
{"mode": "train", "epochs": 1, "timestep": 11, "ep_reward": 5.620452880859375, "reward": 0.39753836393356323, "action": -0.12295710295438766}
{"mode": "train", "epochs": 1, "timestep": 12, "ep_reward": 6.070507049560547, "reward": 0.4500539302825928, "action": -0.179450124502182}
{"mode": "train", "epochs": 1, "timestep": 13, "ep_reward": 6.569680690765381, "reward": 0.49917346239089966, "action": 0.558585524559021}
{"mode": "train", "epochs": 1, "timestep": 14, "ep_reward": 7.1111931800842285, "reward": 0.5415123701095581, "action": 0.6481227874755859}
{"mode": "train", "epochs": 1, "timestep": 15, "ep_reward": 7.690046310424805, "reward": 0.5788531303405762, "action": 0.8428895473480225}
{"mode": "train", "epochs": 1, "timestep": 16, "ep_reward": 8.300142288208008, "reward": 0.6100960969924927, "action": -0.6474534273147583}
{"mode": "train", "epochs": 1, "timestep": 17, "ep_reward": 8.934700965881348, "reward": 0.6345586776733398, "action": -1.2155920267105103}
{"mode": "train", "epochs": 1, "timestep": 18, "ep_reward": 9.57968521118164, "reward": 0.6449844837188721, "action": -0.7725682258605957}
{"mode": "train", "epochs": 1, "timestep": 19, "ep_reward": 10.219886779785156, "reward": 0.6402015089988708, "action": 0.6993377804756165}
{"mode": "train", "epochs": 1, "timestep": 20, "ep_reward": 10.846582412719727, "reward": 0.6266953945159912, "action": -0.251242458820343}
{"mode": "train", "epochs": 1, "timestep": 21, "ep_reward": 11.447543144226074, "reward": 0.600960373878479, "action": 0.7922871112823486}
{"mode": "train", "epochs": 1, "timestep": 22, "ep_reward": 12.017606735229492, "reward": 0.5700637698173523, "action": 0.3353271782398224}
{"mode": "train", "epochs": 1, "timestep": 23, "ep_reward": 12.548239707946777, "reward": 0.5306328535079956, "action": -0.20300033688545227}
{"mode": "train", "epochs": 1, "timestep": 24, "ep_reward": 13.029780387878418, "reward": 0.4815405607223511, "action": -0.0847843736410141}
{"mode": "train", "epochs": 1, "timestep": 25, "ep_reward": 13.457060813903809, "reward": 0.4272804856300354, "action": 0.06171838566660881}
{"mode": "train", "epochs": 1, "timestep": 26, "ep_reward": 13.82804012298584, "reward": 0.3709789514541626, "action": -0.12084151804447174}
{"mode": "train", "epochs": 1, "timestep": 27, "ep_reward": 14.181558609008789, "reward": 0.3535187244415283, "action": -0.010120019316673279}
{"mode": "train", "epochs": 1, "timestep": 28, "ep_reward": 14.588902473449707, "reward": 0.4073442816734314, "action": 0.6905295252799988}
{"mode": "train", "epochs": 1, "timestep": 29, "ep_reward": 15.05022144317627, "reward": 0.4613193869590759, "action": -0.7265151739120483}
{"mode": "train", "epochs": 1, "timestep": 30, "ep_reward": 15.55711555480957, "reward": 0.506894588470459, "action": 0.37999361753463745}
{"mode": "train", "epochs": 1, "timestep": 31, "ep_reward": 16.108213424682617, "reward": 0.5510972738265991, "action": -0.5576525926589966}
{"mode": "train", "epochs": 1, "timestep": 32, "ep_reward": 16.694190979003906, "reward": 0.5859767198562622, "action": -0.30730435252189636}
{"mode": "train", "epochs": 1, "timestep": 33, "ep_reward": 17.30852699279785, "reward": 0.6143361330032349, "action": -0.5806975960731506}
{"mode": "train", "epochs": 1, "timestep": 34, "ep_reward": 17.94287109375, "reward": 0.6343433856964111, "action": 0.29118943214416504}
{"mode": "train", "epochs": 1, "timestep": 35, "ep_reward": 18.58780288696289, "reward": 0.6449326872825623, "action": -0.12137779593467712}
{"mode": "train", "epochs": 1, "timestep": 36, "ep_reward": 19.232154846191406, "reward": 0.6443528532981873, "action": 0.37067338824272156}
{"mode": "train", "epochs": 1, "timestep": 37, "ep_reward": 19.863685607910156, "reward": 0.6315312385559082, "action": -0.23288752138614655}
{"mode": "train", "epochs": 1, "timestep": 38, "ep_reward": 20.47270393371582, "reward": 0.6090176105499268, "action": -0.09883616864681244}
{"mode": "train", "epochs": 1, "timestep": 39, "ep_reward": 21.04924201965332, "reward": 0.5765389204025269, "action": -0.5620602369308472}
{"mode": "train", "epochs": 1, "timestep": 40, "ep_reward": 21.58746910095215, "reward": 0.5382266044616699, "action": -0.14313693344593048}
{"mode": "train", "epochs": 1, "timestep": 41, "ep_reward": 22.079090118408203, "reward": 0.4916209578514099, "action": -0.1477300524711609}
{"mode": "train", "epochs": 1, "timestep": 42, "ep_reward": 22.518972396850586, "reward": 0.4398820400238037, "action": 0.5537386536598206}
{"mode": "train", "epochs": 1, "timestep": 43, "ep_reward": 22.898691177368164, "reward": 0.3797191381454468, "action": 0.26442456245422363}
{"mode": "train", "epochs": 1, "timestep": 44, "ep_reward": 23.240737915039062, "reward": 0.342046856880188, "action": -0.5754011869430542}
{"mode": "train", "epochs": 1, "timestep": 45, "ep_reward": 23.639699935913086, "reward": 0.39896202087402344, "action": -0.39698344469070435}
{"mode": "train", "epochs": 1, "timestep": 46, "ep_reward": 24.092256546020508, "reward": 0.4525567293167114, "action": -0.2340439260005951}
{"mode": "train", "epochs": 1, "timestep": 47, "ep_reward": 24.593597412109375, "reward": 0.5013400316238403, "action": 0.38042575120925903}
{"mode": "train", "epochs": 1, "timestep": 48, "ep_reward": 25.136911392211914, "reward": 0.5433133840560913, "action": 0.251112163066864}
{"mode": "train", "epochs": 1, "timestep": 49, "ep_reward": 25.71677589416504, "reward": 0.579864501953125, "action": 0.47052058577537537}
{"mode": "train", "epochs": 1, "timestep": 50, "ep_reward": 26.325735092163086, "reward": 0.6089583039283752, "action": 0.11838337779045105}
{"mode": "train", "epochs": 1, "timestep": 51, "ep_reward": 26.955913543701172, "reward": 0.6301789283752441, "action": -0.2594708502292633}
{"mode": "train", "epochs": 1, "timestep": 52, "ep_reward": 27.596933364868164, "reward": 0.6410195827484131, "action": 0.3683363199234009}
{"mode": "train", "epochs": 1, "timestep": 53, "ep_reward": 28.23843765258789, "reward": 0.64150470495224, "action": -0.003393637016415596}
{"mode": "train", "epochs": 1, "timestep": 54, "ep_reward": 28.86979103088379, "reward": 0.631354033946991, "action": -0.07407335191965103}
{"mode": "train", "epochs": 1, "timestep": 55, "ep_reward": 29.479928970336914, "reward": 0.6101374626159668, "action": -0.3891046941280365}
{"mode": "train", "epochs": 1, "timestep": 56, "ep_reward": 30.056703567504883, "reward": 0.5767744779586792, "action": -0.3459584712982178}
{"mode": "train", "epochs": 1, "timestep": 57, "ep_reward": 30.58961296081543, "reward": 0.5329102277755737, "action": -0.13394805788993835}
{"mode": "train", "epochs": 1, "timestep": 58, "ep_reward": 31.071216583251953, "reward": 0.48160457611083984, "action": -0.2241804301738739}
{"mode": "train", "epochs": 1, "timestep": 59, "ep_reward": 31.494874954223633, "reward": 0.42365920543670654, "action": 0.4545776844024658}
{"mode": "train", "epochs": 1, "timestep": 60, "ep_reward": 31.86248207092285, "reward": 0.36760634183883667, "action": -0.3706117868423462}
{"mode": "train", "epochs": 1, "timestep": 61, "ep_reward": 32.21456527709961, "reward": 0.3520820736885071, "action": -0.39476579427719116}
{"mode": "train", "epochs": 1, "timestep": 62, "ep_reward": 32.62162780761719, "reward": 0.40706121921539307, "action": 0.6581697463989258}
{"mode": "train", "epochs": 1, "timestep": 63, "ep_reward": 33.08604049682617, "reward": 0.4644126296043396, "action": 0.5297181010246277}
{"mode": "train", "epochs": 1, "timestep": 64, "ep_reward": 33.6015625, "reward": 0.5155221819877625, "action": -0.04189203679561615}
{"mode": "train", "epochs": 1, "timestep": 65, "ep_reward": 34.15969467163086, "reward": 0.5581322908401489, "action": 0.3056437075138092}
{"mode": "train", "epochs": 1, "timestep": 66, "ep_reward": 34.75333786010742, "reward": 0.5936450362205505, "action": -0.07419997453689575}
{"mode": "train", "epochs": 1, "timestep": 67, "ep_reward": 35.37244415283203, "reward": 0.6191047430038452, "action": 0.07191422581672668}
{"mode": "train", "epochs": 1, "timestep": 68, "ep_reward": 36.007266998291016, "reward": 0.6348229646682739, "action": 0.36373233795166016}
{"mode": "train", "epochs": 1, "timestep": 69, "ep_reward": 36.64643096923828, "reward": 0.6391622424125671, "action": 0.22388678789138794}
{"mode": "train", "epochs": 1, "timestep": 70, "ep_reward": 37.27803421020508, "reward": 0.63160240650177, "action": -0.058572135865688324}
{"mode": "train", "epochs": 1, "timestep": 71, "ep_reward": 37.891544342041016, "reward": 0.6135093569755554, "action": 0.8416244983673096}
{"mode": "train", "epochs": 1, "timestep": 72, "ep_reward": 38.47249984741211, "reward": 0.5809570550918579, "action": 0.09615756571292877}
{"mode": "train", "epochs": 1, "timestep": 73, "ep_reward": 39.01254653930664, "reward": 0.5400480031967163, "action": -0.5179139971733093}
{"mode": "train", "epochs": 1, "timestep": 74, "ep_reward": 39.50777053833008, "reward": 0.49522459506988525, "action": 0.176479309797287}
{"mode": "train", "epochs": 1, "timestep": 75, "ep_reward": 39.94914245605469, "reward": 0.4413713812828064, "action": 0.03592867776751518}
{"mode": "train", "epochs": 1, "timestep": 76, "ep_reward": 40.33357238769531, "reward": 0.38442808389663696, "action": -0.12599775195121765}
{"mode": "train", "epochs": 1, "timestep": 77, "ep_reward": 40.67356872558594, "reward": 0.33999741077423096, "action": 0.5567790865898132}
{"mode": "train", "epochs": 1, "timestep": 78, "ep_reward": 41.06600570678711, "reward": 0.39243561029434204, "action": 0.17529332637786865}
{"mode": "train", "epochs": 1, "timestep": 79, "ep_reward": 41.51243591308594, "reward": 0.4464293122291565, "action": -0.6912152767181396}
{"mode": "train", "epochs": 1, "timestep": 80, "ep_reward": 42.01234436035156, "reward": 0.49990856647491455, "action": 0.15366710722446442}
{"mode": "train", "epochs": 1, "timestep": 81, "ep_reward": 42.55677032470703, "reward": 0.5444261431694031, "action": -0.34447792172431946}
{"mode": "train", "epochs": 1, "timestep": 82, "ep_reward": 43.13980484008789, "reward": 0.5830354690551758, "action": -0.23763267695903778}
{"mode": "train", "epochs": 1, "timestep": 83, "ep_reward": 43.75157928466797, "reward": 0.6117739677429199, "action": 0.6048352122306824}
{"mode": "train", "epochs": 1, "timestep": 84, "ep_reward": 44.38217544555664, "reward": 0.6305948495864868, "action": 0.13875623047351837}
{"mode": "train", "epochs": 1, "timestep": 85, "ep_reward": 45.02292251586914, "reward": 0.6407485604286194, "action": 0.48588940501213074}
{"mode": "train", "epochs": 1, "timestep": 86, "ep_reward": 45.66445541381836, "reward": 0.6415325403213501, "action": 0.0636553019285202}
{"mode": "train", "epochs": 1, "timestep": 87, "ep_reward": 46.296443939208984, "reward": 0.6319901347160339, "action": -0.4944421052932739}
{"mode": "train", "epochs": 1, "timestep": 88, "ep_reward": 46.906036376953125, "reward": 0.6095914840698242, "action": 0.43158429861068726}
{"mode": "train", "epochs": 1, "timestep": 89, "ep_reward": 47.48582077026367, "reward": 0.5797828435897827, "action": 0.5530148148536682}
{"mode": "train", "epochs": 1, "timestep": 90, "ep_reward": 48.029083251953125, "reward": 0.5432631969451904, "action": -0.3516373336315155}
{"mode": "train", "epochs": 1, "timestep": 91, "ep_reward": 48.52417755126953, "reward": 0.49509483575820923, "action": 0.18867886066436768}
{"mode": "train", "epochs": 1, "timestep": 92, "ep_reward": 48.96784973144531, "reward": 0.44367069005966187, "action": -0.2551608681678772}
{"mode": "train", "epochs": 1, "timestep": 93, "ep_reward": 49.35368728637695, "reward": 0.3858386278152466, "action": -0.18027174472808838}
{"mode": "train", "epochs": 1, "timestep": 94, "ep_reward": 49.69184875488281, "reward": 0.33816051483154297, "action": 0.2265130579471588}
{"mode": "train", "epochs": 1, "timestep": 95, "ep_reward": 50.08517074584961, "reward": 0.39332062005996704, "action": -0.3701411485671997}
{"mode": "train", "epochs": 1, "timestep": 96, "ep_reward": 50.53063201904297, "reward": 0.44546210765838623, "action": -0.1418427973985672}
{"mode": "train", "epochs": 1, "timestep": 97, "ep_reward": 51.026893615722656, "reward": 0.49626076221466064, "action": -0.7087725400924683}
{"mode": "train", "epochs": 1, "timestep": 98, "ep_reward": 51.568389892578125, "reward": 0.5414963960647583, "action": 0.5027240514755249}
{"mode": "train", "epochs": 1, "timestep": 99, "ep_reward": 52.152252197265625, "reward": 0.5838626027107239, "action": 0.8400682210922241}
{"mode": "train", "epochs": 1, "timestep": 100, "ep_reward": 52.768035888671875, "reward": 0.6157838702201843, "action": 0.4973768889904022}
{"mode": "train", "epochs": 1, "timestep": 101, "ep_reward": 53.4026985168457, "reward": 0.6346637010574341, "action": 0.14259204268455505}
{"mode": "train", "epochs": 1, "timestep": 102, "ep_reward": 54.044273376464844, "reward": 0.6415736079216003, "action": 0.27925440669059753}
{"mode": "train", "epochs": 1, "timestep": 103, "ep_reward": 54.680931091308594, "reward": 0.6366573572158813, "action": 0.33269160985946655}
{"mode": "train", "epochs": 1, "timestep": 104, "ep_reward": 55.30044174194336, "reward": 0.6195120811462402, "action": -0.03619829937815666}
{"mode": "train", "epochs": 1, "timestep": 105, "ep_reward": 55.8927116394043, "reward": 0.5922682285308838, "action": -0.7986408472061157}
{"mode": "train", "epochs": 1, "timestep": 106, "ep_reward": 56.45265579223633, "reward": 0.559944748878479, "action": -0.20363710820674896}
{"mode": "train", "epochs": 1, "timestep": 107, "ep_reward": 56.97119903564453, "reward": 0.5185437798500061, "action": 0.5726850628852844}
{"mode": "train", "epochs": 1, "timestep": 108, "ep_reward": 57.4369010925293, "reward": 0.4657021760940552, "action": 0.6765896081924438}
{"mode": "train", "epochs": 1, "timestep": 109, "ep_reward": 57.84209442138672, "reward": 0.405193030834198, "action": 0.1084895059466362}
{"mode": "train", "epochs": 1, "timestep": 110, "ep_reward": 58.18695068359375, "reward": 0.3448569178581238, "action": 0.13272801041603088}
{"mode": "train", "epochs": 1, "timestep": 111, "ep_reward": 58.55851745605469, "reward": 0.3715663552284241, "action": 0.13563071191310883}
{"mode": "train", "epochs": 1, "timestep": 112, "ep_reward": 58.98572540283203, "reward": 0.42720693349838257, "action": -0.021383434534072876}
{"mode": "train", "epochs": 1, "timestep": 113, "ep_reward": 59.467063903808594, "reward": 0.48133939504623413, "action": 0.6833364963531494}
{"mode": "train", "epochs": 1, "timestep": 114, "ep_reward": 59.99653625488281, "reward": 0.529470682144165, "action": 0.6625277996063232}
{"mode": "train", "epochs": 1, "timestep": 115, "ep_reward": 60.570045471191406, "reward": 0.5735082626342773, "action": -0.27364620566368103}
{"mode": "train", "epochs": 1, "timestep": 116, "ep_reward": 61.182743072509766, "reward": 0.6126973628997803, "action": -0.3401508927345276}
{"mode": "train", "epochs": 1, "timestep": 117, "ep_reward": 61.823753356933594, "reward": 0.6410108804702759, "action": 0.2445894032716751}
{"mode": "train", "epochs": 1, "timestep": 118, "ep_reward": 62.481380462646484, "reward": 0.6576272249221802, "action": -0.07049211859703064}
{"mode": "train", "epochs": 1, "timestep": 119, "ep_reward": 63.14463806152344, "reward": 0.6632580757141113, "action": 0.1294320672750473}
{"mode": "train", "epochs": 1, "timestep": 120, "ep_reward": 63.80198669433594, "reward": 0.6573474407196045, "action": 1.3068784475326538}
{"mode": "train", "epochs": 1, "timestep": 121, "ep_reward": 64.44683074951172, "reward": 0.6448434591293335, "action": 0.6326034069061279}
{"mode": "train", "epochs": 1, "timestep": 122, "ep_reward": 65.06990814208984, "reward": 0.6230765581130981, "action": 0.43329793214797974}
{"mode": "train", "epochs": 1, "timestep": 123, "ep_reward": 65.66193389892578, "reward": 0.5920286774635315, "action": 0.3159412741661072}
{"mode": "train", "epochs": 1, "timestep": 124, "ep_reward": 66.21414947509766, "reward": 0.552215576171875, "action": -0.13574489951133728}
{"mode": "train", "epochs": 1, "timestep": 125, "ep_reward": 66.71633911132812, "reward": 0.5021911263465881, "action": -0.12372750788927078}
{"mode": "train", "epochs": 1, "timestep": 126, "ep_reward": 67.16168975830078, "reward": 0.4453515410423279, "action": 0.18854933977127075}
{"mode": "train", "epochs": 1, "timestep": 127, "ep_reward": 67.54839324951172, "reward": 0.3867061734199524, "action": -0.07129332423210144}
{"mode": "train", "epochs": 1, "timestep": 128, "ep_reward": 67.8786392211914, "reward": 0.3302457332611084, "action": -0.8896192312240601}
{"mode": "train", "epochs": 1, "timestep": 129, "ep_reward": 68.26337432861328, "reward": 0.3847332000732422, "action": 0.41246938705444336}
{"mode": "train", "epochs": 1, "timestep": 130, "ep_reward": 68.70809173583984, "reward": 0.4447181224822998, "action": 0.09769059717655182}
{"mode": "train", "epochs": 1, "timestep": 131, "ep_reward": 69.20760345458984, "reward": 0.49951452016830444, "action": -0.6842375993728638}
{"mode": "train", "epochs": 1, "timestep": 132, "ep_reward": 69.75469970703125, "reward": 0.5470954179763794, "action": 1.0025087594985962}
{"mode": "train", "epochs": 1, "timestep": 133, "ep_reward": 70.34713745117188, "reward": 0.5924409031867981, "action": 0.16319236159324646}
{"mode": "train", "epochs": 1, "timestep": 134, "ep_reward": 70.97146606445312, "reward": 0.6243295669555664, "action": 0.4942915737628937}
{"mode": "train", "epochs": 1, "timestep": 135, "ep_reward": 71.61669158935547, "reward": 0.64522784948349, "action": -0.25856924057006836}
{"mode": "train", "epochs": 1, "timestep": 136, "ep_reward": 72.27098083496094, "reward": 0.6542917490005493, "action": 0.4378700256347656}
{"mode": "train", "epochs": 1, "timestep": 137, "ep_reward": 72.92231750488281, "reward": 0.6513381600379944, "action": 0.07980678975582123}
{"mode": "train", "epochs": 1, "timestep": 138, "ep_reward": 73.5587158203125, "reward": 0.6363965272903442, "action": 0.4739994406700134}
{"mode": "train", "epochs": 1, "timestep": 139, "ep_reward": 74.1668701171875, "reward": 0.6081541180610657, "action": 0.1946762502193451}
{"mode": "train", "epochs": 1, "timestep": 140, "ep_reward": 74.73599243164062, "reward": 0.5691260695457458, "action": -0.340659499168396}
{"mode": "train", "epochs": 1, "timestep": 141, "ep_reward": 75.25981903076172, "reward": 0.5238245725631714, "action": 0.13293957710266113}
{"mode": "train", "epochs": 1, "timestep": 142, "ep_reward": 75.72889709472656, "reward": 0.46908068656921387, "action": -0.43095219135284424}
{"mode": "train", "epochs": 1, "timestep": 143, "ep_reward": 76.14225769042969, "reward": 0.41336315870285034, "action": 0.639724612236023}
{"mode": "train", "epochs": 1, "timestep": 144, "ep_reward": 76.49002838134766, "reward": 0.34777140617370605, "action": 0.7679368257522583}
{"mode": "train", "epochs": 1, "timestep": 145, "ep_reward": 76.85066986083984, "reward": 0.36064374446868896, "action": -0.18272405862808228}
{"mode": "train", "epochs": 1, "timestep": 146, "ep_reward": 77.27198028564453, "reward": 0.4213075637817383, "action": 0.79953932762146}
{"mode": "train", "epochs": 1, "timestep": 147, "ep_reward": 77.74847412109375, "reward": 0.4764958620071411, "action": -0.18652036786079407}
{"mode": "train", "epochs": 1, "timestep": 148, "ep_reward": 78.28086853027344, "reward": 0.5323923230171204, "action": -0.061436429619789124}
{"mode": "train", "epochs": 1, "timestep": 149, "ep_reward": 78.86150360107422, "reward": 0.580636739730835, "action": 0.6710867285728455}
{"mode": "train", "epochs": 1, "timestep": 150, "ep_reward": 79.48065948486328, "reward": 0.6191570162773132, "action": -0.21501417458057404}
{"mode": "train", "epochs": 1, "timestep": 151, "ep_reward": 80.13119506835938, "reward": 0.6505370140075684, "action": 0.1450575441122055}
{"mode": "train", "epochs": 1, "timestep": 152, "ep_reward": 80.8011703491211, "reward": 0.6699748039245605, "action": 0.8177602887153625}
{"mode": "train", "epochs": 1, "timestep": 153, "ep_reward": 81.4803695678711, "reward": 0.6791961789131165, "action": 0.023675289005041122}
{"mode": "train", "epochs": 1, "timestep": 154, "ep_reward": 82.15794372558594, "reward": 0.6775713562965393, "action": 0.08098205924034119}
{"mode": "train", "epochs": 1, "timestep": 155, "ep_reward": 82.82178497314453, "reward": 0.6638442277908325, "action": 0.8023055791854858}
{"mode": "train", "epochs": 1, "timestep": 156, "ep_reward": 83.46340942382812, "reward": 0.6416265964508057, "action": 0.08517289161682129}
{"mode": "train", "epochs": 1, "timestep": 157, "ep_reward": 84.07058715820312, "reward": 0.6071783304214478, "action": -0.30565905570983887}
{"mode": "train", "epochs": 1, "timestep": 158, "ep_reward": 84.63048553466797, "reward": 0.5599007606506348, "action": 0.2710031270980835}
{"mode": "train", "epochs": 1, "timestep": 159, "ep_reward": 85.13700866699219, "reward": 0.5065252780914307, "action": -0.22754254937171936}
{"mode": "train", "epochs": 1, "timestep": 160, "ep_reward": 85.5802993774414, "reward": 0.4432936906814575, "action": 0.10555140674114227}
{"mode": "train", "epochs": 1, "timestep": 161, "ep_reward": 85.95816802978516, "reward": 0.37786513566970825, "action": -1.1202821731567383}
{"mode": "train", "epochs": 1, "timestep": 162, "ep_reward": 86.27700805664062, "reward": 0.31883782148361206, "action": 0.16030941903591156}
{"mode": "train", "epochs": 1, "timestep": 163, "ep_reward": 86.66181945800781, "reward": 0.3848083019256592, "action": 0.2540769577026367}
{"mode": "train", "epochs": 1, "timestep": 164, "ep_reward": 87.11156463623047, "reward": 0.4497467279434204, "action": 0.37281686067581177}
{"mode": "train", "epochs": 1, "timestep": 165, "ep_reward": 87.62236785888672, "reward": 0.510804295539856, "action": -0.4038618505001068}
{"mode": "train", "epochs": 1, "timestep": 166, "ep_reward": 88.18512725830078, "reward": 0.5627585649490356, "action": -0.6898090243339539}
{"mode": "train", "epochs": 1, "timestep": 167, "ep_reward": 88.79275512695312, "reward": 0.6076294183731079, "action": -0.4362800121307373}
{"mode": "train", "epochs": 1, "timestep": 168, "ep_reward": 89.4383316040039, "reward": 0.645577073097229, "action": 0.2045496106147766}
{"mode": "train", "epochs": 1, "timestep": 169, "ep_reward": 90.11256408691406, "reward": 0.6742318272590637, "action": 0.5931788682937622}
{"mode": "train", "epochs": 1, "timestep": 170, "ep_reward": 90.80207824707031, "reward": 0.6895103454589844, "action": -1.059564232826233}
{"mode": "train", "epochs": 1, "timestep": 171, "ep_reward": 91.49518585205078, "reward": 0.6931092739105225, "action": 0.17294573783874512}
{"mode": "train", "epochs": 1, "timestep": 172, "ep_reward": 92.17976379394531, "reward": 0.6845793724060059, "action": 0.16381415724754333}
{"mode": "train", "epochs": 1, "timestep": 173, "ep_reward": 92.84229278564453, "reward": 0.6625320315361023, "action": -0.045683152973651886}
{"mode": "train", "epochs": 1, "timestep": 174, "ep_reward": 93.47071838378906, "reward": 0.6284223794937134, "action": 0.6625336408615112}
{"mode": "train", "epochs": 1, "timestep": 175, "ep_reward": 94.04904174804688, "reward": 0.5783202648162842, "action": 0.40128499269485474}
{"mode": "train", "epochs": 1, "timestep": 176, "ep_reward": 94.5661849975586, "reward": 0.5171446204185486, "action": -0.355607807636261}
{"mode": "train", "epochs": 1, "timestep": 177, "ep_reward": 95.01908111572266, "reward": 0.45289546251296997, "action": 0.7244840860366821}
{"mode": "train", "epochs": 1, "timestep": 178, "ep_reward": 95.39434814453125, "reward": 0.37526363134384155, "action": 0.5248627066612244}
{"mode": "train", "epochs": 1, "timestep": 179, "ep_reward": 95.6951675415039, "reward": 0.3008226156234741, "action": 0.005320623517036438}
{"mode": "train", "epochs": 1, "timestep": 180, "ep_reward": 96.0662612915039, "reward": 0.3710929751396179, "action": 0.05372888594865799}
{"mode": "train", "epochs": 1, "timestep": 181, "ep_reward": 96.50689697265625, "reward": 0.4406321048736572, "action": 0.7725083827972412}
{"mode": "train", "epochs": 1, "timestep": 182, "ep_reward": 97.01129913330078, "reward": 0.5044009685516357, "action": 0.5846911072731018}
{"mode": "train", "epochs": 1, "timestep": 183, "ep_reward": 97.57667541503906, "reward": 0.5653800964355469, "action": 0.4151690602302551}
{"mode": "train", "epochs": 1, "timestep": 184, "ep_reward": 98.197021484375, "reward": 0.6203476190567017, "action": -0.595660924911499}
{"mode": "train", "epochs": 1, "timestep": 185, "ep_reward": 98.86517333984375, "reward": 0.6681532859802246, "action": 0.3135434091091156}
{"mode": "train", "epochs": 1, "timestep": 186, "ep_reward": 99.56568145751953, "reward": 0.7005115151405334, "action": 0.9774476289749146}
{"mode": "train", "epochs": 1, "timestep": 187, "ep_reward": 100.2870101928711, "reward": 0.7213274240493774, "action": -0.2446705549955368}
{"mode": "train", "epochs": 1, "timestep": 188, "ep_reward": 101.01803588867188, "reward": 0.7310247421264648, "action": 0.14034909009933472}
{"mode": "train", "epochs": 1, "timestep": 189, "ep_reward": 101.74475860595703, "reward": 0.7267202138900757, "action": 0.6096158027648926}
{"mode": "train", "epochs": 1, "timestep": 190, "ep_reward": 102.45558166503906, "reward": 0.7108221054077148, "action": -0.15853802859783173}
{"mode": "train", "epochs": 1, "timestep": 191, "ep_reward": 103.13543701171875, "reward": 0.6798537373542786, "action": 0.5622751116752625}
{"mode": "train", "epochs": 1, "timestep": 192, "ep_reward": 103.77449798583984, "reward": 0.639062762260437, "action": -0.36080172657966614}
{"mode": "train", "epochs": 1, "timestep": 193, "ep_reward": 104.35592651367188, "reward": 0.5814253091812134, "action": -0.5260207056999207}
{"mode": "train", "epochs": 1, "timestep": 194, "ep_reward": 104.8656997680664, "reward": 0.509771466255188, "action": -1.1315147876739502}
{"mode": "train", "epochs": 1, "timestep": 195, "ep_reward": 105.28758239746094, "reward": 0.4218812584877014, "action": 0.07902786880731583}
{"mode": "train", "epochs": 1, "timestep": 196, "ep_reward": 105.62480163574219, "reward": 0.3372218608856201, "action": -1.0582869052886963}
{"mode": "train", "epochs": 1, "timestep": 197, "ep_reward": 105.92047119140625, "reward": 0.29567039012908936, "action": 0.19930967688560486}
{"mode": "train", "epochs": 1, "timestep": 198, "ep_reward": 106.29846954345703, "reward": 0.37799882888793945, "action": 0.12184543162584305}
{"mode": "train", "epochs": 1, "timestep": 199, "ep_reward": 106.7566146850586, "reward": 0.45814788341522217, "action": 1.069753885269165}
{"mode": "train", "epochs": 1, "timestep": 200, "ep_reward": 107.2942886352539, "reward": 0.5376724004745483, "action": -0.35065990686416626}
{"mode": "train", "epochs": 1, "timestep": 201, "ep_reward": 107.89468383789062, "reward": 0.6003931760787964, "action": -0.5282164812088013}
{"mode": "train", "epochs": 1, "timestep": 202, "ep_reward": 108.54844665527344, "reward": 0.6537625789642334, "action": -0.45571810007095337}
{"mode": "train", "epochs": 1, "timestep": 203, "ep_reward": 109.24574279785156, "reward": 0.6972948312759399, "action": 0.0808807760477066}
{"mode": "train", "epochs": 1, "timestep": 204, "ep_reward": 109.97559356689453, "reward": 0.7298544645309448, "action": -0.06990411877632141}
{"mode": "train", "epochs": 1, "timestep": 205, "ep_reward": 110.7237319946289, "reward": 0.7481352090835571, "action": 1.1078298091888428}
{"mode": "train", "epochs": 1, "timestep": 206, "ep_reward": 111.47412872314453, "reward": 0.7503994107246399, "action": -0.1305953711271286}
{"mode": "train", "epochs": 1, "timestep": 207, "ep_reward": 112.2112808227539, "reward": 0.7371554374694824, "action": -0.7162812352180481}
{"mode": "train", "epochs": 1, "timestep": 208, "ep_reward": 112.92395782470703, "reward": 0.7126765251159668, "action": 0.09236300736665726}
{"mode": "train", "epochs": 1, "timestep": 209, "ep_reward": 113.59619903564453, "reward": 0.6722447872161865, "action": 0.7199298143386841}
{"mode": "train", "epochs": 1, "timestep": 210, "ep_reward": 114.20926666259766, "reward": 0.6130703091621399, "action": -0.24674825370311737}
{"mode": "train", "epochs": 1, "timestep": 211, "ep_reward": 114.75536346435547, "reward": 0.546097993850708, "action": 0.2301807552576065}
{"mode": "train", "epochs": 1, "timestep": 212, "ep_reward": 115.22084045410156, "reward": 0.4654800295829773, "action": -0.6650615930557251}
{"mode": "train", "epochs": 1, "timestep": 213, "ep_reward": 115.60709381103516, "reward": 0.3862520456314087, "action": -0.6814915537834167}
{"mode": "train", "epochs": 1, "timestep": 214, "ep_reward": 115.91400146484375, "reward": 0.30691051483154297, "action": 0.09098072350025177}
{"mode": "train", "epochs": 1, "timestep": 215, "ep_reward": 116.24732208251953, "reward": 0.33331966400146484, "action": 0.27448126673698425}
{"mode": "train", "epochs": 1, "timestep": 216, "ep_reward": 116.6566162109375, "reward": 0.40929561853408813, "action": 0.1181480884552002}
{"mode": "train", "epochs": 1, "timestep": 217, "ep_reward": 117.14114379882812, "reward": 0.4845268130302429, "action": 0.7695383429527283}
{"mode": "train", "epochs": 1, "timestep": 218, "ep_reward": 117.69316864013672, "reward": 0.5520274043083191, "action": -0.2227766364812851}
{"mode": "train", "epochs": 1, "timestep": 219, "ep_reward": 118.31053924560547, "reward": 0.6173721551895142, "action": -0.29271751642227173}
{"mode": "train", "epochs": 1, "timestep": 220, "ep_reward": 118.98158264160156, "reward": 0.6710450649261475, "action": -0.6985795497894287}
{"mode": "train", "epochs": 1, "timestep": 221, "ep_reward": 119.69303131103516, "reward": 0.7114505171775818, "action": -0.08996999263763428}
{"mode": "train", "epochs": 1, "timestep": 222, "ep_reward": 120.42829895019531, "reward": 0.7352700233459473, "action": -0.11032142490148544}
{"mode": "train", "epochs": 1, "timestep": 223, "ep_reward": 121.1729965209961, "reward": 0.7447003126144409, "action": 0.13644565641880035}
{"mode": "train", "epochs": 1, "timestep": 224, "ep_reward": 121.91304779052734, "reward": 0.7400490045547485, "action": 0.5156469345092773}
{"mode": "train", "epochs": 1, "timestep": 225, "ep_reward": 122.6360855102539, "reward": 0.723034679889679, "action": -1.1614514589309692}
{"mode": "train", "epochs": 1, "timestep": 226, "ep_reward": 123.32152557373047, "reward": 0.6854392886161804, "action": 1.085697889328003}
{"mode": "train", "epochs": 1, "timestep": 227, "ep_reward": 123.96461486816406, "reward": 0.643092155456543, "action": 0.6443551182746887}
{"mode": "train", "epochs": 1, "timestep": 228, "ep_reward": 124.5535888671875, "reward": 0.5889774560928345, "action": 0.34610211849212646}
{"mode": "train", "epochs": 1, "timestep": 229, "ep_reward": 125.07719421386719, "reward": 0.5236036777496338, "action": -1.382097840309143}
{"mode": "train", "epochs": 1, "timestep": 230, "ep_reward": 125.51205444335938, "reward": 0.43486082553863525, "action": -0.15999014675617218}
{"mode": "train", "epochs": 1, "timestep": 231, "ep_reward": 125.85965728759766, "reward": 0.3476032614707947, "action": 0.32814866304397583}
{"mode": "train", "epochs": 1, "timestep": 232, "ep_reward": 126.14800262451172, "reward": 0.2883431315422058, "action": -0.13742314279079437}
{"mode": "train", "epochs": 1, "timestep": 233, "ep_reward": 126.51412200927734, "reward": 0.3661156892776489, "action": 0.7738133668899536}
{"mode": "train", "epochs": 1, "timestep": 234, "ep_reward": 126.96219635009766, "reward": 0.44807302951812744, "action": 0.9108205437660217}
{"mode": "train", "epochs": 1, "timestep": 235, "ep_reward": 127.48629760742188, "reward": 0.5240985155105591, "action": -0.12007476389408112}
{"mode": "train", "epochs": 1, "timestep": 236, "ep_reward": 128.0725860595703, "reward": 0.5862882137298584, "action": 0.3938963711261749}
{"mode": "train", "epochs": 1, "timestep": 237, "ep_reward": 128.71334838867188, "reward": 0.6407582759857178, "action": 0.2995525300502777}
{"mode": "train", "epochs": 1, "timestep": 238, "ep_reward": 129.39540100097656, "reward": 0.6820590496063232, "action": -0.6636207103729248}
{"mode": "train", "epochs": 1, "timestep": 239, "ep_reward": 130.1046600341797, "reward": 0.7092649936676025, "action": 0.021887637674808502}
{"mode": "train", "epochs": 1, "timestep": 240, "ep_reward": 130.83009338378906, "reward": 0.7254273891448975, "action": 0.21633866429328918}
{"mode": "train", "epochs": 1, "timestep": 241, "ep_reward": 131.5574188232422, "reward": 0.7273291349411011, "action": 1.1219395399093628}
{"mode": "train", "epochs": 1, "timestep": 242, "ep_reward": 132.26869201660156, "reward": 0.71127849817276, "action": 1.099557638168335}
{"mode": "train", "epochs": 1, "timestep": 243, "ep_reward": 132.94479370117188, "reward": 0.6761041879653931, "action": -0.023076988756656647}
{"mode": "train", "epochs": 1, "timestep": 244, "ep_reward": 133.5741424560547, "reward": 0.6293557286262512, "action": -0.6778435707092285}
{"mode": "train", "epochs": 1, "timestep": 245, "ep_reward": 134.14927673339844, "reward": 0.5751345157623291, "action": -0.25573402643203735}
{"mode": "train", "epochs": 1, "timestep": 246, "ep_reward": 134.65878295898438, "reward": 0.5095028877258301, "action": 0.7041095495223999}
{"mode": "train", "epochs": 1, "timestep": 247, "ep_reward": 135.0868377685547, "reward": 0.4280511140823364, "action": -0.04121537506580353}
{"mode": "train", "epochs": 1, "timestep": 248, "ep_reward": 135.43353271484375, "reward": 0.346696138381958, "action": -0.5939738750457764}
{"mode": "train", "epochs": 1, "timestep": 249, "ep_reward": 135.74050903320312, "reward": 0.30697011947631836, "action": 0.06613389402627945}
{"mode": "train", "epochs": 1, "timestep": 250, "ep_reward": 136.12095642089844, "reward": 0.3804510235786438, "action": -0.45696890354156494}
{"mode": "train", "epochs": 1, "timestep": 251, "ep_reward": 136.57635498046875, "reward": 0.45539236068725586, "action": 0.7101485729217529}
{"mode": "train", "epochs": 1, "timestep": 252, "ep_reward": 137.09674072265625, "reward": 0.5203802585601807, "action": -0.3691011667251587}
{"mode": "train", "epochs": 1, "timestep": 253, "ep_reward": 137.6813201904297, "reward": 0.5845749974250793, "action": 1.274756908416748}
{"mode": "train", "epochs": 1, "timestep": 254, "ep_reward": 138.3152313232422, "reward": 0.6339120864868164, "action": 0.8041998147964478}
{"mode": "train", "epochs": 1, "timestep": 255, "ep_reward": 138.99288940429688, "reward": 0.6776620745658875, "action": -0.2330000102519989}
{"mode": "train", "epochs": 1, "timestep": 256, "ep_reward": 139.7058563232422, "reward": 0.7129625082015991, "action": -0.6793736815452576}
{"mode": "train", "epochs": 1, "timestep": 257, "ep_reward": 140.43948364257812, "reward": 0.7336231470108032, "action": 0.12030166387557983}
{"mode": "train", "epochs": 1, "timestep": 258, "ep_reward": 141.17816162109375, "reward": 0.7386830449104309, "action": 0.0702720358967781}
{"mode": "train", "epochs": 1, "timestep": 259, "ep_reward": 141.9081268310547, "reward": 0.7299647927284241, "action": -0.7394572496414185}
{"mode": "train", "epochs": 1, "timestep": 260, "ep_reward": 142.6120147705078, "reward": 0.7038918733596802, "action": 0.34691256284713745}
{"mode": "train", "epochs": 1, "timestep": 261, "ep_reward": 143.27850341796875, "reward": 0.6664813756942749, "action": 0.24588407576084137}
{"mode": "train", "epochs": 1, "timestep": 262, "ep_reward": 143.8948974609375, "reward": 0.6163935661315918, "action": 0.36059603095054626}
{"mode": "train", "epochs": 1, "timestep": 263, "ep_reward": 144.45094299316406, "reward": 0.5560442209243774, "action": 0.22069714963436127}
{"mode": "train", "epochs": 1, "timestep": 264, "ep_reward": 144.9368133544922, "reward": 0.48586636781692505, "action": -0.08457212150096893}
{"mode": "train", "epochs": 1, "timestep": 265, "ep_reward": 145.3433380126953, "reward": 0.4065260887145996, "action": 0.23607689142227173}
{"mode": "train", "epochs": 1, "timestep": 266, "ep_reward": 145.67001342773438, "reward": 0.32667654752731323, "action": -0.21425560116767883}
{"mode": "train", "epochs": 1, "timestep": 267, "ep_reward": 145.99383544921875, "reward": 0.3238152265548706, "action": 0.07684793323278427}
{"mode": "train", "epochs": 1, "timestep": 268, "ep_reward": 146.3934783935547, "reward": 0.39964759349823, "action": 0.6353008151054382}
{"mode": "train", "epochs": 1, "timestep": 269, "ep_reward": 146.86935424804688, "reward": 0.47588294744491577, "action": 0.7605704069137573}
{"mode": "train", "epochs": 1, "timestep": 270, "ep_reward": 147.4148406982422, "reward": 0.5454792380332947, "action": 0.1686006784439087}
{"mode": "train", "epochs": 1, "timestep": 271, "ep_reward": 148.0176544189453, "reward": 0.6028149127960205, "action": -0.2176709771156311}
{"mode": "train", "epochs": 1, "timestep": 272, "ep_reward": 148.66650390625, "reward": 0.6488557457923889, "action": 0.050527650862932205}
{"mode": "train", "epochs": 1, "timestep": 273, "ep_reward": 149.35101318359375, "reward": 0.684508204460144, "action": 0.24259281158447266}
{"mode": "train", "epochs": 1, "timestep": 274, "ep_reward": 150.05831909179688, "reward": 0.7073071002960205, "action": 0.7078796029090881}
{"mode": "train", "epochs": 1, "timestep": 275, "ep_reward": 150.7735137939453, "reward": 0.7151945233345032, "action": -0.06743190437555313}
{"mode": "train", "epochs": 1, "timestep": 276, "ep_reward": 151.4821014404297, "reward": 0.7085883021354675, "action": 0.2088710367679596}
{"mode": "train", "epochs": 1, "timestep": 277, "ep_reward": 152.1697235107422, "reward": 0.6876192092895508, "action": 0.16967949271202087}
{"mode": "train", "epochs": 1, "timestep": 278, "ep_reward": 152.82229614257812, "reward": 0.6525706648826599, "action": -0.3503214120864868}
{"mode": "train", "epochs": 1, "timestep": 279, "ep_reward": 153.4296875, "reward": 0.6073873043060303, "action": -1.008561611175537}
{"mode": "train", "epochs": 1, "timestep": 280, "ep_reward": 153.98684692382812, "reward": 0.5571520328521729, "action": -0.8046025633811951}
{"mode": "train", "epochs": 1, "timestep": 281, "ep_reward": 154.4866180419922, "reward": 0.4997747540473938, "action": 0.8150902390480042}
{"mode": "train", "epochs": 1, "timestep": 282, "ep_reward": 154.9109649658203, "reward": 0.4243529438972473, "action": 1.221097707748413}
{"mode": "train", "epochs": 1, "timestep": 283, "ep_reward": 155.2489471435547, "reward": 0.337982714176178, "action": 0.058975622057914734}
{"mode": "train", "epochs": 1, "timestep": 284, "ep_reward": 155.5721893310547, "reward": 0.32323503494262695, "action": 0.950552761554718}
{"mode": "train", "epochs": 1, "timestep": 285, "ep_reward": 155.96395874023438, "reward": 0.3917628526687622, "action": -0.06877703964710236}
{"mode": "train", "epochs": 1, "timestep": 286, "ep_reward": 156.42999267578125, "reward": 0.4660322070121765, "action": -0.10076917707920074}
{"mode": "train", "epochs": 1, "timestep": 287, "ep_reward": 156.96566772460938, "reward": 0.5356692671775818, "action": -0.5679647922515869}
{"mode": "train", "epochs": 1, "timestep": 288, "ep_reward": 157.5646514892578, "reward": 0.5989799499511719, "action": 0.4805028438568115}
{"mode": "train", "epochs": 1, "timestep": 289, "ep_reward": 158.2124481201172, "reward": 0.6478037238121033, "action": 0.32642436027526855}
{"mode": "train", "epochs": 1, "timestep": 290, "ep_reward": 158.89952087402344, "reward": 0.687065839767456, "action": 0.9919546842575073}
{"mode": "train", "epochs": 1, "timestep": 291, "ep_reward": 159.6141815185547, "reward": 0.7146678566932678, "action": -0.5237393975257874}
{"mode": "train", "epochs": 1, "timestep": 292, "ep_reward": 160.34613037109375, "reward": 0.7319556474685669, "action": -0.23755347728729248}
{"mode": "train", "epochs": 1, "timestep": 293, "ep_reward": 161.0796661376953, "reward": 0.7335377931594849, "action": -0.8506921529769897}
{"mode": "train", "epochs": 1, "timestep": 294, "ep_reward": 161.79759216308594, "reward": 0.7179237008094788, "action": 0.33109626173973083}
{"mode": "train", "epochs": 1, "timestep": 295, "ep_reward": 162.48748779296875, "reward": 0.6898963451385498, "action": 1.0543158054351807}
{"mode": "train", "epochs": 1, "timestep": 296, "ep_reward": 163.14134216308594, "reward": 0.6538546085357666, "action": 0.2074836641550064}
{"mode": "train", "epochs": 1, "timestep": 297, "ep_reward": 163.74473571777344, "reward": 0.6033933162689209, "action": -0.8851401805877686}
{"mode": "train", "epochs": 1, "timestep": 298, "ep_reward": 164.27822875976562, "reward": 0.5334979295730591, "action": 0.7986135482788086}
{"mode": "train", "epochs": 1, "timestep": 299, "ep_reward": 164.7439727783203, "reward": 0.46574127674102783, "action": 0.008156143128871918}
{"mode": "train", "epochs": 1, "timestep": 300, "ep_reward": 165.13134765625, "reward": 0.38737815618515015, "action": 0.1580706238746643}
{"mode": "train", "epochs": 1, "timestep": 301, "ep_reward": 165.43948364257812, "reward": 0.3081362843513489, "action": -0.729106605052948}
{"mode": "train", "epochs": 1, "timestep": 302, "ep_reward": 165.78271484375, "reward": 0.34322524070739746, "action": -1.0365244150161743}
{"mode": "train", "epochs": 1, "timestep": 303, "ep_reward": 166.1965789794922, "reward": 0.41386836767196655, "action": -0.5174278020858765}
{"mode": "train", "epochs": 1, "timestep": 304, "ep_reward": 166.6840057373047, "reward": 0.4874301552772522, "action": 0.7854145765304565}
{"mode": "train", "epochs": 1, "timestep": 305, "ep_reward": 167.2465362548828, "reward": 0.562529444694519, "action": 0.06481727957725525}
{"mode": "train", "epochs": 1, "timestep": 306, "ep_reward": 167.87002563476562, "reward": 0.6234925985336304, "action": 0.48876726627349854}
{"mode": "train", "epochs": 1, "timestep": 307, "ep_reward": 168.5441131591797, "reward": 0.6740947961807251, "action": 0.608620285987854}
{"mode": "train", "epochs": 1, "timestep": 308, "ep_reward": 169.25428771972656, "reward": 0.7101819515228271, "action": 0.09830368310213089}
{"mode": "train", "epochs": 1, "timestep": 309, "ep_reward": 169.98463439941406, "reward": 0.730343222618103, "action": 0.7266677618026733}
{"mode": "train", "epochs": 1, "timestep": 310, "ep_reward": 170.71983337402344, "reward": 0.7351992130279541, "action": 0.4221034646034241}
{"mode": "train", "epochs": 1, "timestep": 311, "ep_reward": 171.4434356689453, "reward": 0.7235987186431885, "action": -0.07968562841415405}
{"mode": "train", "epochs": 1, "timestep": 312, "ep_reward": 172.1415557861328, "reward": 0.6981240510940552, "action": 1.0776485204696655}
{"mode": "train", "epochs": 1, "timestep": 313, "ep_reward": 172.79393005371094, "reward": 0.6523740291595459, "action": 0.6038100719451904}
{"mode": "train", "epochs": 1, "timestep": 314, "ep_reward": 173.38563537597656, "reward": 0.5917024612426758, "action": -0.36827170848846436}
{"mode": "train", "epochs": 1, "timestep": 315, "ep_reward": 173.91043090820312, "reward": 0.5247975587844849, "action": 1.3337119817733765}
{"mode": "train", "epochs": 1, "timestep": 316, "ep_reward": 174.3448028564453, "reward": 0.43437427282333374, "action": 0.1713663935661316}
{"mode": "train", "epochs": 1, "timestep": 317, "ep_reward": 174.68984985351562, "reward": 0.3450464606285095, "action": -0.048697471618652344}
{"mode": "train", "epochs": 1, "timestep": 318, "ep_reward": 174.9718475341797, "reward": 0.28199416399002075, "action": 0.7901076674461365}
{"mode": "train", "epochs": 1, "timestep": 319, "ep_reward": 175.33056640625, "reward": 0.35872310400009155, "action": 0.3480600118637085}
{"mode": "train", "epochs": 1, "timestep": 320, "ep_reward": 175.7699432373047, "reward": 0.4393816590309143, "action": 1.3992996215820312}
{"mode": "train", "epochs": 1, "timestep": 321, "ep_reward": 176.28199768066406, "reward": 0.5120539665222168, "action": 0.46731650829315186}
{"mode": "train", "epochs": 1, "timestep": 322, "ep_reward": 176.868408203125, "reward": 0.5864164233207703, "action": 1.2772605419158936}
{"mode": "train", "epochs": 1, "timestep": 323, "ep_reward": 177.5172119140625, "reward": 0.6487971544265747, "action": 1.5027267932891846}
{"mode": "train", "epochs": 1, "timestep": 324, "ep_reward": 178.21951293945312, "reward": 0.7023014426231384, "action": 1.9648348093032837}
{"mode": "train", "epochs": 1, "timestep": 325, "ep_reward": 178.965576171875, "reward": 0.7460567951202393, "action": 1.5642834901809692}
{"mode": "train", "epochs": 1, "timestep": 326, "ep_reward": 179.7486114501953, "reward": 0.7830415964126587, "action": 0.4781169593334198}
{"mode": "train", "epochs": 1, "timestep": 327, "ep_reward": 180.56057739257812, "reward": 0.8119648098945618, "action": 0.9237867593765259}
{"mode": "train", "epochs": 1, "timestep": 328, "ep_reward": 181.38868713378906, "reward": 0.8281049132347107, "action": 0.48117297887802124}
{"mode": "train", "epochs": 1, "timestep": 329, "ep_reward": 182.2213592529297, "reward": 0.8326753377914429, "action": 0.6105659604072571}
{"mode": "train", "epochs": 1, "timestep": 330, "ep_reward": 183.04629516601562, "reward": 0.8249354958534241, "action": 0.13680505752563477}
{"mode": "train", "epochs": 1, "timestep": 331, "ep_reward": 183.84889221191406, "reward": 0.8025981187820435, "action": -1.9231059551239014}
{"mode": "train", "epochs": 1, "timestep": 332, "ep_reward": 184.6025848388672, "reward": 0.7536876201629639, "action": -0.4059904217720032}
{"mode": "train", "epochs": 1, "timestep": 333, "ep_reward": 185.29244995117188, "reward": 0.6898640394210815, "action": -0.5506590604782104}
{"mode": "train", "epochs": 1, "timestep": 334, "ep_reward": 185.89828491210938, "reward": 0.6058366298675537, "action": -0.9597944617271423}
{"mode": "train", "epochs": 1, "timestep": 335, "ep_reward": 186.39736938476562, "reward": 0.49908918142318726, "action": -1.6024267673492432}
{"mode": "train", "epochs": 1, "timestep": 336, "ep_reward": 186.76524353027344, "reward": 0.3678719997406006, "action": -0.8588962554931641}
{"mode": "train", "epochs": 1, "timestep": 337, "ep_reward": 186.99827575683594, "reward": 0.23302572965621948, "action": -1.5318357944488525}
{"mode": "train", "epochs": 1, "timestep": 338, "ep_reward": 187.2013397216797, "reward": 0.20306700468063354, "action": -1.1641987562179565}
{"mode": "train", "epochs": 1, "timestep": 339, "ep_reward": 187.50975036621094, "reward": 0.3084107041358948, "action": -1.5703564882278442}
{"mode": "train", "epochs": 1, "timestep": 340, "ep_reward": 187.92245483398438, "reward": 0.4127039313316345, "action": -1.5743157863616943}
{"mode": "train", "epochs": 1, "timestep": 341, "ep_reward": 188.43792724609375, "reward": 0.5154657959938049, "action": 0.12407803535461426}
{"mode": "train", "epochs": 1, "timestep": 342, "ep_reward": 189.06268310546875, "reward": 0.6247634887695312, "action": -1.13455331325531}
{"mode": "train", "epochs": 1, "timestep": 343, "ep_reward": 189.7706298828125, "reward": 0.7079435586929321, "action": -1.6182184219360352}
{"mode": "train", "epochs": 1, "timestep": 344, "ep_reward": 190.54457092285156, "reward": 0.7739419937133789, "action": -1.1083509922027588}
{"mode": "train", "epochs": 1, "timestep": 345, "ep_reward": 191.37451171875, "reward": 0.829935610294342, "action": -1.286838173866272}
{"mode": "train", "epochs": 1, "timestep": 346, "ep_reward": 192.246826171875, "reward": 0.8723068237304688, "action": -1.3088884353637695}
{"mode": "train", "epochs": 1, "timestep": 347, "ep_reward": 193.1511688232422, "reward": 0.9043375849723816, "action": -1.2026889324188232}
{"mode": "train", "epochs": 1, "timestep": 348, "ep_reward": 194.0797882080078, "reward": 0.9286223649978638, "action": -0.5629544258117676}
{"mode": "train", "epochs": 1, "timestep": 349, "ep_reward": 195.02774047851562, "reward": 0.9479457139968872, "action": -1.0221962928771973}
{"mode": "train", "epochs": 1, "timestep": 350, "ep_reward": 195.98818969726562, "reward": 0.9604421257972717, "action": -1.0121251344680786}
{"mode": "train", "epochs": 1, "timestep": 351, "ep_reward": 196.9573974609375, "reward": 0.9692075848579407, "action": -0.45375752449035645}
{"mode": "train", "epochs": 1, "timestep": 352, "ep_reward": 197.9328155517578, "reward": 0.9754156470298767, "action": -0.7349168658256531}
{"mode": "train", "epochs": 1, "timestep": 353, "ep_reward": 198.91131591796875, "reward": 0.9784938097000122, "action": 0.37342965602874756}
{"mode": "train", "epochs": 1, "timestep": 354, "ep_reward": 199.8898468017578, "reward": 0.9785292744636536, "action": 0.4460635781288147}
{"mode": "train", "epochs": 1, "timestep": 355, "ep_reward": 200.8637237548828, "reward": 0.9738738536834717, "action": 1.021399974822998}
{"mode": "train", "epochs": 1, "timestep": 356, "ep_reward": 201.8260498046875, "reward": 0.9623317718505859, "action": 0.9447116255760193}
{"mode": "train", "epochs": 1, "timestep": 357, "ep_reward": 202.7686309814453, "reward": 0.9425793886184692, "action": 1.1744086742401123}
{"mode": "train", "epochs": 1, "timestep": 358, "ep_reward": 203.67930603027344, "reward": 0.910673201084137, "action": 1.4282668828964233}
{"mode": "train", "epochs": 1, "timestep": 359, "ep_reward": 204.5408172607422, "reward": 0.8615158200263977, "action": 1.0351072549819946}
{"mode": "train", "epochs": 1, "timestep": 360, "ep_reward": 205.3348846435547, "reward": 0.7940738201141357, "action": 1.0899019241333008}
{"mode": "train", "epochs": 1, "timestep": 361, "ep_reward": 206.03561401367188, "reward": 0.7007229328155518, "action": 0.00972217321395874}
{"mode": "train", "epochs": 1, "timestep": 362, "ep_reward": 206.62625122070312, "reward": 0.5906403660774231, "action": 1.6052823066711426}
{"mode": "train", "epochs": 1, "timestep": 363, "ep_reward": 207.05860900878906, "reward": 0.43236154317855835, "action": 1.239367961883545}
{"mode": "train", "epochs": 1, "timestep": 364, "ep_reward": 207.30836486816406, "reward": 0.24975603818893433, "action": 1.6866955757141113}
{"mode": "train", "epochs": 1, "timestep": 365, "ep_reward": 207.377685546875, "reward": 0.06931853294372559, "action": 1.0608550310134888}
{"mode": "train", "epochs": 1, "timestep": 366, "ep_reward": 207.42654418945312, "reward": 0.048863351345062256, "action": 0.6869850158691406}
{"mode": "train", "epochs": 1, "timestep": 367, "ep_reward": 207.61598205566406, "reward": 0.18943822383880615, "action": 0.9539151787757874}
{"mode": "train", "epochs": 1, "timestep": 368, "ep_reward": 207.94569396972656, "reward": 0.3297111392021179, "action": 1.3327769041061401}
{"mode": "train", "epochs": 1, "timestep": 369, "ep_reward": 208.405517578125, "reward": 0.4598190188407898, "action": 1.3360539674758911}
{"mode": "train", "epochs": 1, "timestep": 370, "ep_reward": 208.9815673828125, "reward": 0.5760530233383179, "action": 0.9598279595375061}
{"mode": "train", "epochs": 1, "timestep": 371, "ep_reward": 209.657470703125, "reward": 0.675901472568512, "action": 1.664100170135498}
{"mode": "train", "epochs": 1, "timestep": 372, "ep_reward": 210.40322875976562, "reward": 0.7457578182220459, "action": 0.7947467565536499}
{"mode": "train", "epochs": 1, "timestep": 373, "ep_reward": 211.20558166503906, "reward": 0.8023569583892822, "action": 0.7188580632209778}
{"mode": "train", "epochs": 1, "timestep": 374, "ep_reward": 212.04437255859375, "reward": 0.8387881517410278, "action": 0.9912823438644409}
{"mode": "train", "epochs": 1, "timestep": 375, "ep_reward": 212.8985137939453, "reward": 0.8541445136070251, "action": 1.5156466960906982}
{"mode": "train", "epochs": 1, "timestep": 376, "ep_reward": 213.7455291748047, "reward": 0.8470094203948975, "action": 0.47925591468811035}
{"mode": "train", "epochs": 1, "timestep": 377, "ep_reward": 214.57508850097656, "reward": 0.8295621871948242, "action": 1.7557730674743652}
{"mode": "train", "epochs": 1, "timestep": 378, "ep_reward": 215.3513641357422, "reward": 0.7762782573699951, "action": 1.5269861221313477}
{"mode": "train", "epochs": 1, "timestep": 379, "ep_reward": 216.0453643798828, "reward": 0.6940049529075623, "action": 0.7461881637573242}
{"mode": "train", "epochs": 1, "timestep": 380, "ep_reward": 216.6287841796875, "reward": 0.5834267139434814, "action": 1.2644073963165283}
{"mode": "train", "epochs": 1, "timestep": 381, "ep_reward": 217.051513671875, "reward": 0.4227280616760254, "action": 1.5848023891448975}
{"mode": "train", "epochs": 1, "timestep": 382, "ep_reward": 217.37326049804688, "reward": 0.32174140214920044, "action": 0.36417967081069946}
{"mode": "train", "epochs": 1, "timestep": 383, "ep_reward": 217.57933044433594, "reward": 0.20607370138168335, "action": 1.6837750673294067}
{"mode": "train", "epochs": 1, "timestep": 384, "ep_reward": 217.65005493164062, "reward": 0.07072609663009644, "action": 0.647022008895874}
{"mode": "train", "epochs": 1, "timestep": 385, "ep_reward": 217.69749450683594, "reward": 0.04743772745132446, "action": 1.0118001699447632}
{"mode": "train", "epochs": 1, "timestep": 386, "ep_reward": 217.88365173339844, "reward": 0.1861521601676941, "action": 0.3982190489768982}
{"mode": "train", "epochs": 1, "timestep": 387, "ep_reward": 218.21728515625, "reward": 0.33362674713134766, "action": 1.6132004261016846}
{"mode": "train", "epochs": 1, "timestep": 388, "ep_reward": 218.67686462402344, "reward": 0.4595736861228943, "action": 1.3199408054351807}
{"mode": "train", "epochs": 1, "timestep": 389, "ep_reward": 219.25270080566406, "reward": 0.5758329629898071, "action": 1.7301092147827148}
{"mode": "train", "epochs": 1, "timestep": 390, "ep_reward": 219.92062377929688, "reward": 0.6679158210754395, "action": 0.6603302955627441}
{"mode": "train", "epochs": 1, "timestep": 391, "ep_reward": 220.6693878173828, "reward": 0.7487590909004211, "action": 1.322723150253296}
{"mode": "train", "epochs": 1, "timestep": 392, "ep_reward": 221.4696502685547, "reward": 0.8002627491950989, "action": 1.0764188766479492}
{"mode": "train", "epochs": 1, "timestep": 393, "ep_reward": 222.30337524414062, "reward": 0.8337230682373047, "action": 1.8138189315795898}
{"mode": "train", "epochs": 1, "timestep": 394, "ep_reward": 223.14511108398438, "reward": 0.841731071472168, "action": 1.713489055633545}
{"mode": "train", "epochs": 1, "timestep": 395, "ep_reward": 223.9762420654297, "reward": 0.8311245441436768, "action": 1.6592578887939453}
{"mode": "train", "epochs": 1, "timestep": 396, "ep_reward": 224.7746124267578, "reward": 0.7983744144439697, "action": 1.320418119430542}
{"mode": "train", "epochs": 1, "timestep": 397, "ep_reward": 225.5159454345703, "reward": 0.7413336634635925, "action": 1.0059245824813843}
{"mode": "train", "epochs": 1, "timestep": 398, "ep_reward": 226.1698760986328, "reward": 0.6539280414581299, "action": 0.006688117980957031}
{"mode": "train", "epochs": 1, "timestep": 399, "ep_reward": 226.71075439453125, "reward": 0.5408762693405151, "action": 1.1455591917037964}
{"mode": "train", "epochs": 1, "timestep": 400, "ep_reward": 227.1055908203125, "reward": 0.39483267068862915, "action": 1.2503668069839478}
{"mode": "train", "epochs": 1, "timestep": 401, "ep_reward": 227.3998260498047, "reward": 0.29423946142196655, "action": 1.3956921100616455}
{"mode": "train", "epochs": 1, "timestep": 402, "ep_reward": 227.5735626220703, "reward": 0.17374086380004883, "action": 0.9064939022064209}
{"mode": "train", "epochs": 1, "timestep": 403, "ep_reward": 227.606689453125, "reward": 0.03312891721725464, "action": 1.2280292510986328}
{"mode": "train", "epochs": 1, "timestep": 404, "ep_reward": 227.69117736816406, "reward": 0.08448827266693115, "action": 0.9688147306442261}
{"mode": "train", "epochs": 1, "timestep": 405, "ep_reward": 227.91380310058594, "reward": 0.22262156009674072, "action": 1.332842230796814}
{"mode": "train", "epochs": 1, "timestep": 406, "ep_reward": 228.27174377441406, "reward": 0.3579380512237549, "action": 1.6303982734680176}
{"mode": "train", "epochs": 1, "timestep": 407, "ep_reward": 228.75454711914062, "reward": 0.4828064441680908, "action": 1.0532797574996948}
{"mode": "train", "epochs": 1, "timestep": 408, "ep_reward": 229.35345458984375, "reward": 0.5989058017730713, "action": 1.1081321239471436}
{"mode": "train", "epochs": 1, "timestep": 409, "ep_reward": 230.04559326171875, "reward": 0.6921449899673462, "action": 0.6384878158569336}
{"mode": "train", "epochs": 1, "timestep": 410, "ep_reward": 230.8119659423828, "reward": 0.7663743495941162, "action": 1.2344154119491577}
{"mode": "train", "epochs": 1, "timestep": 411, "ep_reward": 231.62442016601562, "reward": 0.8124545812606812, "action": 0.8714818954467773}
{"mode": "train", "epochs": 1, "timestep": 412, "ep_reward": 232.46646118164062, "reward": 0.842045247554779, "action": 1.0379568338394165}
{"mode": "train", "epochs": 1, "timestep": 413, "ep_reward": 233.318115234375, "reward": 0.8516541123390198, "action": 1.0769360065460205}
{"mode": "train", "epochs": 1, "timestep": 414, "ep_reward": 234.1604461669922, "reward": 0.8423313498497009, "action": 1.2687773704528809}
{"mode": "train", "epochs": 1, "timestep": 415, "ep_reward": 234.97056579589844, "reward": 0.8101158142089844, "action": 1.6188585758209229}
{"mode": "train", "epochs": 1, "timestep": 416, "ep_reward": 235.7184295654297, "reward": 0.7478569746017456, "action": 0.7142491340637207}
{"mode": "train", "epochs": 1, "timestep": 417, "ep_reward": 236.38107299804688, "reward": 0.6626497507095337, "action": 1.2765607833862305}
{"mode": "train", "epochs": 1, "timestep": 418, "ep_reward": 236.91184997558594, "reward": 0.5307818651199341, "action": 1.52874755859375}
{"mode": "train", "epochs": 1, "timestep": 419, "ep_reward": 237.29916381835938, "reward": 0.38731926679611206, "action": 0.8633963465690613}
{"mode": "train", "epochs": 1, "timestep": 420, "ep_reward": 237.58424377441406, "reward": 0.2850763201713562, "action": 1.0210336446762085}
{"mode": "train", "epochs": 1, "timestep": 421, "ep_reward": 237.7471466064453, "reward": 0.16290831565856934, "action": 0.37275761365890503}
{"mode": "train", "epochs": 1, "timestep": 422, "ep_reward": 237.76776123046875, "reward": 0.020609021186828613, "action": 1.1571217775344849}
{"mode": "train", "epochs": 1, "timestep": 423, "ep_reward": 237.8639678955078, "reward": 0.09620928764343262, "action": 1.566849708557129}
{"mode": "train", "epochs": 1, "timestep": 424, "ep_reward": 238.09217834472656, "reward": 0.22821581363677979, "action": 1.1424254179000854}
{"mode": "train", "epochs": 1, "timestep": 425, "ep_reward": 238.4590301513672, "reward": 0.36684495210647583, "action": 1.3250689506530762}
{"mode": "train", "epochs": 1, "timestep": 426, "ep_reward": 238.95376586914062, "reward": 0.4947325587272644, "action": 1.512014389038086}
{"mode": "train", "epochs": 1, "timestep": 427, "ep_reward": 239.55743408203125, "reward": 0.6036690473556519, "action": 1.680009365081787}
{"mode": "train", "epochs": 1, "timestep": 428, "ep_reward": 240.246826171875, "reward": 0.6893895864486694, "action": 1.2182040214538574}
{"mode": "train", "epochs": 1, "timestep": 429, "ep_reward": 241.003662109375, "reward": 0.7568349838256836, "action": 1.1035511493682861}
{"mode": "train", "epochs": 1, "timestep": 430, "ep_reward": 241.80612182617188, "reward": 0.802454948425293, "action": 0.2392798662185669}
{"mode": "train", "epochs": 1, "timestep": 431, "ep_reward": 242.64076232910156, "reward": 0.834641695022583, "action": 1.06586754322052}
{"mode": "train", "epochs": 1, "timestep": 432, "ep_reward": 243.47970581054688, "reward": 0.8389359712600708, "action": 1.2884907722473145}
{"mode": "train", "epochs": 1, "timestep": 433, "ep_reward": 244.30029296875, "reward": 0.8205810785293579, "action": 0.5720721483230591}
{"mode": "train", "epochs": 1, "timestep": 434, "ep_reward": 245.08604431152344, "reward": 0.7857482433319092, "action": 0.9791061878204346}
{"mode": "train", "epochs": 1, "timestep": 435, "ep_reward": 245.8044891357422, "reward": 0.7184466123580933, "action": 0.018909871578216553}
{"mode": "train", "epochs": 1, "timestep": 436, "ep_reward": 246.43344116210938, "reward": 0.6289476156234741, "action": 0.4118346571922302}
{"mode": "train", "epochs": 1, "timestep": 437, "ep_reward": 246.93003845214844, "reward": 0.49659305810928345, "action": 1.4435760974884033}
{"mode": "train", "epochs": 1, "timestep": 438, "ep_reward": 247.28575134277344, "reward": 0.355707049369812, "action": 1.4933704137802124}
{"mode": "train", "epochs": 1, "timestep": 439, "ep_reward": 247.5327606201172, "reward": 0.24700945615768433, "action": -0.46098196506500244}
{"mode": "train", "epochs": 1, "timestep": 440, "ep_reward": 247.65086364746094, "reward": 0.11810368299484253, "action": 1.2357662916183472}
{"mode": "train", "epochs": 1, "timestep": 441, "ep_reward": 247.64759826660156, "reward": -0.003270387649536133, "action": 0.8214932680130005}
{"mode": "train", "epochs": 1, "timestep": 442, "ep_reward": 247.78968811035156, "reward": 0.14209198951721191, "action": 0.4931371212005615}
{"mode": "train", "epochs": 1, "timestep": 443, "ep_reward": 248.07742309570312, "reward": 0.28773778676986694, "action": 0.8150047659873962}
{"mode": "train", "epochs": 1, "timestep": 444, "ep_reward": 248.50332641601562, "reward": 0.42590785026550293, "action": 0.6922190189361572}
{"mode": "train", "epochs": 1, "timestep": 445, "ep_reward": 249.05642700195312, "reward": 0.5530990958213806, "action": 0.7873674631118774}
{"mode": "train", "epochs": 1, "timestep": 446, "ep_reward": 249.716064453125, "reward": 0.6596380472183228, "action": 0.10889047384262085}
{"mode": "train", "epochs": 1, "timestep": 447, "ep_reward": 250.46627807617188, "reward": 0.7502179741859436, "action": 0.280401349067688}
{"mode": "train", "epochs": 1, "timestep": 448, "ep_reward": 251.282470703125, "reward": 0.8161860704421997, "action": 1.477249264717102}
{"mode": "train", "epochs": 1, "timestep": 449, "ep_reward": 252.1363983154297, "reward": 0.8539211750030518, "action": 0.471357524394989}
{"mode": "train", "epochs": 1, "timestep": 450, "ep_reward": 253.02072143554688, "reward": 0.8843178153038025, "action": 1.0150295495986938}
{"mode": "train", "epochs": 1, "timestep": 451, "ep_reward": 253.91787719726562, "reward": 0.897162675857544, "action": 0.7051125168800354}
{"mode": "train", "epochs": 1, "timestep": 452, "ep_reward": 254.8177490234375, "reward": 0.8998656272888184, "action": 0.854636549949646}
{"mode": "train", "epochs": 1, "timestep": 453, "ep_reward": 255.70639038085938, "reward": 0.8886467218399048, "action": 0.5258578062057495}
{"mode": "train", "epochs": 1, "timestep": 454, "ep_reward": 256.5716552734375, "reward": 0.8652791976928711, "action": 0.7310600280761719}
{"mode": "train", "epochs": 1, "timestep": 455, "ep_reward": 257.3937072753906, "reward": 0.8220523595809937, "action": 0.8935363292694092}
{"mode": "train", "epochs": 1, "timestep": 456, "ep_reward": 258.1470031738281, "reward": 0.7532858848571777, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 457, "ep_reward": 258.7868347167969, "reward": 0.6398367881774902, "action": 1.1248390674591064}
{"mode": "train", "epochs": 1, "timestep": 458, "ep_reward": 259.2834167480469, "reward": 0.4965696930885315, "action": 0.8273105025291443}
{"mode": "train", "epochs": 1, "timestep": 459, "ep_reward": 259.6183166503906, "reward": 0.3348879814147949, "action": 1.2543272972106934}
{"mode": "train", "epochs": 1, "timestep": 460, "ep_reward": 259.8402099609375, "reward": 0.2219012975692749, "action": 1.4177618026733398}
{"mode": "train", "epochs": 1, "timestep": 461, "ep_reward": 259.9291076660156, "reward": 0.0888940691947937, "action": 1.6649839878082275}
{"mode": "train", "epochs": 1, "timestep": 462, "ep_reward": 259.95751953125, "reward": 0.02841264009475708, "action": 0.9000475406646729}
{"mode": "train", "epochs": 1, "timestep": 463, "ep_reward": 260.1271667480469, "reward": 0.16966235637664795, "action": 0.15665334463119507}
{"mode": "train", "epochs": 1, "timestep": 464, "ep_reward": 260.4471130371094, "reward": 0.3199399709701538, "action": 1.1181411743164062}
{"mode": "train", "epochs": 1, "timestep": 465, "ep_reward": 260.8992919921875, "reward": 0.45218443870544434, "action": 0.7907314896583557}
{"mode": "train", "epochs": 1, "timestep": 466, "ep_reward": 261.47418212890625, "reward": 0.5748864412307739, "action": 1.1149446964263916}
{"mode": "train", "epochs": 1, "timestep": 467, "ep_reward": 262.1479797363281, "reward": 0.6737870573997498, "action": 1.9080750942230225}
{"mode": "train", "epochs": 1, "timestep": 468, "ep_reward": 262.891845703125, "reward": 0.743855893611908, "action": 0.4171454906463623}
{"mode": "train", "epochs": 1, "timestep": 469, "ep_reward": 263.6992492675781, "reward": 0.8073915243148804, "action": 0.9449350237846375}
{"mode": "train", "epochs": 1, "timestep": 470, "ep_reward": 264.5453186035156, "reward": 0.8460798859596252, "action": 1.4266053438186646}
{"mode": "train", "epochs": 1, "timestep": 471, "ep_reward": 265.40924072265625, "reward": 0.8639336824417114, "action": 0.8394156098365784}
{"mode": "train", "epochs": 1, "timestep": 472, "ep_reward": 266.2799987792969, "reward": 0.8707495927810669, "action": 0.8903190493583679}
{"mode": "train", "epochs": 1, "timestep": 473, "ep_reward": 267.1407470703125, "reward": 0.860761284828186, "action": 1.3000807762145996}
{"mode": "train", "epochs": 1, "timestep": 474, "ep_reward": 267.96905517578125, "reward": 0.828295111656189, "action": 1.7571403980255127}
{"mode": "train", "epochs": 1, "timestep": 475, "ep_reward": 268.7359313964844, "reward": 0.7668624520301819, "action": 1.3095790147781372}
{"mode": "train", "epochs": 1, "timestep": 476, "ep_reward": 269.4139404296875, "reward": 0.6779993176460266, "action": 1.3443681001663208}
{"mode": "train", "epochs": 1, "timestep": 477, "ep_reward": 269.9634094238281, "reward": 0.549483597278595, "action": 0.6648823022842407}
{"mode": "train", "epochs": 1, "timestep": 478, "ep_reward": 270.3548583984375, "reward": 0.391457736492157, "action": 1.2162312269210815}
{"mode": "train", "epochs": 1, "timestep": 479, "ep_reward": 270.6450500488281, "reward": 0.2902039885520935, "action": 0.7282418012619019}
{"mode": "train", "epochs": 1, "timestep": 480, "ep_reward": 270.8138732910156, "reward": 0.16883844137191772, "action": 1.169782280921936}
{"mode": "train", "epochs": 1, "timestep": 481, "ep_reward": 270.8414611816406, "reward": 0.027581632137298584, "action": 0.681210994720459}
{"mode": "train", "epochs": 1, "timestep": 482, "ep_reward": 270.93133544921875, "reward": 0.08987236022949219, "action": -0.09860634803771973}
{"mode": "train", "epochs": 1, "timestep": 483, "ep_reward": 271.1727600097656, "reward": 0.2414175271987915, "action": 0.9517737030982971}
{"mode": "train", "epochs": 1, "timestep": 484, "ep_reward": 271.55133056640625, "reward": 0.3785783052444458, "action": 1.0225951671600342}
{"mode": "train", "epochs": 1, "timestep": 485, "ep_reward": 272.05810546875, "reward": 0.5067758560180664, "action": 0.4848989248275757}
{"mode": "train", "epochs": 1, "timestep": 486, "ep_reward": 272.6822509765625, "reward": 0.6241455078125, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 487, "ep_reward": 273.3871765136719, "reward": 0.7049334049224854, "action": 1.2056201696395874}
{"mode": "train", "epochs": 1, "timestep": 488, "ep_reward": 274.16082763671875, "reward": 0.7736611366271973, "action": 1.0220376253128052}
{"mode": "train", "epochs": 1, "timestep": 489, "ep_reward": 274.9846496582031, "reward": 0.823823869228363, "action": 1.1512590646743774}
{"mode": "train", "epochs": 1, "timestep": 490, "ep_reward": 275.8394775390625, "reward": 0.8548170924186707, "action": 0.41681885719299316}
{"mode": "train", "epochs": 1, "timestep": 491, "ep_reward": 276.71490478515625, "reward": 0.8754193782806396, "action": 1.4274839162826538}
{"mode": "train", "epochs": 1, "timestep": 492, "ep_reward": 277.58740234375, "reward": 0.8724995851516724, "action": 0.8998537659645081}
{"mode": "train", "epochs": 1, "timestep": 493, "ep_reward": 278.44482421875, "reward": 0.8574223518371582, "action": 1.7157639265060425}
{"mode": "train", "epochs": 1, "timestep": 494, "ep_reward": 279.2601013183594, "reward": 0.8152751922607422, "action": 1.2885061502456665}
{"mode": "train", "epochs": 1, "timestep": 495, "ep_reward": 280.0111389160156, "reward": 0.7510378956794739, "action": 1.345715045928955}
{"mode": "train", "epochs": 1, "timestep": 496, "ep_reward": 280.66412353515625, "reward": 0.6529920101165771, "action": 1.2402790784835815}
{"mode": "train", "epochs": 1, "timestep": 497, "ep_reward": 281.179931640625, "reward": 0.5158059000968933, "action": 1.0809568166732788}
{"mode": "train", "epochs": 1, "timestep": 498, "ep_reward": 281.5485534667969, "reward": 0.3686068654060364, "action": 1.329487919807434}
{"mode": "train", "epochs": 1, "timestep": 499, "ep_reward": 281.8110656738281, "reward": 0.2625086307525635, "action": 0.6265625953674316}
{"mode": "train", "epochs": 1, "timestep": 500, "ep_reward": 281.94732666015625, "reward": 0.13626998662948608, "action": 1.123433232307434}
{"mode": "train", "epochs": 1, "timestep": 501, "ep_reward": 281.9374084472656, "reward": -0.009917259216308594, "action": 1.1433501243591309}
{"mode": "train", "epochs": 1, "timestep": 502, "ep_reward": 282.0613708496094, "reward": 0.12397563457489014, "action": 1.23377525806427}
{"mode": "train", "epochs": 1, "timestep": 503, "ep_reward": 282.3213195800781, "reward": 0.2599525451660156, "action": 1.2600202560424805}
{"mode": "train", "epochs": 1, "timestep": 504, "ep_reward": 282.7167663574219, "reward": 0.39545977115631104, "action": 1.0714579820632935}
{"mode": "train", "epochs": 1, "timestep": 505, "ep_reward": 283.2398986816406, "reward": 0.5231372117996216, "action": 0.9233343601226807}
{"mode": "train", "epochs": 1, "timestep": 506, "ep_reward": 283.87359619140625, "reward": 0.6337051391601562, "action": 1.1160411834716797}
{"mode": "train", "epochs": 1, "timestep": 507, "ep_reward": 284.593017578125, "reward": 0.7194250822067261, "action": 0.7672353982925415}
{"mode": "train", "epochs": 1, "timestep": 508, "ep_reward": 285.37872314453125, "reward": 0.7856932878494263, "action": 1.0900601148605347}
{"mode": "train", "epochs": 1, "timestep": 509, "ep_reward": 286.20654296875, "reward": 0.8278312087059021, "action": 0.7003566026687622}
{"mode": "train", "epochs": 1, "timestep": 510, "ep_reward": 287.06121826171875, "reward": 0.8546764254570007, "action": 0.9061983823776245}
{"mode": "train", "epochs": 1, "timestep": 511, "ep_reward": 287.9235534667969, "reward": 0.862321138381958, "action": 1.6379785537719727}
{"mode": "train", "epochs": 1, "timestep": 512, "ep_reward": 288.7696228027344, "reward": 0.8460791707038879, "action": 0.9266506433486938}
{"mode": "train", "epochs": 1, "timestep": 513, "ep_reward": 289.58538818359375, "reward": 0.8157561421394348, "action": 0.6421661376953125}
{"mode": "train", "epochs": 1, "timestep": 514, "ep_reward": 290.34906005859375, "reward": 0.7636778354644775, "action": 1.9539265632629395}
{"mode": "train", "epochs": 1, "timestep": 515, "ep_reward": 291.0142822265625, "reward": 0.6652163863182068, "action": 0.9283314943313599}
{"mode": "train", "epochs": 1, "timestep": 516, "ep_reward": 291.5531921386719, "reward": 0.5389163494110107, "action": 0.46054792404174805}
{"mode": "train", "epochs": 1, "timestep": 517, "ep_reward": 291.93988037109375, "reward": 0.38669997453689575, "action": 0.43406909704208374}
{"mode": "train", "epochs": 1, "timestep": 518, "ep_reward": 292.22418212890625, "reward": 0.28429311513900757, "action": 0.9114201068878174}
{"mode": "train", "epochs": 1, "timestep": 519, "ep_reward": 292.3861083984375, "reward": 0.16191953420639038, "action": 0.9688664078712463}
{"mode": "train", "epochs": 1, "timestep": 520, "ep_reward": 292.4056701660156, "reward": 0.01955890655517578, "action": 0.9150369167327881}
{"mode": "train", "epochs": 1, "timestep": 521, "ep_reward": 292.5030212402344, "reward": 0.09736490249633789, "action": 0.30930131673812866}
{"mode": "train", "epochs": 1, "timestep": 522, "ep_reward": 292.7471008300781, "reward": 0.24409222602844238, "action": 1.060549020767212}
{"mode": "train", "epochs": 1, "timestep": 523, "ep_reward": 293.1278076171875, "reward": 0.3807132840156555, "action": 1.2114189863204956}
{"mode": "train", "epochs": 1, "timestep": 524, "ep_reward": 293.6349792480469, "reward": 0.5071789026260376, "action": 0.6920585632324219}
{"mode": "train", "epochs": 1, "timestep": 525, "ep_reward": 294.2577819824219, "reward": 0.6228084564208984, "action": 1.003127932548523}
{"mode": "train", "epochs": 1, "timestep": 526, "ep_reward": 294.9707336425781, "reward": 0.7129408121109009, "action": 1.6831612586975098}
{"mode": "train", "epochs": 1, "timestep": 527, "ep_reward": 295.745849609375, "reward": 0.7751101851463318, "action": 0.9367265105247498}
{"mode": "train", "epochs": 1, "timestep": 528, "ep_reward": 296.57025146484375, "reward": 0.8244045376777649, "action": 0.37788915634155273}
{"mode": "train", "epochs": 1, "timestep": 529, "ep_reward": 297.429931640625, "reward": 0.8596709966659546, "action": 1.4216258525848389}
{"mode": "train", "epochs": 1, "timestep": 530, "ep_reward": 298.2998352050781, "reward": 0.8699175119400024, "action": 0.6240909099578857}
{"mode": "train", "epochs": 1, "timestep": 531, "ep_reward": 299.1708984375, "reward": 0.8710685968399048, "action": 0.2543145418167114}
{"mode": "train", "epochs": 1, "timestep": 532, "ep_reward": 300.0299072265625, "reward": 0.8590225577354431, "action": 0.4593304991722107}
{"mode": "train", "epochs": 1, "timestep": 533, "ep_reward": 300.8567199707031, "reward": 0.8268046379089355, "action": 1.2974494695663452}
{"mode": "train", "epochs": 1, "timestep": 534, "ep_reward": 301.61981201171875, "reward": 0.7630848288536072, "action": 0.68516606092453}
{"mode": "train", "epochs": 1, "timestep": 535, "ep_reward": 302.2951965332031, "reward": 0.6753968000411987, "action": 0.7316310405731201}
{"mode": "train", "epochs": 1, "timestep": 536, "ep_reward": 302.8465270996094, "reward": 0.5513331890106201, "action": 0.23015856742858887}
{"mode": "train", "epochs": 1, "timestep": 537, "ep_reward": 303.2425842285156, "reward": 0.3960608243942261, "action": 0.8230175375938416}
{"mode": "train", "epochs": 1, "timestep": 538, "ep_reward": 303.5128173828125, "reward": 0.2702195644378662, "action": 1.3929004669189453}
{"mode": "train", "epochs": 1, "timestep": 539, "ep_reward": 303.65826416015625, "reward": 0.1454554796218872, "action": 0.9200661182403564}
{"mode": "train", "epochs": 1, "timestep": 540, "ep_reward": 303.6588439941406, "reward": 0.0005707740783691406, "action": 1.2961757183074951}
{"mode": "train", "epochs": 1, "timestep": 541, "ep_reward": 303.7734069824219, "reward": 0.11455869674682617, "action": 1.4969195127487183}
{"mode": "train", "epochs": 1, "timestep": 542, "ep_reward": 304.02044677734375, "reward": 0.247036874294281, "action": 0.9761502742767334}
{"mode": "train", "epochs": 1, "timestep": 543, "ep_reward": 304.4074401855469, "reward": 0.3869962692260742, "action": 1.4926553964614868}
{"mode": "train", "epochs": 1, "timestep": 544, "ep_reward": 304.9181823730469, "reward": 0.5107483863830566, "action": 0.5675586462020874}
{"mode": "train", "epochs": 1, "timestep": 545, "ep_reward": 305.5455322265625, "reward": 0.6273510456085205, "action": 1.4278310537338257}
{"mode": "train", "epochs": 1, "timestep": 546, "ep_reward": 306.2568054199219, "reward": 0.7112644910812378, "action": 1.3016345500946045}
{"mode": "train", "epochs": 1, "timestep": 547, "ep_reward": 307.031005859375, "reward": 0.7742033004760742, "action": 0.4940955638885498}
{"mode": "train", "epochs": 1, "timestep": 548, "ep_reward": 307.85400390625, "reward": 0.823000431060791, "action": 1.6470496654510498}
{"mode": "train", "epochs": 1, "timestep": 549, "ep_reward": 308.6958312988281, "reward": 0.8418370485305786, "action": 0.4409176707267761}
{"mode": "train", "epochs": 1, "timestep": 550, "ep_reward": 309.5489196777344, "reward": 0.8530857563018799, "action": 0.9668020606040955}
{"mode": "train", "epochs": 1, "timestep": 551, "ep_reward": 310.3898620605469, "reward": 0.8409484624862671, "action": 0.9661611318588257}
{"mode": "train", "epochs": 1, "timestep": 552, "ep_reward": 311.19744873046875, "reward": 0.8075788617134094, "action": 1.7902425527572632}
{"mode": "train", "epochs": 1, "timestep": 553, "ep_reward": 311.9364013671875, "reward": 0.7389497756958008, "action": 0.9380756616592407}
{"mode": "train", "epochs": 1, "timestep": 554, "ep_reward": 312.5818176269531, "reward": 0.6454035043716431, "action": 1.0179439783096313}
{"mode": "train", "epochs": 1, "timestep": 555, "ep_reward": 313.0924072265625, "reward": 0.5105920433998108, "action": 1.2520506381988525}
{"mode": "train", "epochs": 1, "timestep": 556, "ep_reward": 313.4649353027344, "reward": 0.37253618240356445, "action": 1.4299925565719604}
{"mode": "train", "epochs": 1, "timestep": 557, "ep_reward": 313.7320861816406, "reward": 0.2671634554862976, "action": 1.4998538494110107}
{"mode": "train", "epochs": 1, "timestep": 558, "ep_reward": 313.8739013671875, "reward": 0.1418125033378601, "action": 1.4499595165252686}
{"mode": "train", "epochs": 1, "timestep": 559, "ep_reward": 313.8704833984375, "reward": -0.0034281015396118164, "action": 0.43541067838668823}
{"mode": "train", "epochs": 1, "timestep": 560, "ep_reward": 313.9888000488281, "reward": 0.11830168962478638, "action": 1.029193639755249}
{"mode": "train", "epochs": 1, "timestep": 561, "ep_reward": 314.2455139160156, "reward": 0.2566988468170166, "action": 1.0681276321411133}
{"mode": "train", "epochs": 1, "timestep": 562, "ep_reward": 314.63983154296875, "reward": 0.39433276653289795, "action": 0.261430025100708}
{"mode": "train", "epochs": 1, "timestep": 563, "ep_reward": 315.170654296875, "reward": 0.5308171510696411, "action": 1.8485174179077148}
{"mode": "train", "epochs": 1, "timestep": 564, "ep_reward": 315.8006896972656, "reward": 0.6300361156463623, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 565, "ep_reward": 316.5087890625, "reward": 0.70809406042099, "action": 1.2001867294311523}
{"mode": "train", "epochs": 1, "timestep": 566, "ep_reward": 317.2816467285156, "reward": 0.772842526435852, "action": 1.0833419561386108}
{"mode": "train", "epochs": 1, "timestep": 567, "ep_reward": 318.0988464355469, "reward": 0.8172147274017334, "action": 0.5479443669319153}
{"mode": "train", "epochs": 1, "timestep": 568, "ep_reward": 318.9454345703125, "reward": 0.8465980887413025, "action": 0.599389910697937}
{"mode": "train", "epochs": 1, "timestep": 569, "ep_reward": 319.802490234375, "reward": 0.8570511341094971, "action": 1.3409897089004517}
{"mode": "train", "epochs": 1, "timestep": 570, "ep_reward": 320.6451721191406, "reward": 0.8426913619041443, "action": 1.3739787340164185}
{"mode": "train", "epochs": 1, "timestep": 571, "ep_reward": 321.45184326171875, "reward": 0.8066810965538025, "action": 1.2054789066314697}
{"mode": "train", "epochs": 1, "timestep": 572, "ep_reward": 322.19757080078125, "reward": 0.74571293592453, "action": 1.1821922063827515}
{"mode": "train", "epochs": 1, "timestep": 573, "ep_reward": 322.8489685058594, "reward": 0.6513997316360474, "action": 1.7711962461471558}
{"mode": "train", "epochs": 1, "timestep": 574, "ep_reward": 323.35650634765625, "reward": 0.5075526237487793, "action": 0.6763957738876343}
{"mode": "train", "epochs": 1, "timestep": 575, "ep_reward": 323.7329406738281, "reward": 0.37643754482269287, "action": 0.9502891302108765}
{"mode": "train", "epochs": 1, "timestep": 576, "ep_reward": 324.0047302246094, "reward": 0.27177882194519043, "action": 1.6093508005142212}
{"mode": "train", "epochs": 1, "timestep": 577, "ep_reward": 324.152099609375, "reward": 0.1473674774169922, "action": 0.5623507499694824}
{"mode": "train", "epochs": 1, "timestep": 578, "ep_reward": 324.1549072265625, "reward": 0.0028139352798461914, "action": 0.5624550580978394}
{"mode": "train", "epochs": 1, "timestep": 579, "ep_reward": 324.26763916015625, "reward": 0.11274605989456177, "action": -0.337624192237854}
{"mode": "train", "epochs": 1, "timestep": 580, "ep_reward": 324.5352783203125, "reward": 0.2676540017127991, "action": 1.9914965629577637}
{"mode": "train", "epochs": 1, "timestep": 581, "ep_reward": 324.9263916015625, "reward": 0.3911144733428955, "action": 0.772347092628479}
{"mode": "train", "epochs": 1, "timestep": 582, "ep_reward": 325.4481201171875, "reward": 0.5217312574386597, "action": 1.1013078689575195}
{"mode": "train", "epochs": 1, "timestep": 583, "ep_reward": 326.07867431640625, "reward": 0.6305626034736633, "action": 0.9109695553779602}
{"mode": "train", "epochs": 1, "timestep": 584, "ep_reward": 326.79852294921875, "reward": 0.7198394536972046, "action": 1.253747820854187}
{"mode": "train", "epochs": 1, "timestep": 585, "ep_reward": 327.5823974609375, "reward": 0.7838701009750366, "action": 1.065798282623291}
{"mode": "train", "epochs": 1, "timestep": 586, "ep_reward": 328.412109375, "reward": 0.8297268152236938, "action": 1.030655860900879}
{"mode": "train", "epochs": 1, "timestep": 587, "ep_reward": 329.27001953125, "reward": 0.857896089553833, "action": 1.390015721321106}
{"mode": "train", "epochs": 1, "timestep": 588, "ep_reward": 330.1368408203125, "reward": 0.8668079376220703, "action": 1.1173205375671387}
{"mode": "train", "epochs": 1, "timestep": 589, "ep_reward": 330.9985656738281, "reward": 0.8617107272148132, "action": 0.17050224542617798}
{"mode": "train", "epochs": 1, "timestep": 590, "ep_reward": 331.8457946777344, "reward": 0.8472355604171753, "action": 1.1425755023956299}
{"mode": "train", "epochs": 1, "timestep": 591, "ep_reward": 332.64923095703125, "reward": 0.8034389019012451, "action": 0.8241537809371948}
{"mode": "train", "epochs": 1, "timestep": 592, "ep_reward": 333.3856506347656, "reward": 0.736411452293396, "action": 1.173013687133789}
{"mode": "train", "epochs": 1, "timestep": 593, "ep_reward": 334.0178527832031, "reward": 0.6322022676467896, "action": 0.920234203338623}
{"mode": "train", "epochs": 1, "timestep": 594, "ep_reward": 334.50921630859375, "reward": 0.4913761019706726, "action": 0.8063657283782959}
{"mode": "train", "epochs": 1, "timestep": 595, "ep_reward": 334.85467529296875, "reward": 0.3454440236091614, "action": 0.7221267223358154}
{"mode": "train", "epochs": 1, "timestep": 596, "ep_reward": 335.0892028808594, "reward": 0.2345234751701355, "action": 0.9130805730819702}
{"mode": "train", "epochs": 1, "timestep": 597, "ep_reward": 335.19287109375, "reward": 0.10366731882095337, "action": -0.33601951599121094}
{"mode": "train", "epochs": 1, "timestep": 598, "ep_reward": 335.2055969238281, "reward": 0.012713074684143066, "action": 1.1536903381347656}
{"mode": "train", "epochs": 1, "timestep": 599, "ep_reward": 335.36163330078125, "reward": 0.1560218334197998, "action": 0.7312501668930054}
{"mode": "train", "epochs": 1, "timestep": 600, "ep_reward": 335.6606750488281, "reward": 0.2990332841873169, "action": 0.7993131875991821}
{"mode": "train", "epochs": 1, "timestep": 601, "ep_reward": 336.097900390625, "reward": 0.43722230195999146, "action": 1.084945559501648}
{"mode": "train", "epochs": 1, "timestep": 602, "ep_reward": 336.65679931640625, "reward": 0.5588892698287964, "action": 0.6756385564804077}
{"mode": "train", "epochs": 1, "timestep": 603, "ep_reward": 337.3222961425781, "reward": 0.6654876470565796, "action": 0.4689854383468628}
{"mode": "train", "epochs": 1, "timestep": 604, "ep_reward": 338.07318115234375, "reward": 0.750881552696228, "action": 0.9630323052406311}
{"mode": "train", "epochs": 1, "timestep": 605, "ep_reward": 338.8827819824219, "reward": 0.8096008896827698, "action": 1.0618218183517456}
{"mode": "train", "epochs": 1, "timestep": 606, "ep_reward": 339.7315979003906, "reward": 0.8488206267356873, "action": 0.558562695980072}
{"mode": "train", "epochs": 1, "timestep": 607, "ep_reward": 340.6072998046875, "reward": 0.8757073283195496, "action": 0.342548131942749}
{"mode": "train", "epochs": 1, "timestep": 608, "ep_reward": 341.4967041015625, "reward": 0.8894150853157043, "action": 0.8849490880966187}
{"mode": "train", "epochs": 1, "timestep": 609, "ep_reward": 342.38165283203125, "reward": 0.8849430680274963, "action": 1.4969152212142944}
{"mode": "train", "epochs": 1, "timestep": 610, "ep_reward": 343.2417907714844, "reward": 0.86014723777771, "action": 0.942960262298584}
{"mode": "train", "epochs": 1, "timestep": 611, "ep_reward": 344.06243896484375, "reward": 0.8206442594528198, "action": 1.2798163890838623}
{"mode": "train", "epochs": 1, "timestep": 612, "ep_reward": 344.81549072265625, "reward": 0.7530663013458252, "action": 1.2674552202224731}
{"mode": "train", "epochs": 1, "timestep": 613, "ep_reward": 345.4685974121094, "reward": 0.6531211137771606, "action": 0.8059492707252502}
{"mode": "train", "epochs": 1, "timestep": 614, "ep_reward": 345.9888610839844, "reward": 0.5202577114105225, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 615, "ep_reward": 346.34600830078125, "reward": 0.3571494221687317, "action": 0.7197526097297668}
{"mode": "train", "epochs": 1, "timestep": 616, "ep_reward": 346.5944519042969, "reward": 0.24845850467681885, "action": 1.6477625370025635}
{"mode": "train", "epochs": 1, "timestep": 617, "ep_reward": 346.7144775390625, "reward": 0.1200212836265564, "action": 0.9220418930053711}
{"mode": "train", "epochs": 1, "timestep": 618, "ep_reward": 346.7091369628906, "reward": -0.005340218544006348, "action": 0.4107028841972351}
{"mode": "train", "epochs": 1, "timestep": 619, "ep_reward": 346.8492126464844, "reward": 0.14006948471069336, "action": 1.8206350803375244}
{"mode": "train", "epochs": 1, "timestep": 620, "ep_reward": 347.118408203125, "reward": 0.2692025303840637, "action": 0.620187520980835}
{"mode": "train", "epochs": 1, "timestep": 621, "ep_reward": 347.5317077636719, "reward": 0.4132906198501587, "action": 0.4572756290435791}
{"mode": "train", "epochs": 1, "timestep": 622, "ep_reward": 348.07757568359375, "reward": 0.5458654761314392, "action": 0.5101075172424316}
{"mode": "train", "epochs": 1, "timestep": 623, "ep_reward": 348.7341613769531, "reward": 0.6565908193588257, "action": 1.0860934257507324}
{"mode": "train", "epochs": 1, "timestep": 624, "ep_reward": 349.47235107421875, "reward": 0.7381802797317505, "action": 0.6804262399673462}
{"mode": "train", "epochs": 1, "timestep": 625, "ep_reward": 350.2740173339844, "reward": 0.8016641736030579, "action": 1.6039187908172607}
{"mode": "train", "epochs": 1, "timestep": 626, "ep_reward": 351.11151123046875, "reward": 0.8375022411346436, "action": 0.9725046157836914}
{"mode": "train", "epochs": 1, "timestep": 627, "ep_reward": 351.97314453125, "reward": 0.8616286516189575, "action": 1.1963865756988525}
{"mode": "train", "epochs": 1, "timestep": 628, "ep_reward": 352.8408203125, "reward": 0.8676790595054626, "action": 0.6803991794586182}
{"mode": "train", "epochs": 1, "timestep": 629, "ep_reward": 353.7023620605469, "reward": 0.861528217792511, "action": 1.4614739418029785}
{"mode": "train", "epochs": 1, "timestep": 630, "ep_reward": 354.53228759765625, "reward": 0.8299226760864258, "action": 1.1750608682632446}
{"mode": "train", "epochs": 1, "timestep": 631, "ep_reward": 355.3096923828125, "reward": 0.7774007320404053, "action": 0.23855626583099365}
{"mode": "train", "epochs": 1, "timestep": 632, "ep_reward": 356.01611328125, "reward": 0.7064347267150879, "action": 0.247017502784729}
{"mode": "train", "epochs": 1, "timestep": 633, "ep_reward": 356.6186828613281, "reward": 0.6025840044021606, "action": 0.9388405084609985}
{"mode": "train", "epochs": 1, "timestep": 634, "ep_reward": 357.06976318359375, "reward": 0.4510679244995117, "action": 0.7214239835739136}
{"mode": "train", "epochs": 1, "timestep": 635, "ep_reward": 357.385009765625, "reward": 0.3152368664741516, "action": 0.5209400653839111}
{"mode": "train", "epochs": 1, "timestep": 636, "ep_reward": 357.58343505859375, "reward": 0.19841307401657104, "action": 1.3681371212005615}
{"mode": "train", "epochs": 1, "timestep": 637, "ep_reward": 357.6452331542969, "reward": 0.061783552169799805, "action": 0.6022441387176514}
{"mode": "train", "epochs": 1, "timestep": 638, "ep_reward": 357.70159912109375, "reward": 0.056371331214904785, "action": 1.7692370414733887}
{"mode": "train", "epochs": 1, "timestep": 639, "ep_reward": 357.8955993652344, "reward": 0.1940004825592041, "action": 0.21107661724090576}
{"mode": "train", "epochs": 1, "timestep": 640, "ep_reward": 358.2395324707031, "reward": 0.34392309188842773, "action": 1.215039610862732}
{"mode": "train", "epochs": 1, "timestep": 641, "ep_reward": 358.7129821777344, "reward": 0.4734639525413513, "action": 1.7855279445648193}
{"mode": "train", "epochs": 1, "timestep": 642, "ep_reward": 359.2955017089844, "reward": 0.5825222134590149, "action": 0.6940427422523499}
{"mode": "train", "epochs": 1, "timestep": 643, "ep_reward": 359.9795227050781, "reward": 0.6840314865112305, "action": 0.41773825883865356}
{"mode": "train", "epochs": 1, "timestep": 644, "ep_reward": 360.743896484375, "reward": 0.764385461807251, "action": 0.646307110786438}
{"mode": "train", "epochs": 1, "timestep": 645, "ep_reward": 361.56402587890625, "reward": 0.820134162902832, "action": 0.9696456789970398}
{"mode": "train", "epochs": 1, "timestep": 646, "ep_reward": 362.4181823730469, "reward": 0.8541486263275146, "action": 1.0114750862121582}
{"mode": "train", "epochs": 1, "timestep": 647, "ep_reward": 363.28961181640625, "reward": 0.8714171648025513, "action": 1.253953218460083}
{"mode": "train", "epochs": 1, "timestep": 648, "ep_reward": 364.16082763671875, "reward": 0.8712136745452881, "action": 1.1609607934951782}
{"mode": "train", "epochs": 1, "timestep": 649, "ep_reward": 365.0159606933594, "reward": 0.8551437854766846, "action": 1.322975516319275}
{"mode": "train", "epochs": 1, "timestep": 650, "ep_reward": 365.833740234375, "reward": 0.8177913427352905, "action": 1.0681549310684204}
{"mode": "train", "epochs": 1, "timestep": 651, "ep_reward": 366.59149169921875, "reward": 0.7577551007270813, "action": 1.2417352199554443}
{"mode": "train", "epochs": 1, "timestep": 652, "ep_reward": 367.2552490234375, "reward": 0.6637661457061768, "action": 1.6693434715270996}
{"mode": "train", "epochs": 1, "timestep": 653, "ep_reward": 367.7791442871094, "reward": 0.5239037871360779, "action": 1.2764204740524292}
{"mode": "train", "epochs": 1, "timestep": 654, "ep_reward": 368.154052734375, "reward": 0.3749217987060547, "action": 1.2733850479125977}
{"mode": "train", "epochs": 1, "timestep": 655, "ep_reward": 368.4239807128906, "reward": 0.269941508769989, "action": 1.866491675376892}
{"mode": "train", "epochs": 1, "timestep": 656, "ep_reward": 368.56927490234375, "reward": 0.14528149366378784, "action": 0.4687334895133972}
{"mode": "train", "epochs": 1, "timestep": 657, "ep_reward": 368.5697021484375, "reward": 0.0004310011863708496, "action": 0.0292893648147583}
{"mode": "train", "epochs": 1, "timestep": 658, "ep_reward": 368.6845703125, "reward": 0.1148640513420105, "action": 0.9370745420455933}
{"mode": "train", "epochs": 1, "timestep": 659, "ep_reward": 368.9389343261719, "reward": 0.254371702671051, "action": 0.42874056100845337}
{"mode": "train", "epochs": 1, "timestep": 660, "ep_reward": 369.3384094238281, "reward": 0.3994772434234619, "action": 1.507901668548584}
{"mode": "train", "epochs": 1, "timestep": 661, "ep_reward": 369.85894775390625, "reward": 0.5205429792404175, "action": 1.3709893226623535}
{"mode": "train", "epochs": 1, "timestep": 662, "ep_reward": 370.4856872558594, "reward": 0.6267327070236206, "action": 1.2368190288543701}
{"mode": "train", "epochs": 1, "timestep": 663, "ep_reward": 371.1988830566406, "reward": 0.7131982445716858, "action": 0.6893183588981628}
{"mode": "train", "epochs": 1, "timestep": 664, "ep_reward": 371.9814453125, "reward": 0.7825559377670288, "action": 0.17437458038330078}
{"mode": "train", "epochs": 1, "timestep": 665, "ep_reward": 372.8161315917969, "reward": 0.8346730470657349, "action": 1.7620651721954346}
{"mode": "train", "epochs": 1, "timestep": 666, "ep_reward": 373.6708984375, "reward": 0.8547599911689758, "action": 1.3663458824157715}
{"mode": "train", "epochs": 1, "timestep": 667, "ep_reward": 374.5326843261719, "reward": 0.8617997169494629, "action": 0.7918770909309387}
{"mode": "train", "epochs": 1, "timestep": 668, "ep_reward": 375.3894348144531, "reward": 0.8567418456077576, "action": 0.3758472800254822}
{"mode": "train", "epochs": 1, "timestep": 669, "ep_reward": 376.2262268066406, "reward": 0.8367853164672852, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 670, "ep_reward": 377.0047607421875, "reward": 0.7785376906394958, "action": 1.882699966430664}
{"mode": "train", "epochs": 1, "timestep": 671, "ep_reward": 377.6941223144531, "reward": 0.6893746852874756, "action": 0.4862162470817566}
{"mode": "train", "epochs": 1, "timestep": 672, "ep_reward": 378.2733154296875, "reward": 0.5791972875595093, "action": 0.9172946214675903}
{"mode": "train", "epochs": 1, "timestep": 673, "ep_reward": 378.6954345703125, "reward": 0.42211008071899414, "action": 0.9333871603012085}
{"mode": "train", "epochs": 1, "timestep": 674, "ep_reward": 379.0074462890625, "reward": 0.31201571226119995, "action": 1.0341660976409912}
{"mode": "train", "epochs": 1, "timestep": 675, "ep_reward": 379.2021789550781, "reward": 0.1947271227836609, "action": 0.790526270866394}
{"mode": "train", "epochs": 1, "timestep": 676, "ep_reward": 379.2594909667969, "reward": 0.05730116367340088, "action": 1.5409038066864014}
{"mode": "train", "epochs": 1, "timestep": 677, "ep_reward": 379.3202819824219, "reward": 0.060786664485931396, "action": 1.499220371246338}
{"mode": "train", "epochs": 1, "timestep": 678, "ep_reward": 379.5180358886719, "reward": 0.19775354862213135, "action": 0.526235818862915}
{"mode": "train", "epochs": 1, "timestep": 679, "ep_reward": 379.8619689941406, "reward": 0.343947172164917, "action": -0.0978996753692627}
{"mode": "train", "epochs": 1, "timestep": 680, "ep_reward": 380.35125732421875, "reward": 0.4892957806587219, "action": 1.209744930267334}
{"mode": "train", "epochs": 1, "timestep": 681, "ep_reward": 380.9531555175781, "reward": 0.6018970608711243, "action": 0.25276732444763184}
{"mode": "train", "epochs": 1, "timestep": 682, "ep_reward": 381.6572265625, "reward": 0.7040724754333496, "action": 0.8419277667999268}
{"mode": "train", "epochs": 1, "timestep": 683, "ep_reward": 382.43463134765625, "reward": 0.7773998975753784, "action": 1.70009183883667}
{"mode": "train", "epochs": 1, "timestep": 684, "ep_reward": 383.25830078125, "reward": 0.8236726522445679, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 685, "ep_reward": 384.1094970703125, "reward": 0.851189911365509, "action": 1.0206036567687988}
{"mode": "train", "epochs": 1, "timestep": 686, "ep_reward": 384.9805603027344, "reward": 0.8710681200027466, "action": 1.4047906398773193}
{"mode": "train", "epochs": 1, "timestep": 687, "ep_reward": 385.85308837890625, "reward": 0.8725171685218811, "action": 1.1772187948226929}
{"mode": "train", "epochs": 1, "timestep": 688, "ep_reward": 386.7127685546875, "reward": 0.8596771359443665, "action": 0.401141881942749}
{"mode": "train", "epochs": 1, "timestep": 689, "ep_reward": 387.5480651855469, "reward": 0.8353061676025391, "action": 0.9448498487472534}
{"mode": "train", "epochs": 1, "timestep": 690, "ep_reward": 388.3319396972656, "reward": 0.7838711738586426, "action": 0.8459723591804504}
{"mode": "train", "epochs": 1, "timestep": 691, "ep_reward": 389.037109375, "reward": 0.7051816582679749, "action": 0.3294634222984314}
{"mode": "train", "epochs": 1, "timestep": 692, "ep_reward": 389.63592529296875, "reward": 0.5988212823867798, "action": 0.20343691110610962}
{"mode": "train", "epochs": 1, "timestep": 693, "ep_reward": 390.0932922363281, "reward": 0.4573671817779541, "action": 1.218590497970581}
{"mode": "train", "epochs": 1, "timestep": 694, "ep_reward": 390.4036560058594, "reward": 0.3103533387184143, "action": 1.3584909439086914}
{"mode": "train", "epochs": 1, "timestep": 695, "ep_reward": 390.59625244140625, "reward": 0.1926020383834839, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 696, "ep_reward": 390.6513977050781, "reward": 0.05513828992843628, "action": 1.2449835538864136}
{"mode": "train", "epochs": 1, "timestep": 697, "ep_reward": 390.7144775390625, "reward": 0.06308490037918091, "action": 0.8494157195091248}
{"mode": "train", "epochs": 1, "timestep": 698, "ep_reward": 390.9165954589844, "reward": 0.20212477445602417, "action": 0.6263393759727478}
{"mode": "train", "epochs": 1, "timestep": 699, "ep_reward": 391.2630615234375, "reward": 0.34647685289382935, "action": 1.309892177581787}
{"mode": "train", "epochs": 1, "timestep": 700, "ep_reward": 391.73822021484375, "reward": 0.47516894340515137, "action": 1.319466471672058}
{"mode": "train", "epochs": 1, "timestep": 701, "ep_reward": 392.3273620605469, "reward": 0.5891463756561279, "action": 1.4431266784667969}
{"mode": "train", "epochs": 1, "timestep": 702, "ep_reward": 393.0089416503906, "reward": 0.681594729423523, "action": 0.8044110536575317}
{"mode": "train", "epochs": 1, "timestep": 703, "ep_reward": 393.7669982910156, "reward": 0.7580479383468628, "action": 1.3028264045715332}
{"mode": "train", "epochs": 1, "timestep": 704, "ep_reward": 394.57464599609375, "reward": 0.8076349496841431, "action": 1.0807667970657349}
{"mode": "train", "epochs": 1, "timestep": 705, "ep_reward": 395.41424560546875, "reward": 0.8396028280258179, "action": 1.3193130493164062}
{"mode": "train", "epochs": 1, "timestep": 706, "ep_reward": 396.2655334472656, "reward": 0.8512874245643616, "action": 0.8639888763427734}
{"mode": "train", "epochs": 1, "timestep": 707, "ep_reward": 397.1142883300781, "reward": 0.8487673997879028, "action": 1.5677218437194824}
{"mode": "train", "epochs": 1, "timestep": 708, "ep_reward": 397.9339904785156, "reward": 0.8197128176689148, "action": 1.485404372215271}
{"mode": "train", "epochs": 1, "timestep": 709, "ep_reward": 398.7002868652344, "reward": 0.7662822008132935, "action": 0.9105015397071838}
{"mode": "train", "epochs": 1, "timestep": 710, "ep_reward": 399.38818359375, "reward": 0.6879060864448547, "action": 0.5528030395507812}
{"mode": "train", "epochs": 1, "timestep": 711, "ep_reward": 399.96533203125, "reward": 0.5771341323852539, "action": 1.5477912425994873}
{"mode": "train", "epochs": 1, "timestep": 712, "ep_reward": 400.3758239746094, "reward": 0.41047918796539307, "action": 1.0007586479187012}
{"mode": "train", "epochs": 1, "timestep": 713, "ep_reward": 400.68914794921875, "reward": 0.31331974267959595, "action": 1.6395411491394043}
{"mode": "train", "epochs": 1, "timestep": 714, "ep_reward": 400.88543701171875, "reward": 0.19629555940628052, "action": 1.4863303899765015}
{"mode": "train", "epochs": 1, "timestep": 715, "ep_reward": 400.9446716308594, "reward": 0.05923795700073242, "action": 1.5039935111999512}
{"mode": "train", "epochs": 1, "timestep": 716, "ep_reward": 401.0036315917969, "reward": 0.058966100215911865, "action": 0.7391408681869507}
{"mode": "train", "epochs": 1, "timestep": 717, "ep_reward": 401.2027282714844, "reward": 0.19911158084869385, "action": 1.5975968837738037}
{"mode": "train", "epochs": 1, "timestep": 718, "ep_reward": 401.5340881347656, "reward": 0.33137381076812744, "action": 1.1388969421386719}
{"mode": "train", "epochs": 1, "timestep": 719, "ep_reward": 401.99859619140625, "reward": 0.4645068049430847, "action": 1.5929714441299438}
{"mode": "train", "epochs": 1, "timestep": 720, "ep_reward": 402.5759582519531, "reward": 0.5773695111274719, "action": 0.6836685538291931}
{"mode": "train", "epochs": 1, "timestep": 721, "ep_reward": 403.2555847167969, "reward": 0.6796218156814575, "action": 0.28479528427124023}
{"mode": "train", "epochs": 1, "timestep": 722, "ep_reward": 404.0166320800781, "reward": 0.7610623836517334, "action": 0.8795260190963745}
{"mode": "train", "epochs": 1, "timestep": 723, "ep_reward": 404.8300476074219, "reward": 0.8134164810180664, "action": 1.8077126741409302}
{"mode": "train", "epochs": 1, "timestep": 724, "ep_reward": 405.6683044433594, "reward": 0.8382669687271118, "action": 0.22028422355651855}
{"mode": "train", "epochs": 1, "timestep": 725, "ep_reward": 406.5271911621094, "reward": 0.8589011430740356, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 726, "ep_reward": 407.3734436035156, "reward": 0.8462402820587158, "action": 1.000226616859436}
{"mode": "train", "epochs": 1, "timestep": 727, "ep_reward": 408.1958312988281, "reward": 0.8223782181739807, "action": 0.8765608668327332}
{"mode": "train", "epochs": 1, "timestep": 728, "ep_reward": 408.9718017578125, "reward": 0.7759708166122437, "action": 0.9186114072799683}
{"mode": "train", "epochs": 1, "timestep": 729, "ep_reward": 409.6714172363281, "reward": 0.6996113657951355, "action": 1.430957555770874}
{"mode": "train", "epochs": 1, "timestep": 730, "ep_reward": 410.25115966796875, "reward": 0.579729437828064, "action": 0.6982394456863403}
{"mode": "train", "epochs": 1, "timestep": 731, "ep_reward": 410.67803955078125, "reward": 0.42688465118408203, "action": 1.4659360647201538}
{"mode": "train", "epochs": 1, "timestep": 732, "ep_reward": 410.99627685546875, "reward": 0.31825006008148193, "action": 1.0892558097839355}
{"mode": "train", "epochs": 1, "timestep": 733, "ep_reward": 411.1984558105469, "reward": 0.2021644115447998, "action": 0.45631128549575806}
{"mode": "train", "epochs": 1, "timestep": 734, "ep_reward": 411.264404296875, "reward": 0.06595557928085327, "action": 1.0948059558868408}
{"mode": "train", "epochs": 1, "timestep": 735, "ep_reward": 411.31658935546875, "reward": 0.0521998405456543, "action": 1.3000340461730957}
{"mode": "train", "epochs": 1, "timestep": 736, "ep_reward": 411.50689697265625, "reward": 0.19029754400253296, "action": 0.5826355218887329}
{"mode": "train", "epochs": 1, "timestep": 737, "ep_reward": 411.8426208496094, "reward": 0.3357203006744385, "action": 0.15871930122375488}
{"mode": "train", "epochs": 1, "timestep": 738, "ep_reward": 412.32135009765625, "reward": 0.4787330627441406, "action": 1.6749392747879028}
{"mode": "train", "epochs": 1, "timestep": 739, "ep_reward": 412.9092102050781, "reward": 0.5878480672836304, "action": 1.5682644844055176}
{"mode": "train", "epochs": 1, "timestep": 740, "ep_reward": 413.58868408203125, "reward": 0.6794884204864502, "action": 1.905526876449585}
{"mode": "train", "epochs": 1, "timestep": 741, "ep_reward": 414.33563232421875, "reward": 0.7469601035118103, "action": 0.9344123601913452}
{"mode": "train", "epochs": 1, "timestep": 742, "ep_reward": 415.1383056640625, "reward": 0.8026683926582336, "action": 1.971917748451233}
{"mode": "train", "epochs": 1, "timestep": 743, "ep_reward": 415.9673767089844, "reward": 0.8290626406669617, "action": 0.7472550868988037}
{"mode": "train", "epochs": 1, "timestep": 744, "ep_reward": 416.8152160644531, "reward": 0.8478350043296814, "action": 0.8745719790458679}
{"mode": "train", "epochs": 1, "timestep": 745, "ep_reward": 417.6620788574219, "reward": 0.8468527793884277, "action": 0.01299518346786499}
{"mode": "train", "epochs": 1, "timestep": 746, "ep_reward": 418.4964599609375, "reward": 0.8343859910964966, "action": 1.6242997646331787}
{"mode": "train", "epochs": 1, "timestep": 747, "ep_reward": 419.2805480957031, "reward": 0.7840747237205505, "action": 1.035599708557129}
{"mode": "train", "epochs": 1, "timestep": 748, "ep_reward": 419.990966796875, "reward": 0.7104203701019287, "action": 0.5237910747528076}
{"mode": "train", "epochs": 1, "timestep": 749, "ep_reward": 420.59881591796875, "reward": 0.6078474521636963, "action": 1.2794504165649414}
{"mode": "train", "epochs": 1, "timestep": 750, "ep_reward": 421.0530700683594, "reward": 0.45424437522888184, "action": 0.44473809003829956}
{"mode": "train", "epochs": 1, "timestep": 751, "ep_reward": 421.3863220214844, "reward": 0.3332613706588745, "action": 1.1271194219589233}
{"mode": "train", "epochs": 1, "timestep": 752, "ep_reward": 421.6063537597656, "reward": 0.22001999616622925, "action": 0.844164252281189}
{"mode": "train", "epochs": 1, "timestep": 753, "ep_reward": 421.69305419921875, "reward": 0.08669549226760864, "action": 1.2226072549819946}
{"mode": "train", "epochs": 1, "timestep": 754, "ep_reward": 421.7237243652344, "reward": 0.030672311782836914, "action": 1.756300449371338}
{"mode": "train", "epochs": 1, "timestep": 755, "ep_reward": 421.8952941894531, "reward": 0.17156368494033813, "action": 1.703866720199585}
{"mode": "train", "epochs": 1, "timestep": 756, "ep_reward": 422.19805908203125, "reward": 0.30275946855545044, "action": 1.1434156894683838}
{"mode": "train", "epochs": 1, "timestep": 757, "ep_reward": 422.63641357421875, "reward": 0.4383508563041687, "action": 1.2197721004486084}
{"mode": "train", "epochs": 1, "timestep": 758, "ep_reward": 423.1957092285156, "reward": 0.5592892169952393, "action": 0.60411536693573}
{"mode": "train", "epochs": 1, "timestep": 759, "ep_reward": 423.8618469238281, "reward": 0.6661339998245239, "action": 1.35709810256958}
{"mode": "train", "epochs": 1, "timestep": 760, "ep_reward": 424.6029052734375, "reward": 0.7410613298416138, "action": 0.705864429473877}
{"mode": "train", "epochs": 1, "timestep": 761, "ep_reward": 425.4026184082031, "reward": 0.7996984124183655, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 762, "ep_reward": 426.228515625, "reward": 0.8259031772613525, "action": 0.9182083606719971}
{"mode": "train", "epochs": 1, "timestep": 763, "ep_reward": 427.0714416503906, "reward": 0.8429172039031982, "action": 1.1647167205810547}
{"mode": "train", "epochs": 1, "timestep": 764, "ep_reward": 427.90985107421875, "reward": 0.8383979797363281, "action": 0.9169819951057434}
{"mode": "train", "epochs": 1, "timestep": 765, "ep_reward": 428.72509765625, "reward": 0.8152401447296143, "action": 1.0207775831222534}
{"mode": "train", "epochs": 1, "timestep": 766, "ep_reward": 429.4913635253906, "reward": 0.7662709951400757, "action": 1.1478787660598755}
{"mode": "train", "epochs": 1, "timestep": 767, "ep_reward": 430.1761779785156, "reward": 0.6848094463348389, "action": 1.0439342260360718}
{"mode": "train", "epochs": 1, "timestep": 768, "ep_reward": 430.7423400878906, "reward": 0.5661612153053284, "action": 1.3728361129760742}
{"mode": "train", "epochs": 1, "timestep": 769, "ep_reward": 431.1512145996094, "reward": 0.4088783860206604, "action": 0.5571993589401245}
{"mode": "train", "epochs": 1, "timestep": 770, "ep_reward": 431.4626770019531, "reward": 0.31145864725112915, "action": 0.40776360034942627}
{"mode": "train", "epochs": 1, "timestep": 771, "ep_reward": 431.65667724609375, "reward": 0.19400542974472046, "action": 0.7520394325256348}
{"mode": "train", "epochs": 1, "timestep": 772, "ep_reward": 431.71307373046875, "reward": 0.05640077590942383, "action": 1.843493938446045}
{"mode": "train", "epochs": 1, "timestep": 773, "ep_reward": 431.77471923828125, "reward": 0.06165879964828491, "action": 1.2564202547073364}
{"mode": "train", "epochs": 1, "timestep": 774, "ep_reward": 431.9731750488281, "reward": 0.19846171140670776, "action": 0.6177045106887817}
{"mode": "train", "epochs": 1, "timestep": 775, "ep_reward": 432.31671142578125, "reward": 0.34353840351104736, "action": 0.08461815118789673}
{"mode": "train", "epochs": 1, "timestep": 776, "ep_reward": 432.8036804199219, "reward": 0.48697739839553833, "action": 1.2916866540908813}
{"mode": "train", "epochs": 1, "timestep": 777, "ep_reward": 433.4026184082031, "reward": 0.5989439487457275, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 778, "ep_reward": 434.0868835449219, "reward": 0.6842725276947021, "action": 1.4669427871704102}
{"mode": "train", "epochs": 1, "timestep": 779, "ep_reward": 434.841552734375, "reward": 0.7546699047088623, "action": 0.9588536620140076}
{"mode": "train", "epochs": 1, "timestep": 780, "ep_reward": 435.6502685546875, "reward": 0.8087071776390076, "action": 0.9573284387588501}
{"mode": "train", "epochs": 1, "timestep": 781, "ep_reward": 436.4931640625, "reward": 0.8428863286972046, "action": 1.452293038368225}
{"mode": "train", "epochs": 1, "timestep": 782, "ep_reward": 437.3481750488281, "reward": 0.855019211769104, "action": 1.2009966373443604}
{"mode": "train", "epochs": 1, "timestep": 783, "ep_reward": 438.1998596191406, "reward": 0.8516904711723328, "action": 1.5374364852905273}
{"mode": "train", "epochs": 1, "timestep": 784, "ep_reward": 439.025634765625, "reward": 0.825767993927002, "action": 1.078796625137329}
{"mode": "train", "epochs": 1, "timestep": 785, "ep_reward": 439.80609130859375, "reward": 0.7804514169692993, "action": 1.0680465698242188}
{"mode": "train", "epochs": 1, "timestep": 786, "ep_reward": 440.5119323730469, "reward": 0.7058357000350952, "action": 1.0347243547439575}
{"mode": "train", "epochs": 1, "timestep": 787, "ep_reward": 441.1070861816406, "reward": 0.595145583152771, "action": 0.7970224022865295}
{"mode": "train", "epochs": 1, "timestep": 788, "ep_reward": 441.552734375, "reward": 0.44565898180007935, "action": 1.788567304611206}
{"mode": "train", "epochs": 1, "timestep": 789, "ep_reward": 441.8833923339844, "reward": 0.3306591510772705, "action": 0.20001453161239624}
{"mode": "train", "epochs": 1, "timestep": 790, "ep_reward": 442.10015869140625, "reward": 0.2167566418647766, "action": 1.3342643976211548}
{"mode": "train", "epochs": 1, "timestep": 791, "ep_reward": 442.1831970214844, "reward": 0.08304208517074585, "action": 0.7238532304763794}
{"mode": "train", "epochs": 1, "timestep": 792, "ep_reward": 442.21771240234375, "reward": 0.03451251983642578, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 793, "ep_reward": 442.3927917480469, "reward": 0.1750660538673401, "action": 0.9720760583877563}
{"mode": "train", "epochs": 1, "timestep": 794, "ep_reward": 442.7082824707031, "reward": 0.31548404693603516, "action": -0.27827656269073486}
{"mode": "train", "epochs": 1, "timestep": 795, "ep_reward": 443.174072265625, "reward": 0.46579664945602417, "action": 1.166361689567566}
{"mode": "train", "epochs": 1, "timestep": 796, "ep_reward": 443.75616455078125, "reward": 0.5821016430854797, "action": 1.6648542881011963}
{"mode": "train", "epochs": 1, "timestep": 797, "ep_reward": 444.4302673339844, "reward": 0.6740943193435669, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 798, "ep_reward": 445.1730651855469, "reward": 0.7427934408187866, "action": 0.6055420637130737}
{"mode": "train", "epochs": 1, "timestep": 799, "ep_reward": 445.9771728515625, "reward": 0.8041124939918518, "action": 1.0765438079833984}
{"mode": "train", "epochs": 1, "timestep": 800, "ep_reward": 446.8180847167969, "reward": 0.8409105539321899, "action": 1.3625314235687256}
{"mode": "train", "epochs": 1, "timestep": 801, "ep_reward": 447.67584228515625, "reward": 0.85775226354599, "action": 1.1469030380249023}
{"mode": "train", "epochs": 1, "timestep": 802, "ep_reward": 448.5353088378906, "reward": 0.8594614267349243, "action": 1.5570353269577026}
{"mode": "train", "epochs": 1, "timestep": 803, "ep_reward": 449.374755859375, "reward": 0.8394359350204468, "action": 0.2526291012763977}
{"mode": "train", "epochs": 1, "timestep": 804, "ep_reward": 450.185302734375, "reward": 0.8105611205101013, "action": 0.6877259016036987}
{"mode": "train", "epochs": 1, "timestep": 805, "ep_reward": 450.93804931640625, "reward": 0.7527413964271545, "action": 1.0703611373901367}
{"mode": "train", "epochs": 1, "timestep": 806, "ep_reward": 451.59716796875, "reward": 0.6591131687164307, "action": 0.74881911277771}
{"mode": "train", "epochs": 1, "timestep": 807, "ep_reward": 452.1282958984375, "reward": 0.5311200618743896, "action": 1.3281341791152954}
{"mode": "train", "epochs": 1, "timestep": 808, "ep_reward": 452.50079345703125, "reward": 0.372497022151947, "action": 0.8134677410125732}
{"mode": "train", "epochs": 1, "timestep": 809, "ep_reward": 452.767822265625, "reward": 0.26703232526779175, "action": 1.396651029586792}
{"mode": "train", "epochs": 1, "timestep": 810, "ep_reward": 452.9095764160156, "reward": 0.14176911115646362, "action": 0.1615409255027771}
{"mode": "train", "epochs": 1, "timestep": 811, "ep_reward": 452.9059143066406, "reward": -0.003673076629638672, "action": 0.9876616597175598}
{"mode": "train", "epochs": 1, "timestep": 812, "ep_reward": 453.02423095703125, "reward": 0.11830359697341919, "action": 1.945251703262329}
{"mode": "train", "epochs": 1, "timestep": 813, "ep_reward": 453.27154541015625, "reward": 0.24731171131134033, "action": 0.13700991868972778}
{"mode": "train", "epochs": 1, "timestep": 814, "ep_reward": 453.6697998046875, "reward": 0.39824825525283813, "action": 0.5734177827835083}
{"mode": "train", "epochs": 1, "timestep": 815, "ep_reward": 454.2004089355469, "reward": 0.5306105613708496, "action": 1.6982245445251465}
{"mode": "train", "epochs": 1, "timestep": 816, "ep_reward": 454.83203125, "reward": 0.631630003452301, "action": 1.0560303926467896}
{"mode": "train", "epochs": 1, "timestep": 817, "ep_reward": 455.55084228515625, "reward": 0.7188029289245605, "action": 0.2365615963935852}
{"mode": "train", "epochs": 1, "timestep": 818, "ep_reward": 456.3417663574219, "reward": 0.7909137010574341, "action": 0.9639633893966675}
{"mode": "train", "epochs": 1, "timestep": 819, "ep_reward": 457.1766662597656, "reward": 0.8348987102508545, "action": 1.8096511363983154}
{"mode": "train", "epochs": 1, "timestep": 820, "ep_reward": 458.031005859375, "reward": 0.854324460029602, "action": 0.2742518186569214}
{"mode": "train", "epochs": 1, "timestep": 821, "ep_reward": 458.9012145996094, "reward": 0.870220422744751, "action": 0.7088948488235474}
{"mode": "train", "epochs": 1, "timestep": 822, "ep_reward": 459.7674255371094, "reward": 0.8662115335464478, "action": -0.09588205814361572}
{"mode": "train", "epochs": 1, "timestep": 823, "ep_reward": 460.6196594238281, "reward": 0.8522312045097351, "action": 0.905968964099884}
{"mode": "train", "epochs": 1, "timestep": 824, "ep_reward": 461.4294128417969, "reward": 0.8097423315048218, "action": 0.9874911904335022}
{"mode": "train", "epochs": 1, "timestep": 825, "ep_reward": 462.1701354980469, "reward": 0.7407292127609253, "action": 1.5421695709228516}
{"mode": "train", "epochs": 1, "timestep": 826, "ep_reward": 462.8020324707031, "reward": 0.6318889856338501, "action": 0.8366737365722656}
{"mode": "train", "epochs": 1, "timestep": 827, "ep_reward": 463.2937316894531, "reward": 0.4916991591453552, "action": 1.6250731945037842}
{"mode": "train", "epochs": 1, "timestep": 828, "ep_reward": 463.63592529296875, "reward": 0.3421857953071594, "action": 1.4374947547912598}
{"mode": "train", "epochs": 1, "timestep": 829, "ep_reward": 463.86651611328125, "reward": 0.23058605194091797, "action": 1.812958002090454}
{"mode": "train", "epochs": 1, "timestep": 830, "ep_reward": 463.9656982421875, "reward": 0.09916746616363525, "action": 1.271614670753479}
{"mode": "train", "epochs": 1, "timestep": 831, "ep_reward": 463.9831237792969, "reward": 0.01741570234298706, "action": 1.5467818975448608}
{"mode": "train", "epochs": 1, "timestep": 832, "ep_reward": 464.1431884765625, "reward": 0.16007423400878906, "action": 1.4076851606369019}
{"mode": "train", "epochs": 1, "timestep": 833, "ep_reward": 464.43798828125, "reward": 0.2947876453399658, "action": 0.8016135692596436}
{"mode": "train", "epochs": 1, "timestep": 834, "ep_reward": 464.8724670410156, "reward": 0.4344850182533264, "action": 0.8775157928466797}
{"mode": "train", "epochs": 1, "timestep": 835, "ep_reward": 465.43182373046875, "reward": 0.5593701601028442, "action": 0.7948670387268066}
{"mode": "train", "epochs": 1, "timestep": 836, "ep_reward": 466.09637451171875, "reward": 0.6645493507385254, "action": 0.918889582157135}
{"mode": "train", "epochs": 1, "timestep": 837, "ep_reward": 466.84161376953125, "reward": 0.7452477216720581, "action": 1.2427256107330322}
{"mode": "train", "epochs": 1, "timestep": 838, "ep_reward": 467.642578125, "reward": 0.8009610772132874, "action": 1.442443609237671}
{"mode": "train", "epochs": 1, "timestep": 839, "ep_reward": 468.4781799316406, "reward": 0.8356010913848877, "action": 0.7738443613052368}
{"mode": "train", "epochs": 1, "timestep": 840, "ep_reward": 469.33642578125, "reward": 0.8582326173782349, "action": 0.7433425188064575}
{"mode": "train", "epochs": 1, "timestep": 841, "ep_reward": 470.2004089355469, "reward": 0.863976001739502, "action": 1.5562381744384766}
{"mode": "train", "epochs": 1, "timestep": 842, "ep_reward": 471.04559326171875, "reward": 0.8451770544052124, "action": 0.4560807943344116}
{"mode": "train", "epochs": 1, "timestep": 843, "ep_reward": 471.86138916015625, "reward": 0.8157978057861328, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 844, "ep_reward": 472.6067810058594, "reward": 0.7454066872596741, "action": 0.6497732400894165}
{"mode": "train", "epochs": 1, "timestep": 845, "ep_reward": 473.26324462890625, "reward": 0.656456708908081, "action": 0.926636815071106}
{"mode": "train", "epochs": 1, "timestep": 846, "ep_reward": 473.788818359375, "reward": 0.5255858898162842, "action": 1.3659968376159668}
{"mode": "train", "epochs": 1, "timestep": 847, "ep_reward": 474.162841796875, "reward": 0.3740237355232239, "action": 0.3243684768676758}
{"mode": "train", "epochs": 1, "timestep": 848, "ep_reward": 474.4317626953125, "reward": 0.2689065933227539, "action": 0.9203344583511353}
{"mode": "train", "epochs": 1, "timestep": 849, "ep_reward": 474.575439453125, "reward": 0.14367163181304932, "action": 1.8662203550338745}
{"mode": "train", "epochs": 1, "timestep": 850, "ep_reward": 474.5741882324219, "reward": -0.0012603998184204102, "action": 1.1323107481002808}
{"mode": "train", "epochs": 1, "timestep": 851, "ep_reward": 474.6904296875, "reward": 0.1162344217300415, "action": 1.4372897148132324}
{"mode": "train", "epochs": 1, "timestep": 852, "ep_reward": 474.9398498535156, "reward": 0.24942272901535034, "action": 1.4957170486450195}
{"mode": "train", "epochs": 1, "timestep": 853, "ep_reward": 475.3227233886719, "reward": 0.38287097215652466, "action": 0.9828378558158875}
{"mode": "train", "epochs": 1, "timestep": 854, "ep_reward": 475.8362121582031, "reward": 0.5134955644607544, "action": -0.17305278778076172}
{"mode": "train", "epochs": 1, "timestep": 855, "ep_reward": 476.4738464355469, "reward": 0.6376217603683472, "action": 1.0722379684448242}
{"mode": "train", "epochs": 1, "timestep": 856, "ep_reward": 477.1972961425781, "reward": 0.7234638929367065, "action": 0.3278682231903076}
{"mode": "train", "epochs": 1, "timestep": 857, "ep_reward": 477.9911193847656, "reward": 0.7938117980957031, "action": 0.867950439453125}
{"mode": "train", "epochs": 1, "timestep": 858, "ep_reward": 478.8294372558594, "reward": 0.8383071422576904, "action": 0.4393276572227478}
{"mode": "train", "epochs": 1, "timestep": 859, "ep_reward": 479.6981201171875, "reward": 0.8686813116073608, "action": 0.893701434135437}
{"mode": "train", "epochs": 1, "timestep": 860, "ep_reward": 480.5779113769531, "reward": 0.8797786235809326, "action": 0.6536652445793152}
{"mode": "train", "epochs": 1, "timestep": 861, "ep_reward": 481.4559020996094, "reward": 0.8779894709587097, "action": 0.6871246099472046}
{"mode": "train", "epochs": 1, "timestep": 862, "ep_reward": 482.3159484863281, "reward": 0.8600612282752991, "action": 1.3684747219085693}
{"mode": "train", "epochs": 1, "timestep": 863, "ep_reward": 483.1326904296875, "reward": 0.8167510628700256, "action": 1.7768230438232422}
{"mode": "train", "epochs": 1, "timestep": 864, "ep_reward": 483.875732421875, "reward": 0.74305659532547, "action": 0.0012437701225280762}
{"mode": "train", "epochs": 1, "timestep": 865, "ep_reward": 484.5328063964844, "reward": 0.6570620536804199, "action": 1.0806344747543335}
{"mode": "train", "epochs": 1, "timestep": 866, "ep_reward": 485.05413818359375, "reward": 0.5213297605514526, "action": 0.6684303283691406}
{"mode": "train", "epochs": 1, "timestep": 867, "ep_reward": 485.4112548828125, "reward": 0.35711967945098877, "action": 0.45838403701782227}
{"mode": "train", "epochs": 1, "timestep": 868, "ep_reward": 485.6597595214844, "reward": 0.2485036849975586, "action": 1.0416353940963745}
{"mode": "train", "epochs": 1, "timestep": 869, "ep_reward": 485.7796325683594, "reward": 0.11987239122390747, "action": 1.4883999824523926}
{"mode": "train", "epochs": 1, "timestep": 870, "ep_reward": 485.7742614746094, "reward": -0.005382895469665527, "action": 1.3946846723556519}
{"mode": "train", "epochs": 1, "timestep": 871, "ep_reward": 485.9145202636719, "reward": 0.1402605175971985, "action": 1.0826303958892822}
{"mode": "train", "epochs": 1, "timestep": 872, "ep_reward": 486.19305419921875, "reward": 0.2785232663154602, "action": 1.2591652870178223}
{"mode": "train", "epochs": 1, "timestep": 873, "ep_reward": 486.6060485839844, "reward": 0.41297978162765503, "action": 0.5310928225517273}
{"mode": "train", "epochs": 1, "timestep": 874, "ep_reward": 487.1506652832031, "reward": 0.5446154475212097, "action": 0.7695531845092773}
{"mode": "train", "epochs": 1, "timestep": 875, "ep_reward": 487.8035583496094, "reward": 0.6528875827789307, "action": 1.0448243618011475}
{"mode": "train", "epochs": 1, "timestep": 876, "ep_reward": 488.53912353515625, "reward": 0.7355544567108154, "action": 1.0097328424453735}
{"mode": "train", "epochs": 1, "timestep": 877, "ep_reward": 489.3358459472656, "reward": 0.796714186668396, "action": 0.9656346440315247}
{"mode": "train", "epochs": 1, "timestep": 878, "ep_reward": 490.17413330078125, "reward": 0.8382853865623474, "action": 1.6826646327972412}
{"mode": "train", "epochs": 1, "timestep": 879, "ep_reward": 491.0305480957031, "reward": 0.8564081192016602, "action": 0.9532132744789124}
{"mode": "train", "epochs": 1, "timestep": 880, "ep_reward": 491.8946838378906, "reward": 0.8641355633735657, "action": 1.2169466018676758}
{"mode": "train", "epochs": 1, "timestep": 881, "ep_reward": 492.7471923828125, "reward": 0.8524959683418274, "action": 0.3096776604652405}
{"mode": "train", "epochs": 1, "timestep": 882, "ep_reward": 493.5771179199219, "reward": 0.8299126029014587, "action": 0.9027761220932007}
{"mode": "train", "epochs": 1, "timestep": 883, "ep_reward": 494.35626220703125, "reward": 0.7791562080383301, "action": 0.7723521590232849}
{"mode": "train", "epochs": 1, "timestep": 884, "ep_reward": 495.0572204589844, "reward": 0.7009701728820801, "action": 1.4890668392181396}
{"mode": "train", "epochs": 1, "timestep": 885, "ep_reward": 495.63482666015625, "reward": 0.5776113271713257, "action": 1.488430142402649}
{"mode": "train", "epochs": 1, "timestep": 886, "ep_reward": 496.0448913574219, "reward": 0.410062313079834, "action": 1.674551248550415}
{"mode": "train", "epochs": 1, "timestep": 887, "ep_reward": 496.3483581542969, "reward": 0.30348145961761475, "action": 1.057459831237793}
{"mode": "train", "epochs": 1, "timestep": 888, "ep_reward": 496.5329284667969, "reward": 0.18456071615219116, "action": 1.2548160552978516}
{"mode": "train", "epochs": 1, "timestep": 889, "ep_reward": 496.5785827636719, "reward": 0.045647263526916504, "action": 1.3872346878051758}
{"mode": "train", "epochs": 1, "timestep": 890, "ep_reward": 496.65087890625, "reward": 0.07229650020599365, "action": 1.5402271747589111}
{"mode": "train", "epochs": 1, "timestep": 891, "ep_reward": 496.8584899902344, "reward": 0.20761865377426147, "action": 1.201149821281433}
{"mode": "train", "epochs": 1, "timestep": 892, "ep_reward": 497.2040100097656, "reward": 0.3455343246459961, "action": 0.8229160904884338}
{"mode": "train", "epochs": 1, "timestep": 893, "ep_reward": 497.6852111816406, "reward": 0.4811924695968628, "action": 1.346693515777588}
{"mode": "train", "epochs": 1, "timestep": 894, "ep_reward": 498.2793884277344, "reward": 0.5941920280456543, "action": 0.6284197568893433}
{"mode": "train", "epochs": 1, "timestep": 895, "ep_reward": 498.9730224609375, "reward": 0.69364333152771, "action": 0.956116259098053}
{"mode": "train", "epochs": 1, "timestep": 896, "ep_reward": 499.7388610839844, "reward": 0.7658408284187317, "action": 1.2222329378128052}
{"mode": "train", "epochs": 1, "timestep": 897, "ep_reward": 500.5528869628906, "reward": 0.8140405416488647, "action": 0.8628391623497009}
{"mode": "train", "epochs": 1, "timestep": 898, "ep_reward": 501.39886474609375, "reward": 0.8459821939468384, "action": 1.938776969909668}
{"mode": "train", "epochs": 1, "timestep": 899, "ep_reward": 502.2498474121094, "reward": 0.8509719371795654, "action": 0.9081347584724426}
{"mode": "train", "epochs": 1, "timestep": 900, "ep_reward": 503.09674072265625, "reward": 0.8469054698944092, "action": 0.7425793409347534}
{"mode": "train", "epochs": 1, "timestep": 901, "ep_reward": 503.9212951660156, "reward": 0.8245643377304077, "action": 0.6588388681411743}
{"mode": "train", "epochs": 1, "timestep": 902, "ep_reward": 504.7012634277344, "reward": 0.7799579501152039, "action": 0.6103502511978149}
{"mode": "train", "epochs": 1, "timestep": 903, "ep_reward": 505.4089660644531, "reward": 0.7076879739761353, "action": 0.42004477977752686}
{"mode": "train", "epochs": 1, "timestep": 904, "ep_reward": 506.01251220703125, "reward": 0.6035585999488831, "action": 1.7682533264160156}
{"mode": "train", "epochs": 1, "timestep": 905, "ep_reward": 506.4525146484375, "reward": 0.4399911165237427, "action": 0.4670690894126892}
{"mode": "train", "epochs": 1, "timestep": 906, "ep_reward": 506.77471923828125, "reward": 0.3222163915634155, "action": 1.0305095911026}
{"mode": "train", "epochs": 1, "timestep": 907, "ep_reward": 506.9814453125, "reward": 0.2067212462425232, "action": 1.6282494068145752}
{"mode": "train", "epochs": 1, "timestep": 908, "ep_reward": 507.0529479980469, "reward": 0.07149171829223633, "action": 0.0012064576148986816}
{"mode": "train", "epochs": 1, "timestep": 909, "ep_reward": 507.0994873046875, "reward": 0.04653126001358032, "action": 1.8428890705108643}
{"mode": "train", "epochs": 1, "timestep": 910, "ep_reward": 507.2850036621094, "reward": 0.18550360202789307, "action": -0.07785296440124512}
{"mode": "train", "epochs": 1, "timestep": 911, "ep_reward": 507.6239013671875, "reward": 0.33888769149780273, "action": 0.9643239378929138}
{"mode": "train", "epochs": 1, "timestep": 912, "ep_reward": 508.0952453613281, "reward": 0.4713587164878845, "action": 0.6170169711112976}
{"mode": "train", "epochs": 1, "timestep": 913, "ep_reward": 508.6882629394531, "reward": 0.5930126309394836, "action": 1.1488076448440552}
{"mode": "train", "epochs": 1, "timestep": 914, "ep_reward": 509.37646484375, "reward": 0.6881988644599915, "action": 1.5849847793579102}
{"mode": "train", "epochs": 1, "timestep": 915, "ep_reward": 510.13470458984375, "reward": 0.7582329511642456, "action": 1.514085054397583}
{"mode": "train", "epochs": 1, "timestep": 916, "ep_reward": 510.9441223144531, "reward": 0.809421956539154, "action": 0.5593729019165039}
{"mode": "train", "epochs": 1, "timestep": 917, "ep_reward": 511.7944641113281, "reward": 0.8503504395484924, "action": 0.46672046184539795}
{"mode": "train", "epochs": 1, "timestep": 918, "ep_reward": 512.6692504882812, "reward": 0.8747881650924683, "action": 1.5045802593231201}
{"mode": "train", "epochs": 1, "timestep": 919, "ep_reward": 513.5449829101562, "reward": 0.8757483959197998, "action": 1.3247880935668945}
{"mode": "train", "epochs": 1, "timestep": 920, "ep_reward": 514.4071655273438, "reward": 0.8621796369552612, "action": 1.8466148376464844}
{"mode": "train", "epochs": 1, "timestep": 921, "ep_reward": 515.2321166992188, "reward": 0.8249489665031433, "action": 0.28351783752441406}
{"mode": "train", "epochs": 1, "timestep": 922, "ep_reward": 516.0111694335938, "reward": 0.7790558934211731, "action": 1.0175883769989014}
{"mode": "train", "epochs": 1, "timestep": 923, "ep_reward": 516.708251953125, "reward": 0.6970574855804443, "action": 0.8760603666305542}
{"mode": "train", "epochs": 1, "timestep": 924, "ep_reward": 517.2890625, "reward": 0.580780029296875, "action": 0.7971565127372742}
{"mode": "train", "epochs": 1, "timestep": 925, "ep_reward": 517.7142333984375, "reward": 0.42517220973968506, "action": 0.6316866874694824}
{"mode": "train", "epochs": 1, "timestep": 926, "ep_reward": 518.0167236328125, "reward": 0.3024654984474182, "action": 0.9943638443946838}
{"mode": "train", "epochs": 1, "timestep": 927, "ep_reward": 518.2000732421875, "reward": 0.18335574865341187, "action": 1.2091398239135742}
{"mode": "train", "epochs": 1, "timestep": 928, "ep_reward": 518.2444458007812, "reward": 0.044360458850860596, "action": 0.3394903540611267}
{"mode": "train", "epochs": 1, "timestep": 929, "ep_reward": 518.3182373046875, "reward": 0.07380849123001099, "action": 0.06604266166687012}
{"mode": "train", "epochs": 1, "timestep": 930, "ep_reward": 518.5410766601562, "reward": 0.22286862134933472, "action": 0.8563423752784729}
{"mode": "train", "epochs": 1, "timestep": 931, "ep_reward": 518.9031982421875, "reward": 0.3621419072151184, "action": 0.6496301889419556}
{"mode": "train", "epochs": 1, "timestep": 932, "ep_reward": 519.3994140625, "reward": 0.4962172508239746, "action": 1.091893196105957}
{"mode": "train", "epochs": 1, "timestep": 933, "ep_reward": 520.0082397460938, "reward": 0.6088045835494995, "action": 1.9017858505249023}
{"mode": "train", "epochs": 1, "timestep": 934, "ep_reward": 520.7017822265625, "reward": 0.6935425996780396, "action": 0.29927897453308105}
{"mode": "train", "epochs": 1, "timestep": 935, "ep_reward": 521.4749755859375, "reward": 0.7732028365135193, "action": 0.42866724729537964}
{"mode": "train", "epochs": 1, "timestep": 936, "ep_reward": 522.3043823242188, "reward": 0.8293880224227905, "action": 1.9585599899291992}
{"mode": "train", "epochs": 1, "timestep": 937, "ep_reward": 523.1596069335938, "reward": 0.8552033305168152, "action": 0.8701475262641907}
{"mode": "train", "epochs": 1, "timestep": 938, "ep_reward": 524.0338745117188, "reward": 0.8742642402648926, "action": 1.9816570281982422}
{"mode": "train", "epochs": 1, "timestep": 939, "ep_reward": 524.9030151367188, "reward": 0.8691473603248596, "action": 1.7300970554351807}
{"mode": "train", "epochs": 1, "timestep": 940, "ep_reward": 525.751953125, "reward": 0.8489505052566528, "action": 1.1064196825027466}
{"mode": "train", "epochs": 1, "timestep": 941, "ep_reward": 526.5656127929688, "reward": 0.8136627674102783, "action": 1.2196416854858398}
{"mode": "train", "epochs": 1, "timestep": 942, "ep_reward": 527.3173217773438, "reward": 0.7517034411430359, "action": 0.20732218027114868}
{"mode": "train", "epochs": 1, "timestep": 943, "ep_reward": 527.9873046875, "reward": 0.6699658632278442, "action": 1.133745551109314}
{"mode": "train", "epochs": 1, "timestep": 944, "ep_reward": 528.5271606445312, "reward": 0.5398534536361694, "action": 1.0719490051269531}
{"mode": "train", "epochs": 1, "timestep": 945, "ep_reward": 528.9050903320312, "reward": 0.37792909145355225, "action": 1.1630715131759644}
{"mode": "train", "epochs": 1, "timestep": 946, "ep_reward": 529.1788330078125, "reward": 0.27372241020202637, "action": 0.9968591332435608}
{"mode": "train", "epochs": 1, "timestep": 947, "ep_reward": 529.328369140625, "reward": 0.14954370260238647, "action": 0.4439634680747986}
{"mode": "train", "epochs": 1, "timestep": 948, "ep_reward": 529.3336181640625, "reward": 0.005253791809082031, "action": 1.0908859968185425}
{"mode": "train", "epochs": 1, "timestep": 949, "ep_reward": 529.444091796875, "reward": 0.1104695200920105, "action": 0.6043682098388672}
{"mode": "train", "epochs": 1, "timestep": 950, "ep_reward": 529.697998046875, "reward": 0.2538905143737793, "action": 1.272287368774414}
{"mode": "train", "epochs": 1, "timestep": 951, "ep_reward": 530.0863037109375, "reward": 0.3882887363433838, "action": 0.6540400981903076}
{"mode": "train", "epochs": 1, "timestep": 952, "ep_reward": 530.6071166992188, "reward": 0.5208139419555664, "action": 1.3902397155761719}
{"mode": "train", "epochs": 1, "timestep": 953, "ep_reward": 531.23388671875, "reward": 0.6267552375793457, "action": 1.0348560810089111}
{"mode": "train", "epochs": 1, "timestep": 954, "ep_reward": 531.9493408203125, "reward": 0.7154351472854614, "action": 0.8902398943901062}
{"mode": "train", "epochs": 1, "timestep": 955, "ep_reward": 532.732421875, "reward": 0.7830677032470703, "action": 1.144398808479309}
{"mode": "train", "epochs": 1, "timestep": 956, "ep_reward": 533.5601196289062, "reward": 0.8277237415313721, "action": 1.2629427909851074}
{"mode": "train", "epochs": 1, "timestep": 957, "ep_reward": 534.4133911132812, "reward": 0.8532731533050537, "action": 1.1396827697753906}
{"mode": "train", "epochs": 1, "timestep": 958, "ep_reward": 535.2763061523438, "reward": 0.8628910183906555, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 959, "ep_reward": 536.124267578125, "reward": 0.847981333732605, "action": 0.15699982643127441}
{"mode": "train", "epochs": 1, "timestep": 960, "ep_reward": 536.9544067382812, "reward": 0.8301459550857544, "action": 0.6994614005088806}
{"mode": "train", "epochs": 1, "timestep": 961, "ep_reward": 537.7393798828125, "reward": 0.7849756479263306, "action": 0.42904752492904663}
{"mode": "train", "epochs": 1, "timestep": 962, "ep_reward": 538.4546508789062, "reward": 0.7152570486068726, "action": 0.9644982218742371}
{"mode": "train", "epochs": 1, "timestep": 963, "ep_reward": 539.059814453125, "reward": 0.6051861047744751, "action": 1.7907629013061523}
{"mode": "train", "epochs": 1, "timestep": 964, "ep_reward": 539.50146484375, "reward": 0.44167667627334595, "action": 0.13185638189315796}
{"mode": "train", "epochs": 1, "timestep": 965, "ep_reward": 539.8233032226562, "reward": 0.32186853885650635, "action": 1.8906856775283813}
{"mode": "train", "epochs": 1, "timestep": 966, "ep_reward": 540.0299072265625, "reward": 0.2066185474395752, "action": 0.8130606412887573}
{"mode": "train", "epochs": 1, "timestep": 967, "ep_reward": 540.10107421875, "reward": 0.0711367130279541, "action": 1.2111592292785645}
{"mode": "train", "epochs": 1, "timestep": 968, "ep_reward": 540.1480712890625, "reward": 0.04698699712753296, "action": 0.6425983905792236}
{"mode": "train", "epochs": 1, "timestep": 969, "ep_reward": 540.3361206054688, "reward": 0.18804341554641724, "action": 1.0626051425933838}
{"mode": "train", "epochs": 1, "timestep": 970, "ep_reward": 540.6630859375, "reward": 0.326948344707489, "action": 1.0865260362625122}
{"mode": "train", "epochs": 1, "timestep": 971, "ep_reward": 541.1234741210938, "reward": 0.4603993892669678, "action": 0.30203771591186523}
{"mode": "train", "epochs": 1, "timestep": 972, "ep_reward": 541.7113037109375, "reward": 0.587827205657959, "action": 1.372126817703247}
{"mode": "train", "epochs": 1, "timestep": 973, "ep_reward": 542.3929443359375, "reward": 0.6816461682319641, "action": 1.0752644538879395}
{"mode": "train", "epochs": 1, "timestep": 974, "ep_reward": 543.1498413085938, "reward": 0.7568798065185547, "action": 0.3339308500289917}
{"mode": "train", "epochs": 1, "timestep": 975, "ep_reward": 543.967041015625, "reward": 0.8171951174736023, "action": 1.2179877758026123}
{"mode": "train", "epochs": 1, "timestep": 976, "ep_reward": 544.8174438476562, "reward": 0.8504006862640381, "action": 0.9220332503318787}
{"mode": "train", "epochs": 1, "timestep": 977, "ep_reward": 545.68701171875, "reward": 0.8695389032363892, "action": 1.1947979927062988}
{"mode": "train", "epochs": 1, "timestep": 978, "ep_reward": 546.5576782226562, "reward": 0.8706851005554199, "action": 1.5269660949707031}
{"mode": "train", "epochs": 1, "timestep": 979, "ep_reward": 547.4099731445312, "reward": 0.8522881269454956, "action": 1.0409600734710693}
{"mode": "train", "epochs": 1, "timestep": 980, "ep_reward": 548.2280883789062, "reward": 0.8181262016296387, "action": 1.1297085285186768}
{"mode": "train", "epochs": 1, "timestep": 981, "ep_reward": 548.9862670898438, "reward": 0.7581958770751953, "action": 1.1277196407318115}
{"mode": "train", "epochs": 1, "timestep": 982, "ep_reward": 549.6527709960938, "reward": 0.6665301322937012, "action": 0.3787989020347595}
{"mode": "train", "epochs": 1, "timestep": 983, "ep_reward": 550.19970703125, "reward": 0.5469156503677368, "action": 0.8572679758071899}
{"mode": "train", "epochs": 1, "timestep": 984, "ep_reward": 550.5802001953125, "reward": 0.3805053234100342, "action": 0.4890229105949402}
{"mode": "train", "epochs": 1, "timestep": 985, "ep_reward": 550.8563232421875, "reward": 0.2761276364326477, "action": 0.9134858846664429}
{"mode": "train", "epochs": 1, "timestep": 986, "ep_reward": 551.0086669921875, "reward": 0.15232425928115845, "action": 0.868503212928772}
{"mode": "train", "epochs": 1, "timestep": 987, "ep_reward": 551.0172119140625, "reward": 0.008527398109436035, "action": 0.7611899375915527}
{"mode": "train", "epochs": 1, "timestep": 988, "ep_reward": 551.1246337890625, "reward": 0.10741537809371948, "action": 1.4593639373779297}
{"mode": "train", "epochs": 1, "timestep": 989, "ep_reward": 551.3648071289062, "reward": 0.2401658296585083, "action": 0.9528958797454834}
{"mode": "train", "epochs": 1, "timestep": 990, "ep_reward": 551.7454833984375, "reward": 0.38067901134490967, "action": 0.9909285306930542}
{"mode": "train", "epochs": 1, "timestep": 991, "ep_reward": 552.25634765625, "reward": 0.5108664035797119, "action": 0.9370793104171753}
{"mode": "train", "epochs": 1, "timestep": 992, "ep_reward": 552.8797607421875, "reward": 0.6234381794929504, "action": 1.162415862083435}
{"mode": "train", "epochs": 1, "timestep": 993, "ep_reward": 553.5908813476562, "reward": 0.7111221551895142, "action": 1.2942943572998047}
{"mode": "train", "epochs": 1, "timestep": 994, "ep_reward": 554.3658447265625, "reward": 0.7749356627464294, "action": 1.6931390762329102}
{"mode": "train", "epochs": 1, "timestep": 995, "ep_reward": 555.1802368164062, "reward": 0.8143889904022217, "action": 0.5040985345840454}
{"mode": "train", "epochs": 1, "timestep": 996, "ep_reward": 556.0255126953125, "reward": 0.8452701568603516, "action": 0.38741326332092285}
{"mode": "train", "epochs": 1, "timestep": 997, "ep_reward": 556.8841552734375, "reward": 0.8586142063140869, "action": 0.8814266920089722}
{"mode": "train", "epochs": 1, "timestep": 998, "ep_reward": 557.7337646484375, "reward": 0.8496114015579224, "action": 1.7606806755065918}
{"mode": "train", "epochs": 1, "timestep": 999, "ep_reward": 558.5458984375, "reward": 0.8121230006217957, "action": 1.1390774250030518}
{"mode": "train", "epochs": 1, "timestep": 1000, "ep_reward": 559.3003540039062, "reward": 0.7544270157814026, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1001, "ep_reward": 559.9535522460938, "reward": 0.6532125473022461, "action": 1.2928794622421265}
{"mode": "train", "epochs": 1, "timestep": 1002, "ep_reward": 560.4717407226562, "reward": 0.5181924104690552, "action": 1.4499695301055908}
{"mode": "train", "epochs": 1, "timestep": 1003, "ep_reward": 560.8547973632812, "reward": 0.3830750584602356, "action": 1.335217833518982}
{"mode": "train", "epochs": 1, "timestep": 1004, "ep_reward": 561.1348266601562, "reward": 0.28001487255096436, "action": 0.8660411834716797}
{"mode": "train", "epochs": 1, "timestep": 1005, "ep_reward": 561.291748046875, "reward": 0.15692973136901855, "action": 0.35543161630630493}
{"mode": "train", "epochs": 1, "timestep": 1006, "ep_reward": 561.3054809570312, "reward": 0.013721346855163574, "action": 1.2179778814315796}
{"mode": "train", "epochs": 1, "timestep": 1007, "ep_reward": 561.4081420898438, "reward": 0.10264527797698975, "action": 1.1993403434753418}
{"mode": "train", "epochs": 1, "timestep": 1008, "ep_reward": 561.6466674804688, "reward": 0.23850810527801514, "action": 0.9182408452033997}
{"mode": "train", "epochs": 1, "timestep": 1009, "ep_reward": 562.0255737304688, "reward": 0.3788934350013733, "action": 1.4438230991363525}
{"mode": "train", "epochs": 1, "timestep": 1010, "ep_reward": 562.529296875, "reward": 0.5037193298339844, "action": 0.6030198931694031}
{"mode": "train", "epochs": 1, "timestep": 1011, "ep_reward": 563.1505126953125, "reward": 0.6212351322174072, "action": 0.33523863554000854}
{"mode": "train", "epochs": 1, "timestep": 1012, "ep_reward": 563.8682861328125, "reward": 0.7178026437759399, "action": 0.9780296683311462}
{"mode": "train", "epochs": 1, "timestep": 1013, "ep_reward": 564.6526489257812, "reward": 0.7843544483184814, "action": 1.2482680082321167}
{"mode": "train", "epochs": 1, "timestep": 1014, "ep_reward": 565.4808959960938, "reward": 0.8282595872879028, "action": 0.5465620756149292}
{"mode": "train", "epochs": 1, "timestep": 1015, "ep_reward": 566.3410034179688, "reward": 0.8601136207580566, "action": 0.5326772332191467}
{"mode": "train", "epochs": 1, "timestep": 1016, "ep_reward": 567.2164916992188, "reward": 0.8754729628562927, "action": 1.2650810480117798}
{"mode": "train", "epochs": 1, "timestep": 1017, "ep_reward": 568.0858154296875, "reward": 0.8693100214004517, "action": 0.9724363684654236}
{"mode": "train", "epochs": 1, "timestep": 1018, "ep_reward": 568.9342041015625, "reward": 0.8483971953392029, "action": 1.4830148220062256}
{"mode": "train", "epochs": 1, "timestep": 1019, "ep_reward": 569.7360229492188, "reward": 0.8018430471420288, "action": 0.21733087301254272}
{"mode": "train", "epochs": 1, "timestep": 1020, "ep_reward": 570.4779663085938, "reward": 0.7419558763504028, "action": 0.9849506616592407}
{"mode": "train", "epochs": 1, "timestep": 1021, "ep_reward": 571.1199951171875, "reward": 0.6420149207115173, "action": 0.9567559361457825}
{"mode": "train", "epochs": 1, "timestep": 1022, "ep_reward": 571.6234741210938, "reward": 0.5035057663917542, "action": 1.0747706890106201}
{"mode": "train", "epochs": 1, "timestep": 1023, "ep_reward": 571.973388671875, "reward": 0.3498920202255249, "action": 1.0307519435882568}
{"mode": "train", "epochs": 1, "timestep": 1024, "ep_reward": 572.2132568359375, "reward": 0.2398856282234192, "action": 1.0302419662475586}
{"mode": "train", "epochs": 1, "timestep": 1025, "ep_reward": 572.3231201171875, "reward": 0.10989093780517578, "action": 0.9399397373199463}
{"mode": "train", "epochs": 1, "timestep": 1026, "ep_reward": 572.3289794921875, "reward": 0.005864143371582031, "action": 1.026041865348816}
{"mode": "train", "epochs": 1, "timestep": 1027, "ep_reward": 572.4790649414062, "reward": 0.1500592827796936, "action": 0.5720268487930298}
{"mode": "train", "epochs": 1, "timestep": 1028, "ep_reward": 572.77392578125, "reward": 0.2948494553565979, "action": 1.276030421257019}
{"mode": "train", "epochs": 1, "timestep": 1029, "ep_reward": 573.2012939453125, "reward": 0.4273563027381897, "action": 0.6537179946899414}
{"mode": "train", "epochs": 1, "timestep": 1030, "ep_reward": 573.7565307617188, "reward": 0.5552623271942139, "action": 1.2845878601074219}
{"mode": "train", "epochs": 1, "timestep": 1031, "ep_reward": 574.4127807617188, "reward": 0.656262218952179, "action": 0.8500259518623352}
{"mode": "train", "epochs": 1, "timestep": 1032, "ep_reward": 575.1526489257812, "reward": 0.7398717999458313, "action": 1.3501222133636475}
{"mode": "train", "epochs": 1, "timestep": 1033, "ep_reward": 575.949462890625, "reward": 0.7968138456344604, "action": 1.6516634225845337}
{"mode": "train", "epochs": 1, "timestep": 1034, "ep_reward": 576.7814331054688, "reward": 0.8319866061210632, "action": 0.9990379214286804}
{"mode": "train", "epochs": 1, "timestep": 1035, "ep_reward": 577.6365356445312, "reward": 0.8551320433616638, "action": 0.6958120465278625}
{"mode": "train", "epochs": 1, "timestep": 1036, "ep_reward": 578.5003051757812, "reward": 0.8637693524360657, "action": 0.5478178858757019}
{"mode": "train", "epochs": 1, "timestep": 1037, "ep_reward": 579.356689453125, "reward": 0.8563807606697083, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1038, "ep_reward": 580.1730346679688, "reward": 0.816352367401123, "action": 0.5475583076477051}
{"mode": "train", "epochs": 1, "timestep": 1039, "ep_reward": 580.9384155273438, "reward": 0.7654037475585938, "action": 0.5935060977935791}
{"mode": "train", "epochs": 1, "timestep": 1040, "ep_reward": 581.6229248046875, "reward": 0.6845258474349976, "action": 0.7775799632072449}
{"mode": "train", "epochs": 1, "timestep": 1041, "ep_reward": 582.1883544921875, "reward": 0.565422534942627, "action": 0.8390895128250122}
{"mode": "train", "epochs": 1, "timestep": 1042, "ep_reward": 582.5929565429688, "reward": 0.40463006496429443, "action": 1.1893188953399658}
{"mode": "train", "epochs": 1, "timestep": 1043, "ep_reward": 582.885009765625, "reward": 0.2920494079589844, "action": 1.1430398225784302}
{"mode": "train", "epochs": 1, "timestep": 1044, "ep_reward": 583.0560302734375, "reward": 0.1710071563720703, "action": 1.5699797868728638}
{"mode": "train", "epochs": 1, "timestep": 1045, "ep_reward": 583.086181640625, "reward": 0.03017944097518921, "action": 0.44903331995010376}
{"mode": "train", "epochs": 1, "timestep": 1046, "ep_reward": 583.173583984375, "reward": 0.08739131689071655, "action": 0.7619118094444275}
{"mode": "train", "epochs": 1, "timestep": 1047, "ep_reward": 583.40185546875, "reward": 0.22825872898101807, "action": 0.7885938882827759}
{"mode": "train", "epochs": 1, "timestep": 1048, "ep_reward": 583.7716064453125, "reward": 0.3697260618209839, "action": 0.7441493272781372}
{"mode": "train", "epochs": 1, "timestep": 1049, "ep_reward": 584.2744750976562, "reward": 0.5028386116027832, "action": 1.1542271375656128}
{"mode": "train", "epochs": 1, "timestep": 1050, "ep_reward": 584.8887329101562, "reward": 0.614230215549469, "action": 0.6159341931343079}
{"mode": "train", "epochs": 1, "timestep": 1051, "ep_reward": 585.5988159179688, "reward": 0.7100741863250732, "action": 0.48791444301605225}
{"mode": "train", "epochs": 1, "timestep": 1052, "ep_reward": 586.3828125, "reward": 0.7840186953544617, "action": -0.30497634410858154}
{"mode": "train", "epochs": 1, "timestep": 1053, "ep_reward": 587.22607421875, "reward": 0.8432387113571167, "action": 1.0739920139312744}
{"mode": "train", "epochs": 1, "timestep": 1054, "ep_reward": 588.0994262695312, "reward": 0.8733508586883545, "action": 0.5847511291503906}
{"mode": "train", "epochs": 1, "timestep": 1055, "ep_reward": 588.9923706054688, "reward": 0.89292311668396, "action": 1.376302719116211}
{"mode": "train", "epochs": 1, "timestep": 1056, "ep_reward": 589.8860473632812, "reward": 0.8936930894851685, "action": 1.0341368913650513}
{"mode": "train", "epochs": 1, "timestep": 1057, "ep_reward": 590.76953125, "reward": 0.8834933042526245, "action": 1.2198854684829712}
{"mode": "train", "epochs": 1, "timestep": 1058, "ep_reward": 591.6255493164062, "reward": 0.8560115098953247, "action": 0.6663374900817871}
{"mode": "train", "epochs": 1, "timestep": 1059, "ep_reward": 592.4392700195312, "reward": 0.8137312531471252, "action": 0.423132061958313}
{"mode": "train", "epochs": 1, "timestep": 1060, "ep_reward": 593.18896484375, "reward": 0.7497105598449707, "action": 1.5134204626083374}
{"mode": "train", "epochs": 1, "timestep": 1061, "ep_reward": 593.8311157226562, "reward": 0.6421212553977966, "action": 1.8548437356948853}
{"mode": "train", "epochs": 1, "timestep": 1062, "ep_reward": 594.3198852539062, "reward": 0.4887857437133789, "action": 1.3173058032989502}
{"mode": "train", "epochs": 1, "timestep": 1063, "ep_reward": 594.6574096679688, "reward": 0.33755117654800415, "action": 1.5321049690246582}
{"mode": "train", "epochs": 1, "timestep": 1064, "ep_reward": 594.8826293945312, "reward": 0.22519451379776, "action": 1.0904881954193115}
{"mode": "train", "epochs": 1, "timestep": 1065, "ep_reward": 594.975341796875, "reward": 0.09272664785385132, "action": 1.3494077920913696}
{"mode": "train", "epochs": 1, "timestep": 1066, "ep_reward": 594.9996948242188, "reward": 0.02434217929840088, "action": 1.3460158109664917}
{"mode": "train", "epochs": 1, "timestep": 1067, "ep_reward": 595.1658935546875, "reward": 0.16617345809936523, "action": 0.3844313621520996}
{"mode": "train", "epochs": 1, "timestep": 1068, "ep_reward": 595.4794921875, "reward": 0.3135794401168823, "action": 1.2729318141937256}
{"mode": "train", "epochs": 1, "timestep": 1069, "ep_reward": 595.9242553710938, "reward": 0.4447818994522095, "action": 0.7057058811187744}
{"mode": "train", "epochs": 1, "timestep": 1070, "ep_reward": 596.493896484375, "reward": 0.569648265838623, "action": 1.532778024673462}
{"mode": "train", "epochs": 1, "timestep": 1071, "ep_reward": 597.1593627929688, "reward": 0.6654577851295471, "action": 0.32391268014907837}
{"mode": "train", "epochs": 1, "timestep": 1072, "ep_reward": 597.9110717773438, "reward": 0.7517035603523254, "action": 1.0796146392822266}
{"mode": "train", "epochs": 1, "timestep": 1073, "ep_reward": 598.7193603515625, "reward": 0.8083056211471558, "action": 0.9967788457870483}
{"mode": "train", "epochs": 1, "timestep": 1074, "ep_reward": 599.5661010742188, "reward": 0.8467212915420532, "action": 0.6236956119537354}
{"mode": "train", "epochs": 1, "timestep": 1075, "ep_reward": 600.4374389648438, "reward": 0.8713308572769165, "action": 0.5412439703941345}
{"mode": "train", "epochs": 1, "timestep": 1076, "ep_reward": 601.318603515625, "reward": 0.8811931610107422, "action": 0.5710270404815674}
{"mode": "train", "epochs": 1, "timestep": 1077, "ep_reward": 602.1945190429688, "reward": 0.875900387763977, "action": 0.8554776310920715}
{"mode": "train", "epochs": 1, "timestep": 1078, "ep_reward": 603.0465087890625, "reward": 0.8519642353057861, "action": 0.4439274072647095}
{"mode": "train", "epochs": 1, "timestep": 1079, "ep_reward": 603.8585815429688, "reward": 0.8120682239532471, "action": 0.9979627728462219}
{"mode": "train", "epochs": 1, "timestep": 1080, "ep_reward": 604.6005249023438, "reward": 0.7419577836990356, "action": 0.6026729345321655}
{"mode": "train", "epochs": 1, "timestep": 1081, "ep_reward": 605.2449951171875, "reward": 0.6444652080535889, "action": 1.8677972555160522}
{"mode": "train", "epochs": 1, "timestep": 1082, "ep_reward": 605.7366943359375, "reward": 0.4916740655899048, "action": 1.5932788848876953}
{"mode": "train", "epochs": 1, "timestep": 1083, "ep_reward": 606.075927734375, "reward": 0.3392465114593506, "action": 0.7861170172691345}
{"mode": "train", "epochs": 1, "timestep": 1084, "ep_reward": 606.3031005859375, "reward": 0.2271655797958374, "action": -0.12172317504882812}
{"mode": "train", "epochs": 1, "timestep": 1085, "ep_reward": 606.3981323242188, "reward": 0.09504848718643188, "action": 0.03001999855041504}
{"mode": "train", "epochs": 1, "timestep": 1086, "ep_reward": 606.4202270507812, "reward": 0.022089481353759766, "action": 0.3725511431694031}
{"mode": "train", "epochs": 1, "timestep": 1087, "ep_reward": 606.5859375, "reward": 0.16568142175674438, "action": 1.1960585117340088}
{"mode": "train", "epochs": 1, "timestep": 1088, "ep_reward": 606.8887329101562, "reward": 0.30279481410980225, "action": 0.5455923080444336}
{"mode": "train", "epochs": 1, "timestep": 1089, "ep_reward": 607.3331298828125, "reward": 0.44441211223602295, "action": 1.1064196825027466}
{"mode": "train", "epochs": 1, "timestep": 1090, "ep_reward": 607.8981323242188, "reward": 0.5650166273117065, "action": 0.384498655796051}
{"mode": "train", "epochs": 1, "timestep": 1091, "ep_reward": 608.5714111328125, "reward": 0.6732804179191589, "action": 1.3475109338760376}
{"mode": "train", "epochs": 1, "timestep": 1092, "ep_reward": 609.3201293945312, "reward": 0.7486913204193115, "action": 0.8394803404808044}
{"mode": "train", "epochs": 1, "timestep": 1093, "ep_reward": 610.1281127929688, "reward": 0.8079540133476257, "action": 0.8617799878120422}
{"mode": "train", "epochs": 1, "timestep": 1094, "ep_reward": 610.9757080078125, "reward": 0.847623884677887, "action": 0.9465624094009399}
{"mode": "train", "epochs": 1, "timestep": 1095, "ep_reward": 611.8453979492188, "reward": 0.8697022795677185, "action": 1.1573585271835327}
{"mode": "train", "epochs": 1, "timestep": 1096, "ep_reward": 612.7200927734375, "reward": 0.8747183084487915, "action": 0.5777864456176758}
{"mode": "train", "epochs": 1, "timestep": 1097, "ep_reward": 613.5889892578125, "reward": 0.8688925504684448, "action": 0.6852966547012329}
{"mode": "train", "epochs": 1, "timestep": 1098, "ep_reward": 614.43408203125, "reward": 0.845069408416748, "action": 0.4701232314109802}
{"mode": "train", "epochs": 1, "timestep": 1099, "ep_reward": 615.23681640625, "reward": 0.8027396202087402, "action": 1.4533103704452515}
{"mode": "train", "epochs": 1, "timestep": 1100, "ep_reward": 615.9608154296875, "reward": 0.7239934206008911, "action": 0.5661351680755615}
{"mode": "train", "epochs": 1, "timestep": 1101, "ep_reward": 616.5821533203125, "reward": 0.6213515996932983, "action": 1.3408145904541016}
{"mode": "train", "epochs": 1, "timestep": 1102, "ep_reward": 617.0515747070312, "reward": 0.4694057106971741, "action": 0.3886836767196655}
{"mode": "train", "epochs": 1, "timestep": 1103, "ep_reward": 617.3785400390625, "reward": 0.326948344707489, "action": 0.7195602655410767}
{"mode": "train", "epochs": 1, "timestep": 1104, "ep_reward": 617.5909423828125, "reward": 0.2124323844909668, "action": 0.8734973073005676}
{"mode": "train", "epochs": 1, "timestep": 1105, "ep_reward": 617.6688232421875, "reward": 0.07787078619003296, "action": 1.3220341205596924}
{"mode": "train", "epochs": 1, "timestep": 1106, "ep_reward": 617.708740234375, "reward": 0.03992509841918945, "action": 1.4924285411834717}
{"mode": "train", "epochs": 1, "timestep": 1107, "ep_reward": 617.8884887695312, "reward": 0.17971986532211304, "action": 0.05861616134643555}
{"mode": "train", "epochs": 1, "timestep": 1108, "ep_reward": 618.2199096679688, "reward": 0.3314211368560791, "action": 0.2813045382499695}
{"mode": "train", "epochs": 1, "timestep": 1109, "ep_reward": 618.6923828125, "reward": 0.4724913239479065, "action": 0.2307249903678894}
{"mode": "train", "epochs": 1, "timestep": 1110, "ep_reward": 619.2899780273438, "reward": 0.5976250767707825, "action": 0.9725794196128845}
{"mode": "train", "epochs": 1, "timestep": 1111, "ep_reward": 619.9837646484375, "reward": 0.6937986612319946, "action": 1.1314435005187988}
{"mode": "train", "epochs": 1, "timestep": 1112, "ep_reward": 620.75146484375, "reward": 0.7677059769630432, "action": 1.320780634880066}
{"mode": "train", "epochs": 1, "timestep": 1113, "ep_reward": 621.572265625, "reward": 0.8208212852478027, "action": 0.29560577869415283}
{"mode": "train", "epochs": 1, "timestep": 1114, "ep_reward": 622.4371337890625, "reward": 0.8648660778999329, "action": 0.5515629053115845}
{"mode": "train", "epochs": 1, "timestep": 1115, "ep_reward": 623.3284912109375, "reward": 0.8913291096687317, "action": 1.3304556608200073}
{"mode": "train", "epochs": 1, "timestep": 1116, "ep_reward": 624.2279663085938, "reward": 0.899449348449707, "action": 0.9454576373100281}
{"mode": "train", "epochs": 1, "timestep": 1117, "ep_reward": 625.1260986328125, "reward": 0.8981436491012573, "action": 0.9240732192993164}
{"mode": "train", "epochs": 1, "timestep": 1118, "ep_reward": 626.0098266601562, "reward": 0.8837530612945557, "action": 1.0002678632736206}
{"mode": "train", "epochs": 1, "timestep": 1119, "ep_reward": 626.862548828125, "reward": 0.8526999354362488, "action": 1.8924429416656494}
{"mode": "train", "epochs": 1, "timestep": 1120, "ep_reward": 627.6548461914062, "reward": 0.7922807335853577, "action": 0.525373101234436}
{"mode": "train", "epochs": 1, "timestep": 1121, "ep_reward": 628.3722534179688, "reward": 0.7174014449119568, "action": 1.0758060216903687}
{"mode": "train", "epochs": 1, "timestep": 1122, "ep_reward": 628.97509765625, "reward": 0.6028157472610474, "action": 1.4343005418777466}
{"mode": "train", "epochs": 1, "timestep": 1123, "ep_reward": 629.4178466796875, "reward": 0.4427352547645569, "action": 1.8928990364074707}
{"mode": "train", "epochs": 1, "timestep": 1124, "ep_reward": 629.7225341796875, "reward": 0.30471062660217285, "action": 1.8531138896942139}
{"mode": "train", "epochs": 1, "timestep": 1125, "ep_reward": 629.9087524414062, "reward": 0.18620824813842773, "action": 1.1126154661178589}
{"mode": "train", "epochs": 1, "timestep": 1126, "ep_reward": 629.9563598632812, "reward": 0.04758352041244507, "action": 1.0051473379135132}
{"mode": "train", "epochs": 1, "timestep": 1127, "ep_reward": 630.02685546875, "reward": 0.07048159837722778, "action": 1.4234884977340698}
{"mode": "train", "epochs": 1, "timestep": 1128, "ep_reward": 630.2328491210938, "reward": 0.2059946060180664, "action": 1.444225788116455}
{"mode": "train", "epochs": 1, "timestep": 1129, "ep_reward": 630.5737915039062, "reward": 0.34093230962753296, "action": 0.12810873985290527}
{"mode": "train", "epochs": 1, "timestep": 1130, "ep_reward": 631.0593872070312, "reward": 0.485595166683197, "action": 0.810491681098938}
{"mode": "train", "epochs": 1, "timestep": 1131, "ep_reward": 631.6629638671875, "reward": 0.603546142578125, "action": 1.245619535446167}
{"mode": "train", "epochs": 1, "timestep": 1132, "ep_reward": 632.3582763671875, "reward": 0.6953086256980896, "action": 0.6948716044425964}
{"mode": "train", "epochs": 1, "timestep": 1133, "ep_reward": 633.1284790039062, "reward": 0.7701998353004456, "action": 1.0157325267791748}
{"mode": "train", "epochs": 1, "timestep": 1134, "ep_reward": 633.9490356445312, "reward": 0.8205552697181702, "action": 1.4059783220291138}
{"mode": "train", "epochs": 1, "timestep": 1135, "ep_reward": 634.7982177734375, "reward": 0.8491538763046265, "action": 0.4907798767089844}
{"mode": "train", "epochs": 1, "timestep": 1136, "ep_reward": 635.6668701171875, "reward": 0.8686294555664062, "action": 0.7502571940422058}
{"mode": "train", "epochs": 1, "timestep": 1137, "ep_reward": 636.53662109375, "reward": 0.8697793483734131, "action": 0.6791948080062866}
{"mode": "train", "epochs": 1, "timestep": 1138, "ep_reward": 637.391357421875, "reward": 0.8547075986862183, "action": 1.7327947616577148}
{"mode": "train", "epochs": 1, "timestep": 1139, "ep_reward": 638.2013549804688, "reward": 0.810004711151123, "action": 1.43507719039917}
{"mode": "train", "epochs": 1, "timestep": 1140, "ep_reward": 638.9424438476562, "reward": 0.7411192655563354, "action": 0.6915398836135864}
{"mode": "train", "epochs": 1, "timestep": 1141, "ep_reward": 639.5899658203125, "reward": 0.6475311517715454, "action": 0.43044888973236084}
{"mode": "train", "epochs": 1, "timestep": 1142, "ep_reward": 640.1099243164062, "reward": 0.5199353098869324, "action": 0.4879876375198364}
{"mode": "train", "epochs": 1, "timestep": 1143, "ep_reward": 640.4716796875, "reward": 0.3617570400238037, "action": 1.8266007900238037}
{"mode": "train", "epochs": 1, "timestep": 1144, "ep_reward": 640.7260131835938, "reward": 0.25432002544403076, "action": 1.057277798652649}
{"mode": "train", "epochs": 1, "timestep": 1145, "ep_reward": 640.8527221679688, "reward": 0.12671279907226562, "action": 1.2769584655761719}
{"mode": "train", "epochs": 1, "timestep": 1146, "ep_reward": 640.8396606445312, "reward": -0.013048768043518066, "action": 1.2370001077651978}
{"mode": "train", "epochs": 1, "timestep": 1147, "ep_reward": 640.97314453125, "reward": 0.1334754228591919, "action": 1.5593348741531372}
{"mode": "train", "epochs": 1, "timestep": 1148, "ep_reward": 641.23876953125, "reward": 0.26561564207077026, "action": 1.4145140647888184}
{"mode": "train", "epochs": 1, "timestep": 1149, "ep_reward": 641.6383666992188, "reward": 0.39961427450180054, "action": 1.0152873992919922}
{"mode": "train", "epochs": 1, "timestep": 1150, "ep_reward": 642.1661376953125, "reward": 0.5277756452560425, "action": 1.6922504901885986}
{"mode": "train", "epochs": 1, "timestep": 1151, "ep_reward": 642.7952880859375, "reward": 0.6291552186012268, "action": 0.6350476145744324}
{"mode": "train", "epochs": 1, "timestep": 1152, "ep_reward": 643.5147094726562, "reward": 0.7194263935089111, "action": 1.5874104499816895}
{"mode": "train", "epochs": 1, "timestep": 1153, "ep_reward": 644.2908935546875, "reward": 0.7761717438697815, "action": 0.9193724989891052}
{"mode": "train", "epochs": 1, "timestep": 1154, "ep_reward": 645.1087646484375, "reward": 0.8178596496582031, "action": 0.8445984721183777}
{"mode": "train", "epochs": 1, "timestep": 1155, "ep_reward": 645.9486083984375, "reward": 0.8398675918579102, "action": 0.6371470093727112}
{"mode": "train", "epochs": 1, "timestep": 1156, "ep_reward": 646.7928466796875, "reward": 0.8442190885543823, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1157, "ep_reward": 647.6083374023438, "reward": 0.8154852986335754, "action": 0.05596834421157837}
{"mode": "train", "epochs": 1, "timestep": 1158, "ep_reward": 648.3901977539062, "reward": 0.7818640470504761, "action": 0.9734840393066406}
{"mode": "train", "epochs": 1, "timestep": 1159, "ep_reward": 649.1004638671875, "reward": 0.7102896571159363, "action": 0.5947223901748657}
{"mode": "train", "epochs": 1, "timestep": 1160, "ep_reward": 649.7083740234375, "reward": 0.6078895330429077, "action": 1.8653537034988403}
{"mode": "train", "epochs": 1, "timestep": 1161, "ep_reward": 650.1537475585938, "reward": 0.4453975558280945, "action": 1.8941311836242676}
{"mode": "train", "epochs": 1, "timestep": 1162, "ep_reward": 650.49072265625, "reward": 0.3369591236114502, "action": 0.4431479573249817}
{"mode": "train", "epochs": 1, "timestep": 1163, "ep_reward": 650.7150268554688, "reward": 0.22428959608078003, "action": 1.333400845527649}
{"mode": "train", "epochs": 1, "timestep": 1164, "ep_reward": 650.8068237304688, "reward": 0.09180504083633423, "action": 0.6378786563873291}
{"mode": "train", "epochs": 1, "timestep": 1165, "ep_reward": 650.8323364257812, "reward": 0.025517642498016357, "action": 0.4490712881088257}
{"mode": "train", "epochs": 1, "timestep": 1166, "ep_reward": 651.0006713867188, "reward": 0.1683444380760193, "action": 0.47978419065475464}
{"mode": "train", "epochs": 1, "timestep": 1167, "ep_reward": 651.3150024414062, "reward": 0.31432026624679565, "action": 1.327924132347107}
{"mode": "train", "epochs": 1, "timestep": 1168, "ep_reward": 651.7596435546875, "reward": 0.444643497467041, "action": 1.8725881576538086}
{"mode": "train", "epochs": 1, "timestep": 1169, "ep_reward": 652.3163452148438, "reward": 0.55669105052948, "action": 0.6907700300216675}
{"mode": "train", "epochs": 1, "timestep": 1170, "ep_reward": 652.979736328125, "reward": 0.6634024381637573, "action": 0.8915485739707947}
{"mode": "train", "epochs": 1, "timestep": 1171, "ep_reward": 653.7240600585938, "reward": 0.7443164587020874, "action": 0.8142167925834656}
{"mode": "train", "epochs": 1, "timestep": 1172, "ep_reward": 654.5275268554688, "reward": 0.8034716844558716, "action": 1.1932768821716309}
{"mode": "train", "epochs": 1, "timestep": 1173, "ep_reward": 655.36669921875, "reward": 0.8391718864440918, "action": 1.6905252933502197}
{"mode": "train", "epochs": 1, "timestep": 1174, "ep_reward": 656.2197265625, "reward": 0.853044867515564, "action": 1.1923197507858276}
{"mode": "train", "epochs": 1, "timestep": 1175, "ep_reward": 657.0736083984375, "reward": 0.8539087176322937, "action": -0.029592037200927734}
{"mode": "train", "epochs": 1, "timestep": 1176, "ep_reward": 657.921142578125, "reward": 0.8475096821784973, "action": 0.3309595584869385}
{"mode": "train", "epochs": 1, "timestep": 1177, "ep_reward": 658.7393798828125, "reward": 0.8182274103164673, "action": 1.0030649900436401}
{"mode": "train", "epochs": 1, "timestep": 1178, "ep_reward": 659.4974975585938, "reward": 0.7581263780593872, "action": 1.711223840713501}
{"mode": "train", "epochs": 1, "timestep": 1179, "ep_reward": 660.1551513671875, "reward": 0.6576342582702637, "action": 1.2940541505813599}
{"mode": "train", "epochs": 1, "timestep": 1180, "ep_reward": 660.6764526367188, "reward": 0.5212986469268799, "action": 1.1071466207504272}
{"mode": "train", "epochs": 1, "timestep": 1181, "ep_reward": 661.0482788085938, "reward": 0.3718123435974121, "action": 1.644892930984497}
{"mode": "train", "epochs": 1, "timestep": 1182, "ep_reward": 661.314697265625, "reward": 0.2664269804954529, "action": 0.9262709617614746}
{"mode": "train", "epochs": 1, "timestep": 1183, "ep_reward": 661.45556640625, "reward": 0.14085090160369873, "action": 1.4393054246902466}
{"mode": "train", "epochs": 1, "timestep": 1184, "ep_reward": 661.450927734375, "reward": -0.004649639129638672, "action": 1.4447952508926392}
{"mode": "train", "epochs": 1, "timestep": 1185, "ep_reward": 661.5702514648438, "reward": 0.11931240558624268, "action": 0.7712103128433228}
{"mode": "train", "epochs": 1, "timestep": 1186, "ep_reward": 661.8311767578125, "reward": 0.2609497308731079, "action": 0.9479615688323975}
{"mode": "train", "epochs": 1, "timestep": 1187, "ep_reward": 662.23046875, "reward": 0.39931392669677734, "action": 0.6398516297340393}
{"mode": "train", "epochs": 1, "timestep": 1188, "ep_reward": 662.7611694335938, "reward": 0.5306872129440308, "action": 0.6237474083900452}
{"mode": "train", "epochs": 1, "timestep": 1189, "ep_reward": 663.4041137695312, "reward": 0.6429243087768555, "action": 1.0943500995635986}
{"mode": "train", "epochs": 1, "timestep": 1190, "ep_reward": 664.1321411132812, "reward": 0.7280028462409973, "action": 1.0262486934661865}
{"mode": "train", "epochs": 1, "timestep": 1191, "ep_reward": 664.9244384765625, "reward": 0.7923163771629333, "action": 1.306660771369934}
{"mode": "train", "epochs": 1, "timestep": 1192, "ep_reward": 665.7590942382812, "reward": 0.8346651792526245, "action": 1.605604648590088}
{"mode": "train", "epochs": 1, "timestep": 1193, "ep_reward": 666.6166381835938, "reward": 0.8575397729873657, "action": 1.3677971363067627}
{"mode": "train", "epochs": 1, "timestep": 1194, "ep_reward": 667.4830322265625, "reward": 0.8663886785507202, "action": 1.275774598121643}
{"mode": "train", "epochs": 1, "timestep": 1195, "ep_reward": 668.3425903320312, "reward": 0.859585702419281, "action": 0.5623511075973511}
{"mode": "train", "epochs": 1, "timestep": 1196, "ep_reward": 669.1834716796875, "reward": 0.8408821225166321, "action": 0.9489703178405762}
{"mode": "train", "epochs": 1, "timestep": 1197, "ep_reward": 669.9807739257812, "reward": 0.797298789024353, "action": 1.13986074924469}
{"mode": "train", "epochs": 1, "timestep": 1198, "ep_reward": 670.705078125, "reward": 0.7243236303329468, "action": 1.440401554107666}
{"mode": "train", "epochs": 1, "timestep": 1199, "ep_reward": 671.3175659179688, "reward": 0.6124914884567261, "action": 0.3050497770309448}
{"mode": "train", "epochs": 1, "timestep": 1200, "ep_reward": 671.7929077148438, "reward": 0.4753217101097107, "action": 1.513812780380249}
{"mode": "train", "epochs": 1, "timestep": 1201, "ep_reward": 672.1295776367188, "reward": 0.33664214611053467, "action": 0.9953216910362244}
{"mode": "train", "epochs": 1, "timestep": 1202, "ep_reward": 672.353515625, "reward": 0.22396284341812134, "action": 1.376205563545227}
{"mode": "train", "epochs": 1, "timestep": 1203, "ep_reward": 672.4449462890625, "reward": 0.09145480394363403, "action": 0.2557474970817566}
{"mode": "train", "epochs": 1, "timestep": 1204, "ep_reward": 672.4708862304688, "reward": 0.025925159454345703, "action": 0.009210288524627686}
{"mode": "train", "epochs": 1, "timestep": 1205, "ep_reward": 672.6450805664062, "reward": 0.1742171049118042, "action": 0.4918314814567566}
{"mode": "train", "epochs": 1, "timestep": 1206, "ep_reward": 672.9639892578125, "reward": 0.31892651319503784, "action": 0.7320477962493896}
{"mode": "train", "epochs": 1, "timestep": 1207, "ep_reward": 673.4193725585938, "reward": 0.45536476373672485, "action": 0.11081838607788086}
{"mode": "train", "epochs": 1, "timestep": 1208, "ep_reward": 674.0038452148438, "reward": 0.5844554901123047, "action": 0.6089451909065247}
{"mode": "train", "epochs": 1, "timestep": 1209, "ep_reward": 674.6905517578125, "reward": 0.6867291331291199, "action": 0.45829153060913086}
{"mode": "train", "epochs": 1, "timestep": 1210, "ep_reward": 675.4589233398438, "reward": 0.7683993577957153, "action": 0.6048016548156738}
{"mode": "train", "epochs": 1, "timestep": 1211, "ep_reward": 676.2869873046875, "reward": 0.8280858397483826, "action": 0.8977205157279968}
{"mode": "train", "epochs": 1, "timestep": 1212, "ep_reward": 677.1551513671875, "reward": 0.8681345582008362, "action": 1.5563147068023682}
{"mode": "train", "epochs": 1, "timestep": 1213, "ep_reward": 678.0448608398438, "reward": 0.8896801471710205, "action": 0.7941683530807495}
{"mode": "train", "epochs": 1, "timestep": 1214, "ep_reward": 678.9494018554688, "reward": 0.9045144319534302, "action": 1.118777871131897}
{"mode": "train", "epochs": 1, "timestep": 1215, "ep_reward": 679.85498046875, "reward": 0.9055968523025513, "action": 0.26847225427627563}
{"mode": "train", "epochs": 1, "timestep": 1216, "ep_reward": 680.7559204101562, "reward": 0.9009209871292114, "action": 0.9661864638328552}
{"mode": "train", "epochs": 1, "timestep": 1217, "ep_reward": 681.6337890625, "reward": 0.8778975605964661, "action": 0.38126319646835327}
{"mode": "train", "epochs": 1, "timestep": 1218, "ep_reward": 682.4769287109375, "reward": 0.8431553244590759, "action": 0.6472094058990479}
{"mode": "train", "epochs": 1, "timestep": 1219, "ep_reward": 683.2623901367188, "reward": 0.785448431968689, "action": 0.40426766872406006}
{"mode": "train", "epochs": 1, "timestep": 1220, "ep_reward": 683.966064453125, "reward": 0.703671932220459, "action": 1.5751562118530273}
{"mode": "train", "epochs": 1, "timestep": 1221, "ep_reward": 684.5404663085938, "reward": 0.5744269490242004, "action": 0.9873266220092773}
{"mode": "train", "epochs": 1, "timestep": 1222, "ep_reward": 684.953369140625, "reward": 0.4128960371017456, "action": 1.147665023803711}
{"mode": "train", "epochs": 1, "timestep": 1223, "ep_reward": 685.222412109375, "reward": 0.26907241344451904, "action": 0.5497044324874878}
{"mode": "train", "epochs": 1, "timestep": 1224, "ep_reward": 685.3663330078125, "reward": 0.14393538236618042, "action": 1.3184784650802612}
{"mode": "train", "epochs": 1, "timestep": 1225, "ep_reward": 685.3652954101562, "reward": -0.0010178089141845703, "action": 0.49181151390075684}
{"mode": "train", "epochs": 1, "timestep": 1226, "ep_reward": 685.4813232421875, "reward": 0.11601346731185913, "action": 1.7470262050628662}
{"mode": "train", "epochs": 1, "timestep": 1227, "ep_reward": 685.7267456054688, "reward": 0.2454373836517334, "action": 0.562470018863678}
{"mode": "train", "epochs": 1, "timestep": 1228, "ep_reward": 686.117919921875, "reward": 0.39115726947784424, "action": 0.7298140525817871}
{"mode": "train", "epochs": 1, "timestep": 1229, "ep_reward": 686.6408081054688, "reward": 0.5228986740112305, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1230, "ep_reward": 687.2628173828125, "reward": 0.6219961643218994, "action": 0.5580255389213562}
{"mode": "train", "epochs": 1, "timestep": 1231, "ep_reward": 687.9783935546875, "reward": 0.7155711650848389, "action": 1.1399794816970825}
{"mode": "train", "epochs": 1, "timestep": 1232, "ep_reward": 688.7578735351562, "reward": 0.7794992923736572, "action": 0.8193849325180054}
{"mode": "train", "epochs": 1, "timestep": 1233, "ep_reward": 689.5830688476562, "reward": 0.8251955509185791, "action": 1.1165170669555664}
{"mode": "train", "epochs": 1, "timestep": 1234, "ep_reward": 690.4321899414062, "reward": 0.849136233329773, "action": 0.817392110824585}
{"mode": "train", "epochs": 1, "timestep": 1235, "ep_reward": 691.2902221679688, "reward": 0.8580073118209839, "action": 0.7851353287696838}
{"mode": "train", "epochs": 1, "timestep": 1236, "ep_reward": 692.1393432617188, "reward": 0.8491507172584534, "action": 1.9230594635009766}
{"mode": "train", "epochs": 1, "timestep": 1237, "ep_reward": 692.9485473632812, "reward": 0.8092122673988342, "action": 1.3374347686767578}
{"mode": "train", "epochs": 1, "timestep": 1238, "ep_reward": 693.6967163085938, "reward": 0.7481601238250732, "action": 0.3242509365081787}
{"mode": "train", "epochs": 1, "timestep": 1239, "ep_reward": 694.36328125, "reward": 0.6665523052215576, "action": 1.2449082136154175}
{"mode": "train", "epochs": 1, "timestep": 1240, "ep_reward": 694.8986206054688, "reward": 0.5353418588638306, "action": 0.6802190542221069}
{"mode": "train", "epochs": 1, "timestep": 1241, "ep_reward": 695.2825927734375, "reward": 0.38398194313049316, "action": -0.014907360076904297}
{"mode": "train", "epochs": 1, "timestep": 1242, "ep_reward": 695.5633544921875, "reward": 0.280778169631958, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1243, "ep_reward": 695.7213745117188, "reward": 0.15800821781158447, "action": 1.0338047742843628}
{"mode": "train", "epochs": 1, "timestep": 1244, "ep_reward": 695.7363891601562, "reward": 0.015031933784484863, "action": 1.2038047313690186}
{"mode": "train", "epochs": 1, "timestep": 1245, "ep_reward": 695.837890625, "reward": 0.10152232646942139, "action": -0.3176180124282837}
{"mode": "train", "epochs": 1, "timestep": 1246, "ep_reward": 696.0938720703125, "reward": 0.2560104727745056, "action": 1.4303884506225586}
{"mode": "train", "epochs": 1, "timestep": 1247, "ep_reward": 696.48046875, "reward": 0.3866070508956909, "action": 0.01583462953567505}
{"mode": "train", "epochs": 1, "timestep": 1248, "ep_reward": 697.005859375, "reward": 0.5253942012786865, "action": 1.7674726247787476}
{"mode": "train", "epochs": 1, "timestep": 1249, "ep_reward": 697.6322021484375, "reward": 0.6263443827629089, "action": 1.3372869491577148}
{"mode": "train", "epochs": 1, "timestep": 1250, "ep_reward": 698.3450317382812, "reward": 0.7128101587295532, "action": 1.4386857748031616}
{"mode": "train", "epochs": 1, "timestep": 1251, "ep_reward": 699.1226196289062, "reward": 0.7775903344154358, "action": 1.0648596286773682}
{"mode": "train", "epochs": 1, "timestep": 1252, "ep_reward": 699.9486694335938, "reward": 0.8260400295257568, "action": 1.3074133396148682}
{"mode": "train", "epochs": 1, "timestep": 1253, "ep_reward": 700.80322265625, "reward": 0.8545395731925964, "action": 0.882346510887146}
{"mode": "train", "epochs": 1, "timestep": 1254, "ep_reward": 701.6735229492188, "reward": 0.870291531085968, "action": 0.762453019618988}
{"mode": "train", "epochs": 1, "timestep": 1255, "ep_reward": 702.5447387695312, "reward": 0.8712033033370972, "action": 1.0803288221359253}
{"mode": "train", "epochs": 1, "timestep": 1256, "ep_reward": 703.3973999023438, "reward": 0.8526385426521301, "action": 1.5248472690582275}
{"mode": "train", "epochs": 1, "timestep": 1257, "ep_reward": 704.2069702148438, "reward": 0.8095510005950928, "action": 1.4423267841339111}
{"mode": "train", "epochs": 1, "timestep": 1258, "ep_reward": 704.947265625, "reward": 0.7402838468551636, "action": 1.1444282531738281}
{"mode": "train", "epochs": 1, "timestep": 1259, "ep_reward": 705.5875244140625, "reward": 0.6402674913406372, "action": 1.3019098043441772}
{"mode": "train", "epochs": 1, "timestep": 1260, "ep_reward": 706.0849609375, "reward": 0.4974537491798401, "action": 0.5020354986190796}
{"mode": "train", "epochs": 1, "timestep": 1261, "ep_reward": 706.4427490234375, "reward": 0.3577694892883301, "action": 1.18645179271698}
{"mode": "train", "epochs": 1, "timestep": 1262, "ep_reward": 706.692138671875, "reward": 0.2494131326675415, "action": 0.6947460174560547}
{"mode": "train", "epochs": 1, "timestep": 1263, "ep_reward": 706.8131103515625, "reward": 0.12095850706100464, "action": 1.0673431158065796}
{"mode": "train", "epochs": 1, "timestep": 1264, "ep_reward": 706.806640625, "reward": -0.006451964378356934, "action": 0.8515855669975281}
{"mode": "train", "epochs": 1, "timestep": 1265, "ep_reward": 706.9459228515625, "reward": 0.1393079161643982, "action": 0.6644096374511719}
{"mode": "train", "epochs": 1, "timestep": 1266, "ep_reward": 707.2286987304688, "reward": 0.28280431032180786, "action": 0.5214002728462219}
{"mode": "train", "epochs": 1, "timestep": 1267, "ep_reward": 707.6536865234375, "reward": 0.424987256526947, "action": 1.1276682615280151}
{"mode": "train", "epochs": 1, "timestep": 1268, "ep_reward": 708.2010498046875, "reward": 0.5473604202270508, "action": 0.7289455533027649}
{"mode": "train", "epochs": 1, "timestep": 1269, "ep_reward": 708.8565673828125, "reward": 0.6555247902870178, "action": 0.9470293521881104}
{"mode": "train", "epochs": 1, "timestep": 1270, "ep_reward": 709.5956420898438, "reward": 0.7390549778938293, "action": 1.2718894481658936}
{"mode": "train", "epochs": 1, "timestep": 1271, "ep_reward": 710.39404296875, "reward": 0.798407256603241, "action": 0.42597121000289917}
{"mode": "train", "epochs": 1, "timestep": 1272, "ep_reward": 711.2398071289062, "reward": 0.8457747101783752, "action": 1.318485975265503}
{"mode": "train", "epochs": 1, "timestep": 1273, "ep_reward": 712.1085205078125, "reward": 0.8687312602996826, "action": 1.2045141458511353}
{"mode": "train", "epochs": 1, "timestep": 1274, "ep_reward": 712.9862060546875, "reward": 0.8777128458023071, "action": 0.3112514019012451}
{"mode": "train", "epochs": 1, "timestep": 1275, "ep_reward": 713.8651733398438, "reward": 0.8789872527122498, "action": 0.6743030548095703}
{"mode": "train", "epochs": 1, "timestep": 1276, "ep_reward": 714.726806640625, "reward": 0.8616042733192444, "action": 1.2067303657531738}
{"mode": "train", "epochs": 1, "timestep": 1277, "ep_reward": 715.5474243164062, "reward": 0.8206115961074829, "action": 1.3869527578353882}
{"mode": "train", "epochs": 1, "timestep": 1278, "ep_reward": 716.3001098632812, "reward": 0.7526612281799316, "action": 0.7884402871131897}
{"mode": "train", "epochs": 1, "timestep": 1279, "ep_reward": 716.9594116210938, "reward": 0.6593276858329773, "action": 1.2091649770736694}
{"mode": "train", "epochs": 1, "timestep": 1280, "ep_reward": 717.4820556640625, "reward": 0.5226645469665527, "action": 1.2798705101013184}
{"mode": "train", "epochs": 1, "timestep": 1281, "ep_reward": 717.8423461914062, "reward": 0.3603159189224243, "action": 1.1021734476089478}
{"mode": "train", "epochs": 1, "timestep": 1282, "ep_reward": 718.0947265625, "reward": 0.2523786425590515, "action": 1.3593076467514038}
{"mode": "train", "epochs": 1, "timestep": 1283, "ep_reward": 718.2191162109375, "reward": 0.12441116571426392, "action": 1.7240684032440186}
{"mode": "train", "epochs": 1, "timestep": 1284, "ep_reward": 718.2086181640625, "reward": -0.010508298873901367, "action": 1.086394190788269}
{"mode": "train", "epochs": 1, "timestep": 1285, "ep_reward": 718.3443603515625, "reward": 0.13574975728988647, "action": 1.0897877216339111}
{"mode": "train", "epochs": 1, "timestep": 1286, "ep_reward": 718.6182250976562, "reward": 0.27387338876724243, "action": 0.7988735437393188}
{"mode": "train", "epochs": 1, "timestep": 1287, "ep_reward": 719.0323486328125, "reward": 0.41410690546035767, "action": 0.5396232604980469}
{"mode": "train", "epochs": 1, "timestep": 1288, "ep_reward": 719.5772705078125, "reward": 0.5449457168579102, "action": 1.5089051723480225}
{"mode": "train", "epochs": 1, "timestep": 1289, "ep_reward": 720.2227783203125, "reward": 0.6455287933349609, "action": 0.37139856815338135}
{"mode": "train", "epochs": 1, "timestep": 1290, "ep_reward": 720.9590454101562, "reward": 0.7362505793571472, "action": 0.9451391100883484}
{"mode": "train", "epochs": 1, "timestep": 1291, "ep_reward": 721.757568359375, "reward": 0.7985066175460815, "action": 0.6951621770858765}
{"mode": "train", "epochs": 1, "timestep": 1292, "ep_reward": 722.6007690429688, "reward": 0.8431817293167114, "action": 0.8984749913215637}
{"mode": "train", "epochs": 1, "timestep": 1293, "ep_reward": 723.4696655273438, "reward": 0.8689190149307251, "action": 0.6955385208129883}
{"mode": "train", "epochs": 1, "timestep": 1294, "ep_reward": 724.3506469726562, "reward": 0.88099604845047, "action": 0.5527281761169434}
{"mode": "train", "epochs": 1, "timestep": 1295, "ep_reward": 725.2301025390625, "reward": 0.8794800043106079, "action": 0.759108304977417}
{"mode": "train", "epochs": 1, "timestep": 1296, "ep_reward": 726.0907592773438, "reward": 0.860647976398468, "action": 0.5682376623153687}
{"mode": "train", "epochs": 1, "timestep": 1297, "ep_reward": 726.91552734375, "reward": 0.8247743844985962, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1298, "ep_reward": 727.6658935546875, "reward": 0.7503743171691895, "action": 1.0343616008758545}
{"mode": "train", "epochs": 1, "timestep": 1299, "ep_reward": 728.3187866210938, "reward": 0.6529074907302856, "action": 0.635042667388916}
{"mode": "train", "epochs": 1, "timestep": 1300, "ep_reward": 728.8416137695312, "reward": 0.5228236317634583, "action": 0.3793300986289978}
{"mode": "train", "epochs": 1, "timestep": 1301, "ep_reward": 729.1993408203125, "reward": 0.35770750045776367, "action": 1.1910960674285889}
{"mode": "train", "epochs": 1, "timestep": 1302, "ep_reward": 729.4486083984375, "reward": 0.24924439191818237, "action": 1.4153836965560913}
{"mode": "train", "epochs": 1, "timestep": 1303, "ep_reward": 729.5695190429688, "reward": 0.12093502283096313, "action": 0.37242138385772705}
{"mode": "train", "epochs": 1, "timestep": 1304, "ep_reward": 729.5631103515625, "reward": -0.006386160850524902, "action": 1.1053115129470825}
{"mode": "train", "epochs": 1, "timestep": 1305, "ep_reward": 729.7024536132812, "reward": 0.13936221599578857, "action": 0.9612122774124146}
{"mode": "train", "epochs": 1, "timestep": 1306, "ep_reward": 729.9816284179688, "reward": 0.27920252084732056, "action": 0.35518878698349}
{"mode": "train", "epochs": 1, "timestep": 1307, "ep_reward": 730.40576171875, "reward": 0.4241463541984558, "action": 1.1841267347335815}
{"mode": "train", "epochs": 1, "timestep": 1308, "ep_reward": 730.9517822265625, "reward": 0.5460273027420044, "action": 1.4281914234161377}
{"mode": "train", "epochs": 1, "timestep": 1309, "ep_reward": 731.5989990234375, "reward": 0.647240400314331, "action": 0.6357058882713318}
{"mode": "train", "epochs": 1, "timestep": 1310, "ep_reward": 732.333984375, "reward": 0.7349910736083984, "action": 1.3617461919784546}
{"mode": "train", "epochs": 1, "timestep": 1311, "ep_reward": 733.12744140625, "reward": 0.7934627532958984, "action": 1.422446370124817}
{"mode": "train", "epochs": 1, "timestep": 1312, "ep_reward": 733.9595336914062, "reward": 0.8321080207824707, "action": 1.1616849899291992}
{"mode": "train", "epochs": 1, "timestep": 1313, "ep_reward": 734.8148803710938, "reward": 0.8553168773651123, "action": 0.8789058327674866}
{"mode": "train", "epochs": 1, "timestep": 1314, "ep_reward": 735.6787719726562, "reward": 0.8639129996299744, "action": 1.69242262840271}
{"mode": "train", "epochs": 1, "timestep": 1315, "ep_reward": 736.5267944335938, "reward": 0.8480107188224792, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1316, "ep_reward": 737.3348999023438, "reward": 0.8080978393554688, "action": 0.895540714263916}
{"mode": "train", "epochs": 1, "timestep": 1317, "ep_reward": 738.0874633789062, "reward": 0.7525749802589417, "action": 1.5275046825408936}
{"mode": "train", "epochs": 1, "timestep": 1318, "ep_reward": 738.7445068359375, "reward": 0.6570202112197876, "action": 1.1019260883331299}
{"mode": "train", "epochs": 1, "timestep": 1319, "ep_reward": 739.2703857421875, "reward": 0.5258805751800537, "action": 1.0108004808425903}
{"mode": "train", "epochs": 1, "timestep": 1320, "ep_reward": 739.6544799804688, "reward": 0.38408803939819336, "action": 0.8058176636695862}
{"mode": "train", "epochs": 1, "timestep": 1321, "ep_reward": 739.9356689453125, "reward": 0.28117358684539795, "action": 0.725865364074707}
{"mode": "train", "epochs": 1, "timestep": 1322, "ep_reward": 740.0938110351562, "reward": 0.15812689065933228, "action": 1.5898821353912354}
{"mode": "train", "epochs": 1, "timestep": 1323, "ep_reward": 740.109130859375, "reward": 0.01530766487121582, "action": 0.9490439295768738}
{"mode": "train", "epochs": 1, "timestep": 1324, "ep_reward": 740.2103881835938, "reward": 0.1012609601020813, "action": 0.846310019493103}
{"mode": "train", "epochs": 1, "timestep": 1325, "ep_reward": 740.4518432617188, "reward": 0.24146288633346558, "action": 0.9806174635887146}
{"mode": "train", "epochs": 1, "timestep": 1326, "ep_reward": 740.8322143554688, "reward": 0.3803662657737732, "action": 0.14045357704162598}
{"mode": "train", "epochs": 1, "timestep": 1327, "ep_reward": 741.3518676757812, "reward": 0.519641637802124, "action": 0.6705368757247925}
{"mode": "train", "epochs": 1, "timestep": 1328, "ep_reward": 741.985107421875, "reward": 0.633220911026001, "action": 0.8870295882225037}
{"mode": "train", "epochs": 1, "timestep": 1329, "ep_reward": 742.707763671875, "reward": 0.7226396799087524, "action": 0.7708714008331299}
{"mode": "train", "epochs": 1, "timestep": 1330, "ep_reward": 743.4992065429688, "reward": 0.791458249092102, "action": 0.5072138905525208}
{"mode": "train", "epochs": 1, "timestep": 1331, "ep_reward": 744.3416748046875, "reward": 0.8424385190010071, "action": 1.569791316986084}
{"mode": "train", "epochs": 1, "timestep": 1332, "ep_reward": 745.2098388671875, "reward": 0.8681477308273315, "action": 1.3357160091400146}
{"mode": "train", "epochs": 1, "timestep": 1333, "ep_reward": 746.0911865234375, "reward": 0.8813201785087585, "action": 1.4117927551269531}
{"mode": "train", "epochs": 1, "timestep": 1334, "ep_reward": 746.970947265625, "reward": 0.8797363042831421, "action": 0.7663668990135193}
{"mode": "train", "epochs": 1, "timestep": 1335, "ep_reward": 747.8388671875, "reward": 0.8678925633430481, "action": 1.6650805473327637}
{"mode": "train", "epochs": 1, "timestep": 1336, "ep_reward": 748.6690063476562, "reward": 0.8301402926445007, "action": 0.9242374897003174}
{"mode": "train", "epochs": 1, "timestep": 1337, "ep_reward": 749.4445190429688, "reward": 0.7755131125450134, "action": 1.5069544315338135}
{"mode": "train", "epochs": 1, "timestep": 1338, "ep_reward": 750.1289672851562, "reward": 0.6844437122344971, "action": 0.9841126203536987}
{"mode": "train", "epochs": 1, "timestep": 1339, "ep_reward": 750.690673828125, "reward": 0.5617000460624695, "action": 1.083044409751892}
{"mode": "train", "epochs": 1, "timestep": 1340, "ep_reward": 751.0863647460938, "reward": 0.39567887783050537, "action": 1.526278018951416}
{"mode": "train", "epochs": 1, "timestep": 1341, "ep_reward": 751.373779296875, "reward": 0.28738945722579956, "action": 0.4109799265861511}
{"mode": "train", "epochs": 1, "timestep": 1342, "ep_reward": 751.5392456054688, "reward": 0.16547411680221558, "action": 1.3062639236450195}
{"mode": "train", "epochs": 1, "timestep": 1343, "ep_reward": 751.5628051757812, "reward": 0.023563802242279053, "action": 1.7812285423278809}
{"mode": "train", "epochs": 1, "timestep": 1344, "ep_reward": 751.65625, "reward": 0.09345465898513794, "action": 0.7610577344894409}
{"mode": "train", "epochs": 1, "timestep": 1345, "ep_reward": 751.8907470703125, "reward": 0.23451751470565796, "action": 0.7047542929649353}
{"mode": "train", "epochs": 1, "timestep": 1346, "ep_reward": 752.2675170898438, "reward": 0.37679994106292725, "action": 0.6098014116287231}
{"mode": "train", "epochs": 1, "timestep": 1347, "ep_reward": 752.7781982421875, "reward": 0.510684609413147, "action": 0.27750182151794434}
{"mode": "train", "epochs": 1, "timestep": 1348, "ep_reward": 753.407958984375, "reward": 0.6297876834869385, "action": 1.546836256980896}
{"mode": "train", "epochs": 1, "timestep": 1349, "ep_reward": 754.1216430664062, "reward": 0.7136993408203125, "action": 1.4463789463043213}
{"mode": "train", "epochs": 1, "timestep": 1350, "ep_reward": 754.9000854492188, "reward": 0.7784549593925476, "action": 0.9158003330230713}
{"mode": "train", "epochs": 1, "timestep": 1351, "ep_reward": 755.7283935546875, "reward": 0.8282977938652039, "action": 1.4873713254928589}
{"mode": "train", "epochs": 1, "timestep": 1352, "ep_reward": 756.583984375, "reward": 0.8556010723114014, "action": 1.104755163192749}
{"mode": "train", "epochs": 1, "timestep": 1353, "ep_reward": 757.4540405273438, "reward": 0.8700680136680603, "action": 1.3127079010009766}
{"mode": "train", "epochs": 1, "timestep": 1354, "ep_reward": 758.3211059570312, "reward": 0.8670839071273804, "action": 0.5659335851669312}
{"mode": "train", "epochs": 1, "timestep": 1355, "ep_reward": 759.1746215820312, "reward": 0.8534941673278809, "action": 0.7197834849357605}
{"mode": "train", "epochs": 1, "timestep": 1356, "ep_reward": 759.9937133789062, "reward": 0.8191037178039551, "action": 1.5076992511749268}
{"mode": "train", "epochs": 1, "timestep": 1357, "ep_reward": 760.7457885742188, "reward": 0.7520898580551147, "action": 0.20816463232040405}
{"mode": "train", "epochs": 1, "timestep": 1358, "ep_reward": 761.413818359375, "reward": 0.66801917552948, "action": 1.7411717176437378}
{"mode": "train", "epochs": 1, "timestep": 1359, "ep_reward": 761.9409790039062, "reward": 0.5271810293197632, "action": 0.3861777186393738}
{"mode": "train", "epochs": 1, "timestep": 1360, "ep_reward": 762.3098754882812, "reward": 0.3689260482788086, "action": 1.0690783262252808}
{"mode": "train", "epochs": 1, "timestep": 1361, "ep_reward": 762.5726928710938, "reward": 0.26279783248901367, "action": 1.1024227142333984}
{"mode": "train", "epochs": 1, "timestep": 1362, "ep_reward": 762.7094116210938, "reward": 0.13671284914016724, "action": 0.7781874537467957}
{"mode": "train", "epochs": 1, "timestep": 1363, "ep_reward": 762.7000122070312, "reward": -0.009393095970153809, "action": 0.5844603776931763}
{"mode": "train", "epochs": 1, "timestep": 1364, "ep_reward": 762.8235473632812, "reward": 0.1235356330871582, "action": 1.4002989530563354}
{"mode": "train", "epochs": 1, "timestep": 1365, "ep_reward": 763.0809326171875, "reward": 0.2574119567871094, "action": 1.3691529035568237}
{"mode": "train", "epochs": 1, "timestep": 1366, "ep_reward": 763.4729614257812, "reward": 0.39205676317214966, "action": 0.670415997505188}
{"mode": "train", "epochs": 1, "timestep": 1367, "ep_reward": 763.9979858398438, "reward": 0.525004506111145, "action": 1.1987937688827515}
{"mode": "train", "epochs": 1, "timestep": 1368, "ep_reward": 764.6303100585938, "reward": 0.6323180198669434, "action": 0.7944759130477905}
{"mode": "train", "epochs": 1, "timestep": 1369, "ep_reward": 765.3517456054688, "reward": 0.7214325666427612, "action": 0.5533857345581055}
{"mode": "train", "epochs": 1, "timestep": 1370, "ep_reward": 766.1409912109375, "reward": 0.7892716526985168, "action": 1.363376498222351}
{"mode": "train", "epochs": 1, "timestep": 1371, "ep_reward": 766.9696655273438, "reward": 0.8286781311035156, "action": 1.0780836343765259}
{"mode": "train", "epochs": 1, "timestep": 1372, "ep_reward": 767.822021484375, "reward": 0.8523479700088501, "action": 1.1552960872650146}
{"mode": "train", "epochs": 1, "timestep": 1373, "ep_reward": 768.6800537109375, "reward": 0.8580527305603027, "action": 0.4191376566886902}
{"mode": "train", "epochs": 1, "timestep": 1374, "ep_reward": 769.5325927734375, "reward": 0.8525521755218506, "action": 0.8538312911987305}
{"mode": "train", "epochs": 1, "timestep": 1375, "ep_reward": 770.3563232421875, "reward": 0.8237446546554565, "action": 1.361863613128662}
{"mode": "train", "epochs": 1, "timestep": 1376, "ep_reward": 771.1220703125, "reward": 0.7657338380813599, "action": 1.2914377450942993}
{"mode": "train", "epochs": 1, "timestep": 1377, "ep_reward": 771.798828125, "reward": 0.6767595410346985, "action": 1.132111668586731}
{"mode": "train", "epochs": 1, "timestep": 1378, "ep_reward": 772.3496704101562, "reward": 0.5508140325546265, "action": 1.4855258464813232}
{"mode": "train", "epochs": 1, "timestep": 1379, "ep_reward": 772.7408447265625, "reward": 0.39114677906036377, "action": 0.9535884857177734}
{"mode": "train", "epochs": 1, "timestep": 1380, "ep_reward": 773.0306396484375, "reward": 0.2897781729698181, "action": 0.7866519689559937}
{"mode": "train", "epochs": 1, "timestep": 1381, "ep_reward": 773.1989135742188, "reward": 0.1682482361793518, "action": 1.7085351943969727}
{"mode": "train", "epochs": 1, "timestep": 1382, "ep_reward": 773.2258911132812, "reward": 0.026982665061950684, "action": 0.9997169971466064}
{"mode": "train", "epochs": 1, "timestep": 1383, "ep_reward": 773.316162109375, "reward": 0.09024643898010254, "action": 1.5867668390274048}
{"mode": "train", "epochs": 1, "timestep": 1384, "ep_reward": 773.5392456054688, "reward": 0.22310680150985718, "action": 1.0363836288452148}
{"mode": "train", "epochs": 1, "timestep": 1385, "ep_reward": 773.90234375, "reward": 0.3630848526954651, "action": 1.0404956340789795}
{"mode": "train", "epochs": 1, "timestep": 1386, "ep_reward": 774.3969116210938, "reward": 0.4945754408836365, "action": 1.0449126958847046}
{"mode": "train", "epochs": 1, "timestep": 1387, "ep_reward": 775.0057373046875, "reward": 0.6088122129440308, "action": 0.5020895004272461}
{"mode": "train", "epochs": 1, "timestep": 1388, "ep_reward": 775.7120361328125, "reward": 0.706273078918457, "action": 1.2716501951217651}
{"mode": "train", "epochs": 1, "timestep": 1389, "ep_reward": 776.484375, "reward": 0.7723348140716553, "action": 1.3287241458892822}
{"mode": "train", "epochs": 1, "timestep": 1390, "ep_reward": 777.301513671875, "reward": 0.8171476125717163, "action": 0.8166172504425049}
{"mode": "train", "epochs": 1, "timestep": 1391, "ep_reward": 778.1487426757812, "reward": 0.8472511768341064, "action": 1.8739441633224487}
{"mode": "train", "epochs": 1, "timestep": 1392, "ep_reward": 778.9992065429688, "reward": 0.8504502773284912, "action": 0.46657830476760864}
{"mode": "train", "epochs": 1, "timestep": 1393, "ep_reward": 779.8471069335938, "reward": 0.8478801250457764, "action": 0.6050304174423218}
{"mode": "train", "epochs": 1, "timestep": 1394, "ep_reward": 780.6714477539062, "reward": 0.8243505954742432, "action": 1.2434587478637695}
{"mode": "train", "epochs": 1, "timestep": 1395, "ep_reward": 781.4421997070312, "reward": 0.7707526683807373, "action": 1.5715231895446777}
{"mode": "train", "epochs": 1, "timestep": 1396, "ep_reward": 782.1242065429688, "reward": 0.682022213935852, "action": 1.6257569789886475}
{"mode": "train", "epochs": 1, "timestep": 1397, "ep_reward": 782.676513671875, "reward": 0.5523058176040649, "action": 0.6967043876647949}
{"mode": "train", "epochs": 1, "timestep": 1398, "ep_reward": 783.0762939453125, "reward": 0.39979124069213867, "action": 0.5554685592651367}
{"mode": "train", "epochs": 1, "timestep": 1399, "ep_reward": 783.3765869140625, "reward": 0.30030518770217896, "action": 0.5929247140884399}
{"mode": "train", "epochs": 1, "timestep": 1400, "ep_reward": 783.5574340820312, "reward": 0.1808171272277832, "action": 0.6611648797988892}
{"mode": "train", "epochs": 1, "timestep": 1401, "ep_reward": 783.5987548828125, "reward": 0.04130423069000244, "action": 0.963584303855896}
{"mode": "train", "epochs": 1, "timestep": 1402, "ep_reward": 783.67529296875, "reward": 0.07656776905059814, "action": 1.5885205268859863}
{"mode": "train", "epochs": 1, "timestep": 1403, "ep_reward": 783.8865966796875, "reward": 0.21131032705307007, "action": -1.190732479095459}
{"mode": "train", "epochs": 1, "timestep": 1404, "ep_reward": 784.2650146484375, "reward": 0.37839531898498535, "action": 0.1677687168121338}
{"mode": "train", "epochs": 1, "timestep": 1405, "ep_reward": 784.780029296875, "reward": 0.5149915218353271, "action": 1.1328346729278564}
{"mode": "train", "epochs": 1, "timestep": 1406, "ep_reward": 785.40380859375, "reward": 0.6237825155258179, "action": 0.3834254741668701}
{"mode": "train", "epochs": 1, "timestep": 1407, "ep_reward": 786.1240844726562, "reward": 0.7202520966529846, "action": 0.6703763008117676}
{"mode": "train", "epochs": 1, "timestep": 1408, "ep_reward": 786.9164428710938, "reward": 0.7923405766487122, "action": 0.6017194986343384}
{"mode": "train", "epochs": 1, "timestep": 1409, "ep_reward": 787.7623291015625, "reward": 0.8458558320999146, "action": 1.0944733619689941}
{"mode": "train", "epochs": 1, "timestep": 1410, "ep_reward": 788.6421508789062, "reward": 0.8798469305038452, "action": 1.259795069694519}
{"mode": "train", "epochs": 1, "timestep": 1411, "ep_reward": 789.5420532226562, "reward": 0.8999201059341431, "action": 1.6381714344024658}
{"mode": "train", "epochs": 1, "timestep": 1412, "ep_reward": 790.4484252929688, "reward": 0.9063490033149719, "action": 0.4473079442977905}
{"mode": "train", "epochs": 1, "timestep": 1413, "ep_reward": 791.3582153320312, "reward": 0.9097672700881958, "action": 1.483008861541748}
{"mode": "train", "epochs": 1, "timestep": 1414, "ep_reward": 792.252197265625, "reward": 0.8939886689186096, "action": 1.1725835800170898}
{"mode": "train", "epochs": 1, "timestep": 1415, "ep_reward": 793.1178588867188, "reward": 0.8656827807426453, "action": 0.7374560832977295}
{"mode": "train", "epochs": 1, "timestep": 1416, "ep_reward": 793.9403076171875, "reward": 0.8224195241928101, "action": 0.7386761903762817}
{"mode": "train", "epochs": 1, "timestep": 1417, "ep_reward": 794.6958618164062, "reward": 0.7555445432662964, "action": 1.3239012956619263}
{"mode": "train", "epochs": 1, "timestep": 1418, "ep_reward": 795.3472900390625, "reward": 0.6514387726783752, "action": 0.9447765350341797}
{"mode": "train", "epochs": 1, "timestep": 1419, "ep_reward": 795.8613891601562, "reward": 0.514100193977356, "action": 1.1545284986495972}
{"mode": "train", "epochs": 1, "timestep": 1420, "ep_reward": 796.2001953125, "reward": 0.3387945294380188, "action": 1.5034810304641724}
{"mode": "train", "epochs": 1, "timestep": 1421, "ep_reward": 796.4269409179688, "reward": 0.22673940658569336, "action": 0.3869258165359497}
{"mode": "train", "epochs": 1, "timestep": 1422, "ep_reward": 796.521484375, "reward": 0.0945553183555603, "action": 0.33706754446029663}
{"mode": "train", "epochs": 1, "timestep": 1423, "ep_reward": 796.5440673828125, "reward": 0.022599518299102783, "action": 0.5447705984115601}
{"mode": "train", "epochs": 1, "timestep": 1424, "ep_reward": 796.7085571289062, "reward": 0.1644958257675171, "action": 1.2103807926177979}
{"mode": "train", "epochs": 1, "timestep": 1425, "ep_reward": 797.01025390625, "reward": 0.30168288946151733, "action": 1.2642240524291992}
{"mode": "train", "epochs": 1, "timestep": 1426, "ep_reward": 797.4453125, "reward": 0.43505704402923584, "action": 1.0854378938674927}
{"mode": "train", "epochs": 1, "timestep": 1427, "ep_reward": 798.0029907226562, "reward": 0.557698667049408, "action": 0.8915948867797852}
{"mode": "train", "epochs": 1, "timestep": 1428, "ep_reward": 798.6650390625, "reward": 0.6620503664016724, "action": 1.1912297010421753}
{"mode": "train", "epochs": 1, "timestep": 1429, "ep_reward": 799.4051513671875, "reward": 0.7400949001312256, "action": 0.7427928447723389}
{"mode": "train", "epochs": 1, "timestep": 1430, "ep_reward": 800.2052612304688, "reward": 0.8001250624656677, "action": 0.4460257291793823}
{"mode": "train", "epochs": 1, "timestep": 1431, "ep_reward": 801.0472412109375, "reward": 0.8419663310050964, "action": 0.7775583267211914}
{"mode": "train", "epochs": 1, "timestep": 1432, "ep_reward": 801.909912109375, "reward": 0.8626969456672668, "action": 0.6988409161567688}
{"mode": "train", "epochs": 1, "timestep": 1433, "ep_reward": 802.7774047851562, "reward": 0.8674754500389099, "action": 1.1276220083236694}
{"mode": "train", "epochs": 1, "timestep": 1434, "ep_reward": 803.62890625, "reward": 0.8514973521232605, "action": 1.4175469875335693}
{"mode": "train", "epochs": 1, "timestep": 1435, "ep_reward": 804.4413452148438, "reward": 0.8124478459358215, "action": 1.598114013671875}
{"mode": "train", "epochs": 1, "timestep": 1436, "ep_reward": 805.186279296875, "reward": 0.7449053525924683, "action": 1.5412425994873047}
{"mode": "train", "epochs": 1, "timestep": 1437, "ep_reward": 805.8296508789062, "reward": 0.643352746963501, "action": 0.35305750370025635}
{"mode": "train", "epochs": 1, "timestep": 1438, "ep_reward": 806.3467407226562, "reward": 0.5171016454696655, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1439, "ep_reward": 806.7156982421875, "reward": 0.36898791790008545, "action": 0.48246461153030396}
{"mode": "train", "epochs": 1, "timestep": 1440, "ep_reward": 806.978515625, "reward": 0.26279377937316895, "action": 1.1736986637115479}
{"mode": "train", "epochs": 1, "timestep": 1441, "ep_reward": 807.1151123046875, "reward": 0.13661867380142212, "action": 1.4921327829360962}
{"mode": "train", "epochs": 1, "timestep": 1442, "ep_reward": 807.105712890625, "reward": -0.009370684623718262, "action": 0.3387305736541748}
{"mode": "train", "epochs": 1, "timestep": 1443, "ep_reward": 807.2293090820312, "reward": 0.12360721826553345, "action": 0.8359489440917969}
{"mode": "train", "epochs": 1, "timestep": 1444, "ep_reward": 807.4938354492188, "reward": 0.26453644037246704, "action": 1.1180188655853271}
{"mode": "train", "epochs": 1, "timestep": 1445, "ep_reward": 807.8946533203125, "reward": 0.40079623460769653, "action": 0.9997244477272034}
{"mode": "train", "epochs": 1, "timestep": 1446, "ep_reward": 808.4226684570312, "reward": 0.528038740158081, "action": 1.60313081741333}
{"mode": "train", "epochs": 1, "timestep": 1447, "ep_reward": 809.0531616210938, "reward": 0.6305121183395386, "action": 0.8747018575668335}
{"mode": "train", "epochs": 1, "timestep": 1448, "ep_reward": 809.7725830078125, "reward": 0.7194423079490662, "action": 0.4154497981071472}
{"mode": "train", "epochs": 1, "timestep": 1449, "ep_reward": 810.56201171875, "reward": 0.789456844329834, "action": 0.6085289716720581}
{"mode": "train", "epochs": 1, "timestep": 1450, "ep_reward": 811.3981323242188, "reward": 0.8361372351646423, "action": 0.8600268363952637}
{"mode": "train", "epochs": 1, "timestep": 1451, "ep_reward": 812.2606811523438, "reward": 0.8625200986862183, "action": 0.5799384713172913}
{"mode": "train", "epochs": 1, "timestep": 1452, "ep_reward": 813.1356201171875, "reward": 0.8749533891677856, "action": 1.5646202564239502}
{"mode": "train", "epochs": 1, "timestep": 1453, "ep_reward": 813.9989624023438, "reward": 0.8633191585540771, "action": 1.9159879684448242}
{"mode": "train", "epochs": 1, "timestep": 1454, "ep_reward": 814.8287353515625, "reward": 0.8297524452209473, "action": 1.2168811559677124}
{"mode": "train", "epochs": 1, "timestep": 1455, "ep_reward": 815.6074829101562, "reward": 0.7787336707115173, "action": 1.0399664640426636}
{"mode": "train", "epochs": 1, "timestep": 1456, "ep_reward": 816.3073120117188, "reward": 0.699849009513855, "action": 1.4045159816741943}
{"mode": "train", "epochs": 1, "timestep": 1457, "ep_reward": 816.886474609375, "reward": 0.5791921615600586, "action": 1.4702260494232178}
{"mode": "train", "epochs": 1, "timestep": 1458, "ep_reward": 817.2996215820312, "reward": 0.4131743907928467, "action": 1.142291784286499}
{"mode": "train", "epochs": 1, "timestep": 1459, "ep_reward": 817.6116333007812, "reward": 0.3120384216308594, "action": 0.7467865943908691}
{"mode": "train", "epochs": 1, "timestep": 1460, "ep_reward": 817.8062133789062, "reward": 0.1946071982383728, "action": 1.551513433456421}
{"mode": "train", "epochs": 1, "timestep": 1461, "ep_reward": 817.863525390625, "reward": 0.05732083320617676, "action": 1.395625114440918}
{"mode": "train", "epochs": 1, "timestep": 1462, "ep_reward": 817.9244384765625, "reward": 0.060884952545166016, "action": 0.8615262508392334}
{"mode": "train", "epochs": 1, "timestep": 1463, "ep_reward": 818.1240844726562, "reward": 0.19963842630386353, "action": 1.1872878074645996}
{"mode": "train", "epochs": 1, "timestep": 1464, "ep_reward": 818.4612426757812, "reward": 0.3371354937553406, "action": 1.6119877099990845}
{"mode": "train", "epochs": 1, "timestep": 1465, "ep_reward": 818.9251098632812, "reward": 0.46386563777923584, "action": 0.899761974811554}
{"mode": "train", "epochs": 1, "timestep": 1466, "ep_reward": 819.509765625, "reward": 0.5846719741821289, "action": 0.6911070942878723}
{"mode": "train", "epochs": 1, "timestep": 1467, "ep_reward": 820.1953125, "reward": 0.6855303645133972, "action": 0.5445236563682556}
{"mode": "train", "epochs": 1, "timestep": 1468, "ep_reward": 820.958984375, "reward": 0.7636575698852539, "action": -0.28155672550201416}
{"mode": "train", "epochs": 1, "timestep": 1469, "ep_reward": 821.7852783203125, "reward": 0.826288104057312, "action": 0.4213207960128784}
{"mode": "train", "epochs": 1, "timestep": 1470, "ep_reward": 822.6478881835938, "reward": 0.8625878691673279, "action": 1.0139275789260864}
{"mode": "train", "epochs": 1, "timestep": 1471, "ep_reward": 823.5260009765625, "reward": 0.8781092762947083, "action": 0.6317600011825562}
{"mode": "train", "epochs": 1, "timestep": 1472, "ep_reward": 824.4080200195312, "reward": 0.881999671459198, "action": 0.7480797171592712}
{"mode": "train", "epochs": 1, "timestep": 1473, "ep_reward": 825.2778930664062, "reward": 0.8698908090591431, "action": 0.7493284344673157}
{"mode": "train", "epochs": 1, "timestep": 1474, "ep_reward": 826.1182861328125, "reward": 0.8404139280319214, "action": 1.4477757215499878}
{"mode": "train", "epochs": 1, "timestep": 1475, "ep_reward": 826.9005737304688, "reward": 0.7822683453559875, "action": 0.8323773741722107}
{"mode": "train", "epochs": 1, "timestep": 1476, "ep_reward": 827.6019897460938, "reward": 0.7014063596725464, "action": 0.41052621603012085}
{"mode": "train", "epochs": 1, "timestep": 1477, "ep_reward": 828.1934814453125, "reward": 0.5914644002914429, "action": 1.4503488540649414}
{"mode": "train", "epochs": 1, "timestep": 1478, "ep_reward": 828.6214599609375, "reward": 0.42797935009002686, "action": -0.45004260540008545}
{"mode": "train", "epochs": 1, "timestep": 1479, "ep_reward": 828.9201049804688, "reward": 0.2986631989479065, "action": 0.9423625469207764}
{"mode": "train", "epochs": 1, "timestep": 1480, "ep_reward": 829.0989990234375, "reward": 0.17888480424880981, "action": 0.9604226350784302}
{"mode": "train", "epochs": 1, "timestep": 1481, "ep_reward": 829.1381225585938, "reward": 0.039125263690948486, "action": 0.8155754208564758}
{"mode": "train", "epochs": 1, "timestep": 1482, "ep_reward": 829.2168579101562, "reward": 0.07871907949447632, "action": 1.4250117540359497}
{"mode": "train", "epochs": 1, "timestep": 1483, "ep_reward": 829.4299926757812, "reward": 0.21316051483154297, "action": 1.0244518518447876}
{"mode": "train", "epochs": 1, "timestep": 1484, "ep_reward": 829.7831420898438, "reward": 0.3531467914581299, "action": 1.7020351886749268}
{"mode": "train", "epochs": 1, "timestep": 1485, "ep_reward": 830.2607421875, "reward": 0.4776015281677246, "action": 1.130825161933899}
{"mode": "train", "epochs": 1, "timestep": 1486, "ep_reward": 830.8544921875, "reward": 0.5937678813934326, "action": -0.12836134433746338}
{"mode": "train", "epochs": 1, "timestep": 1487, "ep_reward": 831.5551147460938, "reward": 0.7006498575210571, "action": 1.4592986106872559}
{"mode": "train", "epochs": 1, "timestep": 1488, "ep_reward": 832.321533203125, "reward": 0.7664390802383423, "action": 0.18112629652023315}
{"mode": "train", "epochs": 1, "timestep": 1489, "ep_reward": 833.144287109375, "reward": 0.8227674961090088, "action": 0.9743298292160034}
{"mode": "train", "epochs": 1, "timestep": 1490, "ep_reward": 833.9965209960938, "reward": 0.8522620797157288, "action": 0.8626588582992554}
{"mode": "train", "epochs": 1, "timestep": 1491, "ep_reward": 834.8619995117188, "reward": 0.8654734492301941, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1492, "ep_reward": 835.7141723632812, "reward": 0.8522020578384399, "action": 1.1446970701217651}
{"mode": "train", "epochs": 1, "timestep": 1493, "ep_reward": 836.5409545898438, "reward": 0.8267682790756226, "action": 1.4259506464004517}
{"mode": "train", "epochs": 1, "timestep": 1494, "ep_reward": 837.315673828125, "reward": 0.7746891379356384, "action": 0.8559461832046509}
{"mode": "train", "epochs": 1, "timestep": 1495, "ep_reward": 838.01416015625, "reward": 0.6984931230545044, "action": 1.5826040506362915}
{"mode": "train", "epochs": 1, "timestep": 1496, "ep_reward": 838.5900268554688, "reward": 0.5758857727050781, "action": 0.887848973274231}
{"mode": "train", "epochs": 1, "timestep": 1497, "ep_reward": 839.0088500976562, "reward": 0.41882818937301636, "action": 1.4768930673599243}
{"mode": "train", "epochs": 1, "timestep": 1498, "ep_reward": 839.3245239257812, "reward": 0.3156517744064331, "action": 1.4170207977294922}
{"mode": "train", "epochs": 1, "timestep": 1499, "ep_reward": 839.5235595703125, "reward": 0.1990618109703064, "action": 1.215001106262207}
{"mode": "train", "epochs": 1, "timestep": 1500, "ep_reward": 839.5859375, "reward": 0.06235802173614502, "action": 1.6659153699874878}
{"mode": "train", "epochs": 1, "timestep": 1501, "ep_reward": 839.6417236328125, "reward": 0.05577051639556885, "action": 1.014741063117981}
{"mode": "train", "epochs": 1, "timestep": 1502, "ep_reward": 839.8350219726562, "reward": 0.19329941272735596, "action": 1.0478863716125488}
{"mode": "train", "epochs": 1, "timestep": 1503, "ep_reward": 840.1680297851562, "reward": 0.33301472663879395, "action": 0.4481741786003113}
{"mode": "train", "epochs": 1, "timestep": 1504, "ep_reward": 840.641845703125, "reward": 0.47382068634033203, "action": 0.8361933827400208}
{"mode": "train", "epochs": 1, "timestep": 1505, "ep_reward": 841.2349853515625, "reward": 0.5931674242019653, "action": 1.4040688276290894}
{"mode": "train", "epochs": 1, "timestep": 1506, "ep_reward": 841.9203491210938, "reward": 0.6853681802749634, "action": 1.9871633052825928}
{"mode": "train", "epochs": 1, "timestep": 1507, "ep_reward": 842.6710205078125, "reward": 0.7506788372993469, "action": 1.5336111783981323}
{"mode": "train", "epochs": 1, "timestep": 1508, "ep_reward": 843.4710693359375, "reward": 0.8000788688659668, "action": 0.5444839000701904}
{"mode": "train", "epochs": 1, "timestep": 1509, "ep_reward": 844.3095092773438, "reward": 0.8384101390838623, "action": 1.1565748453140259}
{"mode": "train", "epochs": 1, "timestep": 1510, "ep_reward": 845.1620483398438, "reward": 0.8525159955024719, "action": 1.398341417312622}
{"mode": "train", "epochs": 1, "timestep": 1511, "ep_reward": 846.0084838867188, "reward": 0.846441388130188, "action": 0.9097861647605896}
{"mode": "train", "epochs": 1, "timestep": 1512, "ep_reward": 846.8333740234375, "reward": 0.824899435043335, "action": 0.8553547859191895}
{"mode": "train", "epochs": 1, "timestep": 1513, "ep_reward": 847.614013671875, "reward": 0.7806118130683899, "action": 0.2695445418357849}
{"mode": "train", "epochs": 1, "timestep": 1514, "ep_reward": 848.3287353515625, "reward": 0.7146931886672974, "action": 0.623368501663208}
{"mode": "train", "epochs": 1, "timestep": 1515, "ep_reward": 848.9397583007812, "reward": 0.6110020875930786, "action": 1.8858330249786377}
{"mode": "train", "epochs": 1, "timestep": 1516, "ep_reward": 849.38818359375, "reward": 0.4484167695045471, "action": 0.638155460357666}
{"mode": "train", "epochs": 1, "timestep": 1517, "ep_reward": 849.7191162109375, "reward": 0.3309260606765747, "action": 0.8499932289123535}
{"mode": "train", "epochs": 1, "timestep": 1518, "ep_reward": 849.9363403320312, "reward": 0.2172371745109558, "action": 0.03644317388534546}
{"mode": "train", "epochs": 1, "timestep": 1519, "ep_reward": 850.019775390625, "reward": 0.08342605829238892, "action": 1.1146924495697021}
{"mode": "train", "epochs": 1, "timestep": 1520, "ep_reward": 850.0540161132812, "reward": 0.03425562381744385, "action": 0.9646539092063904}
{"mode": "train", "epochs": 1, "timestep": 1521, "ep_reward": 850.2285766601562, "reward": 0.17456263303756714, "action": 1.6655921936035156}
{"mode": "train", "epochs": 1, "timestep": 1522, "ep_reward": 850.5348510742188, "reward": 0.30629026889801025, "action": 1.1210321187973022}
{"mode": "train", "epochs": 1, "timestep": 1523, "ep_reward": 850.9766845703125, "reward": 0.4418315887451172, "action": 1.4628231525421143}
{"mode": "train", "epochs": 1, "timestep": 1524, "ep_reward": 851.5361328125, "reward": 0.5594460964202881, "action": 0.9913581609725952}
{"mode": "train", "epochs": 1, "timestep": 1525, "ep_reward": 852.1983032226562, "reward": 0.6621744632720947, "action": 0.3735774755477905}
{"mode": "train", "epochs": 1, "timestep": 1526, "ep_reward": 852.9453125, "reward": 0.7470028400421143, "action": 0.8973681330680847}
{"mode": "train", "epochs": 1, "timestep": 1527, "ep_reward": 853.7481689453125, "reward": 0.8028479814529419, "action": 1.0288197994232178}
{"mode": "train", "epochs": 1, "timestep": 1528, "ep_reward": 854.585205078125, "reward": 0.8370571136474609, "action": 0.9164294004440308}
{"mode": "train", "epochs": 1, "timestep": 1529, "ep_reward": 855.4389038085938, "reward": 0.8536884784698486, "action": 1.618398666381836}
{"mode": "train", "epochs": 1, "timestep": 1530, "ep_reward": 856.2850952148438, "reward": 0.8462035059928894, "action": 0.5806040167808533}
{"mode": "train", "epochs": 1, "timestep": 1531, "ep_reward": 857.113525390625, "reward": 0.8284598588943481, "action": 0.4465240240097046}
{"mode": "train", "epochs": 1, "timestep": 1532, "ep_reward": 857.9032592773438, "reward": 0.789753794670105, "action": 0.7682924270629883}
{"mode": "train", "epochs": 1, "timestep": 1533, "ep_reward": 858.623779296875, "reward": 0.720538318157196, "action": 0.22865837812423706}
{"mode": "train", "epochs": 1, "timestep": 1534, "ep_reward": 859.2484741210938, "reward": 0.6247103214263916, "action": 0.49941080808639526}
{"mode": "train", "epochs": 1, "timestep": 1535, "ep_reward": 859.7363891601562, "reward": 0.4879056215286255, "action": 1.1814398765563965}
{"mode": "train", "epochs": 1, "timestep": 1536, "ep_reward": 860.077392578125, "reward": 0.34102940559387207, "action": 1.4725978374481201}
{"mode": "train", "epochs": 1, "timestep": 1537, "ep_reward": 860.306640625, "reward": 0.22926205396652222, "action": 1.5646040439605713}
{"mode": "train", "epochs": 1, "timestep": 1538, "ep_reward": 860.4041748046875, "reward": 0.09755730628967285, "action": 1.318025827407837}
{"mode": "train", "epochs": 1, "timestep": 1539, "ep_reward": 860.4234619140625, "reward": 0.019266068935394287, "action": 0.6321847438812256}
{"mode": "train", "epochs": 1, "timestep": 1540, "ep_reward": 860.5850830078125, "reward": 0.1616426706314087, "action": 0.9377720952033997}
{"mode": "train", "epochs": 1, "timestep": 1541, "ep_reward": 860.88720703125, "reward": 0.30210375785827637, "action": 1.5603350400924683}
{"mode": "train", "epochs": 1, "timestep": 1542, "ep_reward": 861.3186645507812, "reward": 0.43143385648727417, "action": 1.0717488527297974}
{"mode": "train", "epochs": 1, "timestep": 1543, "ep_reward": 861.873291015625, "reward": 0.5546517372131348, "action": 1.3203394412994385}
{"mode": "train", "epochs": 1, "timestep": 1544, "ep_reward": 862.5283813476562, "reward": 0.6551117300987244, "action": 0.9771372079849243}
{"mode": "train", "epochs": 1, "timestep": 1545, "ep_reward": 863.2647094726562, "reward": 0.7363119125366211, "action": 1.9426720142364502}
{"mode": "train", "epochs": 1, "timestep": 1546, "ep_reward": 864.050537109375, "reward": 0.7858390212059021, "action": 0.5520222187042236}
{"mode": "train", "epochs": 1, "timestep": 1547, "ep_reward": 864.8783569335938, "reward": 0.8277940154075623, "action": 1.3519492149353027}
{"mode": "train", "epochs": 1, "timestep": 1548, "ep_reward": 865.7210083007812, "reward": 0.8426632285118103, "action": 1.5228605270385742}
{"mode": "train", "epochs": 1, "timestep": 1549, "ep_reward": 866.557861328125, "reward": 0.8368712663650513, "action": 1.2111618518829346}
{"mode": "train", "epochs": 1, "timestep": 1550, "ep_reward": 867.37060546875, "reward": 0.8127384185791016, "action": 0.9016621708869934}
{"mode": "train", "epochs": 1, "timestep": 1551, "ep_reward": 868.1372680664062, "reward": 0.7666738629341125, "action": 0.9030836820602417}
{"mode": "train", "epochs": 1, "timestep": 1552, "ep_reward": 868.8273315429688, "reward": 0.6900707483291626, "action": 0.6370046138763428}
{"mode": "train", "epochs": 1, "timestep": 1553, "ep_reward": 869.4072265625, "reward": 0.5799226760864258, "action": 0.5548151135444641}
{"mode": "train", "epochs": 1, "timestep": 1554, "ep_reward": 869.8370361328125, "reward": 0.42978864908218384, "action": 1.0885767936706543}
{"mode": "train", "epochs": 1, "timestep": 1555, "ep_reward": 870.1578369140625, "reward": 0.3208041787147522, "action": 0.6773648262023926}
{"mode": "train", "epochs": 1, "timestep": 1556, "ep_reward": 870.3629760742188, "reward": 0.20514601469039917, "action": 0.5091349482536316}
{"mode": "train", "epochs": 1, "timestep": 1557, "ep_reward": 870.432373046875, "reward": 0.06937301158905029, "action": 1.3809045553207397}
{"mode": "train", "epochs": 1, "timestep": 1558, "ep_reward": 870.4811401367188, "reward": 0.04876071214675903, "action": 0.6289331912994385}
{"mode": "train", "epochs": 1, "timestep": 1559, "ep_reward": 870.6712036132812, "reward": 0.19005107879638672, "action": 1.0142358541488647}
{"mode": "train", "epochs": 1, "timestep": 1560, "ep_reward": 871.000732421875, "reward": 0.3295356035232544, "action": 0.4883778691291809}
{"mode": "train", "epochs": 1, "timestep": 1561, "ep_reward": 871.4703369140625, "reward": 0.46962934732437134, "action": 1.0446723699569702}
{"mode": "train", "epochs": 1, "timestep": 1562, "ep_reward": 872.0576171875, "reward": 0.5872703790664673, "action": 0.5923515558242798}
{"mode": "train", "epochs": 1, "timestep": 1563, "ep_reward": 872.7466430664062, "reward": 0.6890234351158142, "action": 1.0809780359268188}
{"mode": "train", "epochs": 1, "timestep": 1564, "ep_reward": 873.5096435546875, "reward": 0.7629832029342651, "action": 1.7396175861358643}
{"mode": "train", "epochs": 1, "timestep": 1565, "ep_reward": 874.3204956054688, "reward": 0.810844898223877, "action": 0.2536884546279907}
{"mode": "train", "epochs": 1, "timestep": 1566, "ep_reward": 875.173583984375, "reward": 0.8530756235122681, "action": 1.5147262811660767}
{"mode": "train", "epochs": 1, "timestep": 1567, "ep_reward": 876.0415649414062, "reward": 0.8679948449134827, "action": 0.6970571279525757}
{"mode": "train", "epochs": 1, "timestep": 1568, "ep_reward": 876.9156494140625, "reward": 0.8740777373313904, "action": 0.9626702070236206}
{"mode": "train", "epochs": 1, "timestep": 1569, "ep_reward": 877.7774658203125, "reward": 0.8618269562721252, "action": 1.4959996938705444}
{"mode": "train", "epochs": 1, "timestep": 1570, "ep_reward": 878.6033325195312, "reward": 0.8258765935897827, "action": 1.8422191143035889}
{"mode": "train", "epochs": 1, "timestep": 1571, "ep_reward": 879.3646850585938, "reward": 0.7613450884819031, "action": 1.0735794305801392}
{"mode": "train", "epochs": 1, "timestep": 1572, "ep_reward": 880.0374145507812, "reward": 0.6727169156074524, "action": 0.25907355546951294}
{"mode": "train", "epochs": 1, "timestep": 1573, "ep_reward": 880.5948486328125, "reward": 0.5574331283569336, "action": 1.3796467781066895}
{"mode": "train", "epochs": 1, "timestep": 1574, "ep_reward": 880.9817504882812, "reward": 0.38691240549087524, "action": 0.6329044103622437}
{"mode": "train", "epochs": 1, "timestep": 1575, "ep_reward": 881.2662963867188, "reward": 0.28457218408584595, "action": 0.8900433778762817}
{"mode": "train", "epochs": 1, "timestep": 1576, "ep_reward": 881.4285888671875, "reward": 0.16230660676956177, "action": 0.024855315685272217}
{"mode": "train", "epochs": 1, "timestep": 1577, "ep_reward": 881.4484252929688, "reward": 0.019860267639160156, "action": 1.4529500007629395}
{"mode": "train", "epochs": 1, "timestep": 1578, "ep_reward": 881.54541015625, "reward": 0.09700101613998413, "action": 0.4462093114852905}
{"mode": "train", "epochs": 1, "timestep": 1579, "ep_reward": 881.7872924804688, "reward": 0.2418978214263916, "action": 1.7836096286773682}
{"mode": "train", "epochs": 1, "timestep": 1580, "ep_reward": 882.1573486328125, "reward": 0.37005507946014404, "action": 1.6879808902740479}
{"mode": "train", "epochs": 1, "timestep": 1581, "ep_reward": 882.6502685546875, "reward": 0.49294495582580566, "action": 1.1885221004486084}
{"mode": "train", "epochs": 1, "timestep": 1582, "ep_reward": 883.2562255859375, "reward": 0.605939507484436, "action": -0.18548643589019775}
{"mode": "train", "epochs": 1, "timestep": 1583, "ep_reward": 883.9669799804688, "reward": 0.7107489705085754, "action": 0.5366692543029785}
{"mode": "train", "epochs": 1, "timestep": 1584, "ep_reward": 884.7494506835938, "reward": 0.782447338104248, "action": 1.6428275108337402}
{"mode": "train", "epochs": 1, "timestep": 1585, "ep_reward": 885.5724487304688, "reward": 0.8229998350143433, "action": 1.785266399383545}
{"mode": "train", "epochs": 1, "timestep": 1586, "ep_reward": 886.4169921875, "reward": 0.8445420265197754, "action": 0.30532604455947876}
{"mode": "train", "epochs": 1, "timestep": 1587, "ep_reward": 887.2783813476562, "reward": 0.8613879680633545, "action": 1.1140358448028564}
{"mode": "train", "epochs": 1, "timestep": 1588, "ep_reward": 888.1321411132812, "reward": 0.8537792563438416, "action": 0.7279585599899292}
{"mode": "train", "epochs": 1, "timestep": 1589, "ep_reward": 888.9627685546875, "reward": 0.8306089043617249, "action": 0.36662083864212036}
{"mode": "train", "epochs": 1, "timestep": 1590, "ep_reward": 889.7516479492188, "reward": 0.7888628244400024, "action": 0.677962601184845}
{"mode": "train", "epochs": 1, "timestep": 1591, "ep_reward": 890.468505859375, "reward": 0.7168750762939453, "action": 1.2447340488433838}
{"mode": "train", "epochs": 1, "timestep": 1592, "ep_reward": 891.072021484375, "reward": 0.6035316586494446, "action": 1.0737788677215576}
{"mode": "train", "epochs": 1, "timestep": 1593, "ep_reward": 891.5228881835938, "reward": 0.4508916735649109, "action": 0.9085373282432556}
{"mode": "train", "epochs": 1, "timestep": 1594, "ep_reward": 891.8461303710938, "reward": 0.32323265075683594, "action": 0.843195378780365}
{"mode": "train", "epochs": 1, "timestep": 1595, "ep_reward": 892.0541381835938, "reward": 0.20799541473388672, "action": 1.0935018062591553}
{"mode": "train", "epochs": 1, "timestep": 1596, "ep_reward": 892.1268920898438, "reward": 0.07276678085327148, "action": 1.245373010635376}
{"mode": "train", "epochs": 1, "timestep": 1597, "ep_reward": 892.1721801757812, "reward": 0.04526376724243164, "action": 1.0893025398254395}
{"mode": "train", "epochs": 1, "timestep": 1598, "ep_reward": 892.3564453125, "reward": 0.18426668643951416, "action": 0.5730074644088745}
{"mode": "train", "epochs": 1, "timestep": 1599, "ep_reward": 892.68603515625, "reward": 0.3296002745628357, "action": 1.4916220903396606}
{"mode": "train", "epochs": 1, "timestep": 1600, "ep_reward": 893.1435546875, "reward": 0.4575396180152893, "action": 1.107706069946289}
{"mode": "train", "epochs": 1, "timestep": 1601, "ep_reward": 893.7200927734375, "reward": 0.5765522718429565, "action": 1.3227568864822388}
{"mode": "train", "epochs": 1, "timestep": 1602, "ep_reward": 894.392822265625, "reward": 0.6727010011672974, "action": 1.517892837524414}
{"mode": "train", "epochs": 1, "timestep": 1603, "ep_reward": 895.1375732421875, "reward": 0.7447216510772705, "action": 1.2412503957748413}
{"mode": "train", "epochs": 1, "timestep": 1604, "ep_reward": 895.935302734375, "reward": 0.7977473139762878, "action": 1.2666699886322021}
{"mode": "train", "epochs": 1, "timestep": 1605, "ep_reward": 896.7654418945312, "reward": 0.8301607370376587, "action": 0.777121901512146}
{"mode": "train", "epochs": 1, "timestep": 1606, "ep_reward": 897.6134033203125, "reward": 0.8479317426681519, "action": 0.18783217668533325}
{"mode": "train", "epochs": 1, "timestep": 1607, "ep_reward": 898.4656372070312, "reward": 0.8522499799728394, "action": 1.9046680927276611}
{"mode": "train", "epochs": 1, "timestep": 1608, "ep_reward": 899.2870483398438, "reward": 0.8213843703269958, "action": -0.1369410753250122}
{"mode": "train", "epochs": 1, "timestep": 1609, "ep_reward": 900.0741577148438, "reward": 0.7871324419975281, "action": 0.6716388463973999}
{"mode": "train", "epochs": 1, "timestep": 1610, "ep_reward": 900.7916259765625, "reward": 0.7174741625785828, "action": 1.3797974586486816}
{"mode": "train", "epochs": 1, "timestep": 1611, "ep_reward": 901.39599609375, "reward": 0.6043437719345093, "action": 0.46884721517562866}
{"mode": "train", "epochs": 1, "timestep": 1612, "ep_reward": 901.8583984375, "reward": 0.4624049663543701, "action": 0.7128546833992004}
{"mode": "train", "epochs": 1, "timestep": 1613, "ep_reward": 902.1907348632812, "reward": 0.3323274850845337, "action": 0.43971312046051025}
{"mode": "train", "epochs": 1, "timestep": 1614, "ep_reward": 902.4095458984375, "reward": 0.21882963180541992, "action": 0.8004419207572937}
{"mode": "train", "epochs": 1, "timestep": 1615, "ep_reward": 902.4949340820312, "reward": 0.08537203073501587, "action": 0.673288106918335}
{"mode": "train", "epochs": 1, "timestep": 1616, "ep_reward": 902.5272216796875, "reward": 0.032282114028930664, "action": 0.8319937586784363}
{"mode": "train", "epochs": 1, "timestep": 1617, "ep_reward": 902.7000732421875, "reward": 0.1728513240814209, "action": 1.601933240890503}
{"mode": "train", "epochs": 1, "timestep": 1618, "ep_reward": 903.0054931640625, "reward": 0.30542248487472534, "action": -0.023954272270202637}
{"mode": "train", "epochs": 1, "timestep": 1619, "ep_reward": 903.4602661132812, "reward": 0.45475566387176514, "action": 0.1171950101852417}
{"mode": "train", "epochs": 1, "timestep": 1620, "ep_reward": 904.0450439453125, "reward": 0.5847525596618652, "action": 1.0263011455535889}
{"mode": "train", "epochs": 1, "timestep": 1621, "ep_reward": 904.7278442382812, "reward": 0.6827948689460754, "action": 1.2064521312713623}
{"mode": "train", "epochs": 1, "timestep": 1622, "ep_reward": 905.4854125976562, "reward": 0.757558286190033, "action": 0.9948105216026306}
{"mode": "train", "epochs": 1, "timestep": 1623, "ep_reward": 906.2991943359375, "reward": 0.813764750957489, "action": 1.047736406326294}
{"mode": "train", "epochs": 1, "timestep": 1624, "ep_reward": 907.1502075195312, "reward": 0.8510321378707886, "action": 0.39873164892196655}
{"mode": "train", "epochs": 1, "timestep": 1625, "ep_reward": 908.0272827148438, "reward": 0.877070963382721, "action": 1.2600423097610474}
{"mode": "train", "epochs": 1, "timestep": 1626, "ep_reward": 908.9085693359375, "reward": 0.8813105821609497, "action": 1.9550161361694336}
{"mode": "train", "epochs": 1, "timestep": 1627, "ep_reward": 909.7734375, "reward": 0.8648462295532227, "action": 0.5834989547729492}
{"mode": "train", "epochs": 1, "timestep": 1628, "ep_reward": 910.615478515625, "reward": 0.842035174369812, "action": 1.2217775583267212}
{"mode": "train", "epochs": 1, "timestep": 1629, "ep_reward": 911.4072875976562, "reward": 0.7918123006820679, "action": 0.9941176772117615}
{"mode": "train", "epochs": 1, "timestep": 1630, "ep_reward": 912.1231079101562, "reward": 0.7158505916595459, "action": 0.7785893082618713}
{"mode": "train", "epochs": 1, "timestep": 1631, "ep_reward": 912.7311401367188, "reward": 0.6080217361450195, "action": 1.1529505252838135}
{"mode": "train", "epochs": 1, "timestep": 1632, "ep_reward": 913.1862182617188, "reward": 0.45510005950927734, "action": 0.7526012659072876}
{"mode": "train", "epochs": 1, "timestep": 1633, "ep_reward": 913.5076904296875, "reward": 0.3214881420135498, "action": 1.8076679706573486}
{"mode": "train", "epochs": 1, "timestep": 1634, "ep_reward": 913.7138061523438, "reward": 0.2061011791229248, "action": 1.154610276222229}
{"mode": "train", "epochs": 1, "timestep": 1635, "ep_reward": 913.784423828125, "reward": 0.07063347101211548, "action": 0.8373706936836243}
{"mode": "train", "epochs": 1, "timestep": 1636, "ep_reward": 913.8319702148438, "reward": 0.04751819372177124, "action": 0.9632039070129395}
{"mode": "train", "epochs": 1, "timestep": 1637, "ep_reward": 914.0181274414062, "reward": 0.18616962432861328, "action": 0.9379447102546692}
{"mode": "train", "epochs": 1, "timestep": 1638, "ep_reward": 914.3450317382812, "reward": 0.3269209861755371, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1639, "ep_reward": 914.7946166992188, "reward": 0.44955676794052124, "action": 0.8811083436012268}
{"mode": "train", "epochs": 1, "timestep": 1640, "ep_reward": 915.3673706054688, "reward": 0.5727735757827759, "action": 1.0045047998428345}
{"mode": "train", "epochs": 1, "timestep": 1641, "ep_reward": 916.0401611328125, "reward": 0.6727713346481323, "action": 0.7493619918823242}
{"mode": "train", "epochs": 1, "timestep": 1642, "ep_reward": 916.7916870117188, "reward": 0.7515031099319458, "action": 1.6605520248413086}
{"mode": "train", "epochs": 1, "timestep": 1643, "ep_reward": 917.590576171875, "reward": 0.798913836479187, "action": 1.584250569343567}
{"mode": "train", "epochs": 1, "timestep": 1644, "ep_reward": 918.417724609375, "reward": 0.8271439671516418, "action": 1.4311442375183105}
{"mode": "train", "epochs": 1, "timestep": 1645, "ep_reward": 919.2551879882812, "reward": 0.8374567627906799, "action": 0.98638916015625}
{"mode": "train", "epochs": 1, "timestep": 1646, "ep_reward": 920.087158203125, "reward": 0.8319544196128845, "action": 0.9379916191101074}
{"mode": "train", "epochs": 1, "timestep": 1647, "ep_reward": 920.8920288085938, "reward": 0.804878830909729, "action": 1.7755074501037598}
{"mode": "train", "epochs": 1, "timestep": 1648, "ep_reward": 921.634033203125, "reward": 0.741999626159668, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1649, "ep_reward": 922.2742919921875, "reward": 0.6402297019958496, "action": 1.0807902812957764}
{"mode": "train", "epochs": 1, "timestep": 1650, "ep_reward": 922.7809448242188, "reward": 0.5066384077072144, "action": 1.1486177444458008}
{"mode": "train", "epochs": 1, "timestep": 1651, "ep_reward": 923.16748046875, "reward": 0.3865392804145813, "action": 1.0720030069351196}
{"mode": "train", "epochs": 1, "timestep": 1652, "ep_reward": 923.45166015625, "reward": 0.2841886878013611, "action": 0.759479284286499}
{"mode": "train", "epochs": 1, "timestep": 1653, "ep_reward": 923.613525390625, "reward": 0.16183525323867798, "action": 0.24501848220825195}
{"mode": "train", "epochs": 1, "timestep": 1654, "ep_reward": 923.6329345703125, "reward": 0.019405782222747803, "action": 0.8770965337753296}
{"mode": "train", "epochs": 1, "timestep": 1655, "ep_reward": 923.7304077148438, "reward": 0.0974799394607544, "action": 0.7438801527023315}
{"mode": "train", "epochs": 1, "timestep": 1656, "ep_reward": 923.9690551757812, "reward": 0.23867249488830566, "action": 1.9478342533111572}
{"mode": "train", "epochs": 1, "timestep": 1657, "ep_reward": 924.3346557617188, "reward": 0.3655819296836853, "action": 1.2009397745132446}
{"mode": "train", "epochs": 1, "timestep": 1658, "ep_reward": 924.8297729492188, "reward": 0.495097279548645, "action": 1.5161205530166626}
{"mode": "train", "epochs": 1, "timestep": 1659, "ep_reward": 925.4338989257812, "reward": 0.6041011810302734, "action": 0.1413525938987732}
{"mode": "train", "epochs": 1, "timestep": 1660, "ep_reward": 926.1396484375, "reward": 0.7057522535324097, "action": 1.2047473192214966}
{"mode": "train", "epochs": 1, "timestep": 1661, "ep_reward": 926.911376953125, "reward": 0.7717229127883911, "action": 0.1632724404335022}
{"mode": "train", "epochs": 1, "timestep": 1662, "ep_reward": 927.7369995117188, "reward": 0.8256388902664185, "action": 0.7592446208000183}
{"mode": "train", "epochs": 1, "timestep": 1663, "ep_reward": 928.5914306640625, "reward": 0.8544104099273682, "action": 0.7096025943756104}
{"mode": "train", "epochs": 1, "timestep": 1664, "ep_reward": 929.457763671875, "reward": 0.8663305044174194, "action": 1.6556522846221924}
{"mode": "train", "epochs": 1, "timestep": 1665, "ep_reward": 930.31103515625, "reward": 0.8532904386520386, "action": 1.2277815341949463}
{"mode": "train", "epochs": 1, "timestep": 1666, "ep_reward": 931.1354370117188, "reward": 0.8244010210037231, "action": -0.09401845932006836}
{"mode": "train", "epochs": 1, "timestep": 1667, "ep_reward": 931.9210205078125, "reward": 0.7856022119522095, "action": 1.4598615169525146}
{"mode": "train", "epochs": 1, "timestep": 1668, "ep_reward": 932.62353515625, "reward": 0.702491044998169, "action": 0.583057701587677}
{"mode": "train", "epochs": 1, "timestep": 1669, "ep_reward": 933.21728515625, "reward": 0.59377121925354, "action": 0.7208036184310913}
{"mode": "train", "epochs": 1, "timestep": 1670, "ep_reward": 933.6609497070312, "reward": 0.44365108013153076, "action": 0.40706026554107666}
{"mode": "train", "epochs": 1, "timestep": 1671, "ep_reward": 933.9769897460938, "reward": 0.31602030992507935, "action": 0.9484531283378601}
{"mode": "train", "epochs": 1, "timestep": 1672, "ep_reward": 934.17626953125, "reward": 0.19925951957702637, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1673, "ep_reward": 934.2391357421875, "reward": 0.062885582447052, "action": 0.9592369198799133}
{"mode": "train", "epochs": 1, "timestep": 1674, "ep_reward": 934.29443359375, "reward": 0.05531531572341919, "action": 1.2983042001724243}
{"mode": "train", "epochs": 1, "timestep": 1675, "ep_reward": 934.4873657226562, "reward": 0.19292616844177246, "action": 1.1575136184692383}
{"mode": "train", "epochs": 1, "timestep": 1676, "ep_reward": 934.8184814453125, "reward": 0.3311045169830322, "action": 1.7431254386901855}
{"mode": "train", "epochs": 1, "timestep": 1677, "ep_reward": 935.275390625, "reward": 0.456906259059906, "action": 0.3067336678504944}
{"mode": "train", "epochs": 1, "timestep": 1678, "ep_reward": 935.86083984375, "reward": 0.5854367613792419, "action": 1.3751519918441772}
{"mode": "train", "epochs": 1, "timestep": 1679, "ep_reward": 936.5399169921875, "reward": 0.6790820956230164, "action": 1.7295795679092407}
{"mode": "train", "epochs": 1, "timestep": 1680, "ep_reward": 937.2869262695312, "reward": 0.7470256090164185, "action": 0.9678072929382324}
{"mode": "train", "epochs": 1, "timestep": 1681, "ep_reward": 938.087646484375, "reward": 0.8007018566131592, "action": 0.6279482841491699}
{"mode": "train", "epochs": 1, "timestep": 1682, "ep_reward": 938.9241943359375, "reward": 0.8365469574928284, "action": 0.2954452633857727}
{"mode": "train", "epochs": 1, "timestep": 1683, "ep_reward": 939.7803955078125, "reward": 0.8562226295471191, "action": -0.0037995576858520508}
{"mode": "train", "epochs": 1, "timestep": 1684, "ep_reward": 940.64111328125, "reward": 0.8607231378555298, "action": 0.5899649262428284}
{"mode": "train", "epochs": 1, "timestep": 1685, "ep_reward": 941.483154296875, "reward": 0.8420558571815491, "action": 0.8552916049957275}
{"mode": "train", "epochs": 1, "timestep": 1686, "ep_reward": 942.2830200195312, "reward": 0.79985511302948, "action": 1.298740029335022}
{"mode": "train", "epochs": 1, "timestep": 1687, "ep_reward": 943.0089721679688, "reward": 0.7259252667427063, "action": 1.1568410396575928}
{"mode": "train", "epochs": 1, "timestep": 1688, "ep_reward": 943.6275634765625, "reward": 0.618618369102478, "action": 0.7560919523239136}
{"mode": "train", "epochs": 1, "timestep": 1689, "ep_reward": 944.1038818359375, "reward": 0.4762887954711914, "action": 0.6017827987670898}
{"mode": "train", "epochs": 1, "timestep": 1690, "ep_reward": 944.4425048828125, "reward": 0.3386406898498535, "action": 1.4457160234451294}
{"mode": "train", "epochs": 1, "timestep": 1691, "ep_reward": 944.6689453125, "reward": 0.22644031047821045, "action": 1.3374106884002686}
{"mode": "train", "epochs": 1, "timestep": 1692, "ep_reward": 944.7632446289062, "reward": 0.09428966045379639, "action": 0.8379338979721069}
{"mode": "train", "epochs": 1, "timestep": 1693, "ep_reward": 944.7860717773438, "reward": 0.022829949855804443, "action": 0.7224389314651489}
{"mode": "train", "epochs": 1, "timestep": 1694, "ep_reward": 944.9508666992188, "reward": 0.16476517915725708, "action": 0.74315345287323}
{"mode": "train", "epochs": 1, "timestep": 1695, "ep_reward": 945.2586669921875, "reward": 0.3077777624130249, "action": 0.9859408140182495}
{"mode": "train", "epochs": 1, "timestep": 1696, "ep_reward": 945.7020263671875, "reward": 0.4433513283729553, "action": 0.5179817080497742}
{"mode": "train", "epochs": 1, "timestep": 1697, "ep_reward": 946.2726440429688, "reward": 0.5706260204315186, "action": 1.0484100580215454}
{"mode": "train", "epochs": 1, "timestep": 1698, "ep_reward": 946.9437866210938, "reward": 0.671124279499054, "action": 1.2101030349731445}
{"mode": "train", "epochs": 1, "timestep": 1699, "ep_reward": 947.69189453125, "reward": 0.7481342554092407, "action": 1.3490890264511108}
{"mode": "train", "epochs": 1, "timestep": 1700, "ep_reward": 948.4949340820312, "reward": 0.8030154705047607, "action": 1.0484837293624878}
{"mode": "train", "epochs": 1, "timestep": 1701, "ep_reward": 949.33642578125, "reward": 0.8414864540100098, "action": 1.2004705667495728}
{"mode": "train", "epochs": 1, "timestep": 1702, "ep_reward": 950.1976928710938, "reward": 0.8612862825393677, "action": 1.4153831005096436}
{"mode": "train", "epochs": 1, "timestep": 1703, "ep_reward": 951.0606079101562, "reward": 0.8629381656646729, "action": 0.8585594296455383}
{"mode": "train", "epochs": 1, "timestep": 1704, "ep_reward": 951.9127197265625, "reward": 0.8520908355712891, "action": 0.8242995738983154}
{"mode": "train", "epochs": 1, "timestep": 1705, "ep_reward": 952.7346801757812, "reward": 0.8219788670539856, "action": 1.291458249092102}
{"mode": "train", "epochs": 1, "timestep": 1706, "ep_reward": 953.4976806640625, "reward": 0.7630059719085693, "action": -0.002754807472229004}
{"mode": "train", "epochs": 1, "timestep": 1707, "ep_reward": 954.1861572265625, "reward": 0.6884961724281311, "action": 0.8287831544876099}
{"mode": "train", "epochs": 1, "timestep": 1708, "ep_reward": 954.7554321289062, "reward": 0.569301426410675, "action": 0.7696670293807983}
{"mode": "train", "epochs": 1, "timestep": 1709, "ep_reward": 955.166015625, "reward": 0.4105832576751709, "action": 0.9759469628334045}
{"mode": "train", "epochs": 1, "timestep": 1710, "ep_reward": 955.457763671875, "reward": 0.2917720675468445, "action": 0.31608420610427856}
{"mode": "train", "epochs": 1, "timestep": 1711, "ep_reward": 955.62841796875, "reward": 0.17064756155014038, "action": 1.2478883266448975}
{"mode": "train", "epochs": 1, "timestep": 1712, "ep_reward": 955.6580810546875, "reward": 0.029676079750061035, "action": 0.7590569257736206}
{"mode": "train", "epochs": 1, "timestep": 1713, "ep_reward": 955.7459106445312, "reward": 0.08785969018936157, "action": 0.6045632362365723}
{"mode": "train", "epochs": 1, "timestep": 1714, "ep_reward": 955.9766235351562, "reward": 0.2306894063949585, "action": 0.7848799824714661}
{"mode": "train", "epochs": 1, "timestep": 1715, "ep_reward": 956.3482055664062, "reward": 0.37161147594451904, "action": 1.7784738540649414}
{"mode": "train", "epochs": 1, "timestep": 1716, "ep_reward": 956.8406982421875, "reward": 0.49251222610473633, "action": 0.25828754901885986}
{"mode": "train", "epochs": 1, "timestep": 1717, "ep_reward": 957.4561157226562, "reward": 0.6154265403747559, "action": 1.2102406024932861}
{"mode": "train", "epochs": 1, "timestep": 1718, "ep_reward": 958.1612548828125, "reward": 0.7051247358322144, "action": 0.8571580052375793}
{"mode": "train", "epochs": 1, "timestep": 1719, "ep_reward": 958.9375610351562, "reward": 0.7763141393661499, "action": 0.4893004894256592}
{"mode": "train", "epochs": 1, "timestep": 1720, "ep_reward": 959.7671508789062, "reward": 0.8295842409133911, "action": 1.177873134613037}
{"mode": "train", "epochs": 1, "timestep": 1721, "ep_reward": 960.6257934570312, "reward": 0.8586161136627197, "action": 1.0085679292678833}
{"mode": "train", "epochs": 1, "timestep": 1722, "ep_reward": 961.4988403320312, "reward": 0.8730400800704956, "action": 1.5159313678741455}
{"mode": "train", "epochs": 1, "timestep": 1723, "ep_reward": 962.3666381835938, "reward": 0.8678020238876343, "action": 1.100005030632019}
{"mode": "train", "epochs": 1, "timestep": 1724, "ep_reward": 963.21533203125, "reward": 0.8486850261688232, "action": 1.806039810180664}
{"mode": "train", "epochs": 1, "timestep": 1725, "ep_reward": 964.0172729492188, "reward": 0.8019256591796875, "action": 0.7208874225616455}
{"mode": "train", "epochs": 1, "timestep": 1726, "ep_reward": 964.7562866210938, "reward": 0.7390070557594299, "action": -0.02993953227996826}
{"mode": "train", "epochs": 1, "timestep": 1727, "ep_reward": 965.4099731445312, "reward": 0.653663694858551, "action": 1.4236080646514893}
{"mode": "train", "epochs": 1, "timestep": 1728, "ep_reward": 965.92236328125, "reward": 0.5124027729034424, "action": 1.0472782850265503}
{"mode": "train", "epochs": 1, "timestep": 1729, "ep_reward": 966.2816162109375, "reward": 0.3592751622200012, "action": 1.799302101135254}
{"mode": "train", "epochs": 1, "timestep": 1730, "ep_reward": 966.5328979492188, "reward": 0.25129127502441406, "action": 1.2769865989685059}
{"mode": "train", "epochs": 1, "timestep": 1731, "ep_reward": 966.6561889648438, "reward": 0.12329435348510742, "action": 0.4899032711982727}
{"mode": "train", "epochs": 1, "timestep": 1732, "ep_reward": 966.6470336914062, "reward": -0.009176254272460938, "action": 1.7837157249450684}
{"mode": "train", "epochs": 1, "timestep": 1733, "ep_reward": 966.7841186523438, "reward": 0.13709264993667603, "action": 0.17187267541885376}
{"mode": "train", "epochs": 1, "timestep": 1734, "ep_reward": 967.0706787109375, "reward": 0.28658127784729004, "action": 0.6907864212989807}
{"mode": "train", "epochs": 1, "timestep": 1735, "ep_reward": 967.4962768554688, "reward": 0.4255867600440979, "action": 1.0050022602081299}
{"mode": "train", "epochs": 1, "timestep": 1736, "ep_reward": 968.045166015625, "reward": 0.5489181280136108, "action": 0.6581692695617676}
{"mode": "train", "epochs": 1, "timestep": 1737, "ep_reward": 968.7025756835938, "reward": 0.6574329137802124, "action": 1.030040979385376}
{"mode": "train", "epochs": 1, "timestep": 1738, "ep_reward": 969.4428100585938, "reward": 0.7402201890945435, "action": 0.6183602809906006}
{"mode": "train", "epochs": 1, "timestep": 1739, "ep_reward": 970.2484741210938, "reward": 0.8056731820106506, "action": 0.4406083822250366}
{"mode": "train", "epochs": 1, "timestep": 1740, "ep_reward": 971.1014404296875, "reward": 0.8529919981956482, "action": 1.6371688842773438}
{"mode": "train", "epochs": 1, "timestep": 1741, "ep_reward": 971.9764404296875, "reward": 0.8750121593475342, "action": 1.1343415975570679}
{"mode": "train", "epochs": 1, "timestep": 1742, "ep_reward": 972.8636474609375, "reward": 0.887179434299469, "action": -0.05654096603393555}
{"mode": "train", "epochs": 1, "timestep": 1743, "ep_reward": 973.758544921875, "reward": 0.8949222564697266, "action": 0.7272713780403137}
{"mode": "train", "epochs": 1, "timestep": 1744, "ep_reward": 974.6416625976562, "reward": 0.8831265568733215, "action": 0.6857331991195679}
{"mode": "train", "epochs": 1, "timestep": 1745, "ep_reward": 975.4977416992188, "reward": 0.856102705001831, "action": 0.9081865549087524}
{"mode": "train", "epochs": 1, "timestep": 1746, "ep_reward": 976.30517578125, "reward": 0.8074352741241455, "action": 1.466796875}
{"mode": "train", "epochs": 1, "timestep": 1747, "ep_reward": 977.03173828125, "reward": 0.726580023765564, "action": 1.760582447052002}
{"mode": "train", "epochs": 1, "timestep": 1748, "ep_reward": 977.6382446289062, "reward": 0.6065303087234497, "action": 1.2567722797393799}
{"mode": "train", "epochs": 1, "timestep": 1749, "ep_reward": 978.0891723632812, "reward": 0.450935959815979, "action": 0.5683126449584961}
{"mode": "train", "epochs": 1, "timestep": 1750, "ep_reward": 978.402587890625, "reward": 0.31339460611343384, "action": 1.007163166999817}
{"mode": "train", "epochs": 1, "timestep": 1751, "ep_reward": 978.598876953125, "reward": 0.19628214836120605, "action": 1.3776392936706543}
{"mode": "train", "epochs": 1, "timestep": 1752, "ep_reward": 978.6581420898438, "reward": 0.059281766414642334, "action": 0.9981427192687988}
{"mode": "train", "epochs": 1, "timestep": 1753, "ep_reward": 978.7171630859375, "reward": 0.05903267860412598, "action": 0.0021377205848693848}
{"mode": "train", "epochs": 1, "timestep": 1754, "ep_reward": 978.9254150390625, "reward": 0.20825904607772827, "action": 1.843080997467041}
{"mode": "train", "epochs": 1, "timestep": 1755, "ep_reward": 979.2611083984375, "reward": 0.3357117772102356, "action": 1.4912974834442139}
{"mode": "train", "epochs": 1, "timestep": 1756, "ep_reward": 979.7247924804688, "reward": 0.46366649866104126, "action": 1.2560187578201294}
{"mode": "train", "epochs": 1, "timestep": 1757, "ep_reward": 980.30517578125, "reward": 0.5803695917129517, "action": 0.77567458152771}
{"mode": "train", "epochs": 1, "timestep": 1758, "ep_reward": 980.9864501953125, "reward": 0.6812782287597656, "action": 0.5353737473487854}
{"mode": "train", "epochs": 1, "timestep": 1759, "ep_reward": 981.7468872070312, "reward": 0.7604610323905945, "action": 1.194925308227539}
{"mode": "train", "epochs": 1, "timestep": 1760, "ep_reward": 982.5579223632812, "reward": 0.8110384345054626, "action": 0.3168089985847473}
{"mode": "train", "epochs": 1, "timestep": 1761, "ep_reward": 983.4077758789062, "reward": 0.8498325347900391, "action": 0.8057001829147339}
{"mode": "train", "epochs": 1, "timestep": 1762, "ep_reward": 984.2744750976562, "reward": 0.866698145866394, "action": 1.254623532295227}
{"mode": "train", "epochs": 1, "timestep": 1763, "ep_reward": 985.137939453125, "reward": 0.8634634613990784, "action": 1.0321730375289917}
{"mode": "train", "epochs": 1, "timestep": 1764, "ep_reward": 985.9822998046875, "reward": 0.8443775177001953, "action": 1.258476972579956}
{"mode": "train", "epochs": 1, "timestep": 1765, "ep_reward": 986.7843017578125, "reward": 0.8020001649856567, "action": -0.2631608247756958}
{"mode": "train", "epochs": 1, "timestep": 1766, "ep_reward": 987.5342407226562, "reward": 0.7499397993087769, "action": 0.6428442597389221}
{"mode": "train", "epochs": 1, "timestep": 1767, "ep_reward": 988.1923828125, "reward": 0.6581445932388306, "action": 1.3812041282653809}
{"mode": "train", "epochs": 1, "timestep": 1768, "ep_reward": 988.7112426757812, "reward": 0.5188486576080322, "action": 0.4999794363975525}
{"mode": "train", "epochs": 1, "timestep": 1769, "ep_reward": 989.0719604492188, "reward": 0.3607115149497986, "action": 1.495668649673462}
{"mode": "train", "epochs": 1, "timestep": 1770, "ep_reward": 989.324951171875, "reward": 0.2529686689376831, "action": 1.122976541519165}
{"mode": "train", "epochs": 1, "timestep": 1771, "ep_reward": 989.4501953125, "reward": 0.12522566318511963, "action": 0.5458074808120728}
{"mode": "train", "epochs": 1, "timestep": 1772, "ep_reward": 989.4390258789062, "reward": -0.011176705360412598, "action": 0.3635624647140503}
{"mode": "train", "epochs": 1, "timestep": 1773, "ep_reward": 989.5740966796875, "reward": 0.13507354259490967, "action": 1.328944206237793}
{"mode": "train", "epochs": 1, "timestep": 1774, "ep_reward": 989.8443603515625, "reward": 0.2702406644821167, "action": 0.36073070764541626}
{"mode": "train", "epochs": 1, "timestep": 1775, "ep_reward": 990.2606201171875, "reward": 0.4162476062774658, "action": 1.6556360721588135}
{"mode": "train", "epochs": 1, "timestep": 1776, "ep_reward": 990.7947387695312, "reward": 0.5341076254844666, "action": 1.2177799940109253}
{"mode": "train", "epochs": 1, "timestep": 1777, "ep_reward": 991.4343872070312, "reward": 0.6396311521530151, "action": 0.33173394203186035}
{"mode": "train", "epochs": 1, "timestep": 1778, "ep_reward": 992.166015625, "reward": 0.731651246547699, "action": 0.8457943797111511}
{"mode": "train", "epochs": 1, "timestep": 1779, "ep_reward": 992.9608764648438, "reward": 0.794847846031189, "action": 1.52333402633667}
{"mode": "train", "epochs": 1, "timestep": 1780, "ep_reward": 993.7928466796875, "reward": 0.8319711685180664, "action": 1.120308756828308}
{"mode": "train", "epochs": 1, "timestep": 1781, "ep_reward": 994.647705078125, "reward": 0.8548856377601624, "action": 0.8878071308135986}
{"mode": "train", "epochs": 1, "timestep": 1782, "ep_reward": 995.5103759765625, "reward": 0.8626792430877686, "action": 1.462323784828186}
{"mode": "train", "epochs": 1, "timestep": 1783, "ep_reward": 996.3583374023438, "reward": 0.8479791879653931, "action": 1.412116289138794}
{"mode": "train", "epochs": 1, "timestep": 1784, "ep_reward": 997.17138671875, "reward": 0.8130595684051514, "action": 0.847891628742218}
{"mode": "train", "epochs": 1, "timestep": 1785, "ep_reward": 997.9296875, "reward": 0.7583049535751343, "action": 1.306073546409607}
{"mode": "train", "epochs": 1, "timestep": 1786, "ep_reward": 998.5963134765625, "reward": 0.6666526794433594, "action": 1.0122888088226318}
{"mode": "train", "epochs": 1, "timestep": 1787, "ep_reward": 999.135498046875, "reward": 0.539156973361969, "action": 1.573150396347046}
{"mode": "train", "epochs": 1, "timestep": 1788, "ep_reward": 999.5215454101562, "reward": 0.3860361576080322, "action": 0.977428138256073}
{"mode": "train", "epochs": 1, "timestep": 1789, "ep_reward": 999.8050537109375, "reward": 0.28351277112960815, "action": 1.1683205366134644}
{"mode": "train", "epochs": 1, "timestep": 1790, "ep_reward": 999.9661254882812, "reward": 0.1610870361328125, "action": 0.47016090154647827}
{"mode": "train", "epochs": 1, "timestep": 1791, "ep_reward": 999.9847412109375, "reward": 0.018603801727294922, "action": -0.0896303653717041}
{"mode": "train", "epochs": 1, "timestep": 1792, "ep_reward": 1000.0830078125, "reward": 0.09829682111740112, "action": 0.3447248935699463}
{"mode": "train", "epochs": 1, "timestep": 1793, "ep_reward": 1000.3275146484375, "reward": 0.24452126026153564, "action": 1.6162359714508057}
{"mode": "train", "epochs": 1, "timestep": 1794, "ep_reward": 1000.7020874023438, "reward": 0.3745790719985962, "action": 0.6130388379096985}
{"mode": "train", "epochs": 1, "timestep": 1795, "ep_reward": 1001.2113647460938, "reward": 0.5092490911483765, "action": 0.6392873525619507}
{"mode": "train", "epochs": 1, "timestep": 1796, "ep_reward": 1001.8364868164062, "reward": 0.6251193881034851, "action": 0.8291782140731812}
{"mode": "train", "epochs": 1, "timestep": 1797, "ep_reward": 1002.5531005859375, "reward": 0.7165845632553101, "action": 0.7357089519500732}
{"mode": "train", "epochs": 1, "timestep": 1798, "ep_reward": 1003.3396606445312, "reward": 0.7865445017814636, "action": 1.1755921840667725}
{"mode": "train", "epochs": 1, "timestep": 1799, "ep_reward": 1004.172119140625, "reward": 0.8324788808822632, "action": 0.9769961833953857}
{"mode": "train", "epochs": 1, "timestep": 1800, "ep_reward": 1005.0348510742188, "reward": 0.8627483248710632, "action": 1.304624080657959}
{"mode": "train", "epochs": 1, "timestep": 1801, "ep_reward": 1005.9097290039062, "reward": 0.8749077916145325, "action": 0.3943302631378174}
{"mode": "train", "epochs": 1, "timestep": 1802, "ep_reward": 1006.7890625, "reward": 0.8793208599090576, "action": 1.3601551055908203}
{"mode": "train", "epochs": 1, "timestep": 1803, "ep_reward": 1007.6491088867188, "reward": 0.8600621819496155, "action": 1.0643870830535889}
{"mode": "train", "epochs": 1, "timestep": 1804, "ep_reward": 1008.4733276367188, "reward": 0.8241949677467346, "action": 0.78571617603302}
{"mode": "train", "epochs": 1, "timestep": 1805, "ep_reward": 1009.2405395507812, "reward": 0.7672048807144165, "action": 1.249489665031433}
{"mode": "train", "epochs": 1, "timestep": 1806, "ep_reward": 1009.9154052734375, "reward": 0.6748549938201904, "action": 0.4041321873664856}
{"mode": "train", "epochs": 1, "timestep": 1807, "ep_reward": 1010.4716796875, "reward": 0.5562804937362671, "action": 0.4615286588668823}
{"mode": "train", "epochs": 1, "timestep": 1808, "ep_reward": 1010.8703002929688, "reward": 0.3985993266105652, "action": 1.2414002418518066}
{"mode": "train", "epochs": 1, "timestep": 1809, "ep_reward": 1011.14697265625, "reward": 0.2766461968421936, "action": 0.5251950025558472}
{"mode": "train", "epochs": 1, "timestep": 1810, "ep_reward": 1011.2998046875, "reward": 0.15280896425247192, "action": 1.4481477737426758}
{"mode": "train", "epochs": 1, "timestep": 1811, "ep_reward": 1011.3089599609375, "reward": 0.009149789810180664, "action": 1.0389509201049805}
{"mode": "train", "epochs": 1, "timestep": 1812, "ep_reward": 1011.415771484375, "reward": 0.1068161129951477, "action": 1.4727498292922974}
{"mode": "train", "epochs": 1, "timestep": 1813, "ep_reward": 1011.655029296875, "reward": 0.23923760652542114, "action": 1.8005177974700928}
{"mode": "train", "epochs": 1, "timestep": 1814, "ep_reward": 1012.0244140625, "reward": 0.3693934679031372, "action": 0.620857834815979}
{"mode": "train", "epochs": 1, "timestep": 1815, "ep_reward": 1012.530517578125, "reward": 0.5060989856719971, "action": 0.8467116951942444}
{"mode": "train", "epochs": 1, "timestep": 1816, "ep_reward": 1013.1510620117188, "reward": 0.6205276250839233, "action": 1.1832448244094849}
{"mode": "train", "epochs": 1, "timestep": 1817, "ep_reward": 1013.859375, "reward": 0.7083041667938232, "action": 0.7638915777206421}
{"mode": "train", "epochs": 1, "timestep": 1818, "ep_reward": 1014.6363525390625, "reward": 0.7769774198532104, "action": 1.5487565994262695}
{"mode": "train", "epochs": 1, "timestep": 1819, "ep_reward": 1015.4530639648438, "reward": 0.8166859149932861, "action": 0.9323493242263794}
{"mode": "train", "epochs": 1, "timestep": 1820, "ep_reward": 1016.2955932617188, "reward": 0.8425589203834534, "action": 1.619354009628296}
{"mode": "train", "epochs": 1, "timestep": 1821, "ep_reward": 1017.1393432617188, "reward": 0.8437227010726929, "action": 0.08275920152664185}
{"mode": "train", "epochs": 1, "timestep": 1822, "ep_reward": 1017.97900390625, "reward": 0.8396514058113098, "action": 0.921939492225647}
{"mode": "train", "epochs": 1, "timestep": 1823, "ep_reward": 1018.7855834960938, "reward": 0.80660080909729, "action": 1.347275972366333}
{"mode": "train", "epochs": 1, "timestep": 1824, "ep_reward": 1019.5283813476562, "reward": 0.7428035140037537, "action": 0.9380101561546326}
{"mode": "train", "epochs": 1, "timestep": 1825, "ep_reward": 1020.1785278320312, "reward": 0.6501312255859375, "action": 0.9939385056495667}
{"mode": "train", "epochs": 1, "timestep": 1826, "ep_reward": 1020.6954956054688, "reward": 0.5169899463653564, "action": 1.1439493894577026}
{"mode": "train", "epochs": 1, "timestep": 1827, "ep_reward": 1021.0696411132812, "reward": 0.37413322925567627, "action": 0.5805577039718628}
{"mode": "train", "epochs": 1, "timestep": 1828, "ep_reward": 1021.3385620117188, "reward": 0.2689502239227295, "action": 1.596601963043213}
{"mode": "train", "epochs": 1, "timestep": 1829, "ep_reward": 1021.4826049804688, "reward": 0.14406466484069824, "action": 0.11231684684753418}
{"mode": "train", "epochs": 1, "timestep": 1830, "ep_reward": 1021.4815063476562, "reward": -0.0011131763458251953, "action": 1.4704450368881226}
{"mode": "train", "epochs": 1, "timestep": 1831, "ep_reward": 1021.5974731445312, "reward": 0.11597418785095215, "action": 1.8238226175308228}
{"mode": "train", "epochs": 1, "timestep": 1832, "ep_reward": 1021.8427734375, "reward": 0.24528992176055908, "action": 0.2659369707107544}
{"mode": "train", "epochs": 1, "timestep": 1833, "ep_reward": 1022.2374267578125, "reward": 0.39464688301086426, "action": 0.8993896245956421}
{"mode": "train", "epochs": 1, "timestep": 1834, "ep_reward": 1022.7613525390625, "reward": 0.5239037275314331, "action": 1.193570852279663}
{"mode": "train", "epochs": 1, "timestep": 1835, "ep_reward": 1023.3927612304688, "reward": 0.6313889026641846, "action": 1.4039344787597656}
{"mode": "train", "epochs": 1, "timestep": 1836, "ep_reward": 1024.10791015625, "reward": 0.7151603102684021, "action": 0.8328084349632263}
{"mode": "train", "epochs": 1, "timestep": 1837, "ep_reward": 1024.8902587890625, "reward": 0.7823325991630554, "action": 1.3730688095092773}
{"mode": "train", "epochs": 1, "timestep": 1838, "ep_reward": 1025.7138671875, "reward": 0.8235871195793152, "action": 0.49468445777893066}
{"mode": "train", "epochs": 1, "timestep": 1839, "ep_reward": 1026.567626953125, "reward": 0.8538041710853577, "action": 1.105176568031311}
{"mode": "train", "epochs": 1, "timestep": 1840, "ep_reward": 1027.428955078125, "reward": 0.8613550066947937, "action": 0.4003129005432129}
{"mode": "train", "epochs": 1, "timestep": 1841, "ep_reward": 1028.2867431640625, "reward": 0.8577820658683777, "action": 1.2680120468139648}
{"mode": "train", "epochs": 1, "timestep": 1842, "ep_reward": 1029.1143798828125, "reward": 0.8275900483131409, "action": 1.2204606533050537}
{"mode": "train", "epochs": 1, "timestep": 1843, "ep_reward": 1029.888427734375, "reward": 0.7740321159362793, "action": 0.4835004210472107}
{"mode": "train", "epochs": 1, "timestep": 1844, "ep_reward": 1030.5875244140625, "reward": 0.6991417407989502, "action": 0.04436618089675903}
{"mode": "train", "epochs": 1, "timestep": 1845, "ep_reward": 1031.1834716796875, "reward": 0.5959298014640808, "action": 1.8912596702575684}
{"mode": "train", "epochs": 1, "timestep": 1846, "ep_reward": 1031.61083984375, "reward": 0.42734086513519287, "action": 0.46563583612442017}
{"mode": "train", "epochs": 1, "timestep": 1847, "ep_reward": 1031.92041015625, "reward": 0.3096029758453369, "action": 1.118129014968872}
{"mode": "train", "epochs": 1, "timestep": 1848, "ep_reward": 1032.1123046875, "reward": 0.19191652536392212, "action": 0.254341185092926}
{"mode": "train", "epochs": 1, "timestep": 1849, "ep_reward": 1032.1663818359375, "reward": 0.05405396223068237, "action": 1.3060672283172607}
{"mode": "train", "epochs": 1, "timestep": 1850, "ep_reward": 1032.2305908203125, "reward": 0.06417173147201538, "action": 0.5815565586090088}
{"mode": "train", "epochs": 1, "timestep": 1851, "ep_reward": 1032.4371337890625, "reward": 0.20657426118850708, "action": 0.7091014981269836}
{"mode": "train", "epochs": 1, "timestep": 1852, "ep_reward": 1032.786376953125, "reward": 0.34924447536468506, "action": 0.8001227378845215}
{"mode": "train", "epochs": 1, "timestep": 1853, "ep_reward": 1033.269775390625, "reward": 0.48341095447540283, "action": 0.761775016784668}
{"mode": "train", "epochs": 1, "timestep": 1854, "ep_reward": 1033.8717041015625, "reward": 0.60193932056427, "action": 0.9228143095970154}
{"mode": "train", "epochs": 1, "timestep": 1855, "ep_reward": 1034.569091796875, "reward": 0.6973482370376587, "action": 1.953099012374878}
{"mode": "train", "epochs": 1, "timestep": 1856, "ep_reward": 1035.3306884765625, "reward": 0.7615479826927185, "action": 0.8950126767158508}
{"mode": "train", "epochs": 1, "timestep": 1857, "ep_reward": 1036.1466064453125, "reward": 0.815880298614502, "action": 0.7362749576568604}
{"mode": "train", "epochs": 1, "timestep": 1858, "ep_reward": 1036.9991455078125, "reward": 0.8525527119636536, "action": -0.07826817035675049}
{"mode": "train", "epochs": 1, "timestep": 1859, "ep_reward": 1037.8780517578125, "reward": 0.8789620995521545, "action": -0.38456058502197266}
{"mode": "train", "epochs": 1, "timestep": 1860, "ep_reward": 1038.7706298828125, "reward": 0.892578125, "action": 0.9550753235816956}
{"mode": "train", "epochs": 1, "timestep": 1861, "ep_reward": 1039.6524658203125, "reward": 0.8818515539169312, "action": 1.0229337215423584}
{"mode": "train", "epochs": 1, "timestep": 1862, "ep_reward": 1040.5069580078125, "reward": 0.854508101940155, "action": 1.7716834545135498}
{"mode": "train", "epochs": 1, "timestep": 1863, "ep_reward": 1041.306396484375, "reward": 0.7994725704193115, "action": 1.586472988128662}
{"mode": "train", "epochs": 1, "timestep": 1864, "ep_reward": 1042.0235595703125, "reward": 0.7171802520751953, "action": 1.7628755569458008}
{"mode": "train", "epochs": 1, "timestep": 1865, "ep_reward": 1042.6192626953125, "reward": 0.5956730246543884, "action": 0.5316184759140015}
{"mode": "train", "epochs": 1, "timestep": 1866, "ep_reward": 1043.0682373046875, "reward": 0.4489583969116211, "action": 1.2220817804336548}
{"mode": "train", "epochs": 1, "timestep": 1867, "ep_reward": 1043.385009765625, "reward": 0.31680625677108765, "action": 1.1054197549819946}
{"mode": "train", "epochs": 1, "timestep": 1868, "ep_reward": 1043.58544921875, "reward": 0.20045924186706543, "action": 0.351659893989563}
{"mode": "train", "epochs": 1, "timestep": 1869, "ep_reward": 1043.6494140625, "reward": 0.06400734186172485, "action": 0.8452657461166382}
{"mode": "train", "epochs": 1, "timestep": 1870, "ep_reward": 1043.7037353515625, "reward": 0.05426305532455444, "action": 0.7975010275840759}
{"mode": "train", "epochs": 1, "timestep": 1871, "ep_reward": 1043.8973388671875, "reward": 0.193628191947937, "action": 1.0046415328979492}
{"mode": "train", "epochs": 1, "timestep": 1872, "ep_reward": 1044.2308349609375, "reward": 0.33350569009780884, "action": 0.8014191389083862}
{"mode": "train", "epochs": 1, "timestep": 1873, "ep_reward": 1044.70068359375, "reward": 0.4698101282119751, "action": 1.052093505859375}
{"mode": "train", "epochs": 1, "timestep": 1874, "ep_reward": 1045.2882080078125, "reward": 0.5875537395477295, "action": 0.8647054433822632}
{"mode": "train", "epochs": 1, "timestep": 1875, "ep_reward": 1045.9744873046875, "reward": 0.6863016486167908, "action": 1.5376858711242676}
{"mode": "train", "epochs": 1, "timestep": 1876, "ep_reward": 1046.730224609375, "reward": 0.7557950019836426, "action": 1.5990569591522217}
{"mode": "train", "epochs": 1, "timestep": 1877, "ep_reward": 1047.534423828125, "reward": 0.8041542172431946, "action": 1.607014775276184}
{"mode": "train", "epochs": 1, "timestep": 1878, "ep_reward": 1048.36767578125, "reward": 0.8332074880599976, "action": 1.763014793395996}
{"mode": "train", "epochs": 1, "timestep": 1879, "ep_reward": 1049.2100830078125, "reward": 0.8424383997917175, "action": 1.6514892578125}
{"mode": "train", "epochs": 1, "timestep": 1880, "ep_reward": 1050.0435791015625, "reward": 0.833441436290741, "action": 1.0379918813705444}
{"mode": "train", "epochs": 1, "timestep": 1881, "ep_reward": 1050.85205078125, "reward": 0.8085173964500427, "action": 0.8060643076896667}
{"mode": "train", "epochs": 1, "timestep": 1882, "ep_reward": 1051.6126708984375, "reward": 0.7605795860290527, "action": 0.167935311794281}
{"mode": "train", "epochs": 1, "timestep": 1883, "ep_reward": 1052.302490234375, "reward": 0.6898444890975952, "action": 0.6170392036437988}
{"mode": "train", "epochs": 1, "timestep": 1884, "ep_reward": 1052.8804931640625, "reward": 0.5780149698257446, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1885, "ep_reward": 1053.2894287109375, "reward": 0.4089846611022949, "action": 0.7328038215637207}
{"mode": "train", "epochs": 1, "timestep": 1886, "ep_reward": 1053.6009521484375, "reward": 0.3115161657333374, "action": 1.2694268226623535}
{"mode": "train", "epochs": 1, "timestep": 1887, "ep_reward": 1053.795166015625, "reward": 0.19418072700500488, "action": 0.7542293667793274}
{"mode": "train", "epochs": 1, "timestep": 1888, "ep_reward": 1053.8519287109375, "reward": 0.0567324161529541, "action": 1.1580042839050293}
{"mode": "train", "epochs": 1, "timestep": 1889, "ep_reward": 1053.9134521484375, "reward": 0.06155407428741455, "action": 0.14470332860946655}
{"mode": "train", "epochs": 1, "timestep": 1890, "ep_reward": 1054.1226806640625, "reward": 0.20917487144470215, "action": 1.4900307655334473}
{"mode": "train", "epochs": 1, "timestep": 1891, "ep_reward": 1054.4639892578125, "reward": 0.34126073122024536, "action": 1.171074390411377}
{"mode": "train", "epochs": 1, "timestep": 1892, "ep_reward": 1054.936279296875, "reward": 0.47223830223083496, "action": 1.1868852376937866}
{"mode": "train", "epochs": 1, "timestep": 1893, "ep_reward": 1055.5245361328125, "reward": 0.588215708732605, "action": 0.7591204047203064}
{"mode": "train", "epochs": 1, "timestep": 1894, "ep_reward": 1056.21240234375, "reward": 0.6879016160964966, "action": 0.8295760154724121}
{"mode": "train", "epochs": 1, "timestep": 1895, "ep_reward": 1056.975830078125, "reward": 0.7634177803993225, "action": 1.5054621696472168}
{"mode": "train", "epochs": 1, "timestep": 1896, "ep_reward": 1057.7872314453125, "reward": 0.8114569783210754, "action": 0.24273735284805298}
{"mode": "train", "epochs": 1, "timestep": 1897, "ep_reward": 1058.638671875, "reward": 0.8514952659606934, "action": 1.4294633865356445}
{"mode": "train", "epochs": 1, "timestep": 1898, "ep_reward": 1059.5028076171875, "reward": 0.8641873598098755, "action": 0.6806068420410156}
{"mode": "train", "epochs": 1, "timestep": 1899, "ep_reward": 1060.3697509765625, "reward": 0.8668883442878723, "action": 0.9368210434913635}
{"mode": "train", "epochs": 1, "timestep": 1900, "ep_reward": 1061.219970703125, "reward": 0.8501805067062378, "action": 1.4477342367172241}
{"mode": "train", "epochs": 1, "timestep": 1901, "ep_reward": 1062.0281982421875, "reward": 0.8082173466682434, "action": 1.3160209655761719}
{"mode": "train", "epochs": 1, "timestep": 1902, "ep_reward": 1062.7689208984375, "reward": 0.7406836748123169, "action": 1.271769642829895}
{"mode": "train", "epochs": 1, "timestep": 1903, "ep_reward": 1063.4085693359375, "reward": 0.6396230459213257, "action": 0.2621946334838867}
{"mode": "train", "epochs": 1, "timestep": 1904, "ep_reward": 1063.9212646484375, "reward": 0.5127492547035217, "action": 0.04517507553100586}
{"mode": "train", "epochs": 1, "timestep": 1905, "ep_reward": 1064.2823486328125, "reward": 0.36105024814605713, "action": 1.1608400344848633}
{"mode": "train", "epochs": 1, "timestep": 1906, "ep_reward": 1064.5355224609375, "reward": 0.25321483612060547, "action": 1.6669259071350098}
{"mode": "train", "epochs": 1, "timestep": 1907, "ep_reward": 1064.6611328125, "reward": 0.12561750411987305, "action": 0.6409565210342407}
{"mode": "train", "epochs": 1, "timestep": 1908, "ep_reward": 1064.6492919921875, "reward": -0.011838793754577637, "action": 1.8652938604354858}
{"mode": "train", "epochs": 1, "timestep": 1909, "ep_reward": 1064.7840576171875, "reward": 0.13478881120681763, "action": -0.055954933166503906}
{"mode": "train", "epochs": 1, "timestep": 1910, "ep_reward": 1065.071044921875, "reward": 0.286926805973053, "action": 1.3903831243515015}
{"mode": "train", "epochs": 1, "timestep": 1911, "ep_reward": 1065.48828125, "reward": 0.4172952175140381, "action": 0.492223858833313}
{"mode": "train", "epochs": 1, "timestep": 1912, "ep_reward": 1066.0360107421875, "reward": 0.5476820468902588, "action": 1.2311902046203613}
{"mode": "train", "epochs": 1, "timestep": 1913, "ep_reward": 1066.6866455078125, "reward": 0.6506315469741821, "action": 0.6464045643806458}
{"mode": "train", "epochs": 1, "timestep": 1914, "ep_reward": 1067.4246826171875, "reward": 0.7380244135856628, "action": 1.934787392616272}
{"mode": "train", "epochs": 1, "timestep": 1915, "ep_reward": 1068.217041015625, "reward": 0.7923283576965332, "action": 1.0386338233947754}
{"mode": "train", "epochs": 1, "timestep": 1916, "ep_reward": 1069.05322265625, "reward": 0.8361779451370239, "action": 0.9770289659500122}
{"mode": "train", "epochs": 1, "timestep": 1917, "ep_reward": 1069.9163818359375, "reward": 0.8631223440170288, "action": 0.763191819190979}
{"mode": "train", "epochs": 1, "timestep": 1918, "ep_reward": 1070.792236328125, "reward": 0.8758478164672852, "action": 1.6137183904647827}
{"mode": "train", "epochs": 1, "timestep": 1919, "ep_reward": 1071.658447265625, "reward": 0.8661810159683228, "action": 0.2484452724456787}
{"mode": "train", "epochs": 1, "timestep": 1920, "ep_reward": 1072.5093994140625, "reward": 0.8509813547134399, "action": 0.4770228862762451}
{"mode": "train", "epochs": 1, "timestep": 1921, "ep_reward": 1073.3236083984375, "reward": 0.8142237663269043, "action": 1.7020914554595947}
{"mode": "train", "epochs": 1, "timestep": 1922, "ep_reward": 1074.0633544921875, "reward": 0.7397885322570801, "action": 1.0184741020202637}
{"mode": "train", "epochs": 1, "timestep": 1923, "ep_reward": 1074.7022705078125, "reward": 0.638926088809967, "action": 0.03702723979949951}
{"mode": "train", "epochs": 1, "timestep": 1924, "ep_reward": 1075.2156982421875, "reward": 0.5134105682373047, "action": 1.4366618394851685}
{"mode": "train", "epochs": 1, "timestep": 1925, "ep_reward": 1075.56640625, "reward": 0.3506835103034973, "action": 0.5851644277572632}
{"mode": "train", "epochs": 1, "timestep": 1926, "ep_reward": 1075.80712890625, "reward": 0.24071508646011353, "action": 1.4572627544403076}
{"mode": "train", "epochs": 1, "timestep": 1927, "ep_reward": 1075.9180908203125, "reward": 0.11098378896713257, "action": 0.34800148010253906}
{"mode": "train", "epochs": 1, "timestep": 1928, "ep_reward": 1075.9227294921875, "reward": 0.004677712917327881, "action": 1.2662972211837769}
{"mode": "train", "epochs": 1, "timestep": 1929, "ep_reward": 1076.07177734375, "reward": 0.1490478515625, "action": 0.6851697564125061}
{"mode": "train", "epochs": 1, "timestep": 1930, "ep_reward": 1076.3642578125, "reward": 0.292499840259552, "action": 0.6025802493095398}
{"mode": "train", "epochs": 1, "timestep": 1931, "ep_reward": 1076.79736328125, "reward": 0.4331611394882202, "action": 1.744690179824829}
{"mode": "train", "epochs": 1, "timestep": 1932, "ep_reward": 1077.3450927734375, "reward": 0.5477584600448608, "action": 0.9214122295379639}
{"mode": "train", "epochs": 1, "timestep": 1933, "ep_reward": 1077.9990234375, "reward": 0.6539250612258911, "action": -0.012951493263244629}
{"mode": "train", "epochs": 1, "timestep": 1934, "ep_reward": 1078.7452392578125, "reward": 0.7461698055267334, "action": 1.3108503818511963}
{"mode": "train", "epochs": 1, "timestep": 1935, "ep_reward": 1079.5479736328125, "reward": 0.8027487397193909, "action": 1.7178795337677002}
{"mode": "train", "epochs": 1, "timestep": 1936, "ep_reward": 1080.3851318359375, "reward": 0.8371712565422058, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1937, "ep_reward": 1081.237548828125, "reward": 0.8524224162101746, "action": 1.5692880153656006}
{"mode": "train", "epochs": 1, "timestep": 1938, "ep_reward": 1082.0919189453125, "reward": 0.8543611764907837, "action": 1.4077396392822266}
{"mode": "train", "epochs": 1, "timestep": 1939, "ep_reward": 1082.9310302734375, "reward": 0.8391266465187073, "action": 1.6108697652816772}
{"mode": "train", "epochs": 1, "timestep": 1940, "ep_reward": 1083.7310791015625, "reward": 0.8000355958938599, "action": 0.2081155776977539}
{"mode": "train", "epochs": 1, "timestep": 1941, "ep_reward": 1084.4801025390625, "reward": 0.7489997148513794, "action": 0.9387551546096802}
{"mode": "train", "epochs": 1, "timestep": 1942, "ep_reward": 1085.1385498046875, "reward": 0.6584292650222778, "action": 0.34987133741378784}
{"mode": "train", "epochs": 1, "timestep": 1943, "ep_reward": 1085.6761474609375, "reward": 0.5375779867172241, "action": 0.9857680797576904}
{"mode": "train", "epochs": 1, "timestep": 1944, "ep_reward": 1086.055908203125, "reward": 0.37977665662765503, "action": -0.18519854545593262}
{"mode": "train", "epochs": 1, "timestep": 1945, "ep_reward": 1086.331787109375, "reward": 0.275881826877594, "action": 0.742969810962677}
{"mode": "train", "epochs": 1, "timestep": 1946, "ep_reward": 1086.4837646484375, "reward": 0.15202069282531738, "action": 0.9058088064193726}
{"mode": "train", "epochs": 1, "timestep": 1947, "ep_reward": 1086.491943359375, "reward": 0.008153736591339111, "action": 0.9288703203201294}
{"mode": "train", "epochs": 1, "timestep": 1948, "ep_reward": 1086.599853515625, "reward": 0.10785937309265137, "action": 0.6263116598129272}
{"mode": "train", "epochs": 1, "timestep": 1949, "ep_reward": 1086.850830078125, "reward": 0.25102829933166504, "action": 0.2685737609863281}
{"mode": "train", "epochs": 1, "timestep": 1950, "ep_reward": 1087.2484130859375, "reward": 0.3975484371185303, "action": 1.139607310295105}
{"mode": "train", "epochs": 1, "timestep": 1951, "ep_reward": 1087.7708740234375, "reward": 0.5224773287773132, "action": 1.3051340579986572}
{"mode": "train", "epochs": 1, "timestep": 1952, "ep_reward": 1088.3997802734375, "reward": 0.6288565993309021, "action": 1.6223711967468262}
{"mode": "train", "epochs": 1, "timestep": 1953, "ep_reward": 1089.1114501953125, "reward": 0.711650550365448, "action": 1.6968140602111816}
{"mode": "train", "epochs": 1, "timestep": 1954, "ep_reward": 1089.8846435546875, "reward": 0.7731799483299255, "action": 0.849786639213562}
{"mode": "train", "epochs": 1, "timestep": 1955, "ep_reward": 1090.70703125, "reward": 0.8223463892936707, "action": 0.9196794033050537}
{"mode": "train", "epochs": 1, "timestep": 1956, "ep_reward": 1091.558837890625, "reward": 0.8518320322036743, "action": 1.04604971408844}
{"mode": "train", "epochs": 1, "timestep": 1957, "ep_reward": 1092.4219970703125, "reward": 0.8631031513214111, "action": 0.83714759349823}
{"mode": "train", "epochs": 1, "timestep": 1958, "ep_reward": 1093.28125, "reward": 0.8592351675033569, "action": 1.2419778108596802}
{"mode": "train", "epochs": 1, "timestep": 1959, "ep_reward": 1094.1143798828125, "reward": 0.8331812620162964, "action": 1.273144245147705}
{"mode": "train", "epochs": 1, "timestep": 1960, "ep_reward": 1094.898193359375, "reward": 0.783778190612793, "action": 0.9711690545082092}
{"mode": "train", "epochs": 1, "timestep": 1961, "ep_reward": 1095.606689453125, "reward": 0.7085007429122925, "action": 0.7579333782196045}
{"mode": "train", "epochs": 1, "timestep": 1962, "ep_reward": 1096.2071533203125, "reward": 0.6004041433334351, "action": 1.657423496246338}
{"mode": "train", "epochs": 1, "timestep": 1963, "ep_reward": 1096.6451416015625, "reward": 0.437935471534729, "action": 0.29590147733688354}
{"mode": "train", "epochs": 1, "timestep": 1964, "ep_reward": 1096.96875, "reward": 0.3236463665962219, "action": 0.8771533966064453}
{"mode": "train", "epochs": 1, "timestep": 1965, "ep_reward": 1097.17724609375, "reward": 0.20852148532867432, "action": 0.7571855187416077}
{"mode": "train", "epochs": 1, "timestep": 1966, "ep_reward": 1097.2506103515625, "reward": 0.07341760396957397, "action": 0.036693453788757324}
{"mode": "train", "epochs": 1, "timestep": 1967, "ep_reward": 1097.2952880859375, "reward": 0.04473453760147095, "action": 0.8595777750015259}
{"mode": "train", "epochs": 1, "timestep": 1968, "ep_reward": 1097.47900390625, "reward": 0.1837148666381836, "action": 1.2635440826416016}
{"mode": "train", "epochs": 1, "timestep": 1969, "ep_reward": 1097.7996826171875, "reward": 0.32064902782440186, "action": 0.40484344959259033}
{"mode": "train", "epochs": 1, "timestep": 1970, "ep_reward": 1098.262939453125, "reward": 0.46324896812438965, "action": 0.3710417151451111}
{"mode": "train", "epochs": 1, "timestep": 1971, "ep_reward": 1098.8521728515625, "reward": 0.5892479419708252, "action": 1.6479418277740479}
{"mode": "train", "epochs": 1, "timestep": 1972, "ep_reward": 1099.5323486328125, "reward": 0.6801367998123169, "action": 0.6721456050872803}
{"mode": "train", "epochs": 1, "timestep": 1973, "ep_reward": 1100.2918701171875, "reward": 0.7594624757766724, "action": 0.9878585934638977}
{"mode": "train", "epochs": 1, "timestep": 1974, "ep_reward": 1101.10595703125, "reward": 0.8140442371368408, "action": 0.7570949196815491}
{"mode": "train", "epochs": 1, "timestep": 1975, "ep_reward": 1101.9576416015625, "reward": 0.8516762256622314, "action": 0.45773792266845703}
{"mode": "train", "epochs": 1, "timestep": 1976, "ep_reward": 1102.8323974609375, "reward": 0.8748040795326233, "action": 1.486688256263733}
{"mode": "train", "epochs": 1, "timestep": 1977, "ep_reward": 1103.7069091796875, "reward": 0.8744850158691406, "action": 0.3966137170791626}
{"mode": "train", "epochs": 1, "timestep": 1978, "ep_reward": 1104.5743408203125, "reward": 0.8673803806304932, "action": 1.0314044952392578}
{"mode": "train", "epochs": 1, "timestep": 1979, "ep_reward": 1105.4114990234375, "reward": 0.8371880054473877, "action": 1.1579766273498535}
{"mode": "train", "epochs": 1, "timestep": 1980, "ep_reward": 1106.19482421875, "reward": 0.7833520174026489, "action": 0.5803933143615723}
{"mode": "train", "epochs": 1, "timestep": 1981, "ep_reward": 1106.902099609375, "reward": 0.7072527408599854, "action": 1.287630319595337}
{"mode": "train", "epochs": 1, "timestep": 1982, "ep_reward": 1107.489990234375, "reward": 0.5878788232803345, "action": 0.022837042808532715}
{"mode": "train", "epochs": 1, "timestep": 1983, "ep_reward": 1107.9364013671875, "reward": 0.4464564919471741, "action": 1.0267586708068848}
{"mode": "train", "epochs": 1, "timestep": 1984, "ep_reward": 1108.242919921875, "reward": 0.3065088391304016, "action": 1.0125038623809814}
{"mode": "train", "epochs": 1, "timestep": 1985, "ep_reward": 1108.4310302734375, "reward": 0.188154935836792, "action": 1.0757956504821777}
{"mode": "train", "epochs": 1, "timestep": 1986, "ep_reward": 1108.48095703125, "reward": 0.04987776279449463, "action": 0.15121638774871826}
{"mode": "train", "epochs": 1, "timestep": 1987, "ep_reward": 1108.5494384765625, "reward": 0.06842851638793945, "action": 0.10563677549362183}
{"mode": "train", "epochs": 1, "timestep": 1988, "ep_reward": 1108.7662353515625, "reward": 0.21684259176254272, "action": 0.7063565254211426}
{"mode": "train", "epochs": 1, "timestep": 1989, "ep_reward": 1109.124267578125, "reward": 0.3580716848373413, "action": 1.4278602600097656}
{"mode": "train", "epochs": 1, "timestep": 1990, "ep_reward": 1109.6075439453125, "reward": 0.4833267331123352, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1991, "ep_reward": 1110.1959228515625, "reward": 0.5883979797363281, "action": 1.623673677444458}
{"mode": "train", "epochs": 1, "timestep": 1992, "ep_reward": 1110.875, "reward": 0.6790990829467773, "action": 1.1235030889511108}
{"mode": "train", "epochs": 1, "timestep": 1993, "ep_reward": 1111.6279296875, "reward": 0.7528842091560364, "action": 1.383418083190918}
{"mode": "train", "epochs": 1, "timestep": 1994, "ep_reward": 1112.4300537109375, "reward": 0.8021606206893921, "action": 1.3279263973236084}
{"mode": "train", "epochs": 1, "timestep": 1995, "ep_reward": 1113.2620849609375, "reward": 0.8319804072380066, "action": 0.4527077078819275}
{"mode": "train", "epochs": 1, "timestep": 1996, "ep_reward": 1114.1126708984375, "reward": 0.8505954146385193, "action": 1.2427473068237305}
{"mode": "train", "epochs": 1, "timestep": 1997, "ep_reward": 1114.9560546875, "reward": 0.8433964252471924, "action": 1.3799787759780884}
{"mode": "train", "epochs": 1, "timestep": 1998, "ep_reward": 1115.770263671875, "reward": 0.8141657710075378, "action": 0.9101725816726685}
{"mode": "train", "epochs": 1, "timestep": 1999, "ep_reward": 1116.5347900390625, "reward": 0.7644892930984497, "action": 0.9804326295852661}
{"mode": "train", "epochs": 1, "timestep": 2000, "ep_reward": 1117.2178955078125, "reward": 0.6831238269805908, "action": 1.3956043720245361}
{"mode": "train", "epochs": 2, "timestep": 2001, "ep_reward": 0.4822601079940796, "reward": 0.4822601079940796, "action": 1.209773063659668}
{"mode": "train", "epochs": 2, "timestep": 2002, "ep_reward": 0.9518183469772339, "reward": 0.4695582389831543, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2003, "ep_reward": 1.412292242050171, "reward": 0.460473895072937, "action": 0.8708263039588928}
{"mode": "train", "epochs": 2, "timestep": 2004, "ep_reward": 1.8617615699768066, "reward": 0.44946932792663574, "action": 0.9667302966117859}
{"mode": "train", "epochs": 2, "timestep": 2005, "ep_reward": 2.30060076713562, "reward": 0.4388391971588135, "action": 0.913810133934021}
{"mode": "train", "epochs": 2, "timestep": 2006, "ep_reward": 2.729255199432373, "reward": 0.42865443229675293, "action": 0.8803626298904419}
{"mode": "train", "epochs": 2, "timestep": 2007, "ep_reward": 3.148456573486328, "reward": 0.41920143365859985, "action": 1.0519399642944336}
{"mode": "train", "epochs": 2, "timestep": 2008, "ep_reward": 3.560016632080078, "reward": 0.41156005859375, "action": 0.9055180549621582}
{"mode": "train", "epochs": 2, "timestep": 2009, "ep_reward": 3.9652938842773438, "reward": 0.40527719259262085, "action": 0.547616720199585}
{"mode": "train", "epochs": 2, "timestep": 2010, "ep_reward": 4.36472225189209, "reward": 0.39942842721939087, "action": 0.6392656564712524}
{"mode": "train", "epochs": 2, "timestep": 2011, "ep_reward": 4.759581565856934, "reward": 0.3948591351509094, "action": 0.5667917728424072}
{"mode": "train", "epochs": 2, "timestep": 2012, "ep_reward": 5.150965213775635, "reward": 0.39138364791870117, "action": 0.9202513098716736}
{"mode": "train", "epochs": 2, "timestep": 2013, "ep_reward": 5.541316509246826, "reward": 0.3903512954711914, "action": 0.7270567417144775}
{"mode": "train", "epochs": 2, "timestep": 2014, "ep_reward": 5.932285308837891, "reward": 0.3909689784049988, "action": 0.8877583146095276}
{"mode": "train", "epochs": 2, "timestep": 2015, "ep_reward": 6.326004505157471, "reward": 0.3937190771102905, "action": 1.133206844329834}
{"mode": "train", "epochs": 2, "timestep": 2016, "ep_reward": 6.725113868713379, "reward": 0.39910924434661865, "action": 1.0915333032608032}
{"mode": "train", "epochs": 2, "timestep": 2017, "ep_reward": 7.1319403648376465, "reward": 0.40682655572891235, "action": 1.0531424283981323}
{"mode": "train", "epochs": 2, "timestep": 2018, "ep_reward": 7.548407077789307, "reward": 0.4164668917655945, "action": 1.356471061706543}
{"mode": "train", "epochs": 2, "timestep": 2019, "ep_reward": 7.976702690124512, "reward": 0.42829573154449463, "action": 1.078745722770691}
{"mode": "train", "epochs": 2, "timestep": 2020, "ep_reward": 8.41840648651123, "reward": 0.4417033791542053, "action": 0.25825220346450806}
{"mode": "train", "epochs": 2, "timestep": 2021, "ep_reward": 8.873051643371582, "reward": 0.45464539527893066, "action": 0.8378355503082275}
{"mode": "train", "epochs": 2, "timestep": 2022, "ep_reward": 9.339548110961914, "reward": 0.4664967656135559, "action": 1.353133201599121}
{"mode": "train", "epochs": 2, "timestep": 2023, "ep_reward": 9.81795597076416, "reward": 0.4784082770347595, "action": 1.6308488845825195}
{"mode": "train", "epochs": 2, "timestep": 2024, "ep_reward": 10.30897331237793, "reward": 0.4910171627998352, "action": 1.3695828914642334}
{"mode": "train", "epochs": 2, "timestep": 2025, "ep_reward": 10.812761306762695, "reward": 0.5037879943847656, "action": 1.0220551490783691}
{"mode": "train", "epochs": 2, "timestep": 2026, "ep_reward": 11.328136444091797, "reward": 0.515375018119812, "action": 1.1342955827713013}
{"mode": "train", "epochs": 2, "timestep": 2027, "ep_reward": 11.853333473205566, "reward": 0.5251966714859009, "action": 0.17697370052337646}
{"mode": "train", "epochs": 2, "timestep": 2028, "ep_reward": 12.38419246673584, "reward": 0.5308593511581421, "action": 1.6013550758361816}
{"mode": "train", "epochs": 2, "timestep": 2029, "ep_reward": 12.918952941894531, "reward": 0.5347601175308228, "action": 0.5417691469192505}
{"mode": "train", "epochs": 2, "timestep": 2030, "ep_reward": 13.45358943939209, "reward": 0.5346361994743347, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2031, "ep_reward": 13.988174438476562, "reward": 0.5345849394798279, "action": 1.311408519744873}
{"mode": "train", "epochs": 2, "timestep": 2032, "ep_reward": 14.520805358886719, "reward": 0.5326305627822876, "action": 0.24833893775939941}
{"mode": "train", "epochs": 2, "timestep": 2033, "ep_reward": 15.046067237854004, "reward": 0.5252615213394165, "action": 1.472650170326233}
{"mode": "train", "epochs": 2, "timestep": 2034, "ep_reward": 15.563427925109863, "reward": 0.517361044883728, "action": 1.470571517944336}
{"mode": "train", "epochs": 2, "timestep": 2035, "ep_reward": 16.072160720825195, "reward": 0.5087335109710693, "action": 0.13194429874420166}
{"mode": "train", "epochs": 2, "timestep": 2036, "ep_reward": 16.56635856628418, "reward": 0.49419790506362915, "action": 1.4518071413040161}
{"mode": "train", "epochs": 2, "timestep": 2037, "ep_reward": 17.04761505126953, "reward": 0.48125553131103516, "action": 0.6876553297042847}
{"mode": "train", "epochs": 2, "timestep": 2038, "ep_reward": 17.51300048828125, "reward": 0.4653850197792053, "action": 1.0237013101577759}
{"mode": "train", "epochs": 2, "timestep": 2039, "ep_reward": 17.96282196044922, "reward": 0.4498217701911926, "action": 0.8478631973266602}
{"mode": "train", "epochs": 2, "timestep": 2040, "ep_reward": 18.39659309387207, "reward": 0.4337719678878784, "action": 1.3218662738800049}
{"mode": "train", "epochs": 2, "timestep": 2041, "ep_reward": 18.816896438598633, "reward": 0.4203037619590759, "action": 1.4241751432418823}
{"mode": "train", "epochs": 2, "timestep": 2042, "ep_reward": 19.226451873779297, "reward": 0.40955597162246704, "action": 1.071716070175171}
{"mode": "train", "epochs": 2, "timestep": 2043, "ep_reward": 19.62673568725586, "reward": 0.4002842307090759, "action": 0.743238627910614}
{"mode": "train", "epochs": 2, "timestep": 2044, "ep_reward": 20.018768310546875, "reward": 0.39203304052352905, "action": 0.9604983329772949}
{"mode": "train", "epochs": 2, "timestep": 2045, "ep_reward": 20.405080795288086, "reward": 0.38631170988082886, "action": 1.0732120275497437}
{"mode": "train", "epochs": 2, "timestep": 2046, "ep_reward": 20.78852653503418, "reward": 0.3834453821182251, "action": 1.1932621002197266}
{"mode": "train", "epochs": 2, "timestep": 2047, "ep_reward": 21.172378540039062, "reward": 0.3838523030281067, "action": 0.6482856273651123}
{"mode": "train", "epochs": 2, "timestep": 2048, "ep_reward": 21.558189392089844, "reward": 0.3858106732368469, "action": 0.8459661602973938}
{"mode": "train", "epochs": 2, "timestep": 2049, "ep_reward": 21.94818878173828, "reward": 0.3899996876716614, "action": 0.5866414904594421}
{"mode": "train", "epochs": 2, "timestep": 2050, "ep_reward": 22.34357452392578, "reward": 0.395386278629303, "action": 1.9369702339172363}
{"mode": "train", "epochs": 2, "timestep": 2051, "ep_reward": 22.748674392700195, "reward": 0.4050990343093872, "action": 0.6039013266563416}
{"mode": "train", "epochs": 2, "timestep": 2052, "ep_reward": 23.165132522583008, "reward": 0.41645753383636475, "action": 0.5936193466186523}
{"mode": "train", "epochs": 2, "timestep": 2053, "ep_reward": 23.593360900878906, "reward": 0.42822813987731934, "action": 0.8155956268310547}
{"mode": "train", "epochs": 2, "timestep": 2054, "ep_reward": 24.033679962158203, "reward": 0.44031858444213867, "action": 1.1919556856155396}
{"mode": "train", "epochs": 2, "timestep": 2055, "ep_reward": 24.486774444580078, "reward": 0.45309436321258545, "action": 1.6054010391235352}
{"mode": "train", "epochs": 2, "timestep": 2056, "ep_reward": 24.953981399536133, "reward": 0.4672061800956726, "action": 1.2648733854293823}
{"mode": "train", "epochs": 2, "timestep": 2057, "ep_reward": 25.43613052368164, "reward": 0.4821498990058899, "action": 0.9360563158988953}
{"mode": "train", "epochs": 2, "timestep": 2058, "ep_reward": 25.932655334472656, "reward": 0.4965254068374634, "action": 0.8175468444824219}
{"mode": "train", "epochs": 2, "timestep": 2059, "ep_reward": 26.4417724609375, "reward": 0.5091174840927124, "action": 1.0041824579238892}
{"mode": "train", "epochs": 2, "timestep": 2060, "ep_reward": 26.961380004882812, "reward": 0.5196073055267334, "action": 1.016309380531311}
{"mode": "train", "epochs": 2, "timestep": 2061, "ep_reward": 27.489294052124023, "reward": 0.5279146432876587, "action": 0.544939398765564}
{"mode": "train", "epochs": 2, "timestep": 2062, "ep_reward": 28.021968841552734, "reward": 0.53267502784729, "action": 0.49941378831863403}
{"mode": "train", "epochs": 2, "timestep": 2063, "ep_reward": 28.554931640625, "reward": 0.5329631567001343, "action": 1.4526457786560059}
{"mode": "train", "epochs": 2, "timestep": 2064, "ep_reward": 29.08669090270996, "reward": 0.5317597389221191, "action": 0.48573803901672363}
{"mode": "train", "epochs": 2, "timestep": 2065, "ep_reward": 29.612838745117188, "reward": 0.5261470079421997, "action": 0.28452467918395996}
{"mode": "train", "epochs": 2, "timestep": 2066, "ep_reward": 30.128326416015625, "reward": 0.5154883861541748, "action": 1.018721103668213}
{"mode": "train", "epochs": 2, "timestep": 2067, "ep_reward": 30.63156509399414, "reward": 0.5032392144203186, "action": 0.963206946849823}
{"mode": "train", "epochs": 2, "timestep": 2068, "ep_reward": 31.12059211730957, "reward": 0.489027738571167, "action": 1.294790506362915}
{"mode": "train", "epochs": 2, "timestep": 2069, "ep_reward": 31.595548629760742, "reward": 0.47495633363723755, "action": 1.2190752029418945}
{"mode": "train", "epochs": 2, "timestep": 2070, "ep_reward": 32.05638122558594, "reward": 0.460834264755249, "action": -0.18079984188079834}
{"mode": "train", "epochs": 2, "timestep": 2071, "ep_reward": 32.49732208251953, "reward": 0.4409402012825012, "action": 0.7390034198760986}
{"mode": "train", "epochs": 2, "timestep": 2072, "ep_reward": 32.91957473754883, "reward": 0.4222533702850342, "action": 1.74013090133667}
{"mode": "train", "epochs": 2, "timestep": 2073, "ep_reward": 33.32859420776367, "reward": 0.409021258354187, "action": 0.289164662361145}
{"mode": "train", "epochs": 2, "timestep": 2074, "ep_reward": 33.721622467041016, "reward": 0.3930289149284363, "action": 0.5343607664108276}
{"mode": "train", "epochs": 2, "timestep": 2075, "ep_reward": 34.10184860229492, "reward": 0.3802272081375122, "action": 1.4053030014038086}
{"mode": "train", "epochs": 2, "timestep": 2076, "ep_reward": 34.494651794433594, "reward": 0.39280205965042114, "action": 1.600441813468933}
{"mode": "train", "epochs": 2, "timestep": 2077, "ep_reward": 34.894683837890625, "reward": 0.40003228187561035, "action": 0.34798210859298706}
{"mode": "train", "epochs": 2, "timestep": 2078, "ep_reward": 35.29896545410156, "reward": 0.40428221225738525, "action": 0.7123281359672546}
{"mode": "train", "epochs": 2, "timestep": 2079, "ep_reward": 35.704586029052734, "reward": 0.405619740486145, "action": 1.146536111831665}
{"mode": "train", "epochs": 2, "timestep": 2080, "ep_reward": 36.10710906982422, "reward": 0.4025247097015381, "action": 0.6984544992446899}
{"mode": "train", "epochs": 2, "timestep": 2081, "ep_reward": 36.503353118896484, "reward": 0.3962438702583313, "action": 1.3936253786087036}
{"mode": "train", "epochs": 2, "timestep": 2082, "ep_reward": 36.88807678222656, "reward": 0.38472235202789307, "action": -0.17111778259277344}
{"mode": "train", "epochs": 2, "timestep": 2083, "ep_reward": 37.276180267333984, "reward": 0.3881016969680786, "action": 1.389293909072876}
{"mode": "train", "epochs": 2, "timestep": 2084, "ep_reward": 37.676639556884766, "reward": 0.4004594087600708, "action": 0.979301393032074}
{"mode": "train", "epochs": 2, "timestep": 2085, "ep_reward": 38.091793060302734, "reward": 0.41515374183654785, "action": 0.619450569152832}
{"mode": "train", "epochs": 2, "timestep": 2086, "ep_reward": 38.52259063720703, "reward": 0.43079668283462524, "action": 0.8801612854003906}
{"mode": "train", "epochs": 2, "timestep": 2087, "ep_reward": 38.96920394897461, "reward": 0.44661426544189453, "action": 1.5661031007766724}
{"mode": "train", "epochs": 2, "timestep": 2088, "ep_reward": 39.4326171875, "reward": 0.46341389417648315, "action": 0.8492977619171143}
{"mode": "train", "epochs": 2, "timestep": 2089, "ep_reward": 39.91338348388672, "reward": 0.48076456785202026, "action": 0.25685471296310425}
{"mode": "train", "epochs": 2, "timestep": 2090, "ep_reward": 40.409339904785156, "reward": 0.49595677852630615, "action": 1.744856357574463}
{"mode": "train", "epochs": 2, "timestep": 2091, "ep_reward": 40.918922424316406, "reward": 0.5095844268798828, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2092, "ep_reward": 41.44260787963867, "reward": 0.5236841440200806, "action": 1.9118986129760742}
{"mode": "train", "epochs": 2, "timestep": 2093, "ep_reward": 41.9805908203125, "reward": 0.5379819869995117, "action": 1.7891168594360352}
{"mode": "train", "epochs": 2, "timestep": 2094, "ep_reward": 42.53245544433594, "reward": 0.5518659353256226, "action": 0.7691513299942017}
{"mode": "train", "epochs": 2, "timestep": 2095, "ep_reward": 43.09556198120117, "reward": 0.5631067156791687, "action": 0.028881072998046875}
{"mode": "train", "epochs": 2, "timestep": 2096, "ep_reward": 43.66354751586914, "reward": 0.5679866075515747, "action": 1.5757051706314087}
{"mode": "train", "epochs": 2, "timestep": 2097, "ep_reward": 44.23305130004883, "reward": 0.5695039629936218, "action": 0.4957103133201599}
{"mode": "train", "epochs": 2, "timestep": 2098, "ep_reward": 44.798431396484375, "reward": 0.5653799772262573, "action": 1.442233681678772}
{"mode": "train", "epochs": 2, "timestep": 2099, "ep_reward": 45.35710906982422, "reward": 0.5586773157119751, "action": 1.312996745109558}
{"mode": "train", "epochs": 2, "timestep": 2100, "ep_reward": 45.906192779541016, "reward": 0.5490853786468506, "action": 0.7409221529960632}
{"mode": "train", "epochs": 2, "timestep": 2101, "ep_reward": 46.44084548950195, "reward": 0.5346542596817017, "action": 0.7450004816055298}
{"mode": "train", "epochs": 2, "timestep": 2102, "ep_reward": 46.95708084106445, "reward": 0.5162348747253418, "action": 1.564443588256836}
{"mode": "train", "epochs": 2, "timestep": 2103, "ep_reward": 47.45568084716797, "reward": 0.4986013174057007, "action": 1.1177324056625366}
{"mode": "train", "epochs": 2, "timestep": 2104, "ep_reward": 47.934532165527344, "reward": 0.4788510799407959, "action": 1.0239577293395996}
{"mode": "train", "epochs": 2, "timestep": 2105, "ep_reward": 48.39268493652344, "reward": 0.45815402269363403, "action": 0.5645989179611206}
{"mode": "train", "epochs": 2, "timestep": 2106, "ep_reward": 48.82780838012695, "reward": 0.4351232647895813, "action": 0.6652947664260864}
{"mode": "train", "epochs": 2, "timestep": 2107, "ep_reward": 49.23984909057617, "reward": 0.4120404124259949, "action": 1.3942152261734009}
{"mode": "train", "epochs": 2, "timestep": 2108, "ep_reward": 49.633384704589844, "reward": 0.39353519678115845, "action": 0.44566845893859863}
{"mode": "train", "epochs": 2, "timestep": 2109, "ep_reward": 50.01244354248047, "reward": 0.37905967235565186, "action": 0.8279044032096863}
{"mode": "train", "epochs": 2, "timestep": 2110, "ep_reward": 50.4107666015625, "reward": 0.39832353591918945, "action": 0.49564361572265625}
{"mode": "train", "epochs": 2, "timestep": 2111, "ep_reward": 50.82551574707031, "reward": 0.4147498607635498, "action": 0.8163830637931824}
{"mode": "train", "epochs": 2, "timestep": 2112, "ep_reward": 51.25339889526367, "reward": 0.42788374423980713, "action": 0.5899325609207153}
{"mode": "train", "epochs": 2, "timestep": 2113, "ep_reward": 51.69038009643555, "reward": 0.4369824528694153, "action": 0.8000808358192444}
{"mode": "train", "epochs": 2, "timestep": 2114, "ep_reward": 52.131919860839844, "reward": 0.44154107570648193, "action": 0.7385217547416687}
{"mode": "train", "epochs": 2, "timestep": 2115, "ep_reward": 52.5731086730957, "reward": 0.44118988513946533, "action": 1.1429741382598877}
{"mode": "train", "epochs": 2, "timestep": 2116, "ep_reward": 53.007869720458984, "reward": 0.4347623586654663, "action": 0.611504077911377}
{"mode": "train", "epochs": 2, "timestep": 2117, "ep_reward": 53.43206024169922, "reward": 0.424191951751709, "action": 0.7669385671615601}
{"mode": "train", "epochs": 2, "timestep": 2118, "ep_reward": 53.841304779052734, "reward": 0.40924394130706787, "action": 0.940797746181488}
{"mode": "train", "epochs": 2, "timestep": 2119, "ep_reward": 54.23109436035156, "reward": 0.3897891044616699, "action": 1.27664053440094}
{"mode": "train", "epochs": 2, "timestep": 2120, "ep_reward": 54.61643600463867, "reward": 0.385342001914978, "action": 0.39883673191070557}
{"mode": "train", "epochs": 2, "timestep": 2121, "ep_reward": 55.02354049682617, "reward": 0.4071047902107239, "action": 0.04714655876159668}
{"mode": "train", "epochs": 2, "timestep": 2122, "ep_reward": 55.452239990234375, "reward": 0.42870140075683594, "action": 0.9684790968894958}
{"mode": "train", "epochs": 2, "timestep": 2123, "ep_reward": 55.901546478271484, "reward": 0.44930821657180786, "action": 1.4289464950561523}
{"mode": "train", "epochs": 2, "timestep": 2124, "ep_reward": 56.372032165527344, "reward": 0.470486044883728, "action": 0.6885110139846802}
{"mode": "train", "epochs": 2, "timestep": 2125, "ep_reward": 56.86380386352539, "reward": 0.4917726516723633, "action": 1.3053399324417114}
{"mode": "train", "epochs": 2, "timestep": 2126, "ep_reward": 57.375247955322266, "reward": 0.5114444494247437, "action": 0.4380061626434326}
{"mode": "train", "epochs": 2, "timestep": 2127, "ep_reward": 57.90446472167969, "reward": 0.529217541217804, "action": -0.4262250065803528}
{"mode": "train", "epochs": 2, "timestep": 2128, "ep_reward": 58.445621490478516, "reward": 0.5411584377288818, "action": 1.601011037826538}
{"mode": "train", "epochs": 2, "timestep": 2129, "ep_reward": 58.994850158691406, "reward": 0.5492304563522339, "action": 0.9349249005317688}
{"mode": "train", "epochs": 2, "timestep": 2130, "ep_reward": 59.54918670654297, "reward": 0.5543375015258789, "action": 0.4852001667022705}
{"mode": "train", "epochs": 2, "timestep": 2131, "ep_reward": 60.1036376953125, "reward": 0.5544508695602417, "action": 0.7535606026649475}
{"mode": "train", "epochs": 2, "timestep": 2132, "ep_reward": 60.65367889404297, "reward": 0.5500419735908508, "action": 0.14060813188552856}
{"mode": "train", "epochs": 2, "timestep": 2133, "ep_reward": 61.19275665283203, "reward": 0.539078414440155, "action": 0.9418702721595764}
{"mode": "train", "epochs": 2, "timestep": 2134, "ep_reward": 61.718013763427734, "reward": 0.5252563953399658, "action": 1.171034574508667}
{"mode": "train", "epochs": 2, "timestep": 2135, "ep_reward": 62.22758865356445, "reward": 0.5095755457878113, "action": 1.337057113647461}
{"mode": "train", "epochs": 2, "timestep": 2136, "ep_reward": 62.7206916809082, "reward": 0.49310195446014404, "action": 1.4653574228286743}
{"mode": "train", "epochs": 2, "timestep": 2137, "ep_reward": 63.19748306274414, "reward": 0.4767909049987793, "action": 1.568488597869873}
{"mode": "train", "epochs": 2, "timestep": 2138, "ep_reward": 63.659088134765625, "reward": 0.4616055488586426, "action": 0.9984424114227295}
{"mode": "train", "epochs": 2, "timestep": 2139, "ep_reward": 64.10435485839844, "reward": 0.44526898860931396, "action": 0.7850044369697571}
{"mode": "train", "epochs": 2, "timestep": 2140, "ep_reward": 64.53279876708984, "reward": 0.42844247817993164, "action": 0.4912499785423279}
{"mode": "train", "epochs": 2, "timestep": 2141, "ep_reward": 64.94351959228516, "reward": 0.410722017288208, "action": 0.8726031184196472}
{"mode": "train", "epochs": 2, "timestep": 2142, "ep_reward": 65.3386001586914, "reward": 0.39507871866226196, "action": 0.9890314340591431}
{"mode": "train", "epochs": 2, "timestep": 2143, "ep_reward": 65.72057342529297, "reward": 0.3819729685783386, "action": 0.3948313593864441}
{"mode": "train", "epochs": 2, "timestep": 2144, "ep_reward": 66.11180114746094, "reward": 0.3912285566329956, "action": 1.3866163492202759}
{"mode": "train", "epochs": 2, "timestep": 2145, "ep_reward": 66.51339721679688, "reward": 0.4015985131263733, "action": 1.258084774017334}
{"mode": "train", "epochs": 2, "timestep": 2146, "ep_reward": 66.92022705078125, "reward": 0.40682846307754517, "action": 1.4572136402130127}
{"mode": "train", "epochs": 2, "timestep": 2147, "ep_reward": 67.32659149169922, "reward": 0.4063636064529419, "action": 1.2440197467803955}
{"mode": "train", "epochs": 2, "timestep": 2148, "ep_reward": 67.7270736694336, "reward": 0.4004814028739929, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2149, "ep_reward": 68.11400604248047, "reward": 0.3869309425354004, "action": 1.4918979406356812}
{"mode": "train", "epochs": 2, "timestep": 2150, "ep_reward": 68.5029525756836, "reward": 0.3889429569244385, "action": 0.7375356554985046}
{"mode": "train", "epochs": 2, "timestep": 2151, "ep_reward": 68.90895080566406, "reward": 0.4059997797012329, "action": 0.6517853736877441}
{"mode": "train", "epochs": 2, "timestep": 2152, "ep_reward": 69.33303833007812, "reward": 0.42408472299575806, "action": 0.6558366417884827}
{"mode": "train", "epochs": 2, "timestep": 2153, "ep_reward": 69.77532958984375, "reward": 0.44229334592819214, "action": 1.6240524053573608}
{"mode": "train", "epochs": 2, "timestep": 2154, "ep_reward": 70.23651885986328, "reward": 0.4611862301826477, "action": 0.33054864406585693}
{"mode": "train", "epochs": 2, "timestep": 2155, "ep_reward": 70.71695709228516, "reward": 0.48043882846832275, "action": 0.8252562880516052}
{"mode": "train", "epochs": 2, "timestep": 2156, "ep_reward": 71.21428680419922, "reward": 0.49733251333236694, "action": 1.4083787202835083}
{"mode": "train", "epochs": 2, "timestep": 2157, "ep_reward": 71.72733306884766, "reward": 0.513042688369751, "action": 0.7649087905883789}
{"mode": "train", "epochs": 2, "timestep": 2158, "ep_reward": 72.25421142578125, "reward": 0.5268818140029907, "action": 1.8794056177139282}
{"mode": "train", "epochs": 2, "timestep": 2159, "ep_reward": 72.79338073730469, "reward": 0.539171576499939, "action": 1.7034817934036255}
{"mode": "train", "epochs": 2, "timestep": 2160, "ep_reward": 73.34410858154297, "reward": 0.5507242679595947, "action": 1.4178307056427002}
{"mode": "train", "epochs": 2, "timestep": 2161, "ep_reward": 73.90463256835938, "reward": 0.5605245232582092, "action": 0.41433775424957275}
{"mode": "train", "epochs": 2, "timestep": 2162, "ep_reward": 74.47019958496094, "reward": 0.5655637979507446, "action": 1.8073134422302246}
{"mode": "train", "epochs": 2, "timestep": 2163, "ep_reward": 75.03842163085938, "reward": 0.568225622177124, "action": 0.9254204034805298}
{"mode": "train", "epochs": 2, "timestep": 2164, "ep_reward": 75.60527801513672, "reward": 0.5668526291847229, "action": 0.4809805750846863}
{"mode": "train", "epochs": 2, "timestep": 2165, "ep_reward": 76.16493225097656, "reward": 0.5596519708633423, "action": 0.40341639518737793}
{"mode": "train", "epochs": 2, "timestep": 2166, "ep_reward": 76.71125793457031, "reward": 0.546322762966156, "action": 1.4118690490722656}
{"mode": "train", "epochs": 2, "timestep": 2167, "ep_reward": 77.24313354492188, "reward": 0.5318741798400879, "action": 0.8338810801506042}
{"mode": "train", "epochs": 2, "timestep": 2168, "ep_reward": 77.75627899169922, "reward": 0.5131442546844482, "action": 1.1292697191238403}
{"mode": "train", "epochs": 2, "timestep": 2169, "ep_reward": 78.24939727783203, "reward": 0.4931167960166931, "action": 0.738506555557251}
{"mode": "train", "epochs": 2, "timestep": 2170, "ep_reward": 78.71925354003906, "reward": 0.4698548913002014, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2171, "ep_reward": 79.17115783691406, "reward": 0.45190179347991943, "action": 0.9469119906425476}
{"mode": "train", "epochs": 2, "timestep": 2172, "ep_reward": 79.602783203125, "reward": 0.43162286281585693, "action": 0.31829947233200073}
{"mode": "train", "epochs": 2, "timestep": 2173, "ep_reward": 80.01175689697266, "reward": 0.40897607803344727, "action": 0.6423494815826416}
{"mode": "train", "epochs": 2, "timestep": 2174, "ep_reward": 80.3995361328125, "reward": 0.38778001070022583, "action": 0.9559284448623657}
{"mode": "train", "epochs": 2, "timestep": 2175, "ep_reward": 80.78337097167969, "reward": 0.38383811712265015, "action": 1.1339929103851318}
{"mode": "train", "epochs": 2, "timestep": 2176, "ep_reward": 81.18523406982422, "reward": 0.40186262130737305, "action": 0.5269201397895813}
{"mode": "train", "epochs": 2, "timestep": 2177, "ep_reward": 81.60157775878906, "reward": 0.41634488105773926, "action": 0.5567820072174072}
{"mode": "train", "epochs": 2, "timestep": 2178, "ep_reward": 82.02935028076172, "reward": 0.42777562141418457, "action": 0.8654409646987915}
{"mode": "train", "epochs": 2, "timestep": 2179, "ep_reward": 82.46440887451172, "reward": 0.4350551962852478, "action": -0.3192831873893738}
{"mode": "train", "epochs": 2, "timestep": 2180, "ep_reward": 82.90459442138672, "reward": 0.4401834011077881, "action": 1.138766884803772}
{"mode": "train", "epochs": 2, "timestep": 2181, "ep_reward": 83.34496307373047, "reward": 0.4403676986694336, "action": 0.8114158511161804}
{"mode": "train", "epochs": 2, "timestep": 2182, "ep_reward": 83.78026580810547, "reward": 0.43530213832855225, "action": 0.8656066656112671}
{"mode": "train", "epochs": 2, "timestep": 2183, "ep_reward": 84.2054443359375, "reward": 0.4251807928085327, "action": 0.671193540096283}
{"mode": "train", "epochs": 2, "timestep": 2184, "ep_reward": 84.61651611328125, "reward": 0.4110754132270813, "action": 1.3630633354187012}
{"mode": "train", "epochs": 2, "timestep": 2185, "ep_reward": 85.00712585449219, "reward": 0.3906065821647644, "action": 0.21172326803207397}
{"mode": "train", "epochs": 2, "timestep": 2186, "ep_reward": 85.39053344726562, "reward": 0.38340508937835693, "action": 1.1249847412109375}
{"mode": "train", "epochs": 2, "timestep": 2187, "ep_reward": 85.79405212402344, "reward": 0.4035215377807617, "action": 0.434670090675354}
{"mode": "train", "epochs": 2, "timestep": 2188, "ep_reward": 86.21932220458984, "reward": 0.4252685308456421, "action": 0.7333212494850159}
{"mode": "train", "epochs": 2, "timestep": 2189, "ep_reward": 86.66615295410156, "reward": 0.44683152437210083, "action": 0.4863622784614563}
{"mode": "train", "epochs": 2, "timestep": 2190, "ep_reward": 87.13396453857422, "reward": 0.4678090214729309, "action": 0.9636037945747375}
{"mode": "train", "epochs": 2, "timestep": 2191, "ep_reward": 87.62128448486328, "reward": 0.4873207211494446, "action": 1.029496431350708}
{"mode": "train", "epochs": 2, "timestep": 2192, "ep_reward": 88.12701416015625, "reward": 0.5057299137115479, "action": 0.6464614868164062}
{"mode": "train", "epochs": 2, "timestep": 2193, "ep_reward": 88.64908599853516, "reward": 0.5220693945884705, "action": -0.06510210037231445}
{"mode": "train", "epochs": 2, "timestep": 2194, "ep_reward": 89.18285369873047, "reward": 0.5337707996368408, "action": 1.3903224468231201}
{"mode": "train", "epochs": 2, "timestep": 2195, "ep_reward": 89.72490692138672, "reward": 0.5420538187026978, "action": 0.5758864879608154}
{"mode": "train", "epochs": 2, "timestep": 2196, "ep_reward": 90.27152252197266, "reward": 0.5466123819351196, "action": 1.0048834085464478}
{"mode": "train", "epochs": 2, "timestep": 2197, "ep_reward": 90.81916046142578, "reward": 0.5476342439651489, "action": 0.3586060404777527}
{"mode": "train", "epochs": 2, "timestep": 2198, "ep_reward": 91.36254119873047, "reward": 0.5433801412582397, "action": 0.510653018951416}
{"mode": "train", "epochs": 2, "timestep": 2199, "ep_reward": 91.89679718017578, "reward": 0.5342552661895752, "action": 0.36380553245544434}
{"mode": "train", "epochs": 2, "timestep": 2200, "ep_reward": 92.41671752929688, "reward": 0.5199171304702759, "action": 1.097703456878662}
{"mode": "train", "epochs": 2, "timestep": 2201, "ep_reward": 92.9209976196289, "reward": 0.5042766332626343, "action": 0.9166279435157776}
{"mode": "train", "epochs": 2, "timestep": 2202, "ep_reward": 93.40721130371094, "reward": 0.4862111806869507, "action": 1.4028956890106201}
{"mode": "train", "epochs": 2, "timestep": 2203, "ep_reward": 93.87628173828125, "reward": 0.46906787157058716, "action": 1.2583210468292236}
{"mode": "train", "epochs": 2, "timestep": 2204, "ep_reward": 94.32818603515625, "reward": 0.45190751552581787, "action": 1.3513203859329224}
{"mode": "train", "epochs": 2, "timestep": 2205, "ep_reward": 94.76438903808594, "reward": 0.43620622158050537, "action": -0.34002238512039185}
{"mode": "train", "epochs": 2, "timestep": 2206, "ep_reward": 95.1786880493164, "reward": 0.4142976403236389, "action": 1.30990731716156}
{"mode": "train", "epochs": 2, "timestep": 2207, "ep_reward": 95.57676696777344, "reward": 0.3980778455734253, "action": 0.8576036691665649}
{"mode": "train", "epochs": 2, "timestep": 2208, "ep_reward": 95.95953369140625, "reward": 0.38276952505111694, "action": 0.6556582450866699}
{"mode": "train", "epochs": 2, "timestep": 2209, "ep_reward": 96.34976959228516, "reward": 0.39023923873901367, "action": 0.303951621055603}
{"mode": "train", "epochs": 2, "timestep": 2210, "ep_reward": 96.75369262695312, "reward": 0.4039193391799927, "action": 1.4617148637771606}
{"mode": "train", "epochs": 2, "timestep": 2211, "ep_reward": 97.16749572753906, "reward": 0.4138057827949524, "action": 1.1582529544830322}
{"mode": "train", "epochs": 2, "timestep": 2212, "ep_reward": 97.58573913574219, "reward": 0.4182424545288086, "action": 0.425168514251709}
{"mode": "train", "epochs": 2, "timestep": 2213, "ep_reward": 98.00509643554688, "reward": 0.4193582534790039, "action": 0.8513204455375671}
{"mode": "train", "epochs": 2, "timestep": 2214, "ep_reward": 98.42134094238281, "reward": 0.4162447452545166, "action": 1.8847389221191406}
{"mode": "train", "epochs": 2, "timestep": 2215, "ep_reward": 98.82685852050781, "reward": 0.405514657497406, "action": 1.0182298421859741}
{"mode": "train", "epochs": 2, "timestep": 2216, "ep_reward": 99.21746063232422, "reward": 0.39060407876968384, "action": 0.9978604316711426}
{"mode": "train", "epochs": 2, "timestep": 2217, "ep_reward": 99.60225677490234, "reward": 0.3847975730895996, "action": 0.9896812438964844}
{"mode": "train", "epochs": 2, "timestep": 2218, "ep_reward": 100.00487518310547, "reward": 0.40261566638946533, "action": 0.7474974393844604}
{"mode": "train", "epochs": 2, "timestep": 2219, "ep_reward": 100.42684173583984, "reward": 0.4219678044319153, "action": 1.4120253324508667}
{"mode": "train", "epochs": 2, "timestep": 2220, "ep_reward": 100.86932373046875, "reward": 0.44248247146606445, "action": 0.9289505481719971}
{"mode": "train", "epochs": 2, "timestep": 2221, "ep_reward": 101.33335876464844, "reward": 0.46403181552886963, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2222, "ep_reward": 101.81929016113281, "reward": 0.4859318733215332, "action": -0.0012019872665405273}
{"mode": "train", "epochs": 2, "timestep": 2223, "ep_reward": 102.32770538330078, "reward": 0.5084165930747986, "action": 0.6558587551116943}
{"mode": "train", "epochs": 2, "timestep": 2224, "ep_reward": 102.85403442382812, "reward": 0.5263313055038452, "action": 1.4900121688842773}
{"mode": "train", "epochs": 2, "timestep": 2225, "ep_reward": 103.39576721191406, "reward": 0.5417357683181763, "action": 0.3989397883415222}
{"mode": "train", "epochs": 2, "timestep": 2226, "ep_reward": 103.94972229003906, "reward": 0.5539544224739075, "action": 0.6982651948928833}
{"mode": "train", "epochs": 2, "timestep": 2227, "ep_reward": 104.5108871459961, "reward": 0.5611650347709656, "action": 0.5356236696243286}
{"mode": "train", "epochs": 2, "timestep": 2228, "ep_reward": 105.073974609375, "reward": 0.5630879402160645, "action": 0.814461350440979}
{"mode": "train", "epochs": 2, "timestep": 2229, "ep_reward": 105.63427734375, "reward": 0.5603047013282776, "action": 0.37324100732803345}
{"mode": "train", "epochs": 2, "timestep": 2230, "ep_reward": 106.18577575683594, "reward": 0.5514956712722778, "action": 0.6107738614082336}
{"mode": "train", "epochs": 2, "timestep": 2231, "ep_reward": 106.72357177734375, "reward": 0.5377928018569946, "action": 1.0884761810302734}
{"mode": "train", "epochs": 2, "timestep": 2232, "ep_reward": 107.24524688720703, "reward": 0.5216723680496216, "action": 1.4110989570617676}
{"mode": "train", "epochs": 2, "timestep": 2233, "ep_reward": 107.75003814697266, "reward": 0.5047883987426758, "action": 1.250227451324463}
{"mode": "train", "epochs": 2, "timestep": 2234, "ep_reward": 108.23661041259766, "reward": 0.4865686297416687, "action": 0.7218469977378845}
{"mode": "train", "epochs": 2, "timestep": 2235, "ep_reward": 108.70197296142578, "reward": 0.4653588533401489, "action": 0.8483242988586426}
{"mode": "train", "epochs": 2, "timestep": 2236, "ep_reward": 109.14546203613281, "reward": 0.4434887766838074, "action": 1.5293676853179932}
{"mode": "train", "epochs": 2, "timestep": 2237, "ep_reward": 109.57070922851562, "reward": 0.4252445101737976, "action": 0.16112583875656128}
{"mode": "train", "epochs": 2, "timestep": 2238, "ep_reward": 109.97356414794922, "reward": 0.40285634994506836, "action": 0.3779495358467102}
{"mode": "train", "epochs": 2, "timestep": 2239, "ep_reward": 110.35458374023438, "reward": 0.38101714849472046, "action": 1.5685229301452637}
{"mode": "train", "epochs": 2, "timestep": 2240, "ep_reward": 110.74422454833984, "reward": 0.38963961601257324, "action": 1.4930461645126343}
{"mode": "train", "epochs": 2, "timestep": 2241, "ep_reward": 111.14896392822266, "reward": 0.4047403931617737, "action": 0.868652880191803}
{"mode": "train", "epochs": 2, "timestep": 2242, "ep_reward": 111.5641098022461, "reward": 0.41514384746551514, "action": -0.15670758485794067}
{"mode": "train", "epochs": 2, "timestep": 2243, "ep_reward": 111.98759460449219, "reward": 0.423484742641449, "action": 1.5719687938690186}
{"mode": "train", "epochs": 2, "timestep": 2244, "ep_reward": 112.41449737548828, "reward": 0.4268999695777893, "action": 0.9474130868911743}
{"mode": "train", "epochs": 2, "timestep": 2245, "ep_reward": 112.83928680419922, "reward": 0.4247886538505554, "action": 1.2551758289337158}
{"mode": "train", "epochs": 2, "timestep": 2246, "ep_reward": 113.25602722167969, "reward": 0.41673994064331055, "action": 1.3423635959625244}
{"mode": "train", "epochs": 2, "timestep": 2247, "ep_reward": 113.6585464477539, "reward": 0.40251588821411133, "action": 1.7793809175491333}
{"mode": "train", "epochs": 2, "timestep": 2248, "ep_reward": 114.03952026367188, "reward": 0.38097715377807617, "action": 0.7591992616653442}
{"mode": "train", "epochs": 2, "timestep": 2249, "ep_reward": 114.4327392578125, "reward": 0.3932191729545593, "action": 1.349758505821228}
{"mode": "train", "epochs": 2, "timestep": 2250, "ep_reward": 114.84740447998047, "reward": 0.41466379165649414, "action": 1.2914464473724365}
{"mode": "train", "epochs": 2, "timestep": 2251, "ep_reward": 115.28580474853516, "reward": 0.4383987784385681, "action": 0.6900753974914551}
{"mode": "train", "epochs": 2, "timestep": 2252, "ep_reward": 115.74906921386719, "reward": 0.4632644057273865, "action": 0.9949735999107361}
{"mode": "train", "epochs": 2, "timestep": 2253, "ep_reward": 116.2362060546875, "reward": 0.48713362216949463, "action": 0.8055415153503418}
{"mode": "train", "epochs": 2, "timestep": 2254, "ep_reward": 116.74589538574219, "reward": 0.5096893310546875, "action": 1.402469277381897}
{"mode": "train", "epochs": 2, "timestep": 2255, "ep_reward": 117.27606964111328, "reward": 0.5301743745803833, "action": 0.7642544507980347}
{"mode": "train", "epochs": 2, "timestep": 2256, "ep_reward": 117.8246078491211, "reward": 0.5485347509384155, "action": 1.3226855993270874}
{"mode": "train", "epochs": 2, "timestep": 2257, "ep_reward": 118.38809204101562, "reward": 0.563485324382782, "action": 0.4196193814277649}
{"mode": "train", "epochs": 2, "timestep": 2258, "ep_reward": 118.96214294433594, "reward": 0.5740547180175781, "action": 1.1384756565093994}
{"mode": "train", "epochs": 2, "timestep": 2259, "ep_reward": 119.54195404052734, "reward": 0.5798126459121704, "action": 0.6120309829711914}
{"mode": "train", "epochs": 2, "timestep": 2260, "ep_reward": 120.12200927734375, "reward": 0.5800533294677734, "action": 1.0926626920700073}
{"mode": "train", "epochs": 2, "timestep": 2261, "ep_reward": 120.69784545898438, "reward": 0.5758395195007324, "action": 0.20033854246139526}
{"mode": "train", "epochs": 2, "timestep": 2262, "ep_reward": 121.26204681396484, "reward": 0.5642032623291016, "action": 0.7796117663383484}
{"mode": "train", "epochs": 2, "timestep": 2263, "ep_reward": 121.80998229980469, "reward": 0.5479390621185303, "action": 1.1330276727676392}
{"mode": "train", "epochs": 2, "timestep": 2264, "ep_reward": 122.33894348144531, "reward": 0.5289647579193115, "action": 1.0430899858474731}
{"mode": "train", "epochs": 2, "timestep": 2265, "ep_reward": 122.84603118896484, "reward": 0.5070847272872925, "action": 0.9782347083091736}
{"mode": "train", "epochs": 2, "timestep": 2266, "ep_reward": 123.32901763916016, "reward": 0.48298871517181396, "action": 0.5220083594322205}
{"mode": "train", "epochs": 2, "timestep": 2267, "ep_reward": 123.78425598144531, "reward": 0.4552421569824219, "action": 0.5030509233474731}
{"mode": "train", "epochs": 2, "timestep": 2268, "ep_reward": 124.20994567871094, "reward": 0.42569220066070557, "action": 1.7092417478561401}
{"mode": "train", "epochs": 2, "timestep": 2269, "ep_reward": 124.6127700805664, "reward": 0.40282535552978516, "action": -0.1636030673980713}
{"mode": "train", "epochs": 2, "timestep": 2270, "ep_reward": 124.98616790771484, "reward": 0.37339943647384644, "action": 1.0170425176620483}
{"mode": "train", "epochs": 2, "timestep": 2271, "ep_reward": 125.38075256347656, "reward": 0.39458656311035156, "action": 0.5966787338256836}
{"mode": "train", "epochs": 2, "timestep": 2272, "ep_reward": 125.799560546875, "reward": 0.4188106060028076, "action": 0.6024149656295776}
{"mode": "train", "epochs": 2, "timestep": 2273, "ep_reward": 126.23902893066406, "reward": 0.43947023153305054, "action": 1.941608190536499}
{"mode": "train", "epochs": 2, "timestep": 2274, "ep_reward": 126.69332122802734, "reward": 0.4542960524559021, "action": 0.8820501565933228}
{"mode": "train", "epochs": 2, "timestep": 2275, "ep_reward": 127.1545181274414, "reward": 0.46119701862335205, "action": 1.3177893161773682}
{"mode": "train", "epochs": 2, "timestep": 2276, "ep_reward": 127.61530303955078, "reward": 0.4607868790626526, "action": 0.8334903717041016}
{"mode": "train", "epochs": 2, "timestep": 2277, "ep_reward": 128.0693359375, "reward": 0.454031765460968, "action": 0.4100725054740906}
{"mode": "train", "epochs": 2, "timestep": 2278, "ep_reward": 128.51217651367188, "reward": 0.44284307956695557, "action": 1.8213536739349365}
{"mode": "train", "epochs": 2, "timestep": 2279, "ep_reward": 128.93417358398438, "reward": 0.42199283838272095, "action": 0.9108989238739014}
{"mode": "train", "epochs": 2, "timestep": 2280, "ep_reward": 129.3312530517578, "reward": 0.3970819115638733, "action": 1.329474687576294}
{"mode": "train", "epochs": 2, "timestep": 2281, "ep_reward": 129.70706176757812, "reward": 0.37580811977386475, "action": 0.802514910697937}
{"mode": "train", "epochs": 2, "timestep": 2282, "ep_reward": 130.10992431640625, "reward": 0.40286099910736084, "action": 0.6904573440551758}
{"mode": "train", "epochs": 2, "timestep": 2283, "ep_reward": 130.54112243652344, "reward": 0.4311962127685547, "action": 0.653233528137207}
{"mode": "train", "epochs": 2, "timestep": 2284, "ep_reward": 131.00059509277344, "reward": 0.4594802260398865, "action": 1.135404109954834}
{"mode": "train", "epochs": 2, "timestep": 2285, "ep_reward": 131.48724365234375, "reward": 0.48665010929107666, "action": 1.0166348218917847}
{"mode": "train", "epochs": 2, "timestep": 2286, "ep_reward": 132.00027465820312, "reward": 0.5130277872085571, "action": 1.0298033952713013}
{"mode": "train", "epochs": 2, "timestep": 2287, "ep_reward": 132.5375213623047, "reward": 0.5372408032417297, "action": 1.558738112449646}
{"mode": "train", "epochs": 2, "timestep": 2288, "ep_reward": 133.09640502929688, "reward": 0.5588881969451904, "action": 0.38577669858932495}
{"mode": "train", "epochs": 2, "timestep": 2289, "ep_reward": 133.6739501953125, "reward": 0.5775489807128906, "action": -0.3647899031639099}
{"mode": "train", "epochs": 2, "timestep": 2290, "ep_reward": 134.26234436035156, "reward": 0.5883867740631104, "action": 1.227862000465393}
{"mode": "train", "epochs": 2, "timestep": 2291, "ep_reward": 134.8551788330078, "reward": 0.5928401350975037, "action": 0.95426344871521}
{"mode": "train", "epochs": 2, "timestep": 2292, "ep_reward": 135.4474334716797, "reward": 0.5922499895095825, "action": 0.5660566091537476}
{"mode": "train", "epochs": 2, "timestep": 2293, "ep_reward": 136.03256225585938, "reward": 0.5851255655288696, "action": 0.5421818494796753}
{"mode": "train", "epochs": 2, "timestep": 2294, "ep_reward": 136.60397338867188, "reward": 0.5714060068130493, "action": 0.7574401497840881}
{"mode": "train", "epochs": 2, "timestep": 2295, "ep_reward": 137.15647888183594, "reward": 0.5525093078613281, "action": 0.773402214050293}
{"mode": "train", "epochs": 2, "timestep": 2296, "ep_reward": 137.68539428710938, "reward": 0.528918981552124, "action": 1.3934382200241089}
{"mode": "train", "epochs": 2, "timestep": 2297, "ep_reward": 138.19024658203125, "reward": 0.5048470497131348, "action": 1.4428753852844238}
{"mode": "train", "epochs": 2, "timestep": 2298, "ep_reward": 138.67056274414062, "reward": 0.4803227186203003, "action": 0.5718416571617126}
{"mode": "train", "epochs": 2, "timestep": 2299, "ep_reward": 139.1217803955078, "reward": 0.45122218132019043, "action": 0.8632596731185913}
{"mode": "train", "epochs": 2, "timestep": 2300, "ep_reward": 139.5443572998047, "reward": 0.4225735068321228, "action": 0.8741716146469116}
{"mode": "train", "epochs": 2, "timestep": 2301, "ep_reward": 139.9391632080078, "reward": 0.3948020935058594, "action": 0.8009762167930603}
{"mode": "train", "epochs": 2, "timestep": 2302, "ep_reward": 140.31163024902344, "reward": 0.37247103452682495, "action": 1.480697751045227}
{"mode": "train", "epochs": 2, "timestep": 2303, "ep_reward": 140.71099853515625, "reward": 0.39937007427215576, "action": 1.0307186841964722}
{"mode": "train", "epochs": 2, "timestep": 2304, "ep_reward": 141.13204956054688, "reward": 0.42105621099472046, "action": 0.4041562080383301}
{"mode": "train", "epochs": 2, "timestep": 2305, "ep_reward": 141.57052612304688, "reward": 0.43847090005874634, "action": 1.2723027467727661}
{"mode": "train", "epochs": 2, "timestep": 2306, "ep_reward": 142.02162170410156, "reward": 0.451096773147583, "action": 1.0027903318405151}
{"mode": "train", "epochs": 2, "timestep": 2307, "ep_reward": 142.47854614257812, "reward": 0.4569244384765625, "action": 1.8676409721374512}
{"mode": "train", "epochs": 2, "timestep": 2308, "ep_reward": 142.9324493408203, "reward": 0.453907310962677, "action": 1.5235347747802734}
{"mode": "train", "epochs": 2, "timestep": 2309, "ep_reward": 143.3747100830078, "reward": 0.4422658681869507, "action": 0.3096422553062439}
{"mode": "train", "epochs": 2, "timestep": 2310, "ep_reward": 143.80226135253906, "reward": 0.4275474548339844, "action": 1.2487596273422241}
{"mode": "train", "epochs": 2, "timestep": 2311, "ep_reward": 144.20799255371094, "reward": 0.40572404861450195, "action": 1.2908446788787842}
{"mode": "train", "epochs": 2, "timestep": 2312, "ep_reward": 144.58621215820312, "reward": 0.3782171607017517, "action": 1.4056605100631714}
{"mode": "train", "epochs": 2, "timestep": 2313, "ep_reward": 144.97964477539062, "reward": 0.39342546463012695, "action": 0.6671476364135742}
{"mode": "train", "epochs": 2, "timestep": 2314, "ep_reward": 145.40089416503906, "reward": 0.4212443232536316, "action": 0.0393064022064209}
{"mode": "train", "epochs": 2, "timestep": 2315, "ep_reward": 145.85011291503906, "reward": 0.4492247700691223, "action": 1.3177069425582886}
{"mode": "train", "epochs": 2, "timestep": 2316, "ep_reward": 146.3250274658203, "reward": 0.47491949796676636, "action": 1.30668306350708}
{"mode": "train", "epochs": 2, "timestep": 2317, "ep_reward": 146.82577514648438, "reward": 0.5007449388504028, "action": 1.2219200134277344}
{"mode": "train", "epochs": 2, "timestep": 2318, "ep_reward": 147.3516082763672, "reward": 0.5258282423019409, "action": 0.2577434778213501}
{"mode": "train", "epochs": 2, "timestep": 2319, "ep_reward": 147.90013122558594, "reward": 0.5485256910324097, "action": 1.0646495819091797}
{"mode": "train", "epochs": 2, "timestep": 2320, "ep_reward": 148.46620178222656, "reward": 0.5660673379898071, "action": 1.0970842838287354}
{"mode": "train", "epochs": 2, "timestep": 2321, "ep_reward": 149.0459747314453, "reward": 0.57977294921875, "action": 1.0605072975158691}
{"mode": "train", "epochs": 2, "timestep": 2322, "ep_reward": 149.63511657714844, "reward": 0.5891380310058594, "action": 1.012473464012146}
{"mode": "train", "epochs": 2, "timestep": 2323, "ep_reward": 150.22865295410156, "reward": 0.5935431718826294, "action": 1.597394347190857}
{"mode": "train", "epochs": 2, "timestep": 2324, "ep_reward": 150.82305908203125, "reward": 0.594408392906189, "action": 1.1940195560455322}
{"mode": "train", "epochs": 2, "timestep": 2325, "ep_reward": 151.41384887695312, "reward": 0.5907886028289795, "action": 1.3988628387451172}
{"mode": "train", "epochs": 2, "timestep": 2326, "ep_reward": 151.9971160888672, "reward": 0.5832703113555908, "action": 1.9555599689483643}
{"mode": "train", "epochs": 2, "timestep": 2327, "ep_reward": 152.571533203125, "reward": 0.5744211673736572, "action": 0.942047655582428}
{"mode": "train", "epochs": 2, "timestep": 2328, "ep_reward": 153.13148498535156, "reward": 0.5599467754364014, "action": 1.2383984327316284}
{"mode": "train", "epochs": 2, "timestep": 2329, "ep_reward": 153.67388916015625, "reward": 0.5424084663391113, "action": 1.845457673072815}
{"mode": "train", "epochs": 2, "timestep": 2330, "ep_reward": 154.19906616210938, "reward": 0.525178849697113, "action": 1.246850609779358}
{"mode": "train", "epochs": 2, "timestep": 2331, "ep_reward": 154.7039337158203, "reward": 0.5048741102218628, "action": 1.267964482307434}
{"mode": "train", "epochs": 2, "timestep": 2332, "ep_reward": 155.18748474121094, "reward": 0.483548641204834, "action": 0.8104293346405029}
{"mode": "train", "epochs": 2, "timestep": 2333, "ep_reward": 155.64698791503906, "reward": 0.45950889587402344, "action": 1.259013295173645}
{"mode": "train", "epochs": 2, "timestep": 2334, "ep_reward": 156.08416748046875, "reward": 0.4371814727783203, "action": 0.6005279421806335}
{"mode": "train", "epochs": 2, "timestep": 2335, "ep_reward": 156.49696350097656, "reward": 0.4127959609031677, "action": 0.8821135759353638}
{"mode": "train", "epochs": 2, "timestep": 2336, "ep_reward": 156.8872833251953, "reward": 0.39032524824142456, "action": 1.3781017065048218}
{"mode": "train", "epochs": 2, "timestep": 2337, "ep_reward": 157.2674560546875, "reward": 0.3801717162132263, "action": 0.5817062854766846}
{"mode": "train", "epochs": 2, "timestep": 2338, "ep_reward": 157.6671142578125, "reward": 0.3996579051017761, "action": 0.6332497596740723}
{"mode": "train", "epochs": 2, "timestep": 2339, "ep_reward": 158.08370971679688, "reward": 0.41659510135650635, "action": 0.5545730590820312}
{"mode": "train", "epochs": 2, "timestep": 2340, "ep_reward": 158.5140380859375, "reward": 0.4303264021873474, "action": 0.11399716138839722}
{"mode": "train", "epochs": 2, "timestep": 2341, "ep_reward": 158.95518493652344, "reward": 0.44114959239959717, "action": 0.9879034757614136}
{"mode": "train", "epochs": 2, "timestep": 2342, "ep_reward": 159.40269470214844, "reward": 0.4475039839744568, "action": 1.143150806427002}
{"mode": "train", "epochs": 2, "timestep": 2343, "ep_reward": 159.85011291503906, "reward": 0.4474106431007385, "action": 1.368382453918457}
{"mode": "train", "epochs": 2, "timestep": 2344, "ep_reward": 160.29013061523438, "reward": 0.4400210380554199, "action": 0.637260377407074}
{"mode": "train", "epochs": 2, "timestep": 2345, "ep_reward": 160.71807861328125, "reward": 0.42795121669769287, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2346, "ep_reward": 161.12429809570312, "reward": 0.4062175750732422, "action": 0.7045897245407104}
{"mode": "train", "epochs": 2, "timestep": 2347, "ep_reward": 161.5067138671875, "reward": 0.3824182152748108, "action": 1.132290005683899}
{"mode": "train", "epochs": 2, "timestep": 2348, "ep_reward": 161.89743041992188, "reward": 0.39071762561798096, "action": 1.0355056524276733}
{"mode": "train", "epochs": 2, "timestep": 2349, "ep_reward": 162.31317138671875, "reward": 0.4157475233078003, "action": 1.7916789054870605}
{"mode": "train", "epochs": 2, "timestep": 2350, "ep_reward": 162.7555694580078, "reward": 0.442391037940979, "action": 0.8676353693008423}
{"mode": "train", "epochs": 2, "timestep": 2351, "ep_reward": 163.2271270751953, "reward": 0.47155284881591797, "action": 0.5864797830581665}
{"mode": "train", "epochs": 2, "timestep": 2352, "ep_reward": 163.72683715820312, "reward": 0.4997149705886841, "action": 0.9512979984283447}
{"mode": "train", "epochs": 2, "timestep": 2353, "ep_reward": 164.2518768310547, "reward": 0.5250355005264282, "action": 1.1986644268035889}
{"mode": "train", "epochs": 2, "timestep": 2354, "ep_reward": 164.79969787597656, "reward": 0.5478153228759766, "action": -0.12381225824356079}
{"mode": "train", "epochs": 2, "timestep": 2355, "ep_reward": 165.36651611328125, "reward": 0.5668107271194458, "action": 0.6628022789955139}
{"mode": "train", "epochs": 2, "timestep": 2356, "ep_reward": 165.94537353515625, "reward": 0.578864336013794, "action": 0.8589005470275879}
{"mode": "train", "epochs": 2, "timestep": 2357, "ep_reward": 166.53082275390625, "reward": 0.5854501128196716, "action": 1.7322635650634766}
{"mode": "train", "epochs": 2, "timestep": 2358, "ep_reward": 167.1196746826172, "reward": 0.5888581871986389, "action": 1.3355246782302856}
{"mode": "train", "epochs": 2, "timestep": 2359, "ep_reward": 167.70826721191406, "reward": 0.5885889530181885, "action": 1.243872880935669}
{"mode": "train", "epochs": 2, "timestep": 2360, "ep_reward": 168.29246520996094, "reward": 0.5841964483261108, "action": 0.8718197345733643}
{"mode": "train", "epochs": 2, "timestep": 2361, "ep_reward": 168.866943359375, "reward": 0.5744830965995789, "action": 0.21484243869781494}
{"mode": "train", "epochs": 2, "timestep": 2362, "ep_reward": 169.4239044189453, "reward": 0.5569578409194946, "action": 1.3834302425384521}
{"mode": "train", "epochs": 2, "timestep": 2363, "ep_reward": 169.9620819091797, "reward": 0.5381715297698975, "action": 1.1371140480041504}
{"mode": "train", "epochs": 2, "timestep": 2364, "ep_reward": 170.47817993164062, "reward": 0.516103982925415, "action": 1.1854809522628784}
{"mode": "train", "epochs": 2, "timestep": 2365, "ep_reward": 170.9704132080078, "reward": 0.49223053455352783, "action": 1.4950616359710693}
{"mode": "train", "epochs": 2, "timestep": 2366, "ep_reward": 171.43955993652344, "reward": 0.4691418409347534, "action": 1.0736124515533447}
{"mode": "train", "epochs": 2, "timestep": 2367, "ep_reward": 171.88426208496094, "reward": 0.4447076916694641, "action": 0.5793933868408203}
{"mode": "train", "epochs": 2, "timestep": 2368, "ep_reward": 172.3022918701172, "reward": 0.41803300380706787, "action": 1.7077691555023193}
{"mode": "train", "epochs": 2, "timestep": 2369, "ep_reward": 172.70008850097656, "reward": 0.397794246673584, "action": 1.1835315227508545}
{"mode": "train", "epochs": 2, "timestep": 2370, "ep_reward": 173.07882690429688, "reward": 0.3787410259246826, "action": 1.537813663482666}
{"mode": "train", "epochs": 2, "timestep": 2371, "ep_reward": 173.4711151123047, "reward": 0.3922831416130066, "action": 0.09828263521194458}
{"mode": "train", "epochs": 2, "timestep": 2372, "ep_reward": 173.87936401367188, "reward": 0.40825337171554565, "action": 0.9288665056228638}
{"mode": "train", "epochs": 2, "timestep": 2373, "ep_reward": 174.30091857910156, "reward": 0.42155468463897705, "action": 1.687967300415039}
{"mode": "train", "epochs": 2, "timestep": 2374, "ep_reward": 174.72972106933594, "reward": 0.42880213260650635, "action": 1.2161939144134521}
{"mode": "train", "epochs": 2, "timestep": 2375, "ep_reward": 175.15916442871094, "reward": 0.42944878339767456, "action": 1.189133882522583}
{"mode": "train", "epochs": 2, "timestep": 2376, "ep_reward": 175.58322143554688, "reward": 0.42405831813812256, "action": 1.4286370277404785}
{"mode": "train", "epochs": 2, "timestep": 2377, "ep_reward": 175.99533081054688, "reward": 0.41210687160491943, "action": -0.15490031242370605}
{"mode": "train", "epochs": 2, "timestep": 2378, "ep_reward": 176.39573669433594, "reward": 0.40040290355682373, "action": 1.0492439270019531}
{"mode": "train", "epochs": 2, "timestep": 2379, "ep_reward": 176.7791290283203, "reward": 0.3833999037742615, "action": 1.2607372999191284}
{"mode": "train", "epochs": 2, "timestep": 2380, "ep_reward": 177.1711883544922, "reward": 0.39205658435821533, "action": 0.8445386290550232}
{"mode": "train", "epochs": 2, "timestep": 2381, "ep_reward": 177.58277893066406, "reward": 0.41159379482269287, "action": 0.7757658362388611}
{"mode": "train", "epochs": 2, "timestep": 2382, "ep_reward": 178.01498413085938, "reward": 0.43220001459121704, "action": 1.1990151405334473}
{"mode": "train", "epochs": 2, "timestep": 2383, "ep_reward": 178.4683074951172, "reward": 0.45331764221191406, "action": 1.5175390243530273}
{"mode": "train", "epochs": 2, "timestep": 2384, "ep_reward": 178.94358825683594, "reward": 0.47528135776519775, "action": 1.1534316539764404}
{"mode": "train", "epochs": 2, "timestep": 2385, "ep_reward": 179.44137573242188, "reward": 0.497789204120636, "action": 0.7385402917861938}
{"mode": "train", "epochs": 2, "timestep": 2386, "ep_reward": 179.9603271484375, "reward": 0.5189522504806519, "action": 0.9689344763755798}
{"mode": "train", "epochs": 2, "timestep": 2387, "ep_reward": 180.49742126464844, "reward": 0.537094235420227, "action": 1.7440426349639893}
{"mode": "train", "epochs": 2, "timestep": 2388, "ep_reward": 181.0505828857422, "reward": 0.5531647205352783, "action": 0.5684780478477478}
{"mode": "train", "epochs": 2, "timestep": 2389, "ep_reward": 181.6168975830078, "reward": 0.5663151144981384, "action": 1.2684431076049805}
{"mode": "train", "epochs": 2, "timestep": 2390, "ep_reward": 182.19215393066406, "reward": 0.5752534866333008, "action": 0.7559353709220886}
{"mode": "train", "epochs": 2, "timestep": 2391, "ep_reward": 182.7716827392578, "reward": 0.5795307159423828, "action": 0.8866847157478333}
{"mode": "train", "epochs": 2, "timestep": 2392, "ep_reward": 183.3502960205078, "reward": 0.5786064267158508, "action": 1.6152245998382568}
{"mode": "train", "epochs": 2, "timestep": 2393, "ep_reward": 183.92535400390625, "reward": 0.5750589370727539, "action": 0.8533228635787964}
{"mode": "train", "epochs": 2, "timestep": 2394, "ep_reward": 184.4917449951172, "reward": 0.5663914084434509, "action": 0.806501030921936}
{"mode": "train", "epochs": 2, "timestep": 2395, "ep_reward": 185.0445556640625, "reward": 0.5528146028518677, "action": 0.857161819934845}
{"mode": "train", "epochs": 2, "timestep": 2396, "ep_reward": 185.57960510253906, "reward": 0.535057008266449, "action": 0.794298529624939}
{"mode": "train", "epochs": 2, "timestep": 2397, "ep_reward": 186.09292602539062, "reward": 0.5133206844329834, "action": 1.445817232131958}
{"mode": "train", "epochs": 2, "timestep": 2398, "ep_reward": 186.58494567871094, "reward": 0.49202579259872437, "action": 0.7338535189628601}
{"mode": "train", "epochs": 2, "timestep": 2399, "ep_reward": 187.0518798828125, "reward": 0.466933012008667, "action": 0.5335809588432312}
{"mode": "train", "epochs": 2, "timestep": 2400, "ep_reward": 187.49119567871094, "reward": 0.43931710720062256, "action": 1.55704665184021}
{"mode": "train", "epochs": 2, "timestep": 2401, "ep_reward": 187.90777587890625, "reward": 0.416587233543396, "action": 1.4456406831741333}
{"mode": "train", "epochs": 2, "timestep": 2402, "ep_reward": 188.3040313720703, "reward": 0.39625370502471924, "action": 0.9677160978317261}
{"mode": "train", "epochs": 2, "timestep": 2403, "ep_reward": 188.68069458007812, "reward": 0.376669704914093, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2404, "ep_reward": 189.07420349121094, "reward": 0.3935021162033081, "action": 1.0284926891326904}
{"mode": "train", "epochs": 2, "timestep": 2405, "ep_reward": 189.4806671142578, "reward": 0.40646928548812866, "action": 1.1073459386825562}
{"mode": "train", "epochs": 2, "timestep": 2406, "ep_reward": 189.89569091796875, "reward": 0.41502583026885986, "action": 0.7466912269592285}
{"mode": "train", "epochs": 2, "timestep": 2407, "ep_reward": 190.31520080566406, "reward": 0.4195067286491394, "action": 0.5388606190681458}
{"mode": "train", "epochs": 2, "timestep": 2408, "ep_reward": 190.73574829101562, "reward": 0.42054951190948486, "action": 1.5364030599594116}
{"mode": "train", "epochs": 2, "timestep": 2409, "ep_reward": 191.1511993408203, "reward": 0.41544514894485474, "action": 0.5433984994888306}
{"mode": "train", "epochs": 2, "timestep": 2410, "ep_reward": 191.5582733154297, "reward": 0.4070754647254944, "action": 1.5557960271835327}
{"mode": "train", "epochs": 2, "timestep": 2411, "ep_reward": 191.95034790039062, "reward": 0.3920758366584778, "action": 1.1944000720977783}
{"mode": "train", "epochs": 2, "timestep": 2412, "ep_reward": 192.33389282226562, "reward": 0.3835439085960388, "action": 1.1797962188720703}
{"mode": "train", "epochs": 2, "timestep": 2413, "ep_reward": 192.73582458496094, "reward": 0.40192991495132446, "action": 0.6881876587867737}
{"mode": "train", "epochs": 2, "timestep": 2414, "ep_reward": 193.15805053710938, "reward": 0.42222923040390015, "action": 0.5618585348129272}
{"mode": "train", "epochs": 2, "timestep": 2415, "ep_reward": 193.60089111328125, "reward": 0.44283825159072876, "action": 0.42127031087875366}
{"mode": "train", "epochs": 2, "timestep": 2416, "ep_reward": 194.0634765625, "reward": 0.4625902771949768, "action": 0.9748770594596863}
{"mode": "train", "epochs": 2, "timestep": 2417, "ep_reward": 194.5444793701172, "reward": 0.4810029864311218, "action": 1.2126343250274658}
{"mode": "train", "epochs": 2, "timestep": 2418, "ep_reward": 195.04327392578125, "reward": 0.4987946152687073, "action": 0.49215155839920044}
{"mode": "train", "epochs": 2, "timestep": 2419, "ep_reward": 195.55813598632812, "reward": 0.5148627758026123, "action": 0.8896530866622925}
{"mode": "train", "epochs": 2, "timestep": 2420, "ep_reward": 196.08590698242188, "reward": 0.5277739763259888, "action": 1.2721595764160156}
{"mode": "train", "epochs": 2, "timestep": 2421, "ep_reward": 196.62437438964844, "reward": 0.5384706854820251, "action": 0.6165959239006042}
{"mode": "train", "epochs": 2, "timestep": 2422, "ep_reward": 197.1701202392578, "reward": 0.5457534193992615, "action": 0.7560772895812988}
{"mode": "train", "epochs": 2, "timestep": 2423, "ep_reward": 197.71888732910156, "reward": 0.5487726926803589, "action": 1.2907540798187256}
{"mode": "train", "epochs": 2, "timestep": 2424, "ep_reward": 198.26783752441406, "reward": 0.5489470958709717, "action": 1.7690889835357666}
{"mode": "train", "epochs": 2, "timestep": 2425, "ep_reward": 198.81594848632812, "reward": 0.5481059551239014, "action": 1.0260460376739502}
{"mode": "train", "epochs": 2, "timestep": 2426, "ep_reward": 199.35989379882812, "reward": 0.543948769569397, "action": 0.5766036510467529}
{"mode": "train", "epochs": 2, "timestep": 2427, "ep_reward": 199.89486694335938, "reward": 0.5349728465080261, "action": 1.272549033164978}
{"mode": "train", "epochs": 2, "timestep": 2428, "ep_reward": 200.41928100585938, "reward": 0.5244156718254089, "action": 0.5374709367752075}
{"mode": "train", "epochs": 2, "timestep": 2429, "ep_reward": 200.92840576171875, "reward": 0.5091185569763184, "action": 0.6226545572280884}
{"mode": "train", "epochs": 2, "timestep": 2430, "ep_reward": 201.41908264160156, "reward": 0.4906730651855469, "action": 0.8896458148956299}
{"mode": "train", "epochs": 2, "timestep": 2431, "ep_reward": 201.89013671875, "reward": 0.4710468053817749, "action": 0.07229125499725342}
{"mode": "train", "epochs": 2, "timestep": 2432, "ep_reward": 202.33656311035156, "reward": 0.4464261531829834, "action": 0.7172714471817017}
{"mode": "train", "epochs": 2, "timestep": 2433, "ep_reward": 202.7592315673828, "reward": 0.4226756691932678, "action": 0.6492862701416016}
{"mode": "train", "epochs": 2, "timestep": 2434, "ep_reward": 203.15821838378906, "reward": 0.39898043870925903, "action": 1.0084280967712402}
{"mode": "train", "epochs": 2, "timestep": 2435, "ep_reward": 203.53660583496094, "reward": 0.37838494777679443, "action": -0.40673768520355225}
{"mode": "train", "epochs": 2, "timestep": 2436, "ep_reward": 203.9307861328125, "reward": 0.39417898654937744, "action": -0.11616122722625732}
{"mode": "train", "epochs": 2, "timestep": 2437, "ep_reward": 204.34796142578125, "reward": 0.4171783924102783, "action": 0.9615640640258789}
{"mode": "train", "epochs": 2, "timestep": 2438, "ep_reward": 204.7863006591797, "reward": 0.438342809677124, "action": 0.42621269822120667}
{"mode": "train", "epochs": 2, "timestep": 2439, "ep_reward": 205.2410125732422, "reward": 0.4547179937362671, "action": 0.7728070616722107}
{"mode": "train", "epochs": 2, "timestep": 2440, "ep_reward": 205.7071990966797, "reward": 0.4661884903907776, "action": 1.4080379009246826}
{"mode": "train", "epochs": 2, "timestep": 2441, "ep_reward": 206.1773681640625, "reward": 0.47017383575439453, "action": 1.6525306701660156}
{"mode": "train", "epochs": 2, "timestep": 2442, "ep_reward": 206.64193725585938, "reward": 0.4645765423774719, "action": 1.93135666847229}
{"mode": "train", "epochs": 2, "timestep": 2443, "ep_reward": 207.0903778076172, "reward": 0.44843536615371704, "action": 0.5293478965759277}
{"mode": "train", "epochs": 2, "timestep": 2444, "ep_reward": 207.51889038085938, "reward": 0.4285125136375427, "action": 0.6065211296081543}
{"mode": "train", "epochs": 2, "timestep": 2445, "ep_reward": 207.9232940673828, "reward": 0.40440452098846436, "action": 0.9950371384620667}
{"mode": "train", "epochs": 2, "timestep": 2446, "ep_reward": 208.2985382080078, "reward": 0.37524813413619995, "action": 0.06736969947814941}
{"mode": "train", "epochs": 2, "timestep": 2447, "ep_reward": 208.6931915283203, "reward": 0.3946567177772522, "action": 0.7263498306274414}
{"mode": "train", "epochs": 2, "timestep": 2448, "ep_reward": 209.11375427246094, "reward": 0.42055702209472656, "action": 1.463883399963379}
{"mode": "train", "epochs": 2, "timestep": 2449, "ep_reward": 209.5608367919922, "reward": 0.4470822811126709, "action": 1.0688221454620361}
{"mode": "train", "epochs": 2, "timestep": 2450, "ep_reward": 210.03591918945312, "reward": 0.4750804901123047, "action": 0.8374063968658447}
{"mode": "train", "epochs": 2, "timestep": 2451, "ep_reward": 210.5384521484375, "reward": 0.5025355815887451, "action": 0.8047135472297668}
{"mode": "train", "epochs": 2, "timestep": 2452, "ep_reward": 211.0662078857422, "reward": 0.5277553796768188, "action": 0.9282629489898682}
{"mode": "train", "epochs": 2, "timestep": 2453, "ep_reward": 211.61602783203125, "reward": 0.5498182773590088, "action": -0.07535737752914429}
{"mode": "train", "epochs": 2, "timestep": 2454, "ep_reward": 212.1831512451172, "reward": 0.5671194791793823, "action": 1.661382794380188}
{"mode": "train", "epochs": 2, "timestep": 2455, "ep_reward": 212.7624053955078, "reward": 0.5792577266693115, "action": 0.9869363307952881}
{"mode": "train", "epochs": 2, "timestep": 2456, "ep_reward": 213.35015869140625, "reward": 0.5877571105957031, "action": 0.7214627265930176}
{"mode": "train", "epochs": 2, "timestep": 2457, "ep_reward": 213.94085693359375, "reward": 0.5906980037689209, "action": 0.8079056739807129}
{"mode": "train", "epochs": 2, "timestep": 2458, "ep_reward": 214.5286407470703, "reward": 0.587780237197876, "action": 1.416452169418335}
{"mode": "train", "epochs": 2, "timestep": 2459, "ep_reward": 215.1099090576172, "reward": 0.5812609195709229, "action": 1.2285730838775635}
{"mode": "train", "epochs": 2, "timestep": 2460, "ep_reward": 215.68060302734375, "reward": 0.57069993019104, "action": 0.5483344197273254}
{"mode": "train", "epochs": 2, "timestep": 2461, "ep_reward": 216.23402404785156, "reward": 0.5534258484840393, "action": 1.9466123580932617}
{"mode": "train", "epochs": 2, "timestep": 2462, "ep_reward": 216.7714385986328, "reward": 0.5374155044555664, "action": 0.7111836075782776}
{"mode": "train", "epochs": 2, "timestep": 2463, "ep_reward": 217.28660583496094, "reward": 0.5151689052581787, "action": 1.083068609237671}
{"mode": "train", "epochs": 2, "timestep": 2464, "ep_reward": 217.77818298339844, "reward": 0.49157261848449707, "action": 0.39862436056137085}
{"mode": "train", "epochs": 2, "timestep": 2465, "ep_reward": 218.24105834960938, "reward": 0.4628748297691345, "action": 1.8628681898117065}
{"mode": "train", "epochs": 2, "timestep": 2466, "ep_reward": 218.68128967285156, "reward": 0.440232515335083, "action": 1.4171500205993652}
{"mode": "train", "epochs": 2, "timestep": 2467, "ep_reward": 219.0994110107422, "reward": 0.4181217551231384, "action": 0.8364739418029785}
{"mode": "train", "epochs": 2, "timestep": 2468, "ep_reward": 219.4949493408203, "reward": 0.3955373764038086, "action": -0.06203871965408325}
{"mode": "train", "epochs": 2, "timestep": 2469, "ep_reward": 219.87103271484375, "reward": 0.37608736753463745, "action": 1.141861915588379}
{"mode": "train", "epochs": 2, "timestep": 2470, "ep_reward": 220.27096557617188, "reward": 0.39993566274642944, "action": 0.07585769891738892}
{"mode": "train", "epochs": 2, "timestep": 2471, "ep_reward": 220.69131469726562, "reward": 0.4203529357910156, "action": 0.8194336295127869}
{"mode": "train", "epochs": 2, "timestep": 2472, "ep_reward": 221.1295166015625, "reward": 0.43819659948349, "action": 1.2023801803588867}
{"mode": "train", "epochs": 2, "timestep": 2473, "ep_reward": 221.5799560546875, "reward": 0.45044076442718506, "action": 1.539109230041504}
{"mode": "train", "epochs": 2, "timestep": 2474, "ep_reward": 222.0350799560547, "reward": 0.4551297426223755, "action": 0.4760481119155884}
{"mode": "train", "epochs": 2, "timestep": 2475, "ep_reward": 222.48936462402344, "reward": 0.45429152250289917, "action": 0.8902987241744995}
{"mode": "train", "epochs": 2, "timestep": 2476, "ep_reward": 222.9370574951172, "reward": 0.44769489765167236, "action": 0.0019012689590454102}
{"mode": "train", "epochs": 2, "timestep": 2477, "ep_reward": 223.3756103515625, "reward": 0.43855220079421997, "action": 1.2582730054855347}
{"mode": "train", "epochs": 2, "timestep": 2478, "ep_reward": 223.79783630371094, "reward": 0.4222249984741211, "action": 0.6741253137588501}
{"mode": "train", "epochs": 2, "timestep": 2479, "ep_reward": 224.2002410888672, "reward": 0.40240049362182617, "action": 0.9959776997566223}
{"mode": "train", "epochs": 2, "timestep": 2480, "ep_reward": 224.57806396484375, "reward": 0.37782907485961914, "action": 1.2786985635757446}
{"mode": "train", "epochs": 2, "timestep": 2481, "ep_reward": 224.97320556640625, "reward": 0.39513933658599854, "action": 0.8826523423194885}
{"mode": "train", "epochs": 2, "timestep": 2482, "ep_reward": 225.3938446044922, "reward": 0.4206376075744629, "action": 0.7221723198890686}
{"mode": "train", "epochs": 2, "timestep": 2483, "ep_reward": 225.84078979492188, "reward": 0.446946918964386, "action": 1.2227195501327515}
{"mode": "train", "epochs": 2, "timestep": 2484, "ep_reward": 226.31369018554688, "reward": 0.4728984832763672, "action": 1.0149686336517334}
{"mode": "train", "epochs": 2, "timestep": 2485, "ep_reward": 226.81240844726562, "reward": 0.4987119436264038, "action": 1.442923665046692}
{"mode": "train", "epochs": 2, "timestep": 2486, "ep_reward": 227.33535766601562, "reward": 0.5229454040527344, "action": 1.993303656578064}
{"mode": "train", "epochs": 2, "timestep": 2487, "ep_reward": 227.8816375732422, "reward": 0.5462833642959595, "action": 0.6209006309509277}
{"mode": "train", "epochs": 2, "timestep": 2488, "ep_reward": 228.4501953125, "reward": 0.5685610175132751, "action": 0.9053268432617188}
{"mode": "train", "epochs": 2, "timestep": 2489, "ep_reward": 229.0357666015625, "reward": 0.5855761766433716, "action": 1.2984834909439087}
{"mode": "train", "epochs": 2, "timestep": 2490, "ep_reward": 229.63372802734375, "reward": 0.5979623794555664, "action": 1.3140525817871094}
{"mode": "train", "epochs": 2, "timestep": 2491, "ep_reward": 230.23968505859375, "reward": 0.605964183807373, "action": 1.7627770900726318}
{"mode": "train", "epochs": 2, "timestep": 2492, "ep_reward": 230.85023498535156, "reward": 0.61054927110672, "action": 0.27183276414871216}
{"mode": "train", "epochs": 2, "timestep": 2493, "ep_reward": 231.4581756591797, "reward": 0.6079398989677429, "action": 0.23891180753707886}
{"mode": "train", "epochs": 2, "timestep": 2494, "ep_reward": 232.0548858642578, "reward": 0.5967144966125488, "action": 0.627478837966919}
{"mode": "train", "epochs": 2, "timestep": 2495, "ep_reward": 232.6336669921875, "reward": 0.5787755250930786, "action": 1.151545763015747}
{"mode": "train", "epochs": 2, "timestep": 2496, "ep_reward": 233.1908416748047, "reward": 0.5571799874305725, "action": 0.485048770904541}
{"mode": "train", "epochs": 2, "timestep": 2497, "ep_reward": 233.71929931640625, "reward": 0.5284604430198669, "action": 0.4395444989204407}
{"mode": "train", "epochs": 2, "timestep": 2498, "ep_reward": 234.2138671875, "reward": 0.49456197023391724, "action": 0.814922571182251}
{"mode": "train", "epochs": 2, "timestep": 2499, "ep_reward": 234.67318725585938, "reward": 0.4593260884284973, "action": 0.7110005021095276}
{"mode": "train", "epochs": 2, "timestep": 2500, "ep_reward": 235.0955810546875, "reward": 0.42238879203796387, "action": 1.2046347856521606}
{"mode": "train", "epochs": 2, "timestep": 2501, "ep_reward": 235.48448181152344, "reward": 0.38890528678894043, "action": 1.0424411296844482}
{"mode": "train", "epochs": 2, "timestep": 2502, "ep_reward": 235.85536193847656, "reward": 0.3708725571632385, "action": 1.0956506729125977}
{"mode": "train", "epochs": 2, "timestep": 2503, "ep_reward": 236.2600555419922, "reward": 0.4046861529350281, "action": 1.215548038482666}
{"mode": "train", "epochs": 2, "timestep": 2504, "ep_reward": 236.69407653808594, "reward": 0.4340229034423828, "action": 0.11160075664520264}
{"mode": "train", "epochs": 2, "timestep": 2505, "ep_reward": 237.1517791748047, "reward": 0.4577043056488037, "action": 1.232006549835205}
{"mode": "train", "epochs": 2, "timestep": 2506, "ep_reward": 237.62875366210938, "reward": 0.4769675135612488, "action": 1.5487314462661743}
{"mode": "train", "epochs": 2, "timestep": 2507, "ep_reward": 238.11627197265625, "reward": 0.4875129461288452, "action": 0.737529993057251}
{"mode": "train", "epochs": 2, "timestep": 2508, "ep_reward": 238.60618591308594, "reward": 0.48991191387176514, "action": 0.7958641052246094}
{"mode": "train", "epochs": 2, "timestep": 2509, "ep_reward": 239.09130859375, "reward": 0.48511844873428345, "action": 0.649551510810852}
{"mode": "train", "epochs": 2, "timestep": 2510, "ep_reward": 239.56488037109375, "reward": 0.47357577085494995, "action": 1.7576828002929688}
{"mode": "train", "epochs": 2, "timestep": 2511, "ep_reward": 240.01617431640625, "reward": 0.45129066705703735, "action": 0.6771970391273499}
{"mode": "train", "epochs": 2, "timestep": 2512, "ep_reward": 240.44078063964844, "reward": 0.42460864782333374, "action": 1.5857555866241455}
{"mode": "train", "epochs": 2, "timestep": 2513, "ep_reward": 240.8294677734375, "reward": 0.38868260383605957, "action": 0.9466253519058228}
{"mode": "train", "epochs": 2, "timestep": 2514, "ep_reward": 241.20631408691406, "reward": 0.3768414258956909, "action": 1.094624638557434}
{"mode": "train", "epochs": 2, "timestep": 2515, "ep_reward": 241.6162872314453, "reward": 0.40997081995010376, "action": 1.3848283290863037}
{"mode": "train", "epochs": 2, "timestep": 2516, "ep_reward": 242.06085205078125, "reward": 0.444561243057251, "action": 0.9796456098556519}
{"mode": "train", "epochs": 2, "timestep": 2517, "ep_reward": 242.54161071777344, "reward": 0.48076438903808594, "action": 0.5983071327209473}
{"mode": "train", "epochs": 2, "timestep": 2518, "ep_reward": 243.05755615234375, "reward": 0.5159462094306946, "action": 1.9441332817077637}
{"mode": "train", "epochs": 2, "timestep": 2519, "ep_reward": 243.60447692871094, "reward": 0.5469233989715576, "action": 0.9102649688720703}
{"mode": "train", "epochs": 2, "timestep": 2520, "ep_reward": 244.18206787109375, "reward": 0.5775847434997559, "action": 1.0099495649337769}
{"mode": "train", "epochs": 2, "timestep": 2521, "ep_reward": 244.78515625, "reward": 0.6030902862548828, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2522, "ep_reward": 245.40884399414062, "reward": 0.6236809492111206, "action": 0.4874612092971802}
{"mode": "train", "epochs": 2, "timestep": 2523, "ep_reward": 246.0487518310547, "reward": 0.6399039030075073, "action": 0.8095478415489197}
{"mode": "train", "epochs": 2, "timestep": 2524, "ep_reward": 246.69659423828125, "reward": 0.6478457450866699, "action": 1.1662678718566895}
{"mode": "train", "epochs": 2, "timestep": 2525, "ep_reward": 247.34535217285156, "reward": 0.648754894733429, "action": 1.1549890041351318}
{"mode": "train", "epochs": 2, "timestep": 2526, "ep_reward": 247.98829650878906, "reward": 0.6429489850997925, "action": 1.1452645063400269}
{"mode": "train", "epochs": 2, "timestep": 2527, "ep_reward": 248.61883544921875, "reward": 0.6305445432662964, "action": 0.6799660325050354}
{"mode": "train", "epochs": 2, "timestep": 2528, "ep_reward": 249.22860717773438, "reward": 0.6097785234451294, "action": 0.5001041889190674}
{"mode": "train", "epochs": 2, "timestep": 2529, "ep_reward": 249.80923461914062, "reward": 0.5806291103363037, "action": 0.3508967161178589}
{"mode": "train", "epochs": 2, "timestep": 2530, "ep_reward": 250.3526153564453, "reward": 0.5433871746063232, "action": 0.49651092290878296}
{"mode": "train", "epochs": 2, "timestep": 2531, "ep_reward": 250.85328674316406, "reward": 0.5006775259971619, "action": 0.7708078622817993}
{"mode": "train", "epochs": 2, "timestep": 2532, "ep_reward": 251.3089141845703, "reward": 0.4556344747543335, "action": 1.6865507364273071}
{"mode": "train", "epochs": 2, "timestep": 2533, "ep_reward": 251.72499084472656, "reward": 0.41606980562210083, "action": 1.1736642122268677}
{"mode": "train", "epochs": 2, "timestep": 2534, "ep_reward": 252.10096740722656, "reward": 0.37598246335983276, "action": 0.5754385590553284}
{"mode": "train", "epochs": 2, "timestep": 2535, "ep_reward": 252.4740753173828, "reward": 0.3731096386909485, "action": 0.11545777320861816}
{"mode": "train", "epochs": 2, "timestep": 2536, "ep_reward": 252.88844299316406, "reward": 0.4143695831298828, "action": 1.0337270498275757}
{"mode": "train", "epochs": 2, "timestep": 2537, "ep_reward": 253.34310913085938, "reward": 0.45466554164886475, "action": 0.8302969932556152}
{"mode": "train", "epochs": 2, "timestep": 2538, "ep_reward": 253.83145141601562, "reward": 0.4883437156677246, "action": -0.08326970040798187}
{"mode": "train", "epochs": 2, "timestep": 2539, "ep_reward": 254.3463897705078, "reward": 0.51493239402771, "action": 0.06974514573812485}
{"mode": "train", "epochs": 2, "timestep": 2540, "ep_reward": 254.88270568847656, "reward": 0.5363152027130127, "action": -0.22660961747169495}
{"mode": "train", "epochs": 2, "timestep": 2541, "ep_reward": 255.43408203125, "reward": 0.5513731241226196, "action": 1.5180665254592896}
{"mode": "train", "epochs": 2, "timestep": 2542, "ep_reward": 255.99122619628906, "reward": 0.557137131690979, "action": 0.9753685593605042}
{"mode": "train", "epochs": 2, "timestep": 2543, "ep_reward": 256.5420837402344, "reward": 0.5508648157119751, "action": 1.285620093345642}
{"mode": "train", "epochs": 2, "timestep": 2544, "ep_reward": 257.0743408203125, "reward": 0.5322427749633789, "action": 1.3391624689102173}
{"mode": "train", "epochs": 2, "timestep": 2545, "ep_reward": 257.57586669921875, "reward": 0.5015387535095215, "action": 0.9483031034469604}
{"mode": "train", "epochs": 2, "timestep": 2546, "ep_reward": 258.03802490234375, "reward": 0.46215587854385376, "action": 1.4481204748153687}
{"mode": "train", "epochs": 2, "timestep": 2547, "ep_reward": 258.449951171875, "reward": 0.4119293689727783, "action": 1.1356494426727295}
{"mode": "train", "epochs": 2, "timestep": 2548, "ep_reward": 258.8065490722656, "reward": 0.3565957546234131, "action": 0.5654422640800476}
{"mode": "train", "epochs": 2, "timestep": 2549, "ep_reward": 259.1864318847656, "reward": 0.3798907399177551, "action": 0.8471170663833618}
{"mode": "train", "epochs": 2, "timestep": 2550, "ep_reward": 259.6134033203125, "reward": 0.42695724964141846, "action": 1.8043320178985596}
{"mode": "train", "epochs": 2, "timestep": 2551, "ep_reward": 260.0856628417969, "reward": 0.47226637601852417, "action": 1.0944030284881592}
{"mode": "train", "epochs": 2, "timestep": 2552, "ep_reward": 260.6058349609375, "reward": 0.5201671719551086, "action": 1.4454704523086548}
{"mode": "train", "epochs": 2, "timestep": 2553, "ep_reward": 261.1706237792969, "reward": 0.5647901296615601, "action": 1.2018013000488281}
{"mode": "train", "epochs": 2, "timestep": 2554, "ep_reward": 261.77734375, "reward": 0.6067192554473877, "action": 0.10654711723327637}
{"mode": "train", "epochs": 2, "timestep": 2555, "ep_reward": 262.4217224121094, "reward": 0.644370436668396, "action": 1.334153652191162}
{"mode": "train", "epochs": 2, "timestep": 2556, "ep_reward": 263.0928649902344, "reward": 0.6711503267288208, "action": 0.6716558933258057}
{"mode": "train", "epochs": 2, "timestep": 2557, "ep_reward": 263.7835693359375, "reward": 0.6907028555870056, "action": 1.018671989440918}
{"mode": "train", "epochs": 2, "timestep": 2558, "ep_reward": 264.484375, "reward": 0.7008121609687805, "action": 1.167898416519165}
{"mode": "train", "epochs": 2, "timestep": 2559, "ep_reward": 265.18682861328125, "reward": 0.7024619579315186, "action": 0.19982582330703735}
{"mode": "train", "epochs": 2, "timestep": 2560, "ep_reward": 265.8794860839844, "reward": 0.6926628351211548, "action": 0.8839423656463623}
{"mode": "train", "epochs": 2, "timestep": 2561, "ep_reward": 266.55279541015625, "reward": 0.6733120083808899, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2562, "ep_reward": 267.2034606933594, "reward": 0.6506618857383728, "action": -0.07756006717681885}
{"mode": "train", "epochs": 2, "timestep": 2563, "ep_reward": 267.8152770996094, "reward": 0.6118038892745972, "action": 0.8168282508850098}
{"mode": "train", "epochs": 2, "timestep": 2564, "ep_reward": 268.3828430175781, "reward": 0.5675703287124634, "action": 0.12673938274383545}
{"mode": "train", "epochs": 2, "timestep": 2565, "ep_reward": 268.8947448730469, "reward": 0.5118916034698486, "action": 1.0687150955200195}
{"mode": "train", "epochs": 2, "timestep": 2566, "ep_reward": 269.3518981933594, "reward": 0.45715242624282837, "action": 0.7780612707138062}
{"mode": "train", "epochs": 2, "timestep": 2567, "ep_reward": 269.7509765625, "reward": 0.39909106492996216, "action": 0.6765878200531006}
{"mode": "train", "epochs": 2, "timestep": 2568, "ep_reward": 270.0918273925781, "reward": 0.34084320068359375, "action": -0.7718263864517212}
{"mode": "train", "epochs": 2, "timestep": 2569, "ep_reward": 270.4598388671875, "reward": 0.36801964044570923, "action": -0.8405094742774963}
{"mode": "train", "epochs": 2, "timestep": 2570, "ep_reward": 270.8848876953125, "reward": 0.42505955696105957, "action": -0.8727829456329346}
{"mode": "train", "epochs": 2, "timestep": 2571, "ep_reward": 271.3668518066406, "reward": 0.48196935653686523, "action": -1.4453754425048828}
{"mode": "train", "epochs": 2, "timestep": 2572, "ep_reward": 271.90203857421875, "reward": 0.5351945161819458, "action": -1.2301050424575806}
{"mode": "train", "epochs": 2, "timestep": 2573, "ep_reward": 272.4886474609375, "reward": 0.5866194367408752, "action": -1.123390555381775}
{"mode": "train", "epochs": 2, "timestep": 2574, "ep_reward": 273.12200927734375, "reward": 0.6333711743354797, "action": -0.8610317707061768}
{"mode": "train", "epochs": 2, "timestep": 2575, "ep_reward": 273.7956848144531, "reward": 0.6736794710159302, "action": -0.6308620572090149}
{"mode": "train", "epochs": 2, "timestep": 2576, "ep_reward": 274.5007629394531, "reward": 0.7050797343254089, "action": -1.3064024448394775}
{"mode": "train", "epochs": 2, "timestep": 2577, "ep_reward": 275.2267761230469, "reward": 0.726012110710144, "action": -0.9089596271514893}
{"mode": "train", "epochs": 2, "timestep": 2578, "ep_reward": 275.96484375, "reward": 0.7380663156509399, "action": 0.05506034195423126}
{"mode": "train", "epochs": 2, "timestep": 2579, "ep_reward": 276.7026062011719, "reward": 0.7377476096153259, "action": 1.165894627571106}
{"mode": "train", "epochs": 2, "timestep": 2580, "ep_reward": 277.42169189453125, "reward": 0.7190871238708496, "action": -0.18143558502197266}
{"mode": "train", "epochs": 2, "timestep": 2581, "ep_reward": 278.10919189453125, "reward": 0.6875142455101013, "action": 0.38001343607902527}
{"mode": "train", "epochs": 2, "timestep": 2582, "ep_reward": 278.74847412109375, "reward": 0.6392755508422852, "action": -0.4763922095298767}
{"mode": "train", "epochs": 2, "timestep": 2583, "ep_reward": 279.3312683105469, "reward": 0.5828018188476562, "action": 0.44151943922042847}
{"mode": "train", "epochs": 2, "timestep": 2584, "ep_reward": 279.8404846191406, "reward": 0.5092277526855469, "action": 1.0814217329025269}
{"mode": "train", "epochs": 2, "timestep": 2585, "ep_reward": 280.259521484375, "reward": 0.4190426468849182, "action": 1.2188293933868408}
{"mode": "train", "epochs": 2, "timestep": 2586, "ep_reward": 280.5777587890625, "reward": 0.3182312250137329, "action": 0.6225880980491638}
{"mode": "train", "epochs": 2, "timestep": 2587, "ep_reward": 280.86865234375, "reward": 0.2908939719200134, "action": -0.10254305601119995}
{"mode": "train", "epochs": 2, "timestep": 2588, "ep_reward": 281.24560546875, "reward": 0.3769568204879761, "action": 0.8346713185310364}
{"mode": "train", "epochs": 2, "timestep": 2589, "ep_reward": 281.7018737792969, "reward": 0.4562692642211914, "action": 1.1331559419631958}
{"mode": "train", "epochs": 2, "timestep": 2590, "ep_reward": 282.23382568359375, "reward": 0.5319502353668213, "action": 0.14946407079696655}
{"mode": "train", "epochs": 2, "timestep": 2591, "ep_reward": 282.841552734375, "reward": 0.607727587223053, "action": 1.638354778289795}
{"mode": "train", "epochs": 2, "timestep": 2592, "ep_reward": 283.50860595703125, "reward": 0.6670488119125366, "action": 0.44805020093917847}
{"mode": "train", "epochs": 2, "timestep": 2593, "ep_reward": 284.2314147949219, "reward": 0.7228074073791504, "action": 0.8481264710426331}
{"mode": "train", "epochs": 2, "timestep": 2594, "ep_reward": 284.9963073730469, "reward": 0.7649060487747192, "action": 0.9660645723342896}
{"mode": "train", "epochs": 2, "timestep": 2595, "ep_reward": 285.7914123535156, "reward": 0.7951043844223022, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2596, "ep_reward": 286.6055603027344, "reward": 0.8141599297523499, "action": 1.6946135759353638}
{"mode": "train", "epochs": 2, "timestep": 2597, "ep_reward": 287.431396484375, "reward": 0.8258266448974609, "action": 1.1055755615234375}
{"mode": "train", "epochs": 2, "timestep": 2598, "ep_reward": 288.25982666015625, "reward": 0.8284350037574768, "action": 0.5816267728805542}
{"mode": "train", "epochs": 2, "timestep": 2599, "ep_reward": 289.0791015625, "reward": 0.8192616701126099, "action": 0.8081011176109314}
{"mode": "train", "epochs": 2, "timestep": 2600, "ep_reward": 289.87738037109375, "reward": 0.7982924580574036, "action": 1.271688461303711}
{"mode": "train", "epochs": 2, "timestep": 2601, "ep_reward": 290.64501953125, "reward": 0.7676429748535156, "action": -0.007114410400390625}
{"mode": "train", "epochs": 2, "timestep": 2602, "ep_reward": 291.3627624511719, "reward": 0.7177572250366211, "action": 1.6212860345840454}
{"mode": "train", "epochs": 2, "timestep": 2603, "ep_reward": 292.0271301269531, "reward": 0.6643775701522827, "action": 1.2470579147338867}
{"mode": "train", "epochs": 2, "timestep": 2604, "ep_reward": 292.6260681152344, "reward": 0.5989363193511963, "action": 1.3614672422409058}
{"mode": "train", "epochs": 2, "timestep": 2605, "ep_reward": 293.1522521972656, "reward": 0.5261937379837036, "action": 1.1428937911987305}
{"mode": "train", "epochs": 2, "timestep": 2606, "ep_reward": 293.598388671875, "reward": 0.4461216926574707, "action": 0.5670172572135925}
{"mode": "train", "epochs": 2, "timestep": 2607, "ep_reward": 293.9559020996094, "reward": 0.3575174808502197, "action": -1.224461317062378}
{"mode": "train", "epochs": 2, "timestep": 2608, "ep_reward": 294.2044982910156, "reward": 0.24858683347702026, "action": -0.37464141845703125}
{"mode": "train", "epochs": 2, "timestep": 2609, "ep_reward": 294.53314208984375, "reward": 0.328643798828125, "action": -0.8388109803199768}
{"mode": "train", "epochs": 2, "timestep": 2610, "ep_reward": 294.94671630859375, "reward": 0.4135892391204834, "action": -0.7283133268356323}
{"mode": "train", "epochs": 2, "timestep": 2611, "ep_reward": 295.4451904296875, "reward": 0.49846452474594116, "action": -1.139135718345642}
{"mode": "train", "epochs": 2, "timestep": 2612, "ep_reward": 296.0213928222656, "reward": 0.5761957764625549, "action": -1.9111034870147705}
{"mode": "train", "epochs": 2, "timestep": 2613, "ep_reward": 296.66485595703125, "reward": 0.6434628367424011, "action": -1.1624680757522583}
{"mode": "train", "epochs": 2, "timestep": 2614, "ep_reward": 297.37225341796875, "reward": 0.7074073553085327, "action": -0.6811821460723877}
{"mode": "train", "epochs": 2, "timestep": 2615, "ep_reward": 298.1346130371094, "reward": 0.7623695731163025, "action": -0.7131918668746948}
{"mode": "train", "epochs": 2, "timestep": 2616, "ep_reward": 298.9389343261719, "reward": 0.8043337464332581, "action": -1.151737093925476}
{"mode": "train", "epochs": 2, "timestep": 2617, "ep_reward": 299.7722473144531, "reward": 0.8333269357681274, "action": -0.8482373952865601}
{"mode": "train", "epochs": 2, "timestep": 2618, "ep_reward": 300.6244201660156, "reward": 0.8521677851676941, "action": 0.3119954466819763}
{"mode": "train", "epochs": 2, "timestep": 2619, "ep_reward": 301.4833984375, "reward": 0.8589890599250793, "action": 0.24526089429855347}
{"mode": "train", "epochs": 2, "timestep": 2620, "ep_reward": 302.33392333984375, "reward": 0.8505235910415649, "action": -0.713302731513977}
{"mode": "train", "epochs": 2, "timestep": 2621, "ep_reward": 303.1642761230469, "reward": 0.8303438425064087, "action": 0.18522650003433228}
{"mode": "train", "epochs": 2, "timestep": 2622, "ep_reward": 303.95721435546875, "reward": 0.79293292760849, "action": -0.35015183687210083}
{"mode": "train", "epochs": 2, "timestep": 2623, "ep_reward": 304.698974609375, "reward": 0.741767168045044, "action": -0.7661846280097961}
{"mode": "train", "epochs": 2, "timestep": 2624, "ep_reward": 305.37725830078125, "reward": 0.6782717704772949, "action": -0.2636467218399048}
{"mode": "train", "epochs": 2, "timestep": 2625, "ep_reward": 305.97344970703125, "reward": 0.5961799621582031, "action": -0.8712126612663269}
{"mode": "train", "epochs": 2, "timestep": 2626, "ep_reward": 306.4797058105469, "reward": 0.5062580108642578, "action": -1.6538211107254028}
{"mode": "train", "epochs": 2, "timestep": 2627, "ep_reward": 306.89703369140625, "reward": 0.4173364043235779, "action": -1.5864112377166748}
{"mode": "train", "epochs": 2, "timestep": 2628, "ep_reward": 307.2242736816406, "reward": 0.32724010944366455, "action": -0.4357154369354248}
{"mode": "train", "epochs": 2, "timestep": 2629, "ep_reward": 307.4595031738281, "reward": 0.23522311449050903, "action": -0.43518710136413574}
{"mode": "train", "epochs": 2, "timestep": 2630, "ep_reward": 307.79034423828125, "reward": 0.33084094524383545, "action": -1.924999713897705}
{"mode": "train", "epochs": 2, "timestep": 2631, "ep_reward": 308.22491455078125, "reward": 0.43457841873168945, "action": -1.240202784538269}
{"mode": "train", "epochs": 2, "timestep": 2632, "ep_reward": 308.7486877441406, "reward": 0.5237756967544556, "action": -0.11601763963699341}
{"mode": "train", "epochs": 2, "timestep": 2633, "ep_reward": 309.3445739746094, "reward": 0.5958871841430664, "action": -0.5470061302185059}
{"mode": "train", "epochs": 2, "timestep": 2634, "ep_reward": 310.00311279296875, "reward": 0.658530592918396, "action": -0.45833921432495117}
{"mode": "train", "epochs": 2, "timestep": 2635, "ep_reward": 310.7093505859375, "reward": 0.7062477469444275, "action": 0.2874203026294708}
{"mode": "train", "epochs": 2, "timestep": 2636, "ep_reward": 311.44708251953125, "reward": 0.7377402782440186, "action": 1.3896021842956543}
{"mode": "train", "epochs": 2, "timestep": 2637, "ep_reward": 312.203857421875, "reward": 0.756770670413971, "action": -0.23978859186172485}
{"mode": "train", "epochs": 2, "timestep": 2638, "ep_reward": 312.9687805175781, "reward": 0.7649294137954712, "action": 0.42929530143737793}
{"mode": "train", "epochs": 2, "timestep": 2639, "ep_reward": 313.7279968261719, "reward": 0.7592166662216187, "action": 0.15578073263168335}
{"mode": "train", "epochs": 2, "timestep": 2640, "ep_reward": 314.467529296875, "reward": 0.7395353317260742, "action": 0.5409932732582092}
{"mode": "train", "epochs": 2, "timestep": 2641, "ep_reward": 315.17523193359375, "reward": 0.7077112793922424, "action": 0.38234275579452515}
{"mode": "train", "epochs": 2, "timestep": 2642, "ep_reward": 315.83782958984375, "reward": 0.6625939607620239, "action": 0.165246844291687}
{"mode": "train", "epochs": 2, "timestep": 2643, "ep_reward": 316.4413757324219, "reward": 0.6035442352294922, "action": 0.553987979888916}
{"mode": "train", "epochs": 2, "timestep": 2644, "ep_reward": 316.9774169921875, "reward": 0.5360455513000488, "action": 1.3918917179107666}
{"mode": "train", "epochs": 2, "timestep": 2645, "ep_reward": 317.4463195800781, "reward": 0.4689098000526428, "action": 0.9656557440757751}
{"mode": "train", "epochs": 2, "timestep": 2646, "ep_reward": 317.8425598144531, "reward": 0.39624834060668945, "action": 0.8918901681900024}
{"mode": "train", "epochs": 2, "timestep": 2647, "ep_reward": 318.166015625, "reward": 0.32344675064086914, "action": -0.22294455766677856}
{"mode": "train", "epochs": 2, "timestep": 2648, "ep_reward": 318.501708984375, "reward": 0.33570796251296997, "action": -0.28688251972198486}
{"mode": "train", "epochs": 2, "timestep": 2649, "ep_reward": 318.9093017578125, "reward": 0.4075791835784912, "action": -0.9279570579528809}
{"mode": "train", "epochs": 2, "timestep": 2650, "ep_reward": 319.38482666015625, "reward": 0.47552549839019775, "action": -0.6203500032424927}
{"mode": "train", "epochs": 2, "timestep": 2651, "ep_reward": 319.92755126953125, "reward": 0.5427140593528748, "action": -0.0079270601272583}
{"mode": "train", "epochs": 2, "timestep": 2652, "ep_reward": 320.5338439941406, "reward": 0.6062927842140198, "action": -0.7148152589797974}
{"mode": "train", "epochs": 2, "timestep": 2653, "ep_reward": 321.19134521484375, "reward": 0.6574885249137878, "action": -1.8297569751739502}
{"mode": "train", "epochs": 2, "timestep": 2654, "ep_reward": 321.88861083984375, "reward": 0.697267472743988, "action": -1.442969799041748}
{"mode": "train", "epochs": 2, "timestep": 2655, "ep_reward": 322.6197204589844, "reward": 0.7310959696769714, "action": -0.5095506906509399}
{"mode": "train", "epochs": 2, "timestep": 2656, "ep_reward": 323.37652587890625, "reward": 0.7568042874336243, "action": -0.8694358468055725}
{"mode": "train", "epochs": 2, "timestep": 2657, "ep_reward": 324.14703369140625, "reward": 0.7705103158950806, "action": -0.6946884989738464}
{"mode": "train", "epochs": 2, "timestep": 2658, "ep_reward": 324.9198913574219, "reward": 0.7728641629219055, "action": 0.9863858222961426}
{"mode": "train", "epochs": 2, "timestep": 2659, "ep_reward": 325.6780090332031, "reward": 0.7581090331077576, "action": -0.829346239566803}
{"mode": "train", "epochs": 2, "timestep": 2660, "ep_reward": 326.4103088378906, "reward": 0.7323099970817566, "action": -0.8757737874984741}
{"mode": "train", "epochs": 2, "timestep": 2661, "ep_reward": 327.10565185546875, "reward": 0.6953561902046204, "action": -0.5520038604736328}
{"mode": "train", "epochs": 2, "timestep": 2662, "ep_reward": 327.7509460449219, "reward": 0.6452841758728027, "action": -0.18943530321121216}
{"mode": "train", "epochs": 2, "timestep": 2663, "ep_reward": 328.33184814453125, "reward": 0.5808950662612915, "action": -1.297950267791748}
{"mode": "train", "epochs": 2, "timestep": 2664, "ep_reward": 328.8474426269531, "reward": 0.5155940055847168, "action": -0.755666971206665}
{"mode": "train", "epochs": 2, "timestep": 2665, "ep_reward": 329.2886657714844, "reward": 0.44122153520584106, "action": -1.0564298629760742}
{"mode": "train", "epochs": 2, "timestep": 2666, "ep_reward": 329.6561279296875, "reward": 0.36746126413345337, "action": -0.53956139087677}
{"mode": "train", "epochs": 2, "timestep": 2667, "ep_reward": 329.9465637207031, "reward": 0.29044461250305176, "action": -1.0345295667648315}
{"mode": "train", "epochs": 2, "timestep": 2668, "ep_reward": 330.3123779296875, "reward": 0.3658226728439331, "action": -0.541663408279419}
{"mode": "train", "epochs": 2, "timestep": 2669, "ep_reward": 330.75091552734375, "reward": 0.43853676319122314, "action": -1.6241815090179443}
{"mode": "train", "epochs": 2, "timestep": 2670, "ep_reward": 331.2611083984375, "reward": 0.5102049112319946, "action": 0.00786416232585907}
{"mode": "train", "epochs": 2, "timestep": 2671, "ep_reward": 331.8265075683594, "reward": 0.5654011964797974, "action": 0.6581657528877258}
{"mode": "train", "epochs": 2, "timestep": 2672, "ep_reward": 332.4377136230469, "reward": 0.611198902130127, "action": -0.413651704788208}
{"mode": "train", "epochs": 2, "timestep": 2673, "ep_reward": 333.0884704589844, "reward": 0.6507716178894043, "action": 0.08918750286102295}
{"mode": "train", "epochs": 2, "timestep": 2674, "ep_reward": 333.76568603515625, "reward": 0.6772253513336182, "action": 0.16266626119613647}
{"mode": "train", "epochs": 2, "timestep": 2675, "ep_reward": 334.45751953125, "reward": 0.6918455362319946, "action": 1.2016021013259888}
{"mode": "train", "epochs": 2, "timestep": 2676, "ep_reward": 335.1540222167969, "reward": 0.6964937448501587, "action": 1.2963063716888428}
{"mode": "train", "epochs": 2, "timestep": 2677, "ep_reward": 335.8472595214844, "reward": 0.6932300329208374, "action": 1.6857905387878418}
{"mode": "train", "epochs": 2, "timestep": 2678, "ep_reward": 336.53094482421875, "reward": 0.6836937665939331, "action": 0.6446645855903625}
{"mode": "train", "epochs": 2, "timestep": 2679, "ep_reward": 337.1944885253906, "reward": 0.6635572910308838, "action": 1.2235066890716553}
{"mode": "train", "epochs": 2, "timestep": 2680, "ep_reward": 337.8311767578125, "reward": 0.6366821527481079, "action": 1.068878173828125}
{"mode": "train", "epochs": 2, "timestep": 2681, "ep_reward": 338.4333190917969, "reward": 0.6021536588668823, "action": 0.48616158962249756}
{"mode": "train", "epochs": 2, "timestep": 2682, "ep_reward": 338.9908142089844, "reward": 0.5574885606765747, "action": -0.046859562397003174}
{"mode": "train", "epochs": 2, "timestep": 2683, "ep_reward": 339.4927062988281, "reward": 0.5018829107284546, "action": 0.39922451972961426}
{"mode": "train", "epochs": 2, "timestep": 2684, "ep_reward": 339.9356689453125, "reward": 0.4429616332054138, "action": 0.9459584355354309}
{"mode": "train", "epochs": 2, "timestep": 2685, "ep_reward": 340.32183837890625, "reward": 0.3861786723136902, "action": 0.337857723236084}
{"mode": "train", "epochs": 2, "timestep": 2686, "ep_reward": 340.6480407714844, "reward": 0.32621294260025024, "action": 0.2209566831588745}
{"mode": "train", "epochs": 2, "timestep": 2687, "ep_reward": 341.03271484375, "reward": 0.3846706748008728, "action": -1.0602113008499146}
{"mode": "train", "epochs": 2, "timestep": 2688, "ep_reward": 341.470947265625, "reward": 0.43822968006134033, "action": -0.9313254356384277}
{"mode": "train", "epochs": 2, "timestep": 2689, "ep_reward": 341.9632568359375, "reward": 0.4923129677772522, "action": -1.3885911703109741}
{"mode": "train", "epochs": 2, "timestep": 2690, "ep_reward": 342.5063781738281, "reward": 0.5431177020072937, "action": -0.4142041802406311}
{"mode": "train", "epochs": 2, "timestep": 2691, "ep_reward": 343.09979248046875, "reward": 0.5934175252914429, "action": -1.1914122104644775}
{"mode": "train", "epochs": 2, "timestep": 2692, "ep_reward": 343.7344970703125, "reward": 0.6346997618675232, "action": -0.5131403207778931}
{"mode": "train", "epochs": 2, "timestep": 2693, "ep_reward": 344.4045715332031, "reward": 0.6700785756111145, "action": -1.48469877243042}
{"mode": "train", "epochs": 2, "timestep": 2694, "ep_reward": 345.09991455078125, "reward": 0.6953556537628174, "action": -0.744407057762146}
{"mode": "train", "epochs": 2, "timestep": 2695, "ep_reward": 345.8130798339844, "reward": 0.7131516933441162, "action": -0.06878501176834106}
{"mode": "train", "epochs": 2, "timestep": 2696, "ep_reward": 346.5326843261719, "reward": 0.7195971608161926, "action": 0.3574305474758148}
{"mode": "train", "epochs": 2, "timestep": 2697, "ep_reward": 347.24420166015625, "reward": 0.7115107774734497, "action": 0.27399787306785583}
{"mode": "train", "epochs": 2, "timestep": 2698, "ep_reward": 347.93267822265625, "reward": 0.6884669065475464, "action": -0.4769405722618103}
{"mode": "train", "epochs": 2, "timestep": 2699, "ep_reward": 348.5873718261719, "reward": 0.6546858549118042, "action": -1.5785229206085205}
{"mode": "train", "epochs": 2, "timestep": 2700, "ep_reward": 349.2046813964844, "reward": 0.6173205375671387, "action": -0.0739322304725647}
{"mode": "train", "epochs": 2, "timestep": 2701, "ep_reward": 349.76861572265625, "reward": 0.5639262795448303, "action": -1.0864027738571167}
{"mode": "train", "epochs": 2, "timestep": 2702, "ep_reward": 350.2778015136719, "reward": 0.5091816782951355, "action": -0.47578051686286926}
{"mode": "train", "epochs": 2, "timestep": 2703, "ep_reward": 350.72369384765625, "reward": 0.44587939977645874, "action": -1.4377634525299072}
{"mode": "train", "epochs": 2, "timestep": 2704, "ep_reward": 351.1121520996094, "reward": 0.38845932483673096, "action": -1.113892674446106}
{"mode": "train", "epochs": 2, "timestep": 2705, "ep_reward": 351.44342041015625, "reward": 0.3312603235244751, "action": 0.005218029022216797}
{"mode": "train", "epochs": 2, "timestep": 2706, "ep_reward": 351.8185119628906, "reward": 0.37510502338409424, "action": -0.6259894967079163}
{"mode": "train", "epochs": 2, "timestep": 2707, "ep_reward": 352.25421142578125, "reward": 0.43569594621658325, "action": -0.8297704458236694}
{"mode": "train", "epochs": 2, "timestep": 2708, "ep_reward": 352.7463073730469, "reward": 0.4921015501022339, "action": -0.13871455192565918}
{"mode": "train", "epochs": 2, "timestep": 2709, "ep_reward": 353.2857360839844, "reward": 0.5394378900527954, "action": 0.14940214157104492}
{"mode": "train", "epochs": 2, "timestep": 2710, "ep_reward": 353.8648986816406, "reward": 0.5791561007499695, "action": 0.06119883060455322}
{"mode": "train", "epochs": 2, "timestep": 2711, "ep_reward": 354.4759521484375, "reward": 0.611051082611084, "action": 0.9042062163352966}
{"mode": "train", "epochs": 2, "timestep": 2712, "ep_reward": 355.1097717285156, "reward": 0.6338212490081787, "action": 0.9242902994155884}
{"mode": "train", "epochs": 2, "timestep": 2713, "ep_reward": 355.7593078613281, "reward": 0.6495358943939209, "action": 1.1089277267456055}
{"mode": "train", "epochs": 2, "timestep": 2714, "ep_reward": 356.4172058105469, "reward": 0.6578856706619263, "action": 1.8948626518249512}
{"mode": "train", "epochs": 2, "timestep": 2715, "ep_reward": 357.07818603515625, "reward": 0.6609703302383423, "action": 1.1272516250610352}
{"mode": "train", "epochs": 2, "timestep": 2716, "ep_reward": 357.73541259765625, "reward": 0.6572246551513672, "action": 1.787630319595337}
{"mode": "train", "epochs": 2, "timestep": 2717, "ep_reward": 358.3841552734375, "reward": 0.6487538814544678, "action": 0.2682042717933655}
{"mode": "train", "epochs": 2, "timestep": 2718, "ep_reward": 359.0135192871094, "reward": 0.6293635368347168, "action": 1.1279518604278564}
{"mode": "train", "epochs": 2, "timestep": 2719, "ep_reward": 359.6180114746094, "reward": 0.6045069694519043, "action": 0.3868923783302307}
{"mode": "train", "epochs": 2, "timestep": 2720, "ep_reward": 360.1876220703125, "reward": 0.5696101188659668, "action": 1.337254285812378}
{"mode": "train", "epochs": 2, "timestep": 2721, "ep_reward": 360.7210693359375, "reward": 0.5334458947181702, "action": 0.7203574180603027}
{"mode": "train", "epochs": 2, "timestep": 2722, "ep_reward": 361.21160888671875, "reward": 0.49053168296813965, "action": 1.2416162490844727}
{"mode": "train", "epochs": 2, "timestep": 2723, "ep_reward": 361.6600646972656, "reward": 0.4484679698944092, "action": 0.7383371591567993}
{"mode": "train", "epochs": 2, "timestep": 2724, "ep_reward": 362.0632629394531, "reward": 0.4031965732574463, "action": 1.4916572570800781}
{"mode": "train", "epochs": 2, "timestep": 2725, "ep_reward": 362.42767333984375, "reward": 0.3644179701805115, "action": 0.5041487812995911}
{"mode": "train", "epochs": 2, "timestep": 2726, "ep_reward": 362.811767578125, "reward": 0.38408052921295166, "action": -0.14683735370635986}
{"mode": "train", "epochs": 2, "timestep": 2727, "ep_reward": 363.23675537109375, "reward": 0.42498350143432617, "action": -0.7129837274551392}
{"mode": "train", "epochs": 2, "timestep": 2728, "ep_reward": 363.7005920410156, "reward": 0.46382570266723633, "action": -0.23575156927108765}
{"mode": "train", "epochs": 2, "timestep": 2729, "ep_reward": 364.2023620605469, "reward": 0.5017578601837158, "action": -1.3850584030151367}
{"mode": "train", "epochs": 2, "timestep": 2730, "ep_reward": 364.7371520996094, "reward": 0.5348041653633118, "action": -0.5166715383529663}
{"mode": "train", "epochs": 2, "timestep": 2731, "ep_reward": 365.3034973144531, "reward": 0.5663498640060425, "action": -0.6455737948417664}
{"mode": "train", "epochs": 2, "timestep": 2732, "ep_reward": 365.8955993652344, "reward": 0.5920873880386353, "action": -0.3256397843360901}
{"mode": "train", "epochs": 2, "timestep": 2733, "ep_reward": 366.5068359375, "reward": 0.611233115196228, "action": -0.6011936068534851}
{"mode": "train", "epochs": 2, "timestep": 2734, "ep_reward": 367.12921142578125, "reward": 0.6223777532577515, "action": 1.5817492008209229}
{"mode": "train", "epochs": 2, "timestep": 2735, "ep_reward": 367.75006103515625, "reward": 0.6208535432815552, "action": 1.4580044746398926}
{"mode": "train", "epochs": 2, "timestep": 2736, "ep_reward": 368.3526306152344, "reward": 0.602576494216919, "action": 0.32473134994506836}
{"mode": "train", "epochs": 2, "timestep": 2737, "ep_reward": 368.9263000488281, "reward": 0.5736640095710754, "action": -0.6926898956298828}
{"mode": "train", "epochs": 2, "timestep": 2738, "ep_reward": 369.4668273925781, "reward": 0.5405398607254028, "action": -0.28846022486686707}
{"mode": "train", "epochs": 2, "timestep": 2739, "ep_reward": 369.9668273925781, "reward": 0.5000013113021851, "action": -0.3195842504501343}
{"mode": "train", "epochs": 2, "timestep": 2740, "ep_reward": 370.42169189453125, "reward": 0.45486873388290405, "action": -1.1112046241760254}
{"mode": "train", "epochs": 2, "timestep": 2741, "ep_reward": 370.83428955078125, "reward": 0.4125939607620239, "action": -1.8581161499023438}
{"mode": "train", "epochs": 2, "timestep": 2742, "ep_reward": 371.21173095703125, "reward": 0.37745511531829834, "action": -0.42519399523735046}
{"mode": "train", "epochs": 2, "timestep": 2743, "ep_reward": 371.58673095703125, "reward": 0.3750144839286804, "action": -0.14563962817192078}
{"mode": "train", "epochs": 2, "timestep": 2744, "ep_reward": 372.00146484375, "reward": 0.41474437713623047, "action": 0.4857272505760193}
{"mode": "train", "epochs": 2, "timestep": 2745, "ep_reward": 372.4534606933594, "reward": 0.4519991874694824, "action": -0.644771933555603}
{"mode": "train", "epochs": 2, "timestep": 2746, "ep_reward": 372.9420166015625, "reward": 0.48855531215667725, "action": 1.1657114028930664}
{"mode": "train", "epochs": 2, "timestep": 2747, "ep_reward": 373.4601745605469, "reward": 0.518151044845581, "action": 0.8192450404167175}
{"mode": "train", "epochs": 2, "timestep": 2748, "ep_reward": 374.006103515625, "reward": 0.5459213256835938, "action": -0.6393498182296753}
{"mode": "train", "epochs": 2, "timestep": 2749, "ep_reward": 374.5752258300781, "reward": 0.5691335201263428, "action": 1.1383167505264282}
{"mode": "train", "epochs": 2, "timestep": 2750, "ep_reward": 375.1595458984375, "reward": 0.584314227104187, "action": 0.5030696988105774}
{"mode": "train", "epochs": 2, "timestep": 2751, "ep_reward": 375.7535705566406, "reward": 0.5940373539924622, "action": 1.621413230895996}
{"mode": "train", "epochs": 2, "timestep": 2752, "ep_reward": 376.35296630859375, "reward": 0.5993894934654236, "action": 0.7098644971847534}
{"mode": "train", "epochs": 2, "timestep": 2753, "ep_reward": 376.951904296875, "reward": 0.5989470481872559, "action": 1.806950569152832}
{"mode": "train", "epochs": 2, "timestep": 2754, "ep_reward": 377.54754638671875, "reward": 0.5956403613090515, "action": 0.5093655586242676}
{"mode": "train", "epochs": 2, "timestep": 2755, "ep_reward": 378.13262939453125, "reward": 0.5850965976715088, "action": 1.3773828744888306}
{"mode": "train", "epochs": 2, "timestep": 2756, "ep_reward": 378.70404052734375, "reward": 0.5714237689971924, "action": 0.7679921984672546}
{"mode": "train", "epochs": 2, "timestep": 2757, "ep_reward": 379.2558288574219, "reward": 0.551781415939331, "action": 0.38175588846206665}
{"mode": "train", "epochs": 2, "timestep": 2758, "ep_reward": 379.7813415527344, "reward": 0.5255099534988403, "action": 0.971932590007782}
{"mode": "train", "epochs": 2, "timestep": 2759, "ep_reward": 380.27886962890625, "reward": 0.49751847982406616, "action": 0.4223836660385132}
{"mode": "train", "epochs": 2, "timestep": 2760, "ep_reward": 380.74322509765625, "reward": 0.46435195207595825, "action": 1.2510337829589844}
{"mode": "train", "epochs": 2, "timestep": 2761, "ep_reward": 381.1771545410156, "reward": 0.43392616510391235, "action": 0.8393269777297974}
{"mode": "train", "epochs": 2, "timestep": 2762, "ep_reward": 381.5794372558594, "reward": 0.402290403842926, "action": 1.692575454711914}
{"mode": "train", "epochs": 2, "timestep": 2763, "ep_reward": 381.956787109375, "reward": 0.37735384702682495, "action": 1.053642749786377}
{"mode": "train", "epochs": 2, "timestep": 2764, "ep_reward": 382.3466796875, "reward": 0.3898922801017761, "action": 1.3287627696990967}
{"mode": "train", "epochs": 2, "timestep": 2765, "ep_reward": 382.76153564453125, "reward": 0.41485893726348877, "action": 0.4103478789329529}
{"mode": "train", "epochs": 2, "timestep": 2766, "ep_reward": 383.1963806152344, "reward": 0.4348539113998413, "action": 1.4131256341934204}
{"mode": "train", "epochs": 2, "timestep": 2767, "ep_reward": 383.6466064453125, "reward": 0.4502307176589966, "action": 1.0363892316818237}
{"mode": "train", "epochs": 2, "timestep": 2768, "ep_reward": 384.10528564453125, "reward": 0.4586752653121948, "action": 0.2451297640800476}
{"mode": "train", "epochs": 2, "timestep": 2769, "ep_reward": 384.5675964355469, "reward": 0.4623134136199951, "action": 1.1255507469177246}
{"mode": "train", "epochs": 2, "timestep": 2770, "ep_reward": 385.0270080566406, "reward": 0.4594041109085083, "action": 1.6068857908248901}
{"mode": "train", "epochs": 2, "timestep": 2771, "ep_reward": 385.4747009277344, "reward": 0.4477003216743469, "action": 0.9564259052276611}
{"mode": "train", "epochs": 2, "timestep": 2772, "ep_reward": 385.90478515625, "reward": 0.4300714135169983, "action": 0.7730681896209717}
{"mode": "train", "epochs": 2, "timestep": 2773, "ep_reward": 386.3125915527344, "reward": 0.4077971577644348, "action": 1.669149398803711}
{"mode": "train", "epochs": 2, "timestep": 2774, "ep_reward": 386.68988037109375, "reward": 0.3772820830345154, "action": 0.41759786009788513}
{"mode": "train", "epochs": 2, "timestep": 2775, "ep_reward": 387.0825500488281, "reward": 0.39266669750213623, "action": 1.0322866439819336}
{"mode": "train", "epochs": 2, "timestep": 2776, "ep_reward": 387.5023498535156, "reward": 0.4198065400123596, "action": 0.6613127589225769}
{"mode": "train", "epochs": 2, "timestep": 2777, "ep_reward": 387.9504089355469, "reward": 0.4480704665184021, "action": 1.7866439819335938}
{"mode": "train", "epochs": 2, "timestep": 2778, "ep_reward": 388.42608642578125, "reward": 0.47566401958465576, "action": 1.0664241313934326}
{"mode": "train", "epochs": 2, "timestep": 2779, "ep_reward": 388.9307861328125, "reward": 0.5046963691711426, "action": 0.7440312504768372}
{"mode": "train", "epochs": 2, "timestep": 2780, "ep_reward": 389.4627990722656, "reward": 0.5320141315460205, "action": 1.337039589881897}
{"mode": "train", "epochs": 2, "timestep": 2781, "ep_reward": 390.0186462402344, "reward": 0.5558422803878784, "action": 1.2144391536712646}
{"mode": "train", "epochs": 2, "timestep": 2782, "ep_reward": 390.5956115722656, "reward": 0.5769708752632141, "action": 0.4017984867095947}
{"mode": "train", "epochs": 2, "timestep": 2783, "ep_reward": 391.18896484375, "reward": 0.5933572053909302, "action": 1.6494386196136475}
{"mode": "train", "epochs": 2, "timestep": 2784, "ep_reward": 391.7933654785156, "reward": 0.6043986678123474, "action": 1.7095203399658203}
{"mode": "train", "epochs": 2, "timestep": 2785, "ep_reward": 392.405517578125, "reward": 0.6121619343757629, "action": 1.2779242992401123}
{"mode": "train", "epochs": 2, "timestep": 2786, "ep_reward": 393.0209655761719, "reward": 0.6154589653015137, "action": 1.1595673561096191}
{"mode": "train", "epochs": 2, "timestep": 2787, "ep_reward": 393.6343078613281, "reward": 0.6133378744125366, "action": 1.376950740814209}
{"mode": "train", "epochs": 2, "timestep": 2788, "ep_reward": 394.2408447265625, "reward": 0.606549859046936, "action": 0.9684073328971863}
{"mode": "train", "epochs": 2, "timestep": 2789, "ep_reward": 394.83453369140625, "reward": 0.5936926007270813, "action": 1.1085056066513062}
{"mode": "train", "epochs": 2, "timestep": 2790, "ep_reward": 395.4104309082031, "reward": 0.5759010314941406, "action": 1.266714096069336}
{"mode": "train", "epochs": 2, "timestep": 2791, "ep_reward": 395.9649353027344, "reward": 0.5544955730438232, "action": 0.7419497966766357}
{"mode": "train", "epochs": 2, "timestep": 2792, "ep_reward": 396.49212646484375, "reward": 0.5272050499916077, "action": 0.7912076115608215}
{"mode": "train", "epochs": 2, "timestep": 2793, "ep_reward": 396.9884338378906, "reward": 0.49630165100097656, "action": 0.8040881156921387}
{"mode": "train", "epochs": 2, "timestep": 2794, "ep_reward": 397.451416015625, "reward": 0.462981641292572, "action": 0.7402342557907104}
{"mode": "train", "epochs": 2, "timestep": 2795, "ep_reward": 397.8796081542969, "reward": 0.4281807541847229, "action": 0.372017502784729}
{"mode": "train", "epochs": 2, "timestep": 2796, "ep_reward": 398.270751953125, "reward": 0.39113497734069824, "action": -0.16560286283493042}
{"mode": "train", "epochs": 2, "timestep": 2797, "ep_reward": 398.63787841796875, "reward": 0.36714011430740356, "action": 1.12046480178833}
{"mode": "train", "epochs": 2, "timestep": 2798, "ep_reward": 399.04351806640625, "reward": 0.40564823150634766, "action": 0.4064045250415802}
{"mode": "train", "epochs": 2, "timestep": 2799, "ep_reward": 399.4827575683594, "reward": 0.43922537565231323, "action": 0.48963838815689087}
{"mode": "train", "epochs": 2, "timestep": 2800, "ep_reward": 399.9519348144531, "reward": 0.469180703163147, "action": -0.1317451000213623}
{"mode": "train", "epochs": 2, "timestep": 2801, "ep_reward": 400.4461364746094, "reward": 0.4942052364349365, "action": 0.337393194437027}
{"mode": "train", "epochs": 2, "timestep": 2802, "ep_reward": 400.9609375, "reward": 0.5148115158081055, "action": 0.6068952083587646}
{"mode": "train", "epochs": 2, "timestep": 2803, "ep_reward": 401.4892272949219, "reward": 0.5282902717590332, "action": 1.8335158824920654}
{"mode": "train", "epochs": 2, "timestep": 2804, "ep_reward": 402.020263671875, "reward": 0.5310416221618652, "action": 0.35978126525878906}
{"mode": "train", "epochs": 2, "timestep": 2805, "ep_reward": 402.5448913574219, "reward": 0.5246391296386719, "action": 1.591483473777771}
{"mode": "train", "epochs": 2, "timestep": 2806, "ep_reward": 403.0511474609375, "reward": 0.5062441825866699, "action": 0.7776018381118774}
{"mode": "train", "epochs": 2, "timestep": 2807, "ep_reward": 403.5311584472656, "reward": 0.48001569509506226, "action": -0.22937864065170288}
{"mode": "train", "epochs": 2, "timestep": 2808, "ep_reward": 403.983154296875, "reward": 0.45200467109680176, "action": 0.21263490617275238}
{"mode": "train", "epochs": 2, "timestep": 2809, "ep_reward": 404.4021911621094, "reward": 0.41904133558273315, "action": 1.1166932582855225}
{"mode": "train", "epochs": 2, "timestep": 2810, "ep_reward": 404.7802429199219, "reward": 0.37806224822998047, "action": 0.2816299796104431}
{"mode": "train", "epochs": 2, "timestep": 2811, "ep_reward": 405.1614074707031, "reward": 0.3811553716659546, "action": 0.773073673248291}
{"mode": "train", "epochs": 2, "timestep": 2812, "ep_reward": 405.57867431640625, "reward": 0.4172714948654175, "action": 0.5529099106788635}
{"mode": "train", "epochs": 2, "timestep": 2813, "ep_reward": 406.03277587890625, "reward": 0.4540978670120239, "action": 1.2864344120025635}
{"mode": "train", "epochs": 2, "timestep": 2814, "ep_reward": 406.5218505859375, "reward": 0.4890626072883606, "action": -0.04904961585998535}
{"mode": "train", "epochs": 2, "timestep": 2815, "ep_reward": 407.0462951660156, "reward": 0.5244324207305908, "action": 0.7755265235900879}
{"mode": "train", "epochs": 2, "timestep": 2816, "ep_reward": 407.5998840332031, "reward": 0.5536031126976013, "action": 0.008877694606781006}
{"mode": "train", "epochs": 2, "timestep": 2817, "ep_reward": 408.17803955078125, "reward": 0.5781428217887878, "action": 0.8106874227523804}
{"mode": "train", "epochs": 2, "timestep": 2818, "ep_reward": 408.7732849121094, "reward": 0.5952433347702026, "action": 1.475337028503418}
{"mode": "train", "epochs": 2, "timestep": 2819, "ep_reward": 409.3807373046875, "reward": 0.607438325881958, "action": 1.2049341201782227}
{"mode": "train", "epochs": 2, "timestep": 2820, "ep_reward": 409.99578857421875, "reward": 0.6150571703910828, "action": 1.163388729095459}
{"mode": "train", "epochs": 2, "timestep": 2821, "ep_reward": 410.6131896972656, "reward": 0.6173934936523438, "action": 0.21633487939834595}
{"mode": "train", "epochs": 2, "timestep": 2822, "ep_reward": 411.22454833984375, "reward": 0.6113668084144592, "action": 1.069716453552246}
{"mode": "train", "epochs": 2, "timestep": 2823, "ep_reward": 411.8242492675781, "reward": 0.5997069478034973, "action": 0.1752699613571167}
{"mode": "train", "epochs": 2, "timestep": 2824, "ep_reward": 412.40301513671875, "reward": 0.5787748098373413, "action": 0.7043506503105164}
{"mode": "train", "epochs": 2, "timestep": 2825, "ep_reward": 412.9553527832031, "reward": 0.5523363351821899, "action": 1.7851619720458984}
{"mode": "train", "epochs": 2, "timestep": 2826, "ep_reward": 413.48223876953125, "reward": 0.5268797874450684, "action": 1.3240553140640259}
{"mode": "train", "epochs": 2, "timestep": 2827, "ep_reward": 413.98046875, "reward": 0.49822258949279785, "action": 1.2990176677703857}
{"mode": "train", "epochs": 2, "timestep": 2828, "ep_reward": 414.4490661621094, "reward": 0.46858859062194824, "action": 0.9924701452255249}
{"mode": "train", "epochs": 2, "timestep": 2829, "ep_reward": 414.886474609375, "reward": 0.4374009966850281, "action": -0.0915117859840393}
{"mode": "train", "epochs": 2, "timestep": 2830, "ep_reward": 415.28656005859375, "reward": 0.40009087324142456, "action": -0.25498977303504944}
{"mode": "train", "epochs": 2, "timestep": 2831, "ep_reward": 415.6468505859375, "reward": 0.3602777123451233, "action": -0.933391809463501}
{"mode": "train", "epochs": 2, "timestep": 2832, "ep_reward": 416.04290771484375, "reward": 0.39604949951171875, "action": -0.8652282953262329}
{"mode": "train", "epochs": 2, "timestep": 2833, "ep_reward": 416.47711181640625, "reward": 0.43421274423599243, "action": -0.3086792230606079}
{"mode": "train", "epochs": 2, "timestep": 2834, "ep_reward": 416.9502868652344, "reward": 0.47316622734069824, "action": -0.822311520576477}
{"mode": "train", "epochs": 2, "timestep": 2835, "ep_reward": 417.45904541015625, "reward": 0.508765697479248, "action": -1.4777336120605469}
{"mode": "train", "epochs": 2, "timestep": 2836, "ep_reward": 418.00030517578125, "reward": 0.5412688851356506, "action": -1.4825583696365356}
{"mode": "train", "epochs": 2, "timestep": 2837, "ep_reward": 418.5721740722656, "reward": 0.5718820095062256, "action": -1.1885091066360474}
{"mode": "train", "epochs": 2, "timestep": 2838, "ep_reward": 419.1717224121094, "reward": 0.5995354652404785, "action": -1.4334893226623535}
{"mode": "train", "epochs": 2, "timestep": 2839, "ep_reward": 419.7939758300781, "reward": 0.6222395896911621, "action": -1.9947844743728638}
{"mode": "train", "epochs": 2, "timestep": 2840, "ep_reward": 420.4345397949219, "reward": 0.6405553817749023, "action": -1.2946951389312744}
{"mode": "train", "epochs": 2, "timestep": 2841, "ep_reward": 421.089111328125, "reward": 0.6545765399932861, "action": 0.12869292497634888}
{"mode": "train", "epochs": 2, "timestep": 2842, "ep_reward": 421.748779296875, "reward": 0.6596632599830627, "action": 0.6419345736503601}
{"mode": "train", "epochs": 2, "timestep": 2843, "ep_reward": 422.3998718261719, "reward": 0.6510911583900452, "action": 0.30116578936576843}
{"mode": "train", "epochs": 2, "timestep": 2844, "ep_reward": 423.02947998046875, "reward": 0.6295971870422363, "action": 0.14954856038093567}
{"mode": "train", "epochs": 2, "timestep": 2845, "ep_reward": 423.62603759765625, "reward": 0.5965465307235718, "action": -0.5368635654449463}
{"mode": "train", "epochs": 2, "timestep": 2846, "ep_reward": 424.18310546875, "reward": 0.5570806264877319, "action": -0.29133087396621704}
{"mode": "train", "epochs": 2, "timestep": 2847, "ep_reward": 424.6925354003906, "reward": 0.5094197988510132, "action": -0.6489710807800293}
{"mode": "train", "epochs": 2, "timestep": 2848, "ep_reward": 425.1514587402344, "reward": 0.45892322063446045, "action": -0.39135923981666565}
{"mode": "train", "epochs": 2, "timestep": 2849, "ep_reward": 425.55572509765625, "reward": 0.4042573571205139, "action": -1.2034099102020264}
{"mode": "train", "epochs": 2, "timestep": 2850, "ep_reward": 425.9114074707031, "reward": 0.3556862473487854, "action": -0.1342887282371521}
{"mode": "train", "epochs": 2, "timestep": 2851, "ep_reward": 426.28521728515625, "reward": 0.37381529808044434, "action": -0.5678824186325073}
{"mode": "train", "epochs": 2, "timestep": 2852, "ep_reward": 426.7109375, "reward": 0.42571723461151123, "action": -0.5780880451202393}
{"mode": "train", "epochs": 2, "timestep": 2853, "ep_reward": 427.18463134765625, "reward": 0.4736882448196411, "action": 1.0987420082092285}
{"mode": "train", "epochs": 2, "timestep": 2854, "ep_reward": 427.6982421875, "reward": 0.5135964155197144, "action": 0.8118722438812256}
{"mode": "train", "epochs": 2, "timestep": 2855, "ep_reward": 428.2498779296875, "reward": 0.5516475439071655, "action": 1.5097475051879883}
{"mode": "train", "epochs": 2, "timestep": 2856, "ep_reward": 428.8345031738281, "reward": 0.5846347212791443, "action": 1.8913350105285645}
{"mode": "train", "epochs": 2, "timestep": 2857, "ep_reward": 429.4485168457031, "reward": 0.6140108704566956, "action": 1.5776288509368896}
{"mode": "train", "epochs": 2, "timestep": 2858, "ep_reward": 430.0887756347656, "reward": 0.6402595639228821, "action": 0.9056637287139893}
{"mode": "train", "epochs": 2, "timestep": 2859, "ep_reward": 430.7500305175781, "reward": 0.6612621545791626, "action": 0.4081803560256958}
{"mode": "train", "epochs": 2, "timestep": 2860, "ep_reward": 431.4236755371094, "reward": 0.6736477613449097, "action": 0.7068639397621155}
{"mode": "train", "epochs": 2, "timestep": 2861, "ep_reward": 432.0999450683594, "reward": 0.6762838363647461, "action": 1.0212303400039673}
{"mode": "train", "epochs": 2, "timestep": 2862, "ep_reward": 432.7705078125, "reward": 0.670556902885437, "action": 0.5736587047576904}
{"mode": "train", "epochs": 2, "timestep": 2863, "ep_reward": 433.425537109375, "reward": 0.6550360918045044, "action": 0.8154326677322388}
{"mode": "train", "epochs": 2, "timestep": 2864, "ep_reward": 434.0567321777344, "reward": 0.631182074546814, "action": -0.06712567806243896}
{"mode": "train", "epochs": 2, "timestep": 2865, "ep_reward": 434.65106201171875, "reward": 0.5943399667739868, "action": 1.4317402839660645}
{"mode": "train", "epochs": 2, "timestep": 2866, "ep_reward": 435.20794677734375, "reward": 0.5568879842758179, "action": 0.36382392048835754}
{"mode": "train", "epochs": 2, "timestep": 2867, "ep_reward": 435.7166748046875, "reward": 0.508718729019165, "action": -0.7277950048446655}
{"mode": "train", "epochs": 2, "timestep": 2868, "ep_reward": 436.16357421875, "reward": 0.44688719511032104, "action": -0.6021689772605896}
{"mode": "train", "epochs": 2, "timestep": 2869, "ep_reward": 436.5425109863281, "reward": 0.37894904613494873, "action": -1.6180121898651123}
{"mode": "train", "epochs": 2, "timestep": 2870, "ep_reward": 436.86224365234375, "reward": 0.3197391629219055, "action": -0.2238338589668274}
{"mode": "train", "epochs": 2, "timestep": 2871, "ep_reward": 437.2467041015625, "reward": 0.3844680190086365, "action": -1.057597041130066}
{"mode": "train", "epochs": 2, "timestep": 2872, "ep_reward": 437.6925964355469, "reward": 0.4458836317062378, "action": -0.7997037768363953}
{"mode": "train", "epochs": 2, "timestep": 2873, "ep_reward": 438.200439453125, "reward": 0.5078405737876892, "action": -1.5196564197540283}
{"mode": "train", "epochs": 2, "timestep": 2874, "ep_reward": 438.764404296875, "reward": 0.5639710426330566, "action": -1.255664348602295}
{"mode": "train", "epochs": 2, "timestep": 2875, "ep_reward": 439.3818664550781, "reward": 0.6174616813659668, "action": -0.9647807478904724}
{"mode": "train", "epochs": 2, "timestep": 2876, "ep_reward": 440.04718017578125, "reward": 0.6653234958648682, "action": -1.784531831741333}
{"mode": "train", "epochs": 2, "timestep": 2877, "ep_reward": 440.7503967285156, "reward": 0.7032212018966675, "action": -1.295736312866211}
{"mode": "train", "epochs": 2, "timestep": 2878, "ep_reward": 441.4853210449219, "reward": 0.734923779964447, "action": -0.6794975996017456}
{"mode": "train", "epochs": 2, "timestep": 2879, "ep_reward": 442.2430114746094, "reward": 0.7577040195465088, "action": -0.691504955291748}
{"mode": "train", "epochs": 2, "timestep": 2880, "ep_reward": 443.01190185546875, "reward": 0.7688906788825989, "action": -0.7529043555259705}
{"mode": "train", "epochs": 2, "timestep": 2881, "ep_reward": 443.7804260253906, "reward": 0.7685368657112122, "action": 0.5088810920715332}
{"mode": "train", "epochs": 2, "timestep": 2882, "ep_reward": 444.53277587890625, "reward": 0.7523571252822876, "action": 0.21952350437641144}
{"mode": "train", "epochs": 2, "timestep": 2883, "ep_reward": 445.2529296875, "reward": 0.7201461791992188, "action": -1.3705388307571411}
{"mode": "train", "epochs": 2, "timestep": 2884, "ep_reward": 445.9348449707031, "reward": 0.6819289922714233, "action": -0.9702895879745483}
{"mode": "train", "epochs": 2, "timestep": 2885, "ep_reward": 446.56695556640625, "reward": 0.6321194767951965, "action": -1.3998650312423706}
{"mode": "train", "epochs": 2, "timestep": 2886, "ep_reward": 447.1437072753906, "reward": 0.5767395496368408, "action": -0.21045517921447754}
{"mode": "train", "epochs": 2, "timestep": 2887, "ep_reward": 447.6490478515625, "reward": 0.5053353309631348, "action": -0.6806051731109619}
{"mode": "train", "epochs": 2, "timestep": 2888, "ep_reward": 448.0800476074219, "reward": 0.43100571632385254, "action": -0.08441227674484253}
{"mode": "train", "epochs": 2, "timestep": 2889, "ep_reward": 448.42852783203125, "reward": 0.34847748279571533, "action": -0.39209437370300293}
{"mode": "train", "epochs": 2, "timestep": 2890, "ep_reward": 448.7274169921875, "reward": 0.29890120029449463, "action": -0.8216455578804016}
{"mode": "train", "epochs": 2, "timestep": 2891, "ep_reward": 449.1056823730469, "reward": 0.37825924158096313, "action": -1.4974377155303955}
{"mode": "train", "epochs": 2, "timestep": 2892, "ep_reward": 449.5627136230469, "reward": 0.45703715085983276, "action": -0.6084936261177063}
{"mode": "train", "epochs": 2, "timestep": 2893, "ep_reward": 450.0861511230469, "reward": 0.5234459638595581, "action": 0.4608597457408905}
{"mode": "train", "epochs": 2, "timestep": 2894, "ep_reward": 450.66424560546875, "reward": 0.5781029462814331, "action": 0.7745721340179443}
{"mode": "train", "epochs": 2, "timestep": 2895, "ep_reward": 451.2892150878906, "reward": 0.6249734163284302, "action": 0.5284105539321899}
{"mode": "train", "epochs": 2, "timestep": 2896, "ep_reward": 451.9537048339844, "reward": 0.6644775867462158, "action": 0.5286743640899658}
{"mode": "train", "epochs": 2, "timestep": 2897, "ep_reward": 452.64776611328125, "reward": 0.6940752267837524, "action": 1.0107972621917725}
{"mode": "train", "epochs": 2, "timestep": 2898, "ep_reward": 453.3609924316406, "reward": 0.7132315635681152, "action": 0.8711560964584351}
{"mode": "train", "epochs": 2, "timestep": 2899, "ep_reward": 454.0838928222656, "reward": 0.7228947877883911, "action": 1.2311755418777466}
{"mode": "train", "epochs": 2, "timestep": 2900, "ep_reward": 454.8072814941406, "reward": 0.7234007120132446, "action": 0.4544352889060974}
{"mode": "train", "epochs": 2, "timestep": 2901, "ep_reward": 455.5199279785156, "reward": 0.7126612067222595, "action": 0.630765438079834}
{"mode": "train", "epochs": 2, "timestep": 2902, "ep_reward": 456.2107238769531, "reward": 0.6907947063446045, "action": 1.2309584617614746}
{"mode": "train", "epochs": 2, "timestep": 2903, "ep_reward": 456.8721008300781, "reward": 0.661369264125824, "action": -0.5220807194709778}
{"mode": "train", "epochs": 2, "timestep": 2904, "ep_reward": 457.48516845703125, "reward": 0.6130770444869995, "action": -1.2937226295471191}
{"mode": "train", "epochs": 2, "timestep": 2905, "ep_reward": 458.0299987792969, "reward": 0.544835090637207, "action": -0.4594267010688782}
{"mode": "train", "epochs": 2, "timestep": 2906, "ep_reward": 458.4984436035156, "reward": 0.46844226121902466, "action": -0.9235295057296753}
{"mode": "train", "epochs": 2, "timestep": 2907, "ep_reward": 458.87738037109375, "reward": 0.37892627716064453, "action": -1.964737057685852}
{"mode": "train", "epochs": 2, "timestep": 2908, "ep_reward": 459.14959716796875, "reward": 0.2722206115722656, "action": -0.8614693284034729}
{"mode": "train", "epochs": 2, "timestep": 2909, "ep_reward": 459.48199462890625, "reward": 0.3324078321456909, "action": -1.091638207435608}
{"mode": "train", "epochs": 2, "timestep": 2910, "ep_reward": 459.893798828125, "reward": 0.4118145704269409, "action": -1.089137077331543}
{"mode": "train", "epochs": 2, "timestep": 2911, "ep_reward": 460.38531494140625, "reward": 0.4915162920951843, "action": -0.9090867042541504}
{"mode": "train", "epochs": 2, "timestep": 2912, "ep_reward": 460.9544677734375, "reward": 0.5691432952880859, "action": -0.1945623755455017}
{"mode": "train", "epochs": 2, "timestep": 2913, "ep_reward": 461.59765625, "reward": 0.64319908618927, "action": -0.47059184312820435}
{"mode": "train", "epochs": 2, "timestep": 2914, "ep_reward": 462.3017883300781, "reward": 0.7041186690330505, "action": -0.9477537870407104}
{"mode": "train", "epochs": 2, "timestep": 2915, "ep_reward": 463.0531311035156, "reward": 0.7513308525085449, "action": -0.6227887868881226}
{"mode": "train", "epochs": 2, "timestep": 2916, "ep_reward": 463.8408203125, "reward": 0.7876970767974854, "action": -1.6928541660308838}
{"mode": "train", "epochs": 2, "timestep": 2917, "ep_reward": 464.6518859863281, "reward": 0.8110688328742981, "action": -1.2251871824264526}
{"mode": "train", "epochs": 2, "timestep": 2918, "ep_reward": 465.47784423828125, "reward": 0.8259724378585815, "action": -0.7564586997032166}
{"mode": "train", "epochs": 2, "timestep": 2919, "ep_reward": 466.3082580566406, "reward": 0.8304123878479004, "action": -0.17460176348686218}
{"mode": "train", "epochs": 2, "timestep": 2920, "ep_reward": 467.1298828125, "reward": 0.8216392993927002, "action": 0.7792124152183533}
{"mode": "train", "epochs": 2, "timestep": 2921, "ep_reward": 467.9243469238281, "reward": 0.7944753170013428, "action": -0.6170386075973511}
{"mode": "train", "epochs": 2, "timestep": 2922, "ep_reward": 468.6803283691406, "reward": 0.7559744119644165, "action": -0.2856391966342926}
{"mode": "train", "epochs": 2, "timestep": 2923, "ep_reward": 469.38165283203125, "reward": 0.7013282775878906, "action": -0.9197453856468201}
{"mode": "train", "epochs": 2, "timestep": 2924, "ep_reward": 470.01849365234375, "reward": 0.6368281841278076, "action": -1.141299843788147}
{"mode": "train", "epochs": 2, "timestep": 2925, "ep_reward": 470.5816650390625, "reward": 0.5631732940673828, "action": -0.3368259072303772}
{"mode": "train", "epochs": 2, "timestep": 2926, "ep_reward": 471.0546875, "reward": 0.473025918006897, "action": -1.2887510061264038}
{"mode": "train", "epochs": 2, "timestep": 2927, "ep_reward": 471.44085693359375, "reward": 0.38615530729293823, "action": -1.0094369649887085}
{"mode": "train", "epochs": 2, "timestep": 2928, "ep_reward": 471.73760986328125, "reward": 0.2967391610145569, "action": -0.8642122745513916}
{"mode": "train", "epochs": 2, "timestep": 2929, "ep_reward": 472.0332946777344, "reward": 0.2956858277320862, "action": -1.4855855703353882}
{"mode": "train", "epochs": 2, "timestep": 2930, "ep_reward": 472.4234924316406, "reward": 0.39021164178848267, "action": -0.9945778846740723}
{"mode": "train", "epochs": 2, "timestep": 2931, "ep_reward": 472.8990478515625, "reward": 0.475567102432251, "action": -0.5527406334877014}
{"mode": "train", "epochs": 2, "timestep": 2932, "ep_reward": 473.4493408203125, "reward": 0.5502943396568298, "action": 0.03811046481132507}
{"mode": "train", "epochs": 2, "timestep": 2933, "ep_reward": 474.0620422363281, "reward": 0.6126864552497864, "action": 0.3938524127006531}
{"mode": "train", "epochs": 2, "timestep": 2934, "ep_reward": 474.7255859375, "reward": 0.6635411977767944, "action": 1.7250432968139648}
{"mode": "train", "epochs": 2, "timestep": 2935, "ep_reward": 475.4271545410156, "reward": 0.7015621662139893, "action": 1.174570918083191}
{"mode": "train", "epochs": 2, "timestep": 2936, "ep_reward": 476.1603698730469, "reward": 0.7332274913787842, "action": 1.1325559616088867}
{"mode": "train", "epochs": 2, "timestep": 2937, "ep_reward": 476.9157409667969, "reward": 0.7553813457489014, "action": 1.8228304386138916}
{"mode": "train", "epochs": 2, "timestep": 2938, "ep_reward": 477.6840515136719, "reward": 0.7683115005493164, "action": 1.6603291034698486}
{"mode": "train", "epochs": 2, "timestep": 2939, "ep_reward": 478.4576416015625, "reward": 0.7735841274261475, "action": 1.2287722826004028}
{"mode": "train", "epochs": 2, "timestep": 2940, "ep_reward": 479.2273254394531, "reward": 0.7696872353553772, "action": 1.1215522289276123}
{"mode": "train", "epochs": 2, "timestep": 2941, "ep_reward": 479.98291015625, "reward": 0.7555719017982483, "action": 1.5237007141113281}
{"mode": "train", "epochs": 2, "timestep": 2942, "ep_reward": 480.7160949707031, "reward": 0.7331773042678833, "action": -0.32370468974113464}
{"mode": "train", "epochs": 2, "timestep": 2943, "ep_reward": 481.4078063964844, "reward": 0.6917129755020142, "action": -0.9846614599227905}
{"mode": "train", "epochs": 2, "timestep": 2944, "ep_reward": 482.0370788574219, "reward": 0.6292732357978821, "action": -1.105736494064331}
{"mode": "train", "epochs": 2, "timestep": 2945, "ep_reward": 482.58447265625, "reward": 0.5474051237106323, "action": -0.8662617206573486}
{"mode": "train", "epochs": 2, "timestep": 2946, "ep_reward": 483.0359191894531, "reward": 0.45144379138946533, "action": -1.179733157157898}
{"mode": "train", "epochs": 2, "timestep": 2947, "ep_reward": 483.3766784667969, "reward": 0.3407527208328247, "action": -1.4352850914001465}
{"mode": "train", "epochs": 2, "timestep": 2948, "ep_reward": 483.59765625, "reward": 0.22099167108535767, "action": -0.591029167175293}
{"mode": "train", "epochs": 2, "timestep": 2949, "ep_reward": 483.91064453125, "reward": 0.31299299001693726, "action": -0.4461156725883484}
{"mode": "train", "epochs": 2, "timestep": 2950, "ep_reward": 484.31884765625, "reward": 0.40821635723114014, "action": -0.729308545589447}
{"mode": "train", "epochs": 2, "timestep": 2951, "ep_reward": 484.818115234375, "reward": 0.49926304817199707, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 2952, "ep_reward": 485.3952941894531, "reward": 0.5771693587303162, "action": -1.0634177923202515}
{"mode": "train", "epochs": 2, "timestep": 2953, "ep_reward": 486.05078125, "reward": 0.6554873585700989, "action": -0.8824739456176758}
{"mode": "train", "epochs": 2, "timestep": 2954, "ep_reward": 486.7746887207031, "reward": 0.723913311958313, "action": -1.6440768241882324}
{"mode": "train", "epochs": 2, "timestep": 2955, "ep_reward": 487.55157470703125, "reward": 0.7768820524215698, "action": -0.6748684048652649}
{"mode": "train", "epochs": 2, "timestep": 2956, "ep_reward": 488.3742370605469, "reward": 0.8226646780967712, "action": -1.5442112684249878}
{"mode": "train", "epochs": 2, "timestep": 2957, "ep_reward": 489.2282409667969, "reward": 0.8539891839027405, "action": -1.4255290031433105}
{"mode": "train", "epochs": 2, "timestep": 2958, "ep_reward": 490.1048889160156, "reward": 0.8766571283340454, "action": -1.319398045539856}
{"mode": "train", "epochs": 2, "timestep": 2959, "ep_reward": 490.9960021972656, "reward": 0.8910996317863464, "action": -1.1182056665420532}
{"mode": "train", "epochs": 2, "timestep": 2960, "ep_reward": 491.8935546875, "reward": 0.8975462317466736, "action": -0.3413531184196472}
{"mode": "train", "epochs": 2, "timestep": 2961, "ep_reward": 492.7878112792969, "reward": 0.894258439540863, "action": 0.885262668132782}
{"mode": "train", "epochs": 2, "timestep": 2962, "ep_reward": 493.6634826660156, "reward": 0.8756835460662842, "action": -0.12433752417564392}
{"mode": "train", "epochs": 2, "timestep": 2963, "ep_reward": 494.508056640625, "reward": 0.8445613384246826, "action": 0.5649323463439941}
{"mode": "train", "epochs": 2, "timestep": 2964, "ep_reward": 495.3018798828125, "reward": 0.793826162815094, "action": -0.9316330552101135}
{"mode": "train", "epochs": 2, "timestep": 2965, "ep_reward": 496.0367126464844, "reward": 0.7348450422286987, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 2966, "ep_reward": 496.7078857421875, "reward": 0.6711653470993042, "action": -1.2289938926696777}
{"mode": "train", "epochs": 2, "timestep": 2967, "ep_reward": 497.29730224609375, "reward": 0.5894035696983337, "action": -1.5569207668304443}
{"mode": "train", "epochs": 2, "timestep": 2968, "ep_reward": 497.7976379394531, "reward": 0.500325083732605, "action": -1.1361405849456787}
{"mode": "train", "epochs": 2, "timestep": 2969, "ep_reward": 498.1977844238281, "reward": 0.4001612067222595, "action": -1.0469597578048706}
{"mode": "train", "epochs": 2, "timestep": 2970, "ep_reward": 498.4942321777344, "reward": 0.2964627146720886, "action": -1.067355751991272}
{"mode": "train", "epochs": 2, "timestep": 2971, "ep_reward": 498.7200927734375, "reward": 0.22585439682006836, "action": -0.1344628930091858}
{"mode": "train", "epochs": 2, "timestep": 2972, "ep_reward": 499.0455627441406, "reward": 0.3254826068878174, "action": -1.613680362701416}
{"mode": "train", "epochs": 2, "timestep": 2973, "ep_reward": 499.4804992675781, "reward": 0.43493157625198364, "action": -1.1713371276855469}
{"mode": "train", "epochs": 2, "timestep": 2974, "ep_reward": 500.0119323730469, "reward": 0.5314472913742065, "action": -0.34468507766723633}
{"mode": "train", "epochs": 2, "timestep": 2975, "ep_reward": 500.622802734375, "reward": 0.6108806133270264, "action": -0.7271726727485657}
{"mode": "train", "epochs": 2, "timestep": 2976, "ep_reward": 501.301513671875, "reward": 0.6786971688270569, "action": 1.4140362739562988}
{"mode": "train", "epochs": 2, "timestep": 2977, "ep_reward": 502.0262756347656, "reward": 0.72477126121521, "action": -0.28176313638687134}
{"mode": "train", "epochs": 2, "timestep": 2978, "ep_reward": 502.79095458984375, "reward": 0.7646784782409668, "action": 0.6020516753196716}
{"mode": "train", "epochs": 2, "timestep": 2979, "ep_reward": 503.5792541503906, "reward": 0.7882958650588989, "action": 1.1374324560165405}
{"mode": "train", "epochs": 2, "timestep": 2980, "ep_reward": 504.3793640136719, "reward": 0.8001012206077576, "action": 0.7820615768432617}
{"mode": "train", "epochs": 2, "timestep": 2981, "ep_reward": 505.18035888671875, "reward": 0.8009881377220154, "action": 1.104598879814148}
{"mode": "train", "epochs": 2, "timestep": 2982, "ep_reward": 505.97161865234375, "reward": 0.7912545800209045, "action": 0.27464598417282104}
{"mode": "train", "epochs": 2, "timestep": 2983, "ep_reward": 506.7389831542969, "reward": 0.7673496007919312, "action": -0.9653259515762329}
{"mode": "train", "epochs": 2, "timestep": 2984, "ep_reward": 507.4609680175781, "reward": 0.7219890356063843, "action": 0.5873721837997437}
{"mode": "train", "epochs": 2, "timestep": 2985, "ep_reward": 508.1283264160156, "reward": 0.667373538017273, "action": -1.7994098663330078}
{"mode": "train", "epochs": 2, "timestep": 2986, "ep_reward": 508.7078552246094, "reward": 0.5795252323150635, "action": -1.4044623374938965}
{"mode": "train", "epochs": 2, "timestep": 2987, "ep_reward": 509.18115234375, "reward": 0.4732917547225952, "action": -0.7236023545265198}
{"mode": "train", "epochs": 2, "timestep": 2988, "ep_reward": 509.53973388671875, "reward": 0.3585779070854187, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 2989, "ep_reward": 509.76019287109375, "reward": 0.22047239542007446, "action": -0.9790166020393372}
{"mode": "train", "epochs": 2, "timestep": 2990, "ep_reward": 510.0167541503906, "reward": 0.2565650939941406, "action": -0.8081305027008057}
{"mode": "train", "epochs": 2, "timestep": 2991, "ep_reward": 510.3754577636719, "reward": 0.3587028384208679, "action": -0.7798000574111938}
{"mode": "train", "epochs": 2, "timestep": 2992, "ep_reward": 510.8367919921875, "reward": 0.4613356590270996, "action": -0.6104663610458374}
{"mode": "train", "epochs": 2, "timestep": 2993, "ep_reward": 511.397216796875, "reward": 0.5604358911514282, "action": -0.11791574954986572}
{"mode": "train", "epochs": 2, "timestep": 2994, "ep_reward": 512.0498046875, "reward": 0.6525813341140747, "action": -1.6057257652282715}
{"mode": "train", "epochs": 2, "timestep": 2995, "ep_reward": 512.7714233398438, "reward": 0.721642255783081, "action": -1.1927934885025024}
{"mode": "train", "epochs": 2, "timestep": 2996, "ep_reward": 513.55322265625, "reward": 0.7818019390106201, "action": -0.654309868812561}
{"mode": "train", "epochs": 2, "timestep": 2997, "ep_reward": 514.3848876953125, "reward": 0.8316417932510376, "action": -1.3090466260910034}
{"mode": "train", "epochs": 2, "timestep": 2998, "ep_reward": 515.251708984375, "reward": 0.8667954206466675, "action": -0.3480735421180725}
{"mode": "train", "epochs": 2, "timestep": 2999, "ep_reward": 516.1458129882812, "reward": 0.8941276669502258, "action": -1.080435037612915}
{"mode": "train", "epochs": 2, "timestep": 3000, "ep_reward": 517.0556640625, "reward": 0.9098763465881348, "action": -1.2061121463775635}
{"mode": "train", "epochs": 2, "timestep": 3001, "ep_reward": 517.9735107421875, "reward": 0.9178693294525146, "action": -1.717033863067627}
{"mode": "train", "epochs": 2, "timestep": 3002, "ep_reward": 518.8933715820312, "reward": 0.919874906539917, "action": 0.4137558341026306}
{"mode": "train", "epochs": 2, "timestep": 3003, "ep_reward": 519.8053588867188, "reward": 0.9120147228240967, "action": 1.0664399862289429}
{"mode": "train", "epochs": 2, "timestep": 3004, "ep_reward": 520.6940307617188, "reward": 0.8886634707450867, "action": 1.414280891418457}
{"mode": "train", "epochs": 2, "timestep": 3005, "ep_reward": 521.5398559570312, "reward": 0.8458021283149719, "action": -0.04380735754966736}
{"mode": "train", "epochs": 2, "timestep": 3006, "ep_reward": 522.331298828125, "reward": 0.7914136052131653, "action": -0.41841280460357666}
{"mode": "train", "epochs": 2, "timestep": 3007, "ep_reward": 523.05322265625, "reward": 0.7219364643096924, "action": -0.7419507503509521}
{"mode": "train", "epochs": 2, "timestep": 3008, "ep_reward": 523.690673828125, "reward": 0.6374267339706421, "action": -1.1882648468017578}
{"mode": "train", "epochs": 2, "timestep": 3009, "ep_reward": 524.232177734375, "reward": 0.5415269732475281, "action": -1.4518375396728516}
{"mode": "train", "epochs": 2, "timestep": 3010, "ep_reward": 524.6694946289062, "reward": 0.4373283386230469, "action": -0.926333487033844}
{"mode": "train", "epochs": 2, "timestep": 3011, "ep_reward": 524.9901123046875, "reward": 0.3206446170806885, "action": -1.1035329103469849}
{"mode": "train", "epochs": 2, "timestep": 3012, "ep_reward": 525.1959228515625, "reward": 0.20582902431488037, "action": -0.8938498497009277}
{"mode": "train", "epochs": 2, "timestep": 3013, "ep_reward": 525.4421997070312, "reward": 0.24627727270126343, "action": -1.5222446918487549}
{"mode": "train", "epochs": 2, "timestep": 3014, "ep_reward": 525.81005859375, "reward": 0.3678327798843384, "action": -1.4326874017715454}
{"mode": "train", "epochs": 2, "timestep": 3015, "ep_reward": 526.2913208007812, "reward": 0.481268048286438, "action": -0.896005392074585}
{"mode": "train", "epochs": 2, "timestep": 3016, "ep_reward": 526.8699951171875, "reward": 0.5786809921264648, "action": -0.6180174350738525}
{"mode": "train", "epochs": 2, "timestep": 3017, "ep_reward": 527.5299072265625, "reward": 0.659896731376648, "action": 0.2621278166770935}
{"mode": "train", "epochs": 2, "timestep": 3018, "ep_reward": 528.2514038085938, "reward": 0.7215240001678467, "action": 0.8825806379318237}
{"mode": "train", "epochs": 2, "timestep": 3019, "ep_reward": 529.0191650390625, "reward": 0.7677642107009888, "action": 0.04963499307632446}
{"mode": "train", "epochs": 2, "timestep": 3020, "ep_reward": 529.822509765625, "reward": 0.8033509254455566, "action": 1.8921202421188354}
{"mode": "train", "epochs": 2, "timestep": 3021, "ep_reward": 530.646240234375, "reward": 0.8237581849098206, "action": 1.0352002382278442}
{"mode": "train", "epochs": 2, "timestep": 3022, "ep_reward": 531.482421875, "reward": 0.8361592888832092, "action": 0.015984296798706055}
{"mode": "train", "epochs": 2, "timestep": 3023, "ep_reward": 532.318603515625, "reward": 0.8362014293670654, "action": 1.5441559553146362}
{"mode": "train", "epochs": 2, "timestep": 3024, "ep_reward": 533.1451416015625, "reward": 0.8265563249588013, "action": -0.04603472352027893}
{"mode": "train", "epochs": 2, "timestep": 3025, "ep_reward": 533.9462890625, "reward": 0.8011623620986938, "action": -1.5306111574172974}
{"mode": "train", "epochs": 2, "timestep": 3026, "ep_reward": 534.6971435546875, "reward": 0.7508500814437866, "action": -1.646965742111206}
{"mode": "train", "epochs": 2, "timestep": 3027, "ep_reward": 535.372314453125, "reward": 0.6751490235328674, "action": -0.20914703607559204}
{"mode": "train", "epochs": 2, "timestep": 3028, "ep_reward": 535.960205078125, "reward": 0.5879189968109131, "action": -0.5746644735336304}
{"mode": "train", "epochs": 2, "timestep": 3029, "ep_reward": 536.4404296875, "reward": 0.48024290800094604, "action": -0.1436101198196411}
{"mode": "train", "epochs": 2, "timestep": 3030, "ep_reward": 536.80419921875, "reward": 0.3637514114379883, "action": -1.0451157093048096}
{"mode": "train", "epochs": 2, "timestep": 3031, "ep_reward": 537.033447265625, "reward": 0.22925400733947754, "action": -0.821160078048706}
{"mode": "train", "epochs": 2, "timestep": 3032, "ep_reward": 537.257080078125, "reward": 0.22363126277923584, "action": -1.3248518705368042}
{"mode": "train", "epochs": 2, "timestep": 3033, "ep_reward": 537.5816040039062, "reward": 0.3245497941970825, "action": -1.1877855062484741}
{"mode": "train", "epochs": 2, "timestep": 3034, "ep_reward": 538.0108642578125, "reward": 0.4292658567428589, "action": -1.0422728061676025}
{"mode": "train", "epochs": 2, "timestep": 3035, "ep_reward": 538.543212890625, "reward": 0.5323322415351868, "action": -0.6643905639648438}
{"mode": "train", "epochs": 2, "timestep": 3036, "ep_reward": 539.1729125976562, "reward": 0.6296764016151428, "action": -0.6863529682159424}
{"mode": "train", "epochs": 2, "timestep": 3037, "ep_reward": 539.8861694335938, "reward": 0.7132360935211182, "action": -0.5583562850952148}
{"mode": "train", "epochs": 2, "timestep": 3038, "ep_reward": 540.6685180664062, "reward": 0.7823551893234253, "action": -0.716954231262207}
{"mode": "train", "epochs": 2, "timestep": 3039, "ep_reward": 541.5040283203125, "reward": 0.8355393409729004, "action": -0.9031848907470703}
{"mode": "train", "epochs": 2, "timestep": 3040, "ep_reward": 542.3790283203125, "reward": 0.8749938011169434, "action": -0.37176692485809326}
{"mode": "train", "epochs": 2, "timestep": 3041, "ep_reward": 543.2839965820312, "reward": 0.9049859642982483, "action": -1.1981682777404785}
{"mode": "train", "epochs": 2, "timestep": 3042, "ep_reward": 544.20751953125, "reward": 0.9235199093818665, "action": -0.6061160564422607}
{"mode": "train", "epochs": 2, "timestep": 3043, "ep_reward": 545.143310546875, "reward": 0.9358213543891907, "action": -0.7058979272842407}
{"mode": "train", "epochs": 2, "timestep": 3044, "ep_reward": 546.0842895507812, "reward": 0.9409933686256409, "action": 0.5579615831375122}
{"mode": "train", "epochs": 2, "timestep": 3045, "ep_reward": 547.0220947265625, "reward": 0.9377801418304443, "action": 0.14820265769958496}
{"mode": "train", "epochs": 2, "timestep": 3046, "ep_reward": 547.9468994140625, "reward": 0.9247950911521912, "action": 1.3453094959259033}
{"mode": "train", "epochs": 2, "timestep": 3047, "ep_reward": 548.8427734375, "reward": 0.895880937576294, "action": 0.7082090377807617}
{"mode": "train", "epochs": 2, "timestep": 3048, "ep_reward": 549.6954345703125, "reward": 0.8526754379272461, "action": -0.6758418083190918}
{"mode": "train", "epochs": 2, "timestep": 3049, "ep_reward": 550.4966430664062, "reward": 0.8011792898178101, "action": -1.2682034969329834}
{"mode": "train", "epochs": 2, "timestep": 3050, "ep_reward": 551.2357177734375, "reward": 0.739089846611023, "action": -0.5365022420883179}
{"mode": "train", "epochs": 2, "timestep": 3051, "ep_reward": 551.8900146484375, "reward": 0.6542678475379944, "action": -0.27137261629104614}
{"mode": "train", "epochs": 2, "timestep": 3052, "ep_reward": 552.4378662109375, "reward": 0.5478360056877136, "action": -0.16349166631698608}
{"mode": "train", "epochs": 2, "timestep": 3053, "ep_reward": 552.8603515625, "reward": 0.42249733209609985, "action": -1.245116114616394}
{"mode": "train", "epochs": 2, "timestep": 3054, "ep_reward": 553.1607666015625, "reward": 0.3004067540168762, "action": -1.3164801597595215}
{"mode": "train", "epochs": 2, "timestep": 3055, "ep_reward": 553.34033203125, "reward": 0.17953598499298096, "action": -0.41064876317977905}
{"mode": "train", "epochs": 2, "timestep": 3056, "ep_reward": 553.5557861328125, "reward": 0.21547096967697144, "action": -1.4463307857513428}
{"mode": "train", "epochs": 2, "timestep": 3057, "ep_reward": 553.90234375, "reward": 0.34656375646591187, "action": -1.5762075185775757}
{"mode": "train", "epochs": 2, "timestep": 3058, "ep_reward": 554.3740844726562, "reward": 0.47172683477401733, "action": -0.5580441951751709}
{"mode": "train", "epochs": 2, "timestep": 3059, "ep_reward": 554.949951171875, "reward": 0.575884222984314, "action": -0.4215826094150543}
{"mode": "train", "epochs": 2, "timestep": 3060, "ep_reward": 555.61474609375, "reward": 0.6648008823394775, "action": -0.5286540985107422}
{"mode": "train", "epochs": 2, "timestep": 3061, "ep_reward": 556.352294921875, "reward": 0.7375370264053345, "action": 0.11678040027618408}
{"mode": "train", "epochs": 2, "timestep": 3062, "ep_reward": 557.1424560546875, "reward": 0.7901474237442017, "action": 0.318939745426178}
{"mode": "train", "epochs": 2, "timestep": 3063, "ep_reward": 557.969482421875, "reward": 0.8270524740219116, "action": 1.776122808456421}
{"mode": "train", "epochs": 2, "timestep": 3064, "ep_reward": 558.8187866210938, "reward": 0.8493096828460693, "action": 1.340855598449707}
{"mode": "train", "epochs": 2, "timestep": 3065, "ep_reward": 559.6826171875, "reward": 0.8638132810592651, "action": 0.6163276433944702}
{"mode": "train", "epochs": 2, "timestep": 3066, "ep_reward": 560.55126953125, "reward": 0.8686603307723999, "action": 1.0134408473968506}
{"mode": "train", "epochs": 2, "timestep": 3067, "ep_reward": 561.4144287109375, "reward": 0.8631850481033325, "action": 1.0966465473175049}
{"mode": "train", "epochs": 2, "timestep": 3068, "ep_reward": 562.2623901367188, "reward": 0.8479667901992798, "action": -0.6264529228210449}
{"mode": "train", "epochs": 2, "timestep": 3069, "ep_reward": 563.0763549804688, "reward": 0.8139426708221436, "action": -0.8760008215904236}
{"mode": "train", "epochs": 2, "timestep": 3070, "ep_reward": 563.8353271484375, "reward": 0.7589764595031738, "action": -1.6940118074417114}
{"mode": "train", "epochs": 2, "timestep": 3071, "ep_reward": 564.510498046875, "reward": 0.6751720905303955, "action": -0.8484833836555481}
{"mode": "train", "epochs": 2, "timestep": 3072, "ep_reward": 565.0836181640625, "reward": 0.5731101036071777, "action": -0.7350188493728638}
{"mode": "train", "epochs": 2, "timestep": 3073, "ep_reward": 565.5350341796875, "reward": 0.45142215490341187, "action": -1.181858777999878}
{"mode": "train", "epochs": 2, "timestep": 3074, "ep_reward": 565.843017578125, "reward": 0.30799657106399536, "action": -1.6362206935882568}
{"mode": "train", "epochs": 2, "timestep": 3075, "ep_reward": 565.9908447265625, "reward": 0.1478530764579773, "action": -1.0547759532928467}
{"mode": "train", "epochs": 2, "timestep": 3076, "ep_reward": 566.1884765625, "reward": 0.19764745235443115, "action": 0.10815870761871338}
{"mode": "train", "epochs": 2, "timestep": 3077, "ep_reward": 566.51416015625, "reward": 0.32567209005355835, "action": -1.1613491773605347}
{"mode": "train", "epochs": 2, "timestep": 3078, "ep_reward": 566.9533081054688, "reward": 0.43915098905563354, "action": -0.5000534057617188}
{"mode": "train", "epochs": 2, "timestep": 3079, "ep_reward": 567.5067138671875, "reward": 0.5533765554428101, "action": -0.5424027442932129}
{"mode": "train", "epochs": 2, "timestep": 3080, "ep_reward": 568.1607055664062, "reward": 0.6540014743804932, "action": -1.4599177837371826}
{"mode": "train", "epochs": 2, "timestep": 3081, "ep_reward": 568.892578125, "reward": 0.7318875789642334, "action": -1.201495885848999}
{"mode": "train", "epochs": 2, "timestep": 3082, "ep_reward": 569.6898193359375, "reward": 0.7972419261932373, "action": -1.1836612224578857}
{"mode": "train", "epochs": 2, "timestep": 3083, "ep_reward": 570.5383911132812, "reward": 0.8485913276672363, "action": -1.0810503959655762}
{"mode": "train", "epochs": 2, "timestep": 3084, "ep_reward": 571.4266357421875, "reward": 0.8882619738578796, "action": -0.5177657604217529}
{"mode": "train", "epochs": 2, "timestep": 3085, "ep_reward": 572.3466186523438, "reward": 0.919977068901062, "action": -1.001570224761963}
{"mode": "train", "epochs": 2, "timestep": 3086, "ep_reward": 573.2877807617188, "reward": 0.9411780834197998, "action": -1.4212942123413086}
{"mode": "train", "epochs": 2, "timestep": 3087, "ep_reward": 574.2432861328125, "reward": 0.9555277228355408, "action": -0.6338711977005005}
{"mode": "train", "epochs": 2, "timestep": 3088, "ep_reward": 575.211181640625, "reward": 0.9679209589958191, "action": -0.5022677183151245}
{"mode": "train", "epochs": 2, "timestep": 3089, "ep_reward": 576.1881103515625, "reward": 0.9769005179405212, "action": -0.15866833925247192}
{"mode": "train", "epochs": 2, "timestep": 3090, "ep_reward": 577.1714477539062, "reward": 0.9833466410636902, "action": -1.687507152557373}
{"mode": "train", "epochs": 2, "timestep": 3091, "ep_reward": 578.15771484375, "reward": 0.9862474203109741, "action": -0.549675464630127}
{"mode": "train", "epochs": 2, "timestep": 3092, "ep_reward": 579.1471557617188, "reward": 0.9894711375236511, "action": -0.8277370929718018}
{"mode": "train", "epochs": 2, "timestep": 3093, "ep_reward": 580.1386108398438, "reward": 0.9914613366127014, "action": -0.6389198899269104}
{"mode": "train", "epochs": 2, "timestep": 3094, "ep_reward": 581.1314697265625, "reward": 0.9928544163703918, "action": 0.7040565609931946}
{"mode": "train", "epochs": 2, "timestep": 3095, "ep_reward": 582.1248779296875, "reward": 0.9934157729148865, "action": 0.669330358505249}
{"mode": "train", "epochs": 2, "timestep": 3096, "ep_reward": 583.11669921875, "reward": 0.9917973279953003, "action": 0.845406174659729}
{"mode": "train", "epochs": 2, "timestep": 3097, "ep_reward": 584.1041870117188, "reward": 0.9874741435050964, "action": 0.936403751373291}
{"mode": "train", "epochs": 2, "timestep": 3098, "ep_reward": 585.0836791992188, "reward": 0.9794783592224121, "action": 1.1863665580749512}
{"mode": "train", "epochs": 2, "timestep": 3099, "ep_reward": 586.0494995117188, "reward": 0.9658050537109375, "action": 0.831459105014801}
{"mode": "train", "epochs": 2, "timestep": 3100, "ep_reward": 586.9957275390625, "reward": 0.9462149143218994, "action": 0.4490995705127716}
{"mode": "train", "epochs": 2, "timestep": 3101, "ep_reward": 587.9150390625, "reward": 0.9193185567855835, "action": 0.34063440561294556}
{"mode": "train", "epochs": 2, "timestep": 3102, "ep_reward": 588.7963256835938, "reward": 0.8812931776046753, "action": -0.6733958721160889}
{"mode": "train", "epochs": 2, "timestep": 3103, "ep_reward": 589.6322021484375, "reward": 0.8359061479568481, "action": -0.9254505634307861}
{"mode": "train", "epochs": 2, "timestep": 3104, "ep_reward": 590.4090576171875, "reward": 0.7768682837486267, "action": -0.6700423955917358}
{"mode": "train", "epochs": 2, "timestep": 3105, "ep_reward": 591.1058349609375, "reward": 0.6967883110046387, "action": -0.9797179698944092}
{"mode": "train", "epochs": 2, "timestep": 3106, "ep_reward": 591.7049560546875, "reward": 0.5991007089614868, "action": -0.9031358957290649}
{"mode": "train", "epochs": 2, "timestep": 3107, "ep_reward": 592.185791015625, "reward": 0.48085981607437134, "action": -0.4789894223213196}
{"mode": "train", "epochs": 2, "timestep": 3108, "ep_reward": 592.5263061523438, "reward": 0.340493381023407, "action": -1.4622575044631958}
{"mode": "train", "epochs": 2, "timestep": 3109, "ep_reward": 592.732421875, "reward": 0.2060890793800354, "action": -1.106281042098999}
{"mode": "train", "epochs": 2, "timestep": 3110, "ep_reward": 592.82470703125, "reward": 0.09231525659561157, "action": -0.9944908022880554}
{"mode": "train", "epochs": 2, "timestep": 3111, "ep_reward": 593.056396484375, "reward": 0.2317177653312683, "action": -0.5765078663825989}
{"mode": "train", "epochs": 2, "timestep": 3112, "ep_reward": 593.4222412109375, "reward": 0.3658600449562073, "action": -1.681510090827942}
{"mode": "train", "epochs": 2, "timestep": 3113, "ep_reward": 593.9255981445312, "reward": 0.5033835768699646, "action": -1.241901159286499}
{"mode": "train", "epochs": 2, "timestep": 3114, "ep_reward": 594.5448608398438, "reward": 0.6192532777786255, "action": -1.1080882549285889}
{"mode": "train", "epochs": 2, "timestep": 3115, "ep_reward": 595.2584228515625, "reward": 0.7135417461395264, "action": 0.44779735803604126}
{"mode": "train", "epochs": 2, "timestep": 3116, "ep_reward": 596.0372314453125, "reward": 0.7788191437721252, "action": 0.6093457937240601}
{"mode": "train", "epochs": 2, "timestep": 3117, "ep_reward": 596.8658447265625, "reward": 0.8285883665084839, "action": 0.9716517329216003}
{"mode": "train", "epochs": 2, "timestep": 3118, "ep_reward": 597.72998046875, "reward": 0.8641649484634399, "action": 1.5619168281555176}
{"mode": "train", "epochs": 2, "timestep": 3119, "ep_reward": 598.618408203125, "reward": 0.8884009718894958, "action": 0.28654563426971436}
{"mode": "train", "epochs": 2, "timestep": 3120, "ep_reward": 599.5242919921875, "reward": 0.905881404876709, "action": 1.4308967590332031}
{"mode": "train", "epochs": 2, "timestep": 3121, "ep_reward": 600.4378051757812, "reward": 0.9134978652000427, "action": -0.03952735662460327}
{"mode": "train", "epochs": 2, "timestep": 3122, "ep_reward": 601.3504028320312, "reward": 0.9125765562057495, "action": 0.5720221996307373}
{"mode": "train", "epochs": 2, "timestep": 3123, "ep_reward": 602.2523803710938, "reward": 0.9020023345947266, "action": -0.6338579058647156}
{"mode": "train", "epochs": 2, "timestep": 3124, "ep_reward": 603.1287841796875, "reward": 0.8764240741729736, "action": -0.5702258348464966}
{"mode": "train", "epochs": 2, "timestep": 3125, "ep_reward": 603.96337890625, "reward": 0.8345766663551331, "action": -0.6408495306968689}
{"mode": "train", "epochs": 2, "timestep": 3126, "ep_reward": 604.736572265625, "reward": 0.773181676864624, "action": -0.9364251494407654}
{"mode": "train", "epochs": 2, "timestep": 3127, "ep_reward": 605.423583984375, "reward": 0.6870156526565552, "action": -0.9814051389694214}
{"mode": "train", "epochs": 2, "timestep": 3128, "ep_reward": 605.9987182617188, "reward": 0.5751596093177795, "action": -0.8376924991607666}
{"mode": "train", "epochs": 2, "timestep": 3129, "ep_reward": 606.4393920898438, "reward": 0.4406777620315552, "action": -0.6239734292030334}
{"mode": "train", "epochs": 2, "timestep": 3130, "ep_reward": 606.7298583984375, "reward": 0.2904411554336548, "action": -1.082890272140503}
{"mode": "train", "epochs": 2, "timestep": 3131, "ep_reward": 606.8536987304688, "reward": 0.12385314702987671, "action": -1.565458059310913}
{"mode": "train", "epochs": 2, "timestep": 3132, "ep_reward": 606.995849609375, "reward": 0.14216989278793335, "action": -1.213046908378601}
{"mode": "train", "epochs": 2, "timestep": 3133, "ep_reward": 607.2618408203125, "reward": 0.26600050926208496, "action": -1.988842487335205}
{"mode": "train", "epochs": 2, "timestep": 3134, "ep_reward": 607.6454467773438, "reward": 0.3836062550544739, "action": -0.8012120723724365}
{"mode": "train", "epochs": 2, "timestep": 3135, "ep_reward": 608.1558837890625, "reward": 0.510434627532959, "action": -0.5703601837158203}
{"mode": "train", "epochs": 2, "timestep": 3136, "ep_reward": 608.7806396484375, "reward": 0.6247453689575195, "action": -0.9026290774345398}
{"mode": "train", "epochs": 2, "timestep": 3137, "ep_reward": 609.4966430664062, "reward": 0.7160003185272217, "action": -1.979062557220459}
{"mode": "train", "epochs": 2, "timestep": 3138, "ep_reward": 610.275634765625, "reward": 0.7790079712867737, "action": -1.4215344190597534}
{"mode": "train", "epochs": 2, "timestep": 3139, "ep_reward": 611.1058349609375, "reward": 0.830227255821228, "action": -0.6922330260276794}
{"mode": "train", "epochs": 2, "timestep": 3140, "ep_reward": 611.9769897460938, "reward": 0.8711382150650024, "action": -1.0509412288665771}
{"mode": "train", "epochs": 2, "timestep": 3141, "ep_reward": 612.8724365234375, "reward": 0.895457923412323, "action": -1.261868953704834}
{"mode": "train", "epochs": 2, "timestep": 3142, "ep_reward": 613.779052734375, "reward": 0.9066358208656311, "action": -1.0690382719039917}
{"mode": "train", "epochs": 2, "timestep": 3143, "ep_reward": 614.6870727539062, "reward": 0.9080159664154053, "action": -1.1089003086090088}
{"mode": "train", "epochs": 2, "timestep": 3144, "ep_reward": 615.5844116210938, "reward": 0.8973610997200012, "action": 0.057343244552612305}
{"mode": "train", "epochs": 2, "timestep": 3145, "ep_reward": 616.4666137695312, "reward": 0.8821766972541809, "action": -1.1626015901565552}
{"mode": "train", "epochs": 2, "timestep": 3146, "ep_reward": 617.3078002929688, "reward": 0.8412048816680908, "action": -1.115722894668579}
{"mode": "train", "epochs": 2, "timestep": 3147, "ep_reward": 618.0858764648438, "reward": 0.7781047821044922, "action": -1.5883128643035889}
{"mode": "train", "epochs": 2, "timestep": 3148, "ep_reward": 618.7659912109375, "reward": 0.6800971031188965, "action": -0.8141226768493652}
{"mode": "train", "epochs": 2, "timestep": 3149, "ep_reward": 619.3204956054688, "reward": 0.5544741153717041, "action": -0.807698130607605}
{"mode": "train", "epochs": 2, "timestep": 3150, "ep_reward": 619.7108764648438, "reward": 0.3903845548629761, "action": -1.5066487789154053}
{"mode": "train", "epochs": 2, "timestep": 3151, "ep_reward": 619.9700317382812, "reward": 0.2591296434402466, "action": -0.73884117603302}
{"mode": "train", "epochs": 2, "timestep": 3152, "ep_reward": 620.1023559570312, "reward": 0.13235217332839966, "action": -0.8887114524841309}
{"mode": "train", "epochs": 2, "timestep": 3153, "ep_reward": 620.0879516601562, "reward": -0.014379024505615234, "action": -0.5423167943954468}
{"mode": "train", "epochs": 2, "timestep": 3154, "ep_reward": 620.2159423828125, "reward": 0.12798625230789185, "action": -1.0243021249771118}
{"mode": "train", "epochs": 2, "timestep": 3155, "ep_reward": 620.482666015625, "reward": 0.266693115234375, "action": -1.106395959854126}
{"mode": "train", "epochs": 2, "timestep": 3156, "ep_reward": 620.885986328125, "reward": 0.40330249071121216, "action": -1.4731764793395996}
{"mode": "train", "epochs": 2, "timestep": 3157, "ep_reward": 621.4111328125, "reward": 0.5251336097717285, "action": -0.7959295511245728}
{"mode": "train", "epochs": 2, "timestep": 3158, "ep_reward": 622.0478515625, "reward": 0.6366971731185913, "action": -1.1776645183563232}
{"mode": "train", "epochs": 2, "timestep": 3159, "ep_reward": 622.7691040039062, "reward": 0.7212426662445068, "action": -0.35066479444503784}
{"mode": "train", "epochs": 2, "timestep": 3160, "ep_reward": 623.5599975585938, "reward": 0.7909157872200012, "action": -1.1682991981506348}
{"mode": "train", "epochs": 2, "timestep": 3161, "ep_reward": 624.3917846679688, "reward": 0.8317972421646118, "action": -0.9109537601470947}
{"mode": "train", "epochs": 2, "timestep": 3162, "ep_reward": 625.24853515625, "reward": 0.8567343950271606, "action": -1.3612382411956787}
{"mode": "train", "epochs": 2, "timestep": 3163, "ep_reward": 626.1095581054688, "reward": 0.8610145449638367, "action": -0.2636525630950928}
{"mode": "train", "epochs": 2, "timestep": 3164, "ep_reward": 626.9671630859375, "reward": 0.8575819730758667, "action": -1.0320221185684204}
{"mode": "train", "epochs": 2, "timestep": 3165, "ep_reward": 627.795654296875, "reward": 0.8285216689109802, "action": -1.2087156772613525}
{"mode": "train", "epochs": 2, "timestep": 3166, "ep_reward": 628.5698852539062, "reward": 0.7742219567298889, "action": -0.7390505075454712}
{"mode": "train", "epochs": 2, "timestep": 3167, "ep_reward": 629.2651977539062, "reward": 0.6953123211860657, "action": -0.8979451060295105}
{"mode": "train", "epochs": 2, "timestep": 3168, "ep_reward": 629.8438720703125, "reward": 0.5786538124084473, "action": -1.212705135345459}
{"mode": "train", "epochs": 2, "timestep": 3169, "ep_reward": 630.2595825195312, "reward": 0.4156848192214966, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3170, "ep_reward": 630.5624389648438, "reward": 0.30288034677505493, "action": -1.1298543214797974}
{"mode": "train", "epochs": 2, "timestep": 3171, "ep_reward": 630.746337890625, "reward": 0.18391263484954834, "action": -0.8479117155075073}
{"mode": "train", "epochs": 2, "timestep": 3172, "ep_reward": 630.7911376953125, "reward": 0.044802725315093994, "action": -1.560971975326538}
{"mode": "train", "epochs": 2, "timestep": 3173, "ep_reward": 630.8643188476562, "reward": 0.07317972183227539, "action": -0.9734615087509155}
{"mode": "train", "epochs": 2, "timestep": 3174, "ep_reward": 631.0751953125, "reward": 0.21084731817245483, "action": -1.642469882965088}
{"mode": "train", "epochs": 2, "timestep": 3175, "ep_reward": 631.41796875, "reward": 0.3427526354789734, "action": -1.2177749872207642}
{"mode": "train", "epochs": 2, "timestep": 3176, "ep_reward": 631.892333984375, "reward": 0.47434908151626587, "action": -0.9283222556114197}
{"mode": "train", "epochs": 2, "timestep": 3177, "ep_reward": 632.4855346679688, "reward": 0.593194842338562, "action": -1.1150054931640625}
{"mode": "train", "epochs": 2, "timestep": 3178, "ep_reward": 633.1732788085938, "reward": 0.6877489686012268, "action": 0.11310362815856934}
{"mode": "train", "epochs": 2, "timestep": 3179, "ep_reward": 633.9437866210938, "reward": 0.7705048322677612, "action": -1.7559940814971924}
{"mode": "train", "epochs": 2, "timestep": 3180, "ep_reward": 634.7566528320312, "reward": 0.8128793239593506, "action": -0.5257481336593628}
{"mode": "train", "epochs": 2, "timestep": 3181, "ep_reward": 635.6039428710938, "reward": 0.847305178642273, "action": -0.5820914506912231}
{"mode": "train", "epochs": 2, "timestep": 3182, "ep_reward": 636.4669189453125, "reward": 0.8629977107048035, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3183, "ep_reward": 637.316162109375, "reward": 0.8492376804351807, "action": -1.4048113822937012}
{"mode": "train", "epochs": 2, "timestep": 3184, "ep_reward": 638.1366577148438, "reward": 0.8205199837684631, "action": -0.9155559539794922}
{"mode": "train", "epochs": 2, "timestep": 3185, "ep_reward": 638.908935546875, "reward": 0.7722790241241455, "action": -0.5290845632553101}
{"mode": "train", "epochs": 2, "timestep": 3186, "ep_reward": 639.60791015625, "reward": 0.6990000009536743, "action": -0.5296953320503235}
{"mode": "train", "epochs": 2, "timestep": 3187, "ep_reward": 640.19873046875, "reward": 0.5908001661300659, "action": -1.4038573503494263}
{"mode": "train", "epochs": 2, "timestep": 3188, "ep_reward": 640.6279296875, "reward": 0.4292173981666565, "action": -0.44779300689697266}
{"mode": "train", "epochs": 2, "timestep": 3189, "ep_reward": 640.9445190429688, "reward": 0.31657540798187256, "action": -0.49431413412094116}
{"mode": "train", "epochs": 2, "timestep": 3190, "ep_reward": 641.14453125, "reward": 0.200020432472229, "action": -1.2517857551574707}
{"mode": "train", "epochs": 2, "timestep": 3191, "ep_reward": 641.2081298828125, "reward": 0.06361699104309082, "action": -0.6824867725372314}
{"mode": "train", "epochs": 2, "timestep": 3192, "ep_reward": 641.2626953125, "reward": 0.05457550287246704, "action": -1.4901832342147827}
{"mode": "train", "epochs": 2, "timestep": 3193, "ep_reward": 641.455078125, "reward": 0.19236934185028076, "action": -0.7129606008529663}
{"mode": "train", "epochs": 2, "timestep": 3194, "ep_reward": 641.791015625, "reward": 0.3359658718109131, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3195, "ep_reward": 642.2487182617188, "reward": 0.45768725872039795, "action": -1.0543545484542847}
{"mode": "train", "epochs": 2, "timestep": 3196, "ep_reward": 642.826416015625, "reward": 0.5777217149734497, "action": 0.04416608810424805}
{"mode": "train", "epochs": 2, "timestep": 3197, "ep_reward": 643.513916015625, "reward": 0.6875002384185791, "action": -1.2472623586654663}
{"mode": "train", "epochs": 2, "timestep": 3198, "ep_reward": 644.2730712890625, "reward": 0.7591782212257385, "action": -0.15106552839279175}
{"mode": "train", "epochs": 2, "timestep": 3199, "ep_reward": 645.0924072265625, "reward": 0.8193405866622925, "action": -0.789332389831543}
{"mode": "train", "epochs": 2, "timestep": 3200, "ep_reward": 645.9463500976562, "reward": 0.8539352416992188, "action": -0.734708309173584}
{"mode": "train", "epochs": 2, "timestep": 3201, "ep_reward": 646.8185424804688, "reward": 0.8721636533737183, "action": -1.5375926494598389}
{"mode": "train", "epochs": 2, "timestep": 3202, "ep_reward": 647.6867065429688, "reward": 0.8681908845901489, "action": -1.1634713411331177}
{"mode": "train", "epochs": 2, "timestep": 3203, "ep_reward": 648.5369873046875, "reward": 0.8503063917160034, "action": -0.015722274780273438}
{"mode": "train", "epochs": 2, "timestep": 3204, "ep_reward": 649.3604125976562, "reward": 0.8234461545944214, "action": -0.8715674877166748}
{"mode": "train", "epochs": 2, "timestep": 3205, "ep_reward": 650.1255493164062, "reward": 0.7651623487472534, "action": -1.5591316223144531}
{"mode": "train", "epochs": 2, "timestep": 3206, "ep_reward": 650.793701171875, "reward": 0.668168842792511, "action": -0.8524951338768005}
{"mode": "train", "epochs": 2, "timestep": 3207, "ep_reward": 651.3348388671875, "reward": 0.5411543846130371, "action": -0.6571098566055298}
{"mode": "train", "epochs": 2, "timestep": 3208, "ep_reward": 651.7110595703125, "reward": 0.376247763633728, "action": -1.6552443504333496}
{"mode": "train", "epochs": 2, "timestep": 3209, "ep_reward": 651.9812622070312, "reward": 0.2701742649078369, "action": -0.49223780632019043}
{"mode": "train", "epochs": 2, "timestep": 3210, "ep_reward": 652.1265258789062, "reward": 0.14527958631515503, "action": -0.9091566801071167}
{"mode": "train", "epochs": 2, "timestep": 3211, "ep_reward": 652.126953125, "reward": 0.00042498111724853516, "action": -0.8776110410690308}
{"mode": "train", "epochs": 2, "timestep": 3212, "ep_reward": 652.2417602539062, "reward": 0.11481046676635742, "action": -1.05797278881073}
{"mode": "train", "epochs": 2, "timestep": 3213, "ep_reward": 652.4945068359375, "reward": 0.2527688145637512, "action": -0.9665847420692444}
{"mode": "train", "epochs": 2, "timestep": 3214, "ep_reward": 652.8863525390625, "reward": 0.39184778928756714, "action": 0.34848105907440186}
{"mode": "train", "epochs": 2, "timestep": 3215, "ep_reward": 653.4217529296875, "reward": 0.5353761911392212, "action": -1.992612361907959}
{"mode": "train", "epochs": 2, "timestep": 3216, "ep_reward": 654.0542602539062, "reward": 0.6325358152389526, "action": -0.8325958251953125}
{"mode": "train", "epochs": 2, "timestep": 3217, "ep_reward": 654.7763061523438, "reward": 0.7220464944839478, "action": -1.1702163219451904}
{"mode": "train", "epochs": 2, "timestep": 3218, "ep_reward": 655.5623168945312, "reward": 0.7860348224639893, "action": -1.4755477905273438}
{"mode": "train", "epochs": 2, "timestep": 3219, "ep_reward": 656.3899536132812, "reward": 0.8276146650314331, "action": -1.0182782411575317}
{"mode": "train", "epochs": 2, "timestep": 3220, "ep_reward": 657.2451782226562, "reward": 0.8551952838897705, "action": -1.8842979669570923}
{"mode": "train", "epochs": 2, "timestep": 3221, "ep_reward": 658.1040649414062, "reward": 0.8588936924934387, "action": -0.6867985725402832}
{"mode": "train", "epochs": 2, "timestep": 3222, "ep_reward": 658.959716796875, "reward": 0.8556537628173828, "action": -0.7877535820007324}
{"mode": "train", "epochs": 2, "timestep": 3223, "ep_reward": 659.79248046875, "reward": 0.8327575922012329, "action": -0.9191192388534546}
{"mode": "train", "epochs": 2, "timestep": 3224, "ep_reward": 660.5787353515625, "reward": 0.78624027967453, "action": -0.35470259189605713}
{"mode": "train", "epochs": 2, "timestep": 3225, "ep_reward": 661.2969970703125, "reward": 0.7182877659797668, "action": -0.3338383436203003}
{"mode": "train", "epochs": 2, "timestep": 3226, "ep_reward": 661.9151000976562, "reward": 0.6180849075317383, "action": -1.6397838592529297}
{"mode": "train", "epochs": 2, "timestep": 3227, "ep_reward": 662.3758544921875, "reward": 0.46073848009109497, "action": -1.3256032466888428}
{"mode": "train", "epochs": 2, "timestep": 3228, "ep_reward": 662.7039794921875, "reward": 0.3281164765357971, "action": -0.9680416584014893}
{"mode": "train", "epochs": 2, "timestep": 3229, "ep_reward": 662.9179077148438, "reward": 0.21390092372894287, "action": -0.010247111320495605}
{"mode": "train", "epochs": 2, "timestep": 3230, "ep_reward": 662.9974365234375, "reward": 0.07952570915222168, "action": -1.2710121870040894}
{"mode": "train", "epochs": 2, "timestep": 3231, "ep_reward": 663.03564453125, "reward": 0.03820699453353882, "action": -1.5608258247375488}
{"mode": "train", "epochs": 2, "timestep": 3232, "ep_reward": 663.2138061523438, "reward": 0.1781499981880188, "action": -1.2342194318771362}
{"mode": "train", "epochs": 2, "timestep": 3233, "ep_reward": 663.5291137695312, "reward": 0.31533193588256836, "action": -0.8257692456245422}
{"mode": "train", "epochs": 2, "timestep": 3234, "ep_reward": 663.9822998046875, "reward": 0.45317989587783813, "action": -0.9955053329467773}
{"mode": "train", "epochs": 2, "timestep": 3235, "ep_reward": 664.5564575195312, "reward": 0.5741308331489563, "action": -0.7608199119567871}
{"mode": "train", "epochs": 2, "timestep": 3236, "ep_reward": 665.2330322265625, "reward": 0.676585853099823, "action": -1.656985878944397}
{"mode": "train", "epochs": 2, "timestep": 3237, "ep_reward": 665.9802856445312, "reward": 0.7472633123397827, "action": -0.7562017440795898}
{"mode": "train", "epochs": 2, "timestep": 3238, "ep_reward": 666.7855834960938, "reward": 0.8053130507469177, "action": -1.0562653541564941}
{"mode": "train", "epochs": 2, "timestep": 3239, "ep_reward": 667.6260986328125, "reward": 0.8405109643936157, "action": -0.7709285020828247}
{"mode": "train", "epochs": 2, "timestep": 3240, "ep_reward": 668.486328125, "reward": 0.8601993918418884, "action": -1.4600523710250854}
{"mode": "train", "epochs": 2, "timestep": 3241, "ep_reward": 669.3433227539062, "reward": 0.8569726943969727, "action": -0.8958652019500732}
{"mode": "train", "epochs": 2, "timestep": 3242, "ep_reward": 670.18359375, "reward": 0.8402552008628845, "action": -1.4158629179000854}
{"mode": "train", "epochs": 2, "timestep": 3243, "ep_reward": 670.9804077148438, "reward": 0.7968168258666992, "action": -1.4419910907745361}
{"mode": "train", "epochs": 2, "timestep": 3244, "ep_reward": 671.7052001953125, "reward": 0.7247937917709351, "action": -0.1574699878692627}
{"mode": "train", "epochs": 2, "timestep": 3245, "ep_reward": 672.339111328125, "reward": 0.6339293718338013, "action": -0.7135528326034546}
{"mode": "train", "epochs": 2, "timestep": 3246, "ep_reward": 672.8370361328125, "reward": 0.49794167280197144, "action": -0.6400602459907532}
{"mode": "train", "epochs": 2, "timestep": 3247, "ep_reward": 673.19140625, "reward": 0.35434138774871826, "action": -0.4500313997268677}
{"mode": "train", "epochs": 2, "timestep": 3248, "ep_reward": 673.4365844726562, "reward": 0.2451568841934204, "action": -1.0680662393569946}
{"mode": "train", "epochs": 2, "timestep": 3249, "ep_reward": 673.5526733398438, "reward": 0.11607134342193604, "action": -0.7030375003814697}
{"mode": "train", "epochs": 2, "timestep": 3250, "ep_reward": 673.551513671875, "reward": -0.0011359453201293945, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3251, "ep_reward": 673.695556640625, "reward": 0.14404839277267456, "action": -1.263944387435913}
{"mode": "train", "epochs": 2, "timestep": 3252, "ep_reward": 673.9757690429688, "reward": 0.2802198529243469, "action": -0.6347432136535645}
{"mode": "train", "epochs": 2, "timestep": 3253, "ep_reward": 674.3982543945312, "reward": 0.4224740266799927, "action": -0.1720559000968933}
{"mode": "train", "epochs": 2, "timestep": 3254, "ep_reward": 674.9547729492188, "reward": 0.5565083026885986, "action": -0.6575006246566772}
{"mode": "train", "epochs": 2, "timestep": 3255, "ep_reward": 675.6183471679688, "reward": 0.6635473966598511, "action": -1.7806206941604614}
{"mode": "train", "epochs": 2, "timestep": 3256, "ep_reward": 676.35595703125, "reward": 0.7376403212547302, "action": -0.6848490238189697}
{"mode": "train", "epochs": 2, "timestep": 3257, "ep_reward": 677.1575927734375, "reward": 0.8016590476036072, "action": -0.9308449029922485}
{"mode": "train", "epochs": 2, "timestep": 3258, "ep_reward": 678.0010986328125, "reward": 0.8435350656509399, "action": -1.848023772239685}
{"mode": "train", "epochs": 2, "timestep": 3259, "ep_reward": 678.8623046875, "reward": 0.8612140417098999, "action": -0.7800593972206116}
{"mode": "train", "epochs": 2, "timestep": 3260, "ep_reward": 679.7341918945312, "reward": 0.8718891143798828, "action": -1.4126133918762207}
{"mode": "train", "epochs": 2, "timestep": 3261, "ep_reward": 680.5953979492188, "reward": 0.8612029552459717, "action": -0.7110501527786255}
{"mode": "train", "epochs": 2, "timestep": 3262, "ep_reward": 681.433837890625, "reward": 0.8384274840354919, "action": -0.3587633967399597}
{"mode": "train", "epochs": 2, "timestep": 3263, "ep_reward": 682.2317504882812, "reward": 0.7979152798652649, "action": 0.16933107376098633}
{"mode": "train", "epochs": 2, "timestep": 3264, "ep_reward": 682.9699096679688, "reward": 0.7381409406661987, "action": -0.8467743396759033}
{"mode": "train", "epochs": 2, "timestep": 3265, "ep_reward": 683.606201171875, "reward": 0.6363098621368408, "action": -1.2768219709396362}
{"mode": "train", "epochs": 2, "timestep": 3266, "ep_reward": 684.09619140625, "reward": 0.48999470472335815, "action": -1.2033193111419678}
{"mode": "train", "epochs": 2, "timestep": 3267, "ep_reward": 684.4326171875, "reward": 0.3364051580429077, "action": -1.4888006448745728}
{"mode": "train", "epochs": 2, "timestep": 3268, "ep_reward": 684.6564331054688, "reward": 0.22384494543075562, "action": -0.8222676515579224}
{"mode": "train", "epochs": 2, "timestep": 3269, "ep_reward": 684.7474975585938, "reward": 0.09108459949493408, "action": -1.5285104513168335}
{"mode": "train", "epochs": 2, "timestep": 3270, "ep_reward": 684.773681640625, "reward": 0.026164889335632324, "action": -0.30280351638793945}
{"mode": "train", "epochs": 2, "timestep": 3271, "ep_reward": 684.9444580078125, "reward": 0.17076611518859863, "action": -1.1221903562545776}
{"mode": "train", "epochs": 2, "timestep": 3272, "ep_reward": 685.2529907226562, "reward": 0.30855125188827515, "action": -0.4796220660209656}
{"mode": "train", "epochs": 2, "timestep": 3273, "ep_reward": 685.7032470703125, "reward": 0.45025449991226196, "action": -0.8985691070556641}
{"mode": "train", "epochs": 2, "timestep": 3274, "ep_reward": 686.2753295898438, "reward": 0.5720880031585693, "action": -1.2665507793426514}
{"mode": "train", "epochs": 2, "timestep": 3275, "ep_reward": 686.9454956054688, "reward": 0.6701758503913879, "action": -0.35713422298431396}
{"mode": "train", "epochs": 2, "timestep": 3276, "ep_reward": 687.7007446289062, "reward": 0.7552414536476135, "action": -1.1181138753890991}
{"mode": "train", "epochs": 2, "timestep": 3277, "ep_reward": 688.51171875, "reward": 0.8110020160675049, "action": -1.7181979417800903}
{"mode": "train", "epochs": 2, "timestep": 3278, "ep_reward": 689.355224609375, "reward": 0.8434877395629883, "action": -0.5127774477005005}
{"mode": "train", "epochs": 2, "timestep": 3279, "ep_reward": 690.224609375, "reward": 0.869414210319519, "action": -1.1556930541992188}
{"mode": "train", "epochs": 2, "timestep": 3280, "ep_reward": 691.0989379882812, "reward": 0.8743233680725098, "action": -1.5003464221954346}
{"mode": "train", "epochs": 2, "timestep": 3281, "ep_reward": 691.9593505859375, "reward": 0.8604044914245605, "action": -0.9916876554489136}
{"mode": "train", "epochs": 2, "timestep": 3282, "ep_reward": 692.79150390625, "reward": 0.8321417570114136, "action": -1.1775225400924683}
{"mode": "train", "epochs": 2, "timestep": 3283, "ep_reward": 693.5706176757812, "reward": 0.7791070342063904, "action": -0.5903071165084839}
{"mode": "train", "epochs": 2, "timestep": 3284, "ep_reward": 694.2740478515625, "reward": 0.7034320831298828, "action": -1.240964651107788}
{"mode": "train", "epochs": 2, "timestep": 3285, "ep_reward": 694.8585205078125, "reward": 0.5844455361366272, "action": -1.334457516670227}
{"mode": "train", "epochs": 2, "timestep": 3286, "ep_reward": 695.280029296875, "reward": 0.42152512073516846, "action": -0.35422253608703613}
{"mode": "train", "epochs": 2, "timestep": 3287, "ep_reward": 695.5868530273438, "reward": 0.3068014979362488, "action": -1.30604887008667}
{"mode": "train", "epochs": 2, "timestep": 3288, "ep_reward": 695.7754516601562, "reward": 0.18859511613845825, "action": -0.7644578814506531}
{"mode": "train", "epochs": 2, "timestep": 3289, "ep_reward": 695.82568359375, "reward": 0.0502549409866333, "action": -1.265709400177002}
{"mode": "train", "epochs": 2, "timestep": 3290, "ep_reward": 695.8934936523438, "reward": 0.06781184673309326, "action": -1.5020246505737305}
{"mode": "train", "epochs": 2, "timestep": 3291, "ep_reward": 696.0972900390625, "reward": 0.2038019895553589, "action": -0.74233078956604}
{"mode": "train", "epochs": 2, "timestep": 3292, "ep_reward": 696.444580078125, "reward": 0.34730464220046997, "action": -1.1840037107467651}
{"mode": "train", "epochs": 2, "timestep": 3293, "ep_reward": 696.9224853515625, "reward": 0.4778860807418823, "action": -1.3205058574676514}
{"mode": "train", "epochs": 2, "timestep": 3294, "ep_reward": 697.5140991210938, "reward": 0.5916441082954407, "action": -0.5028438568115234}
{"mode": "train", "epochs": 2, "timestep": 3295, "ep_reward": 698.2071533203125, "reward": 0.6930665969848633, "action": -0.5247257351875305}
{"mode": "train", "epochs": 2, "timestep": 3296, "ep_reward": 698.9771118164062, "reward": 0.7699745297431946, "action": -0.672607421875}
{"mode": "train", "epochs": 2, "timestep": 3297, "ep_reward": 699.800537109375, "reward": 0.8234384059906006, "action": -0.754541277885437}
{"mode": "train", "epochs": 2, "timestep": 3298, "ep_reward": 700.6578369140625, "reward": 0.8573281168937683, "action": -0.7923094034194946}
{"mode": "train", "epochs": 2, "timestep": 3299, "ep_reward": 701.5321655273438, "reward": 0.8743555545806885, "action": -1.8418848514556885}
{"mode": "train", "epochs": 2, "timestep": 3300, "ep_reward": 702.3997192382812, "reward": 0.8675263524055481, "action": -0.7612493634223938}
{"mode": "train", "epochs": 2, "timestep": 3301, "ep_reward": 703.25244140625, "reward": 0.8527506589889526, "action": -0.7610459923744202}
{"mode": "train", "epochs": 2, "timestep": 3302, "ep_reward": 704.0708618164062, "reward": 0.8184336423873901, "action": -1.0298187732696533}
{"mode": "train", "epochs": 2, "timestep": 3303, "ep_reward": 704.827880859375, "reward": 0.7570440769195557, "action": -0.6045632362365723}
{"mode": "train", "epochs": 2, "timestep": 3304, "ep_reward": 705.4973754882812, "reward": 0.6694983243942261, "action": -1.5422790050506592}
{"mode": "train", "epochs": 2, "timestep": 3305, "ep_reward": 706.0296020507812, "reward": 0.5322184562683105, "action": -1.2381271123886108}
{"mode": "train", "epochs": 2, "timestep": 3306, "ep_reward": 706.4010009765625, "reward": 0.37142515182495117, "action": -1.2117891311645508}
{"mode": "train", "epochs": 2, "timestep": 3307, "ep_reward": 706.6666870117188, "reward": 0.2656940221786499, "action": -1.8875298500061035}
{"mode": "train", "epochs": 2, "timestep": 3308, "ep_reward": 706.8069458007812, "reward": 0.14023959636688232, "action": -1.1075295209884644}
{"mode": "train", "epochs": 2, "timestep": 3309, "ep_reward": 706.8015747070312, "reward": -0.0053931474685668945, "action": -1.3196033239364624}
{"mode": "train", "epochs": 2, "timestep": 3310, "ep_reward": 706.9215698242188, "reward": 0.11997067928314209, "action": -1.0065873861312866}
{"mode": "train", "epochs": 2, "timestep": 3311, "ep_reward": 707.18017578125, "reward": 0.2586110234260559, "action": -1.5710256099700928}
{"mode": "train", "epochs": 2, "timestep": 3312, "ep_reward": 707.5701904296875, "reward": 0.3900004029273987, "action": -0.5757108926773071}
{"mode": "train", "epochs": 2, "timestep": 3313, "ep_reward": 708.09423828125, "reward": 0.524029016494751, "action": -1.4241087436676025}
{"mode": "train", "epochs": 2, "timestep": 3314, "ep_reward": 708.7233276367188, "reward": 0.6290799379348755, "action": -1.0608476400375366}
{"mode": "train", "epochs": 2, "timestep": 3315, "ep_reward": 709.4397583007812, "reward": 0.7164013385772705, "action": -0.5897156596183777}
{"mode": "train", "epochs": 2, "timestep": 3316, "ep_reward": 710.2250366210938, "reward": 0.7852701544761658, "action": -0.10224974155426025}
{"mode": "train", "epochs": 2, "timestep": 3317, "ep_reward": 711.0617065429688, "reward": 0.8366503715515137, "action": -0.037683963775634766}
{"mode": "train", "epochs": 2, "timestep": 3318, "ep_reward": 711.9310302734375, "reward": 0.8693056106567383, "action": -1.4322881698608398}
{"mode": "train", "epochs": 2, "timestep": 3319, "ep_reward": 712.8057250976562, "reward": 0.8746678829193115, "action": -1.610248327255249}
{"mode": "train", "epochs": 2, "timestep": 3320, "ep_reward": 713.6685791015625, "reward": 0.8628530502319336, "action": -0.9455973505973816}
{"mode": "train", "epochs": 2, "timestep": 3321, "ep_reward": 714.507080078125, "reward": 0.8385270833969116, "action": -1.0018717050552368}
{"mode": "train", "epochs": 2, "timestep": 3322, "ep_reward": 715.2987670898438, "reward": 0.791707456111908, "action": -1.3381985425949097}
{"mode": "train", "epochs": 2, "timestep": 3323, "ep_reward": 716.0117797851562, "reward": 0.7129870057106018, "action": -1.3224458694458008}
{"mode": "train", "epochs": 2, "timestep": 3324, "ep_reward": 716.6098022460938, "reward": 0.5979937314987183, "action": -0.49662137031555176}
{"mode": "train", "epochs": 2, "timestep": 3325, "ep_reward": 717.06298828125, "reward": 0.45319801568984985, "action": -0.8140087127685547}
{"mode": "train", "epochs": 2, "timestep": 3326, "ep_reward": 717.3870849609375, "reward": 0.3241262435913086, "action": -1.034948468208313}
{"mode": "train", "epochs": 2, "timestep": 3327, "ep_reward": 717.59619140625, "reward": 0.2091001272201538, "action": -0.9629143476486206}
{"mode": "train", "epochs": 2, "timestep": 3328, "ep_reward": 717.6702880859375, "reward": 0.07409369945526123, "action": -0.6820996999740601}
{"mode": "train", "epochs": 2, "timestep": 3329, "ep_reward": 717.7142944335938, "reward": 0.044030189514160156, "action": -0.5295979976654053}
{"mode": "train", "epochs": 2, "timestep": 3330, "ep_reward": 717.9006958007812, "reward": 0.18641674518585205, "action": -0.8881677389144897}
{"mode": "train", "epochs": 2, "timestep": 3331, "ep_reward": 718.227783203125, "reward": 0.32710713148117065, "action": -1.8157539367675781}
{"mode": "train", "epochs": 2, "timestep": 3332, "ep_reward": 718.6793212890625, "reward": 0.4515208601951599, "action": -0.17041486501693726}
{"mode": "train", "epochs": 2, "timestep": 3333, "ep_reward": 719.261474609375, "reward": 0.5821407437324524, "action": -0.438951313495636}
{"mode": "train", "epochs": 2, "timestep": 3334, "ep_reward": 719.9479370117188, "reward": 0.6864368915557861, "action": -0.9384423494338989}
{"mode": "train", "epochs": 2, "timestep": 3335, "ep_reward": 720.7102661132812, "reward": 0.7623223662376404, "action": -0.1422390341758728}
{"mode": "train", "epochs": 2, "timestep": 3336, "ep_reward": 721.5341186523438, "reward": 0.823874831199646, "action": 0.7682853937149048}
{"mode": "train", "epochs": 2, "timestep": 3337, "ep_reward": 722.406982421875, "reward": 0.8728414177894592, "action": -0.7954849004745483}
{"mode": "train", "epochs": 2, "timestep": 3338, "ep_reward": 723.3007202148438, "reward": 0.8937177658081055, "action": -0.966883659362793}
{"mode": "train", "epochs": 2, "timestep": 3339, "ep_reward": 724.2015380859375, "reward": 0.9008076786994934, "action": -0.854439377784729}
{"mode": "train", "epochs": 2, "timestep": 3340, "ep_reward": 725.097900390625, "reward": 0.8963897228240967, "action": -0.7525299787521362}
{"mode": "train", "epochs": 2, "timestep": 3341, "ep_reward": 725.9771118164062, "reward": 0.879199206829071, "action": -0.5604212284088135}
{"mode": "train", "epochs": 2, "timestep": 3342, "ep_reward": 726.824462890625, "reward": 0.8473401069641113, "action": -1.3388012647628784}
{"mode": "train", "epochs": 2, "timestep": 3343, "ep_reward": 727.6116943359375, "reward": 0.7872240543365479, "action": -1.6564157009124756}
{"mode": "train", "epochs": 2, "timestep": 3344, "ep_reward": 728.3058471679688, "reward": 0.6941369771957397, "action": -0.9362649321556091}
{"mode": "train", "epochs": 2, "timestep": 3345, "ep_reward": 728.87841796875, "reward": 0.5725440979003906, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3346, "ep_reward": 729.2727661132812, "reward": 0.3943327069282532, "action": -0.9515789747238159}
{"mode": "train", "epochs": 2, "timestep": 3347, "ep_reward": 729.5511474609375, "reward": 0.2784046530723572, "action": -0.4624010920524597}
{"mode": "train", "epochs": 2, "timestep": 3348, "ep_reward": 729.7059936523438, "reward": 0.15486466884613037, "action": -1.4774348735809326}
{"mode": "train", "epochs": 2, "timestep": 3349, "ep_reward": 729.7174682617188, "reward": 0.011487007141113281, "action": -1.246191143989563}
{"mode": "train", "epochs": 2, "timestep": 3350, "ep_reward": 729.8221435546875, "reward": 0.10464614629745483, "action": -1.5048599243164062}
{"mode": "train", "epochs": 2, "timestep": 3351, "ep_reward": 730.058837890625, "reward": 0.23670095205307007, "action": -1.2758984565734863}
{"mode": "train", "epochs": 2, "timestep": 3352, "ep_reward": 730.4323120117188, "reward": 0.37344902753829956, "action": -1.1004077196121216}
{"mode": "train", "epochs": 2, "timestep": 3353, "ep_reward": 730.9356689453125, "reward": 0.5033328533172607, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3354, "ep_reward": 731.5411376953125, "reward": 0.6054396629333496, "action": -1.5552406311035156}
{"mode": "train", "epochs": 2, "timestep": 3355, "ep_reward": 732.232666015625, "reward": 0.6915569305419922, "action": -1.7894792556762695}
{"mode": "train", "epochs": 2, "timestep": 3356, "ep_reward": 732.9845581054688, "reward": 0.7519108653068542, "action": -1.6676042079925537}
{"mode": "train", "epochs": 2, "timestep": 3357, "ep_reward": 733.775390625, "reward": 0.7908132076263428, "action": -0.7331730723381042}
{"mode": "train", "epochs": 2, "timestep": 3358, "ep_reward": 734.5918579101562, "reward": 0.8164855241775513, "action": -0.4745594263076782}
{"mode": "train", "epochs": 2, "timestep": 3359, "ep_reward": 735.414306640625, "reward": 0.8224488496780396, "action": -1.0620441436767578}
{"mode": "train", "epochs": 2, "timestep": 3360, "ep_reward": 736.2139282226562, "reward": 0.7996488213539124, "action": -1.4210842847824097}
{"mode": "train", "epochs": 2, "timestep": 3361, "ep_reward": 736.9598388671875, "reward": 0.7459230422973633, "action": -1.1840285062789917}
{"mode": "train", "epochs": 2, "timestep": 3362, "ep_reward": 737.6207275390625, "reward": 0.6608778238296509, "action": -1.0220654010772705}
{"mode": "train", "epochs": 2, "timestep": 3363, "ep_reward": 738.1577758789062, "reward": 0.5370277166366577, "action": -0.9379110932350159}
{"mode": "train", "epochs": 2, "timestep": 3364, "ep_reward": 738.5626220703125, "reward": 0.4048488140106201, "action": -1.1071739196777344}
{"mode": "train", "epochs": 2, "timestep": 3365, "ep_reward": 738.8692016601562, "reward": 0.30658960342407227, "action": 0.11412549018859863}
{"mode": "train", "epochs": 2, "timestep": 3366, "ep_reward": 739.0572509765625, "reward": 0.18802613019943237, "action": -1.9154798984527588}
{"mode": "train", "epochs": 2, "timestep": 3367, "ep_reward": 739.1071166992188, "reward": 0.04986768960952759, "action": -0.9164104461669922}
{"mode": "train", "epochs": 2, "timestep": 3368, "ep_reward": 739.1753540039062, "reward": 0.0682557225227356, "action": -1.4134873151779175}
{"mode": "train", "epochs": 2, "timestep": 3369, "ep_reward": 739.3795776367188, "reward": 0.20420527458190918, "action": 0.05863595008850098}
{"mode": "train", "epochs": 2, "timestep": 3370, "ep_reward": 739.7371215820312, "reward": 0.35754841566085815, "action": -0.8416996002197266}
{"mode": "train", "epochs": 2, "timestep": 3371, "ep_reward": 740.227294921875, "reward": 0.4901677370071411, "action": -0.6465025544166565}
{"mode": "train", "epochs": 2, "timestep": 3372, "ep_reward": 740.8359985351562, "reward": 0.6087071299552917, "action": -1.3147504329681396}
{"mode": "train", "epochs": 2, "timestep": 3373, "ep_reward": 741.5352172851562, "reward": 0.6992034912109375, "action": -0.8060407638549805}
{"mode": "train", "epochs": 2, "timestep": 3374, "ep_reward": 742.3085327148438, "reward": 0.7732950448989868, "action": -1.4693959951400757}
{"mode": "train", "epochs": 2, "timestep": 3375, "ep_reward": 743.1296997070312, "reward": 0.821173369884491, "action": -1.1629382371902466}
{"mode": "train", "epochs": 2, "timestep": 3376, "ep_reward": 743.9838256835938, "reward": 0.8541311025619507, "action": -1.1068155765533447}
{"mode": "train", "epochs": 2, "timestep": 3377, "ep_reward": 744.8552856445312, "reward": 0.8714509010314941, "action": -1.0499966144561768}
{"mode": "train", "epochs": 2, "timestep": 3378, "ep_reward": 745.7290649414062, "reward": 0.8737725019454956, "action": -1.6351715326309204}
{"mode": "train", "epochs": 2, "timestep": 3379, "ep_reward": 746.5838012695312, "reward": 0.8547429442405701, "action": -1.664995789527893}
{"mode": "train", "epochs": 2, "timestep": 3380, "ep_reward": 747.398681640625, "reward": 0.8148885369300842, "action": -1.903882384300232}
{"mode": "train", "epochs": 2, "timestep": 3381, "ep_reward": 748.1443481445312, "reward": 0.7456870079040527, "action": -1.241549015045166}
{"mode": "train", "epochs": 2, "timestep": 3382, "ep_reward": 748.793701171875, "reward": 0.6493332982063293, "action": -0.6846678853034973}
{"mode": "train", "epochs": 2, "timestep": 3383, "ep_reward": 749.3141479492188, "reward": 0.520438551902771, "action": -1.222449541091919}
{"mode": "train", "epochs": 2, "timestep": 3384, "ep_reward": 749.6875, "reward": 0.37335091829299927, "action": -1.3786104917526245}
{"mode": "train", "epochs": 2, "timestep": 3385, "ep_reward": 749.9556274414062, "reward": 0.2681494951248169, "action": -1.438887119293213}
{"mode": "train", "epochs": 2, "timestep": 3386, "ep_reward": 750.0986938476562, "reward": 0.14304471015930176, "action": -0.8312110304832458}
{"mode": "train", "epochs": 2, "timestep": 3387, "ep_reward": 750.0963745117188, "reward": -0.002344489097595215, "action": -1.9647692441940308}
{"mode": "train", "epochs": 2, "timestep": 3388, "ep_reward": 750.2134399414062, "reward": 0.11707699298858643, "action": -1.3644765615463257}
{"mode": "train", "epochs": 2, "timestep": 3389, "ep_reward": 750.4647827148438, "reward": 0.2513176202774048, "action": -0.5724313259124756}
{"mode": "train", "epochs": 2, "timestep": 3390, "ep_reward": 750.8606567382812, "reward": 0.3958437442779541, "action": -0.7979646325111389}
{"mode": "train", "epochs": 2, "timestep": 3391, "ep_reward": 751.3865966796875, "reward": 0.5259615778923035, "action": -1.516359806060791}
{"mode": "train", "epochs": 2, "timestep": 3392, "ep_reward": 752.0161743164062, "reward": 0.6295966506004333, "action": -1.674968957901001}
{"mode": "train", "epochs": 2, "timestep": 3393, "ep_reward": 752.7271118164062, "reward": 0.7109354138374329, "action": -1.228021502494812}
{"mode": "train", "epochs": 2, "timestep": 3394, "ep_reward": 753.502197265625, "reward": 0.7750608921051025, "action": -0.8031662106513977}
{"mode": "train", "epochs": 2, "timestep": 3395, "ep_reward": 754.323974609375, "reward": 0.8217786550521851, "action": -0.9467688202857971}
{"mode": "train", "epochs": 2, "timestep": 3396, "ep_reward": 755.1715698242188, "reward": 0.8475900888442993, "action": -1.3798301219940186}
{"mode": "train", "epochs": 2, "timestep": 3397, "ep_reward": 756.0232543945312, "reward": 0.8516929149627686, "action": -0.44795161485671997}
{"mode": "train", "epochs": 2, "timestep": 3398, "ep_reward": 756.8689575195312, "reward": 0.8456981778144836, "action": -0.8697758913040161}
{"mode": "train", "epochs": 2, "timestep": 3399, "ep_reward": 757.6845703125, "reward": 0.8156263828277588, "action": -0.5664792060852051}
{"mode": "train", "epochs": 2, "timestep": 3400, "ep_reward": 758.4488525390625, "reward": 0.7642925381660461, "action": -0.9176057577133179}
{"mode": "train", "epochs": 2, "timestep": 3401, "ep_reward": 759.1278686523438, "reward": 0.6790034770965576, "action": -0.8810242414474487}
{"mode": "train", "epochs": 2, "timestep": 3402, "ep_reward": 759.6846923828125, "reward": 0.556824803352356, "action": -1.3185007572174072}
{"mode": "train", "epochs": 2, "timestep": 3403, "ep_reward": 760.074462890625, "reward": 0.38974499702453613, "action": -1.5016179084777832}
{"mode": "train", "epochs": 2, "timestep": 3404, "ep_reward": 760.3626098632812, "reward": 0.288152277469635, "action": -0.9529727697372437}
{"mode": "train", "epochs": 2, "timestep": 3405, "ep_reward": 760.5291137695312, "reward": 0.16651248931884766, "action": -0.5590906739234924}
{"mode": "train", "epochs": 2, "timestep": 3406, "ep_reward": 760.553955078125, "reward": 0.02482503652572632, "action": -0.6913537979125977}
{"mode": "train", "epochs": 2, "timestep": 3407, "ep_reward": 760.6463623046875, "reward": 0.09242022037506104, "action": -0.8745113611221313}
{"mode": "train", "epochs": 2, "timestep": 3408, "ep_reward": 760.8783569335938, "reward": 0.23199999332427979, "action": -1.110434889793396}
{"mode": "train", "epochs": 2, "timestep": 3409, "ep_reward": 761.248046875, "reward": 0.3696663975715637, "action": -0.8441774249076843}
{"mode": "train", "epochs": 2, "timestep": 3410, "ep_reward": 761.7503051757812, "reward": 0.5022419691085815, "action": -0.611021876335144}
{"mode": "train", "epochs": 2, "timestep": 3411, "ep_reward": 762.369873046875, "reward": 0.6195820569992065, "action": -1.524409294128418}
{"mode": "train", "epochs": 2, "timestep": 3412, "ep_reward": 763.0750122070312, "reward": 0.705165684223175, "action": -1.555191993713379}
{"mode": "train", "epochs": 2, "timestep": 3413, "ep_reward": 763.8442993164062, "reward": 0.7692674994468689, "action": -1.6847946643829346}
{"mode": "train", "epochs": 2, "timestep": 3414, "ep_reward": 764.6563110351562, "reward": 0.8120254278182983, "action": -0.908961296081543}
{"mode": "train", "epochs": 2, "timestep": 3415, "ep_reward": 765.498779296875, "reward": 0.8424729704856873, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3416, "ep_reward": 766.3439331054688, "reward": 0.8451377153396606, "action": -0.8156135082244873}
{"mode": "train", "epochs": 2, "timestep": 3417, "ep_reward": 767.1834106445312, "reward": 0.8394539952278137, "action": -0.9198415279388428}
{"mode": "train", "epochs": 2, "timestep": 3418, "ep_reward": 767.9951782226562, "reward": 0.8117530941963196, "action": -1.3401076793670654}
{"mode": "train", "epochs": 2, "timestep": 3419, "ep_reward": 768.7493286132812, "reward": 0.7541599869728088, "action": -0.9047150611877441}
{"mode": "train", "epochs": 2, "timestep": 3420, "ep_reward": 769.4183959960938, "reward": 0.6690556406974792, "action": -0.9781610369682312}
{"mode": "train", "epochs": 2, "timestep": 3421, "ep_reward": 769.962646484375, "reward": 0.5442707538604736, "action": -0.9927448630332947}
{"mode": "train", "epochs": 2, "timestep": 3422, "ep_reward": 770.3555908203125, "reward": 0.3929683566093445, "action": -1.850541591644287}
{"mode": "train", "epochs": 2, "timestep": 3423, "ep_reward": 770.6477661132812, "reward": 0.29218584299087524, "action": -0.8162351846694946}
{"mode": "train", "epochs": 2, "timestep": 3424, "ep_reward": 770.8189697265625, "reward": 0.1712052822113037, "action": -1.0372787714004517}
{"mode": "train", "epochs": 2, "timestep": 3425, "ep_reward": 770.8492431640625, "reward": 0.030259251594543457, "action": -0.9649568200111389}
{"mode": "train", "epochs": 2, "timestep": 3426, "ep_reward": 770.9365234375, "reward": 0.08729851245880127, "action": -0.4538419842720032}
{"mode": "train", "epochs": 2, "timestep": 3427, "ep_reward": 771.1682739257812, "reward": 0.23176729679107666, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3428, "ep_reward": 771.52587890625, "reward": 0.357632040977478, "action": -1.5211710929870605}
{"mode": "train", "epochs": 2, "timestep": 3429, "ep_reward": 772.009765625, "reward": 0.4838717579841614, "action": -1.6162173748016357}
{"mode": "train", "epochs": 2, "timestep": 3430, "ep_reward": 772.603271484375, "reward": 0.5935355424880981, "action": -0.8812007904052734}
{"mode": "train", "epochs": 2, "timestep": 3431, "ep_reward": 773.2930908203125, "reward": 0.6898413896560669, "action": -1.0174038410186768}
{"mode": "train", "epochs": 2, "timestep": 3432, "ep_reward": 774.053466796875, "reward": 0.760372519493103, "action": -1.1394364833831787}
{"mode": "train", "epochs": 2, "timestep": 3433, "ep_reward": 774.8606567382812, "reward": 0.8071619272232056, "action": -0.505968451499939}
{"mode": "train", "epochs": 2, "timestep": 3434, "ep_reward": 775.6997680664062, "reward": 0.8390860557556152, "action": -1.0668790340423584}
{"mode": "train", "epochs": 2, "timestep": 3435, "ep_reward": 776.5465087890625, "reward": 0.8467217683792114, "action": -0.7019974589347839}
{"mode": "train", "epochs": 2, "timestep": 3436, "ep_reward": 777.3848876953125, "reward": 0.8383921980857849, "action": -1.7407275438308716}
{"mode": "train", "epochs": 2, "timestep": 3437, "ep_reward": 778.1832275390625, "reward": 0.798355221748352, "action": -1.1236615180969238}
{"mode": "train", "epochs": 2, "timestep": 3438, "ep_reward": 778.9199829101562, "reward": 0.73675936460495, "action": -1.0820578336715698}
{"mode": "train", "epochs": 2, "timestep": 3439, "ep_reward": 779.5613403320312, "reward": 0.6413589715957642, "action": -1.718839168548584}
{"mode": "train", "epochs": 2, "timestep": 3440, "ep_reward": 780.0564575195312, "reward": 0.49511170387268066, "action": -1.249354362487793}
{"mode": "train", "epochs": 2, "timestep": 3441, "ep_reward": 780.4286499023438, "reward": 0.3722113370895386, "action": -1.4095195531845093}
{"mode": "train", "epochs": 2, "timestep": 3442, "ep_reward": 780.6954956054688, "reward": 0.26684921979904175, "action": -0.9582160711288452}
{"mode": "train", "epochs": 2, "timestep": 3443, "ep_reward": 780.8368530273438, "reward": 0.14135229587554932, "action": -1.4156841039657593}
{"mode": "train", "epochs": 2, "timestep": 3444, "ep_reward": 780.8328247070312, "reward": -0.0040171146392822266, "action": -1.0238093137741089}
{"mode": "train", "epochs": 2, "timestep": 3445, "ep_reward": 780.95166015625, "reward": 0.11882489919662476, "action": -0.5778560638427734}
{"mode": "train", "epochs": 2, "timestep": 3446, "ep_reward": 781.2144775390625, "reward": 0.26281243562698364, "action": -1.1666216850280762}
{"mode": "train", "epochs": 2, "timestep": 3447, "ep_reward": 781.612548828125, "reward": 0.3980485796928406, "action": -0.9972333908081055}
{"mode": "train", "epochs": 2, "timestep": 3448, "ep_reward": 782.1380004882812, "reward": 0.5254767537117004, "action": -1.1625250577926636}
{"mode": "train", "epochs": 2, "timestep": 3449, "ep_reward": 782.7710571289062, "reward": 0.6330536603927612, "action": -1.0488518476486206}
{"mode": "train", "epochs": 2, "timestep": 3450, "ep_reward": 783.4912109375, "reward": 0.7201570272445679, "action": -1.0796382427215576}
{"mode": "train", "epochs": 2, "timestep": 3451, "ep_reward": 784.2760009765625, "reward": 0.7847973108291626, "action": -0.775840163230896}
{"mode": "train", "epochs": 2, "timestep": 3452, "ep_reward": 785.107666015625, "reward": 0.8316769003868103, "action": -0.6813037395477295}
{"mode": "train", "epochs": 2, "timestep": 3453, "ep_reward": 785.968505859375, "reward": 0.8608471751213074, "action": -1.5733165740966797}
{"mode": "train", "epochs": 2, "timestep": 3454, "ep_reward": 786.8348388671875, "reward": 0.8663225769996643, "action": -1.014508843421936}
{"mode": "train", "epochs": 2, "timestep": 3455, "ep_reward": 787.6947021484375, "reward": 0.8598456382751465, "action": -1.7506115436553955}
{"mode": "train", "epochs": 2, "timestep": 3456, "ep_reward": 788.5226440429688, "reward": 0.8279454708099365, "action": -1.1575437784194946}
{"mode": "train", "epochs": 2, "timestep": 3457, "ep_reward": 789.3003540039062, "reward": 0.7776980400085449, "action": -0.6374925971031189}
{"mode": "train", "epochs": 2, "timestep": 3458, "ep_reward": 790.0043334960938, "reward": 0.7039614319801331, "action": -0.195317804813385}
{"mode": "train", "epochs": 2, "timestep": 3459, "ep_reward": 790.6058349609375, "reward": 0.6015113592147827, "action": -1.7905436754226685}
{"mode": "train", "epochs": 2, "timestep": 3460, "ep_reward": 791.04248046875, "reward": 0.43665772676467896, "action": -1.3546969890594482}
{"mode": "train", "epochs": 2, "timestep": 3461, "ep_reward": 791.3615112304688, "reward": 0.31903719902038574, "action": -0.977627158164978}
{"mode": "train", "epochs": 2, "timestep": 3462, "ep_reward": 791.5645141601562, "reward": 0.20303285121917725, "action": -1.0045435428619385}
{"mode": "train", "epochs": 2, "timestep": 3463, "ep_reward": 791.6315307617188, "reward": 0.06703680753707886, "action": -0.9621528387069702}
{"mode": "train", "epochs": 2, "timestep": 3464, "ep_reward": 791.6826782226562, "reward": 0.05113023519515991, "action": -1.242605447769165}
{"mode": "train", "epochs": 2, "timestep": 3465, "ep_reward": 791.8720092773438, "reward": 0.18931454420089722, "action": -1.066563367843628}
{"mode": "train", "epochs": 2, "timestep": 3466, "ep_reward": 792.2007446289062, "reward": 0.32871198654174805, "action": -0.942621111869812}
{"mode": "train", "epochs": 2, "timestep": 3467, "ep_reward": 792.664794921875, "reward": 0.4640272855758667, "action": -0.8375561237335205}
{"mode": "train", "epochs": 2, "timestep": 3468, "ep_reward": 793.2498168945312, "reward": 0.5850378274917603, "action": -1.62026047706604}
{"mode": "train", "epochs": 2, "timestep": 3469, "ep_reward": 793.9264526367188, "reward": 0.6766152381896973, "action": -0.9737651348114014}
{"mode": "train", "epochs": 2, "timestep": 3470, "ep_reward": 794.6793823242188, "reward": 0.7529151439666748, "action": -1.0207769870758057}
{"mode": "train", "epochs": 2, "timestep": 3471, "ep_reward": 795.4859619140625, "reward": 0.8065857291221619, "action": -0.8564904928207397}
{"mode": "train", "epochs": 2, "timestep": 3472, "ep_reward": 796.3276977539062, "reward": 0.8417055606842041, "action": -1.2310889959335327}
{"mode": "train", "epochs": 2, "timestep": 3473, "ep_reward": 797.18310546875, "reward": 0.85538250207901, "action": -1.8452599048614502}
{"mode": "train", "epochs": 2, "timestep": 3474, "ep_reward": 798.0291137695312, "reward": 0.8459870219230652, "action": -1.074007272720337}
{"mode": "train", "epochs": 2, "timestep": 3475, "ep_reward": 798.8525390625, "reward": 0.8234448432922363, "action": -0.9381123185157776}
{"mode": "train", "epochs": 2, "timestep": 3476, "ep_reward": 799.631103515625, "reward": 0.7785425186157227, "action": -1.037201166152954}
{"mode": "train", "epochs": 2, "timestep": 3477, "ep_reward": 800.334228515625, "reward": 0.7031444311141968, "action": -1.100835919380188}
{"mode": "train", "epochs": 2, "timestep": 3478, "ep_reward": 800.9244995117188, "reward": 0.5902672410011292, "action": -0.3791210651397705}
{"mode": "train", "epochs": 2, "timestep": 3479, "ep_reward": 801.3705444335938, "reward": 0.4460597038269043, "action": -0.857418417930603}
{"mode": "train", "epochs": 2, "timestep": 3480, "ep_reward": 801.6980590820312, "reward": 0.32750290632247925, "action": -1.2675460577011108}
{"mode": "train", "epochs": 2, "timestep": 3481, "ep_reward": 801.9111328125, "reward": 0.213084876537323, "action": -1.4682947397232056}
{"mode": "train", "epochs": 2, "timestep": 3482, "ep_reward": 801.989990234375, "reward": 0.07883262634277344, "action": 0.22234272956848145}
{"mode": "train", "epochs": 2, "timestep": 3483, "ep_reward": 802.0291748046875, "reward": 0.039176881313323975, "action": -0.23755282163619995}
{"mode": "train", "epochs": 2, "timestep": 3484, "ep_reward": 802.2141723632812, "reward": 0.184984028339386, "action": -1.2570483684539795}
{"mode": "train", "epochs": 2, "timestep": 3485, "ep_reward": 802.5347900390625, "reward": 0.3206106424331665, "action": -1.3210991621017456}
{"mode": "train", "epochs": 2, "timestep": 3486, "ep_reward": 802.986328125, "reward": 0.45151108503341675, "action": -0.19139647483825684}
{"mode": "train", "epochs": 2, "timestep": 3487, "ep_reward": 803.5679321289062, "reward": 0.5816161632537842, "action": -0.5421591997146606}
{"mode": "train", "epochs": 2, "timestep": 3488, "ep_reward": 804.2529296875, "reward": 0.6849707365036011, "action": -1.4792065620422363}
{"mode": "train", "epochs": 2, "timestep": 3489, "ep_reward": 805.0093994140625, "reward": 0.7564625144004822, "action": -1.2675570249557495}
{"mode": "train", "epochs": 2, "timestep": 3490, "ep_reward": 805.8192749023438, "reward": 0.8098575472831726, "action": -0.44780218601226807}
{"mode": "train", "epochs": 2, "timestep": 3491, "ep_reward": 806.6705932617188, "reward": 0.8513142466545105, "action": -1.4303086996078491}
{"mode": "train", "epochs": 2, "timestep": 3492, "ep_reward": 807.5383911132812, "reward": 0.8677722215652466, "action": -1.011631965637207}
{"mode": "train", "epochs": 2, "timestep": 3493, "ep_reward": 808.4104614257812, "reward": 0.8720564246177673, "action": -1.4084296226501465}
{"mode": "train", "epochs": 2, "timestep": 3494, "ep_reward": 809.26708984375, "reward": 0.8566429615020752, "action": -0.9121862649917603}
{"mode": "train", "epochs": 2, "timestep": 3495, "ep_reward": 810.093505859375, "reward": 0.8264036774635315, "action": -0.46118682622909546}
{"mode": "train", "epochs": 2, "timestep": 3496, "ep_reward": 810.8711547851562, "reward": 0.7776241898536682, "action": -0.9174848794937134}
{"mode": "train", "epochs": 2, "timestep": 3497, "ep_reward": 811.5665893554688, "reward": 0.6954317688941956, "action": -1.5111141204833984}
{"mode": "train", "epochs": 2, "timestep": 3498, "ep_reward": 812.1355590820312, "reward": 0.5689603090286255, "action": -1.366206169128418}
{"mode": "train", "epochs": 2, "timestep": 3499, "ep_reward": 812.5360107421875, "reward": 0.4004759192466736, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3500, "ep_reward": 812.8303833007812, "reward": 0.29439473152160645, "action": -0.659522294998169}
{"mode": "train", "epochs": 2, "timestep": 3501, "ep_reward": 813.0042114257812, "reward": 0.1738346815109253, "action": -0.6752480268478394}
{"mode": "train", "epochs": 2, "timestep": 3502, "ep_reward": 813.0375366210938, "reward": 0.033303260803222656, "action": 0.13159668445587158}
{"mode": "train", "epochs": 2, "timestep": 3503, "ep_reward": 813.1220092773438, "reward": 0.08445537090301514, "action": -0.4865061044692993}
{"mode": "train", "epochs": 2, "timestep": 3504, "ep_reward": 813.3505249023438, "reward": 0.22853851318359375, "action": -1.538407564163208}
{"mode": "train", "epochs": 2, "timestep": 3505, "ep_reward": 813.7108764648438, "reward": 0.3603264093399048, "action": -0.40238893032073975}
{"mode": "train", "epochs": 2, "timestep": 3506, "ep_reward": 814.2098999023438, "reward": 0.49899953603744507, "action": -0.6859071254730225}
{"mode": "train", "epochs": 2, "timestep": 3507, "ep_reward": 814.825927734375, "reward": 0.6160401105880737, "action": -0.7480708360671997}
{"mode": "train", "epochs": 2, "timestep": 3508, "ep_reward": 815.5361328125, "reward": 0.7102280259132385, "action": -1.3150304555892944}
{"mode": "train", "epochs": 2, "timestep": 3509, "ep_reward": 816.31298828125, "reward": 0.7768670320510864, "action": -1.1304875612258911}
{"mode": "train", "epochs": 2, "timestep": 3510, "ep_reward": 817.1383056640625, "reward": 0.8253339529037476, "action": -1.5498557090759277}
{"mode": "train", "epochs": 2, "timestep": 3511, "ep_reward": 817.9909057617188, "reward": 0.8525943756103516, "action": -0.6930939555168152}
{"mode": "train", "epochs": 2, "timestep": 3512, "ep_reward": 818.861572265625, "reward": 0.8706470131874084, "action": -1.210680603981018}
{"mode": "train", "epochs": 2, "timestep": 3513, "ep_reward": 819.7301635742188, "reward": 0.868582546710968, "action": -0.9926540851593018}
{"mode": "train", "epochs": 2, "timestep": 3514, "ep_reward": 820.5813598632812, "reward": 0.8512013554573059, "action": -1.8884806632995605}
{"mode": "train", "epochs": 2, "timestep": 3515, "ep_reward": 821.38623046875, "reward": 0.8048940300941467, "action": -0.407825231552124}
{"mode": "train", "epochs": 2, "timestep": 3516, "ep_reward": 822.1331176757812, "reward": 0.7468805313110352, "action": -1.6356987953186035}
{"mode": "train", "epochs": 2, "timestep": 3517, "ep_reward": 822.7755126953125, "reward": 0.642364501953125, "action": -1.4695205688476562}
{"mode": "train", "epochs": 2, "timestep": 3518, "ep_reward": 823.2732543945312, "reward": 0.49774742126464844, "action": -1.3289800882339478}
{"mode": "train", "epochs": 2, "timestep": 3519, "ep_reward": 823.6328735351562, "reward": 0.35962510108947754, "action": -1.4580910205841064}
{"mode": "train", "epochs": 2, "timestep": 3520, "ep_reward": 823.8845825195312, "reward": 0.2517017126083374, "action": -0.6548099517822266}
{"mode": "train", "epochs": 2, "timestep": 3521, "ep_reward": 824.0081176757812, "reward": 0.12353503704071045, "action": -1.6323528289794922}
{"mode": "train", "epochs": 2, "timestep": 3522, "ep_reward": 823.9986572265625, "reward": -0.009433507919311523, "action": -0.4500030279159546}
{"mode": "train", "epochs": 2, "timestep": 3523, "ep_reward": 824.1351318359375, "reward": 0.13648396730422974, "action": -1.8928338289260864}
{"mode": "train", "epochs": 2, "timestep": 3524, "ep_reward": 824.3997802734375, "reward": 0.2646262049674988, "action": -0.5898211002349854}
{"mode": "train", "epochs": 2, "timestep": 3525, "ep_reward": 824.8092041015625, "reward": 0.40941691398620605, "action": -0.900676965713501}
{"mode": "train", "epochs": 2, "timestep": 3526, "ep_reward": 825.3465576171875, "reward": 0.5373731255531311, "action": -1.2868492603302002}
{"mode": "train", "epochs": 2, "timestep": 3527, "ep_reward": 825.9879760742188, "reward": 0.6414142847061157, "action": -1.4952905178070068}
{"mode": "train", "epochs": 2, "timestep": 3528, "ep_reward": 826.709228515625, "reward": 0.7212501764297485, "action": -1.338927149772644}
{"mode": "train", "epochs": 2, "timestep": 3529, "ep_reward": 827.48974609375, "reward": 0.7804906368255615, "action": -1.1546878814697266}
{"mode": "train", "epochs": 2, "timestep": 3530, "ep_reward": 828.31005859375, "reward": 0.8202834725379944, "action": -1.1139291524887085}
{"mode": "train", "epochs": 2, "timestep": 3531, "ep_reward": 829.1505737304688, "reward": 0.8405342698097229, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3532, "ep_reward": 829.9840087890625, "reward": 0.8334066271781921, "action": -1.7834664583206177}
{"mode": "train", "epochs": 2, "timestep": 3533, "ep_reward": 830.7904052734375, "reward": 0.806369423866272, "action": -1.1402112245559692}
{"mode": "train", "epochs": 2, "timestep": 3534, "ep_reward": 831.5499877929688, "reward": 0.7595539093017578, "action": -0.7760401964187622}
{"mode": "train", "epochs": 2, "timestep": 3535, "ep_reward": 832.2353515625, "reward": 0.6853381395339966, "action": -0.755933940410614}
{"mode": "train", "epochs": 2, "timestep": 3536, "ep_reward": 832.80908203125, "reward": 0.5737575888633728, "action": -0.9547291994094849}
{"mode": "train", "epochs": 2, "timestep": 3537, "ep_reward": 833.2275390625, "reward": 0.4184580445289612, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3538, "ep_reward": 833.5509643554688, "reward": 0.3234323263168335, "action": -1.388481855392456}
{"mode": "train", "epochs": 2, "timestep": 3539, "ep_reward": 833.75927734375, "reward": 0.2082967758178711, "action": -1.2744102478027344}
{"mode": "train", "epochs": 2, "timestep": 3540, "ep_reward": 833.832275390625, "reward": 0.07299435138702393, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3541, "ep_reward": 833.8770751953125, "reward": 0.04482036828994751, "action": -1.4254908561706543}
{"mode": "train", "epochs": 2, "timestep": 3542, "ep_reward": 834.06103515625, "reward": 0.18393337726593018, "action": -0.5013313293457031}
{"mode": "train", "epochs": 2, "timestep": 3543, "ep_reward": 834.3912963867188, "reward": 0.3302741050720215, "action": -0.22218674421310425}
{"mode": "train", "epochs": 2, "timestep": 3544, "ep_reward": 834.8642578125, "reward": 0.47294437885284424, "action": -0.2767251133918762}
{"mode": "train", "epochs": 2, "timestep": 3545, "ep_reward": 835.462158203125, "reward": 0.5979179739952087, "action": -0.7930168509483337}
{"mode": "train", "epochs": 2, "timestep": 3546, "ep_reward": 836.157958984375, "reward": 0.6958118677139282, "action": -0.18307030200958252}
{"mode": "train", "epochs": 2, "timestep": 3547, "ep_reward": 836.935302734375, "reward": 0.7773375511169434, "action": -0.18436694145202637}
{"mode": "train", "epochs": 2, "timestep": 3548, "ep_reward": 837.7726440429688, "reward": 0.8373171091079712, "action": -0.9864747524261475}
{"mode": "train", "epochs": 2, "timestep": 3549, "ep_reward": 838.6463623046875, "reward": 0.87373286485672, "action": -1.086525797843933}
{"mode": "train", "epochs": 2, "timestep": 3550, "ep_reward": 839.5422973632812, "reward": 0.895913302898407, "action": -1.1988298892974854}
{"mode": "train", "epochs": 2, "timestep": 3551, "ep_reward": 840.4478149414062, "reward": 0.9055333137512207, "action": -1.0156608819961548}
{"mode": "train", "epochs": 2, "timestep": 3552, "ep_reward": 841.352783203125, "reward": 0.9049807190895081, "action": -1.1910321712493896}
{"mode": "train", "epochs": 2, "timestep": 3553, "ep_reward": 842.2435302734375, "reward": 0.8907588124275208, "action": -1.028452754020691}
{"mode": "train", "epochs": 2, "timestep": 3554, "ep_reward": 843.1062622070312, "reward": 0.8627191185951233, "action": -1.0951108932495117}
{"mode": "train", "epochs": 2, "timestep": 3555, "ep_reward": 843.9210815429688, "reward": 0.8148208856582642, "action": -0.872063398361206}
{"mode": "train", "epochs": 2, "timestep": 3556, "ep_reward": 844.6650390625, "reward": 0.7439606189727783, "action": -1.0941028594970703}
{"mode": "train", "epochs": 2, "timestep": 3557, "ep_reward": 845.3038940429688, "reward": 0.6388376951217651, "action": -0.9806598424911499}
{"mode": "train", "epochs": 2, "timestep": 3558, "ep_reward": 845.8009643554688, "reward": 0.49709582328796387, "action": -0.31750988960266113}
{"mode": "train", "epochs": 2, "timestep": 3559, "ep_reward": 846.1315307617188, "reward": 0.3305695652961731, "action": -1.2434552907943726}
{"mode": "train", "epochs": 2, "timestep": 3560, "ep_reward": 846.3483276367188, "reward": 0.21682453155517578, "action": -0.883752703666687}
{"mode": "train", "epochs": 2, "timestep": 3561, "ep_reward": 846.4313354492188, "reward": 0.08299678564071655, "action": -1.1617450714111328}
{"mode": "train", "epochs": 2, "timestep": 3562, "ep_reward": 846.466064453125, "reward": 0.03470855951309204, "action": -0.8694515824317932}
{"mode": "train", "epochs": 2, "timestep": 3563, "ep_reward": 846.6409912109375, "reward": 0.1749364733695984, "action": -1.7105400562286377}
{"mode": "train", "epochs": 2, "timestep": 3564, "ep_reward": 846.9471435546875, "reward": 0.3061431050300598, "action": -0.8648948669433594}
{"mode": "train", "epochs": 2, "timestep": 3565, "ep_reward": 847.3921508789062, "reward": 0.4449916481971741, "action": -0.29847604036331177}
{"mode": "train", "epochs": 2, "timestep": 3566, "ep_reward": 847.9674072265625, "reward": 0.5752586722373962, "action": -0.2763984203338623}
{"mode": "train", "epochs": 2, "timestep": 3567, "ep_reward": 848.6499633789062, "reward": 0.6825637817382812, "action": -0.9730613827705383}
{"mode": "train", "epochs": 2, "timestep": 3568, "ep_reward": 849.4088745117188, "reward": 0.7589138746261597, "action": -0.898974597454071}
{"mode": "train", "epochs": 2, "timestep": 3569, "ep_reward": 850.2235717773438, "reward": 0.8147151470184326, "action": -0.9708748459815979}
{"mode": "train", "epochs": 2, "timestep": 3570, "ep_reward": 851.0745849609375, "reward": 0.8510123491287231, "action": -1.1596394777297974}
{"mode": "train", "epochs": 2, "timestep": 3571, "ep_reward": 851.94384765625, "reward": 0.8692857027053833, "action": -0.7611589431762695}
{"mode": "train", "epochs": 2, "timestep": 3572, "ep_reward": 852.8191528320312, "reward": 0.875308632850647, "action": -1.0215378999710083}
{"mode": "train", "epochs": 2, "timestep": 3573, "ep_reward": 853.6824951171875, "reward": 0.8633237481117249, "action": -0.8166227340698242}
{"mode": "train", "epochs": 2, "timestep": 3574, "ep_reward": 854.5174560546875, "reward": 0.8349778652191162, "action": -0.6939160227775574}
{"mode": "train", "epochs": 2, "timestep": 3575, "ep_reward": 855.3031616210938, "reward": 0.7856955528259277, "action": -1.3460462093353271}
{"mode": "train", "epochs": 2, "timestep": 3576, "ep_reward": 856.0040893554688, "reward": 0.700957179069519, "action": -1.4975990056991577}
{"mode": "train", "epochs": 2, "timestep": 3577, "ep_reward": 856.5808715820312, "reward": 0.5768089890480042, "action": -1.5782523155212402}
{"mode": "train", "epochs": 2, "timestep": 3578, "ep_reward": 856.9884033203125, "reward": 0.40750694274902344, "action": -0.4984579086303711}
{"mode": "train", "epochs": 2, "timestep": 3579, "ep_reward": 857.2883911132812, "reward": 0.2999727129936218, "action": -0.4965992569923401}
{"mode": "train", "epochs": 2, "timestep": 3580, "ep_reward": 857.46875, "reward": 0.18034136295318604, "action": -1.278070330619812}
{"mode": "train", "epochs": 2, "timestep": 3581, "ep_reward": 857.5095825195312, "reward": 0.04084610939025879, "action": -0.9233317971229553}
{"mode": "train", "epochs": 2, "timestep": 3582, "ep_reward": 857.5865478515625, "reward": 0.07696616649627686, "action": -1.8200714588165283}
{"mode": "train", "epochs": 2, "timestep": 3583, "ep_reward": 857.79833984375, "reward": 0.21176284551620483, "action": -0.5931879281997681}
{"mode": "train", "epochs": 2, "timestep": 3584, "ep_reward": 858.1553955078125, "reward": 0.3570607304573059, "action": -1.6517715454101562}
{"mode": "train", "epochs": 2, "timestep": 3585, "ep_reward": 858.636474609375, "reward": 0.48107314109802246, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3586, "ep_reward": 859.2233276367188, "reward": 0.5868649482727051, "action": -0.4937191605567932}
{"mode": "train", "epochs": 2, "timestep": 3587, "ep_reward": 859.9119873046875, "reward": 0.6886632442474365, "action": -1.7950499057769775}
{"mode": "train", "epochs": 2, "timestep": 3588, "ep_reward": 860.664794921875, "reward": 0.7527831196784973, "action": -1.1993207931518555}
{"mode": "train", "epochs": 2, "timestep": 3589, "ep_reward": 861.4658813476562, "reward": 0.8011053800582886, "action": -0.22411668300628662}
{"mode": "train", "epochs": 2, "timestep": 3590, "ep_reward": 862.3032836914062, "reward": 0.8373885750770569, "action": -0.5792585611343384}
{"mode": "train", "epochs": 2, "timestep": 3591, "ep_reward": 863.1539916992188, "reward": 0.8507164716720581, "action": -1.448470115661621}
{"mode": "train", "epochs": 2, "timestep": 3592, "ep_reward": 863.9912719726562, "reward": 0.8372670412063599, "action": -1.2964446544647217}
{"mode": "train", "epochs": 2, "timestep": 3593, "ep_reward": 864.7946166992188, "reward": 0.8033177852630615, "action": -1.4803385734558105}
{"mode": "train", "epochs": 2, "timestep": 3594, "ep_reward": 865.5348510742188, "reward": 0.7402405738830566, "action": -0.681402325630188}
{"mode": "train", "epochs": 2, "timestep": 3595, "ep_reward": 866.1875, "reward": 0.6526551246643066, "action": -0.9638047814369202}
{"mode": "train", "epochs": 2, "timestep": 3596, "ep_reward": 866.70947265625, "reward": 0.5219976902008057, "action": -1.3035988807678223}
{"mode": "train", "epochs": 2, "timestep": 3597, "ep_reward": 867.0908203125, "reward": 0.38132941722869873, "action": -1.0465675592422485}
{"mode": "train", "epochs": 2, "timestep": 3598, "ep_reward": 867.3687133789062, "reward": 0.2778856158256531, "action": -0.2596241235733032}
{"mode": "train", "epochs": 2, "timestep": 3599, "ep_reward": 867.5230712890625, "reward": 0.15432798862457275, "action": -0.9324660301208496}
{"mode": "train", "epochs": 2, "timestep": 3600, "ep_reward": 867.5338745117188, "reward": 0.010785460472106934, "action": -1.2000974416732788}
{"mode": "train", "epochs": 2, "timestep": 3601, "ep_reward": 867.6392211914062, "reward": 0.10532468557357788, "action": -1.326172113418579}
{"mode": "train", "epochs": 2, "timestep": 3602, "ep_reward": 867.87890625, "reward": 0.23965942859649658, "action": -1.0794389247894287}
{"mode": "train", "epochs": 2, "timestep": 3603, "ep_reward": 868.2572021484375, "reward": 0.3782693147659302, "action": -1.5765408277511597}
{"mode": "train", "epochs": 2, "timestep": 3604, "ep_reward": 868.759033203125, "reward": 0.5018517374992371, "action": -1.0595663785934448}
{"mode": "train", "epochs": 2, "timestep": 3605, "ep_reward": 869.3737182617188, "reward": 0.6146801114082336, "action": -1.2075986862182617}
{"mode": "train", "epochs": 2, "timestep": 3606, "ep_reward": 870.0770874023438, "reward": 0.7033467292785645, "action": -0.5545518398284912}
{"mode": "train", "epochs": 2, "timestep": 3607, "ep_reward": 870.8521728515625, "reward": 0.7750943303108215, "action": -0.17171144485473633}
{"mode": "train", "epochs": 2, "timestep": 3608, "ep_reward": 871.6795654296875, "reward": 0.8273775577545166, "action": -1.8404908180236816}
{"mode": "train", "epochs": 2, "timestep": 3609, "ep_reward": 872.5250244140625, "reward": 0.8454764485359192, "action": -1.5382853746414185}
{"mode": "train", "epochs": 2, "timestep": 3610, "ep_reward": 873.3734741210938, "reward": 0.8484362363815308, "action": -1.4121448993682861}
{"mode": "train", "epochs": 2, "timestep": 3611, "ep_reward": 874.2068481445312, "reward": 0.8333619236946106, "action": -0.7445424795150757}
{"mode": "train", "epochs": 2, "timestep": 3612, "ep_reward": 875.009521484375, "reward": 0.8027019500732422, "action": -0.5771321058273315}
{"mode": "train", "epochs": 2, "timestep": 3613, "ep_reward": 875.7575073242188, "reward": 0.7479710578918457, "action": -1.125515103340149}
{"mode": "train", "epochs": 2, "timestep": 3614, "ep_reward": 876.4122924804688, "reward": 0.6547850370407104, "action": -1.123583436012268}
{"mode": "train", "epochs": 2, "timestep": 3615, "ep_reward": 876.933837890625, "reward": 0.5215280055999756, "action": -0.7008198499679565}
{"mode": "train", "epochs": 2, "timestep": 3616, "ep_reward": 877.3115234375, "reward": 0.37768930196762085, "action": -1.5574439764022827}
{"mode": "train", "epochs": 2, "timestep": 3617, "ep_reward": 877.5850219726562, "reward": 0.2735157012939453, "action": -0.9745194911956787}
{"mode": "train", "epochs": 2, "timestep": 3618, "ep_reward": 877.734130859375, "reward": 0.1491134762763977, "action": -1.7725598812103271}
{"mode": "train", "epochs": 2, "timestep": 3619, "ep_reward": 877.739013671875, "reward": 0.004864096641540527, "action": -1.7026333808898926}
{"mode": "train", "epochs": 2, "timestep": 3620, "ep_reward": 877.8497314453125, "reward": 0.11070448160171509, "action": -0.8427697420120239}
{"mode": "train", "epochs": 2, "timestep": 3621, "ep_reward": 878.1009521484375, "reward": 0.251193642616272, "action": -1.1621330976486206}
{"mode": "train", "epochs": 2, "timestep": 3622, "ep_reward": 878.4884643554688, "reward": 0.3875090479850769, "action": -0.6129881143569946}
{"mode": "train", "epochs": 2, "timestep": 3623, "ep_reward": 879.00927734375, "reward": 0.5208150148391724, "action": -0.9271543622016907}
{"mode": "train", "epochs": 2, "timestep": 3624, "ep_reward": 879.6409301757812, "reward": 0.6316550970077515, "action": -1.149261713027954}
{"mode": "train", "epochs": 2, "timestep": 3625, "ep_reward": 880.3593139648438, "reward": 0.7183800339698792, "action": -0.5858544111251831}
{"mode": "train", "epochs": 2, "timestep": 3626, "ep_reward": 881.147705078125, "reward": 0.788383424282074, "action": -0.6103605031967163}
{"mode": "train", "epochs": 2, "timestep": 3627, "ep_reward": 881.98486328125, "reward": 0.8371433019638062, "action": -1.223101019859314}
{"mode": "train", "epochs": 2, "timestep": 3628, "ep_reward": 882.8480834960938, "reward": 0.8631936311721802, "action": -0.41157305240631104}
{"mode": "train", "epochs": 2, "timestep": 3629, "ep_reward": 883.7282104492188, "reward": 0.8801354169845581, "action": -1.3883763551712036}
{"mode": "train", "epochs": 2, "timestep": 3630, "ep_reward": 884.6024780273438, "reward": 0.8742486834526062, "action": -1.3676050901412964}
{"mode": "train", "epochs": 2, "timestep": 3631, "ep_reward": 885.4542846679688, "reward": 0.8518322706222534, "action": -1.0742714405059814}
{"mode": "train", "epochs": 2, "timestep": 3632, "ep_reward": 886.2659912109375, "reward": 0.8116817474365234, "action": 0.21608316898345947}
{"mode": "train", "epochs": 2, "timestep": 3633, "ep_reward": 887.0263671875, "reward": 0.7603806257247925, "action": -1.0517727136611938}
{"mode": "train", "epochs": 2, "timestep": 3634, "ep_reward": 887.6923217773438, "reward": 0.6659485697746277, "action": -1.6801035404205322}
{"mode": "train", "epochs": 2, "timestep": 3635, "ep_reward": 888.2169189453125, "reward": 0.5246126651763916, "action": -0.6079951524734497}
{"mode": "train", "epochs": 2, "timestep": 3636, "ep_reward": 888.5802612304688, "reward": 0.36334145069122314, "action": -1.4858613014221191}
{"mode": "train", "epochs": 2, "timestep": 3637, "ep_reward": 888.8363647460938, "reward": 0.25608348846435547, "action": -1.4478263854980469}
{"mode": "train", "epochs": 2, "timestep": 3638, "ep_reward": 888.9652099609375, "reward": 0.12887263298034668, "action": -1.1132487058639526}
{"mode": "train", "epochs": 2, "timestep": 3639, "ep_reward": 888.9498291015625, "reward": -0.01539313793182373, "action": -0.2648239731788635}
{"mode": "train", "epochs": 2, "timestep": 3640, "ep_reward": 889.0812377929688, "reward": 0.1314253807067871, "action": -1.111664056777954}
{"mode": "train", "epochs": 2, "timestep": 3641, "ep_reward": 889.3504638671875, "reward": 0.26919716596603394, "action": -0.44167959690093994}
{"mode": "train", "epochs": 2, "timestep": 3642, "ep_reward": 889.7644653320312, "reward": 0.41397958993911743, "action": -0.5524080991744995}
{"mode": "train", "epochs": 2, "timestep": 3643, "ep_reward": 890.308837890625, "reward": 0.544379711151123, "action": -1.2403563261032104}
{"mode": "train", "epochs": 2, "timestep": 3644, "ep_reward": 890.9566040039062, "reward": 0.6477881669998169, "action": -1.1060149669647217}
{"mode": "train", "epochs": 2, "timestep": 3645, "ep_reward": 891.6880493164062, "reward": 0.7314612865447998, "action": -0.4739810824394226}
{"mode": "train", "epochs": 2, "timestep": 3646, "ep_reward": 892.4873046875, "reward": 0.7992346286773682, "action": -0.3212445378303528}
{"mode": "train", "epochs": 2, "timestep": 3647, "ep_reward": 893.3350830078125, "reward": 0.8477661609649658, "action": -0.21540004014968872}
{"mode": "train", "epochs": 2, "timestep": 3648, "ep_reward": 894.2147827148438, "reward": 0.8797227144241333, "action": -0.26445072889328003}
{"mode": "train", "epochs": 2, "timestep": 3649, "ep_reward": 895.1115112304688, "reward": 0.8967406749725342, "action": -0.1884627342224121}
{"mode": "train", "epochs": 2, "timestep": 3650, "ep_reward": 896.0130004882812, "reward": 0.9014731645584106, "action": -0.9061521291732788}
{"mode": "train", "epochs": 2, "timestep": 3651, "ep_reward": 896.9010620117188, "reward": 0.8880783319473267, "action": -1.2303320169448853}
{"mode": "train", "epochs": 2, "timestep": 3652, "ep_reward": 897.7578125, "reward": 0.8567283153533936, "action": -0.1444677710533142}
{"mode": "train", "epochs": 2, "timestep": 3653, "ep_reward": 898.5734252929688, "reward": 0.8156282901763916, "action": -0.9366458058357239}
{"mode": "train", "epochs": 2, "timestep": 3654, "ep_reward": 899.3164672851562, "reward": 0.7430649995803833, "action": -1.1162009239196777}
{"mode": "train", "epochs": 2, "timestep": 3655, "ep_reward": 899.9530639648438, "reward": 0.6365902423858643, "action": -1.049660086631775}
{"mode": "train", "epochs": 2, "timestep": 3656, "ep_reward": 900.4459228515625, "reward": 0.4928305745124817, "action": -0.587180495262146}
{"mode": "train", "epochs": 2, "timestep": 3657, "ep_reward": 900.771484375, "reward": 0.32554006576538086, "action": -1.5336086750030518}
{"mode": "train", "epochs": 2, "timestep": 3658, "ep_reward": 900.9823608398438, "reward": 0.21086031198501587, "action": -1.1233679056167603}
{"mode": "train", "epochs": 2, "timestep": 3659, "ep_reward": 901.0584106445312, "reward": 0.07605445384979248, "action": -1.482938528060913}
{"mode": "train", "epochs": 2, "timestep": 3660, "ep_reward": 901.1002807617188, "reward": 0.04184216260910034, "action": -1.0668401718139648}
{"mode": "train", "epochs": 2, "timestep": 3661, "ep_reward": 901.2816162109375, "reward": 0.18130922317504883, "action": -0.44708651304244995}
{"mode": "train", "epochs": 2, "timestep": 3662, "ep_reward": 901.60986328125, "reward": 0.32824015617370605, "action": -0.8578521609306335}
{"mode": "train", "epochs": 2, "timestep": 3663, "ep_reward": 902.0733032226562, "reward": 0.4634511470794678, "action": -1.3685755729675293}
{"mode": "train", "epochs": 2, "timestep": 3664, "ep_reward": 902.6517333984375, "reward": 0.5784128904342651, "action": -0.6449782252311707}
{"mode": "train", "epochs": 2, "timestep": 3665, "ep_reward": 903.3331298828125, "reward": 0.6814221143722534, "action": -0.7805237174034119}
{"mode": "train", "epochs": 2, "timestep": 3666, "ep_reward": 904.0929565429688, "reward": 0.7598128318786621, "action": -1.042019009590149}
{"mode": "train", "epochs": 2, "timestep": 3667, "ep_reward": 904.9073486328125, "reward": 0.8144012689590454, "action": -1.0958553552627563}
{"mode": "train", "epochs": 2, "timestep": 3668, "ep_reward": 905.75732421875, "reward": 0.849994421005249, "action": -0.5351078510284424}
{"mode": "train", "epochs": 2, "timestep": 3669, "ep_reward": 906.630859375, "reward": 0.8735089898109436, "action": -1.4225077629089355}
{"mode": "train", "epochs": 2, "timestep": 3670, "ep_reward": 907.5054931640625, "reward": 0.8746174573898315, "action": -0.8053683638572693}
{"mode": "train", "epochs": 2, "timestep": 3671, "ep_reward": 908.3704833984375, "reward": 0.8649687767028809, "action": -0.9835026860237122}
{"mode": "train", "epochs": 2, "timestep": 3672, "ep_reward": 909.2061157226562, "reward": 0.8356478214263916, "action": -1.8640990257263184}
{"mode": "train", "epochs": 2, "timestep": 3673, "ep_reward": 909.9807739257812, "reward": 0.7746295928955078, "action": -0.8370360136032104}
{"mode": "train", "epochs": 2, "timestep": 3674, "ep_reward": 910.674560546875, "reward": 0.6938166618347168, "action": -0.8899280428886414}
{"mode": "train", "epochs": 2, "timestep": 3675, "ep_reward": 911.2508544921875, "reward": 0.5762972831726074, "action": -1.529552698135376}
{"mode": "train", "epochs": 2, "timestep": 3676, "ep_reward": 911.6583251953125, "reward": 0.40748971700668335, "action": -1.319017767906189}
{"mode": "train", "epochs": 2, "timestep": 3677, "ep_reward": 911.957275390625, "reward": 0.2989296317100525, "action": -1.136674404144287}
{"mode": "train", "epochs": 2, "timestep": 3678, "ep_reward": 912.1365356445312, "reward": 0.17926090955734253, "action": -0.6504126191139221}
{"mode": "train", "epochs": 2, "timestep": 3679, "ep_reward": 912.176025390625, "reward": 0.039497554302215576, "action": -1.0386853218078613}
{"mode": "train", "epochs": 2, "timestep": 3680, "ep_reward": 912.2544555664062, "reward": 0.07845151424407959, "action": -0.4122259020805359}
{"mode": "train", "epochs": 2, "timestep": 3681, "ep_reward": 912.4777221679688, "reward": 0.22324800491333008, "action": -1.6589250564575195}
{"mode": "train", "epochs": 2, "timestep": 3682, "ep_reward": 912.8312377929688, "reward": 0.3534865379333496, "action": -1.1727805137634277}
{"mode": "train", "epochs": 2, "timestep": 3683, "ep_reward": 913.3151245117188, "reward": 0.4838590621948242, "action": -1.261597752571106}
{"mode": "train", "epochs": 2, "timestep": 3684, "ep_reward": 913.9125366210938, "reward": 0.5973986387252808, "action": -0.2766065001487732}
{"mode": "train", "epochs": 2, "timestep": 3685, "ep_reward": 914.6123046875, "reward": 0.6997758150100708, "action": -0.8300949335098267}
{"mode": "train", "epochs": 2, "timestep": 3686, "ep_reward": 915.3844604492188, "reward": 0.7721311450004578, "action": -1.18911612033844}
{"mode": "train", "epochs": 2, "timestep": 3687, "ep_reward": 916.2045288085938, "reward": 0.8200656175613403, "action": -0.11154049634933472}
{"mode": "train", "epochs": 2, "timestep": 3688, "ep_reward": 917.0628662109375, "reward": 0.8583393096923828, "action": -1.566260576248169}
{"mode": "train", "epochs": 2, "timestep": 3689, "ep_reward": 917.9305419921875, "reward": 0.8676896095275879, "action": -1.3629696369171143}
{"mode": "train", "epochs": 2, "timestep": 3690, "ep_reward": 918.79296875, "reward": 0.8624522686004639, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3691, "ep_reward": 919.626220703125, "reward": 0.8332353830337524, "action": -0.3933294415473938}
{"mode": "train", "epochs": 2, "timestep": 3692, "ep_reward": 920.4229125976562, "reward": 0.7966866493225098, "action": -0.9688071608543396}
{"mode": "train", "epochs": 2, "timestep": 3693, "ep_reward": 921.1505126953125, "reward": 0.7276144027709961, "action": -0.4261227250099182}
{"mode": "train", "epochs": 2, "timestep": 3694, "ep_reward": 921.7821044921875, "reward": 0.6316020488739014, "action": -1.8298165798187256}
{"mode": "train", "epochs": 2, "timestep": 3695, "ep_reward": 922.2587890625, "reward": 0.476703405380249, "action": -1.5028066635131836}
{"mode": "train", "epochs": 2, "timestep": 3696, "ep_reward": 922.6036987304688, "reward": 0.34490716457366943, "action": -0.6734346151351929}
{"mode": "train", "epochs": 2, "timestep": 3697, "ep_reward": 922.8375854492188, "reward": 0.2338848114013672, "action": -0.8466818928718567}
{"mode": "train", "epochs": 2, "timestep": 3698, "ep_reward": 922.9403686523438, "reward": 0.1027875542640686, "action": -1.4786877632141113}
{"mode": "train", "epochs": 2, "timestep": 3699, "ep_reward": 922.9539794921875, "reward": 0.013589859008789062, "action": -0.5485507249832153}
{"mode": "train", "epochs": 2, "timestep": 3700, "ep_reward": 923.1106567382812, "reward": 0.15667206048965454, "action": -1.179394245147705}
{"mode": "train", "epochs": 2, "timestep": 3701, "ep_reward": 923.40478515625, "reward": 0.2941257357597351, "action": -1.0201382637023926}
{"mode": "train", "epochs": 2, "timestep": 3702, "ep_reward": 923.8356323242188, "reward": 0.4308212399482727, "action": -0.8129190802574158}
{"mode": "train", "epochs": 2, "timestep": 3703, "ep_reward": 924.392333984375, "reward": 0.556682825088501, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3704, "ep_reward": 925.0421142578125, "reward": 0.6497812271118164, "action": -0.9185924530029297}
{"mode": "train", "epochs": 2, "timestep": 3705, "ep_reward": 925.7750244140625, "reward": 0.7329142093658447, "action": -1.6795425415039062}
{"mode": "train", "epochs": 2, "timestep": 3706, "ep_reward": 926.5609130859375, "reward": 0.7858602404594421, "action": -1.5609887838363647}
{"mode": "train", "epochs": 2, "timestep": 3707, "ep_reward": 927.3804931640625, "reward": 0.8195585012435913, "action": -1.0103256702423096}
{"mode": "train", "epochs": 2, "timestep": 3708, "ep_reward": 928.2190551757812, "reward": 0.8385858535766602, "action": -1.1766210794448853}
{"mode": "train", "epochs": 2, "timestep": 3709, "ep_reward": 929.0555419921875, "reward": 0.8364598155021667, "action": -1.134901762008667}
{"mode": "train", "epochs": 2, "timestep": 3710, "ep_reward": 929.8690185546875, "reward": 0.8134725093841553, "action": -1.3711751699447632}
{"mode": "train", "epochs": 2, "timestep": 3711, "ep_reward": 930.6317749023438, "reward": 0.7627396583557129, "action": -0.5665782690048218}
{"mode": "train", "epochs": 2, "timestep": 3712, "ep_reward": 931.3217163085938, "reward": 0.6899385452270508, "action": -0.46101754903793335}
{"mode": "train", "epochs": 2, "timestep": 3713, "ep_reward": 931.9041137695312, "reward": 0.5823681950569153, "action": -1.2851308584213257}
{"mode": "train", "epochs": 2, "timestep": 3714, "ep_reward": 932.3251953125, "reward": 0.4210580587387085, "action": -0.9683879017829895}
{"mode": "train", "epochs": 2, "timestep": 3715, "ep_reward": 932.645751953125, "reward": 0.32057029008865356, "action": -1.3472399711608887}
{"mode": "train", "epochs": 2, "timestep": 3716, "ep_reward": 932.8507080078125, "reward": 0.20498371124267578, "action": 0.13398325443267822}
{"mode": "train", "epochs": 2, "timestep": 3717, "ep_reward": 932.9199829101562, "reward": 0.06928634643554688, "action": -0.05820775032043457}
{"mode": "train", "epochs": 2, "timestep": 3718, "ep_reward": 932.96875, "reward": 0.04878443479537964, "action": -1.8355859518051147}
{"mode": "train", "epochs": 2, "timestep": 3719, "ep_reward": 933.1561279296875, "reward": 0.18740296363830566, "action": -0.8896600604057312}
{"mode": "train", "epochs": 2, "timestep": 3720, "ep_reward": 933.485107421875, "reward": 0.32895898818969727, "action": -0.9709237813949585}
{"mode": "train", "epochs": 2, "timestep": 3721, "ep_reward": 933.94873046875, "reward": 0.4636231064796448, "action": -0.8779851794242859}
{"mode": "train", "epochs": 2, "timestep": 3722, "ep_reward": 934.5328369140625, "reward": 0.5841168165206909, "action": -1.7931079864501953}
{"mode": "train", "epochs": 2, "timestep": 3723, "ep_reward": 935.20703125, "reward": 0.674181342124939, "action": -0.8882028460502625}
{"mode": "train", "epochs": 2, "timestep": 3724, "ep_reward": 935.9589233398438, "reward": 0.7519218921661377, "action": -1.026817798614502}
{"mode": "train", "epochs": 2, "timestep": 3725, "ep_reward": 936.7649536132812, "reward": 0.8060435056686401, "action": -0.4594525098800659}
{"mode": "train", "epochs": 2, "timestep": 3726, "ep_reward": 937.6100463867188, "reward": 0.8450962901115417, "action": -1.0938935279846191}
{"mode": "train", "epochs": 2, "timestep": 3727, "ep_reward": 938.4706420898438, "reward": 0.8605884909629822, "action": -1.6290810108184814}
{"mode": "train", "epochs": 2, "timestep": 3728, "ep_reward": 939.3251953125, "reward": 0.8545538187026978, "action": -0.770506739616394}
{"mode": "train", "epochs": 2, "timestep": 3729, "ep_reward": 940.16259765625, "reward": 0.8373925685882568, "action": -0.9127594232559204}
{"mode": "train", "epochs": 2, "timestep": 3730, "ep_reward": 940.9598388671875, "reward": 0.7972133755683899, "action": -1.0253697633743286}
{"mode": "train", "epochs": 2, "timestep": 3731, "ep_reward": 941.6885986328125, "reward": 0.7287477254867554, "action": -0.22975420951843262}
{"mode": "train", "epochs": 2, "timestep": 3732, "ep_reward": 942.3252563476562, "reward": 0.6366795301437378, "action": -1.1105165481567383}
{"mode": "train", "epochs": 2, "timestep": 3733, "ep_reward": 942.8200073242188, "reward": 0.49476301670074463, "action": -1.236238718032837}
{"mode": "train", "epochs": 2, "timestep": 3734, "ep_reward": 943.1707763671875, "reward": 0.3507589101791382, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3735, "ep_reward": 943.4119873046875, "reward": 0.241199791431427, "action": -0.4543744921684265}
{"mode": "train", "epochs": 2, "timestep": 3736, "ep_reward": 943.5233764648438, "reward": 0.1113734245300293, "action": -0.8353615999221802}
{"mode": "train", "epochs": 2, "timestep": 3737, "ep_reward": 943.5275268554688, "reward": 0.004146933555603027, "action": -1.6053845882415771}
{"mode": "train", "epochs": 2, "timestep": 3738, "ep_reward": 943.676025390625, "reward": 0.1485123634338379, "action": -1.5789918899536133}
{"mode": "train", "epochs": 2, "timestep": 3739, "ep_reward": 943.9566650390625, "reward": 0.280637264251709, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3740, "ep_reward": 944.3634643554688, "reward": 0.40679049491882324, "action": -0.981914222240448}
{"mode": "train", "epochs": 2, "timestep": 3741, "ep_reward": 944.8983154296875, "reward": 0.5348690748214722, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3742, "ep_reward": 945.5296020507812, "reward": 0.6313056349754333, "action": -0.3818931579589844}
{"mode": "train", "epochs": 2, "timestep": 3743, "ep_reward": 946.252197265625, "reward": 0.7225812673568726, "action": -0.7134357690811157}
{"mode": "train", "epochs": 2, "timestep": 3744, "ep_reward": 947.0370483398438, "reward": 0.7848672866821289, "action": -0.9337208867073059}
{"mode": "train", "epochs": 2, "timestep": 3745, "ep_reward": 947.8594970703125, "reward": 0.8224403262138367, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3746, "ep_reward": 948.689697265625, "reward": 0.8301845192909241, "action": -0.7523251175880432}
{"mode": "train", "epochs": 2, "timestep": 3747, "ep_reward": 949.5189819335938, "reward": 0.8292610049247742, "action": -0.11137127876281738}
{"mode": "train", "epochs": 2, "timestep": 3748, "ep_reward": 950.33203125, "reward": 0.813023030757904, "action": -0.3037744164466858}
{"mode": "train", "epochs": 2, "timestep": 3749, "ep_reward": 951.10302734375, "reward": 0.7709943056106567, "action": -0.8291065096855164}
{"mode": "train", "epochs": 2, "timestep": 3750, "ep_reward": 951.7969970703125, "reward": 0.6939891576766968, "action": -1.0796784162521362}
{"mode": "train", "epochs": 2, "timestep": 3751, "ep_reward": 952.3740234375, "reward": 0.5770100355148315, "action": -0.4660346508026123}
{"mode": "train", "epochs": 2, "timestep": 3752, "ep_reward": 952.8009643554688, "reward": 0.42695432901382446, "action": -1.0137306451797485}
{"mode": "train", "epochs": 2, "timestep": 3753, "ep_reward": 953.1156005859375, "reward": 0.3146626353263855, "action": -1.674062967300415}
{"mode": "train", "epochs": 2, "timestep": 3754, "ep_reward": 953.3135375976562, "reward": 0.19795829057693481, "action": -1.1334202289581299}
{"mode": "train", "epochs": 2, "timestep": 3755, "ep_reward": 953.3746948242188, "reward": 0.06115919351577759, "action": -1.1368228197097778}
{"mode": "train", "epochs": 2, "timestep": 3756, "ep_reward": 953.4317626953125, "reward": 0.057056307792663574, "action": -1.107499361038208}
{"mode": "train", "epochs": 2, "timestep": 3757, "ep_reward": 953.626220703125, "reward": 0.1944345235824585, "action": -0.9422176480293274}
{"mode": "train", "epochs": 2, "timestep": 3758, "ep_reward": 953.9616088867188, "reward": 0.33539021015167236, "action": -1.1922390460968018}
{"mode": "train", "epochs": 2, "timestep": 3759, "ep_reward": 954.4285278320312, "reward": 0.4669184684753418, "action": -1.884087324142456}
{"mode": "train", "epochs": 2, "timestep": 3760, "ep_reward": 955.0045776367188, "reward": 0.5760473012924194, "action": -0.7195566892623901}
{"mode": "train", "epochs": 2, "timestep": 3761, "ep_reward": 955.682861328125, "reward": 0.6782670617103577, "action": -0.3462510108947754}
{"mode": "train", "epochs": 2, "timestep": 3762, "ep_reward": 956.4424438476562, "reward": 0.7596080303192139, "action": -0.9061589241027832}
{"mode": "train", "epochs": 2, "timestep": 3763, "ep_reward": 957.2548217773438, "reward": 0.8123959302902222, "action": -1.3269997835159302}
{"mode": "train", "epochs": 2, "timestep": 3764, "ep_reward": 958.0966796875, "reward": 0.8418822288513184, "action": -1.3261085748672485}
{"mode": "train", "epochs": 2, "timestep": 3765, "ep_reward": 958.9503173828125, "reward": 0.8536478281021118, "action": -1.008481502532959}
{"mode": "train", "epochs": 2, "timestep": 3766, "ep_reward": 959.8006591796875, "reward": 0.8503659963607788, "action": -0.7828150987625122}
{"mode": "train", "epochs": 2, "timestep": 3767, "ep_reward": 960.6304931640625, "reward": 0.8298063278198242, "action": -0.766338586807251}
{"mode": "train", "epochs": 2, "timestep": 3768, "ep_reward": 961.4173583984375, "reward": 0.7868474721908569, "action": -0.9277633428573608}
{"mode": "train", "epochs": 2, "timestep": 3769, "ep_reward": 962.1315307617188, "reward": 0.7141518592834473, "action": -0.6002478003501892}
{"mode": "train", "epochs": 2, "timestep": 3770, "ep_reward": 962.742431640625, "reward": 0.610916256904602, "action": 0.07952737808227539}
{"mode": "train", "epochs": 2, "timestep": 3771, "ep_reward": 963.2215576171875, "reward": 0.4791056513786316, "action": -1.2071336507797241}
{"mode": "train", "epochs": 2, "timestep": 3772, "ep_reward": 963.5563354492188, "reward": 0.3347914218902588, "action": -0.7687728404998779}
{"mode": "train", "epochs": 2, "timestep": 3773, "ep_reward": 963.7781372070312, "reward": 0.22181397676467896, "action": -0.6526104211807251}
{"mode": "train", "epochs": 2, "timestep": 3774, "ep_reward": 963.8667602539062, "reward": 0.08863645792007446, "action": -1.8634856939315796}
{"mode": "train", "epochs": 2, "timestep": 3775, "ep_reward": 963.8954467773438, "reward": 0.02867645025253296, "action": -0.4039875864982605}
{"mode": "train", "epochs": 2, "timestep": 3776, "ep_reward": 964.0675659179688, "reward": 0.17214030027389526, "action": -0.7768446207046509}
{"mode": "train", "epochs": 2, "timestep": 3777, "ep_reward": 964.3818969726562, "reward": 0.314339816570282, "action": -0.9790504574775696}
{"mode": "train", "epochs": 2, "timestep": 3778, "ep_reward": 964.8312377929688, "reward": 0.44935548305511475, "action": -0.1582881212234497}
{"mode": "train", "epochs": 2, "timestep": 3779, "ep_reward": 965.410888671875, "reward": 0.5796728730201721, "action": -0.2912142276763916}
{"mode": "train", "epochs": 2, "timestep": 3780, "ep_reward": 966.096923828125, "reward": 0.6860628724098206, "action": -0.3706997036933899}
{"mode": "train", "epochs": 2, "timestep": 3781, "ep_reward": 966.8651123046875, "reward": 0.7681957483291626, "action": -0.6421408653259277}
{"mode": "train", "epochs": 2, "timestep": 3782, "ep_reward": 967.6918334960938, "reward": 0.8267068862915039, "action": -0.645164966583252}
{"mode": "train", "epochs": 2, "timestep": 3783, "ep_reward": 968.5592041015625, "reward": 0.8673936724662781, "action": -1.2357642650604248}
{"mode": "train", "epochs": 2, "timestep": 3784, "ep_reward": 969.4482421875, "reward": 0.8890668153762817, "action": -1.6546807289123535}
{"mode": "train", "epochs": 2, "timestep": 3785, "ep_reward": 970.343505859375, "reward": 0.8952838778495789, "action": -0.9641295075416565}
{"mode": "train", "epochs": 2, "timestep": 3786, "ep_reward": 971.2374267578125, "reward": 0.8939014673233032, "action": -1.10105299949646}
{"mode": "train", "epochs": 2, "timestep": 3787, "ep_reward": 972.1150512695312, "reward": 0.87760329246521, "action": -1.0333234071731567}
{"mode": "train", "epochs": 2, "timestep": 3788, "ep_reward": 972.9601440429688, "reward": 0.845095694065094, "action": -0.41757678985595703}
{"mode": "train", "epochs": 2, "timestep": 3789, "ep_reward": 973.7574462890625, "reward": 0.797279417514801, "action": -1.7048790454864502}
{"mode": "train", "epochs": 2, "timestep": 3790, "ep_reward": 974.466552734375, "reward": 0.7091243267059326, "action": -1.2040400505065918}
{"mode": "train", "epochs": 2, "timestep": 3791, "ep_reward": 975.0567016601562, "reward": 0.5901676416397095, "action": -1.0220327377319336}
{"mode": "train", "epochs": 2, "timestep": 3792, "ep_reward": 975.4895629882812, "reward": 0.4328917860984802, "action": -1.9733117818832397}
{"mode": "train", "epochs": 2, "timestep": 3793, "ep_reward": 975.7886962890625, "reward": 0.29912781715393066, "action": -0.3664405345916748}
{"mode": "train", "epochs": 2, "timestep": 3794, "ep_reward": 975.9679565429688, "reward": 0.1792689561843872, "action": -1.6351292133331299}
{"mode": "train", "epochs": 2, "timestep": 3795, "ep_reward": 976.007568359375, "reward": 0.03961539268493652, "action": -1.392734169960022}
{"mode": "train", "epochs": 2, "timestep": 3796, "ep_reward": 976.0858764648438, "reward": 0.07828199863433838, "action": -0.482474148273468}
{"mode": "train", "epochs": 2, "timestep": 3797, "ep_reward": 976.3082275390625, "reward": 0.2223750352859497, "action": -0.20482587814331055}
{"mode": "train", "epochs": 2, "timestep": 3798, "ep_reward": 976.6786499023438, "reward": 0.3704448938369751, "action": -0.5613774657249451}
{"mode": "train", "epochs": 2, "timestep": 3799, "ep_reward": 977.182861328125, "reward": 0.5042166709899902, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3800, "ep_reward": 977.7889404296875, "reward": 0.6060488820075989, "action": -1.0682843923568726}
{"mode": "train", "epochs": 2, "timestep": 3801, "ep_reward": 978.4882202148438, "reward": 0.6992862224578857, "action": -0.9587468504905701}
{"mode": "train", "epochs": 2, "timestep": 3802, "ep_reward": 979.2598266601562, "reward": 0.7715835571289062, "action": -1.5043237209320068}
{"mode": "train", "epochs": 2, "timestep": 3803, "ep_reward": 980.0784301757812, "reward": 0.8186218738555908, "action": -1.14126455783844}
{"mode": "train", "epochs": 2, "timestep": 3804, "ep_reward": 980.9292602539062, "reward": 0.8508057594299316, "action": -1.4531196355819702}
{"mode": "train", "epochs": 2, "timestep": 3805, "ep_reward": 981.7930908203125, "reward": 0.8638538122177124, "action": -0.6557604074478149}
{"mode": "train", "epochs": 2, "timestep": 3806, "ep_reward": 982.660400390625, "reward": 0.8673237562179565, "action": -0.9581556916236877}
{"mode": "train", "epochs": 2, "timestep": 3807, "ep_reward": 983.5115356445312, "reward": 0.8511542081832886, "action": -0.8346632122993469}
{"mode": "train", "epochs": 2, "timestep": 3808, "ep_reward": 984.3277587890625, "reward": 0.8162051439285278, "action": -1.052551507949829}
{"mode": "train", "epochs": 2, "timestep": 3809, "ep_reward": 985.08203125, "reward": 0.7542722225189209, "action": -0.8908913135528564}
{"mode": "train", "epochs": 2, "timestep": 3810, "ep_reward": 985.7444458007812, "reward": 0.6624187231063843, "action": -1.7369437217712402}
{"mode": "train", "epochs": 2, "timestep": 3811, "ep_reward": 986.2647705078125, "reward": 0.5203160643577576, "action": -0.4313015341758728}
{"mode": "train", "epochs": 2, "timestep": 3812, "ep_reward": 986.6339111328125, "reward": 0.36916935443878174, "action": -1.2527234554290771}
{"mode": "train", "epochs": 2, "timestep": 3813, "ep_reward": 986.8970947265625, "reward": 0.2631974220275879, "action": -0.2021835446357727}
{"mode": "train", "epochs": 2, "timestep": 3814, "ep_reward": 987.0341796875, "reward": 0.13710814714431763, "action": -0.6324211359024048}
{"mode": "train", "epochs": 2, "timestep": 3815, "ep_reward": 987.0252685546875, "reward": -0.008933782577514648, "action": -0.09384644031524658}
{"mode": "train", "epochs": 2, "timestep": 3816, "ep_reward": 987.1484985351562, "reward": 0.12322419881820679, "action": -0.8578857183456421}
{"mode": "train", "epochs": 2, "timestep": 3817, "ep_reward": 987.4124145507812, "reward": 0.2639121413230896, "action": -0.7627843618392944}
{"mode": "train", "epochs": 2, "timestep": 3818, "ep_reward": 987.8169555664062, "reward": 0.4045349359512329, "action": -0.8159040212631226}
{"mode": "train", "epochs": 2, "timestep": 3819, "ep_reward": 988.3501586914062, "reward": 0.5331823825836182, "action": -1.0121324062347412}
{"mode": "train", "epochs": 2, "timestep": 3820, "ep_reward": 988.9911499023438, "reward": 0.6409813761711121, "action": -0.9225468635559082}
{"mode": "train", "epochs": 2, "timestep": 3821, "ep_reward": 989.718994140625, "reward": 0.7278738617897034, "action": -0.7057141065597534}
{"mode": "train", "epochs": 2, "timestep": 3822, "ep_reward": 990.5136108398438, "reward": 0.794597327709198, "action": -1.2524946928024292}
{"mode": "train", "epochs": 2, "timestep": 3823, "ep_reward": 991.3502197265625, "reward": 0.836594820022583, "action": -1.0209702253341675}
{"mode": "train", "epochs": 2, "timestep": 3824, "ep_reward": 992.2136840820312, "reward": 0.8634859323501587, "action": -0.3272808790206909}
{"mode": "train", "epochs": 2, "timestep": 3825, "ep_reward": 993.0938720703125, "reward": 0.8802046775817871, "action": -0.9405387043952942}
{"mode": "train", "epochs": 2, "timestep": 3826, "ep_reward": 993.9708862304688, "reward": 0.877029538154602, "action": -0.8681692481040955}
{"mode": "train", "epochs": 2, "timestep": 3827, "ep_reward": 994.829345703125, "reward": 0.8584480285644531, "action": -0.8207424879074097}
{"mode": "train", "epochs": 2, "timestep": 3828, "ep_reward": 995.6505126953125, "reward": 0.8211799263954163, "action": -1.3467087745666504}
{"mode": "train", "epochs": 2, "timestep": 3829, "ep_reward": 996.4047241210938, "reward": 0.7542014122009277, "action": -0.6958017349243164}
{"mode": "train", "epochs": 2, "timestep": 3830, "ep_reward": 997.0675659179688, "reward": 0.6628262996673584, "action": -0.787131130695343}
{"mode": "train", "epochs": 2, "timestep": 3831, "ep_reward": 997.6011962890625, "reward": 0.5336265563964844, "action": -0.6423664093017578}
{"mode": "train", "epochs": 2, "timestep": 3832, "ep_reward": 997.9680786132812, "reward": 0.36686474084854126, "action": -1.2053430080413818}
{"mode": "train", "epochs": 2, "timestep": 3833, "ep_reward": 998.2246704101562, "reward": 0.2566074728965759, "action": -0.9093781113624573}
{"mode": "train", "epochs": 2, "timestep": 3834, "ep_reward": 998.3540649414062, "reward": 0.1293664574623108, "action": -1.2911920547485352}
{"mode": "train", "epochs": 2, "timestep": 3835, "ep_reward": 998.3379516601562, "reward": -0.016103029251098633, "action": -1.3799257278442383}
{"mode": "train", "epochs": 2, "timestep": 3836, "ep_reward": 998.4689331054688, "reward": 0.13096368312835693, "action": -0.5595014691352844}
{"mode": "train", "epochs": 2, "timestep": 3837, "ep_reward": 998.7445068359375, "reward": 0.27554434537887573, "action": -0.638261079788208}
{"mode": "train", "epochs": 2, "timestep": 3838, "ep_reward": 999.1610107421875, "reward": 0.41650307178497314, "action": -0.8792570233345032}
{"mode": "train", "epochs": 2, "timestep": 3839, "ep_reward": 999.70361328125, "reward": 0.5426003932952881, "action": -1.0276027917861938}
{"mode": "train", "epochs": 2, "timestep": 3840, "ep_reward": 1000.3521728515625, "reward": 0.6485636234283447, "action": -0.5966010689735413}
{"mode": "train", "epochs": 2, "timestep": 3841, "ep_reward": 1001.0889892578125, "reward": 0.7368395328521729, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3842, "ep_reward": 1001.8798217773438, "reward": 0.7908360958099365, "action": -0.9368284940719604}
{"mode": "train", "epochs": 2, "timestep": 3843, "ep_reward": 1002.7155151367188, "reward": 0.83571857213974, "action": -1.5012872219085693}
{"mode": "train", "epochs": 2, "timestep": 3844, "ep_reward": 1003.5740356445312, "reward": 0.8585028052330017, "action": 0.3404104709625244}
{"mode": "train", "epochs": 2, "timestep": 3845, "ep_reward": 1004.454345703125, "reward": 0.8802909255027771, "action": -1.5240646600723267}
{"mode": "train", "epochs": 2, "timestep": 3846, "ep_reward": 1005.3258666992188, "reward": 0.8715478777885437, "action": -1.5121934413909912}
{"mode": "train", "epochs": 2, "timestep": 3847, "ep_reward": 1006.1714477539062, "reward": 0.8455788493156433, "action": -1.0833427906036377}
{"mode": "train", "epochs": 2, "timestep": 3848, "ep_reward": 1006.9735107421875, "reward": 0.8020774126052856, "action": -1.0326114892959595}
{"mode": "train", "epochs": 2, "timestep": 3849, "ep_reward": 1007.7057495117188, "reward": 0.7322666645050049, "action": -1.0880764722824097}
{"mode": "train", "epochs": 2, "timestep": 3850, "ep_reward": 1008.3338012695312, "reward": 0.6280412673950195, "action": -0.1792415976524353}
{"mode": "train", "epochs": 2, "timestep": 3851, "ep_reward": 1008.8311157226562, "reward": 0.49730539321899414, "action": -1.1446194648742676}
{"mode": "train", "epochs": 2, "timestep": 3852, "ep_reward": 1009.1759643554688, "reward": 0.34485918283462524, "action": -0.39880692958831787}
{"mode": "train", "epochs": 2, "timestep": 3853, "ep_reward": 1009.40966796875, "reward": 0.23371922969818115, "action": -1.4465417861938477}
{"mode": "train", "epochs": 2, "timestep": 3854, "ep_reward": 1009.512451171875, "reward": 0.10279679298400879, "action": -0.7448472380638123}
{"mode": "train", "epochs": 2, "timestep": 3855, "ep_reward": 1009.5260620117188, "reward": 0.01363074779510498, "action": -1.1219604015350342}
{"mode": "train", "epochs": 2, "timestep": 3856, "ep_reward": 1009.682861328125, "reward": 0.1567942500114441, "action": -0.915656566619873}
{"mode": "train", "epochs": 2, "timestep": 3857, "ep_reward": 1009.9804077148438, "reward": 0.2975549101829529, "action": -0.6612750291824341}
{"mode": "train", "epochs": 2, "timestep": 3858, "ep_reward": 1010.4182739257812, "reward": 0.43784624338150024, "action": -0.8002191185951233}
{"mode": "train", "epochs": 2, "timestep": 3859, "ep_reward": 1010.98095703125, "reward": 0.5626553297042847, "action": -0.35453712940216064}
{"mode": "train", "epochs": 2, "timestep": 3860, "ep_reward": 1011.6525268554688, "reward": 0.6715840101242065, "action": -1.8646085262298584}
{"mode": "train", "epochs": 2, "timestep": 3861, "ep_reward": 1012.3954467773438, "reward": 0.7429014444351196, "action": -1.4269986152648926}
{"mode": "train", "epochs": 2, "timestep": 3862, "ep_reward": 1013.1940307617188, "reward": 0.7985808849334717, "action": -1.3113082647323608}
{"mode": "train", "epochs": 2, "timestep": 3863, "ep_reward": 1014.0302734375, "reward": 0.8362479209899902, "action": -1.1026713848114014}
{"mode": "train", "epochs": 2, "timestep": 3864, "ep_reward": 1014.8883666992188, "reward": 0.8580824136734009, "action": -1.3955081701278687}
{"mode": "train", "epochs": 2, "timestep": 3865, "ep_reward": 1015.7490844726562, "reward": 0.8607423305511475, "action": -0.7318145036697388}
{"mode": "train", "epochs": 2, "timestep": 3866, "ep_reward": 1016.6005859375, "reward": 0.8514842391014099, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3867, "ep_reward": 1017.4108276367188, "reward": 0.8102669715881348, "action": -1.2194769382476807}
{"mode": "train", "epochs": 2, "timestep": 3868, "ep_reward": 1018.1608276367188, "reward": 0.749975323677063, "action": -0.8730799555778503}
{"mode": "train", "epochs": 2, "timestep": 3869, "ep_reward": 1018.8218383789062, "reward": 0.661036491394043, "action": -1.2886556386947632}
{"mode": "train", "epochs": 2, "timestep": 3870, "ep_reward": 1019.34912109375, "reward": 0.5272877216339111, "action": -1.1305962800979614}
{"mode": "train", "epochs": 2, "timestep": 3871, "ep_reward": 1019.7298583984375, "reward": 0.38072627782821655, "action": -1.5109968185424805}
{"mode": "train", "epochs": 2, "timestep": 3872, "ep_reward": 1020.007080078125, "reward": 0.2772475481033325, "action": 0.06619465351104736}
{"mode": "train", "epochs": 2, "timestep": 3873, "ep_reward": 1020.1607055664062, "reward": 0.1536271572113037, "action": -0.052431344985961914}
{"mode": "train", "epochs": 2, "timestep": 3874, "ep_reward": 1020.1704711914062, "reward": 0.009792923927307129, "action": -1.8523619174957275}
{"mode": "train", "epochs": 2, "timestep": 3875, "ep_reward": 1020.2766723632812, "reward": 0.10620242357254028, "action": -0.6558903455734253}
{"mode": "train", "epochs": 2, "timestep": 3876, "ep_reward": 1020.5255737304688, "reward": 0.24890631437301636, "action": -0.9754158854484558}
{"mode": "train", "epochs": 2, "timestep": 3877, "ep_reward": 1020.9127807617188, "reward": 0.38717949390411377, "action": -0.587536096572876}
{"mode": "train", "epochs": 2, "timestep": 3878, "ep_reward": 1021.4330444335938, "reward": 0.5202717781066895, "action": -1.506467580795288}
{"mode": "train", "epochs": 2, "timestep": 3879, "ep_reward": 1022.0580444335938, "reward": 0.6249759793281555, "action": -1.4136581420898438}
{"mode": "train", "epochs": 2, "timestep": 3880, "ep_reward": 1022.7684936523438, "reward": 0.7104203701019287, "action": -1.302847146987915}
{"mode": "train", "epochs": 2, "timestep": 3881, "ep_reward": 1023.5438842773438, "reward": 0.7753947973251343, "action": -1.4918041229248047}
{"mode": "train", "epochs": 2, "timestep": 3882, "ep_reward": 1024.3621826171875, "reward": 0.8183213472366333, "action": -0.6264137029647827}
{"mode": "train", "epochs": 2, "timestep": 3883, "ep_reward": 1025.212158203125, "reward": 0.8500145673751831, "action": -1.2159645557403564}
{"mode": "train", "epochs": 2, "timestep": 3884, "ep_reward": 1026.0711669921875, "reward": 0.8589759469032288, "action": -0.997532844543457}
{"mode": "train", "epochs": 2, "timestep": 3885, "ep_reward": 1026.9234619140625, "reward": 0.8522667288780212, "action": -1.5386319160461426}
{"mode": "train", "epochs": 2, "timestep": 3886, "ep_reward": 1027.744384765625, "reward": 0.8209165930747986, "action": -0.7389911413192749}
{"mode": "train", "epochs": 2, "timestep": 3887, "ep_reward": 1028.5174560546875, "reward": 0.7730719447135925, "action": -1.216782569885254}
{"mode": "train", "epochs": 2, "timestep": 3888, "ep_reward": 1029.20751953125, "reward": 0.6901161074638367, "action": -0.3028823137283325}
{"mode": "train", "epochs": 2, "timestep": 3889, "ep_reward": 1029.78955078125, "reward": 0.5820481181144714, "action": -1.1077388525009155}
{"mode": "train", "epochs": 2, "timestep": 3890, "ep_reward": 1030.211669921875, "reward": 0.4221741557121277, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3891, "ep_reward": 1030.521484375, "reward": 0.3098236322402954, "action": -0.6420189142227173}
{"mode": "train", "epochs": 2, "timestep": 3892, "ep_reward": 1030.7135009765625, "reward": 0.19198310375213623, "action": -1.4804760217666626}
{"mode": "train", "epochs": 2, "timestep": 3893, "ep_reward": 1030.767822265625, "reward": 0.0543217658996582, "action": -1.0552335977554321}
{"mode": "train", "epochs": 2, "timestep": 3894, "ep_reward": 1030.831787109375, "reward": 0.06391924619674683, "action": -0.848558783531189}
{"mode": "train", "epochs": 2, "timestep": 3895, "ep_reward": 1031.03466796875, "reward": 0.20291495323181152, "action": -1.2975143194198608}
{"mode": "train", "epochs": 2, "timestep": 3896, "ep_reward": 1031.3736572265625, "reward": 0.3389962911605835, "action": -1.353731393814087}
{"mode": "train", "epochs": 2, "timestep": 3897, "ep_reward": 1031.8424072265625, "reward": 0.46878159046173096, "action": -0.5818966031074524}
{"mode": "train", "epochs": 2, "timestep": 3898, "ep_reward": 1032.4345703125, "reward": 0.5921489000320435, "action": -1.645604133605957}
{"mode": "train", "epochs": 2, "timestep": 3899, "ep_reward": 1033.1163330078125, "reward": 0.6817951202392578, "action": -1.2139676809310913}
{"mode": "train", "epochs": 2, "timestep": 3900, "ep_reward": 1033.8702392578125, "reward": 0.7539564371109009, "action": -0.43716365098953247}
{"mode": "train", "epochs": 2, "timestep": 3901, "ep_reward": 1034.6812744140625, "reward": 0.8110086917877197, "action": -1.6916340589523315}
{"mode": "train", "epochs": 2, "timestep": 3902, "ep_reward": 1035.5177001953125, "reward": 0.8363679647445679, "action": -1.502788782119751}
{"mode": "train", "epochs": 2, "timestep": 3903, "ep_reward": 1036.3626708984375, "reward": 0.8449527025222778, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3904, "ep_reward": 1037.1923828125, "reward": 0.829670250415802, "action": -1.1651630401611328}
{"mode": "train", "epochs": 2, "timestep": 3905, "ep_reward": 1037.991943359375, "reward": 0.7996054887771606, "action": -1.4871001243591309}
{"mode": "train", "epochs": 2, "timestep": 3906, "ep_reward": 1038.7305908203125, "reward": 0.7386424541473389, "action": -1.184247374534607}
{"mode": "train", "epochs": 2, "timestep": 3907, "ep_reward": 1039.376708984375, "reward": 0.6461744904518127, "action": -1.9285527467727661}
{"mode": "train", "epochs": 2, "timestep": 3908, "ep_reward": 1039.8773193359375, "reward": 0.5006231665611267, "action": -0.5556385517120361}
{"mode": "train", "epochs": 2, "timestep": 3909, "ep_reward": 1040.26171875, "reward": 0.38441193103790283, "action": -1.6253373622894287}
{"mode": "train", "epochs": 2, "timestep": 3910, "ep_reward": 1040.5433349609375, "reward": 0.28167492151260376, "action": -1.106289029121399}
{"mode": "train", "epochs": 2, "timestep": 3911, "ep_reward": 1040.7021484375, "reward": 0.15884649753570557, "action": -1.1305426359176636}
{"mode": "train", "epochs": 2, "timestep": 3912, "ep_reward": 1040.7181396484375, "reward": 0.01602005958557129, "action": -1.1445921659469604}
{"mode": "train", "epochs": 2, "timestep": 3913, "ep_reward": 1040.8187255859375, "reward": 0.10053855180740356, "action": -1.1664464473724365}
{"mode": "train", "epochs": 2, "timestep": 3914, "ep_reward": 1041.0555419921875, "reward": 0.23679685592651367, "action": -0.1493443250656128}
{"mode": "train", "epochs": 2, "timestep": 3915, "ep_reward": 1041.442138671875, "reward": 0.3866329789161682, "action": -0.1534712314605713}
{"mode": "train", "epochs": 2, "timestep": 3916, "ep_reward": 1041.96630859375, "reward": 0.5241822004318237, "action": -1.995755672454834}
{"mode": "train", "epochs": 2, "timestep": 3917, "ep_reward": 1042.58935546875, "reward": 0.62306809425354, "action": -1.0259019136428833}
{"mode": "train", "epochs": 2, "timestep": 3918, "ep_reward": 1043.3023681640625, "reward": 0.7130097150802612, "action": -0.6766330003738403}
{"mode": "train", "epochs": 2, "timestep": 3919, "ep_reward": 1044.08642578125, "reward": 0.7840657234191895, "action": -1.0676326751708984}
{"mode": "train", "epochs": 2, "timestep": 3920, "ep_reward": 1044.91748046875, "reward": 0.8310438394546509, "action": -1.0492172241210938}
{"mode": "train", "epochs": 2, "timestep": 3921, "ep_reward": 1045.778076171875, "reward": 0.8605616688728333, "action": -1.2770841121673584}
{"mode": "train", "epochs": 2, "timestep": 3922, "ep_reward": 1046.6505126953125, "reward": 0.8724541664123535, "action": -1.0321691036224365}
{"mode": "train", "epochs": 2, "timestep": 3923, "ep_reward": 1047.5213623046875, "reward": 0.870800256729126, "action": -1.4686068296432495}
{"mode": "train", "epochs": 2, "timestep": 3924, "ep_reward": 1048.3697509765625, "reward": 0.8484489917755127, "action": -1.1123982667922974}
{"mode": "train", "epochs": 2, "timestep": 3925, "ep_reward": 1049.1781005859375, "reward": 0.808362603187561, "action": -1.4742317199707031}
{"mode": "train", "epochs": 2, "timestep": 3926, "ep_reward": 1049.916015625, "reward": 0.7378689646720886, "action": -1.5833830833435059}
{"mode": "train", "epochs": 2, "timestep": 3927, "ep_reward": 1050.5469970703125, "reward": 0.6309831142425537, "action": -0.8505638241767883}
{"mode": "train", "epochs": 2, "timestep": 3928, "ep_reward": 1051.0391845703125, "reward": 0.4921746850013733, "action": -1.490308403968811}
{"mode": "train", "epochs": 2, "timestep": 3929, "ep_reward": 1051.3934326171875, "reward": 0.35430145263671875, "action": -0.724148154258728}
{"mode": "train", "epochs": 2, "timestep": 3930, "ep_reward": 1051.6385498046875, "reward": 0.24516648054122925, "action": -0.8024672865867615}
{"mode": "train", "epochs": 2, "timestep": 3931, "ep_reward": 1051.7545166015625, "reward": 0.11602634191513062, "action": -0.9250380992889404}
{"mode": "train", "epochs": 2, "timestep": 3932, "ep_reward": 1051.75341796875, "reward": -0.0010384321212768555, "action": -1.6704745292663574}
{"mode": "train", "epochs": 2, "timestep": 3933, "ep_reward": 1051.8975830078125, "reward": 0.14411205053329468, "action": -0.9188544154167175}
{"mode": "train", "epochs": 2, "timestep": 3934, "ep_reward": 1052.181884765625, "reward": 0.2843455672264099, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3935, "ep_reward": 1052.5911865234375, "reward": 0.4092905521392822, "action": -0.3381456136703491}
{"mode": "train", "epochs": 2, "timestep": 3936, "ep_reward": 1053.13525390625, "reward": 0.5441268086433411, "action": -0.8875880837440491}
{"mode": "train", "epochs": 2, "timestep": 3937, "ep_reward": 1053.7864990234375, "reward": 0.6512222290039062, "action": -1.1254085302352905}
{"mode": "train", "epochs": 2, "timestep": 3938, "ep_reward": 1054.51953125, "reward": 0.7329893112182617, "action": -0.8420295715332031}
{"mode": "train", "epochs": 2, "timestep": 3939, "ep_reward": 1055.314697265625, "reward": 0.7951826453208923, "action": -0.9860436916351318}
{"mode": "train", "epochs": 2, "timestep": 3940, "ep_reward": 1056.1502685546875, "reward": 0.8355595469474792, "action": -1.0387134552001953}
{"mode": "train", "epochs": 2, "timestep": 3941, "ep_reward": 1057.0076904296875, "reward": 0.8574329614639282, "action": -0.88336580991745}
{"mode": "train", "epochs": 2, "timestep": 3942, "ep_reward": 1057.8714599609375, "reward": 0.8637129068374634, "action": -1.1436326503753662}
{"mode": "train", "epochs": 2, "timestep": 3943, "ep_reward": 1058.7218017578125, "reward": 0.850352942943573, "action": -1.4285719394683838}
{"mode": "train", "epochs": 2, "timestep": 3944, "ep_reward": 1059.535888671875, "reward": 0.8140922784805298, "action": -0.693508505821228}
{"mode": "train", "epochs": 2, "timestep": 3945, "ep_reward": 1060.2958984375, "reward": 0.7599632143974304, "action": -1.1114239692687988}
{"mode": "train", "epochs": 2, "timestep": 3946, "ep_reward": 1060.9659423828125, "reward": 0.670067548751831, "action": -1.715648889541626}
{"mode": "train", "epochs": 2, "timestep": 3947, "ep_reward": 1061.49853515625, "reward": 0.5325602293014526, "action": -0.9708310961723328}
{"mode": "train", "epochs": 2, "timestep": 3948, "ep_reward": 1061.8812255859375, "reward": 0.38275134563446045, "action": -0.9884898662567139}
{"mode": "train", "epochs": 2, "timestep": 3949, "ep_reward": 1062.16064453125, "reward": 0.2794579267501831, "action": -1.5465996265411377}
{"mode": "train", "epochs": 2, "timestep": 3950, "ep_reward": 1062.31689453125, "reward": 0.15630710124969482, "action": -1.2384824752807617}
{"mode": "train", "epochs": 2, "timestep": 3951, "ep_reward": 1062.3299560546875, "reward": 0.013086676597595215, "action": -1.3412846326828003}
{"mode": "train", "epochs": 2, "timestep": 3952, "ep_reward": 1062.4332275390625, "reward": 0.10321986675262451, "action": -1.1408679485321045}
{"mode": "train", "epochs": 2, "timestep": 3953, "ep_reward": 1062.673095703125, "reward": 0.23987847566604614, "action": 0.05739474296569824}
{"mode": "train", "epochs": 2, "timestep": 3954, "ep_reward": 1063.06494140625, "reward": 0.3919064998626709, "action": -1.3517429828643799}
{"mode": "train", "epochs": 2, "timestep": 3955, "ep_reward": 1063.580078125, "reward": 0.5151227712631226, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3956, "ep_reward": 1064.195556640625, "reward": 0.6154584884643555, "action": -1.194625735282898}
{"mode": "train", "epochs": 2, "timestep": 3957, "ep_reward": 1064.9002685546875, "reward": 0.704762876033783, "action": -0.519309937953949}
{"mode": "train", "epochs": 2, "timestep": 3958, "ep_reward": 1065.6781005859375, "reward": 0.7777903079986572, "action": -1.1965327262878418}
{"mode": "train", "epochs": 2, "timestep": 3959, "ep_reward": 1066.5009765625, "reward": 0.8228984475135803, "action": -0.73102867603302}
{"mode": "train", "epochs": 2, "timestep": 3960, "ep_reward": 1067.3543701171875, "reward": 0.8533391952514648, "action": -1.2353050708770752}
{"mode": "train", "epochs": 2, "timestep": 3961, "ep_reward": 1068.2166748046875, "reward": 0.8623572587966919, "action": -0.8597822785377502}
{"mode": "train", "epochs": 2, "timestep": 3962, "ep_reward": 1069.07421875, "reward": 0.8575780987739563, "action": -1.1690433025360107}
{"mode": "train", "epochs": 2, "timestep": 3963, "ep_reward": 1069.905517578125, "reward": 0.8312826156616211, "action": -0.8538831472396851}
{"mode": "train", "epochs": 2, "timestep": 3964, "ep_reward": 1070.6907958984375, "reward": 0.7852352857589722, "action": -0.46264421939849854}
{"mode": "train", "epochs": 2, "timestep": 3965, "ep_reward": 1071.406494140625, "reward": 0.7156435251235962, "action": -1.3240584135055542}
{"mode": "train", "epochs": 2, "timestep": 3966, "ep_reward": 1072.0076904296875, "reward": 0.6012102961540222, "action": -1.1727057695388794}
{"mode": "train", "epochs": 2, "timestep": 3967, "ep_reward": 1072.4542236328125, "reward": 0.446547269821167, "action": -0.5847150087356567}
{"mode": "train", "epochs": 2, "timestep": 3968, "ep_reward": 1072.7779541015625, "reward": 0.3236997723579407, "action": -1.1591346263885498}
{"mode": "train", "epochs": 2, "timestep": 3969, "ep_reward": 1072.986572265625, "reward": 0.20861965417861938, "action": -0.924304723739624}
{"mode": "train", "epochs": 2, "timestep": 3970, "ep_reward": 1073.0599365234375, "reward": 0.07332170009613037, "action": -1.9649162292480469}
{"mode": "train", "epochs": 2, "timestep": 3971, "ep_reward": 1073.1043701171875, "reward": 0.04440957307815552, "action": -1.8354673385620117}
{"mode": "train", "epochs": 2, "timestep": 3972, "ep_reward": 1073.2879638671875, "reward": 0.18363559246063232, "action": -0.6944068670272827}
{"mode": "train", "epochs": 2, "timestep": 3973, "ep_reward": 1073.615478515625, "reward": 0.3275490999221802, "action": -0.9169850945472717}
{"mode": "train", "epochs": 2, "timestep": 3974, "ep_reward": 1074.078125, "reward": 0.4625900983810425, "action": -1.0398584604263306}
{"mode": "train", "epochs": 2, "timestep": 3975, "ep_reward": 1074.6595458984375, "reward": 0.5813765525817871, "action": -1.3554688692092896}
{"mode": "train", "epochs": 2, "timestep": 3976, "ep_reward": 1075.3360595703125, "reward": 0.6764678955078125, "action": -1.4502487182617188}
{"mode": "train", "epochs": 2, "timestep": 3977, "ep_reward": 1076.0848388671875, "reward": 0.7487863302230835, "action": -1.9992197751998901}
{"mode": "train", "epochs": 2, "timestep": 3978, "ep_reward": 1076.8800048828125, "reward": 0.7951720952987671, "action": -0.8872721195220947}
{"mode": "train", "epochs": 2, "timestep": 3979, "ep_reward": 1077.7120361328125, "reward": 0.8320318460464478, "action": -1.4658087491989136}
{"mode": "train", "epochs": 2, "timestep": 3980, "ep_reward": 1078.5567626953125, "reward": 0.844741702079773, "action": -0.4480794072151184}
{"mode": "train", "epochs": 2, "timestep": 3981, "ep_reward": 1079.40478515625, "reward": 0.847993016242981, "action": -0.40303850173950195}
{"mode": "train", "epochs": 2, "timestep": 3982, "ep_reward": 1080.237060546875, "reward": 0.8322714567184448, "action": -1.1616899967193604}
{"mode": "train", "epochs": 2, "timestep": 3983, "ep_reward": 1081.02392578125, "reward": 0.786874532699585, "action": -0.7537940740585327}
{"mode": "train", "epochs": 2, "timestep": 3984, "ep_reward": 1081.7413330078125, "reward": 0.717466413974762, "action": -1.1559946537017822}
{"mode": "train", "epochs": 2, "timestep": 3985, "ep_reward": 1082.349609375, "reward": 0.6082586050033569, "action": -1.1696137189865112}
{"mode": "train", "epochs": 2, "timestep": 3986, "ep_reward": 1082.8062744140625, "reward": 0.4567248225212097, "action": -0.8661757111549377}
{"mode": "train", "epochs": 2, "timestep": 3987, "ep_reward": 1083.141845703125, "reward": 0.3355828523635864, "action": -0.5072115659713745}
{"mode": "train", "epochs": 2, "timestep": 3988, "ep_reward": 1083.364501953125, "reward": 0.22271031141281128, "action": -0.8999578952789307}
{"mode": "train", "epochs": 2, "timestep": 3989, "ep_reward": 1083.4542236328125, "reward": 0.08972394466400146, "action": -1.7869548797607422}
{"mode": "train", "epochs": 2, "timestep": 3990, "ep_reward": 1083.481689453125, "reward": 0.027480781078338623, "action": -1.0834707021713257}
{"mode": "train", "epochs": 2, "timestep": 3991, "ep_reward": 1083.6505126953125, "reward": 0.16876304149627686, "action": -1.323281168937683}
{"mode": "train", "epochs": 2, "timestep": 3992, "ep_reward": 1083.955078125, "reward": 0.30458182096481323, "action": -1.537805199623108}
{"mode": "train", "epochs": 2, "timestep": 3993, "ep_reward": 1084.3897705078125, "reward": 0.43471211194992065, "action": -0.8228362798690796}
{"mode": "train", "epochs": 2, "timestep": 3994, "ep_reward": 1084.950439453125, "reward": 0.5606461763381958, "action": -0.8588334321975708}
{"mode": "train", "epochs": 2, "timestep": 3995, "ep_reward": 1085.615234375, "reward": 0.6647642850875854, "action": -0.5992919206619263}
{"mode": "train", "epochs": 2, "timestep": 3996, "ep_reward": 1086.3629150390625, "reward": 0.747623085975647, "action": -1.2034642696380615}
{"mode": "train", "epochs": 2, "timestep": 3997, "ep_reward": 1087.1646728515625, "reward": 0.8017057180404663, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3998, "ep_reward": 1087.993896484375, "reward": 0.8291960954666138, "action": -0.8099188804626465}
{"mode": "train", "epochs": 2, "timestep": 3999, "ep_reward": 1088.8427734375, "reward": 0.8489357233047485, "action": -0.5683844089508057}
{"mode": "train", "epochs": 2, "timestep": 4000, "ep_reward": 1089.6953125, "reward": 0.852492094039917, "action": -0.6388770937919617}
{"mode": "train", "epochs": 3, "timestep": 4001, "ep_reward": 0.9997752904891968, "reward": 0.9997752904891968, "action": 0.897407054901123}
{"mode": "train", "epochs": 3, "timestep": 4002, "ep_reward": 1.999377727508545, "reward": 0.9996024370193481, "action": 1.4289929866790771}
{"mode": "train", "epochs": 3, "timestep": 4003, "ep_reward": 2.998572826385498, "reward": 0.9991949796676636, "action": 0.48111259937286377}
{"mode": "train", "epochs": 3, "timestep": 4004, "ep_reward": 3.9974277019500732, "reward": 0.99885493516922, "action": 1.4347937107086182}
{"mode": "train", "epochs": 3, "timestep": 4005, "ep_reward": 4.994893550872803, "reward": 0.9974657297134399, "action": 1.3330368995666504}
{"mode": "train", "epochs": 3, "timestep": 4006, "ep_reward": 5.99006462097168, "reward": 0.995171070098877, "action": 1.5053632259368896}
{"mode": "train", "epochs": 3, "timestep": 4007, "ep_reward": 6.981235504150391, "reward": 0.9911709427833557, "action": 1.0153099298477173}
{"mode": "train", "epochs": 3, "timestep": 4008, "ep_reward": 7.967258930206299, "reward": 0.9860234260559082, "action": 0.78473961353302}
{"mode": "train", "epochs": 3, "timestep": 4009, "ep_reward": 8.945887565612793, "reward": 0.9786282777786255, "action": 1.614027738571167}
{"mode": "train", "epochs": 3, "timestep": 4010, "ep_reward": 9.910152435302734, "reward": 0.964264988899231, "action": 0.3850187063217163}
{"mode": "train", "epochs": 3, "timestep": 4011, "ep_reward": 10.858409881591797, "reward": 0.9482574462890625, "action": 0.9868419766426086}
{"mode": "train", "epochs": 3, "timestep": 4012, "ep_reward": 11.779438972473145, "reward": 0.9210294485092163, "action": 0.9306548833847046}
{"mode": "train", "epochs": 3, "timestep": 4013, "ep_reward": 12.6608304977417, "reward": 0.8813915252685547, "action": 0.6743831634521484}
{"mode": "train", "epochs": 3, "timestep": 4014, "ep_reward": 13.487252235412598, "reward": 0.8264217972755432, "action": -0.29261526465415955}
{"mode": "train", "epochs": 3, "timestep": 4015, "ep_reward": 14.246377944946289, "reward": 0.7591257095336914, "action": -0.9016863703727722}
{"mode": "train", "epochs": 3, "timestep": 4016, "ep_reward": 14.922499656677246, "reward": 0.6761220693588257, "action": -0.15204328298568726}
{"mode": "train", "epochs": 3, "timestep": 4017, "ep_reward": 15.483274459838867, "reward": 0.5607750415802002, "action": -0.18596196174621582}
{"mode": "train", "epochs": 3, "timestep": 4018, "ep_reward": 15.903794288635254, "reward": 0.4205198287963867, "action": -0.7667050957679749}
{"mode": "train", "epochs": 3, "timestep": 4019, "ep_reward": 16.173450469970703, "reward": 0.2696567177772522, "action": -1.3890385627746582}
{"mode": "train", "epochs": 3, "timestep": 4020, "ep_reward": 16.295785903930664, "reward": 0.12233632802963257, "action": -1.162647008895874}
{"mode": "train", "epochs": 3, "timestep": 4021, "ep_reward": 16.38332176208496, "reward": 0.08753633499145508, "action": -0.8321120142936707}
{"mode": "train", "epochs": 3, "timestep": 4022, "ep_reward": 16.6196346282959, "reward": 0.23631346225738525, "action": -1.2079436779022217}
{"mode": "train", "epochs": 3, "timestep": 4023, "ep_reward": 17.006765365600586, "reward": 0.38713133335113525, "action": -1.255368947982788}
{"mode": "train", "epochs": 3, "timestep": 4024, "ep_reward": 17.533008575439453, "reward": 0.5262426733970642, "action": -1.9467957019805908}
{"mode": "train", "epochs": 3, "timestep": 4025, "ep_reward": 18.18450927734375, "reward": 0.6515010595321655, "action": -1.310420036315918}
{"mode": "train", "epochs": 3, "timestep": 4026, "ep_reward": 18.93079948425293, "reward": 0.7462909817695618, "action": -0.058859050273895264}
{"mode": "train", "epochs": 3, "timestep": 4027, "ep_reward": 19.741989135742188, "reward": 0.8111891150474548, "action": 2.0}
{"mode": "train", "epochs": 3, "timestep": 4028, "ep_reward": 20.59379005432129, "reward": 0.8518016338348389, "action": 0.15257799625396729}
{"mode": "train", "epochs": 3, "timestep": 4029, "ep_reward": 21.483356475830078, "reward": 0.8895654678344727, "action": 0.41541796922683716}
{"mode": "train", "epochs": 3, "timestep": 4030, "ep_reward": 22.397897720336914, "reward": 0.9145419597625732, "action": 0.9831980466842651}
{"mode": "train", "epochs": 3, "timestep": 4031, "ep_reward": 23.327392578125, "reward": 0.9294941425323486, "action": 1.0144883394241333}
{"mode": "train", "epochs": 3, "timestep": 4032, "ep_reward": 24.26516342163086, "reward": 0.9377701878547668, "action": 1.2443480491638184}
{"mode": "train", "epochs": 3, "timestep": 4033, "ep_reward": 25.205547332763672, "reward": 0.9403842687606812, "action": 1.2178683280944824}
{"mode": "train", "epochs": 3, "timestep": 4034, "ep_reward": 26.14354133605957, "reward": 0.937994658946991, "action": -0.47521695494651794}
{"mode": "train", "epochs": 3, "timestep": 4035, "ep_reward": 27.069290161132812, "reward": 0.9257494211196899, "action": -0.38589638471603394}
{"mode": "train", "epochs": 3, "timestep": 4036, "ep_reward": 27.971229553222656, "reward": 0.9019388556480408, "action": -1.3354160785675049}
{"mode": "train", "epochs": 3, "timestep": 4037, "ep_reward": 28.8301944732666, "reward": 0.8589656352996826, "action": -0.7880324125289917}
{"mode": "train", "epochs": 3, "timestep": 4038, "ep_reward": 29.629043579101562, "reward": 0.7988486289978027, "action": -0.8102659583091736}
{"mode": "train", "epochs": 3, "timestep": 4039, "ep_reward": 30.345006942749023, "reward": 0.7159634828567505, "action": -0.2529897689819336}
{"mode": "train", "epochs": 3, "timestep": 4040, "ep_reward": 30.958654403686523, "reward": 0.6136482954025269, "action": -1.08782160282135}
{"mode": "train", "epochs": 3, "timestep": 4041, "ep_reward": 31.436016082763672, "reward": 0.47736090421676636, "action": -0.22562330961227417}
{"mode": "train", "epochs": 3, "timestep": 4042, "ep_reward": 31.765714645385742, "reward": 0.329697847366333, "action": -0.4865163564682007}
{"mode": "train", "epochs": 3, "timestep": 4043, "ep_reward": 31.931964874267578, "reward": 0.16625094413757324, "action": -1.4673845767974854}
{"mode": "train", "epochs": 3, "timestep": 4044, "ep_reward": 32.006038665771484, "reward": 0.07407242059707642, "action": -1.066544532775879}
{"mode": "train", "epochs": 3, "timestep": 4045, "ep_reward": 32.20771789550781, "reward": 0.20167815685272217, "action": -0.8471280932426453}
{"mode": "train", "epochs": 3, "timestep": 4046, "ep_reward": 32.54413986206055, "reward": 0.3364229202270508, "action": -0.2967134118080139}
{"mode": "train", "epochs": 3, "timestep": 4047, "ep_reward": 33.01725387573242, "reward": 0.47311311960220337, "action": 0.04290199279785156}
{"mode": "train", "epochs": 3, "timestep": 4048, "ep_reward": 33.615997314453125, "reward": 0.5987420678138733, "action": -0.4179679751396179}
{"mode": "train", "epochs": 3, "timestep": 4049, "ep_reward": 34.31509780883789, "reward": 0.6990995407104492, "action": -1.6071276664733887}
{"mode": "train", "epochs": 3, "timestep": 4050, "ep_reward": 35.08454895019531, "reward": 0.7694494128227234, "action": -0.7381303310394287}
{"mode": "train", "epochs": 3, "timestep": 4051, "ep_reward": 35.91427230834961, "reward": 0.8297233581542969, "action": -0.8526279926300049}
{"mode": "train", "epochs": 3, "timestep": 4052, "ep_reward": 36.7872200012207, "reward": 0.8729471564292908, "action": -0.9894342422485352}
{"mode": "train", "epochs": 3, "timestep": 4053, "ep_reward": 37.68948745727539, "reward": 0.9022672176361084, "action": -0.4128463864326477}
{"mode": "train", "epochs": 3, "timestep": 4054, "ep_reward": 38.6138801574707, "reward": 0.9243916869163513, "action": -0.9592081308364868}
{"mode": "train", "epochs": 3, "timestep": 4055, "ep_reward": 39.548194885253906, "reward": 0.9343149065971375, "action": -1.3471958637237549}
{"mode": "train", "epochs": 3, "timestep": 4056, "ep_reward": 40.4824104309082, "reward": 0.9342142939567566, "action": -0.9270885586738586}
{"mode": "train", "epochs": 3, "timestep": 4057, "ep_reward": 41.41068649291992, "reward": 0.9282745122909546, "action": 0.2613641023635864}
{"mode": "train", "epochs": 3, "timestep": 4058, "ep_reward": 42.33138656616211, "reward": 0.9207018613815308, "action": -0.7566952109336853}
{"mode": "train", "epochs": 3, "timestep": 4059, "ep_reward": 43.22716522216797, "reward": 0.8957788348197937, "action": -1.0093687772750854}
{"mode": "train", "epochs": 3, "timestep": 4060, "ep_reward": 44.08119583129883, "reward": 0.8540308475494385, "action": -0.4304683804512024}
{"mode": "train", "epochs": 3, "timestep": 4061, "ep_reward": 44.87839126586914, "reward": 0.7971958518028259, "action": -1.4691963195800781}
{"mode": "train", "epochs": 3, "timestep": 4062, "ep_reward": 45.5822868347168, "reward": 0.7038970589637756, "action": -1.3272767066955566}
{"mode": "train", "epochs": 3, "timestep": 4063, "ep_reward": 46.1591682434082, "reward": 0.5768805742263794, "action": -1.8123730421066284}
{"mode": "train", "epochs": 3, "timestep": 4064, "ep_reward": 46.56245803833008, "reward": 0.4032915234565735, "action": -1.0723825693130493}
{"mode": "train", "epochs": 3, "timestep": 4065, "ep_reward": 46.81880187988281, "reward": 0.2563452124595642, "action": -0.34031981229782104}
{"mode": "train", "epochs": 3, "timestep": 4066, "ep_reward": 46.9478759765625, "reward": 0.12907451391220093, "action": -0.7483259439468384}
{"mode": "train", "epochs": 3, "timestep": 4067, "ep_reward": 46.93229293823242, "reward": -0.015581369400024414, "action": 0.45282280445098877}
{"mode": "train", "epochs": 3, "timestep": 4068, "ep_reward": 47.06939697265625, "reward": 0.13710474967956543, "action": -0.842101514339447}
{"mode": "train", "epochs": 3, "timestep": 4069, "ep_reward": 47.346351623535156, "reward": 0.27695542573928833, "action": -1.0135539770126343}
{"mode": "train", "epochs": 3, "timestep": 4070, "ep_reward": 47.75941848754883, "reward": 0.4130682349205017, "action": -0.1767197847366333}
{"mode": "train", "epochs": 3, "timestep": 4071, "ep_reward": 48.307029724121094, "reward": 0.5476129055023193, "action": -0.3866403102874756}
{"mode": "train", "epochs": 3, "timestep": 4072, "ep_reward": 48.96609115600586, "reward": 0.6590626239776611, "action": -0.7398901581764221}
{"mode": "train", "epochs": 3, "timestep": 4073, "ep_reward": 49.71046447753906, "reward": 0.7443751096725464, "action": -1.1640625}
{"mode": "train", "epochs": 3, "timestep": 4074, "ep_reward": 50.515628814697266, "reward": 0.8051638603210449, "action": -0.4962065815925598}
{"mode": "train", "epochs": 3, "timestep": 4075, "ep_reward": 51.36871337890625, "reward": 0.8530864715576172, "action": -1.4145920276641846}
{"mode": "train", "epochs": 3, "timestep": 4076, "ep_reward": 52.24686813354492, "reward": 0.8781534433364868, "action": -0.4936688542366028}
{"mode": "train", "epochs": 3, "timestep": 4077, "ep_reward": 53.14331817626953, "reward": 0.8964508771896362, "action": -1.75681471824646}
{"mode": "train", "epochs": 3, "timestep": 4078, "ep_reward": 54.03602600097656, "reward": 0.892708957195282, "action": -1.8713462352752686}
{"mode": "train", "epochs": 3, "timestep": 4079, "ep_reward": 54.909767150878906, "reward": 0.8737429976463318, "action": -1.8656353950500488}
{"mode": "train", "epochs": 3, "timestep": 4080, "ep_reward": 55.74632263183594, "reward": 0.8365554809570312, "action": -1.3127071857452393}
{"mode": "train", "epochs": 3, "timestep": 4081, "ep_reward": 56.527069091796875, "reward": 0.7807464003562927, "action": -1.6074471473693848}
{"mode": "train", "epochs": 3, "timestep": 4082, "ep_reward": 57.218441009521484, "reward": 0.6913708448410034, "action": -1.1428718566894531}
{"mode": "train", "epochs": 3, "timestep": 4083, "ep_reward": 57.787803649902344, "reward": 0.5693634748458862, "action": -1.390753984451294}
{"mode": "train", "epochs": 3, "timestep": 4084, "ep_reward": 58.18867492675781, "reward": 0.4008721113204956, "action": -0.8766372203826904}
{"mode": "train", "epochs": 3, "timestep": 4085, "ep_reward": 58.48444366455078, "reward": 0.29576706886291504, "action": -0.01945626735687256}
{"mode": "train", "epochs": 3, "timestep": 4086, "ep_reward": 58.65978240966797, "reward": 0.17533975839614868, "action": -1.3436440229415894}
{"mode": "train", "epochs": 3, "timestep": 4087, "ep_reward": 58.69487762451172, "reward": 0.035096824169158936, "action": -0.8128481507301331}
{"mode": "train", "epochs": 3, "timestep": 4088, "ep_reward": 58.777565002441406, "reward": 0.08268624544143677, "action": -0.7065303325653076}
{"mode": "train", "epochs": 3, "timestep": 4089, "ep_reward": 59.0016975402832, "reward": 0.22413170337677002, "action": -0.276153564453125}
{"mode": "train", "epochs": 3, "timestep": 4090, "ep_reward": 59.37349319458008, "reward": 0.37179476022720337, "action": -0.7900627851486206}
{"mode": "train", "epochs": 3, "timestep": 4091, "ep_reward": 59.87696838378906, "reward": 0.5034735202789307, "action": -0.8432096838951111}
{"mode": "train", "epochs": 3, "timestep": 4092, "ep_reward": 60.494815826416016, "reward": 0.6178480386734009, "action": -0.4699147343635559}
{"mode": "train", "epochs": 3, "timestep": 4093, "ep_reward": 61.20943069458008, "reward": 0.7146146297454834, "action": -0.36337411403656006}
{"mode": "train", "epochs": 3, "timestep": 4094, "ep_reward": 61.998878479003906, "reward": 0.7894470691680908, "action": -1.2232251167297363}
{"mode": "train", "epochs": 3, "timestep": 4095, "ep_reward": 62.83574295043945, "reward": 0.8368631601333618, "action": -1.5445449352264404}
{"mode": "train", "epochs": 3, "timestep": 4096, "ep_reward": 63.70140075683594, "reward": 0.8656567931175232, "action": -1.5499296188354492}
{"mode": "train", "epochs": 3, "timestep": 4097, "ep_reward": 64.58158874511719, "reward": 0.8801916837692261, "action": -0.9873973727226257}
{"mode": "train", "epochs": 3, "timestep": 4098, "ep_reward": 65.46661376953125, "reward": 0.8850212097167969, "action": -1.5767090320587158}
{"mode": "train", "epochs": 3, "timestep": 4099, "ep_reward": 66.33708953857422, "reward": 0.8704755306243896, "action": -0.878715991973877}
{"mode": "train", "epochs": 3, "timestep": 4100, "ep_reward": 67.1814193725586, "reward": 0.8443266153335571, "action": -1.0033140182495117}
{"mode": "train", "epochs": 3, "timestep": 4101, "ep_reward": 67.97723388671875, "reward": 0.7958145141601562, "action": -0.8284376263618469}
{"mode": "train", "epochs": 3, "timestep": 4102, "ep_reward": 68.6992416381836, "reward": 0.7220054268836975, "action": -0.9186484217643738}
{"mode": "train", "epochs": 3, "timestep": 4103, "ep_reward": 69.31278991699219, "reward": 0.6135516166687012, "action": -0.4642474055290222}
{"mode": "train", "epochs": 3, "timestep": 4104, "ep_reward": 69.78548431396484, "reward": 0.47269612550735474, "action": -1.0235673189163208}
{"mode": "train", "epochs": 3, "timestep": 4105, "ep_reward": 70.10892486572266, "reward": 0.3234405517578125, "action": -0.2638002634048462}
{"mode": "train", "epochs": 3, "timestep": 4106, "ep_reward": 70.31713104248047, "reward": 0.20820659399032593, "action": -0.9914940595626831}
{"mode": "train", "epochs": 3, "timestep": 4107, "ep_reward": 70.39017486572266, "reward": 0.07304567098617554, "action": -0.8530083894729614}
{"mode": "train", "epochs": 3, "timestep": 4108, "ep_reward": 70.43524932861328, "reward": 0.04507160186767578, "action": -0.7489169836044312}
{"mode": "train", "epochs": 3, "timestep": 4109, "ep_reward": 70.62004089355469, "reward": 0.1847926378250122, "action": -0.5108910799026489}
{"mode": "train", "epochs": 3, "timestep": 4110, "ep_reward": 70.9506607055664, "reward": 0.3306177258491516, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4111, "ep_reward": 71.40299224853516, "reward": 0.4523286819458008, "action": -0.8764714002609253}
{"mode": "train", "epochs": 3, "timestep": 4112, "ep_reward": 71.97795867919922, "reward": 0.574966311454773, "action": -0.5909653902053833}
{"mode": "train", "epochs": 3, "timestep": 4113, "ep_reward": 72.65702056884766, "reward": 0.6790651082992554, "action": -0.3776490092277527}
{"mode": "train", "epochs": 3, "timestep": 4114, "ep_reward": 73.41785430908203, "reward": 0.7608363628387451, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4115, "ep_reward": 74.22368621826172, "reward": 0.8058344125747681, "action": -0.7310056686401367}
{"mode": "train", "epochs": 3, "timestep": 4116, "ep_reward": 75.06698608398438, "reward": 0.8432995676994324, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4117, "ep_reward": 75.91927337646484, "reward": 0.8522839546203613, "action": -0.12853753566741943}
{"mode": "train", "epochs": 3, "timestep": 4118, "ep_reward": 76.77943420410156, "reward": 0.8601572513580322, "action": -0.7551508545875549}
{"mode": "train", "epochs": 3, "timestep": 4119, "ep_reward": 77.62403106689453, "reward": 0.8445941209793091, "action": -0.011147499084472656}
{"mode": "train", "epochs": 3, "timestep": 4120, "ep_reward": 78.4400405883789, "reward": 0.8160076141357422, "action": -0.9104905724525452}
{"mode": "train", "epochs": 3, "timestep": 4121, "ep_reward": 79.19464111328125, "reward": 0.7546019554138184, "action": -0.7122257947921753}
{"mode": "train", "epochs": 3, "timestep": 4122, "ep_reward": 79.85905456542969, "reward": 0.6644128561019897, "action": -1.1512130498886108}
{"mode": "train", "epochs": 3, "timestep": 4123, "ep_reward": 80.39012145996094, "reward": 0.5310646295547485, "action": -0.6337558031082153}
{"mode": "train", "epochs": 3, "timestep": 4124, "ep_reward": 80.75817108154297, "reward": 0.36805206537246704, "action": -0.35100722312927246}
{"mode": "train", "epochs": 3, "timestep": 4125, "ep_reward": 81.0198974609375, "reward": 0.26172804832458496, "action": -0.42771226167678833}
{"mode": "train", "epochs": 3, "timestep": 4126, "ep_reward": 81.1552963256836, "reward": 0.13539665937423706, "action": -0.6008138656616211}
{"mode": "train", "epochs": 3, "timestep": 4127, "ep_reward": 81.14424133300781, "reward": -0.011054158210754395, "action": -1.5663328170776367}
{"mode": "train", "epochs": 3, "timestep": 4128, "ep_reward": 81.26918029785156, "reward": 0.12493830919265747, "action": -1.0728873014450073}
{"mode": "train", "epochs": 3, "timestep": 4129, "ep_reward": 81.53218841552734, "reward": 0.2630118727684021, "action": -0.6757841110229492}
{"mode": "train", "epochs": 3, "timestep": 4130, "ep_reward": 81.9372329711914, "reward": 0.4050411581993103, "action": -1.6303021907806396}
{"mode": "train", "epochs": 3, "timestep": 4131, "ep_reward": 82.4617919921875, "reward": 0.52455735206604, "action": -0.6696598529815674}
{"mode": "train", "epochs": 3, "timestep": 4132, "ep_reward": 83.09925842285156, "reward": 0.6374630928039551, "action": -1.7176012992858887}
{"mode": "train", "epochs": 3, "timestep": 4133, "ep_reward": 83.81586456298828, "reward": 0.7166060209274292, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4134, "ep_reward": 84.58794403076172, "reward": 0.7720777988433838, "action": -0.7507084608078003}
{"mode": "train", "epochs": 3, "timestep": 4135, "ep_reward": 85.40663146972656, "reward": 0.8186860084533691, "action": -0.7538934946060181}
{"mode": "train", "epochs": 3, "timestep": 4136, "ep_reward": 86.25177764892578, "reward": 0.8451488018035889, "action": -0.36972057819366455}
{"mode": "train", "epochs": 3, "timestep": 4137, "ep_reward": 87.10832977294922, "reward": 0.8565531373023987, "action": -0.5158272385597229}
{"mode": "train", "epochs": 3, "timestep": 4138, "ep_reward": 87.9569091796875, "reward": 0.8485773801803589, "action": -0.7143411636352539}
{"mode": "train", "epochs": 3, "timestep": 4139, "ep_reward": 88.77592468261719, "reward": 0.8190154433250427, "action": -0.7988094687461853}
{"mode": "train", "epochs": 3, "timestep": 4140, "ep_reward": 89.54046630859375, "reward": 0.764542818069458, "action": -1.2744948863983154}
{"mode": "train", "epochs": 3, "timestep": 4141, "ep_reward": 90.21434783935547, "reward": 0.6738791465759277, "action": -1.3795921802520752}
{"mode": "train", "epochs": 3, "timestep": 4142, "ep_reward": 90.75688171386719, "reward": 0.5425319671630859, "action": -1.0632327795028687}
{"mode": "train", "epochs": 3, "timestep": 4143, "ep_reward": 91.14193725585938, "reward": 0.38505619764328003, "action": -1.1213672161102295}
{"mode": "train", "epochs": 3, "timestep": 4144, "ep_reward": 91.42427825927734, "reward": 0.2823437452316284, "action": -1.1599889993667603}
{"mode": "train", "epochs": 3, "timestep": 4145, "ep_reward": 91.58396911621094, "reward": 0.15969252586364746, "action": -0.673554539680481}
{"mode": "train", "epochs": 3, "timestep": 4146, "ep_reward": 91.60088348388672, "reward": 0.016913890838623047, "action": -1.2658100128173828}
{"mode": "train", "epochs": 3, "timestep": 4147, "ep_reward": 91.70063018798828, "reward": 0.09974676370620728, "action": -0.7458837032318115}
{"mode": "train", "epochs": 3, "timestep": 4148, "ep_reward": 91.94180297851562, "reward": 0.24116945266723633, "action": -0.8455004692077637}
{"mode": "train", "epochs": 3, "timestep": 4149, "ep_reward": 92.32329559326172, "reward": 0.3814951181411743, "action": -0.3742920160293579}
{"mode": "train", "epochs": 3, "timestep": 4150, "ep_reward": 92.8409652709961, "reward": 0.5176687836647034, "action": -0.8685588836669922}
{"mode": "train", "epochs": 3, "timestep": 4151, "ep_reward": 93.47048950195312, "reward": 0.6295244693756104, "action": -0.7836700081825256}
{"mode": "train", "epochs": 3, "timestep": 4152, "ep_reward": 94.19109344482422, "reward": 0.7206030488014221, "action": -1.2305320501327515}
{"mode": "train", "epochs": 3, "timestep": 4153, "ep_reward": 94.97693634033203, "reward": 0.785840630531311, "action": -0.05654406547546387}
{"mode": "train", "epochs": 3, "timestep": 4154, "ep_reward": 95.81835174560547, "reward": 0.8414130210876465, "action": -0.8619220852851868}
{"mode": "train", "epochs": 3, "timestep": 4155, "ep_reward": 96.69084167480469, "reward": 0.8724880218505859, "action": -1.4982662200927734}
{"mode": "train", "epochs": 3, "timestep": 4156, "ep_reward": 97.5750961303711, "reward": 0.8842512369155884, "action": -1.7413095235824585}
{"mode": "train", "epochs": 3, "timestep": 4157, "ep_reward": 98.45539855957031, "reward": 0.8803030848503113, "action": -1.371006727218628}
{"mode": "train", "epochs": 3, "timestep": 4158, "ep_reward": 99.31913757324219, "reward": 0.8637364506721497, "action": -0.9445605278015137}
{"mode": "train", "epochs": 3, "timestep": 4159, "ep_reward": 100.15155029296875, "reward": 0.832409679889679, "action": -0.42788803577423096}
{"mode": "train", "epochs": 3, "timestep": 4160, "ep_reward": 100.93528747558594, "reward": 0.7837364673614502, "action": -1.340968370437622}
{"mode": "train", "epochs": 3, "timestep": 4161, "ep_reward": 101.63248443603516, "reward": 0.6971954703330994, "action": -0.48795372247695923}
{"mode": "train", "epochs": 3, "timestep": 4162, "ep_reward": 102.21770477294922, "reward": 0.5852211117744446, "action": -1.2521271705627441}
{"mode": "train", "epochs": 3, "timestep": 4163, "ep_reward": 102.64081573486328, "reward": 0.4231099486351013, "action": -1.0094504356384277}
{"mode": "train", "epochs": 3, "timestep": 4164, "ep_reward": 102.9380874633789, "reward": 0.2972683310508728, "action": -1.0938732624053955}
{"mode": "train", "epochs": 3, "timestep": 4165, "ep_reward": 103.11534118652344, "reward": 0.1772499680519104, "action": -1.0129122734069824}
{"mode": "train", "epochs": 3, "timestep": 4166, "ep_reward": 103.15254974365234, "reward": 0.03720980882644653, "action": -1.0965933799743652}
{"mode": "train", "epochs": 3, "timestep": 4167, "ep_reward": 103.23307800292969, "reward": 0.08053028583526611, "action": -1.439385175704956}
{"mode": "train", "epochs": 3, "timestep": 4168, "ep_reward": 103.44775390625, "reward": 0.2146739959716797, "action": -1.3631978034973145}
{"mode": "train", "epochs": 3, "timestep": 4169, "ep_reward": 103.79837036132812, "reward": 0.35061389207839966, "action": -0.8955819606781006}
{"mode": "train", "epochs": 3, "timestep": 4170, "ep_reward": 104.2837142944336, "reward": 0.48534607887268066, "action": -0.6374813318252563}
{"mode": "train", "epochs": 3, "timestep": 4171, "ep_reward": 104.8893051147461, "reward": 0.6055895686149597, "action": -0.5872244238853455}
{"mode": "train", "epochs": 3, "timestep": 4172, "ep_reward": 105.59233856201172, "reward": 0.7030298709869385, "action": -1.6002967357635498}
{"mode": "train", "epochs": 3, "timestep": 4173, "ep_reward": 106.3595199584961, "reward": 0.7671809196472168, "action": -1.7494571208953857}
{"mode": "train", "epochs": 3, "timestep": 4174, "ep_reward": 107.16932678222656, "reward": 0.8098049163818359, "action": -0.573212206363678}
{"mode": "train", "epochs": 3, "timestep": 4175, "ep_reward": 108.0129623413086, "reward": 0.8436319828033447, "action": -1.5552676916122437}
{"mode": "train", "epochs": 3, "timestep": 4176, "ep_reward": 108.8635025024414, "reward": 0.8505417704582214, "action": 0.0016633272171020508}
{"mode": "train", "epochs": 3, "timestep": 4177, "ep_reward": 109.71662139892578, "reward": 0.8531169295310974, "action": -1.3246217966079712}
{"mode": "train", "epochs": 3, "timestep": 4178, "ep_reward": 110.54084014892578, "reward": 0.8242213129997253, "action": -1.4413987398147583}
{"mode": "train", "epochs": 3, "timestep": 4179, "ep_reward": 111.31057739257812, "reward": 0.7697383165359497, "action": -0.457366943359375}
{"mode": "train", "epochs": 3, "timestep": 4180, "ep_reward": 112.0064697265625, "reward": 0.6958898305892944, "action": -0.6188664436340332}
{"mode": "train", "epochs": 3, "timestep": 4181, "ep_reward": 112.59151458740234, "reward": 0.5850411653518677, "action": -0.6591528654098511}
{"mode": "train", "epochs": 3, "timestep": 4182, "ep_reward": 113.02508544921875, "reward": 0.4335685968399048, "action": -0.6389106512069702}
{"mode": "train", "epochs": 3, "timestep": 4183, "ep_reward": 113.33822631835938, "reward": 0.313144326210022, "action": -0.669431209564209}
{"mode": "train", "epochs": 3, "timestep": 4184, "ep_reward": 113.53424072265625, "reward": 0.19601428508758545, "action": -0.8480501174926758}
{"mode": "train", "epochs": 3, "timestep": 4185, "ep_reward": 113.59307861328125, "reward": 0.058836400508880615, "action": -1.3242683410644531}
{"mode": "train", "epochs": 3, "timestep": 4186, "ep_reward": 113.65249633789062, "reward": 0.05941694974899292, "action": -0.5142492055892944}
{"mode": "train", "epochs": 3, "timestep": 4187, "ep_reward": 113.85486602783203, "reward": 0.20236867666244507, "action": -1.6187573671340942}
{"mode": "train", "epochs": 3, "timestep": 4188, "ep_reward": 114.18876647949219, "reward": 0.3338988423347473, "action": -0.3194350600242615}
{"mode": "train", "epochs": 3, "timestep": 4189, "ep_reward": 114.66492462158203, "reward": 0.47615450620651245, "action": -1.7795872688293457}
{"mode": "train", "epochs": 3, "timestep": 4190, "ep_reward": 115.24979400634766, "reward": 0.5848701000213623, "action": -1.1565093994140625}
{"mode": "train", "epochs": 3, "timestep": 4191, "ep_reward": 115.93084716796875, "reward": 0.6810535788536072, "action": -0.9828234910964966}
{"mode": "train", "epochs": 3, "timestep": 4192, "ep_reward": 116.68704223632812, "reward": 0.7561914920806885, "action": -0.33607858419418335}
{"mode": "train", "epochs": 3, "timestep": 4193, "ep_reward": 117.5019760131836, "reward": 0.814937174320221, "action": -1.1894190311431885}
{"mode": "train", "epochs": 3, "timestep": 4194, "ep_reward": 118.34798431396484, "reward": 0.8460065126419067, "action": -1.4948583841323853}
{"mode": "train", "epochs": 3, "timestep": 4195, "ep_reward": 119.20526123046875, "reward": 0.8572798371315002, "action": -0.5288330316543579}
{"mode": "train", "epochs": 3, "timestep": 4196, "ep_reward": 120.06488800048828, "reward": 0.8596264123916626, "action": -1.5200145244598389}
{"mode": "train", "epochs": 3, "timestep": 4197, "ep_reward": 120.89961242675781, "reward": 0.8347238898277283, "action": -1.3893229961395264}
{"mode": "train", "epochs": 3, "timestep": 4198, "ep_reward": 121.6876220703125, "reward": 0.7880078554153442, "action": -1.2916187047958374}
{"mode": "train", "epochs": 3, "timestep": 4199, "ep_reward": 122.40062713623047, "reward": 0.7130075693130493, "action": -1.5585360527038574}
{"mode": "train", "epochs": 3, "timestep": 4200, "ep_reward": 122.99811553955078, "reward": 0.597486138343811, "action": -1.6508855819702148}
{"mode": "train", "epochs": 3, "timestep": 4201, "ep_reward": 123.43351745605469, "reward": 0.4353986978530884, "action": -1.708277940750122}
{"mode": "train", "epochs": 3, "timestep": 4202, "ep_reward": 123.7667236328125, "reward": 0.3332030177116394, "action": -1.03949773311615}
{"mode": "train", "epochs": 3, "timestep": 4203, "ep_reward": 123.9866714477539, "reward": 0.2199506163597107, "action": -0.6659363508224487}
{"mode": "train", "epochs": 3, "timestep": 4204, "ep_reward": 124.07321166992188, "reward": 0.0865371823310852, "action": -1.5430963039398193}
{"mode": "train", "epochs": 3, "timestep": 4205, "ep_reward": 124.10416412353516, "reward": 0.030951738357543945, "action": -0.6251206398010254}
{"mode": "train", "epochs": 3, "timestep": 4206, "ep_reward": 124.27588653564453, "reward": 0.17172545194625854, "action": -1.3773467540740967}
{"mode": "train", "epochs": 3, "timestep": 4207, "ep_reward": 124.58292388916016, "reward": 0.30703580379486084, "action": -0.7545452117919922}
{"mode": "train", "epochs": 3, "timestep": 4208, "ep_reward": 125.02943420410156, "reward": 0.44651007652282715, "action": -0.9556991457939148}
{"mode": "train", "epochs": 3, "timestep": 4209, "ep_reward": 125.59825134277344, "reward": 0.5688199996948242, "action": -1.1439871788024902}
{"mode": "train", "epochs": 3, "timestep": 4210, "ep_reward": 126.26678466796875, "reward": 0.6685330867767334, "action": -0.6569451093673706}
{"mode": "train", "epochs": 3, "timestep": 4211, "ep_reward": 127.01718139648438, "reward": 0.7503934502601624, "action": -0.41315436363220215}
{"mode": "train", "epochs": 3, "timestep": 4212, "ep_reward": 127.82884216308594, "reward": 0.8116583824157715, "action": -0.6051796078681946}
{"mode": "train", "epochs": 3, "timestep": 4213, "ep_reward": 128.67996215820312, "reward": 0.8511207103729248, "action": -0.21966451406478882}
{"mode": "train", "epochs": 3, "timestep": 4214, "ep_reward": 129.55661010742188, "reward": 0.8766431212425232, "action": -0.2665709853172302}
{"mode": "train", "epochs": 3, "timestep": 4215, "ep_reward": 130.44309997558594, "reward": 0.8864833116531372, "action": -1.6142845153808594}
{"mode": "train", "epochs": 3, "timestep": 4216, "ep_reward": 131.31407165527344, "reward": 0.8709762692451477, "action": -1.059156060218811}
{"mode": "train", "epochs": 3, "timestep": 4217, "ep_reward": 132.15655517578125, "reward": 0.8424887657165527, "action": -1.145220160484314}
{"mode": "train", "epochs": 3, "timestep": 4218, "ep_reward": 132.94786071777344, "reward": 0.7913105487823486, "action": -1.5686829090118408}
{"mode": "train", "epochs": 3, "timestep": 4219, "ep_reward": 133.6547393798828, "reward": 0.7068784236907959, "action": -0.4900689125061035}
{"mode": "train", "epochs": 3, "timestep": 4220, "ep_reward": 134.25437927246094, "reward": 0.599643349647522, "action": -0.7693392038345337}
{"mode": "train", "epochs": 3, "timestep": 4221, "ep_reward": 134.70436096191406, "reward": 0.44998884201049805, "action": -0.003636479377746582}
{"mode": "train", "epochs": 3, "timestep": 4222, "ep_reward": 135.01846313476562, "reward": 0.3141055107116699, "action": -0.6571933031082153}
{"mode": "train", "epochs": 3, "timestep": 4223, "ep_reward": 135.21559143066406, "reward": 0.19713103771209717, "action": -1.0417277812957764}
{"mode": "train", "epochs": 3, "timestep": 4224, "ep_reward": 135.27577209472656, "reward": 0.06018102169036865, "action": -1.1594431400299072}
{"mode": "train", "epochs": 3, "timestep": 4225, "ep_reward": 135.33380126953125, "reward": 0.05802375078201294, "action": -1.1980704069137573}
{"mode": "train", "epochs": 3, "timestep": 4226, "ep_reward": 135.529052734375, "reward": 0.19524890184402466, "action": -1.2059637308120728}
{"mode": "train", "epochs": 3, "timestep": 4227, "ep_reward": 135.86196899414062, "reward": 0.3329182267189026, "action": -1.424758791923523}
{"mode": "train", "epochs": 3, "timestep": 4228, "ep_reward": 136.32427978515625, "reward": 0.4623148441314697, "action": -1.6192138195037842}
{"mode": "train", "epochs": 3, "timestep": 4229, "ep_reward": 136.89952087402344, "reward": 0.575236439704895, "action": -0.7339774370193481}
{"mode": "train", "epochs": 3, "timestep": 4230, "ep_reward": 137.5767364501953, "reward": 0.6772085428237915, "action": -1.3901069164276123}
{"mode": "train", "epochs": 3, "timestep": 4231, "ep_reward": 138.32489013671875, "reward": 0.7481467723846436, "action": -1.3279178142547607}
{"mode": "train", "epochs": 3, "timestep": 4232, "ep_reward": 139.1223602294922, "reward": 0.7974762916564941, "action": -1.0193668603897095}
{"mode": "train", "epochs": 3, "timestep": 4233, "ep_reward": 139.951171875, "reward": 0.8288120031356812, "action": -0.7749180197715759}
{"mode": "train", "epochs": 3, "timestep": 4234, "ep_reward": 140.79368591308594, "reward": 0.842507541179657, "action": -1.3799933195114136}
{"mode": "train", "epochs": 3, "timestep": 4235, "ep_reward": 141.62454223632812, "reward": 0.8308494687080383, "action": -1.078871250152588}
{"mode": "train", "epochs": 3, "timestep": 4236, "ep_reward": 142.42430114746094, "reward": 0.7997560501098633, "action": -0.18013709783554077}
{"mode": "train", "epochs": 3, "timestep": 4237, "ep_reward": 143.17645263671875, "reward": 0.7521518468856812, "action": -0.2182108759880066}
{"mode": "train", "epochs": 3, "timestep": 4238, "ep_reward": 143.85055541992188, "reward": 0.6741071939468384, "action": -1.181267261505127}
{"mode": "train", "epochs": 3, "timestep": 4239, "ep_reward": 144.397216796875, "reward": 0.5466629266738892, "action": -1.552405595779419}
{"mode": "train", "epochs": 3, "timestep": 4240, "ep_reward": 144.78733825683594, "reward": 0.3901243805885315, "action": -1.1356244087219238}
{"mode": "train", "epochs": 3, "timestep": 4241, "ep_reward": 145.07586669921875, "reward": 0.2885321378707886, "action": -1.025019645690918}
{"mode": "train", "epochs": 3, "timestep": 4242, "ep_reward": 145.24267578125, "reward": 0.16681212186813354, "action": -1.6888792514801025}
{"mode": "train", "epochs": 3, "timestep": 4243, "ep_reward": 145.2679901123047, "reward": 0.02532142400741577, "action": -0.9917363524436951}
{"mode": "train", "epochs": 3, "timestep": 4244, "ep_reward": 145.35992431640625, "reward": 0.09193968772888184, "action": -0.7160553932189941}
{"mode": "train", "epochs": 3, "timestep": 4245, "ep_reward": 145.59339904785156, "reward": 0.2334766387939453, "action": -1.0757019519805908}
{"mode": "train", "epochs": 3, "timestep": 4246, "ep_reward": 145.96449279785156, "reward": 0.3710935711860657, "action": -1.454947590827942}
{"mode": "train", "epochs": 3, "timestep": 4247, "ep_reward": 146.4607391357422, "reward": 0.49624162912368774, "action": -0.004762113094329834}
{"mode": "train", "epochs": 3, "timestep": 4248, "ep_reward": 147.0821075439453, "reward": 0.6213665008544922, "action": -0.376395046710968}
{"mode": "train", "epochs": 3, "timestep": 4249, "ep_reward": 147.80001831054688, "reward": 0.7179100513458252, "action": -1.3259128332138062}
{"mode": "train", "epochs": 3, "timestep": 4250, "ep_reward": 148.58273315429688, "reward": 0.7827169299125671, "action": -0.6867949962615967}
{"mode": "train", "epochs": 3, "timestep": 4251, "ep_reward": 149.41627502441406, "reward": 0.833549439907074, "action": -0.527314305305481}
{"mode": "train", "epochs": 3, "timestep": 4252, "ep_reward": 150.28399658203125, "reward": 0.8677210211753845, "action": -0.8761016726493835}
{"mode": "train", "epochs": 3, "timestep": 4253, "ep_reward": 151.1676483154297, "reward": 0.8836577534675598, "action": -1.5166683197021484}
{"mode": "train", "epochs": 3, "timestep": 4254, "ep_reward": 152.04818725585938, "reward": 0.8805372714996338, "action": -0.5140752196311951}
{"mode": "train", "epochs": 3, "timestep": 4255, "ep_reward": 152.9183807373047, "reward": 0.8701963424682617, "action": -1.5008385181427002}
{"mode": "train", "epochs": 3, "timestep": 4256, "ep_reward": 153.7520751953125, "reward": 0.8337016105651855, "action": -1.3143521547317505}
{"mode": "train", "epochs": 3, "timestep": 4257, "ep_reward": 154.5272216796875, "reward": 0.775148868560791, "action": -1.6229898929595947}
{"mode": "train", "epochs": 3, "timestep": 4258, "ep_reward": 155.2095184326172, "reward": 0.6822983622550964, "action": -0.4439312815666199}
{"mode": "train", "epochs": 3, "timestep": 4259, "ep_reward": 155.77601623535156, "reward": 0.5664950609207153, "action": -1.3645350933074951}
{"mode": "train", "epochs": 3, "timestep": 4260, "ep_reward": 156.1731719970703, "reward": 0.39715391397476196, "action": -1.1684527397155762}
{"mode": "train", "epochs": 3, "timestep": 4261, "ep_reward": 156.46002197265625, "reward": 0.286857545375824, "action": -0.692635715007782}
{"mode": "train", "epochs": 3, "timestep": 4262, "ep_reward": 156.62498474121094, "reward": 0.16496914625167847, "action": -0.2805364727973938}
{"mode": "train", "epochs": 3, "timestep": 4263, "ep_reward": 156.64804077148438, "reward": 0.023060262203216553, "action": -0.06815201044082642}
{"mode": "train", "epochs": 3, "timestep": 4264, "ep_reward": 156.7420654296875, "reward": 0.09402734041213989, "action": -1.4059245586395264}
{"mode": "train", "epochs": 3, "timestep": 4265, "ep_reward": 156.9690704345703, "reward": 0.22700512409210205, "action": -1.267382264137268}
{"mode": "train", "epochs": 3, "timestep": 4266, "ep_reward": 157.33311462402344, "reward": 0.36404067277908325, "action": -0.5964272022247314}
{"mode": "train", "epochs": 3, "timestep": 4267, "ep_reward": 157.8339385986328, "reward": 0.5008209347724915, "action": -1.545242428779602}
{"mode": "train", "epochs": 3, "timestep": 4268, "ep_reward": 158.4424591064453, "reward": 0.6085240840911865, "action": -0.5124648809432983}
{"mode": "train", "epochs": 3, "timestep": 4269, "ep_reward": 159.14830017089844, "reward": 0.7058484554290771, "action": -0.6938775181770325}
{"mode": "train", "epochs": 3, "timestep": 4270, "ep_reward": 159.92523193359375, "reward": 0.7769268751144409, "action": -1.545076847076416}
{"mode": "train", "epochs": 3, "timestep": 4271, "ep_reward": 160.7440948486328, "reward": 0.8188565969467163, "action": -0.9503642320632935}
{"mode": "train", "epochs": 3, "timestep": 4272, "ep_reward": 161.59144592285156, "reward": 0.8473448753356934, "action": -1.065167784690857}
{"mode": "train", "epochs": 3, "timestep": 4273, "ep_reward": 162.4485321044922, "reward": 0.8570800423622131, "action": -0.8026270866394043}
{"mode": "train", "epochs": 3, "timestep": 4274, "ep_reward": 163.2998809814453, "reward": 0.851345419883728, "action": -1.2112494707107544}
{"mode": "train", "epochs": 3, "timestep": 4275, "ep_reward": 164.1220703125, "reward": 0.8221899271011353, "action": -1.283308982849121}
{"mode": "train", "epochs": 3, "timestep": 4276, "ep_reward": 164.88983154296875, "reward": 0.7677599787712097, "action": -1.3083624839782715}
{"mode": "train", "epochs": 3, "timestep": 4277, "ep_reward": 165.57144165039062, "reward": 0.6816055774688721, "action": -1.0025490522384644}
{"mode": "train", "epochs": 3, "timestep": 4278, "ep_reward": 166.13204956054688, "reward": 0.5606065988540649, "action": -1.4717046022415161}
{"mode": "train", "epochs": 3, "timestep": 4279, "ep_reward": 166.5321044921875, "reward": 0.40005332231521606, "action": -1.158202886581421}
{"mode": "train", "epochs": 3, "timestep": 4280, "ep_reward": 166.83274841308594, "reward": 0.3006405830383301, "action": -1.1604019403457642}
{"mode": "train", "epochs": 3, "timestep": 4281, "ep_reward": 167.01405334472656, "reward": 0.18130791187286377, "action": -0.2609012722969055}
{"mode": "train", "epochs": 3, "timestep": 4282, "ep_reward": 167.05589294433594, "reward": 0.041844308376312256, "action": -0.9392240643501282}
{"mode": "train", "epochs": 3, "timestep": 4283, "ep_reward": 167.13209533691406, "reward": 0.07619500160217285, "action": -0.4583698511123657}
{"mode": "train", "epochs": 3, "timestep": 4284, "ep_reward": 167.3526153564453, "reward": 0.22052371501922607, "action": -0.0589480996131897}
{"mode": "train", "epochs": 3, "timestep": 4285, "ep_reward": 167.72283935546875, "reward": 0.37022876739501953, "action": -1.452297329902649}
{"mode": "train", "epochs": 3, "timestep": 4286, "ep_reward": 168.21678161621094, "reward": 0.4939374327659607, "action": -0.9007217884063721}
{"mode": "train", "epochs": 3, "timestep": 4287, "ep_reward": 168.8259735107422, "reward": 0.6091980338096619, "action": -1.2889666557312012}
{"mode": "train", "epochs": 3, "timestep": 4288, "ep_reward": 169.52574157714844, "reward": 0.6997672915458679, "action": -0.6863071918487549}
{"mode": "train", "epochs": 3, "timestep": 4289, "ep_reward": 170.30035400390625, "reward": 0.7746157646179199, "action": -1.0840229988098145}
{"mode": "train", "epochs": 3, "timestep": 4290, "ep_reward": 171.1254425048828, "reward": 0.8250868916511536, "action": -1.2035439014434814}
{"mode": "train", "epochs": 3, "timestep": 4291, "ep_reward": 171.98231506347656, "reward": 0.8568666577339172, "action": -1.0955164432525635}
{"mode": "train", "epochs": 3, "timestep": 4292, "ep_reward": 172.85610961914062, "reward": 0.8737926483154297, "action": -0.2140381932258606}
{"mode": "train", "epochs": 3, "timestep": 4293, "ep_reward": 173.73883056640625, "reward": 0.8827138543128967, "action": -1.2263803482055664}
{"mode": "train", "epochs": 3, "timestep": 4294, "ep_reward": 174.6071014404297, "reward": 0.86827552318573, "action": -1.3911755084991455}
{"mode": "train", "epochs": 3, "timestep": 4295, "ep_reward": 175.44137573242188, "reward": 0.8342785835266113, "action": -1.1128901243209839}
{"mode": "train", "epochs": 3, "timestep": 4296, "ep_reward": 176.2210235595703, "reward": 0.7796540260314941, "action": -1.3313853740692139}
{"mode": "train", "epochs": 3, "timestep": 4297, "ep_reward": 176.9139862060547, "reward": 0.6929607391357422, "action": -0.5481674671173096}
{"mode": "train", "epochs": 3, "timestep": 4298, "ep_reward": 177.49339294433594, "reward": 0.5794088840484619, "action": -1.6976628303527832}
{"mode": "train", "epochs": 3, "timestep": 4299, "ep_reward": 177.9020233154297, "reward": 0.40862441062927246, "action": -0.7943705916404724}
{"mode": "train", "epochs": 3, "timestep": 4300, "ep_reward": 178.19842529296875, "reward": 0.2964073419570923, "action": -1.1905500888824463}
{"mode": "train", "epochs": 3, "timestep": 4301, "ep_reward": 178.37469482421875, "reward": 0.17626571655273438, "action": -0.8693237900733948}
{"mode": "train", "epochs": 3, "timestep": 4302, "ep_reward": 178.41073608398438, "reward": 0.03604668378829956, "action": -1.1544275283813477}
{"mode": "train", "epochs": 3, "timestep": 4303, "ep_reward": 178.49234008789062, "reward": 0.08160334825515747, "action": -1.6244699954986572}
{"mode": "train", "epochs": 3, "timestep": 4304, "ep_reward": 178.70806884765625, "reward": 0.21572184562683105, "action": -0.6132989525794983}
{"mode": "train", "epochs": 3, "timestep": 4305, "ep_reward": 179.06903076171875, "reward": 0.3609558343887329, "action": -0.2227410078048706}
{"mode": "train", "epochs": 3, "timestep": 4306, "ep_reward": 179.5705108642578, "reward": 0.5014865398406982, "action": -0.9550656080245972}
{"mode": "train", "epochs": 3, "timestep": 4307, "ep_reward": 180.18568420410156, "reward": 0.6151770353317261, "action": -0.5642893314361572}
{"mode": "train", "epochs": 3, "timestep": 4308, "ep_reward": 180.8970947265625, "reward": 0.7114028930664062, "action": -0.8816547989845276}
{"mode": "train", "epochs": 3, "timestep": 4309, "ep_reward": 181.67901611328125, "reward": 0.781922459602356, "action": -0.4179752469062805}
{"mode": "train", "epochs": 3, "timestep": 4310, "ep_reward": 182.5150909423828, "reward": 0.8360756635665894, "action": -0.7304061055183411}
{"mode": "train", "epochs": 3, "timestep": 4311, "ep_reward": 183.38485717773438, "reward": 0.8697724938392639, "action": -1.2929880619049072}
{"mode": "train", "epochs": 3, "timestep": 4312, "ep_reward": 184.26930236816406, "reward": 0.8844483494758606, "action": -0.7579362988471985}
{"mode": "train", "epochs": 3, "timestep": 4313, "ep_reward": 185.1588897705078, "reward": 0.8895814418792725, "action": -0.6386728286743164}
{"mode": "train", "epochs": 3, "timestep": 4314, "ep_reward": 186.04037475585938, "reward": 0.8814898133277893, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4315, "ep_reward": 186.88624572753906, "reward": 0.8458676338195801, "action": -0.8248728513717651}
{"mode": "train", "epochs": 3, "timestep": 4316, "ep_reward": 187.6849822998047, "reward": 0.798737108707428, "action": -1.7766038179397583}
{"mode": "train", "epochs": 3, "timestep": 4317, "ep_reward": 188.39906311035156, "reward": 0.7140783071517944, "action": 0.16378414630889893}
{"mode": "train", "epochs": 3, "timestep": 4318, "ep_reward": 189.01702880859375, "reward": 0.6179702281951904, "action": -0.9960485696792603}
{"mode": "train", "epochs": 3, "timestep": 4319, "ep_reward": 189.48683166503906, "reward": 0.46980351209640503, "action": -1.5475800037384033}
{"mode": "train", "epochs": 3, "timestep": 4320, "ep_reward": 189.808349609375, "reward": 0.32152074575424194, "action": -0.3944045901298523}
{"mode": "train", "epochs": 3, "timestep": 4321, "ep_reward": 190.01426696777344, "reward": 0.205918550491333, "action": -1.0655229091644287}
{"mode": "train", "epochs": 3, "timestep": 4322, "ep_reward": 190.08465576171875, "reward": 0.07038402557373047, "action": -1.0157140493392944}
{"mode": "train", "epochs": 3, "timestep": 4323, "ep_reward": 190.13229370117188, "reward": 0.04764312505722046, "action": -1.6473206281661987}
{"mode": "train", "epochs": 3, "timestep": 4324, "ep_reward": 190.3187255859375, "reward": 0.1864263415336609, "action": -0.2947857975959778}
{"mode": "train", "epochs": 3, "timestep": 4325, "ep_reward": 190.65394592285156, "reward": 0.33521568775177, "action": -1.3684495687484741}
{"mode": "train", "epochs": 3, "timestep": 4326, "ep_reward": 191.1177520751953, "reward": 0.4638058543205261, "action": -1.0718353986740112}
{"mode": "train", "epochs": 3, "timestep": 4327, "ep_reward": 191.69996643066406, "reward": 0.5822114944458008, "action": -0.10379135608673096}
{"mode": "train", "epochs": 3, "timestep": 4328, "ep_reward": 192.38986206054688, "reward": 0.6898931264877319, "action": 0.18729019165039062}
{"mode": "train", "epochs": 3, "timestep": 4329, "ep_reward": 193.1651153564453, "reward": 0.7752535939216614, "action": -0.9801998734474182}
{"mode": "train", "epochs": 3, "timestep": 4330, "ep_reward": 193.9932098388672, "reward": 0.8281008005142212, "action": -0.8077089190483093}
{"mode": "train", "epochs": 3, "timestep": 4331, "ep_reward": 194.8582305908203, "reward": 0.8650195002555847, "action": -0.4468766450881958}
{"mode": "train", "epochs": 3, "timestep": 4332, "ep_reward": 195.7477569580078, "reward": 0.8895325064659119, "action": -1.0002696514129639}
{"mode": "train", "epochs": 3, "timestep": 4333, "ep_reward": 196.64443969726562, "reward": 0.8966803550720215, "action": -0.8189676403999329}
{"mode": "train", "epochs": 3, "timestep": 4334, "ep_reward": 197.53663635253906, "reward": 0.892196536064148, "action": -1.730384111404419}
{"mode": "train", "epochs": 3, "timestep": 4335, "ep_reward": 198.40260314941406, "reward": 0.8659660816192627, "action": -1.2940444946289062}
{"mode": "train", "epochs": 3, "timestep": 4336, "ep_reward": 199.22674560546875, "reward": 0.8241386413574219, "action": -0.8131625056266785}
{"mode": "train", "epochs": 3, "timestep": 4337, "ep_reward": 199.98936462402344, "reward": 0.7626177072525024, "action": -1.7306640148162842}
{"mode": "train", "epochs": 3, "timestep": 4338, "ep_reward": 200.64901733398438, "reward": 0.6596571207046509, "action": -1.0032844543457031}
{"mode": "train", "epochs": 3, "timestep": 4339, "ep_reward": 201.1752166748047, "reward": 0.5261936187744141, "action": 0.5374032258987427}
{"mode": "train", "epochs": 3, "timestep": 4340, "ep_reward": 201.55252075195312, "reward": 0.37729698419570923, "action": -0.5422594547271729}
{"mode": "train", "epochs": 3, "timestep": 4341, "ep_reward": 201.8075714111328, "reward": 0.25505387783050537, "action": -0.7135494351387024}
{"mode": "train", "epochs": 3, "timestep": 4342, "ep_reward": 201.93515014648438, "reward": 0.12758255004882812, "action": -0.8370254039764404}
{"mode": "train", "epochs": 3, "timestep": 4343, "ep_reward": 201.92117309570312, "reward": -0.013978123664855957, "action": -1.286828637123108}
{"mode": "train", "epochs": 3, "timestep": 4344, "ep_reward": 202.05398559570312, "reward": 0.13281536102294922, "action": -0.414050817489624}
{"mode": "train", "epochs": 3, "timestep": 4345, "ep_reward": 202.33323669433594, "reward": 0.2792472243309021, "action": -0.44049131870269775}
{"mode": "train", "epochs": 3, "timestep": 4346, "ep_reward": 202.75526428222656, "reward": 0.42203283309936523, "action": -1.1329904794692993}
{"mode": "train", "epochs": 3, "timestep": 4347, "ep_reward": 203.29965209960938, "reward": 0.5443907380104065, "action": 0.062485694885253906}
{"mode": "train", "epochs": 3, "timestep": 4348, "ep_reward": 203.96060180664062, "reward": 0.660951554775238, "action": -1.5159823894500732}
{"mode": "train", "epochs": 3, "timestep": 4349, "ep_reward": 204.6994171142578, "reward": 0.738815188407898, "action": -0.6939922571182251}
{"mode": "train", "epochs": 3, "timestep": 4350, "ep_reward": 205.50363159179688, "reward": 0.8042073845863342, "action": -0.4378467798233032}
{"mode": "train", "epochs": 3, "timestep": 4351, "ep_reward": 206.35597229003906, "reward": 0.8523391485214233, "action": -0.9001083970069885}
{"mode": "train", "epochs": 3, "timestep": 4352, "ep_reward": 207.2365264892578, "reward": 0.8805564045906067, "action": -0.9464229941368103}
{"mode": "train", "epochs": 3, "timestep": 4353, "ep_reward": 208.1313934326172, "reward": 0.8948656320571899, "action": -0.6744410395622253}
{"mode": "train", "epochs": 3, "timestep": 4354, "ep_reward": 209.02987670898438, "reward": 0.8984894156455994, "action": -1.033544659614563}
{"mode": "train", "epochs": 3, "timestep": 4355, "ep_reward": 209.91624450683594, "reward": 0.8863734602928162, "action": -0.9752238988876343}
{"mode": "train", "epochs": 3, "timestep": 4356, "ep_reward": 210.7755889892578, "reward": 0.8593420386314392, "action": -0.5603559613227844}
{"mode": "train", "epochs": 3, "timestep": 4357, "ep_reward": 211.5923614501953, "reward": 0.8167702555656433, "action": -1.5924789905548096}
{"mode": "train", "epochs": 3, "timestep": 4358, "ep_reward": 212.33145141601562, "reward": 0.7390868663787842, "action": -0.18967998027801514}
{"mode": "train", "epochs": 3, "timestep": 4359, "ep_reward": 212.9764404296875, "reward": 0.644987165927887, "action": -0.38652318716049194}
{"mode": "train", "epochs": 3, "timestep": 4360, "ep_reward": 213.490234375, "reward": 0.5137889385223389, "action": -1.6324701309204102}
{"mode": "train", "epochs": 3, "timestep": 4361, "ep_reward": 213.8256378173828, "reward": 0.3354073166847229, "action": -1.3104524612426758}
{"mode": "train", "epochs": 3, "timestep": 4362, "ep_reward": 214.0481719970703, "reward": 0.22253954410552979, "action": -1.3767403364181519}
{"mode": "train", "epochs": 3, "timestep": 4363, "ep_reward": 214.13796997070312, "reward": 0.0897911787033081, "action": -0.39761704206466675}
{"mode": "train", "epochs": 3, "timestep": 4364, "ep_reward": 214.1655731201172, "reward": 0.02759706974029541, "action": -1.1975672245025635}
{"mode": "train", "epochs": 3, "timestep": 4365, "ep_reward": 214.3345184326172, "reward": 0.16893905401229858, "action": -0.9029769897460938}
{"mode": "train", "epochs": 3, "timestep": 4366, "ep_reward": 214.64456176757812, "reward": 0.31004929542541504, "action": -0.997139573097229}
{"mode": "train", "epochs": 3, "timestep": 4367, "ep_reward": 215.08998107910156, "reward": 0.44541221857070923, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4368, "ep_reward": 215.6460418701172, "reward": 0.5560632944107056, "action": -0.21680009365081787}
{"mode": "train", "epochs": 3, "timestep": 4369, "ep_reward": 216.31387329101562, "reward": 0.6678271293640137, "action": -0.2708513140678406}
{"mode": "train", "epochs": 3, "timestep": 4370, "ep_reward": 217.06752014160156, "reward": 0.7536505460739136, "action": -0.18744784593582153}
{"mode": "train", "epochs": 3, "timestep": 4371, "ep_reward": 217.88424682617188, "reward": 0.8167262077331543, "action": -0.5768263339996338}
{"mode": "train", "epochs": 3, "timestep": 4372, "ep_reward": 218.74063110351562, "reward": 0.8563863039016724, "action": -1.586042881011963}
{"mode": "train", "epochs": 3, "timestep": 4373, "ep_reward": 219.61248779296875, "reward": 0.8718532919883728, "action": -0.8355525732040405}
{"mode": "train", "epochs": 3, "timestep": 4374, "ep_reward": 220.49090576171875, "reward": 0.8784220814704895, "action": -0.9537279009819031}
{"mode": "train", "epochs": 3, "timestep": 4375, "ep_reward": 221.3595733642578, "reward": 0.86866295337677, "action": -0.8800476789474487}
{"mode": "train", "epochs": 3, "timestep": 4376, "ep_reward": 222.20167541503906, "reward": 0.8420975804328918, "action": -0.9714967608451843}
{"mode": "train", "epochs": 3, "timestep": 4377, "ep_reward": 222.99484252929688, "reward": 0.7931731939315796, "action": -1.1845893859863281}
{"mode": "train", "epochs": 3, "timestep": 4378, "ep_reward": 223.70904541015625, "reward": 0.7142002582550049, "action": -0.7139912843704224}
{"mode": "train", "epochs": 3, "timestep": 4379, "ep_reward": 224.3151092529297, "reward": 0.6060652732849121, "action": -1.27910578250885}
{"mode": "train", "epochs": 3, "timestep": 4380, "ep_reward": 224.76535034179688, "reward": 0.45024430751800537, "action": -1.2532962560653687}
{"mode": "train", "epochs": 3, "timestep": 4381, "ep_reward": 225.082763671875, "reward": 0.3174147605895996, "action": -0.049668192863464355}
{"mode": "train", "epochs": 3, "timestep": 4382, "ep_reward": 225.28384399414062, "reward": 0.20107495784759521, "action": -0.594262957572937}
{"mode": "train", "epochs": 3, "timestep": 4383, "ep_reward": 225.3485107421875, "reward": 0.06467288732528687, "action": -1.302600383758545}
{"mode": "train", "epochs": 3, "timestep": 4384, "ep_reward": 225.40206909179688, "reward": 0.05355381965637207, "action": -0.5328314304351807}
{"mode": "train", "epochs": 3, "timestep": 4385, "ep_reward": 225.59820556640625, "reward": 0.19614273309707642, "action": -1.3364089727401733}
{"mode": "train", "epochs": 3, "timestep": 4386, "ep_reward": 225.9295196533203, "reward": 0.33131909370422363, "action": -0.41631579399108887}
{"mode": "train", "epochs": 3, "timestep": 4387, "ep_reward": 226.40185546875, "reward": 0.4723318815231323, "action": -1.5971438884735107}
{"mode": "train", "epochs": 3, "timestep": 4388, "ep_reward": 226.98541259765625, "reward": 0.583561360836029, "action": -1.0826148986816406}
{"mode": "train", "epochs": 3, "timestep": 4389, "ep_reward": 227.666259765625, "reward": 0.680851399898529, "action": -1.473520040512085}
{"mode": "train", "epochs": 3, "timestep": 4390, "ep_reward": 228.4181365966797, "reward": 0.7518825531005859, "action": -0.8330037593841553}
{"mode": "train", "epochs": 3, "timestep": 4391, "ep_reward": 229.22576904296875, "reward": 0.8076393008232117, "action": -0.39861392974853516}
{"mode": "train", "epochs": 3, "timestep": 4392, "ep_reward": 230.0726776123047, "reward": 0.8469144701957703, "action": -1.33351469039917}
{"mode": "train", "epochs": 3, "timestep": 4393, "ep_reward": 230.93309020996094, "reward": 0.8604170680046082, "action": -0.8719691038131714}
{"mode": "train", "epochs": 3, "timestep": 4394, "ep_reward": 231.79415893554688, "reward": 0.8610637784004211, "action": -0.6946481466293335}
{"mode": "train", "epochs": 3, "timestep": 4395, "ep_reward": 232.63951110839844, "reward": 0.8453536629676819, "action": -1.6652026176452637}
{"mode": "train", "epochs": 3, "timestep": 4396, "ep_reward": 233.43893432617188, "reward": 0.7994160652160645, "action": -0.8219242095947266}
{"mode": "train", "epochs": 3, "timestep": 4397, "ep_reward": 234.17355346679688, "reward": 0.7346200942993164, "action": -0.8180225491523743}
{"mode": "train", "epochs": 3, "timestep": 4398, "ep_reward": 234.81033325195312, "reward": 0.6367805600166321, "action": -1.4688676595687866}
{"mode": "train", "epochs": 3, "timestep": 4399, "ep_reward": 235.30032348632812, "reward": 0.48998332023620605, "action": 0.010254621505737305}
{"mode": "train", "epochs": 3, "timestep": 4400, "ep_reward": 235.6538848876953, "reward": 0.3535587191581726, "action": -0.4391786456108093}
{"mode": "train", "epochs": 3, "timestep": 4401, "ep_reward": 235.89805603027344, "reward": 0.24417340755462646, "action": -1.3480533361434937}
{"mode": "train", "epochs": 3, "timestep": 4402, "ep_reward": 236.01304626464844, "reward": 0.11499559879302979, "action": -0.3471219539642334}
{"mode": "train", "epochs": 3, "timestep": 4403, "ep_reward": 236.01329040527344, "reward": 0.0002442002296447754, "action": -1.2208813428878784}
{"mode": "train", "epochs": 3, "timestep": 4404, "ep_reward": 236.15850830078125, "reward": 0.14521336555480957, "action": -0.07617783546447754}
{"mode": "train", "epochs": 3, "timestep": 4405, "ep_reward": 236.45455932617188, "reward": 0.2960437536239624, "action": -0.8356332778930664}
{"mode": "train", "epochs": 3, "timestep": 4406, "ep_reward": 236.88729858398438, "reward": 0.43273645639419556, "action": -0.6573380827903748}
{"mode": "train", "epochs": 3, "timestep": 4407, "ep_reward": 237.44625854492188, "reward": 0.5589651465415955, "action": -1.4425930976867676}
{"mode": "train", "epochs": 3, "timestep": 4408, "ep_reward": 238.10400390625, "reward": 0.6577457189559937, "action": -0.7507852911949158}
{"mode": "train", "epochs": 3, "timestep": 4409, "ep_reward": 238.8467559814453, "reward": 0.7427446842193604, "action": -0.755707323551178}
{"mode": "train", "epochs": 3, "timestep": 4410, "ep_reward": 239.65269470214844, "reward": 0.8059377074241638, "action": -1.1500568389892578}
{"mode": "train", "epochs": 3, "timestep": 4411, "ep_reward": 240.4995574951172, "reward": 0.8468639850616455, "action": -0.46999412775039673}
{"mode": "train", "epochs": 3, "timestep": 4412, "ep_reward": 241.37637329101562, "reward": 0.8768224120140076, "action": -1.454785943031311}
{"mode": "train", "epochs": 3, "timestep": 4413, "ep_reward": 242.2611083984375, "reward": 0.884740948677063, "action": -0.7093178629875183}
{"mode": "train", "epochs": 3, "timestep": 4414, "ep_reward": 243.1455078125, "reward": 0.8844009637832642, "action": -1.3424279689788818}
{"mode": "train", "epochs": 3, "timestep": 4415, "ep_reward": 244.00933837890625, "reward": 0.8638271689414978, "action": -0.29835045337677}
{"mode": "train", "epochs": 3, "timestep": 4416, "ep_reward": 244.84344482421875, "reward": 0.8341005444526672, "action": -0.9937799572944641}
{"mode": "train", "epochs": 3, "timestep": 4417, "ep_reward": 245.61917114257812, "reward": 0.7757253646850586, "action": -1.21541166305542}
{"mode": "train", "epochs": 3, "timestep": 4418, "ep_reward": 246.30453491210938, "reward": 0.6853703260421753, "action": -0.36667466163635254}
{"mode": "train", "epochs": 3, "timestep": 4419, "ep_reward": 246.874267578125, "reward": 0.5697376728057861, "action": -1.0429335832595825}
{"mode": "train", "epochs": 3, "timestep": 4420, "ep_reward": 247.28048706054688, "reward": 0.4062233567237854, "action": -0.6523515582084656}
{"mode": "train", "epochs": 3, "timestep": 4421, "ep_reward": 247.55943298339844, "reward": 0.2789419889450073, "action": -1.7789292335510254}
{"mode": "train", "epochs": 3, "timestep": 4422, "ep_reward": 247.71527099609375, "reward": 0.1558455228805542, "action": 0.2723947763442993}
{"mode": "train", "epochs": 3, "timestep": 4423, "ep_reward": 247.72779846191406, "reward": 0.012528717517852783, "action": -0.713212788105011}
{"mode": "train", "epochs": 3, "timestep": 4424, "ep_reward": 247.83169555664062, "reward": 0.10389035940170288, "action": -0.1133044958114624}
{"mode": "train", "epochs": 3, "timestep": 4425, "ep_reward": 248.08480834960938, "reward": 0.2531067132949829, "action": -1.6807310581207275}
{"mode": "train", "epochs": 3, "timestep": 4426, "ep_reward": 248.4664306640625, "reward": 0.3816251754760742, "action": -0.869109570980072}
{"mode": "train", "epochs": 3, "timestep": 4427, "ep_reward": 248.9788055419922, "reward": 0.5123814940452576, "action": -0.8140674829483032}
{"mode": "train", "epochs": 3, "timestep": 4428, "ep_reward": 249.6045684814453, "reward": 0.6257585883140564, "action": -1.6886835098266602}
{"mode": "train", "epochs": 3, "timestep": 4429, "ep_reward": 250.31307983398438, "reward": 0.7085129022598267, "action": -0.9782853126525879}
{"mode": "train", "epochs": 3, "timestep": 4430, "ep_reward": 251.0900115966797, "reward": 0.7769267559051514, "action": -1.6250934600830078}
{"mode": "train", "epochs": 3, "timestep": 4431, "ep_reward": 251.90887451171875, "reward": 0.818856954574585, "action": -0.5471011400222778}
{"mode": "train", "epochs": 3, "timestep": 4432, "ep_reward": 252.76055908203125, "reward": 0.8516842722892761, "action": -0.8051756620407104}
{"mode": "train", "epochs": 3, "timestep": 4433, "ep_reward": 253.62535095214844, "reward": 0.8647944331169128, "action": -0.7617236375808716}
{"mode": "train", "epochs": 3, "timestep": 4434, "ep_reward": 254.4869384765625, "reward": 0.8615907430648804, "action": -0.1474151611328125}
{"mode": "train", "epochs": 3, "timestep": 4435, "ep_reward": 255.33311462402344, "reward": 0.8461728096008301, "action": -0.8338185548782349}
{"mode": "train", "epochs": 3, "timestep": 4436, "ep_reward": 256.1372985839844, "reward": 0.8041927218437195, "action": -0.8251758813858032}
{"mode": "train", "epochs": 3, "timestep": 4437, "ep_reward": 256.8736877441406, "reward": 0.7363923192024231, "action": -0.2488420009613037}
{"mode": "train", "epochs": 3, "timestep": 4438, "ep_reward": 257.5174255371094, "reward": 0.6437435150146484, "action": 0.09175670146942139}
{"mode": "train", "epochs": 3, "timestep": 4439, "ep_reward": 258.03814697265625, "reward": 0.5207356214523315, "action": -1.3477153778076172}
{"mode": "train", "epochs": 3, "timestep": 4440, "ep_reward": 258.38592529296875, "reward": 0.347792387008667, "action": 0.0496143102645874}
{"mode": "train", "epochs": 3, "timestep": 4441, "ep_reward": 258.6231384277344, "reward": 0.23720109462738037, "action": -1.551724910736084}
{"mode": "train", "epochs": 3, "timestep": 4442, "ep_reward": 258.7299499511719, "reward": 0.10680234432220459, "action": -1.315138578414917}
{"mode": "train", "epochs": 3, "timestep": 4443, "ep_reward": 258.7391662597656, "reward": 0.009210705757141113, "action": -0.9348738789558411}
{"mode": "train", "epochs": 3, "timestep": 4444, "ep_reward": 258.8920593261719, "reward": 0.1529064178466797, "action": -1.116723895072937}
{"mode": "train", "epochs": 3, "timestep": 4445, "ep_reward": 259.18310546875, "reward": 0.291046142578125, "action": -1.1370962858200073}
{"mode": "train", "epochs": 3, "timestep": 4446, "ep_reward": 259.6095275878906, "reward": 0.42641139030456543, "action": -0.5519809722900391}
{"mode": "train", "epochs": 3, "timestep": 4447, "ep_reward": 260.16552734375, "reward": 0.5559929609298706, "action": -1.0998728275299072}
{"mode": "train", "epochs": 3, "timestep": 4448, "ep_reward": 260.8241271972656, "reward": 0.6585999727249146, "action": -1.6223361492156982}
{"mode": "train", "epochs": 3, "timestep": 4449, "ep_reward": 261.5581359863281, "reward": 0.7340084314346313, "action": -1.2875292301177979}
{"mode": "train", "epochs": 3, "timestep": 4450, "ep_reward": 262.3496398925781, "reward": 0.7915141582489014, "action": -0.8823351263999939}
{"mode": "train", "epochs": 3, "timestep": 4451, "ep_reward": 263.1820068359375, "reward": 0.8323527574539185, "action": -1.0549538135528564}
{"mode": "train", "epochs": 3, "timestep": 4452, "ep_reward": 264.0350036621094, "reward": 0.8529883027076721, "action": -1.255866527557373}
{"mode": "train", "epochs": 3, "timestep": 4453, "ep_reward": 264.8893127441406, "reward": 0.8543192148208618, "action": -1.0227097272872925}
{"mode": "train", "epochs": 3, "timestep": 4454, "ep_reward": 265.72845458984375, "reward": 0.8391544818878174, "action": -0.8012760281562805}
{"mode": "train", "epochs": 3, "timestep": 4455, "ep_reward": 266.533203125, "reward": 0.8047602772712708, "action": -0.9341966509819031}
{"mode": "train", "epochs": 3, "timestep": 4456, "ep_reward": 267.2760925292969, "reward": 0.742892324924469, "action": -1.523573637008667}
{"mode": "train", "epochs": 3, "timestep": 4457, "ep_reward": 267.91656494140625, "reward": 0.6404764652252197, "action": -1.4086145162582397}
{"mode": "train", "epochs": 3, "timestep": 4458, "ep_reward": 268.4137878417969, "reward": 0.49722522497177124, "action": -1.1414369344711304}
{"mode": "train", "epochs": 3, "timestep": 4459, "ep_reward": 268.7783203125, "reward": 0.3645368218421936, "action": -1.452650547027588}
{"mode": "train", "epochs": 3, "timestep": 4460, "ep_reward": 269.0359191894531, "reward": 0.257590115070343, "action": -0.9491459727287292}
{"mode": "train", "epochs": 3, "timestep": 4461, "ep_reward": 269.1664123535156, "reward": 0.1304832100868225, "action": -1.5144870281219482}
{"mode": "train", "epochs": 3, "timestep": 4462, "ep_reward": 269.14996337890625, "reward": -0.01645803451538086, "action": -1.0224616527557373}
{"mode": "train", "epochs": 3, "timestep": 4463, "ep_reward": 269.27972412109375, "reward": 0.12974923849105835, "action": -1.1209148168563843}
{"mode": "train", "epochs": 3, "timestep": 4464, "ep_reward": 269.5470886230469, "reward": 0.2673719525337219, "action": -0.32001936435699463}
{"mode": "train", "epochs": 3, "timestep": 4465, "ep_reward": 269.9607849121094, "reward": 0.41370272636413574, "action": -0.740636944770813}
{"mode": "train", "epochs": 3, "timestep": 4466, "ep_reward": 270.5027160644531, "reward": 0.541939377784729, "action": -1.0982074737548828}
{"mode": "train", "epochs": 3, "timestep": 4467, "ep_reward": 271.1499938964844, "reward": 0.6472911238670349, "action": -0.7611069679260254}
{"mode": "train", "epochs": 3, "timestep": 4468, "ep_reward": 271.88427734375, "reward": 0.734298586845398, "action": -1.4196701049804688}
{"mode": "train", "epochs": 3, "timestep": 4469, "ep_reward": 272.6777038574219, "reward": 0.7934368252754211, "action": -1.3297533988952637}
{"mode": "train", "epochs": 3, "timestep": 4470, "ep_reward": 273.51202392578125, "reward": 0.8343112468719482, "action": -1.8948854207992554}
{"mode": "train", "epochs": 3, "timestep": 4471, "ep_reward": 274.3654479980469, "reward": 0.8534237146377563, "action": -0.5879027843475342}
{"mode": "train", "epochs": 3, "timestep": 4472, "ep_reward": 275.2325439453125, "reward": 0.8670970797538757, "action": -0.507818877696991}
{"mode": "train", "epochs": 3, "timestep": 4473, "ep_reward": 276.09747314453125, "reward": 0.8649212718009949, "action": -0.9201005697250366}
{"mode": "train", "epochs": 3, "timestep": 4474, "ep_reward": 276.9389343261719, "reward": 0.8414700031280518, "action": -1.320310115814209}
{"mode": "train", "epochs": 3, "timestep": 4475, "ep_reward": 277.73138427734375, "reward": 0.7924641370773315, "action": -0.9490546584129333}
{"mode": "train", "epochs": 3, "timestep": 4476, "ep_reward": 278.4505920410156, "reward": 0.7192118167877197, "action": -0.7192221283912659}
{"mode": "train", "epochs": 3, "timestep": 4477, "ep_reward": 279.0651550292969, "reward": 0.6145617961883545, "action": -1.03059720993042}
{"mode": "train", "epochs": 3, "timestep": 4478, "ep_reward": 279.5311279296875, "reward": 0.46597468852996826, "action": -1.1633542776107788}
{"mode": "train", "epochs": 3, "timestep": 4479, "ep_reward": 279.8614501953125, "reward": 0.33033376932144165, "action": -0.621591329574585}
{"mode": "train", "epochs": 3, "timestep": 4480, "ep_reward": 280.07794189453125, "reward": 0.21648448705673218, "action": -0.5820238590240479}
{"mode": "train", "epochs": 3, "timestep": 4481, "ep_reward": 280.1604919433594, "reward": 0.08255255222320557, "action": -1.274148941040039}
{"mode": "train", "epochs": 3, "timestep": 4482, "ep_reward": 280.1956787109375, "reward": 0.03519934415817261, "action": -0.21517884731292725}
{"mode": "train", "epochs": 3, "timestep": 4483, "ep_reward": 280.3768310546875, "reward": 0.181147038936615, "action": -1.3077428340911865}
{"mode": "train", "epochs": 3, "timestep": 4484, "ep_reward": 280.6930236816406, "reward": 0.3161981701850891, "action": -1.1500073671340942}
{"mode": "train", "epochs": 3, "timestep": 4485, "ep_reward": 281.1424560546875, "reward": 0.4494377374649048, "action": -1.2314950227737427}
{"mode": "train", "epochs": 3, "timestep": 4486, "ep_reward": 281.7105407714844, "reward": 0.5680991411209106, "action": -1.5757861137390137}
{"mode": "train", "epochs": 3, "timestep": 4487, "ep_reward": 282.3738708496094, "reward": 0.663332998752594, "action": -1.2726494073867798}
{"mode": "train", "epochs": 3, "timestep": 4488, "ep_reward": 283.11370849609375, "reward": 0.739830732345581, "action": -1.0165959596633911}
{"mode": "train", "epochs": 3, "timestep": 4489, "ep_reward": 283.9100341796875, "reward": 0.796325147151947, "action": -1.7972404956817627}
{"mode": "train", "epochs": 3, "timestep": 4490, "ep_reward": 284.7351379394531, "reward": 0.8250893354415894, "action": -1.4774495363235474}
{"mode": "train", "epochs": 3, "timestep": 4491, "ep_reward": 285.57281494140625, "reward": 0.8376758694648743, "action": -0.9517768025398254}
{"mode": "train", "epochs": 3, "timestep": 4492, "ep_reward": 286.4081115722656, "reward": 0.8352965116500854, "action": -1.7713737487792969}
{"mode": "train", "epochs": 3, "timestep": 4493, "ep_reward": 287.2113037109375, "reward": 0.803187370300293, "action": -1.495222806930542}
{"mode": "train", "epochs": 3, "timestep": 4494, "ep_reward": 287.9577941894531, "reward": 0.7464934587478638, "action": -0.7330429553985596}
{"mode": "train", "epochs": 3, "timestep": 4495, "ep_reward": 288.6230773925781, "reward": 0.6652787923812866, "action": 0.45961952209472656}
{"mode": "train", "epochs": 3, "timestep": 4496, "ep_reward": 289.18597412109375, "reward": 0.5628910064697266, "action": -1.3471434116363525}
{"mode": "train", "epochs": 3, "timestep": 4497, "ep_reward": 289.5887145996094, "reward": 0.40274250507354736, "action": -0.6554726362228394}
{"mode": "train", "epochs": 3, "timestep": 4498, "ep_reward": 289.89263916015625, "reward": 0.30392396450042725, "action": -0.642155647277832}
{"mode": "train", "epochs": 3, "timestep": 4499, "ep_reward": 290.0777587890625, "reward": 0.18511885404586792, "action": -0.43571382761001587}
{"mode": "train", "epochs": 3, "timestep": 4500, "ep_reward": 290.1240234375, "reward": 0.04626333713531494, "action": -0.8855174779891968}
{"mode": "train", "epochs": 3, "timestep": 4501, "ep_reward": 290.19586181640625, "reward": 0.07182979583740234, "action": -1.1540076732635498}
{"mode": "train", "epochs": 3, "timestep": 4502, "ep_reward": 290.4031982421875, "reward": 0.20734792947769165, "action": -0.59565669298172}
{"mode": "train", "epochs": 3, "timestep": 4503, "ep_reward": 290.75592041015625, "reward": 0.3527348041534424, "action": 0.12243449687957764}
{"mode": "train", "epochs": 3, "timestep": 4504, "ep_reward": 291.2538146972656, "reward": 0.4978848695755005, "action": -0.40589016675949097}
{"mode": "train", "epochs": 3, "timestep": 4505, "ep_reward": 291.8714904785156, "reward": 0.6176636815071106, "action": -0.8239407539367676}
{"mode": "train", "epochs": 3, "timestep": 4506, "ep_reward": 292.5826721191406, "reward": 0.7111782431602478, "action": -0.8611822724342346}
{"mode": "train", "epochs": 3, "timestep": 4507, "ep_reward": 293.36541748046875, "reward": 0.7827407121658325, "action": -1.3067724704742432}
{"mode": "train", "epochs": 3, "timestep": 4508, "ep_reward": 294.1965026855469, "reward": 0.8310729265213013, "action": -1.1235685348510742}
{"mode": "train", "epochs": 3, "timestep": 4509, "ep_reward": 295.0607604980469, "reward": 0.8642446994781494, "action": -1.4102360010147095}
{"mode": "train", "epochs": 3, "timestep": 4510, "ep_reward": 295.9412536621094, "reward": 0.8804932832717896, "action": -0.781488299369812}
{"mode": "train", "epochs": 3, "timestep": 4511, "ep_reward": 296.8288269042969, "reward": 0.8875853419303894, "action": -1.4881606101989746}
{"mode": "train", "epochs": 3, "timestep": 4512, "ep_reward": 297.70361328125, "reward": 0.8747749328613281, "action": -1.2797507047653198}
{"mode": "train", "epochs": 3, "timestep": 4513, "ep_reward": 298.5502014160156, "reward": 0.8465984463691711, "action": -0.8601916432380676}
{"mode": "train", "epochs": 3, "timestep": 4514, "ep_reward": 299.35137939453125, "reward": 0.8011762499809265, "action": -0.39875322580337524}
{"mode": "train", "epochs": 3, "timestep": 4515, "ep_reward": 300.08599853515625, "reward": 0.7346323132514954, "action": -1.64568030834198}
{"mode": "train", "epochs": 3, "timestep": 4516, "ep_reward": 300.7068786621094, "reward": 0.6208695769309998, "action": -0.13934803009033203}
{"mode": "train", "epochs": 3, "timestep": 4517, "ep_reward": 301.19439697265625, "reward": 0.48751652240753174, "action": -0.9727967381477356}
{"mode": "train", "epochs": 3, "timestep": 4518, "ep_reward": 301.5260925292969, "reward": 0.3317035436630249, "action": -1.4791538715362549}
{"mode": "train", "epochs": 3, "timestep": 4519, "ep_reward": 301.74432373046875, "reward": 0.21824079751968384, "action": -0.7278451919555664}
{"mode": "train", "epochs": 3, "timestep": 4520, "ep_reward": 301.8290100097656, "reward": 0.08468347787857056, "action": -0.6278702616691589}
{"mode": "train", "epochs": 3, "timestep": 4521, "ep_reward": 301.86181640625, "reward": 0.03280198574066162, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4522, "ep_reward": 302.0352478027344, "reward": 0.17343789339065552, "action": -1.8061740398406982}
{"mode": "train", "epochs": 3, "timestep": 4523, "ep_reward": 302.33868408203125, "reward": 0.30343008041381836, "action": -0.7995891571044922}
{"mode": "train", "epochs": 3, "timestep": 4524, "ep_reward": 302.78204345703125, "reward": 0.4433690309524536, "action": -0.8034226298332214}
{"mode": "train", "epochs": 3, "timestep": 4525, "ep_reward": 303.3500061035156, "reward": 0.5679750442504883, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4526, "ep_reward": 304.0085754394531, "reward": 0.6585808396339417, "action": -1.4956588745117188}
{"mode": "train", "epochs": 3, "timestep": 4527, "ep_reward": 304.7415466308594, "reward": 0.7329720854759216, "action": -1.6469205617904663}
{"mode": "train", "epochs": 3, "timestep": 4528, "ep_reward": 305.5249328613281, "reward": 0.783376157283783, "action": -1.1652393341064453}
{"mode": "train", "epochs": 3, "timestep": 4529, "ep_reward": 306.34185791015625, "reward": 0.816933810710907, "action": -0.6891285181045532}
{"mode": "train", "epochs": 3, "timestep": 4530, "ep_reward": 307.17596435546875, "reward": 0.8341187238693237, "action": -0.8277304172515869}
{"mode": "train", "epochs": 3, "timestep": 4531, "ep_reward": 308.0052490234375, "reward": 0.8292982578277588, "action": -1.6903643608093262}
{"mode": "train", "epochs": 3, "timestep": 4532, "ep_reward": 308.798583984375, "reward": 0.7933260798454285, "action": -1.029713749885559}
{"mode": "train", "epochs": 3, "timestep": 4533, "ep_reward": 309.53472900390625, "reward": 0.7361430525779724, "action": -0.12928646802902222}
{"mode": "train", "epochs": 3, "timestep": 4534, "ep_reward": 310.19146728515625, "reward": 0.6567299365997314, "action": -1.2143604755401611}
{"mode": "train", "epochs": 3, "timestep": 4535, "ep_reward": 310.7159118652344, "reward": 0.5244512557983398, "action": -0.9361521005630493}
{"mode": "train", "epochs": 3, "timestep": 4536, "ep_reward": 311.1024475097656, "reward": 0.3865247368812561, "action": -0.7957255840301514}
{"mode": "train", "epochs": 3, "timestep": 4537, "ep_reward": 311.3865966796875, "reward": 0.28415727615356445, "action": -0.4110722541809082}
{"mode": "train", "epochs": 3, "timestep": 4538, "ep_reward": 311.5483093261719, "reward": 0.16171056032180786, "action": -0.9905562996864319}
{"mode": "train", "epochs": 3, "timestep": 4539, "ep_reward": 311.5676574707031, "reward": 0.019333362579345703, "action": -0.8319244980812073}
{"mode": "train", "epochs": 3, "timestep": 4540, "ep_reward": 311.6651916503906, "reward": 0.09752321243286133, "action": -1.0045208930969238}
{"mode": "train", "epochs": 3, "timestep": 4541, "ep_reward": 311.90081787109375, "reward": 0.23561501502990723, "action": -1.253626823425293}
{"mode": "train", "epochs": 3, "timestep": 4542, "ep_reward": 312.2724914550781, "reward": 0.3716810345649719, "action": -0.8824566006660461}
{"mode": "train", "epochs": 3, "timestep": 4543, "ep_reward": 312.7763671875, "reward": 0.5038808584213257, "action": -1.1020123958587646}
{"mode": "train", "epochs": 3, "timestep": 4544, "ep_reward": 313.3922424316406, "reward": 0.6158673763275146, "action": -0.7200101613998413}
{"mode": "train", "epochs": 3, "timestep": 4545, "ep_reward": 314.1018981933594, "reward": 0.7096459865570068, "action": -1.9261431694030762}
{"mode": "train", "epochs": 3, "timestep": 4546, "ep_reward": 314.870849609375, "reward": 0.768963634967804, "action": -1.2702406644821167}
{"mode": "train", "epochs": 3, "timestep": 4547, "ep_reward": 315.6851501464844, "reward": 0.8142935037612915, "action": -1.0233628749847412}
{"mode": "train", "epochs": 3, "timestep": 4548, "ep_reward": 316.5275573730469, "reward": 0.8424020409584045, "action": -0.4674186110496521}
{"mode": "train", "epochs": 3, "timestep": 4549, "ep_reward": 317.3844909667969, "reward": 0.8569357395172119, "action": -1.6597044467926025}
{"mode": "train", "epochs": 3, "timestep": 4550, "ep_reward": 318.227294921875, "reward": 0.8428118824958801, "action": -0.8831329345703125}
{"mode": "train", "epochs": 3, "timestep": 4551, "ep_reward": 319.04229736328125, "reward": 0.8149975538253784, "action": -1.140965223312378}
{"mode": "train", "epochs": 3, "timestep": 4552, "ep_reward": 319.8018798828125, "reward": 0.7595770955085754, "action": -1.0825179815292358}
{"mode": "train", "epochs": 3, "timestep": 4553, "ep_reward": 320.4749450683594, "reward": 0.6730677485466003, "action": 0.501132607460022}
{"mode": "train", "epochs": 3, "timestep": 4554, "ep_reward": 321.04559326171875, "reward": 0.570661723613739, "action": -1.651056170463562}
{"mode": "train", "epochs": 3, "timestep": 4555, "ep_reward": 321.44390869140625, "reward": 0.398323655128479, "action": -0.4252045154571533}
{"mode": "train", "epochs": 3, "timestep": 4556, "ep_reward": 321.7397766113281, "reward": 0.29587727785110474, "action": -1.2728819847106934}
{"mode": "train", "epochs": 3, "timestep": 4557, "ep_reward": 321.91534423828125, "reward": 0.17555689811706543, "action": -1.5354442596435547}
{"mode": "train", "epochs": 3, "timestep": 4558, "ep_reward": 321.95068359375, "reward": 0.03533238172531128, "action": -1.2530930042266846}
{"mode": "train", "epochs": 3, "timestep": 4559, "ep_reward": 322.0331115722656, "reward": 0.08242213726043701, "action": -0.4621121883392334}
{"mode": "train", "epochs": 3, "timestep": 4560, "ep_reward": 322.259765625, "reward": 0.22664165496826172, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4561, "ep_reward": 322.6125183105469, "reward": 0.3527458906173706, "action": -0.9535074234008789}
{"mode": "train", "epochs": 3, "timestep": 4562, "ep_reward": 323.09881591796875, "reward": 0.48628634214401245, "action": -0.9755550026893616}
{"mode": "train", "epochs": 3, "timestep": 4563, "ep_reward": 323.701416015625, "reward": 0.6025943756103516, "action": -0.8515244722366333}
{"mode": "train", "epochs": 3, "timestep": 4564, "ep_reward": 324.3994140625, "reward": 0.6979870796203613, "action": -1.346402883529663}
{"mode": "train", "epochs": 3, "timestep": 4565, "ep_reward": 325.1647033691406, "reward": 0.7652817368507385, "action": -1.431827187538147}
{"mode": "train", "epochs": 3, "timestep": 4566, "ep_reward": 325.975341796875, "reward": 0.8106241226196289, "action": -1.9432823657989502}
{"mode": "train", "epochs": 3, "timestep": 4567, "ep_reward": 326.80755615234375, "reward": 0.8322058320045471, "action": -0.1862056851387024}
{"mode": "train", "epochs": 3, "timestep": 4568, "ep_reward": 327.6584167480469, "reward": 0.8508639335632324, "action": -0.5282468199729919}
{"mode": "train", "epochs": 3, "timestep": 4569, "ep_reward": 328.5060119628906, "reward": 0.8475894927978516, "action": -1.691842794418335}
{"mode": "train", "epochs": 3, "timestep": 4570, "ep_reward": 329.319091796875, "reward": 0.8130942583084106, "action": -1.608651876449585}
{"mode": "train", "epochs": 3, "timestep": 4571, "ep_reward": 330.07196044921875, "reward": 0.7528782486915588, "action": -1.3433154821395874}
{"mode": "train", "epochs": 3, "timestep": 4572, "ep_reward": 330.73394775390625, "reward": 0.6619812250137329, "action": -0.9073906540870667}
{"mode": "train", "epochs": 3, "timestep": 4573, "ep_reward": 331.2703857421875, "reward": 0.536424994468689, "action": -1.5847458839416504}
{"mode": "train", "epochs": 3, "timestep": 4574, "ep_reward": 331.6622009277344, "reward": 0.3918074369430542, "action": -1.4336013793945312}
{"mode": "train", "epochs": 3, "timestep": 4575, "ep_reward": 331.9529113769531, "reward": 0.29070615768432617, "action": -0.23014557361602783}
{"mode": "train", "epochs": 3, "timestep": 4576, "ep_reward": 332.1222229003906, "reward": 0.16931265592575073, "action": -1.6539950370788574}
{"mode": "train", "epochs": 3, "timestep": 4577, "ep_reward": 332.1503601074219, "reward": 0.028123199939727783, "action": -1.4716819524765015}
{"mode": "train", "epochs": 3, "timestep": 4578, "ep_reward": 332.23944091796875, "reward": 0.08907490968704224, "action": -1.7123794555664062}
{"mode": "train", "epochs": 3, "timestep": 4579, "ep_reward": 332.46148681640625, "reward": 0.22205662727355957, "action": -1.4537657499313354}
{"mode": "train", "epochs": 3, "timestep": 4580, "ep_reward": 332.81842041015625, "reward": 0.35692745447158813, "action": -0.5141364336013794}
{"mode": "train", "epochs": 3, "timestep": 4581, "ep_reward": 333.314208984375, "reward": 0.49579381942749023, "action": 0.13117659091949463}
{"mode": "train", "epochs": 3, "timestep": 4582, "ep_reward": 333.936767578125, "reward": 0.622552752494812, "action": 0.17804372310638428}
{"mode": "train", "epochs": 3, "timestep": 4583, "ep_reward": 334.6608581542969, "reward": 0.7240976095199585, "action": -1.4170143604278564}
{"mode": "train", "epochs": 3, "timestep": 4584, "ep_reward": 335.4477844238281, "reward": 0.7869253158569336, "action": -1.4713587760925293}
{"mode": "train", "epochs": 3, "timestep": 4585, "ep_reward": 336.2784118652344, "reward": 0.8306324481964111, "action": -0.8718194961547852}
{"mode": "train", "epochs": 3, "timestep": 4586, "ep_reward": 337.1405029296875, "reward": 0.8620889782905579, "action": -1.834981918334961}
{"mode": "train", "epochs": 3, "timestep": 4587, "ep_reward": 338.0107727050781, "reward": 0.8702740669250488, "action": -0.5100123882293701}
{"mode": "train", "epochs": 3, "timestep": 4588, "ep_reward": 338.88458251953125, "reward": 0.8738135695457458, "action": -1.0929969549179077}
{"mode": "train", "epochs": 3, "timestep": 4589, "ep_reward": 339.7406311035156, "reward": 0.8560347557067871, "action": -1.5700523853302002}
{"mode": "train", "epochs": 3, "timestep": 4590, "ep_reward": 340.5545654296875, "reward": 0.813935399055481, "action": -1.3437777757644653}
{"mode": "train", "epochs": 3, "timestep": 4591, "ep_reward": 341.3022766113281, "reward": 0.7477092742919922, "action": -1.1205172538757324}
{"mode": "train", "epochs": 3, "timestep": 4592, "ep_reward": 341.95306396484375, "reward": 0.6507849097251892, "action": -1.4142160415649414}
{"mode": "train", "epochs": 3, "timestep": 4593, "ep_reward": 342.4627380371094, "reward": 0.5096721053123474, "action": -1.5964608192443848}
{"mode": "train", "epochs": 3, "timestep": 4594, "ep_reward": 342.8270568847656, "reward": 0.36431950330734253, "action": -0.5012738704681396}
{"mode": "train", "epochs": 3, "timestep": 4595, "ep_reward": 343.08428955078125, "reward": 0.25723153352737427, "action": -0.4868185520172119}
{"mode": "train", "epochs": 3, "timestep": 4596, "ep_reward": 343.2142639160156, "reward": 0.1299859881401062, "action": -1.659416913986206}
{"mode": "train", "epochs": 3, "timestep": 4597, "ep_reward": 343.1974182128906, "reward": -0.0168454647064209, "action": -1.0912902355194092}
{"mode": "train", "epochs": 3, "timestep": 4598, "ep_reward": 343.3276672363281, "reward": 0.1302417516708374, "action": -0.9347843527793884}
{"mode": "train", "epochs": 3, "timestep": 4599, "ep_reward": 343.59771728515625, "reward": 0.27003729343414307, "action": -1.5654526948928833}
{"mode": "train", "epochs": 3, "timestep": 4600, "ep_reward": 343.9984436035156, "reward": 0.40072983503341675, "action": -1.7240910530090332}
{"mode": "train", "epochs": 3, "timestep": 4601, "ep_reward": 344.51849365234375, "reward": 0.5200579166412354, "action": -1.9209434986114502}
{"mode": "train", "epochs": 3, "timestep": 4602, "ep_reward": 345.1385192871094, "reward": 0.6200377941131592, "action": -1.9176112413406372}
{"mode": "train", "epochs": 3, "timestep": 4603, "ep_reward": 345.8373107910156, "reward": 0.6988052129745483, "action": -0.9110665917396545}
{"mode": "train", "epochs": 3, "timestep": 4604, "ep_reward": 346.6019287109375, "reward": 0.7646181583404541, "action": -0.9746749401092529}
{"mode": "train", "epochs": 3, "timestep": 4605, "ep_reward": 347.4079895019531, "reward": 0.8060741424560547, "action": -1.0174345970153809}
{"mode": "train", "epochs": 3, "timestep": 4606, "ep_reward": 348.23333740234375, "reward": 0.8253421187400818, "action": -0.7906568050384521}
{"mode": "train", "epochs": 3, "timestep": 4607, "ep_reward": 349.0588684082031, "reward": 0.8255400657653809, "action": -1.1232253313064575}
{"mode": "train", "epochs": 3, "timestep": 4608, "ep_reward": 349.8587646484375, "reward": 0.7998934388160706, "action": -0.4745265245437622}
{"mode": "train", "epochs": 3, "timestep": 4609, "ep_reward": 350.6136474609375, "reward": 0.7548863291740417, "action": 0.09361886978149414}
{"mode": "train", "epochs": 3, "timestep": 4610, "ep_reward": 351.3001403808594, "reward": 0.686485767364502, "action": -0.5988616943359375}
{"mode": "train", "epochs": 3, "timestep": 4611, "ep_reward": 351.87432861328125, "reward": 0.5741762518882751, "action": -1.2555665969848633}
{"mode": "train", "epochs": 3, "timestep": 4612, "ep_reward": 352.28460693359375, "reward": 0.41028380393981934, "action": -1.1116371154785156}
{"mode": "train", "epochs": 3, "timestep": 4613, "ep_reward": 352.59521484375, "reward": 0.31059736013412476, "action": -1.1910263299942017}
{"mode": "train", "epochs": 3, "timestep": 4614, "ep_reward": 352.7882995605469, "reward": 0.19308555126190186, "action": -0.6522775888442993}
{"mode": "train", "epochs": 3, "timestep": 4615, "ep_reward": 352.84381103515625, "reward": 0.055512428283691406, "action": -0.6494373083114624}
{"mode": "train", "epochs": 3, "timestep": 4616, "ep_reward": 352.90655517578125, "reward": 0.06273770332336426, "action": -1.1862351894378662}
{"mode": "train", "epochs": 3, "timestep": 4617, "ep_reward": 353.1057434082031, "reward": 0.19919484853744507, "action": -1.8470287322998047}
{"mode": "train", "epochs": 3, "timestep": 4618, "ep_reward": 353.43475341796875, "reward": 0.32900893688201904, "action": -0.9599837064743042}
{"mode": "train", "epochs": 3, "timestep": 4619, "ep_reward": 353.900146484375, "reward": 0.4653869867324829, "action": -0.017266929149627686}
{"mode": "train", "epochs": 3, "timestep": 4620, "ep_reward": 354.49603271484375, "reward": 0.5958749055862427, "action": -0.8003644943237305}
{"mode": "train", "epochs": 3, "timestep": 4621, "ep_reward": 355.1894226074219, "reward": 0.6933944821357727, "action": -1.5085651874542236}
{"mode": "train", "epochs": 3, "timestep": 4622, "ep_reward": 355.95050048828125, "reward": 0.7610640525817871, "action": -0.8845374584197998}
{"mode": "train", "epochs": 3, "timestep": 4623, "ep_reward": 356.7640380859375, "reward": 0.8135422468185425, "action": -1.5243326425552368}
{"mode": "train", "epochs": 3, "timestep": 4624, "ep_reward": 357.6048278808594, "reward": 0.8407920002937317, "action": -1.9034903049468994}
{"mode": "train", "epochs": 3, "timestep": 4625, "ep_reward": 358.4518737792969, "reward": 0.8470607399940491, "action": -0.7178940773010254}
{"mode": "train", "epochs": 3, "timestep": 4626, "ep_reward": 359.2972106933594, "reward": 0.8453330397605896, "action": -1.3583714962005615}
{"mode": "train", "epochs": 3, "timestep": 4627, "ep_reward": 360.1145324707031, "reward": 0.817328929901123, "action": -0.9766263365745544}
{"mode": "train", "epochs": 3, "timestep": 4628, "ep_reward": 360.8828430175781, "reward": 0.7683038711547852, "action": -1.1887218952178955}
{"mode": "train", "epochs": 3, "timestep": 4629, "ep_reward": 361.5689392089844, "reward": 0.6860865950584412, "action": -1.190017819404602}
{"mode": "train", "epochs": 3, "timestep": 4630, "ep_reward": 362.1342468261719, "reward": 0.5653155446052551, "action": -0.49157631397247314}
{"mode": "train", "epochs": 3, "timestep": 4631, "ep_reward": 362.5459899902344, "reward": 0.4117546081542969, "action": -0.9982557892799377}
{"mode": "train", "epochs": 3, "timestep": 4632, "ep_reward": 362.8560485839844, "reward": 0.31007128953933716, "action": -0.8323846459388733}
{"mode": "train", "epochs": 3, "timestep": 4633, "ep_reward": 363.04840087890625, "reward": 0.19235467910766602, "action": -1.1309418678283691}
{"mode": "train", "epochs": 3, "timestep": 4634, "ep_reward": 363.10308837890625, "reward": 0.05469232797622681, "action": -1.0028691291809082}
{"mode": "train", "epochs": 3, "timestep": 4635, "ep_reward": 363.1666259765625, "reward": 0.06354057788848877, "action": -1.0037555694580078}
{"mode": "train", "epochs": 3, "timestep": 4636, "ep_reward": 363.36724853515625, "reward": 0.2006087303161621, "action": -1.1768929958343506}
{"mode": "train", "epochs": 3, "timestep": 4637, "ep_reward": 363.705810546875, "reward": 0.33855336904525757, "action": -1.4737192392349243}
{"mode": "train", "epochs": 3, "timestep": 4638, "ep_reward": 364.1726379394531, "reward": 0.4668393135070801, "action": -1.707383394241333}
{"mode": "train", "epochs": 3, "timestep": 4639, "ep_reward": 364.7506103515625, "reward": 0.5779802799224854, "action": -1.524635910987854}
{"mode": "train", "epochs": 3, "timestep": 4640, "ep_reward": 365.4215393066406, "reward": 0.6709293723106384, "action": -1.2922565937042236}
{"mode": "train", "epochs": 3, "timestep": 4641, "ep_reward": 366.1645202636719, "reward": 0.7429760098457336, "action": -1.7519032955169678}
{"mode": "train", "epochs": 3, "timestep": 4642, "ep_reward": 366.9519958496094, "reward": 0.7874695062637329, "action": -1.2208353281021118}
{"mode": "train", "epochs": 3, "timestep": 4643, "ep_reward": 367.76727294921875, "reward": 0.8152760863304138, "action": -1.7058279514312744}
{"mode": "train", "epochs": 3, "timestep": 4644, "ep_reward": 368.5840759277344, "reward": 0.8168120384216309, "action": -1.1720184087753296}
{"mode": "train", "epochs": 3, "timestep": 4645, "ep_reward": 369.3846130371094, "reward": 0.8005491495132446, "action": -0.5200439691543579}
{"mode": "train", "epochs": 3, "timestep": 4646, "ep_reward": 370.14971923828125, "reward": 0.7651193141937256, "action": -1.3803772926330566}
{"mode": "train", "epochs": 3, "timestep": 4647, "ep_reward": 370.8385925292969, "reward": 0.6888830661773682, "action": -0.7651696801185608}
{"mode": "train", "epochs": 3, "timestep": 4648, "ep_reward": 371.4201965332031, "reward": 0.5816057324409485, "action": -1.002874493598938}
{"mode": "train", "epochs": 3, "timestep": 4649, "ep_reward": 371.85064697265625, "reward": 0.43044614791870117, "action": -0.2936018705368042}
{"mode": "train", "epochs": 3, "timestep": 4650, "ep_reward": 372.18853759765625, "reward": 0.3379042148590088, "action": -1.7724244594573975}
{"mode": "train", "epochs": 3, "timestep": 4651, "ep_reward": 372.4142761230469, "reward": 0.22572475671768188, "action": -0.6378774642944336}
{"mode": "train", "epochs": 3, "timestep": 4652, "ep_reward": 372.50762939453125, "reward": 0.09334748983383179, "action": -0.9208505749702454}
{"mode": "train", "epochs": 3, "timestep": 4653, "ep_reward": 372.53143310546875, "reward": 0.02380579710006714, "action": -0.9187946915626526}
{"mode": "train", "epochs": 3, "timestep": 4654, "ep_reward": 372.697021484375, "reward": 0.16559141874313354, "action": -1.0813217163085938}
{"mode": "train", "epochs": 3, "timestep": 4655, "ep_reward": 373.0014953613281, "reward": 0.3044874668121338, "action": -0.44153863191604614}
{"mode": "train", "epochs": 3, "timestep": 4656, "ep_reward": 373.44879150390625, "reward": 0.44730836153030396, "action": -0.7479622960090637}
{"mode": "train", "epochs": 3, "timestep": 4657, "ep_reward": 374.02020263671875, "reward": 0.571412205696106, "action": -0.5321388840675354}
{"mode": "train", "epochs": 3, "timestep": 4658, "ep_reward": 374.6971435546875, "reward": 0.6769428253173828, "action": -1.3388217687606812}
{"mode": "train", "epochs": 3, "timestep": 4659, "ep_reward": 375.4490051269531, "reward": 0.7518672943115234, "action": -0.8843024969100952}
{"mode": "train", "epochs": 3, "timestep": 4660, "ep_reward": 376.2593688964844, "reward": 0.8103711009025574, "action": -1.2476750612258911}
{"mode": "train", "epochs": 3, "timestep": 4661, "ep_reward": 377.1062927246094, "reward": 0.8469288945198059, "action": -0.975368857383728}
{"mode": "train", "epochs": 3, "timestep": 4662, "ep_reward": 377.9755859375, "reward": 0.8692888021469116, "action": -0.5544744729995728}
{"mode": "train", "epochs": 3, "timestep": 4663, "ep_reward": 378.8551940917969, "reward": 0.8795942068099976, "action": -1.2219336032867432}
{"mode": "train", "epochs": 3, "timestep": 4664, "ep_reward": 379.7242431640625, "reward": 0.8690379858016968, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4665, "ep_reward": 380.5578918457031, "reward": 0.8336607813835144, "action": -1.2200112342834473}
{"mode": "train", "epochs": 3, "timestep": 4666, "ep_reward": 381.3397216796875, "reward": 0.7818193435668945, "action": -0.7293041348457336}
{"mode": "train", "epochs": 3, "timestep": 4667, "ep_reward": 382.04608154296875, "reward": 0.7063741683959961, "action": -0.47318214178085327}
{"mode": "train", "epochs": 3, "timestep": 4668, "ep_reward": 382.6458740234375, "reward": 0.5997793674468994, "action": -1.3571957349777222}
{"mode": "train", "epochs": 3, "timestep": 4669, "ep_reward": 383.08685302734375, "reward": 0.4409831762313843, "action": -1.3633346557617188}
{"mode": "train", "epochs": 3, "timestep": 4670, "ep_reward": 383.4024353027344, "reward": 0.31558167934417725, "action": -1.1539334058761597}
{"mode": "train", "epochs": 3, "timestep": 4671, "ep_reward": 383.601318359375, "reward": 0.19889384508132935, "action": -1.424113154411316}
{"mode": "train", "epochs": 3, "timestep": 4672, "ep_reward": 383.6635437011719, "reward": 0.06223559379577637, "action": -1.5039830207824707}
{"mode": "train", "epochs": 3, "timestep": 4673, "ep_reward": 383.7194519042969, "reward": 0.05591428279876709, "action": -1.1032617092132568}
{"mode": "train", "epochs": 3, "timestep": 4674, "ep_reward": 383.91290283203125, "reward": 0.19344067573547363, "action": -0.9937600493431091}
{"mode": "train", "epochs": 3, "timestep": 4675, "ep_reward": 384.2467041015625, "reward": 0.33381372690200806, "action": -0.650471568107605}
{"mode": "train", "epochs": 3, "timestep": 4676, "ep_reward": 384.7186584472656, "reward": 0.471965491771698, "action": -1.6826224327087402}
{"mode": "train", "epochs": 3, "timestep": 4677, "ep_reward": 385.301025390625, "reward": 0.5823711156845093, "action": -1.404564380645752}
{"mode": "train", "epochs": 3, "timestep": 4678, "ep_reward": 385.9774475097656, "reward": 0.6764150857925415, "action": -1.3043241500854492}
{"mode": "train", "epochs": 3, "timestep": 4679, "ep_reward": 386.7265930175781, "reward": 0.749152660369873, "action": -0.9121891856193542}
{"mode": "train", "epochs": 3, "timestep": 4680, "ep_reward": 387.5299072265625, "reward": 0.8033085465431213, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4681, "ep_reward": 388.35711669921875, "reward": 0.8272166848182678, "action": -1.5385444164276123}
{"mode": "train", "epochs": 3, "timestep": 4682, "ep_reward": 389.19342041015625, "reward": 0.8363074064254761, "action": -0.10871118307113647}
{"mode": "train", "epochs": 3, "timestep": 4683, "ep_reward": 390.03216552734375, "reward": 0.8387467265129089, "action": -1.702981948852539}
{"mode": "train", "epochs": 3, "timestep": 4684, "ep_reward": 390.83685302734375, "reward": 0.8046811819076538, "action": -0.0982096791267395}
{"mode": "train", "epochs": 3, "timestep": 4685, "ep_reward": 391.5982666015625, "reward": 0.7614268064498901, "action": -0.0373842716217041}
{"mode": "train", "epochs": 3, "timestep": 4686, "ep_reward": 392.288330078125, "reward": 0.690076470375061, "action": -1.0123989582061768}
{"mode": "train", "epochs": 3, "timestep": 4687, "ep_reward": 392.8595275878906, "reward": 0.5712055563926697, "action": -1.056066870689392}
{"mode": "train", "epochs": 3, "timestep": 4688, "ep_reward": 393.2687683105469, "reward": 0.40924978256225586, "action": -0.7826440334320068}
{"mode": "train", "epochs": 3, "timestep": 4689, "ep_reward": 393.57281494140625, "reward": 0.3040562868118286, "action": -0.6193195581436157}
{"mode": "train", "epochs": 3, "timestep": 4690, "ep_reward": 393.7580871582031, "reward": 0.18528205156326294, "action": -0.22498905658721924}
{"mode": "train", "epochs": 3, "timestep": 4691, "ep_reward": 393.8045654296875, "reward": 0.04647272825241089, "action": -0.5379120111465454}
{"mode": "train", "epochs": 3, "timestep": 4692, "ep_reward": 393.87615966796875, "reward": 0.07160162925720215, "action": -1.4809939861297607}
{"mode": "train", "epochs": 3, "timestep": 4693, "ep_reward": 394.0832214355469, "reward": 0.20706230401992798, "action": -0.7756240963935852}
{"mode": "train", "epochs": 3, "timestep": 4694, "ep_reward": 394.4334716796875, "reward": 0.35024720430374146, "action": -0.5229513645172119}
{"mode": "train", "epochs": 3, "timestep": 4695, "ep_reward": 394.921875, "reward": 0.48839277029037476, "action": -1.2270636558532715}
{"mode": "train", "epochs": 3, "timestep": 4696, "ep_reward": 395.52313232421875, "reward": 0.6012516021728516, "action": -1.4273301362991333}
{"mode": "train", "epochs": 3, "timestep": 4697, "ep_reward": 396.21466064453125, "reward": 0.691513180732727, "action": -1.470458745956421}
{"mode": "train", "epochs": 3, "timestep": 4698, "ep_reward": 396.97442626953125, "reward": 0.7597793340682983, "action": -0.8482733964920044}
{"mode": "train", "epochs": 3, "timestep": 4699, "ep_reward": 397.7869567871094, "reward": 0.8125336766242981, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4700, "ep_reward": 398.62255859375, "reward": 0.835594117641449, "action": -1.3054126501083374}
{"mode": "train", "epochs": 3, "timestep": 4701, "ep_reward": 399.4692687988281, "reward": 0.8467230200767517, "action": -0.6720975637435913}
{"mode": "train", "epochs": 3, "timestep": 4702, "ep_reward": 400.31414794921875, "reward": 0.8448812961578369, "action": -0.17045950889587402}
{"mode": "train", "epochs": 3, "timestep": 4703, "ep_reward": 401.14215087890625, "reward": 0.8280034065246582, "action": -0.8329764604568481}
{"mode": "train", "epochs": 3, "timestep": 4704, "ep_reward": 401.9241638183594, "reward": 0.7820269465446472, "action": -1.6171822547912598}
{"mode": "train", "epochs": 3, "timestep": 4705, "ep_reward": 402.6221923828125, "reward": 0.6980293989181519, "action": -0.6778061389923096}
{"mode": "train", "epochs": 3, "timestep": 4706, "ep_reward": 403.21026611328125, "reward": 0.5880599617958069, "action": -1.4810874462127686}
{"mode": "train", "epochs": 3, "timestep": 4707, "ep_reward": 403.6348876953125, "reward": 0.4246327877044678, "action": -1.174086093902588}
{"mode": "train", "epochs": 3, "timestep": 4708, "ep_reward": 403.9527893066406, "reward": 0.31789910793304443, "action": -0.1646254062652588}
{"mode": "train", "epochs": 3, "timestep": 4709, "ep_reward": 404.1543884277344, "reward": 0.20161253213882446, "action": -1.012911319732666}
{"mode": "train", "epochs": 3, "timestep": 4710, "ep_reward": 404.2196044921875, "reward": 0.06521743535995483, "action": -1.9421311616897583}
{"mode": "train", "epochs": 3, "timestep": 4711, "ep_reward": 404.2723388671875, "reward": 0.05274015665054321, "action": -1.5331768989562988}
{"mode": "train", "epochs": 3, "timestep": 4712, "ep_reward": 404.4630126953125, "reward": 0.19066917896270752, "action": -1.5494917631149292}
{"mode": "train", "epochs": 3, "timestep": 4713, "ep_reward": 404.7869873046875, "reward": 0.3239833116531372, "action": -1.6410636901855469}
{"mode": "train", "epochs": 3, "timestep": 4714, "ep_reward": 405.239013671875, "reward": 0.4520251154899597, "action": -0.7181090116500854}
{"mode": "train", "epochs": 3, "timestep": 4715, "ep_reward": 405.81591796875, "reward": 0.5769028663635254, "action": -0.6684221029281616}
{"mode": "train", "epochs": 3, "timestep": 4716, "ep_reward": 406.4953308105469, "reward": 0.679419219493866, "action": -1.0975571870803833}
{"mode": "train", "epochs": 3, "timestep": 4717, "ep_reward": 407.2486267089844, "reward": 0.7532849311828613, "action": -1.127174973487854}
{"mode": "train", "epochs": 3, "timestep": 4718, "ep_reward": 408.0533142089844, "reward": 0.8046969175338745, "action": -0.6108907461166382}
{"mode": "train", "epochs": 3, "timestep": 4719, "ep_reward": 408.8937683105469, "reward": 0.8404584527015686, "action": -0.8237968683242798}
{"mode": "train", "epochs": 3, "timestep": 4720, "ep_reward": 409.74945068359375, "reward": 0.8556971549987793, "action": -0.9009590148925781}
{"mode": "train", "epochs": 3, "timestep": 4721, "ep_reward": 410.6019592285156, "reward": 0.85251784324646, "action": -0.029087066650390625}
{"mode": "train", "epochs": 3, "timestep": 4722, "ep_reward": 411.4405212402344, "reward": 0.838576078414917, "action": -0.7306499481201172}
{"mode": "train", "epochs": 3, "timestep": 4723, "ep_reward": 412.23748779296875, "reward": 0.7969527244567871, "action": -0.9643315076828003}
{"mode": "train", "epochs": 3, "timestep": 4724, "ep_reward": 412.9635314941406, "reward": 0.7260353565216064, "action": -0.9196897745132446}
{"mode": "train", "epochs": 3, "timestep": 4725, "ep_reward": 413.5852355957031, "reward": 0.6217010021209717, "action": -0.7046928405761719}
{"mode": "train", "epochs": 3, "timestep": 4726, "ep_reward": 414.06610107421875, "reward": 0.4808557629585266, "action": 0.24932897090911865}
{"mode": "train", "epochs": 3, "timestep": 4727, "ep_reward": 414.4047546386719, "reward": 0.3386561870574951, "action": -0.35214972496032715}
{"mode": "train", "epochs": 3, "timestep": 4728, "ep_reward": 414.631103515625, "reward": 0.2263636589050293, "action": -0.9804256558418274}
{"mode": "train", "epochs": 3, "timestep": 4729, "ep_reward": 414.7252502441406, "reward": 0.09415936470031738, "action": -0.6297703981399536}
{"mode": "train", "epochs": 3, "timestep": 4730, "ep_reward": 414.7482604980469, "reward": 0.02300053834915161, "action": -0.5886701345443726}
{"mode": "train", "epochs": 3, "timestep": 4731, "ep_reward": 414.9131164550781, "reward": 0.16485905647277832, "action": -1.1259335279464722}
{"mode": "train", "epochs": 3, "timestep": 4732, "ep_reward": 415.21624755859375, "reward": 0.3031280040740967, "action": -1.0940872430801392}
{"mode": "train", "epochs": 3, "timestep": 4733, "ep_reward": 415.6546325683594, "reward": 0.43838173151016235, "action": -0.06770408153533936}
{"mode": "train", "epochs": 3, "timestep": 4734, "ep_reward": 416.22637939453125, "reward": 0.5717517137527466, "action": -1.0407392978668213}
{"mode": "train", "epochs": 3, "timestep": 4735, "ep_reward": 416.8984680175781, "reward": 0.6720937490463257, "action": -1.2104157209396362}
{"mode": "train", "epochs": 3, "timestep": 4736, "ep_reward": 417.6473083496094, "reward": 0.7488523721694946, "action": -0.7120686769485474}
{"mode": "train", "epochs": 3, "timestep": 4737, "ep_reward": 418.4562683105469, "reward": 0.8089593648910522, "action": -0.8366671800613403}
{"mode": "train", "epochs": 3, "timestep": 4738, "ep_reward": 419.3045654296875, "reward": 0.8482869863510132, "action": -1.695115327835083}
{"mode": "train", "epochs": 3, "timestep": 4739, "ep_reward": 420.16839599609375, "reward": 0.8638261556625366, "action": -1.517138957977295}
{"mode": "train", "epochs": 3, "timestep": 4740, "ep_reward": 421.03338623046875, "reward": 0.8649845719337463, "action": -1.1814072132110596}
{"mode": "train", "epochs": 3, "timestep": 4741, "ep_reward": 421.8851623535156, "reward": 0.8517864942550659, "action": -1.4403358697891235}
{"mode": "train", "epochs": 3, "timestep": 4742, "ep_reward": 422.7010498046875, "reward": 0.8158999085426331, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4743, "ep_reward": 423.4489440917969, "reward": 0.7478821873664856, "action": -1.022742509841919}
{"mode": "train", "epochs": 3, "timestep": 4744, "ep_reward": 424.1055603027344, "reward": 0.6566146612167358, "action": -1.1151747703552246}
{"mode": "train", "epochs": 3, "timestep": 4745, "ep_reward": 424.62982177734375, "reward": 0.5242719650268555, "action": -1.3074196577072144}
{"mode": "train", "epochs": 3, "timestep": 4746, "ep_reward": 425.0098571777344, "reward": 0.38004201650619507, "action": -1.064907431602478}
{"mode": "train", "epochs": 3, "timestep": 4747, "ep_reward": 425.2860412597656, "reward": 0.27619218826293945, "action": -1.486682653427124}
{"mode": "train", "epochs": 3, "timestep": 4748, "ep_reward": 425.4385070800781, "reward": 0.15245258808135986, "action": -1.2384542226791382}
{"mode": "train", "epochs": 3, "timestep": 4749, "ep_reward": 425.4472351074219, "reward": 0.008742928504943848, "action": -0.62232905626297}
{"mode": "train", "epochs": 3, "timestep": 4750, "ep_reward": 425.5545654296875, "reward": 0.10734015703201294, "action": -0.601369321346283}
{"mode": "train", "epochs": 3, "timestep": 4751, "ep_reward": 425.8052978515625, "reward": 0.2507403492927551, "action": -1.0630263090133667}
{"mode": "train", "epochs": 3, "timestep": 4752, "ep_reward": 426.1930847167969, "reward": 0.3877936005592346, "action": -0.3072025775909424}
{"mode": "train", "epochs": 3, "timestep": 4753, "ep_reward": 426.7171936035156, "reward": 0.5241179466247559, "action": -0.8944351673126221}
{"mode": "train", "epochs": 3, "timestep": 4754, "ep_reward": 427.351806640625, "reward": 0.6346272230148315, "action": -0.7388678789138794}
{"mode": "train", "epochs": 3, "timestep": 4755, "ep_reward": 428.0768127441406, "reward": 0.7249985933303833, "action": -1.2073980569839478}
{"mode": "train", "epochs": 3, "timestep": 4756, "ep_reward": 428.8660583496094, "reward": 0.7892580032348633, "action": -0.9011616110801697}
{"mode": "train", "epochs": 3, "timestep": 4757, "ep_reward": 429.7029113769531, "reward": 0.8368451595306396, "action": -1.3578358888626099}
{"mode": "train", "epochs": 3, "timestep": 4758, "ep_reward": 430.566650390625, "reward": 0.8637319803237915, "action": 0.1300196647644043}
{"mode": "train", "epochs": 3, "timestep": 4759, "ep_reward": 431.4537048339844, "reward": 0.8870599269866943, "action": -1.3568916320800781}
{"mode": "train", "epochs": 3, "timestep": 4760, "ep_reward": 432.3384094238281, "reward": 0.8846937417984009, "action": -0.29727602005004883}
{"mode": "train", "epochs": 3, "timestep": 4761, "ep_reward": 433.2145080566406, "reward": 0.8761065602302551, "action": -1.1049388647079468}
{"mode": "train", "epochs": 3, "timestep": 4762, "ep_reward": 434.05877685546875, "reward": 0.8442637920379639, "action": -0.33117401599884033}
{"mode": "train", "epochs": 3, "timestep": 4763, "ep_reward": 434.85723876953125, "reward": 0.7984711527824402, "action": -1.9903855323791504}
{"mode": "train", "epochs": 3, "timestep": 4764, "ep_reward": 435.56561279296875, "reward": 0.7083718776702881, "action": -1.0254790782928467}
{"mode": "train", "epochs": 3, "timestep": 4765, "ep_reward": 436.1579284667969, "reward": 0.5923051238059998, "action": -1.7280795574188232}
{"mode": "train", "epochs": 3, "timestep": 4766, "ep_reward": 436.58258056640625, "reward": 0.42465072870254517, "action": -1.829376220703125}
{"mode": "train", "epochs": 3, "timestep": 4767, "ep_reward": 436.8847961425781, "reward": 0.3022181987762451, "action": -1.0741534233093262}
{"mode": "train", "epochs": 3, "timestep": 4768, "ep_reward": 437.06787109375, "reward": 0.18308132886886597, "action": -1.1691168546676636}
{"mode": "train", "epochs": 3, "timestep": 4769, "ep_reward": 437.11187744140625, "reward": 0.044007837772369385, "action": -0.7583272457122803}
{"mode": "train", "epochs": 3, "timestep": 4770, "ep_reward": 437.18597412109375, "reward": 0.0740894079208374, "action": -0.7421404123306274}
{"mode": "train", "epochs": 3, "timestep": 4771, "ep_reward": 437.4007873535156, "reward": 0.21481406688690186, "action": -0.569896936416626}
{"mode": "train", "epochs": 3, "timestep": 4772, "ep_reward": 437.7598876953125, "reward": 0.3590959310531616, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4773, "ep_reward": 438.2383117675781, "reward": 0.47842299938201904, "action": -1.11862051486969}
{"mode": "train", "epochs": 3, "timestep": 4774, "ep_reward": 438.8326416015625, "reward": 0.5943376421928406, "action": -1.0568568706512451}
{"mode": "train", "epochs": 3, "timestep": 4775, "ep_reward": 439.5221252441406, "reward": 0.6894819736480713, "action": -0.9450087547302246}
{"mode": "train", "epochs": 3, "timestep": 4776, "ep_reward": 440.2847595214844, "reward": 0.7626459002494812, "action": -0.8302116394042969}
{"mode": "train", "epochs": 3, "timestep": 4777, "ep_reward": 441.0996398925781, "reward": 0.8148698806762695, "action": -0.8740187883377075}
{"mode": "train", "epochs": 3, "timestep": 4778, "ep_reward": 441.94671630859375, "reward": 0.8470638990402222, "action": -0.3421592712402344}
{"mode": "train", "epochs": 3, "timestep": 4779, "ep_reward": 442.8127746582031, "reward": 0.8660608530044556, "action": -1.2924795150756836}
{"mode": "train", "epochs": 3, "timestep": 4780, "ep_reward": 443.6729736328125, "reward": 0.8601949214935303, "action": -1.4439054727554321}
{"mode": "train", "epochs": 3, "timestep": 4781, "ep_reward": 444.5074462890625, "reward": 0.8344672322273254, "action": -0.7911422252655029}
{"mode": "train", "epochs": 3, "timestep": 4782, "ep_reward": 445.2999572753906, "reward": 0.7925243973731995, "action": 0.42024552822113037}
{"mode": "train", "epochs": 3, "timestep": 4783, "ep_reward": 446.03759765625, "reward": 0.737638533115387, "action": -1.2059550285339355}
{"mode": "train", "epochs": 3, "timestep": 4784, "ep_reward": 446.6705322265625, "reward": 0.6329432725906372, "action": -1.1355139017105103}
{"mode": "train", "epochs": 3, "timestep": 4785, "ep_reward": 447.1593933105469, "reward": 0.48884767293930054, "action": -0.8942301869392395}
{"mode": "train", "epochs": 3, "timestep": 4786, "ep_reward": 447.50335693359375, "reward": 0.34396857023239136, "action": -1.124552607536316}
{"mode": "train", "epochs": 3, "timestep": 4787, "ep_reward": 447.7362060546875, "reward": 0.23284143209457397, "action": -0.6267735958099365}
{"mode": "train", "epochs": 3, "timestep": 4788, "ep_reward": 447.8377685546875, "reward": 0.1015777587890625, "action": -1.3095433712005615}
{"mode": "train", "epochs": 3, "timestep": 4789, "ep_reward": 447.8525695800781, "reward": 0.014813482761383057, "action": -1.4947160482406616}
{"mode": "train", "epochs": 3, "timestep": 4790, "ep_reward": 448.0103759765625, "reward": 0.15780675411224365, "action": -1.3913631439208984}
{"mode": "train", "epochs": 3, "timestep": 4791, "ep_reward": 448.30303955078125, "reward": 0.29266953468322754, "action": -0.8801129460334778}
{"mode": "train", "epochs": 3, "timestep": 4792, "ep_reward": 448.73455810546875, "reward": 0.4315066337585449, "action": -0.9193567633628845}
{"mode": "train", "epochs": 3, "timestep": 4793, "ep_reward": 449.2908935546875, "reward": 0.5563271641731262, "action": -1.0385407209396362}
{"mode": "train", "epochs": 3, "timestep": 4794, "ep_reward": 449.9504699707031, "reward": 0.659583568572998, "action": -0.44694167375564575}
{"mode": "train", "epochs": 3, "timestep": 4795, "ep_reward": 450.6961975097656, "reward": 0.7457171678543091, "action": -1.1040513515472412}
{"mode": "train", "epochs": 3, "timestep": 4796, "ep_reward": 451.49896240234375, "reward": 0.8027694225311279, "action": -0.8702911734580994}
{"mode": "train", "epochs": 3, "timestep": 4797, "ep_reward": 452.3412780761719, "reward": 0.8423172235488892, "action": -0.7933230400085449}
{"mode": "train", "epochs": 3, "timestep": 4798, "ep_reward": 453.2060546875, "reward": 0.8647661209106445, "action": -1.8505240678787231}
{"mode": "train", "epochs": 3, "timestep": 4799, "ep_reward": 454.06829833984375, "reward": 0.862255334854126, "action": -0.8958481550216675}
{"mode": "train", "epochs": 3, "timestep": 4800, "ep_reward": 454.9188232421875, "reward": 0.850520133972168, "action": -0.3266712427139282}
{"mode": "train", "epochs": 3, "timestep": 4801, "ep_reward": 455.7433776855469, "reward": 0.8245408535003662, "action": -1.258597493171692}
{"mode": "train", "epochs": 3, "timestep": 4802, "ep_reward": 456.5093078613281, "reward": 0.7659159302711487, "action": -0.8568826913833618}
{"mode": "train", "epochs": 3, "timestep": 4803, "ep_reward": 457.190185546875, "reward": 0.6808762550354004, "action": -1.1513183116912842}
{"mode": "train", "epochs": 3, "timestep": 4804, "ep_reward": 457.74505615234375, "reward": 0.5548578500747681, "action": 0.2099095582962036}
{"mode": "train", "epochs": 3, "timestep": 4805, "ep_reward": 458.1534118652344, "reward": 0.4083436131477356, "action": -1.3689079284667969}
{"mode": "train", "epochs": 3, "timestep": 4806, "ep_reward": 458.4410400390625, "reward": 0.2876192331314087, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4807, "ep_reward": 458.607177734375, "reward": 0.1661320924758911, "action": -0.16959071159362793}
{"mode": "train", "epochs": 3, "timestep": 4808, "ep_reward": 458.6314392089844, "reward": 0.024249911308288574, "action": -1.5454058647155762}
{"mode": "train", "epochs": 3, "timestep": 4809, "ep_reward": 458.7243347167969, "reward": 0.09289032220840454, "action": -0.2151472568511963}
{"mode": "train", "epochs": 3, "timestep": 4810, "ep_reward": 458.96502685546875, "reward": 0.24068576097488403, "action": -0.740437388420105}
{"mode": "train", "epochs": 3, "timestep": 4811, "ep_reward": 459.3460998535156, "reward": 0.3810847997665405, "action": -0.9421388506889343}
{"mode": "train", "epochs": 3, "timestep": 4812, "ep_reward": 459.8561096191406, "reward": 0.5100165605545044, "action": -1.1407344341278076}
{"mode": "train", "epochs": 3, "timestep": 4813, "ep_reward": 460.47637939453125, "reward": 0.620262861251831, "action": -0.43499982357025146}
{"mode": "train", "epochs": 3, "timestep": 4814, "ep_reward": 461.1929626464844, "reward": 0.7165928483009338, "action": -1.542128324508667}
{"mode": "train", "epochs": 3, "timestep": 4815, "ep_reward": 461.9732360839844, "reward": 0.7802767157554626, "action": -0.8829224109649658}
{"mode": "train", "epochs": 3, "timestep": 4816, "ep_reward": 462.80389404296875, "reward": 0.830653965473175, "action": -0.6217433214187622}
{"mode": "train", "epochs": 3, "timestep": 4817, "ep_reward": 463.6693115234375, "reward": 0.8654134273529053, "action": -0.2512545585632324}
{"mode": "train", "epochs": 3, "timestep": 4818, "ep_reward": 464.5567321777344, "reward": 0.8874224424362183, "action": -0.9853075742721558}
{"mode": "train", "epochs": 3, "timestep": 4819, "ep_reward": 465.4466247558594, "reward": 0.8898951411247253, "action": -1.2208242416381836}
{"mode": "train", "epochs": 3, "timestep": 4820, "ep_reward": 466.3230285644531, "reward": 0.8764097094535828, "action": -0.7555630207061768}
{"mode": "train", "epochs": 3, "timestep": 4821, "ep_reward": 467.1732177734375, "reward": 0.8501843810081482, "action": -0.9158226847648621}
{"mode": "train", "epochs": 3, "timestep": 4822, "ep_reward": 467.9754333496094, "reward": 0.8022090196609497, "action": -0.3773297071456909}
{"mode": "train", "epochs": 3, "timestep": 4823, "ep_reward": 468.7094421386719, "reward": 0.7340186834335327, "action": -1.4529924392700195}
{"mode": "train", "epochs": 3, "timestep": 4824, "ep_reward": 469.3305969238281, "reward": 0.6211565732955933, "action": -0.8919339179992676}
{"mode": "train", "epochs": 3, "timestep": 4825, "ep_reward": 469.8062744140625, "reward": 0.47566354274749756, "action": -0.7019217014312744}
{"mode": "train", "epochs": 3, "timestep": 4826, "ep_reward": 470.12982177734375, "reward": 0.3235422372817993, "action": -0.7944490313529968}
{"mode": "train", "epochs": 3, "timestep": 4827, "ep_reward": 470.3381652832031, "reward": 0.20835262537002563, "action": -1.1309447288513184}
{"mode": "train", "epochs": 3, "timestep": 4828, "ep_reward": 470.4114074707031, "reward": 0.07324790954589844, "action": -0.7617204189300537}
{"mode": "train", "epochs": 3, "timestep": 4829, "ep_reward": 470.456298828125, "reward": 0.04489177465438843, "action": 0.4849233627319336}
{"mode": "train", "epochs": 3, "timestep": 4830, "ep_reward": 470.6560974121094, "reward": 0.19980841875076294, "action": -1.1164809465408325}
{"mode": "train", "epochs": 3, "timestep": 4831, "ep_reward": 470.9913635253906, "reward": 0.3352636694908142, "action": -0.9617640972137451}
{"mode": "train", "epochs": 3, "timestep": 4832, "ep_reward": 471.4590759277344, "reward": 0.4677138328552246, "action": -1.4916906356811523}
{"mode": "train", "epochs": 3, "timestep": 4833, "ep_reward": 472.0395202636719, "reward": 0.5804392099380493, "action": -0.5887879133224487}
{"mode": "train", "epochs": 3, "timestep": 4834, "ep_reward": 472.72308349609375, "reward": 0.6835587024688721, "action": -1.6047335863113403}
{"mode": "train", "epochs": 3, "timestep": 4835, "ep_reward": 473.47747802734375, "reward": 0.7543890476226807, "action": -0.8052923083305359}
{"mode": "train", "epochs": 3, "timestep": 4836, "ep_reward": 474.2897033691406, "reward": 0.8122119307518005, "action": -1.7626821994781494}
{"mode": "train", "epochs": 3, "timestep": 4837, "ep_reward": 475.1328125, "reward": 0.8431212902069092, "action": -0.6138743162155151}
{"mode": "train", "epochs": 3, "timestep": 4838, "ep_reward": 475.999755859375, "reward": 0.866951584815979, "action": -1.1495615243911743}
{"mode": "train", "epochs": 3, "timestep": 4839, "ep_reward": 476.86993408203125, "reward": 0.870192289352417, "action": -1.739768147468567}
{"mode": "train", "epochs": 3, "timestep": 4840, "ep_reward": 477.7216796875, "reward": 0.8517389893531799, "action": -0.8847765922546387}
{"mode": "train", "epochs": 3, "timestep": 4841, "ep_reward": 478.5425720214844, "reward": 0.8208884000778198, "action": -1.1645667552947998}
{"mode": "train", "epochs": 3, "timestep": 4842, "ep_reward": 479.3055114746094, "reward": 0.7629406452178955, "action": -0.5850784182548523}
{"mode": "train", "epochs": 3, "timestep": 4843, "ep_reward": 479.98626708984375, "reward": 0.680759072303772, "action": -1.4748952388763428}
{"mode": "train", "epochs": 3, "timestep": 4844, "ep_reward": 480.53619384765625, "reward": 0.5499348640441895, "action": -1.5163064002990723}
{"mode": "train", "epochs": 3, "timestep": 4845, "ep_reward": 480.92315673828125, "reward": 0.38697153329849243, "action": -1.5726516246795654}
{"mode": "train", "epochs": 3, "timestep": 4846, "ep_reward": 481.2077941894531, "reward": 0.2846519351005554, "action": -1.7859963178634644}
{"mode": "train", "epochs": 3, "timestep": 4847, "ep_reward": 481.3702392578125, "reward": 0.1624511480331421, "action": -1.4198048114776611}
{"mode": "train", "epochs": 3, "timestep": 4848, "ep_reward": 481.3904724121094, "reward": 0.02024596929550171, "action": -0.9602370262145996}
{"mode": "train", "epochs": 3, "timestep": 4849, "ep_reward": 481.4871826171875, "reward": 0.09669560194015503, "action": -0.6676657199859619}
{"mode": "train", "epochs": 3, "timestep": 4850, "ep_reward": 481.7261962890625, "reward": 0.23900949954986572, "action": -0.7369973659515381}
{"mode": "train", "epochs": 3, "timestep": 4851, "ep_reward": 482.1067199707031, "reward": 0.380526065826416, "action": -0.7141116857528687}
{"mode": "train", "epochs": 3, "timestep": 4852, "ep_reward": 482.6194152832031, "reward": 0.5126830339431763, "action": -1.0902045965194702}
{"mode": "train", "epochs": 3, "timestep": 4853, "ep_reward": 483.2425231933594, "reward": 0.6230964660644531, "action": -0.6746225357055664}
{"mode": "train", "epochs": 3, "timestep": 4854, "ep_reward": 483.9590148925781, "reward": 0.7164998054504395, "action": -1.0147473812103271}
{"mode": "train", "epochs": 3, "timestep": 4855, "ep_reward": 484.7433166503906, "reward": 0.7843092679977417, "action": -0.898301362991333}
{"mode": "train", "epochs": 3, "timestep": 4856, "ep_reward": 485.57659912109375, "reward": 0.8332791924476624, "action": 0.11054837703704834}
{"mode": "train", "epochs": 3, "timestep": 4857, "ep_reward": 486.4491271972656, "reward": 0.8725265264511108, "action": -1.3748183250427246}
{"mode": "train", "epochs": 3, "timestep": 4858, "ep_reward": 487.3340759277344, "reward": 0.88495272397995, "action": 0.6545614004135132}
{"mode": "train", "epochs": 3, "timestep": 4859, "ep_reward": 488.2333984375, "reward": 0.8993209004402161, "action": -1.0108990669250488}
{"mode": "train", "epochs": 3, "timestep": 4860, "ep_reward": 489.121337890625, "reward": 0.8879377245903015, "action": -0.9084333777427673}
{"mode": "train", "epochs": 3, "timestep": 4861, "ep_reward": 489.9834899902344, "reward": 0.8621609807014465, "action": -1.443242073059082}
{"mode": "train", "epochs": 3, "timestep": 4862, "ep_reward": 490.7957458496094, "reward": 0.8122503757476807, "action": -0.7106069326400757}
{"mode": "train", "epochs": 3, "timestep": 4863, "ep_reward": 491.53961181640625, "reward": 0.7438714504241943, "action": -0.1920519471168518}
{"mode": "train", "epochs": 3, "timestep": 4864, "ep_reward": 492.19085693359375, "reward": 0.651250958442688, "action": -0.6835606098175049}
{"mode": "train", "epochs": 3, "timestep": 4865, "ep_reward": 492.70849609375, "reward": 0.5176455974578857, "action": -1.144680380821228}
{"mode": "train", "epochs": 3, "timestep": 4866, "ep_reward": 493.0472412109375, "reward": 0.33874940872192383, "action": -1.2474478483200073}
{"mode": "train", "epochs": 3, "timestep": 4867, "ep_reward": 493.2736511230469, "reward": 0.22640252113342285, "action": -1.3506232500076294}
{"mode": "train", "epochs": 3, "timestep": 4868, "ep_reward": 493.36785888671875, "reward": 0.09421283006668091, "action": -1.126718521118164}
{"mode": "train", "epochs": 3, "timestep": 4869, "ep_reward": 493.3907165527344, "reward": 0.022868990898132324, "action": -0.7775608897209167}
{"mode": "train", "epochs": 3, "timestep": 4870, "ep_reward": 493.5553283691406, "reward": 0.16459864377975464, "action": -1.9573509693145752}
{"mode": "train", "epochs": 3, "timestep": 4871, "ep_reward": 493.847900390625, "reward": 0.2925766110420227, "action": -0.30050748586654663}
{"mode": "train", "epochs": 3, "timestep": 4872, "ep_reward": 494.28741455078125, "reward": 0.4395138621330261, "action": -0.49445921182632446}
{"mode": "train", "epochs": 3, "timestep": 4873, "ep_reward": 494.85546875, "reward": 0.5680495500564575, "action": -1.0089309215545654}
{"mode": "train", "epochs": 3, "timestep": 4874, "ep_reward": 495.5248718261719, "reward": 0.6693973541259766, "action": -0.7253737449645996}
{"mode": "train", "epochs": 3, "timestep": 4875, "ep_reward": 496.2757568359375, "reward": 0.7508741617202759, "action": -0.7934105396270752}
{"mode": "train", "epochs": 3, "timestep": 4876, "ep_reward": 497.085205078125, "reward": 0.8094501495361328, "action": -1.1785674095153809}
{"mode": "train", "epochs": 3, "timestep": 4877, "ep_reward": 497.9305725097656, "reward": 0.8453736305236816, "action": -0.8156368732452393}
{"mode": "train", "epochs": 3, "timestep": 4878, "ep_reward": 498.7979736328125, "reward": 0.8674071431159973, "action": -0.7887828350067139}
{"mode": "train", "epochs": 3, "timestep": 4879, "ep_reward": 499.6717224121094, "reward": 0.8737454414367676, "action": -1.3109657764434814}
{"mode": "train", "epochs": 3, "timestep": 4880, "ep_reward": 500.53131103515625, "reward": 0.8595966100692749, "action": -1.0604581832885742}
{"mode": "train", "epochs": 3, "timestep": 4881, "ep_reward": 501.3598327636719, "reward": 0.8285151124000549, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4882, "ep_reward": 502.12371826171875, "reward": 0.7638799548149109, "action": -0.5140150189399719}
{"mode": "train", "epochs": 3, "timestep": 4883, "ep_reward": 502.8075256347656, "reward": 0.6838161945343018, "action": -1.0277389287948608}
{"mode": "train", "epochs": 3, "timestep": 4884, "ep_reward": 503.3685607910156, "reward": 0.5610434412956238, "action": -0.5058367252349854}
{"mode": "train", "epochs": 3, "timestep": 4885, "ep_reward": 503.773193359375, "reward": 0.40464192628860474, "action": -0.9261199831962585}
{"mode": "train", "epochs": 3, "timestep": 4886, "ep_reward": 504.06488037109375, "reward": 0.29169201850891113, "action": -1.9608650207519531}
{"mode": "train", "epochs": 3, "timestep": 4887, "ep_reward": 504.2358093261719, "reward": 0.17092573642730713, "action": -0.125244140625}
{"mode": "train", "epochs": 3, "timestep": 4888, "ep_reward": 504.2656555175781, "reward": 0.029831647872924805, "action": -1.1998860836029053}
{"mode": "train", "epochs": 3, "timestep": 4889, "ep_reward": 504.3533020019531, "reward": 0.08765667676925659, "action": -0.6601561903953552}
{"mode": "train", "epochs": 3, "timestep": 4890, "ep_reward": 504.58306884765625, "reward": 0.22978001832962036, "action": -0.9564387798309326}
{"mode": "train", "epochs": 3, "timestep": 4891, "ep_reward": 504.95196533203125, "reward": 0.368910014629364, "action": -1.0012277364730835}
{"mode": "train", "epochs": 3, "timestep": 4892, "ep_reward": 505.451171875, "reward": 0.49919795989990234, "action": -1.3940201997756958}
{"mode": "train", "epochs": 3, "timestep": 4893, "ep_reward": 506.059814453125, "reward": 0.6086511015892029, "action": -0.966311514377594}
{"mode": "train", "epochs": 3, "timestep": 4894, "ep_reward": 506.76153564453125, "reward": 0.7017275094985962, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4895, "ep_reward": 507.5239562988281, "reward": 0.7624174356460571, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4896, "ep_reward": 508.3273010253906, "reward": 0.80333411693573, "action": -0.3763939142227173}
{"mode": "train", "epochs": 3, "timestep": 4897, "ep_reward": 509.1667175292969, "reward": 0.8394016027450562, "action": -0.8867495059967041}
{"mode": "train", "epochs": 3, "timestep": 4898, "ep_reward": 510.0184326171875, "reward": 0.8517218232154846, "action": -1.2426142692565918}
{"mode": "train", "epochs": 3, "timestep": 4899, "ep_reward": 510.8607177734375, "reward": 0.8422989249229431, "action": -1.2858381271362305}
{"mode": "train", "epochs": 3, "timestep": 4900, "ep_reward": 511.6722106933594, "reward": 0.8114793300628662, "action": -0.9976096749305725}
{"mode": "train", "epochs": 3, "timestep": 4901, "ep_reward": 512.4300537109375, "reward": 0.7578690052032471, "action": -1.6406258344650269}
{"mode": "train", "epochs": 3, "timestep": 4902, "ep_reward": 513.094482421875, "reward": 0.6644120812416077, "action": -0.5462528467178345}
{"mode": "train", "epochs": 3, "timestep": 4903, "ep_reward": 513.6395874023438, "reward": 0.5450854301452637, "action": -1.059894323348999}
{"mode": "train", "epochs": 3, "timestep": 4904, "ep_reward": 514.0333251953125, "reward": 0.39371323585510254, "action": -0.7266848087310791}
{"mode": "train", "epochs": 3, "timestep": 4905, "ep_reward": 514.3259887695312, "reward": 0.2926676273345947, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4906, "ep_reward": 514.4979248046875, "reward": 0.17195749282836914, "action": -1.4536632299423218}
{"mode": "train", "epochs": 3, "timestep": 4907, "ep_reward": 514.5291137695312, "reward": 0.031172990798950195, "action": -1.1945087909698486}
{"mode": "train", "epochs": 3, "timestep": 4908, "ep_reward": 514.615478515625, "reward": 0.08635503053665161, "action": -0.9514372944831848}
{"mode": "train", "epochs": 3, "timestep": 4909, "ep_reward": 514.8402099609375, "reward": 0.22472882270812988, "action": -1.5034371614456177}
{"mode": "train", "epochs": 3, "timestep": 4910, "ep_reward": 515.197998046875, "reward": 0.35776805877685547, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4911, "ep_reward": 515.6764526367188, "reward": 0.47842931747436523, "action": -0.9220209717750549}
{"mode": "train", "epochs": 3, "timestep": 4912, "ep_reward": 516.2733154296875, "reward": 0.5968745946884155, "action": -0.3758052587509155}
{"mode": "train", "epochs": 3, "timestep": 4913, "ep_reward": 516.9711303710938, "reward": 0.6978381872177124, "action": -0.484108030796051}
{"mode": "train", "epochs": 3, "timestep": 4914, "ep_reward": 517.7434692382812, "reward": 0.7723134160041809, "action": -1.2579221725463867}
{"mode": "train", "epochs": 3, "timestep": 4915, "ep_reward": 518.5607299804688, "reward": 0.817284107208252, "action": -0.5978215932846069}
{"mode": "train", "epochs": 3, "timestep": 4916, "ep_reward": 519.4094848632812, "reward": 0.8487614989280701, "action": -1.3532459735870361}
{"mode": "train", "epochs": 3, "timestep": 4917, "ep_reward": 520.2653198242188, "reward": 0.8558388352394104, "action": -0.8754655122756958}
{"mode": "train", "epochs": 3, "timestep": 4918, "ep_reward": 521.1144409179688, "reward": 0.849151074886322, "action": -1.5153906345367432}
{"mode": "train", "epochs": 3, "timestep": 4919, "ep_reward": 521.9307861328125, "reward": 0.8163710832595825, "action": -1.3512428998947144}
{"mode": "train", "epochs": 3, "timestep": 4920, "ep_reward": 522.6903686523438, "reward": 0.7596061825752258, "action": -0.9340884685516357}
{"mode": "train", "epochs": 3, "timestep": 4921, "ep_reward": 523.3659057617188, "reward": 0.6755630970001221, "action": -1.3620989322662354}
{"mode": "train", "epochs": 3, "timestep": 4922, "ep_reward": 523.9130859375, "reward": 0.5471676588058472, "action": -0.5950706601142883}
{"mode": "train", "epochs": 3, "timestep": 4923, "ep_reward": 524.308349609375, "reward": 0.3952646851539612, "action": -1.3662316799163818}
{"mode": "train", "epochs": 3, "timestep": 4924, "ep_reward": 524.60302734375, "reward": 0.29467976093292236, "action": -1.933519721031189}
{"mode": "train", "epochs": 3, "timestep": 4925, "ep_reward": 524.7774047851562, "reward": 0.17439740896224976, "action": -0.8828243017196655}
{"mode": "train", "epochs": 3, "timestep": 4926, "ep_reward": 524.8113403320312, "reward": 0.03390592336654663, "action": -1.0842846632003784}
{"mode": "train", "epochs": 3, "timestep": 4927, "ep_reward": 524.8950805664062, "reward": 0.08376306295394897, "action": -0.9799597263336182}
{"mode": "train", "epochs": 3, "timestep": 4928, "ep_reward": 525.1168212890625, "reward": 0.22177058458328247, "action": -1.1136952638626099}
{"mode": "train", "epochs": 3, "timestep": 4929, "ep_reward": 525.4765625, "reward": 0.35973989963531494, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4930, "ep_reward": 525.9563598632812, "reward": 0.47980982065200806, "action": -1.2975798845291138}
{"mode": "train", "epochs": 3, "timestep": 4931, "ep_reward": 526.5499877929688, "reward": 0.5936486124992371, "action": -1.3474980592727661}
{"mode": "train", "epochs": 3, "timestep": 4932, "ep_reward": 527.2352294921875, "reward": 0.6852487325668335, "action": -0.06282401084899902}
{"mode": "train", "epochs": 3, "timestep": 4933, "ep_reward": 528.001220703125, "reward": 0.7659610509872437, "action": -1.0298032760620117}
{"mode": "train", "epochs": 3, "timestep": 4934, "ep_reward": 528.814697265625, "reward": 0.8134675025939941, "action": -1.5340871810913086}
{"mode": "train", "epochs": 3, "timestep": 4935, "ep_reward": 529.6513061523438, "reward": 0.8366231918334961, "action": -1.1343857049942017}
{"mode": "train", "epochs": 3, "timestep": 4936, "ep_reward": 530.4959106445312, "reward": 0.8446023464202881, "action": -1.0612298250198364}
{"mode": "train", "epochs": 3, "timestep": 4937, "ep_reward": 531.3294677734375, "reward": 0.8335784077644348, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4938, "ep_reward": 532.1202392578125, "reward": 0.7907945513725281, "action": -0.9234416484832764}
{"mode": "train", "epochs": 3, "timestep": 4939, "ep_reward": 532.8507690429688, "reward": 0.7305140495300293, "action": -0.7810271978378296}
{"mode": "train", "epochs": 3, "timestep": 4940, "ep_reward": 533.4886474609375, "reward": 0.6378657817840576, "action": -0.8730363249778748}
{"mode": "train", "epochs": 3, "timestep": 4941, "ep_reward": 533.9923095703125, "reward": 0.5036642551422119, "action": -0.860797107219696}
{"mode": "train", "epochs": 3, "timestep": 4942, "ep_reward": 534.3646850585938, "reward": 0.37237823009490967, "action": -0.8605411052703857}
{"mode": "train", "epochs": 3, "timestep": 4943, "ep_reward": 534.6315307617188, "reward": 0.26683545112609863, "action": -1.7019968032836914}
{"mode": "train", "epochs": 3, "timestep": 4944, "ep_reward": 534.77294921875, "reward": 0.1414356827735901, "action": -1.6660528182983398}
{"mode": "train", "epochs": 3, "timestep": 4945, "ep_reward": 534.7689819335938, "reward": -0.003986001014709473, "action": -1.7367832660675049}
{"mode": "train", "epochs": 3, "timestep": 4946, "ep_reward": 534.8875732421875, "reward": 0.11860454082489014, "action": -1.2722177505493164}
{"mode": "train", "epochs": 3, "timestep": 4947, "ep_reward": 535.1416015625, "reward": 0.25401610136032104, "action": -0.7949151396751404}
{"mode": "train", "epochs": 3, "timestep": 4948, "ep_reward": 535.5369262695312, "reward": 0.39532673358917236, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4949, "ep_reward": 536.0487670898438, "reward": 0.5118470788002014, "action": -1.178462028503418}
{"mode": "train", "epochs": 3, "timestep": 4950, "ep_reward": 536.6703491210938, "reward": 0.6215673685073853, "action": -1.5757331848144531}
{"mode": "train", "epochs": 3, "timestep": 4951, "ep_reward": 537.3749389648438, "reward": 0.7045885324478149, "action": -1.4587702751159668}
{"mode": "train", "epochs": 3, "timestep": 4952, "ep_reward": 538.1410522460938, "reward": 0.7661401033401489, "action": -1.1196900606155396}
{"mode": "train", "epochs": 3, "timestep": 4953, "ep_reward": 538.949951171875, "reward": 0.8089233040809631, "action": -0.05649763345718384}
{"mode": "train", "epochs": 3, "timestep": 4954, "ep_reward": 539.7904663085938, "reward": 0.8405115008354187, "action": -1.2541059255599976}
{"mode": "train", "epochs": 3, "timestep": 4955, "ep_reward": 540.6317749023438, "reward": 0.8413060903549194, "action": -1.7744965553283691}
{"mode": "train", "epochs": 3, "timestep": 4956, "ep_reward": 541.4484252929688, "reward": 0.8166276216506958, "action": -0.7315161824226379}
{"mode": "train", "epochs": 3, "timestep": 4957, "ep_reward": 542.2261962890625, "reward": 0.7777800559997559, "action": -0.8488839864730835}
{"mode": "train", "epochs": 3, "timestep": 4958, "ep_reward": 542.9347534179688, "reward": 0.7085862159729004, "action": -0.9439808130264282}
{"mode": "train", "epochs": 3, "timestep": 4959, "ep_reward": 543.5369262695312, "reward": 0.6021959781646729, "action": -1.355427622795105}
{"mode": "train", "epochs": 3, "timestep": 4960, "ep_reward": 543.9840087890625, "reward": 0.4470791816711426, "action": -0.5380708575248718}
{"mode": "train", "epochs": 3, "timestep": 4961, "ep_reward": 544.3244018554688, "reward": 0.3403867483139038, "action": 0.3231029510498047}
{"mode": "train", "epochs": 3, "timestep": 4962, "ep_reward": 544.5527954101562, "reward": 0.2283836007118225, "action": -1.3162953853607178}
{"mode": "train", "epochs": 3, "timestep": 4963, "ep_reward": 544.6493530273438, "reward": 0.09656262397766113, "action": -0.6749216318130493}
{"mode": "train", "epochs": 3, "timestep": 4964, "ep_reward": 544.6697387695312, "reward": 0.020403385162353516, "action": -0.8206460475921631}
{"mode": "train", "epochs": 3, "timestep": 4965, "ep_reward": 544.8323974609375, "reward": 0.162641704082489, "action": -0.9694250226020813}
{"mode": "train", "epochs": 3, "timestep": 4966, "ep_reward": 545.1351928710938, "reward": 0.3028196096420288, "action": -0.9764171242713928}
{"mode": "train", "epochs": 3, "timestep": 4967, "ep_reward": 545.5744018554688, "reward": 0.43918269872665405, "action": -0.684531569480896}
{"mode": "train", "epochs": 3, "timestep": 4968, "ep_reward": 546.1397705078125, "reward": 0.5653878450393677, "action": -0.7512515187263489}
{"mode": "train", "epochs": 3, "timestep": 4969, "ep_reward": 546.8096923828125, "reward": 0.6699071526527405, "action": -0.9371448159217834}
{"mode": "train", "epochs": 3, "timestep": 4970, "ep_reward": 547.5593872070312, "reward": 0.7497082948684692, "action": -0.903404951095581}
{"mode": "train", "epochs": 3, "timestep": 4971, "ep_reward": 548.3674926757812, "reward": 0.8081008195877075, "action": -1.845076084136963}
{"mode": "train", "epochs": 3, "timestep": 4972, "ep_reward": 549.20703125, "reward": 0.8395307064056396, "action": -1.2737926244735718}
{"mode": "train", "epochs": 3, "timestep": 4973, "ep_reward": 550.0659790039062, "reward": 0.8589245676994324, "action": -1.6579715013504028}
{"mode": "train", "epochs": 3, "timestep": 4974, "ep_reward": 550.9244384765625, "reward": 0.8584292531013489, "action": -1.2065132856369019}
{"mode": "train", "epochs": 3, "timestep": 4975, "ep_reward": 551.7681274414062, "reward": 0.8436863422393799, "action": -1.7911618947982788}
{"mode": "train", "epochs": 3, "timestep": 4976, "ep_reward": 552.570068359375, "reward": 0.8019341826438904, "action": -1.1813143491744995}
{"mode": "train", "epochs": 3, "timestep": 4977, "ep_reward": 553.308837890625, "reward": 0.7387657165527344, "action": -0.58191978931427}
{"mode": "train", "epochs": 3, "timestep": 4978, "ep_reward": 553.958251953125, "reward": 0.6494009494781494, "action": -1.0128636360168457}
{"mode": "train", "epochs": 3, "timestep": 4979, "ep_reward": 554.4736938476562, "reward": 0.5154646635055542, "action": -0.8068282008171082}
{"mode": "train", "epochs": 3, "timestep": 4980, "ep_reward": 554.8458251953125, "reward": 0.3721110224723816, "action": -0.8290948867797852}
{"mode": "train", "epochs": 3, "timestep": 4981, "ep_reward": 555.1124877929688, "reward": 0.2666580080986023, "action": -0.707554817199707}
{"mode": "train", "epochs": 3, "timestep": 4982, "ep_reward": 555.253662109375, "reward": 0.14114457368850708, "action": -1.1357580423355103}
{"mode": "train", "epochs": 3, "timestep": 4983, "ep_reward": 555.2493896484375, "reward": -0.004245758056640625, "action": -0.3466697335243225}
{"mode": "train", "epochs": 3, "timestep": 4984, "ep_reward": 555.3683471679688, "reward": 0.11898529529571533, "action": -1.3481777906417847}
{"mode": "train", "epochs": 3, "timestep": 4985, "ep_reward": 555.621826171875, "reward": 0.2534641623497009, "action": -0.8138866424560547}
{"mode": "train", "epochs": 3, "timestep": 4986, "ep_reward": 556.0167236328125, "reward": 0.3948749303817749, "action": -1.239661693572998}
{"mode": "train", "epochs": 3, "timestep": 4987, "ep_reward": 556.5370483398438, "reward": 0.5203195810317993, "action": -1.25801682472229}
{"mode": "train", "epochs": 3, "timestep": 4988, "ep_reward": 557.1649169921875, "reward": 0.6278655529022217, "action": -0.16122066974639893}
{"mode": "train", "epochs": 3, "timestep": 4989, "ep_reward": 557.8892211914062, "reward": 0.7242863178253174, "action": -1.0096373558044434}
{"mode": "train", "epochs": 3, "timestep": 4990, "ep_reward": 558.6774291992188, "reward": 0.7881911993026733, "action": -1.4070827960968018}
{"mode": "train", "epochs": 3, "timestep": 4991, "ep_reward": 559.5057983398438, "reward": 0.828390896320343, "action": -0.5105850100517273}
{"mode": "train", "epochs": 3, "timestep": 4992, "ep_reward": 560.3638916015625, "reward": 0.8580806255340576, "action": -1.5152544975280762}
{"mode": "train", "epochs": 3, "timestep": 4993, "ep_reward": 561.2263793945312, "reward": 0.8624638915061951, "action": -0.3174927234649658}
{"mode": "train", "epochs": 3, "timestep": 4994, "ep_reward": 562.0864868164062, "reward": 0.8601162433624268, "action": -1.4261945486068726}
{"mode": "train", "epochs": 3, "timestep": 4995, "ep_reward": 562.915771484375, "reward": 0.8292673826217651, "action": -1.4871968030929565}
{"mode": "train", "epochs": 3, "timestep": 4996, "ep_reward": 563.689453125, "reward": 0.7736731767654419, "action": -1.4541614055633545}
{"mode": "train", "epochs": 3, "timestep": 4997, "ep_reward": 564.3765258789062, "reward": 0.6870512962341309, "action": -1.531294584274292}
{"mode": "train", "epochs": 3, "timestep": 4998, "ep_reward": 564.9365234375, "reward": 0.5600149631500244, "action": -1.3119028806686401}
{"mode": "train", "epochs": 3, "timestep": 4999, "ep_reward": 565.337646484375, "reward": 0.40114814043045044, "action": -1.0549142360687256}
{"mode": "train", "epochs": 3, "timestep": 5000, "ep_reward": 565.6396484375, "reward": 0.30200719833374023, "action": -0.8216298222541809}
{"mode": "train", "epochs": 3, "timestep": 5001, "ep_reward": 565.8224487304688, "reward": 0.18277990818023682, "action": -1.275453805923462}
{"mode": "train", "epochs": 3, "timestep": 5002, "ep_reward": 565.8660888671875, "reward": 0.043636441230773926, "action": -1.1178579330444336}
{"mode": "train", "epochs": 3, "timestep": 5003, "ep_reward": 565.9404907226562, "reward": 0.07441949844360352, "action": -0.6264693140983582}
{"mode": "train", "epochs": 3, "timestep": 5004, "ep_reward": 566.156982421875, "reward": 0.2164960503578186, "action": -1.3641393184661865}
{"mode": "train", "epochs": 3, "timestep": 5005, "ep_reward": 566.5079956054688, "reward": 0.351010262966156, "action": -0.8024049997329712}
{"mode": "train", "epochs": 3, "timestep": 5006, "ep_reward": 566.993896484375, "reward": 0.4858960509300232, "action": -1.0505787134170532}
{"mode": "train", "epochs": 3, "timestep": 5007, "ep_reward": 567.59521484375, "reward": 0.6012935638427734, "action": -0.13712257146835327}
{"mode": "train", "epochs": 3, "timestep": 5008, "ep_reward": 568.299560546875, "reward": 0.7043489217758179, "action": -1.6037249565124512}
{"mode": "train", "epochs": 3, "timestep": 5009, "ep_reward": 569.0690307617188, "reward": 0.7694598436355591, "action": -1.5212558507919312}
{"mode": "train", "epochs": 3, "timestep": 5010, "ep_reward": 569.884765625, "reward": 0.81575608253479, "action": -0.7041539549827576}
{"mode": "train", "epochs": 3, "timestep": 5011, "ep_reward": 570.7352294921875, "reward": 0.8504603505134583, "action": -1.9697279930114746}
{"mode": "train", "epochs": 3, "timestep": 5012, "ep_reward": 571.5926513671875, "reward": 0.8574111461639404, "action": -1.1314700841903687}
{"mode": "train", "epochs": 3, "timestep": 5013, "ep_reward": 572.447021484375, "reward": 0.8543629050254822, "action": -0.9497175812721252}
{"mode": "train", "epochs": 3, "timestep": 5014, "ep_reward": 573.2811279296875, "reward": 0.8341046571731567, "action": -0.44196951389312744}
{"mode": "train", "epochs": 3, "timestep": 5015, "ep_reward": 574.0780639648438, "reward": 0.7969654202461243, "action": -0.4171763062477112}
{"mode": "train", "epochs": 3, "timestep": 5016, "ep_reward": 574.812255859375, "reward": 0.7341864109039307, "action": -1.2165067195892334}
{"mode": "train", "epochs": 3, "timestep": 5017, "ep_reward": 575.4415893554688, "reward": 0.6293213963508606, "action": -0.7175212502479553}
{"mode": "train", "epochs": 3, "timestep": 5018, "ep_reward": 575.9325561523438, "reward": 0.4909968376159668, "action": -1.3447048664093018}
{"mode": "train", "epochs": 3, "timestep": 5019, "ep_reward": 576.2792358398438, "reward": 0.3466991186141968, "action": -0.5186020135879517}
{"mode": "train", "epochs": 3, "timestep": 5020, "ep_reward": 576.5152587890625, "reward": 0.2360437512397766, "action": -0.5568361282348633}
{"mode": "train", "epochs": 3, "timestep": 5021, "ep_reward": 576.6206665039062, "reward": 0.10541075468063354, "action": 0.050826311111450195}
{"mode": "train", "epochs": 3, "timestep": 5022, "ep_reward": 576.6315307617188, "reward": 0.010871529579162598, "action": -0.6908156871795654}
{"mode": "train", "epochs": 3, "timestep": 5023, "ep_reward": 576.7858276367188, "reward": 0.15428882837295532, "action": -1.3624365329742432}
{"mode": "train", "epochs": 3, "timestep": 5024, "ep_reward": 577.0752563476562, "reward": 0.2893992066383362, "action": -1.1956487894058228}
{"mode": "train", "epochs": 3, "timestep": 5025, "ep_reward": 577.4998168945312, "reward": 0.42455971240997314, "action": -0.9149813055992126}
{"mode": "train", "epochs": 3, "timestep": 5026, "ep_reward": 578.0504150390625, "reward": 0.5505995750427246, "action": -0.4773210883140564}
{"mode": "train", "epochs": 3, "timestep": 5027, "ep_reward": 578.711181640625, "reward": 0.6607425212860107, "action": -0.9871219992637634}
{"mode": "train", "epochs": 3, "timestep": 5028, "ep_reward": 579.4526977539062, "reward": 0.7415057420730591, "action": -1.8452742099761963}
{"mode": "train", "epochs": 3, "timestep": 5029, "ep_reward": 580.2452392578125, "reward": 0.7925269603729248, "action": -1.36758291721344}
{"mode": "train", "epochs": 3, "timestep": 5030, "ep_reward": 581.0738525390625, "reward": 0.8285989761352539, "action": -0.5067555904388428}
{"mode": "train", "epochs": 3, "timestep": 5031, "ep_reward": 581.927490234375, "reward": 0.8536110520362854, "action": 0.11975312232971191}
{"mode": "train", "epochs": 3, "timestep": 5032, "ep_reward": 582.7937622070312, "reward": 0.8662806749343872, "action": -0.9132441282272339}
{"mode": "train", "epochs": 3, "timestep": 5033, "ep_reward": 583.646484375, "reward": 0.8527365326881409, "action": -1.4539920091629028}
{"mode": "train", "epochs": 3, "timestep": 5034, "ep_reward": 584.460693359375, "reward": 0.8142171502113342, "action": -1.1421717405319214}
{"mode": "train", "epochs": 3, "timestep": 5035, "ep_reward": 585.2136840820312, "reward": 0.752974271774292, "action": -1.0055749416351318}
{"mode": "train", "epochs": 3, "timestep": 5036, "ep_reward": 585.8748168945312, "reward": 0.6611229181289673, "action": -0.5501666069030762}
{"mode": "train", "epochs": 3, "timestep": 5037, "ep_reward": 586.411865234375, "reward": 0.537043571472168, "action": -1.8496837615966797}
{"mode": "train", "epochs": 3, "timestep": 5038, "ep_reward": 586.7880859375, "reward": 0.3762018084526062, "action": -0.9627562165260315}
{"mode": "train", "epochs": 3, "timestep": 5039, "ep_reward": 587.0595703125, "reward": 0.2714839577674866, "action": -1.6742995977401733}
{"mode": "train", "epochs": 3, "timestep": 5040, "ep_reward": 587.2066040039062, "reward": 0.14700734615325928, "action": -0.9100807905197144}
{"mode": "train", "epochs": 3, "timestep": 5041, "ep_reward": 587.208984375, "reward": 0.0023959875106811523, "action": -1.009095311164856}
{"mode": "train", "epochs": 3, "timestep": 5042, "ep_reward": 587.322021484375, "reward": 0.11304837465286255, "action": -0.7993437051773071}
{"mode": "train", "epochs": 3, "timestep": 5043, "ep_reward": 587.5760498046875, "reward": 0.2540399432182312, "action": -1.7427003383636475}
{"mode": "train", "epochs": 3, "timestep": 5044, "ep_reward": 587.9590454101562, "reward": 0.38301950693130493, "action": -1.3818544149398804}
{"mode": "train", "epochs": 3, "timestep": 5045, "ep_reward": 588.4674682617188, "reward": 0.508428692817688, "action": -1.4238691329956055}
{"mode": "train", "epochs": 3, "timestep": 5046, "ep_reward": 589.0836791992188, "reward": 0.6162071228027344, "action": -0.012326300144195557}
{"mode": "train", "epochs": 3, "timestep": 5047, "ep_reward": 589.800048828125, "reward": 0.7163417339324951, "action": -1.313067078590393}
{"mode": "train", "epochs": 3, "timestep": 5048, "ep_reward": 590.57861328125, "reward": 0.7785801887512207, "action": -1.4729304313659668}
{"mode": "train", "epochs": 3, "timestep": 5049, "ep_reward": 591.3973388671875, "reward": 0.8187295198440552, "action": -0.7550932765007019}
{"mode": "train", "epochs": 3, "timestep": 5050, "ep_reward": 592.2433471679688, "reward": 0.8460356593132019, "action": -1.5118757486343384}
{"mode": "train", "epochs": 3, "timestep": 5051, "ep_reward": 593.091552734375, "reward": 0.8481874465942383, "action": -1.8490321636199951}
{"mode": "train", "epochs": 3, "timestep": 5052, "ep_reward": 593.9192504882812, "reward": 0.8276978731155396, "action": -1.5765292644500732}
{"mode": "train", "epochs": 3, "timestep": 5053, "ep_reward": 594.7053833007812, "reward": 0.786104679107666, "action": -0.7968010306358337}
{"mode": "train", "epochs": 3, "timestep": 5054, "ep_reward": 595.4293823242188, "reward": 0.7239944338798523, "action": -0.6713640093803406}
{"mode": "train", "epochs": 3, "timestep": 5055, "ep_reward": 596.05859375, "reward": 0.6291981339454651, "action": -0.5674440860748291}
{"mode": "train", "epochs": 3, "timestep": 5056, "ep_reward": 596.5545654296875, "reward": 0.4959554076194763, "action": -1.5617529153823853}
{"mode": "train", "epochs": 3, "timestep": 5057, "ep_reward": 596.9181518554688, "reward": 0.3636006712913513, "action": -0.3800433278083801}
{"mode": "train", "epochs": 3, "timestep": 5058, "ep_reward": 597.1743774414062, "reward": 0.2562483549118042, "action": -1.4034416675567627}
{"mode": "train", "epochs": 3, "timestep": 5059, "ep_reward": 597.3034057617188, "reward": 0.12902766466140747, "action": -1.3033626079559326}
{"mode": "train", "epochs": 3, "timestep": 5060, "ep_reward": 597.2877807617188, "reward": -0.015643596649169922, "action": -0.8472608923912048}
{"mode": "train", "epochs": 3, "timestep": 5061, "ep_reward": 597.4190673828125, "reward": 0.13131004571914673, "action": -0.38563835620880127}
{"mode": "train", "epochs": 3, "timestep": 5062, "ep_reward": 597.6971435546875, "reward": 0.2780535817146301, "action": -0.5217469334602356}
{"mode": "train", "epochs": 3, "timestep": 5063, "ep_reward": 598.1171264648438, "reward": 0.4199524521827698, "action": -0.3325520157814026}
{"mode": "train", "epochs": 3, "timestep": 5064, "ep_reward": 598.6683959960938, "reward": 0.5512794256210327, "action": -1.4130301475524902}
{"mode": "train", "epochs": 3, "timestep": 5065, "ep_reward": 599.3200073242188, "reward": 0.6515816450119019, "action": -1.4854493141174316}
{"mode": "train", "epochs": 3, "timestep": 5066, "ep_reward": 600.0513305664062, "reward": 0.7313133478164673, "action": -1.2732832431793213}
{"mode": "train", "epochs": 3, "timestep": 5067, "ep_reward": 600.8441162109375, "reward": 0.7928001284599304, "action": -1.0977317094802856}
{"mode": "train", "epochs": 3, "timestep": 5068, "ep_reward": 601.6808471679688, "reward": 0.8367369174957275, "action": -0.5310337543487549}
{"mode": "train", "epochs": 3, "timestep": 5069, "ep_reward": 602.548828125, "reward": 0.8679754734039307, "action": -1.1162419319152832}
{"mode": "train", "epochs": 3, "timestep": 5070, "ep_reward": 603.4279174804688, "reward": 0.8790653944015503, "action": -0.5022009015083313}
{"mode": "train", "epochs": 3, "timestep": 5071, "ep_reward": 604.3082885742188, "reward": 0.8803440928459167, "action": -0.7701936364173889}
{"mode": "train", "epochs": 3, "timestep": 5072, "ep_reward": 605.1723022460938, "reward": 0.8640058040618896, "action": -0.6641286611557007}
{"mode": "train", "epochs": 3, "timestep": 5073, "ep_reward": 606.002685546875, "reward": 0.8304029703140259, "action": -1.4295086860656738}
{"mode": "train", "epochs": 3, "timestep": 5074, "ep_reward": 606.768798828125, "reward": 0.7661112546920776, "action": -0.991459846496582}
{"mode": "train", "epochs": 3, "timestep": 5075, "ep_reward": 607.4442749023438, "reward": 0.6754956841468811, "action": -0.6890702843666077}
{"mode": "train", "epochs": 3, "timestep": 5076, "ep_reward": 607.996337890625, "reward": 0.552088737487793, "action": -1.442492961883545}
{"mode": "train", "epochs": 3, "timestep": 5077, "ep_reward": 608.37353515625, "reward": 0.3771687150001526, "action": -0.0562860369682312}
{"mode": "train", "epochs": 3, "timestep": 5078, "ep_reward": 608.6423950195312, "reward": 0.2688613533973694, "action": -0.6647989749908447}
{"mode": "train", "epochs": 3, "timestep": 5079, "ep_reward": 608.7860717773438, "reward": 0.14368993043899536, "action": -1.3661850690841675}
{"mode": "train", "epochs": 3, "timestep": 5080, "ep_reward": 608.7847290039062, "reward": -0.001324772834777832, "action": -0.8896852135658264}
{"mode": "train", "epochs": 3, "timestep": 5081, "ep_reward": 608.9010009765625, "reward": 0.11628073453903198, "action": -1.6396815776824951}
{"mode": "train", "epochs": 3, "timestep": 5082, "ep_reward": 609.14794921875, "reward": 0.24697422981262207, "action": -1.3013665676116943}
{"mode": "train", "epochs": 3, "timestep": 5083, "ep_reward": 609.5313110351562, "reward": 0.383334219455719, "action": -0.6880536675453186}
{"mode": "train", "epochs": 3, "timestep": 5084, "ep_reward": 610.0485229492188, "reward": 0.5172298550605774, "action": -1.4953837394714355}
{"mode": "train", "epochs": 3, "timestep": 5085, "ep_reward": 610.6712036132812, "reward": 0.6227079033851624, "action": -0.5389000177383423}
{"mode": "train", "epochs": 3, "timestep": 5086, "ep_reward": 611.387451171875, "reward": 0.7162314653396606, "action": -0.3648029565811157}
{"mode": "train", "epochs": 3, "timestep": 5087, "ep_reward": 612.17431640625, "reward": 0.786885142326355, "action": -0.8355870842933655}
{"mode": "train", "epochs": 3, "timestep": 5088, "ep_reward": 613.0056762695312, "reward": 0.8313559293746948, "action": -0.6652445197105408}
{"mode": "train", "epochs": 3, "timestep": 5089, "ep_reward": 613.8644409179688, "reward": 0.8587599396705627, "action": 0.007848262786865234}
{"mode": "train", "epochs": 3, "timestep": 5090, "ep_reward": 614.7393798828125, "reward": 0.8749492168426514, "action": -0.957822859287262}
{"mode": "train", "epochs": 3, "timestep": 5091, "ep_reward": 615.6065673828125, "reward": 0.8671863079071045, "action": -1.0482394695281982}
{"mode": "train", "epochs": 3, "timestep": 5092, "ep_reward": 616.4476318359375, "reward": 0.8410521149635315, "action": -0.6600573062896729}
{"mode": "train", "epochs": 3, "timestep": 5093, "ep_reward": 617.2447509765625, "reward": 0.7971367239952087, "action": -1.1661019325256348}
{"mode": "train", "epochs": 3, "timestep": 5094, "ep_reward": 617.9656372070312, "reward": 0.7208771705627441, "action": -1.778038740158081}
{"mode": "train", "epochs": 3, "timestep": 5095, "ep_reward": 618.5669555664062, "reward": 0.6013463735580444, "action": -0.7453117370605469}
{"mode": "train", "epochs": 3, "timestep": 5096, "ep_reward": 619.0202026367188, "reward": 0.45322614908218384, "action": -1.7209177017211914}
{"mode": "train", "epochs": 3, "timestep": 5097, "ep_reward": 619.3438110351562, "reward": 0.32363390922546387, "action": -0.7925336956977844}
{"mode": "train", "epochs": 3, "timestep": 5098, "ep_reward": 619.5523071289062, "reward": 0.20850658416748047, "action": -0.7477648258209229}
{"mode": "train", "epochs": 3, "timestep": 5099, "ep_reward": 619.6256713867188, "reward": 0.07334589958190918, "action": -1.015592336654663}
{"mode": "train", "epochs": 3, "timestep": 5100, "ep_reward": 619.6703491210938, "reward": 0.04469972848892212, "action": -1.1105387210845947}
{"mode": "train", "epochs": 3, "timestep": 5101, "ep_reward": 619.8541259765625, "reward": 0.18379473686218262, "action": -0.3279385566711426}
{"mode": "train", "epochs": 3, "timestep": 5102, "ep_reward": 620.186279296875, "reward": 0.33215129375457764, "action": -1.3441416025161743}
{"mode": "train", "epochs": 3, "timestep": 5103, "ep_reward": 620.6475830078125, "reward": 0.461292564868927, "action": -0.9081991910934448}
{"mode": "train", "epochs": 3, "timestep": 5104, "ep_reward": 621.2293090820312, "reward": 0.5817107558250427, "action": -1.5149651765823364}
{"mode": "train", "epochs": 3, "timestep": 5105, "ep_reward": 621.904541015625, "reward": 0.6752376556396484, "action": -0.6942874193191528}
{"mode": "train", "epochs": 3, "timestep": 5106, "ep_reward": 622.6596069335938, "reward": 0.7550824880599976, "action": -1.603374719619751}
{"mode": "train", "epochs": 3, "timestep": 5107, "ep_reward": 623.4641723632812, "reward": 0.8045918941497803, "action": -1.2238118648529053}
{"mode": "train", "epochs": 3, "timestep": 5108, "ep_reward": 624.302734375, "reward": 0.8385851383209229, "action": -0.2588288187980652}
{"mode": "train", "epochs": 3, "timestep": 5109, "ep_reward": 625.1656494140625, "reward": 0.8629412651062012, "action": -0.5306962132453918}
{"mode": "train", "epochs": 3, "timestep": 5110, "ep_reward": 626.0336303710938, "reward": 0.8679971694946289, "action": -1.4054632186889648}
{"mode": "train", "epochs": 3, "timestep": 5111, "ep_reward": 626.8820190429688, "reward": 0.8483901023864746, "action": -1.280074119567871}
{"mode": "train", "epochs": 3, "timestep": 5112, "ep_reward": 627.6911010742188, "reward": 0.809100866317749, "action": -0.4814068675041199}
{"mode": "train", "epochs": 3, "timestep": 5113, "ep_reward": 628.4434814453125, "reward": 0.7523966431617737, "action": -1.1541774272918701}
{"mode": "train", "epochs": 3, "timestep": 5114, "ep_reward": 629.1002197265625, "reward": 0.6567490100860596, "action": -1.3639615774154663}
{"mode": "train", "epochs": 3, "timestep": 5115, "ep_reward": 629.61865234375, "reward": 0.5184428095817566, "action": -1.509364366531372}
{"mode": "train", "epochs": 3, "timestep": 5116, "ep_reward": 629.9867553710938, "reward": 0.36810213327407837, "action": -1.4055631160736084}
{"mode": "train", "epochs": 3, "timestep": 5117, "ep_reward": 630.24853515625, "reward": 0.26179295778274536, "action": -1.5414578914642334}
{"mode": "train", "epochs": 3, "timestep": 5118, "ep_reward": 630.3841552734375, "reward": 0.1356329321861267, "action": -0.6326045989990234}
{"mode": "train", "epochs": 3, "timestep": 5119, "ep_reward": 630.3734741210938, "reward": -0.010652422904968262, "action": -0.6638942956924438}
{"mode": "train", "epochs": 3, "timestep": 5120, "ep_reward": 630.4981079101562, "reward": 0.12463605403900146, "action": -1.4360309839248657}
{"mode": "train", "epochs": 3, "timestep": 5121, "ep_reward": 630.7562866210938, "reward": 0.25816720724105835, "action": -0.8564600944519043}
{"mode": "train", "epochs": 3, "timestep": 5122, "ep_reward": 631.1552734375, "reward": 0.3989875912666321, "action": -1.538856029510498}
{"mode": "train", "epochs": 3, "timestep": 5123, "ep_reward": 631.67578125, "reward": 0.5205159783363342, "action": -1.8868393898010254}
{"mode": "train", "epochs": 3, "timestep": 5124, "ep_reward": 632.2967529296875, "reward": 0.6209640502929688, "action": -1.6235933303833008}
{"mode": "train", "epochs": 3, "timestep": 5125, "ep_reward": 632.9999389648438, "reward": 0.7031720876693726, "action": -0.9612100124359131}
{"mode": "train", "epochs": 3, "timestep": 5126, "ep_reward": 633.7688598632812, "reward": 0.768896222114563, "action": -0.8515869379043579}
{"mode": "train", "epochs": 3, "timestep": 5127, "ep_reward": 634.58154296875, "reward": 0.8126989603042603, "action": -0.8667611479759216}
{"mode": "train", "epochs": 3, "timestep": 5128, "ep_reward": 635.4168090820312, "reward": 0.8352930545806885, "action": -1.5087568759918213}
{"mode": "train", "epochs": 3, "timestep": 5129, "ep_reward": 636.248779296875, "reward": 0.8319905996322632, "action": -0.8438946008682251}
{"mode": "train", "epochs": 3, "timestep": 5130, "ep_reward": 637.062255859375, "reward": 0.813450813293457, "action": -1.4546754360198975}
{"mode": "train", "epochs": 3, "timestep": 5131, "ep_reward": 637.8257446289062, "reward": 0.7635051012039185, "action": -0.8138111233711243}
{"mode": "train", "epochs": 3, "timestep": 5132, "ep_reward": 638.5150146484375, "reward": 0.6892555952072144, "action": -0.5086273550987244}
{"mode": "train", "epochs": 3, "timestep": 5133, "ep_reward": 639.0971069335938, "reward": 0.5820677280426025, "action": -0.49743664264678955}
{"mode": "train", "epochs": 3, "timestep": 5134, "ep_reward": 639.5311889648438, "reward": 0.4340794086456299, "action": -0.44661426544189453}
{"mode": "train", "epochs": 3, "timestep": 5135, "ep_reward": 639.857177734375, "reward": 0.3259979486465454, "action": -1.8366172313690186}
{"mode": "train", "epochs": 3, "timestep": 5136, "ep_reward": 640.0687255859375, "reward": 0.21152186393737793, "action": -0.7868862152099609}
{"mode": "train", "epochs": 3, "timestep": 5137, "ep_reward": 640.1456298828125, "reward": 0.07691186666488647, "action": 0.1256648302078247}
{"mode": "train", "epochs": 3, "timestep": 5138, "ep_reward": 640.1867065429688, "reward": 0.041076064109802246, "action": -1.2167463302612305}
{"mode": "train", "epochs": 3, "timestep": 5139, "ep_reward": 640.3673095703125, "reward": 0.18060940504074097, "action": -1.0365747213363647}
{"mode": "train", "epochs": 3, "timestep": 5140, "ep_reward": 640.6875610351562, "reward": 0.3202565908432007, "action": -0.9811242818832397}
{"mode": "train", "epochs": 3, "timestep": 5141, "ep_reward": 641.1431884765625, "reward": 0.4556571841239929, "action": -0.31371867656707764}
{"mode": "train", "epochs": 3, "timestep": 5142, "ep_reward": 641.7269287109375, "reward": 0.5837470293045044, "action": -0.928796648979187}
{"mode": "train", "epochs": 3, "timestep": 5143, "ep_reward": 642.4097900390625, "reward": 0.6828532218933105, "action": -0.9876909852027893}
{"mode": "train", "epochs": 3, "timestep": 5144, "ep_reward": 643.1687622070312, "reward": 0.7589433193206787, "action": -1.1750080585479736}
{"mode": "train", "epochs": 3, "timestep": 5145, "ep_reward": 643.9810180664062, "reward": 0.8122698664665222, "action": -1.0806150436401367}
{"mode": "train", "epochs": 3, "timestep": 5146, "ep_reward": 644.8287963867188, "reward": 0.8477556705474854, "action": -0.9075567722320557}
{"mode": "train", "epochs": 3, "timestep": 5147, "ep_reward": 645.6965942382812, "reward": 0.8678247928619385, "action": -1.001620888710022}
{"mode": "train", "epochs": 3, "timestep": 5148, "ep_reward": 646.5676879882812, "reward": 0.8710882067680359, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5149, "ep_reward": 647.4168090820312, "reward": 0.849145233631134, "action": -1.0533344745635986}
{"mode": "train", "epochs": 3, "timestep": 5150, "ep_reward": 648.2317504882812, "reward": 0.8149362802505493, "action": -1.2405204772949219}
{"mode": "train", "epochs": 3, "timestep": 5151, "ep_reward": 648.9852294921875, "reward": 0.7534984350204468, "action": -0.5957317352294922}
{"mode": "train", "epochs": 3, "timestep": 5152, "ep_reward": 649.6528930664062, "reward": 0.667656660079956, "action": -0.8846712708473206}
{"mode": "train", "epochs": 3, "timestep": 5153, "ep_reward": 650.19384765625, "reward": 0.5409612655639648, "action": -0.18632709980010986}
{"mode": "train", "epochs": 3, "timestep": 5154, "ep_reward": 650.5780029296875, "reward": 0.38416188955307007, "action": -1.076245665550232}
{"mode": "train", "epochs": 3, "timestep": 5155, "ep_reward": 650.85400390625, "reward": 0.2760063409805298, "action": -1.2737071514129639}
{"mode": "train", "epochs": 3, "timestep": 5156, "ep_reward": 651.0060424804688, "reward": 0.15203672647476196, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5157, "ep_reward": 651.014404296875, "reward": 0.008355438709259033, "action": -1.3316255807876587}
{"mode": "train", "epochs": 3, "timestep": 5158, "ep_reward": 651.1220092773438, "reward": 0.10759484767913818, "action": -0.8238697052001953}
{"mode": "train", "epochs": 3, "timestep": 5159, "ep_reward": 651.3702392578125, "reward": 0.24824637174606323, "action": -1.0914013385772705}
{"mode": "train", "epochs": 3, "timestep": 5160, "ep_reward": 651.7556762695312, "reward": 0.3854396343231201, "action": -1.1114239692687988}
{"mode": "train", "epochs": 3, "timestep": 5161, "ep_reward": 652.2688598632812, "reward": 0.5131687521934509, "action": -0.9020133018493652}
{"mode": "train", "epochs": 3, "timestep": 5162, "ep_reward": 652.8945922851562, "reward": 0.6257373094558716, "action": -0.22977429628372192}
{"mode": "train", "epochs": 3, "timestep": 5163, "ep_reward": 653.6170654296875, "reward": 0.7224822044372559, "action": -0.8751175403594971}
{"mode": "train", "epochs": 3, "timestep": 5164, "ep_reward": 654.4063720703125, "reward": 0.7893242835998535, "action": -1.055545687675476}
{"mode": "train", "epochs": 3, "timestep": 5165, "ep_reward": 655.2409057617188, "reward": 0.8345316648483276, "action": -1.024050235748291}
{"mode": "train", "epochs": 3, "timestep": 5166, "ep_reward": 656.1033935546875, "reward": 0.8624696135520935, "action": -1.7090024948120117}
{"mode": "train", "epochs": 3, "timestep": 5167, "ep_reward": 656.9725341796875, "reward": 0.8691582679748535, "action": -1.3053017854690552}
{"mode": "train", "epochs": 3, "timestep": 5168, "ep_reward": 657.8356323242188, "reward": 0.8630963563919067, "action": -1.5039881467819214}
{"mode": "train", "epochs": 3, "timestep": 5169, "ep_reward": 658.6727294921875, "reward": 0.8371033072471619, "action": -0.7697136998176575}
{"mode": "train", "epochs": 3, "timestep": 5170, "ep_reward": 659.4685668945312, "reward": 0.7958659529685974, "action": -0.9762088060379028}
{"mode": "train", "epochs": 3, "timestep": 5171, "ep_reward": 660.1939697265625, "reward": 0.7254311442375183, "action": -0.6415830254554749}
{"mode": "train", "epochs": 3, "timestep": 5172, "ep_reward": 660.8192749023438, "reward": 0.62530517578125, "action": -0.7047548294067383}
{"mode": "train", "epochs": 3, "timestep": 5173, "ep_reward": 661.3048706054688, "reward": 0.4855800271034241, "action": -1.4428071975708008}
{"mode": "train", "epochs": 3, "timestep": 5174, "ep_reward": 661.646728515625, "reward": 0.3418445587158203, "action": -0.9777674674987793}
{"mode": "train", "epochs": 3, "timestep": 5175, "ep_reward": 661.876953125, "reward": 0.23021858930587769, "action": -1.1411330699920654}
{"mode": "train", "epochs": 3, "timestep": 5176, "ep_reward": 661.9756469726562, "reward": 0.09869056940078735, "action": -0.2971697449684143}
{"mode": "train", "epochs": 3, "timestep": 5177, "ep_reward": 661.9937744140625, "reward": 0.018099725246429443, "action": -1.149472713470459}
{"mode": "train", "epochs": 3, "timestep": 5178, "ep_reward": 662.1544189453125, "reward": 0.1606532335281372, "action": -1.1382025480270386}
{"mode": "train", "epochs": 3, "timestep": 5179, "ep_reward": 662.4530639648438, "reward": 0.29866790771484375, "action": -1.2420295476913452}
{"mode": "train", "epochs": 3, "timestep": 5180, "ep_reward": 662.885498046875, "reward": 0.4324195384979248, "action": -0.15552204847335815}
{"mode": "train", "epochs": 3, "timestep": 5181, "ep_reward": 663.4513549804688, "reward": 0.5658367872238159, "action": -0.18747293949127197}
{"mode": "train", "epochs": 3, "timestep": 5182, "ep_reward": 664.1273803710938, "reward": 0.6760169863700867, "action": -0.7102195024490356}
{"mode": "train", "epochs": 3, "timestep": 5183, "ep_reward": 664.88427734375, "reward": 0.7569051384925842, "action": -1.328508973121643}
{"mode": "train", "epochs": 3, "timestep": 5184, "ep_reward": 665.6953735351562, "reward": 0.8111212849617004, "action": -1.372689962387085}
{"mode": "train", "epochs": 3, "timestep": 5185, "ep_reward": 666.5423583984375, "reward": 0.847010612487793, "action": -1.200157880783081}
{"mode": "train", "epochs": 3, "timestep": 5186, "ep_reward": 667.4105224609375, "reward": 0.8681612014770508, "action": -0.264570951461792}
{"mode": "train", "epochs": 3, "timestep": 5187, "ep_reward": 668.2919921875, "reward": 0.8814762830734253, "action": -1.058937430381775}
{"mode": "train", "epochs": 3, "timestep": 5188, "ep_reward": 669.1653442382812, "reward": 0.8733527660369873, "action": -1.0813748836517334}
{"mode": "train", "epochs": 3, "timestep": 5189, "ep_reward": 670.0134887695312, "reward": 0.8481695055961609, "action": -0.9398753643035889}
{"mode": "train", "epochs": 3, "timestep": 5190, "ep_reward": 670.8169555664062, "reward": 0.8034461736679077, "action": -1.3209662437438965}
{"mode": "train", "epochs": 3, "timestep": 5191, "ep_reward": 671.5449829101562, "reward": 0.7280268669128418, "action": -0.7440492510795593}
{"mode": "train", "epochs": 3, "timestep": 5192, "ep_reward": 672.1702880859375, "reward": 0.625311553478241, "action": -1.0347175598144531}
{"mode": "train", "epochs": 3, "timestep": 5193, "ep_reward": 672.6500244140625, "reward": 0.4797462224960327, "action": -0.7344725131988525}
{"mode": "train", "epochs": 3, "timestep": 5194, "ep_reward": 672.984375, "reward": 0.3343374729156494, "action": -0.4336240887641907}
{"mode": "train", "epochs": 3, "timestep": 5195, "ep_reward": 673.2056274414062, "reward": 0.22122204303741455, "action": -0.8616432547569275}
{"mode": "train", "epochs": 3, "timestep": 5196, "ep_reward": 673.2938232421875, "reward": 0.08817809820175171, "action": 0.4041869640350342}
{"mode": "train", "epochs": 3, "timestep": 5197, "ep_reward": 673.3231811523438, "reward": 0.029388248920440674, "action": -0.13367599248886108}
{"mode": "train", "epochs": 3, "timestep": 5198, "ep_reward": 673.4994506835938, "reward": 0.17626279592514038, "action": -0.37294358015060425}
{"mode": "train", "epochs": 3, "timestep": 5199, "ep_reward": 673.8220825195312, "reward": 0.3226545453071594, "action": -0.9920108914375305}
{"mode": "train", "epochs": 3, "timestep": 5200, "ep_reward": 674.27783203125, "reward": 0.45572054386138916, "action": -1.1342332363128662}
{"mode": "train", "epochs": 3, "timestep": 5201, "ep_reward": 674.8515625, "reward": 0.5737415552139282, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5202, "ep_reward": 675.515625, "reward": 0.6640793681144714, "action": -0.80937659740448}
{"mode": "train", "epochs": 3, "timestep": 5203, "ep_reward": 676.26171875, "reward": 0.7461076974868774, "action": -0.39152300357818604}
{"mode": "train", "epochs": 3, "timestep": 5204, "ep_reward": 677.0711059570312, "reward": 0.8093911409378052, "action": -1.7587432861328125}
{"mode": "train", "epochs": 3, "timestep": 5205, "ep_reward": 677.912353515625, "reward": 0.8412359356880188, "action": -1.3062092065811157}
{"mode": "train", "epochs": 3, "timestep": 5206, "ep_reward": 678.7725830078125, "reward": 0.8602206110954285, "action": -1.119080662727356}
{"mode": "train", "epochs": 3, "timestep": 5207, "ep_reward": 679.6369018554688, "reward": 0.8643414378166199, "action": -0.9771604537963867}
{"mode": "train", "epochs": 3, "timestep": 5208, "ep_reward": 680.4894409179688, "reward": 0.8525252342224121, "action": -0.7446357011795044}
{"mode": "train", "epochs": 3, "timestep": 5209, "ep_reward": 681.3128662109375, "reward": 0.8234081268310547, "action": -0.0770953893661499}
{"mode": "train", "epochs": 3, "timestep": 5210, "ep_reward": 682.0910034179688, "reward": 0.7781339287757874, "action": -0.868141770362854}
{"mode": "train", "epochs": 3, "timestep": 5211, "ep_reward": 682.78759765625, "reward": 0.6966153383255005, "action": -0.5930746793746948}
{"mode": "train", "epochs": 3, "timestep": 5212, "ep_reward": 683.3709716796875, "reward": 0.5833653211593628, "action": -1.1609749794006348}
{"mode": "train", "epochs": 3, "timestep": 5213, "ep_reward": 683.7932739257812, "reward": 0.42228537797927856, "action": -1.0968250036239624}
{"mode": "train", "epochs": 3, "timestep": 5214, "ep_reward": 684.091796875, "reward": 0.2985234260559082, "action": -1.1991134881973267}
{"mode": "train", "epochs": 3, "timestep": 5215, "ep_reward": 684.2705688476562, "reward": 0.17879199981689453, "action": -0.6433641910552979}
{"mode": "train", "epochs": 3, "timestep": 5216, "ep_reward": 684.3095703125, "reward": 0.03898584842681885, "action": -0.7717269062995911}
{"mode": "train", "epochs": 3, "timestep": 5217, "ep_reward": 684.3885498046875, "reward": 0.07895445823669434, "action": -0.6947307586669922}
{"mode": "train", "epochs": 3, "timestep": 5218, "ep_reward": 684.60888671875, "reward": 0.22034704685211182, "action": -1.226932406425476}
{"mode": "train", "epochs": 3, "timestep": 5219, "ep_reward": 684.9653930664062, "reward": 0.3564980626106262, "action": -1.3428802490234375}
{"mode": "train", "epochs": 3, "timestep": 5220, "ep_reward": 685.4498291015625, "reward": 0.4844360947608948, "action": -1.192190170288086}
{"mode": "train", "epochs": 3, "timestep": 5221, "ep_reward": 686.0484008789062, "reward": 0.5985574722290039, "action": -1.2588318586349487}
{"mode": "train", "epochs": 3, "timestep": 5222, "ep_reward": 686.7391357421875, "reward": 0.6907181739807129, "action": -0.8252201676368713}
{"mode": "train", "epochs": 3, "timestep": 5223, "ep_reward": 687.5033569335938, "reward": 0.7642486691474915, "action": -1.5224523544311523}
{"mode": "train", "epochs": 3, "timestep": 5224, "ep_reward": 688.3125610351562, "reward": 0.8092252016067505, "action": -1.6553599834442139}
{"mode": "train", "epochs": 3, "timestep": 5225, "ep_reward": 689.1463012695312, "reward": 0.8337485194206238, "action": -0.6316813826560974}
{"mode": "train", "epochs": 3, "timestep": 5226, "ep_reward": 689.9950561523438, "reward": 0.8487441539764404, "action": -0.08805203437805176}
{"mode": "train", "epochs": 3, "timestep": 5227, "ep_reward": 690.8450317382812, "reward": 0.8499521613121033, "action": -1.0534378290176392}
{"mode": "train", "epochs": 3, "timestep": 5228, "ep_reward": 691.6677856445312, "reward": 0.8227241039276123, "action": -0.5194944143295288}
{"mode": "train", "epochs": 3, "timestep": 5229, "ep_reward": 692.445068359375, "reward": 0.7773021459579468, "action": -0.7318291068077087}
{"mode": "train", "epochs": 3, "timestep": 5230, "ep_reward": 693.146240234375, "reward": 0.7011619806289673, "action": -0.3994694948196411}
{"mode": "train", "epochs": 3, "timestep": 5231, "ep_reward": 693.74072265625, "reward": 0.5945079922676086, "action": -0.6968666315078735}
{"mode": "train", "epochs": 3, "timestep": 5232, "ep_reward": 694.185546875, "reward": 0.44483548402786255, "action": -0.9327288269996643}
{"mode": "train", "epochs": 3, "timestep": 5233, "ep_reward": 694.5009155273438, "reward": 0.31535810232162476, "action": -1.2974226474761963}
{"mode": "train", "epochs": 3, "timestep": 5234, "ep_reward": 694.6996459960938, "reward": 0.19875508546829224, "action": -0.6477164626121521}
{"mode": "train", "epochs": 3, "timestep": 5235, "ep_reward": 694.76171875, "reward": 0.06209689378738403, "action": -0.22066998481750488}
{"mode": "train", "epochs": 3, "timestep": 5236, "ep_reward": 694.8178100585938, "reward": 0.056088268756866455, "action": -1.7007482051849365}
{"mode": "train", "epochs": 3, "timestep": 5237, "ep_reward": 695.011474609375, "reward": 0.1936938762664795, "action": -0.8898159265518188}
{"mode": "train", "epochs": 3, "timestep": 5238, "ep_reward": 695.3467407226562, "reward": 0.33525460958480835, "action": -1.403369426727295}
{"mode": "train", "epochs": 3, "timestep": 5239, "ep_reward": 695.8111572265625, "reward": 0.46442943811416626, "action": -0.2775734066963196}
{"mode": "train", "epochs": 3, "timestep": 5240, "ep_reward": 696.4030151367188, "reward": 0.5918583869934082, "action": -0.6617355346679688}
{"mode": "train", "epochs": 3, "timestep": 5241, "ep_reward": 697.0948486328125, "reward": 0.6918516159057617, "action": -1.119270920753479}
{"mode": "train", "epochs": 3, "timestep": 5242, "ep_reward": 697.8591918945312, "reward": 0.7643135190010071, "action": -0.9469332098960876}
{"mode": "train", "epochs": 3, "timestep": 5243, "ep_reward": 698.6765747070312, "reward": 0.8173885941505432, "action": -1.3803777694702148}
{"mode": "train", "epochs": 3, "timestep": 5244, "ep_reward": 699.5247192382812, "reward": 0.848156750202179, "action": -0.2712332010269165}
{"mode": "train", "epochs": 3, "timestep": 5245, "ep_reward": 700.3961181640625, "reward": 0.8714202046394348, "action": -0.22846585512161255}
{"mode": "train", "epochs": 3, "timestep": 5246, "ep_reward": 701.2753295898438, "reward": 0.8792016506195068, "action": -0.5093375444412231}
{"mode": "train", "epochs": 3, "timestep": 5247, "ep_reward": 702.1446533203125, "reward": 0.8693121671676636, "action": -0.8263269066810608}
{"mode": "train", "epochs": 3, "timestep": 5248, "ep_reward": 702.9840087890625, "reward": 0.8393744230270386, "action": -1.2302416563034058}
{"mode": "train", "epochs": 3, "timestep": 5249, "ep_reward": 703.7675170898438, "reward": 0.783498227596283, "action": -1.139582872390747}
{"mode": "train", "epochs": 3, "timestep": 5250, "ep_reward": 704.4668579101562, "reward": 0.6993610858917236, "action": -0.8875821828842163}
{"mode": "train", "epochs": 3, "timestep": 5251, "ep_reward": 705.0491943359375, "reward": 0.5823246240615845, "action": -1.642382025718689}
{"mode": "train", "epochs": 3, "timestep": 5252, "ep_reward": 705.4623413085938, "reward": 0.4131646752357483, "action": -1.0137617588043213}
{"mode": "train", "epochs": 3, "timestep": 5253, "ep_reward": 705.7582397460938, "reward": 0.2959026098251343, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5254, "ep_reward": 705.9338989257812, "reward": 0.1756885051727295, "action": -1.8819329738616943}
{"mode": "train", "epochs": 3, "timestep": 5255, "ep_reward": 705.969482421875, "reward": 0.035601794719696045, "action": -1.027381181716919}
{"mode": "train", "epochs": 3, "timestep": 5256, "ep_reward": 706.0516357421875, "reward": 0.08217167854309082, "action": -0.766599714756012}
{"mode": "train", "epochs": 3, "timestep": 5257, "ep_reward": 706.2743530273438, "reward": 0.22273772954940796, "action": -1.4190282821655273}
{"mode": "train", "epochs": 3, "timestep": 5258, "ep_reward": 706.6310424804688, "reward": 0.35666775703430176, "action": -1.0813740491867065}
{"mode": "train", "epochs": 3, "timestep": 5259, "ep_reward": 707.1190795898438, "reward": 0.4880405068397522, "action": -0.5224029421806335}
{"mode": "train", "epochs": 3, "timestep": 5260, "ep_reward": 707.7279663085938, "reward": 0.6089144945144653, "action": -1.208787202835083}
{"mode": "train", "epochs": 3, "timestep": 5261, "ep_reward": 708.4276123046875, "reward": 0.6996239423751831, "action": -1.75579833984375}
{"mode": "train", "epochs": 3, "timestep": 5262, "ep_reward": 709.1908569335938, "reward": 0.7632269263267517, "action": -0.16607195138931274}
{"mode": "train", "epochs": 3, "timestep": 5263, "ep_reward": 710.011474609375, "reward": 0.8205888867378235, "action": -1.5674786567687988}
{"mode": "train", "epochs": 3, "timestep": 5264, "ep_reward": 710.8573608398438, "reward": 0.8458671569824219, "action": -0.11768418550491333}
{"mode": "train", "epochs": 3, "timestep": 5265, "ep_reward": 711.7235107421875, "reward": 0.8661389946937561, "action": -1.6379245519638062}
{"mode": "train", "epochs": 3, "timestep": 5266, "ep_reward": 712.580078125, "reward": 0.8565590381622314, "action": -1.1208934783935547}
{"mode": "train", "epochs": 3, "timestep": 5267, "ep_reward": 713.4126586914062, "reward": 0.8325819373130798, "action": -0.7930451035499573}
{"mode": "train", "epochs": 3, "timestep": 5268, "ep_reward": 714.201904296875, "reward": 0.7892699837684631, "action": -0.7794871926307678}
{"mode": "train", "epochs": 3, "timestep": 5269, "ep_reward": 714.9204711914062, "reward": 0.7185667753219604, "action": -0.04133492708206177}
{"mode": "train", "epochs": 3, "timestep": 5270, "ep_reward": 715.5443115234375, "reward": 0.623851478099823, "action": -0.611240565776825}
{"mode": "train", "epochs": 3, "timestep": 5271, "ep_reward": 716.0289916992188, "reward": 0.4846816062927246, "action": 0.5037133693695068}
{"mode": "train", "epochs": 3, "timestep": 5272, "ep_reward": 716.36572265625, "reward": 0.33675163984298706, "action": -1.6416404247283936}
{"mode": "train", "epochs": 3, "timestep": 5273, "ep_reward": 716.5900268554688, "reward": 0.22430574893951416, "action": -0.7328695058822632}
{"mode": "train", "epochs": 3, "timestep": 5274, "ep_reward": 716.6817626953125, "reward": 0.09174942970275879, "action": -0.3954041600227356}
{"mode": "train", "epochs": 3, "timestep": 5275, "ep_reward": 716.7073364257812, "reward": 0.025601863861083984, "action": 0.26136815547943115}
{"mode": "train", "epochs": 3, "timestep": 5276, "ep_reward": 716.8845825195312, "reward": 0.17721736431121826, "action": -0.6976372003555298}
{"mode": "train", "epochs": 3, "timestep": 5277, "ep_reward": 717.2033081054688, "reward": 0.31872081756591797, "action": -0.7122294306755066}
{"mode": "train", "epochs": 3, "timestep": 5278, "ep_reward": 717.658447265625, "reward": 0.4551212191581726, "action": -1.632500410079956}
{"mode": "train", "epochs": 3, "timestep": 5279, "ep_reward": 718.2261962890625, "reward": 0.5677365064620972, "action": -1.1878434419631958}
{"mode": "train", "epochs": 3, "timestep": 5280, "ep_reward": 718.8936157226562, "reward": 0.6674352884292603, "action": -0.8452755808830261}
{"mode": "train", "epochs": 3, "timestep": 5281, "ep_reward": 719.6425170898438, "reward": 0.7488718032836914, "action": -0.5161968469619751}
{"mode": "train", "epochs": 3, "timestep": 5282, "ep_reward": 720.4539184570312, "reward": 0.8113960027694702, "action": -1.246569037437439}
{"mode": "train", "epochs": 3, "timestep": 5283, "ep_reward": 721.3023071289062, "reward": 0.8483668565750122, "action": -1.546632170677185}
{"mode": "train", "epochs": 3, "timestep": 5284, "ep_reward": 722.1691284179688, "reward": 0.8667930960655212, "action": -1.337903618812561}
{"mode": "train", "epochs": 3, "timestep": 5285, "ep_reward": 723.0406494140625, "reward": 0.8715310096740723, "action": -1.3981305360794067}
{"mode": "train", "epochs": 3, "timestep": 5286, "ep_reward": 723.9002685546875, "reward": 0.8595944046974182, "action": -0.7188624143600464}
{"mode": "train", "epochs": 3, "timestep": 5287, "ep_reward": 724.7353515625, "reward": 0.8350761532783508, "action": -0.9616265296936035}
{"mode": "train", "epochs": 3, "timestep": 5288, "ep_reward": 725.5214233398438, "reward": 0.7860763072967529, "action": -0.9712201356887817}
{"mode": "train", "epochs": 3, "timestep": 5289, "ep_reward": 726.2300415039062, "reward": 0.70864337682724, "action": -0.5284234285354614}
{"mode": "train", "epochs": 3, "timestep": 5290, "ep_reward": 726.83203125, "reward": 0.6020048260688782, "action": -0.7878929376602173}
{"mode": "train", "epochs": 3, "timestep": 5291, "ep_reward": 727.2849731445312, "reward": 0.4529609680175781, "action": -0.4104582667350769}
{"mode": "train", "epochs": 3, "timestep": 5292, "ep_reward": 727.6029052734375, "reward": 0.31790798902511597, "action": -1.0353368520736694}
{"mode": "train", "epochs": 3, "timestep": 5293, "ep_reward": 727.8046264648438, "reward": 0.20172643661499023, "action": -0.7834020853042603}
{"mode": "train", "epochs": 3, "timestep": 5294, "ep_reward": 727.8701782226562, "reward": 0.06553393602371216, "action": -0.5851122140884399}
{"mode": "train", "epochs": 3, "timestep": 5295, "ep_reward": 727.9229125976562, "reward": 0.0527346134185791, "action": -0.8863045573234558}
{"mode": "train", "epochs": 3, "timestep": 5296, "ep_reward": 728.1137084960938, "reward": 0.19077366590499878, "action": -1.9411664009094238}
{"mode": "train", "epochs": 3, "timestep": 5297, "ep_reward": 728.4329223632812, "reward": 0.3192381262779236, "action": -1.174874186515808}
{"mode": "train", "epochs": 3, "timestep": 5298, "ep_reward": 728.8865966796875, "reward": 0.45370161533355713, "action": -1.4479399919509888}
{"mode": "train", "epochs": 3, "timestep": 5299, "ep_reward": 729.45654296875, "reward": 0.5699479579925537, "action": -0.9537913799285889}
{"mode": "train", "epochs": 3, "timestep": 5300, "ep_reward": 730.1270751953125, "reward": 0.6705259680747986, "action": -1.3816096782684326}
{"mode": "train", "epochs": 3, "timestep": 5301, "ep_reward": 730.8695068359375, "reward": 0.7424408197402954, "action": -1.052453875541687}
{"mode": "train", "epochs": 3, "timestep": 5302, "ep_reward": 731.6641845703125, "reward": 0.7946955561637878, "action": -0.6437716484069824}
{"mode": "train", "epochs": 3, "timestep": 5303, "ep_reward": 732.4932861328125, "reward": 0.8291215300559998, "action": 0.07995355129241943}
{"mode": "train", "epochs": 3, "timestep": 5304, "ep_reward": 733.3433227539062, "reward": 0.8500480651855469, "action": -0.06288832426071167}
{"mode": "train", "epochs": 3, "timestep": 5305, "ep_reward": 734.194091796875, "reward": 0.8507991433143616, "action": -0.9059215188026428}
{"mode": "train", "epochs": 3, "timestep": 5306, "ep_reward": 735.0184936523438, "reward": 0.8244088292121887, "action": -0.8664380311965942}
{"mode": "train", "epochs": 3, "timestep": 5307, "ep_reward": 735.7933959960938, "reward": 0.7749302387237549, "action": -0.19770997762680054}
{"mode": "train", "epochs": 3, "timestep": 5308, "ep_reward": 736.4977416992188, "reward": 0.7043445706367493, "action": -0.7288018465042114}
{"mode": "train", "epochs": 3, "timestep": 5309, "ep_reward": 737.0912475585938, "reward": 0.5935251712799072, "action": -0.708340585231781}
{"mode": "train", "epochs": 3, "timestep": 5310, "ep_reward": 737.5344848632812, "reward": 0.44323307275772095, "action": -1.3716460466384888}
{"mode": "train", "epochs": 3, "timestep": 5311, "ep_reward": 737.8482666015625, "reward": 0.3137865662574768, "action": -1.5069446563720703}
{"mode": "train", "epochs": 3, "timestep": 5312, "ep_reward": 738.045166015625, "reward": 0.1969035267829895, "action": -0.9430873394012451}
{"mode": "train", "epochs": 3, "timestep": 5313, "ep_reward": 738.1050415039062, "reward": 0.059898197650909424, "action": -1.2146753072738647}
{"mode": "train", "epochs": 3, "timestep": 5314, "ep_reward": 738.1633911132812, "reward": 0.05835336446762085, "action": -0.7197261452674866}
{"mode": "train", "epochs": 3, "timestep": 5315, "ep_reward": 738.3622436523438, "reward": 0.1988685131072998, "action": -0.5417044162750244}
{"mode": "train", "epochs": 3, "timestep": 5316, "ep_reward": 738.7063598632812, "reward": 0.34410130977630615, "action": -0.8351336717605591}
{"mode": "train", "epochs": 3, "timestep": 5317, "ep_reward": 739.1846313476562, "reward": 0.47826266288757324, "action": -1.1469424962997437}
{"mode": "train", "epochs": 3, "timestep": 5318, "ep_reward": 739.778076171875, "reward": 0.5934469699859619, "action": -0.8483763933181763}
{"mode": "train", "epochs": 3, "timestep": 5319, "ep_reward": 740.469482421875, "reward": 0.6913868188858032, "action": -1.0624935626983643}
{"mode": "train", "epochs": 3, "timestep": 5320, "ep_reward": 741.2343139648438, "reward": 0.7648449540138245, "action": -0.6390500068664551}
{"mode": "train", "epochs": 3, "timestep": 5321, "ep_reward": 742.0555419921875, "reward": 0.8212095499038696, "action": -0.2545519471168518}
{"mode": "train", "epochs": 3, "timestep": 5322, "ep_reward": 742.9172973632812, "reward": 0.8617573976516724, "action": -0.4026780128479004}
{"mode": "train", "epochs": 3, "timestep": 5323, "ep_reward": 743.8021240234375, "reward": 0.8848018050193787, "action": -0.7179262638092041}
{"mode": "train", "epochs": 3, "timestep": 5324, "ep_reward": 744.6935424804688, "reward": 0.8914395570755005, "action": -0.32143527269363403}
{"mode": "train", "epochs": 3, "timestep": 5325, "ep_reward": 745.5810546875, "reward": 0.8875269293785095, "action": -1.0914498567581177}
{"mode": "train", "epochs": 3, "timestep": 5326, "ep_reward": 746.4436645507812, "reward": 0.8625901937484741, "action": -0.583774745464325}
{"mode": "train", "epochs": 3, "timestep": 5327, "ep_reward": 747.2669677734375, "reward": 0.8233300447463989, "action": -1.185261845588684}
{"mode": "train", "epochs": 3, "timestep": 5328, "ep_reward": 748.0213012695312, "reward": 0.754358172416687, "action": -1.4029518365859985}
{"mode": "train", "epochs": 3, "timestep": 5329, "ep_reward": 748.6720581054688, "reward": 0.650780200958252, "action": -0.8351459503173828}
{"mode": "train", "epochs": 3, "timestep": 5330, "ep_reward": 749.1878662109375, "reward": 0.5157943964004517, "action": -1.1998087167739868}
{"mode": "train", "epochs": 3, "timestep": 5331, "ep_reward": 749.5352172851562, "reward": 0.3473552465438843, "action": -1.2845945358276367}
{"mode": "train", "epochs": 3, "timestep": 5332, "ep_reward": 749.7721557617188, "reward": 0.2369360327720642, "action": -0.5242283344268799}
{"mode": "train", "epochs": 3, "timestep": 5333, "ep_reward": 749.8786010742188, "reward": 0.10643947124481201, "action": -0.3837134838104248}
{"mode": "train", "epochs": 3, "timestep": 5334, "ep_reward": 749.88818359375, "reward": 0.009571492671966553, "action": -1.7715522050857544}
{"mode": "train", "epochs": 3, "timestep": 5335, "ep_reward": 750.0416259765625, "reward": 0.15341520309448242, "action": -0.23912197351455688}
{"mode": "train", "epochs": 3, "timestep": 5336, "ep_reward": 750.3440551757812, "reward": 0.30244600772857666, "action": -0.5424197912216187}
{"mode": "train", "epochs": 3, "timestep": 5337, "ep_reward": 750.7865600585938, "reward": 0.44252002239227295, "action": -0.9464871883392334}
{"mode": "train", "epochs": 3, "timestep": 5338, "ep_reward": 751.3509521484375, "reward": 0.5643725395202637, "action": -0.7682114839553833}
{"mode": "train", "epochs": 3, "timestep": 5339, "ep_reward": 752.019775390625, "reward": 0.6688183546066284, "action": -1.6615180969238281}
{"mode": "train", "epochs": 3, "timestep": 5340, "ep_reward": 752.7628173828125, "reward": 0.7430472373962402, "action": -1.3774322271347046}
{"mode": "train", "epochs": 3, "timestep": 5341, "ep_reward": 753.5630493164062, "reward": 0.8002319931983948, "action": -1.103679895401001}
{"mode": "train", "epochs": 3, "timestep": 5342, "ep_reward": 754.4041748046875, "reward": 0.8410953283309937, "action": -0.7222164869308472}
{"mode": "train", "epochs": 3, "timestep": 5343, "ep_reward": 755.272216796875, "reward": 0.8680198788642883, "action": -0.8633098602294922}
{"mode": "train", "epochs": 3, "timestep": 5344, "ep_reward": 756.150390625, "reward": 0.8781813979148865, "action": -1.2848472595214844}
{"mode": "train", "epochs": 3, "timestep": 5345, "ep_reward": 757.0201416015625, "reward": 0.8697406053543091, "action": -0.2314249873161316}
{"mode": "train", "epochs": 3, "timestep": 5346, "ep_reward": 757.8734130859375, "reward": 0.8532508611679077, "action": -1.9874804019927979}
{"mode": "train", "epochs": 3, "timestep": 5347, "ep_reward": 758.6738891601562, "reward": 0.8004981279373169, "action": -0.6583627462387085}
{"mode": "train", "epochs": 3, "timestep": 5348, "ep_reward": 759.4072875976562, "reward": 0.7334209680557251, "action": -1.4978541135787964}
{"mode": "train", "epochs": 3, "timestep": 5349, "ep_reward": 760.0303344726562, "reward": 0.6230239868164062, "action": -1.0968271493911743}
{"mode": "train", "epochs": 3, "timestep": 5350, "ep_reward": 760.5067138671875, "reward": 0.4763822555541992, "action": -1.1504005193710327}
{"mode": "train", "epochs": 3, "timestep": 5351, "ep_reward": 760.844970703125, "reward": 0.33823835849761963, "action": 0.359566330909729}
{"mode": "train", "epochs": 3, "timestep": 5352, "ep_reward": 761.0706176757812, "reward": 0.22567462921142578, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5353, "ep_reward": 761.1641845703125, "reward": 0.09354156255722046, "action": -0.9945570826530457}
{"mode": "train", "epochs": 3, "timestep": 5354, "ep_reward": 761.1876220703125, "reward": 0.023442864418029785, "action": -1.7851738929748535}
{"mode": "train", "epochs": 3, "timestep": 5355, "ep_reward": 761.35302734375, "reward": 0.16542762517929077, "action": -0.8848990201950073}
{"mode": "train", "epochs": 3, "timestep": 5356, "ep_reward": 761.6597290039062, "reward": 0.3067132830619812, "action": -0.8642391562461853}
{"mode": "train", "epochs": 3, "timestep": 5357, "ep_reward": 762.1038208007812, "reward": 0.4440615177154541, "action": -0.09743815660476685}
{"mode": "train", "epochs": 3, "timestep": 5358, "ep_reward": 762.6797485351562, "reward": 0.5759224891662598, "action": -0.6567695140838623}
{"mode": "train", "epochs": 3, "timestep": 5359, "ep_reward": 763.3590698242188, "reward": 0.6793322563171387, "action": -1.361196756362915}
{"mode": "train", "epochs": 3, "timestep": 5360, "ep_reward": 764.11279296875, "reward": 0.7537434101104736, "action": -1.1828290224075317}
{"mode": "train", "epochs": 3, "timestep": 5361, "ep_reward": 764.9225463867188, "reward": 0.8097511529922485, "action": -0.6031783223152161}
{"mode": "train", "epochs": 3, "timestep": 5362, "ep_reward": 765.7745361328125, "reward": 0.8520143628120422, "action": -0.977313756942749}
{"mode": "train", "epochs": 3, "timestep": 5363, "ep_reward": 766.6492309570312, "reward": 0.8746819496154785, "action": -1.0158528089523315}
{"mode": "train", "epochs": 3, "timestep": 5364, "ep_reward": 767.5316162109375, "reward": 0.8823936581611633, "action": -0.7796632051467896}
{"mode": "train", "epochs": 3, "timestep": 5365, "ep_reward": 768.408935546875, "reward": 0.8773006796836853, "action": -1.2865725755691528}
{"mode": "train", "epochs": 3, "timestep": 5366, "ep_reward": 769.2605590820312, "reward": 0.8516307473182678, "action": -1.1723504066467285}
{"mode": "train", "epochs": 3, "timestep": 5367, "ep_reward": 770.0668334960938, "reward": 0.8062958717346191, "action": -0.7867929339408875}
{"mode": "train", "epochs": 3, "timestep": 5368, "ep_reward": 770.8055419921875, "reward": 0.7386845350265503, "action": -1.351035714149475}
{"mode": "train", "epochs": 3, "timestep": 5369, "ep_reward": 771.4371337890625, "reward": 0.6316162943840027, "action": -0.876084566116333}
{"mode": "train", "epochs": 3, "timestep": 5370, "ep_reward": 771.9278564453125, "reward": 0.49073266983032227, "action": -0.9864580631256104}
{"mode": "train", "epochs": 3, "timestep": 5371, "ep_reward": 772.2689819335938, "reward": 0.3411073684692383, "action": -1.111288070678711}
{"mode": "train", "epochs": 3, "timestep": 5372, "ep_reward": 772.498291015625, "reward": 0.22929680347442627, "action": -1.5063867568969727}
{"mode": "train", "epochs": 3, "timestep": 5373, "ep_reward": 772.595947265625, "reward": 0.09763401746749878, "action": -0.9743390083312988}
{"mode": "train", "epochs": 3, "timestep": 5374, "ep_reward": 772.6151733398438, "reward": 0.01924043893814087, "action": -0.5830886363983154}
{"mode": "train", "epochs": 3, "timestep": 5375, "ep_reward": 772.7767333984375, "reward": 0.16156035661697388, "action": -1.336515188217163}
{"mode": "train", "epochs": 3, "timestep": 5376, "ep_reward": 773.0739135742188, "reward": 0.29719996452331543, "action": -0.7066554427146912}
{"mode": "train", "epochs": 3, "timestep": 5377, "ep_reward": 773.51171875, "reward": 0.43780237436294556, "action": -0.4405456781387329}
{"mode": "train", "epochs": 3, "timestep": 5378, "ep_reward": 774.0787353515625, "reward": 0.5670255422592163, "action": -0.23551446199417114}
{"mode": "train", "epochs": 3, "timestep": 5379, "ep_reward": 774.7551879882812, "reward": 0.6764490604400635, "action": -1.0312570333480835}
{"mode": "train", "epochs": 3, "timestep": 5380, "ep_reward": 775.5093994140625, "reward": 0.7542413473129272, "action": -1.6457834243774414}
{"mode": "train", "epochs": 3, "timestep": 5381, "ep_reward": 776.3154296875, "reward": 0.8060373663902283, "action": -1.1111098527908325}
{"mode": "train", "epochs": 3, "timestep": 5382, "ep_reward": 777.1597900390625, "reward": 0.8443547487258911, "action": -0.34519243240356445}
{"mode": "train", "epochs": 3, "timestep": 5383, "ep_reward": 778.0316772460938, "reward": 0.8718876838684082, "action": -1.3464224338531494}
{"mode": "train", "epochs": 3, "timestep": 5384, "ep_reward": 778.9075317382812, "reward": 0.8758776783943176, "action": -1.0254961252212524}
{"mode": "train", "epochs": 3, "timestep": 5385, "ep_reward": 779.7744140625, "reward": 0.8668853044509888, "action": -1.1360893249511719}
{"mode": "train", "epochs": 3, "timestep": 5386, "ep_reward": 780.613525390625, "reward": 0.8391215801239014, "action": -1.2382614612579346}
{"mode": "train", "epochs": 3, "timestep": 5387, "ep_reward": 781.401611328125, "reward": 0.788080632686615, "action": -0.9809598922729492}
{"mode": "train", "epochs": 3, "timestep": 5388, "ep_reward": 782.1128540039062, "reward": 0.7112265825271606, "action": -0.436833918094635}
{"mode": "train", "epochs": 3, "timestep": 5389, "ep_reward": 782.7196044921875, "reward": 0.6067208051681519, "action": -0.7520803213119507}
{"mode": "train", "epochs": 3, "timestep": 5390, "ep_reward": 783.17919921875, "reward": 0.45959562063217163, "action": -0.6232054233551025}
{"mode": "train", "epochs": 3, "timestep": 5391, "ep_reward": 783.499755859375, "reward": 0.32054293155670166, "action": -0.8409599661827087}
{"mode": "train", "epochs": 3, "timestep": 5392, "ep_reward": 783.70458984375, "reward": 0.20482653379440308, "action": -0.8343363404273987}
{"mode": "train", "epochs": 3, "timestep": 5393, "ep_reward": 783.773681640625, "reward": 0.06909269094467163, "action": -0.9868528842926025}
{"mode": "train", "epochs": 3, "timestep": 5394, "ep_reward": 783.82275390625, "reward": 0.0490681529045105, "action": -0.9992431402206421}
{"mode": "train", "epochs": 3, "timestep": 5395, "ep_reward": 784.0103149414062, "reward": 0.18754583597183228, "action": -0.6184322834014893}
{"mode": "train", "epochs": 3, "timestep": 5396, "ep_reward": 784.3427734375, "reward": 0.33243513107299805, "action": -1.003309726715088}
{"mode": "train", "epochs": 3, "timestep": 5397, "ep_reward": 784.8087768554688, "reward": 0.46601080894470215, "action": -1.0668659210205078}
{"mode": "train", "epochs": 3, "timestep": 5398, "ep_reward": 785.3928833007812, "reward": 0.5840829014778137, "action": -1.0138378143310547}
{"mode": "train", "epochs": 3, "timestep": 5399, "ep_reward": 786.0750122070312, "reward": 0.6821435689926147, "action": -1.0734200477600098}
{"mode": "train", "epochs": 3, "timestep": 5400, "ep_reward": 786.8321533203125, "reward": 0.7571694254875183, "action": -0.3589913249015808}
{"mode": "train", "epochs": 3, "timestep": 5401, "ep_reward": 787.6492309570312, "reward": 0.817086398601532, "action": -0.46752095222473145}
{"mode": "train", "epochs": 3, "timestep": 5402, "ep_reward": 788.5054321289062, "reward": 0.8561826944351196, "action": -0.7008432149887085}
{"mode": "train", "epochs": 3, "timestep": 5403, "ep_reward": 789.3822021484375, "reward": 0.8767397403717041, "action": -0.6584863662719727}
{"mode": "train", "epochs": 3, "timestep": 5404, "ep_reward": 790.264892578125, "reward": 0.8827182650566101, "action": -1.1757816076278687}
{"mode": "train", "epochs": 3, "timestep": 5405, "ep_reward": 791.1343994140625, "reward": 0.8695322275161743, "action": -0.8786221146583557}
{"mode": "train", "epochs": 3, "timestep": 5406, "ep_reward": 791.9757080078125, "reward": 0.8413273692131042, "action": -1.1814517974853516}
{"mode": "train", "epochs": 3, "timestep": 5407, "ep_reward": 792.7640991210938, "reward": 0.7883641123771667, "action": -1.5857696533203125}
{"mode": "train", "epochs": 3, "timestep": 5408, "ep_reward": 793.4659423828125, "reward": 0.7018313407897949, "action": -1.255434274673462}
{"mode": "train", "epochs": 3, "timestep": 5409, "ep_reward": 794.0476684570312, "reward": 0.5817264318466187, "action": -1.1017342805862427}
{"mode": "train", "epochs": 3, "timestep": 5410, "ep_reward": 794.46923828125, "reward": 0.42156755924224854, "action": -0.9499745965003967}
{"mode": "train", "epochs": 3, "timestep": 5411, "ep_reward": 794.773193359375, "reward": 0.30394619703292847, "action": -0.7064124941825867}
{"mode": "train", "epochs": 3, "timestep": 5412, "ep_reward": 794.9583129882812, "reward": 0.1851068139076233, "action": -0.9517663717269897}
{"mode": "train", "epochs": 3, "timestep": 5413, "ep_reward": 795.0044555664062, "reward": 0.046156466007232666, "action": -1.7601902484893799}
{"mode": "train", "epochs": 3, "timestep": 5414, "ep_reward": 795.0762329101562, "reward": 0.07175886631011963, "action": -1.3693625926971436}
{"mode": "train", "epochs": 3, "timestep": 5415, "ep_reward": 795.2832641601562, "reward": 0.20705711841583252, "action": -1.606577754020691}
{"mode": "train", "epochs": 3, "timestep": 5416, "ep_reward": 795.6231079101562, "reward": 0.33985161781311035, "action": -1.454887866973877}
{"mode": "train", "epochs": 3, "timestep": 5417, "ep_reward": 796.0921020507812, "reward": 0.4690084457397461, "action": -1.3629896640777588}
{"mode": "train", "epochs": 3, "timestep": 5418, "ep_reward": 796.676025390625, "reward": 0.5839245319366455, "action": -0.8646729588508606}
{"mode": "train", "epochs": 3, "timestep": 5419, "ep_reward": 797.3585205078125, "reward": 0.6824991703033447, "action": -0.4486149549484253}
{"mode": "train", "epochs": 3, "timestep": 5420, "ep_reward": 798.118896484375, "reward": 0.7603783011436462, "action": -1.4975658655166626}
{"mode": "train", "epochs": 3, "timestep": 5421, "ep_reward": 798.923828125, "reward": 0.8049497008323669, "action": -0.9928175210952759}
{"mode": "train", "epochs": 3, "timestep": 5422, "ep_reward": 799.7578735351562, "reward": 0.8340204954147339, "action": -0.4649399518966675}
{"mode": "train", "epochs": 3, "timestep": 5423, "ep_reward": 800.6063842773438, "reward": 0.8485056161880493, "action": -0.7680189609527588}
{"mode": "train", "epochs": 3, "timestep": 5424, "ep_reward": 801.4476318359375, "reward": 0.841234028339386, "action": -0.6771641969680786}
{"mode": "train", "epochs": 3, "timestep": 5425, "ep_reward": 802.2618408203125, "reward": 0.8141998052597046, "action": -0.5529159307479858}
{"mode": "train", "epochs": 3, "timestep": 5426, "ep_reward": 803.0259399414062, "reward": 0.7640954852104187, "action": -1.1789661645889282}
{"mode": "train", "epochs": 3, "timestep": 5427, "ep_reward": 803.7024536132812, "reward": 0.6765013337135315, "action": -0.9711586236953735}
{"mode": "train", "epochs": 3, "timestep": 5428, "ep_reward": 804.2555541992188, "reward": 0.5530766248703003, "action": -1.170933723449707}
{"mode": "train", "epochs": 3, "timestep": 5429, "ep_reward": 804.647705078125, "reward": 0.39213335514068604, "action": -1.3212368488311768}
{"mode": "train", "epochs": 3, "timestep": 5430, "ep_reward": 804.938720703125, "reward": 0.2910321354866028, "action": -0.9046075940132141}
{"mode": "train", "epochs": 3, "timestep": 5431, "ep_reward": 805.108642578125, "reward": 0.1698927879333496, "action": -0.7148834466934204}
{"mode": "train", "epochs": 3, "timestep": 5432, "ep_reward": 805.1373901367188, "reward": 0.02872568368911743, "action": -0.8106992244720459}
{"mode": "train", "epochs": 3, "timestep": 5433, "ep_reward": 805.22607421875, "reward": 0.08866697549819946, "action": -1.3300883769989014}
{"mode": "train", "epochs": 3, "timestep": 5434, "ep_reward": 805.4485473632812, "reward": 0.222478449344635, "action": -0.9563983678817749}
{"mode": "train", "epochs": 3, "timestep": 5435, "ep_reward": 805.8117065429688, "reward": 0.36316531896591187, "action": -1.7705247402191162}
{"mode": "train", "epochs": 3, "timestep": 5436, "ep_reward": 806.2975463867188, "reward": 0.4858649969100952, "action": -1.0641697645187378}
{"mode": "train", "epochs": 3, "timestep": 5437, "ep_reward": 806.89892578125, "reward": 0.601372241973877, "action": -1.0456316471099854}
{"mode": "train", "epochs": 3, "timestep": 5438, "ep_reward": 807.5935668945312, "reward": 0.6946132183074951, "action": -0.46121299266815186}
{"mode": "train", "epochs": 3, "timestep": 5439, "ep_reward": 808.36328125, "reward": 0.7697001695632935, "action": -1.259535789489746}
{"mode": "train", "epochs": 3, "timestep": 5440, "ep_reward": 809.1778564453125, "reward": 0.8145500421524048, "action": -1.302138090133667}
{"mode": "train", "epochs": 3, "timestep": 5441, "ep_reward": 810.017333984375, "reward": 0.8394759893417358, "action": -1.4482706785202026}
{"mode": "train", "epochs": 3, "timestep": 5442, "ep_reward": 810.8618774414062, "reward": 0.8445650935173035, "action": -0.6200177073478699}
{"mode": "train", "epochs": 3, "timestep": 5443, "ep_reward": 811.6998291015625, "reward": 0.8379386067390442, "action": -0.8309361934661865}
{"mode": "train", "epochs": 3, "timestep": 5444, "ep_reward": 812.5078735351562, "reward": 0.8080253005027771, "action": -1.6583311557769775}
{"mode": "train", "epochs": 3, "timestep": 5445, "ep_reward": 813.2510986328125, "reward": 0.7432135939598083, "action": -0.8126581311225891}
{"mode": "train", "epochs": 3, "timestep": 5446, "ep_reward": 813.9052124023438, "reward": 0.6541323065757751, "action": -1.4203824996948242}
{"mode": "train", "epochs": 3, "timestep": 5447, "ep_reward": 814.4220581054688, "reward": 0.5168466567993164, "action": -0.8965282440185547}
{"mode": "train", "epochs": 3, "timestep": 5448, "ep_reward": 814.8021850585938, "reward": 0.38013166189193726, "action": -1.0727609395980835}
{"mode": "train", "epochs": 3, "timestep": 5449, "ep_reward": 815.0785522460938, "reward": 0.276347815990448, "action": -1.2176284790039062}
{"mode": "train", "epochs": 3, "timestep": 5450, "ep_reward": 815.2310180664062, "reward": 0.15244776010513306, "action": -1.9188456535339355}
{"mode": "train", "epochs": 3, "timestep": 5451, "ep_reward": 815.2399291992188, "reward": 0.00889277458190918, "action": -0.6099549531936646}
{"mode": "train", "epochs": 3, "timestep": 5452, "ep_reward": 815.3471069335938, "reward": 0.10719943046569824, "action": -0.6626805067062378}
{"mode": "train", "epochs": 3, "timestep": 5453, "ep_reward": 815.5969848632812, "reward": 0.24989807605743408, "action": -0.5018144845962524}
{"mode": "train", "epochs": 3, "timestep": 5454, "ep_reward": 815.9908447265625, "reward": 0.3938335180282593, "action": -0.5643990635871887}
{"mode": "train", "epochs": 3, "timestep": 5455, "ep_reward": 816.5167846679688, "reward": 0.525929868221283, "action": -1.2151901721954346}
{"mode": "train", "epochs": 3, "timestep": 5456, "ep_reward": 817.1495361328125, "reward": 0.632753849029541, "action": -0.5605753660202026}
{"mode": "train", "epochs": 3, "timestep": 5457, "ep_reward": 817.8746948242188, "reward": 0.7251863479614258, "action": -1.4180752038955688}
{"mode": "train", "epochs": 3, "timestep": 5458, "ep_reward": 818.6622924804688, "reward": 0.7875933051109314, "action": -1.7606666088104248}
{"mode": "train", "epochs": 3, "timestep": 5459, "ep_reward": 819.4908447265625, "reward": 0.8285580277442932, "action": -0.5732159614562988}
{"mode": "train", "epochs": 3, "timestep": 5460, "ep_reward": 820.353271484375, "reward": 0.8624025583267212, "action": -0.4306222200393677}
{"mode": "train", "epochs": 3, "timestep": 5461, "ep_reward": 821.2345581054688, "reward": 0.8812829256057739, "action": -0.7603791952133179}
{"mode": "train", "epochs": 3, "timestep": 5462, "ep_reward": 822.1174926757812, "reward": 0.882949709892273, "action": -0.4609154462814331}
{"mode": "train", "epochs": 3, "timestep": 5463, "ep_reward": 822.9896850585938, "reward": 0.872184157371521, "action": 0.21923089027404785}
{"mode": "train", "epochs": 3, "timestep": 5464, "ep_reward": 823.840576171875, "reward": 0.8508720397949219, "action": -1.606459617614746}
{"mode": "train", "epochs": 3, "timestep": 5465, "ep_reward": 824.6334228515625, "reward": 0.7928199768066406, "action": -1.3921549320220947}
{"mode": "train", "epochs": 3, "timestep": 5466, "ep_reward": 825.3412475585938, "reward": 0.7078101634979248, "action": -0.08432209491729736}
{"mode": "train", "epochs": 3, "timestep": 5467, "ep_reward": 825.9454345703125, "reward": 0.6042172312736511, "action": -0.8879855871200562}
{"mode": "train", "epochs": 3, "timestep": 5468, "ep_reward": 826.3986206054688, "reward": 0.45318859815597534, "action": -0.5460041761398315}
{"mode": "train", "epochs": 3, "timestep": 5469, "ep_reward": 826.7034912109375, "reward": 0.30485260486602783, "action": -1.6596813201904297}
{"mode": "train", "epochs": 3, "timestep": 5470, "ep_reward": 826.889892578125, "reward": 0.18640100955963135, "action": -0.19559252262115479}
{"mode": "train", "epochs": 3, "timestep": 5471, "ep_reward": 826.9375, "reward": 0.04758584499359131, "action": -1.7750693559646606}
{"mode": "train", "epochs": 3, "timestep": 5472, "ep_reward": 827.0077514648438, "reward": 0.07022500038146973, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5473, "ep_reward": 827.2137451171875, "reward": 0.20597773790359497, "action": -0.7186139225959778}
{"mode": "train", "epochs": 3, "timestep": 5474, "ep_reward": 827.5635986328125, "reward": 0.34984755516052246, "action": -0.666519820690155}
{"mode": "train", "epochs": 3, "timestep": 5475, "ep_reward": 828.0498657226562, "reward": 0.48625868558883667, "action": -1.2653709650039673}
{"mode": "train", "epochs": 3, "timestep": 5476, "ep_reward": 828.64892578125, "reward": 0.5990802049636841, "action": -1.2723171710968018}
{"mode": "train", "epochs": 3, "timestep": 5477, "ep_reward": 829.34033203125, "reward": 0.6914292573928833, "action": -0.24880880117416382}
{"mode": "train", "epochs": 3, "timestep": 5478, "ep_reward": 830.111572265625, "reward": 0.7712240219116211, "action": -0.7600257992744446}
{"mode": "train", "epochs": 3, "timestep": 5479, "ep_reward": 830.9353637695312, "reward": 0.8238126039505005, "action": -1.3134053945541382}
{"mode": "train", "epochs": 3, "timestep": 5480, "ep_reward": 831.7886352539062, "reward": 0.8532583713531494, "action": -0.7854715585708618}
{"mode": "train", "epochs": 3, "timestep": 5481, "ep_reward": 832.6593017578125, "reward": 0.8706701993942261, "action": -1.2756547927856445}
{"mode": "train", "epochs": 3, "timestep": 5482, "ep_reward": 833.5275268554688, "reward": 0.8682118058204651, "action": -1.234773874282837}
{"mode": "train", "epochs": 3, "timestep": 5483, "ep_reward": 834.37646484375, "reward": 0.8489253520965576, "action": -1.023162841796875}
{"mode": "train", "epochs": 3, "timestep": 5484, "ep_reward": 835.1875610351562, "reward": 0.8110952377319336, "action": -0.08983844518661499}
{"mode": "train", "epochs": 3, "timestep": 5485, "ep_reward": 835.9457397460938, "reward": 0.7582002878189087, "action": -0.9149947166442871}
{"mode": "train", "epochs": 3, "timestep": 5486, "ep_reward": 836.6122436523438, "reward": 0.6664906740188599, "action": -0.8759016990661621}
{"mode": "train", "epochs": 3, "timestep": 5487, "ep_reward": 837.1500244140625, "reward": 0.5377517342567444, "action": -1.6460412740707397}
{"mode": "train", "epochs": 3, "timestep": 5488, "ep_reward": 837.5199584960938, "reward": 0.369920551776886, "action": -0.673264741897583}
{"mode": "train", "epochs": 3, "timestep": 5489, "ep_reward": 837.7838745117188, "reward": 0.26394063234329224, "action": -1.1499568223953247}
{"mode": "train", "epochs": 3, "timestep": 5490, "ep_reward": 837.9219360351562, "reward": 0.13808715343475342, "action": -0.4236573576927185}
{"mode": "train", "epochs": 3, "timestep": 5491, "ep_reward": 837.9140625, "reward": -0.007894158363342285, "action": -1.0447593927383423}
{"mode": "train", "epochs": 3, "timestep": 5492, "ep_reward": 838.0363159179688, "reward": 0.1222459077835083, "action": -0.8356795907020569}
{"mode": "train", "epochs": 3, "timestep": 5493, "ep_reward": 838.2992553710938, "reward": 0.2629687190055847, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5494, "ep_reward": 838.6879272460938, "reward": 0.3886467218399048, "action": -0.6046184301376343}
{"mode": "train", "epochs": 3, "timestep": 5495, "ep_reward": 839.2107543945312, "reward": 0.5228143930435181, "action": -1.1059496402740479}
{"mode": "train", "epochs": 3, "timestep": 5496, "ep_reward": 839.8421630859375, "reward": 0.6313939094543457, "action": -1.6099661588668823}
{"mode": "train", "epochs": 3, "timestep": 5497, "ep_reward": 840.5548095703125, "reward": 0.7126510739326477, "action": -0.7737751603126526}
{"mode": "train", "epochs": 3, "timestep": 5498, "ep_reward": 841.334716796875, "reward": 0.7798926830291748, "action": -1.029470682144165}
{"mode": "train", "epochs": 3, "timestep": 5499, "ep_reward": 842.1575317382812, "reward": 0.8228448033332825, "action": -1.540174126625061}
{"mode": "train", "epochs": 3, "timestep": 5500, "ep_reward": 842.9996337890625, "reward": 0.8421071767807007, "action": -0.575636625289917}
{"mode": "train", "epochs": 3, "timestep": 5501, "ep_reward": 843.8510131835938, "reward": 0.8513858914375305, "action": -1.957580327987671}
{"mode": "train", "epochs": 3, "timestep": 5502, "ep_reward": 844.6798706054688, "reward": 0.8288781642913818, "action": -1.4156591892242432}
{"mode": "train", "epochs": 3, "timestep": 5503, "ep_reward": 845.4676513671875, "reward": 0.7877755761146545, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5504, "ep_reward": 846.1778564453125, "reward": 0.7101790904998779, "action": -1.789095401763916}
{"mode": "train", "epochs": 3, "timestep": 5505, "ep_reward": 846.7733764648438, "reward": 0.5955405235290527, "action": -0.009972035884857178}
{"mode": "train", "epochs": 3, "timestep": 5506, "ep_reward": 847.2354736328125, "reward": 0.4620862603187561, "action": -1.4948620796203613}
{"mode": "train", "epochs": 3, "timestep": 5507, "ep_reward": 847.5870971679688, "reward": 0.3516024351119995, "action": -0.12817388772964478}
{"mode": "train", "epochs": 3, "timestep": 5508, "ep_reward": 847.828857421875, "reward": 0.24178344011306763, "action": -1.5129553079605103}
{"mode": "train", "epochs": 3, "timestep": 5509, "ep_reward": 847.9411010742188, "reward": 0.11223036050796509, "action": -0.5628383159637451}
{"mode": "train", "epochs": 3, "timestep": 5510, "ep_reward": 847.9444580078125, "reward": 0.003339529037475586, "action": -0.8754565119743347}
{"mode": "train", "epochs": 3, "timestep": 5511, "ep_reward": 848.0922241210938, "reward": 0.14778751134872437, "action": -1.1263964176177979}
{"mode": "train", "epochs": 3, "timestep": 5512, "ep_reward": 848.3779296875, "reward": 0.285716712474823, "action": -0.9640560746192932}
{"mode": "train", "epochs": 3, "timestep": 5513, "ep_reward": 848.80126953125, "reward": 0.42334020137786865, "action": -1.4553148746490479}
{"mode": "train", "epochs": 3, "timestep": 5514, "ep_reward": 849.34423828125, "reward": 0.5429390668869019, "action": -1.270743489265442}
{"mode": "train", "epochs": 3, "timestep": 5515, "ep_reward": 849.9904174804688, "reward": 0.6461592316627502, "action": -1.11003839969635}
{"mode": "train", "epochs": 3, "timestep": 5516, "ep_reward": 850.718994140625, "reward": 0.7285871505737305, "action": -1.1682578325271606}
{"mode": "train", "epochs": 3, "timestep": 5517, "ep_reward": 851.5068359375, "reward": 0.7878136038780212, "action": -0.47755706310272217}
{"mode": "train", "epochs": 3, "timestep": 5518, "ep_reward": 852.3390502929688, "reward": 0.8322408199310303, "action": -1.2703440189361572}
{"mode": "train", "epochs": 3, "timestep": 5519, "ep_reward": 853.1895751953125, "reward": 0.8505004048347473, "action": -1.4158451557159424}
{"mode": "train", "epochs": 3, "timestep": 5520, "ep_reward": 854.0392456054688, "reward": 0.8497003316879272, "action": -0.5570303201675415}
{"mode": "train", "epochs": 3, "timestep": 5521, "ep_reward": 854.8768920898438, "reward": 0.8376216888427734, "action": -1.1506953239440918}
{"mode": "train", "epochs": 3, "timestep": 5522, "ep_reward": 855.6752319335938, "reward": 0.7983134984970093, "action": -0.4770622253417969}
{"mode": "train", "epochs": 3, "timestep": 5523, "ep_reward": 856.4146118164062, "reward": 0.7394089698791504, "action": -1.0337836742401123}
{"mode": "train", "epochs": 3, "timestep": 5524, "ep_reward": 857.0560302734375, "reward": 0.6414390802383423, "action": -1.839418888092041}
{"mode": "train", "epochs": 3, "timestep": 5525, "ep_reward": 857.5471801757812, "reward": 0.49116331338882446, "action": -1.1441949605941772}
{"mode": "train", "epochs": 3, "timestep": 5526, "ep_reward": 857.9073486328125, "reward": 0.3601701259613037, "action": -1.0415171384811401}
{"mode": "train", "epochs": 3, "timestep": 5527, "ep_reward": 858.1596069335938, "reward": 0.2522647976875305, "action": -0.8386123180389404}
{"mode": "train", "epochs": 3, "timestep": 5528, "ep_reward": 858.2838745117188, "reward": 0.12427830696105957, "action": -1.2762389183044434}
{"mode": "train", "epochs": 3, "timestep": 5529, "ep_reward": 858.273681640625, "reward": -0.010196208953857422, "action": -0.3431782126426697}
{"mode": "train", "epochs": 3, "timestep": 5530, "ep_reward": 858.40966796875, "reward": 0.13599038124084473, "action": -0.8746304512023926}
{"mode": "train", "epochs": 3, "timestep": 5531, "ep_reward": 858.6864624023438, "reward": 0.276790976524353, "action": -0.7307472825050354}
{"mode": "train", "epochs": 3, "timestep": 5532, "ep_reward": 859.1036987304688, "reward": 0.4172312617301941, "action": -0.9175490140914917}
{"mode": "train", "epochs": 3, "timestep": 5533, "ep_reward": 859.6468505859375, "reward": 0.5431514978408813, "action": -1.5860018730163574}
{"mode": "train", "epochs": 3, "timestep": 5534, "ep_reward": 860.2899169921875, "reward": 0.6430515050888062, "action": -1.7807364463806152}
{"mode": "train", "epochs": 3, "timestep": 5535, "ep_reward": 861.010498046875, "reward": 0.7205673456192017, "action": -0.23992687463760376}
{"mode": "train", "epochs": 3, "timestep": 5536, "ep_reward": 861.8018188476562, "reward": 0.7913162708282471, "action": -0.4691193699836731}
{"mode": "train", "epochs": 3, "timestep": 5537, "ep_reward": 862.6396484375, "reward": 0.8378135561943054, "action": -1.8964521884918213}
{"mode": "train", "epochs": 3, "timestep": 5538, "ep_reward": 863.493896484375, "reward": 0.854237973690033, "action": -0.9686301946640015}
{"mode": "train", "epochs": 3, "timestep": 5539, "ep_reward": 864.3557739257812, "reward": 0.861905038356781, "action": -0.4029275178909302}
{"mode": "train", "epochs": 3, "timestep": 5540, "ep_reward": 865.2130737304688, "reward": 0.8573259115219116, "action": -0.4378553628921509}
{"mode": "train", "epochs": 3, "timestep": 5541, "ep_reward": 866.047119140625, "reward": 0.834069013595581, "action": -0.6608631610870361}
{"mode": "train", "epochs": 3, "timestep": 5542, "ep_reward": 866.8339233398438, "reward": 0.7868189811706543, "action": -1.4725583791732788}
{"mode": "train", "epochs": 3, "timestep": 5543, "ep_reward": 867.536376953125, "reward": 0.702457845211029, "action": -0.8695189952850342}
{"mode": "train", "epochs": 3, "timestep": 5544, "ep_reward": 868.1249389648438, "reward": 0.5885337591171265, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5545, "ep_reward": 868.541015625, "reward": 0.41610217094421387, "action": -0.3916320204734802}
{"mode": "train", "epochs": 3, "timestep": 5546, "ep_reward": 868.8488159179688, "reward": 0.30779391527175903, "action": -0.8709935545921326}
{"mode": "train", "epochs": 3, "timestep": 5547, "ep_reward": 869.0385131835938, "reward": 0.1896795630455017, "action": -0.9826300740242004}
{"mode": "train", "epochs": 3, "timestep": 5548, "ep_reward": 869.090087890625, "reward": 0.051595866680145264, "action": -0.8314543962478638}
{"mode": "train", "epochs": 3, "timestep": 5549, "ep_reward": 869.15673828125, "reward": 0.06667149066925049, "action": -0.47283458709716797}
{"mode": "train", "epochs": 3, "timestep": 5550, "ep_reward": 869.3672485351562, "reward": 0.21052658557891846, "action": -0.31172728538513184}
{"mode": "train", "epochs": 3, "timestep": 5551, "ep_reward": 869.724853515625, "reward": 0.3576294183731079, "action": -0.8457059860229492}
{"mode": "train", "epochs": 3, "timestep": 5552, "ep_reward": 870.2146606445312, "reward": 0.48981237411499023, "action": -0.0036197304725646973}
{"mode": "train", "epochs": 3, "timestep": 5553, "ep_reward": 870.82958984375, "reward": 0.614936351776123, "action": -1.4563814401626587}
{"mode": "train", "epochs": 3, "timestep": 5554, "ep_reward": 871.53271484375, "reward": 0.7031230330467224, "action": -0.5913866758346558}
{"mode": "train", "epochs": 3, "timestep": 5555, "ep_reward": 872.3115844726562, "reward": 0.7788935899734497, "action": -1.6747138500213623}
{"mode": "train", "epochs": 3, "timestep": 5556, "ep_reward": 873.1370239257812, "reward": 0.8254659175872803, "action": -1.5881597995758057}
{"mode": "train", "epochs": 3, "timestep": 5557, "ep_reward": 873.9935913085938, "reward": 0.8565380573272705, "action": -0.3811219334602356}
{"mode": "train", "epochs": 3, "timestep": 5558, "ep_reward": 874.8753662109375, "reward": 0.8817974925041199, "action": -1.24434232711792}
{"mode": "train", "epochs": 3, "timestep": 5559, "ep_reward": 875.761474609375, "reward": 0.8860946893692017, "action": -1.0159062147140503}
{"mode": "train", "epochs": 3, "timestep": 5560, "ep_reward": 876.639404296875, "reward": 0.8779087066650391, "action": -0.6095882654190063}
{"mode": "train", "epochs": 3, "timestep": 5561, "ep_reward": 877.4964599609375, "reward": 0.857058584690094, "action": -0.9258680939674377}
{"mode": "train", "epochs": 3, "timestep": 5562, "ep_reward": 878.3106079101562, "reward": 0.8141495585441589, "action": -0.6556845903396606}
{"mode": "train", "epochs": 3, "timestep": 5563, "ep_reward": 879.0598754882812, "reward": 0.7492662668228149, "action": -0.5183314681053162}
{"mode": "train", "epochs": 3, "timestep": 5564, "ep_reward": 879.7155151367188, "reward": 0.6556488275527954, "action": -0.9368292689323425}
{"mode": "train", "epochs": 3, "timestep": 5565, "ep_reward": 880.2360229492188, "reward": 0.52051842212677, "action": -0.18681347370147705}
{"mode": "train", "epochs": 3, "timestep": 5566, "ep_reward": 880.5940551757812, "reward": 0.35803067684173584, "action": -1.5091593265533447}
{"mode": "train", "epochs": 3, "timestep": 5567, "ep_reward": 880.8329467773438, "reward": 0.23891884088516235, "action": -1.4315327405929565}
{"mode": "train", "epochs": 3, "timestep": 5568, "ep_reward": 880.9417724609375, "reward": 0.10879755020141602, "action": -1.219065546989441}
{"mode": "train", "epochs": 3, "timestep": 5569, "ep_reward": 880.9488525390625, "reward": 0.007085442543029785, "action": -0.30220282077789307}
{"mode": "train", "epochs": 3, "timestep": 5570, "ep_reward": 881.099853515625, "reward": 0.15098392963409424, "action": -1.6948435306549072}
{"mode": "train", "epochs": 3, "timestep": 5571, "ep_reward": 881.3817749023438, "reward": 0.2819265127182007, "action": -0.6496598124504089}
{"mode": "train", "epochs": 3, "timestep": 5572, "ep_reward": 881.806396484375, "reward": 0.424641489982605, "action": -1.3338534832000732}
{"mode": "train", "epochs": 3, "timestep": 5573, "ep_reward": 882.3521118164062, "reward": 0.5457434058189392, "action": -0.47136253118515015}
{"mode": "train", "epochs": 3, "timestep": 5574, "ep_reward": 883.0089111328125, "reward": 0.6568074226379395, "action": -1.4488638639450073}
{"mode": "train", "epochs": 3, "timestep": 5575, "ep_reward": 883.742919921875, "reward": 0.7340391278266907, "action": -0.562355637550354}
{"mode": "train", "epochs": 3, "timestep": 5576, "ep_reward": 884.5407104492188, "reward": 0.797786295413971, "action": -0.8843700289726257}
{"mode": "train", "epochs": 3, "timestep": 5577, "ep_reward": 885.37841796875, "reward": 0.8377206325531006, "action": -0.2678419351577759}
{"mode": "train", "epochs": 3, "timestep": 5578, "ep_reward": 886.2431030273438, "reward": 0.8647076487541199, "action": -0.9076254963874817}
{"mode": "train", "epochs": 3, "timestep": 5579, "ep_reward": 887.1128540039062, "reward": 0.8697688579559326, "action": -1.0415998697280884}
{"mode": "train", "epochs": 3, "timestep": 5580, "ep_reward": 887.969970703125, "reward": 0.8570898175239563, "action": -1.2615305185317993}
{"mode": "train", "epochs": 3, "timestep": 5581, "ep_reward": 888.7931518554688, "reward": 0.8231633901596069, "action": -0.6341273188591003}
{"mode": "train", "epochs": 3, "timestep": 5582, "ep_reward": 889.5645141601562, "reward": 0.7713769674301147, "action": -1.7216150760650635}
{"mode": "train", "epochs": 3, "timestep": 5583, "ep_reward": 890.2417602539062, "reward": 0.677253246307373, "action": -0.21329587697982788}
{"mode": "train", "epochs": 3, "timestep": 5584, "ep_reward": 890.805908203125, "reward": 0.56415855884552, "action": -0.6804007291793823}
{"mode": "train", "epochs": 3, "timestep": 5585, "ep_reward": 891.2114868164062, "reward": 0.40556997060775757, "action": -0.44557738304138184}
{"mode": "train", "epochs": 3, "timestep": 5586, "ep_reward": 891.5013427734375, "reward": 0.289861798286438, "action": -0.4146178364753723}
{"mode": "train", "epochs": 3, "timestep": 5587, "ep_reward": 891.669677734375, "reward": 0.16835415363311768, "action": -1.5084738731384277}
{"mode": "train", "epochs": 3, "timestep": 5588, "ep_reward": 891.69677734375, "reward": 0.027072906494140625, "action": -0.875858724117279}
{"mode": "train", "epochs": 3, "timestep": 5589, "ep_reward": 891.7870483398438, "reward": 0.09028416872024536, "action": -0.878507137298584}
{"mode": "train", "epochs": 3, "timestep": 5590, "ep_reward": 892.0167846679688, "reward": 0.22975176572799683, "action": -1.0753577947616577}
{"mode": "train", "epochs": 3, "timestep": 5591, "ep_reward": 892.384765625, "reward": 0.36796820163726807, "action": -0.2308381199836731}
{"mode": "train", "epochs": 3, "timestep": 5592, "ep_reward": 892.8924560546875, "reward": 0.5076987147331238, "action": -1.0503795146942139}
{"mode": "train", "epochs": 3, "timestep": 5593, "ep_reward": 893.5117797851562, "reward": 0.619335949420929, "action": -1.0500073432922363}
{"mode": "train", "epochs": 3, "timestep": 5594, "ep_reward": 894.2216796875, "reward": 0.7099141478538513, "action": -0.6467575430870056}
{"mode": "train", "epochs": 3, "timestep": 5595, "ep_reward": 895.0038452148438, "reward": 0.7821623086929321, "action": -1.195229411125183}
{"mode": "train", "epochs": 3, "timestep": 5596, "ep_reward": 895.8328247070312, "reward": 0.8289813995361328, "action": -0.6415205001831055}
{"mode": "train", "epochs": 3, "timestep": 5597, "ep_reward": 896.6956176757812, "reward": 0.8627690076828003, "action": -0.7979599237442017}
{"mode": "train", "epochs": 3, "timestep": 5598, "ep_reward": 897.5750122070312, "reward": 0.8794153332710266, "action": -0.8587167263031006}
{"mode": "train", "epochs": 3, "timestep": 5599, "ep_reward": 898.4557495117188, "reward": 0.8807601928710938, "action": -1.8061273097991943}
{"mode": "train", "epochs": 3, "timestep": 5600, "ep_reward": 899.3145141601562, "reward": 0.8587689399719238, "action": -0.22298651933670044}
{"mode": "train", "epochs": 3, "timestep": 5601, "ep_reward": 900.1463012695312, "reward": 0.8317717909812927, "action": -0.8906808495521545}
{"mode": "train", "epochs": 3, "timestep": 5602, "ep_reward": 900.9225463867188, "reward": 0.7762455344200134, "action": -0.953484058380127}
{"mode": "train", "epochs": 3, "timestep": 5603, "ep_reward": 901.6134033203125, "reward": 0.6908861398696899, "action": -1.1845372915267944}
{"mode": "train", "epochs": 3, "timestep": 5604, "ep_reward": 902.1796264648438, "reward": 0.5662314891815186, "action": -1.0962668657302856}
{"mode": "train", "epochs": 3, "timestep": 5605, "ep_reward": 902.5806884765625, "reward": 0.4010809063911438, "action": -1.2428158521652222}
{"mode": "train", "epochs": 3, "timestep": 5606, "ep_reward": 902.8656005859375, "reward": 0.2849233150482178, "action": -1.505884051322937}
{"mode": "train", "epochs": 3, "timestep": 5607, "ep_reward": 903.0283203125, "reward": 0.1627131700515747, "action": -1.3607794046401978}
{"mode": "train", "epochs": 3, "timestep": 5608, "ep_reward": 903.048828125, "reward": 0.020538270473480225, "action": -0.9391765594482422}
{"mode": "train", "epochs": 3, "timestep": 5609, "ep_reward": 903.1452026367188, "reward": 0.0963851809501648, "action": -1.0433169603347778}
{"mode": "train", "epochs": 3, "timestep": 5610, "ep_reward": 903.3792724609375, "reward": 0.23403984308242798, "action": -0.6042158603668213}
{"mode": "train", "epochs": 3, "timestep": 5611, "ep_reward": 903.7574462890625, "reward": 0.378190279006958, "action": -0.4407537579536438}
{"mode": "train", "epochs": 3, "timestep": 5612, "ep_reward": 904.271484375, "reward": 0.5140402913093567, "action": -0.9755297303199768}
{"mode": "train", "epochs": 3, "timestep": 5613, "ep_reward": 904.8969116210938, "reward": 0.625411868095398, "action": -0.8795980215072632}
{"mode": "train", "epochs": 3, "timestep": 5614, "ep_reward": 905.6133422851562, "reward": 0.7164402008056641, "action": -0.4205474257469177}
{"mode": "train", "epochs": 3, "timestep": 5615, "ep_reward": 906.4027709960938, "reward": 0.7894291877746582, "action": -0.9077466130256653}
{"mode": "train", "epochs": 3, "timestep": 5616, "ep_reward": 907.2402954101562, "reward": 0.8375107645988464, "action": -1.4772223234176636}
{"mode": "train", "epochs": 3, "timestep": 5617, "ep_reward": 908.1044921875, "reward": 0.8642014265060425, "action": -0.9495130777359009}
{"mode": "train", "epochs": 3, "timestep": 5618, "ep_reward": 908.9846801757812, "reward": 0.8801935911178589, "action": -0.26124078035354614}
{"mode": "train", "epochs": 3, "timestep": 5619, "ep_reward": 909.871826171875, "reward": 0.8871639966964722, "action": -0.9910870790481567}
{"mode": "train", "epochs": 3, "timestep": 5620, "ep_reward": 910.7455444335938, "reward": 0.8737316727638245, "action": -1.5220649242401123}
{"mode": "train", "epochs": 3, "timestep": 5621, "ep_reward": 911.583984375, "reward": 0.8384320139884949, "action": -0.37415701150894165}
{"mode": "train", "epochs": 3, "timestep": 5622, "ep_reward": 912.375732421875, "reward": 0.79176926612854, "action": -1.0969219207763672}
{"mode": "train", "epochs": 3, "timestep": 5623, "ep_reward": 913.086181640625, "reward": 0.7104741334915161, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5624, "ep_reward": 913.6677856445312, "reward": 0.5815945267677307, "action": -1.3531808853149414}
{"mode": "train", "epochs": 3, "timestep": 5625, "ep_reward": 914.0847778320312, "reward": 0.4170169234275818, "action": -1.5767064094543457}
{"mode": "train", "epochs": 3, "timestep": 5626, "ep_reward": 914.385009765625, "reward": 0.3002058267593384, "action": -0.9316051006317139}
{"mode": "train", "epochs": 3, "timestep": 5627, "ep_reward": 914.5657348632812, "reward": 0.18075042963027954, "action": -0.4831809401512146}
{"mode": "train", "epochs": 3, "timestep": 5628, "ep_reward": 914.6069946289062, "reward": 0.04123485088348389, "action": -0.7563052177429199}
{"mode": "train", "epochs": 3, "timestep": 5629, "ep_reward": 914.6837158203125, "reward": 0.07673019170761108, "action": -1.1582564115524292}
{"mode": "train", "epochs": 3, "timestep": 5630, "ep_reward": 914.8960571289062, "reward": 0.21235018968582153, "action": -0.6259731650352478}
{"mode": "train", "epochs": 3, "timestep": 5631, "ep_reward": 915.2532348632812, "reward": 0.3571956157684326, "action": -0.7058382034301758}
{"mode": "train", "epochs": 3, "timestep": 5632, "ep_reward": 915.74560546875, "reward": 0.4923937916755676, "action": -0.6768384575843811}
{"mode": "train", "epochs": 3, "timestep": 5633, "ep_reward": 916.356201171875, "reward": 0.610594630241394, "action": -1.088188648223877}
{"mode": "train", "epochs": 3, "timestep": 5634, "ep_reward": 917.0587158203125, "reward": 0.7025073766708374, "action": -1.6893398761749268}
{"mode": "train", "epochs": 3, "timestep": 5635, "ep_reward": 917.825927734375, "reward": 0.7672260999679565, "action": 0.20963048934936523}
{"mode": "train", "epochs": 3, "timestep": 5636, "ep_reward": 918.654541015625, "reward": 0.828614354133606, "action": -1.2646598815917969}
{"mode": "train", "epochs": 3, "timestep": 5637, "ep_reward": 919.5126342773438, "reward": 0.8580652475357056, "action": -1.0100433826446533}
{"mode": "train", "epochs": 3, "timestep": 5638, "ep_reward": 920.386474609375, "reward": 0.8738222718238831, "action": -0.7901360988616943}
{"mode": "train", "epochs": 3, "timestep": 5639, "ep_reward": 921.2623901367188, "reward": 0.8759294748306274, "action": -1.9823393821716309}
{"mode": "train", "epochs": 3, "timestep": 5640, "ep_reward": 922.114013671875, "reward": 0.8516323566436768, "action": -1.8158245086669922}
{"mode": "train", "epochs": 3, "timestep": 5641, "ep_reward": 922.9214477539062, "reward": 0.8074386119842529, "action": -0.908602237701416}
{"mode": "train", "epochs": 3, "timestep": 5642, "ep_reward": 923.6669921875, "reward": 0.7455686330795288, "action": -0.8830420970916748}
{"mode": "train", "epochs": 3, "timestep": 5643, "ep_reward": 924.3186645507812, "reward": 0.6516439914703369, "action": -1.3785521984100342}
{"mode": "train", "epochs": 3, "timestep": 5644, "ep_reward": 924.830322265625, "reward": 0.5116314888000488, "action": -0.8596776723861694}
{"mode": "train", "epochs": 3, "timestep": 5645, "ep_reward": 925.1961669921875, "reward": 0.3658565878868103, "action": -0.08411085605621338}
{"mode": "train", "epochs": 3, "timestep": 5646, "ep_reward": 925.4551391601562, "reward": 0.258952796459198, "action": -1.4387943744659424}
{"mode": "train", "epochs": 3, "timestep": 5647, "ep_reward": 925.58740234375, "reward": 0.13228517770767212, "action": -0.6032367944717407}
{"mode": "train", "epochs": 3, "timestep": 5648, "ep_reward": 925.5726928710938, "reward": -0.014709711074829102, "action": -1.9759905338287354}
{"mode": "train", "epochs": 3, "timestep": 5649, "ep_reward": 925.7008056640625, "reward": 0.12813621759414673, "action": -0.5082733631134033}
{"mode": "train", "epochs": 3, "timestep": 5650, "ep_reward": 925.9740600585938, "reward": 0.27326810359954834, "action": -0.7526434659957886}
{"mode": "train", "epochs": 3, "timestep": 5651, "ep_reward": 926.386962890625, "reward": 0.4129144549369812, "action": 0.1850264072418213}
{"mode": "train", "epochs": 3, "timestep": 5652, "ep_reward": 926.9381103515625, "reward": 0.5511224269866943, "action": -1.7496521472930908}
{"mode": "train", "epochs": 3, "timestep": 5653, "ep_reward": 927.5862426757812, "reward": 0.6481183767318726, "action": -0.9310098886489868}
{"mode": "train", "epochs": 3, "timestep": 5654, "ep_reward": 928.3199462890625, "reward": 0.7337306141853333, "action": -1.1922587156295776}
{"mode": "train", "epochs": 3, "timestep": 5655, "ep_reward": 929.1157836914062, "reward": 0.7958085536956787, "action": -0.28052204847335815}
{"mode": "train", "epochs": 3, "timestep": 5656, "ep_reward": 929.962158203125, "reward": 0.8463709950447083, "action": -0.8322411179542542}
{"mode": "train", "epochs": 3, "timestep": 5657, "ep_reward": 930.8374633789062, "reward": 0.875307559967041, "action": -0.14137685298919678}
{"mode": "train", "epochs": 3, "timestep": 5658, "ep_reward": 931.732421875, "reward": 0.8949654698371887, "action": -1.407925009727478}
{"mode": "train", "epochs": 3, "timestep": 5659, "ep_reward": 932.62451171875, "reward": 0.8920762538909912, "action": -1.0618271827697754}
{"mode": "train", "epochs": 3, "timestep": 5660, "ep_reward": 933.5023803710938, "reward": 0.8778709769248962, "action": -0.3552616238594055}
{"mode": "train", "epochs": 3, "timestep": 5661, "ep_reward": 934.3556518554688, "reward": 0.8532634377479553, "action": -1.4443806409835815}
{"mode": "train", "epochs": 3, "timestep": 5662, "ep_reward": 935.1544189453125, "reward": 0.7987736463546753, "action": 0.13542485237121582}
{"mode": "train", "epochs": 3, "timestep": 5663, "ep_reward": 935.8884887695312, "reward": 0.7340982556343079, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5664, "ep_reward": 936.5013427734375, "reward": 0.6128320693969727, "action": -1.7326018810272217}
{"mode": "train", "epochs": 3, "timestep": 5665, "ep_reward": 936.952880859375, "reward": 0.45152366161346436, "action": -1.1772898435592651}
{"mode": "train", "epochs": 3, "timestep": 5666, "ep_reward": 937.2670288085938, "reward": 0.3141329884529114, "action": -0.7695685625076294}
{"mode": "train", "epochs": 3, "timestep": 5667, "ep_reward": 937.4641723632812, "reward": 0.19716566801071167, "action": -1.0611730813980103}
{"mode": "train", "epochs": 3, "timestep": 5668, "ep_reward": 937.5244140625, "reward": 0.060253798961639404, "action": -0.8574992418289185}
{"mode": "train", "epochs": 3, "timestep": 5669, "ep_reward": 937.5824584960938, "reward": 0.058032214641571045, "action": -0.9370424151420593}
{"mode": "train", "epochs": 3, "timestep": 5670, "ep_reward": 937.7781982421875, "reward": 0.19576191902160645, "action": -1.070684790611267}
{"mode": "train", "epochs": 3, "timestep": 5671, "ep_reward": 938.1132202148438, "reward": 0.3350212574005127, "action": -1.310065746307373}
{"mode": "train", "epochs": 3, "timestep": 5672, "ep_reward": 938.5786743164062, "reward": 0.4654560089111328, "action": -1.0856785774230957}
{"mode": "train", "epochs": 3, "timestep": 5673, "ep_reward": 939.1624145507812, "reward": 0.5837409496307373, "action": -1.2986644506454468}
{"mode": "train", "epochs": 3, "timestep": 5674, "ep_reward": 939.8408813476562, "reward": 0.6784486174583435, "action": -1.63006591796875}
{"mode": "train", "epochs": 3, "timestep": 5675, "ep_reward": 940.588134765625, "reward": 0.7472794055938721, "action": -1.3710262775421143}
{"mode": "train", "epochs": 3, "timestep": 5676, "ep_reward": 941.385009765625, "reward": 0.7968904972076416, "action": -1.3850066661834717}
{"mode": "train", "epochs": 3, "timestep": 5677, "ep_reward": 942.2106323242188, "reward": 0.8256015181541443, "action": -1.567828893661499}
{"mode": "train", "epochs": 3, "timestep": 5678, "ep_reward": 943.04345703125, "reward": 0.8328521251678467, "action": -0.5075312256813049}
{"mode": "train", "epochs": 3, "timestep": 5679, "ep_reward": 943.873046875, "reward": 0.8296109437942505, "action": -0.9191617369651794}
{"mode": "train", "epochs": 3, "timestep": 5680, "ep_reward": 944.6732788085938, "reward": 0.8002263307571411, "action": -0.14907753467559814}
{"mode": "train", "epochs": 3, "timestep": 5681, "ep_reward": 945.4264526367188, "reward": 0.7531610727310181, "action": -0.8841775059700012}
{"mode": "train", "epochs": 3, "timestep": 5682, "ep_reward": 946.0933227539062, "reward": 0.666845977306366, "action": -1.2884345054626465}
{"mode": "train", "epochs": 3, "timestep": 5683, "ep_reward": 946.6292724609375, "reward": 0.5359375476837158, "action": -1.6640305519104004}
{"mode": "train", "epochs": 3, "timestep": 5684, "ep_reward": 947.0177612304688, "reward": 0.38848018646240234, "action": -1.3404113054275513}
{"mode": "train", "epochs": 3, "timestep": 5685, "ep_reward": 947.30419921875, "reward": 0.2864340543746948, "action": -1.7590529918670654}
{"mode": "train", "epochs": 3, "timestep": 5686, "ep_reward": 947.4686279296875, "reward": 0.16445112228393555, "action": -1.8282668590545654}
{"mode": "train", "epochs": 3, "timestep": 5687, "ep_reward": 947.4913330078125, "reward": 0.022682905197143555, "action": -0.3406949043273926}
{"mode": "train", "epochs": 3, "timestep": 5688, "ep_reward": 947.5858154296875, "reward": 0.0945056676864624, "action": -0.04410046339035034}
{"mode": "train", "epochs": 3, "timestep": 5689, "ep_reward": 947.8302612304688, "reward": 0.2444685697555542, "action": -0.6100723147392273}
{"mode": "train", "epochs": 3, "timestep": 5690, "ep_reward": 948.2161865234375, "reward": 0.385952889919281, "action": -0.3586606979370117}
{"mode": "train", "epochs": 3, "timestep": 5691, "ep_reward": 948.7366333007812, "reward": 0.5204267501831055, "action": -1.551662802696228}
{"mode": "train", "epochs": 3, "timestep": 5692, "ep_reward": 949.3609619140625, "reward": 0.6243473291397095, "action": -1.372300624847412}
{"mode": "train", "epochs": 3, "timestep": 5693, "ep_reward": 950.0720825195312, "reward": 0.7111294269561768, "action": -0.960591733455658}
{"mode": "train", "epochs": 3, "timestep": 5694, "ep_reward": 950.85302734375, "reward": 0.7809720039367676, "action": -1.4182908535003662}
{"mode": "train", "epochs": 3, "timestep": 5695, "ep_reward": 951.68017578125, "reward": 0.8271180987358093, "action": -0.7914673686027527}
{"mode": "train", "epochs": 3, "timestep": 5696, "ep_reward": 952.5411376953125, "reward": 0.8609731197357178, "action": -1.9831124544143677}
{"mode": "train", "epochs": 3, "timestep": 5697, "ep_reward": 953.410888671875, "reward": 0.8697519302368164, "action": -0.45007073879241943}
{"mode": "train", "epochs": 3, "timestep": 5698, "ep_reward": 954.2865600585938, "reward": 0.8756887912750244, "action": -0.8950134515762329}
{"mode": "train", "epochs": 3, "timestep": 5699, "ep_reward": 955.1485595703125, "reward": 0.8620138764381409, "action": -0.7799245715141296}
{"mode": "train", "epochs": 3, "timestep": 5700, "ep_reward": 955.9794311523438, "reward": 0.8308483958244324, "action": -1.6949071884155273}
{"mode": "train", "epochs": 3, "timestep": 5701, "ep_reward": 956.7467041015625, "reward": 0.7672818303108215, "action": -0.30741482973098755}
{"mode": "train", "epochs": 3, "timestep": 5702, "ep_reward": 957.4348754882812, "reward": 0.688166618347168, "action": -1.918517827987671}
{"mode": "train", "epochs": 3, "timestep": 5703, "ep_reward": 957.9872436523438, "reward": 0.5523898601531982, "action": -1.2932244539260864}
{"mode": "train", "epochs": 3, "timestep": 5704, "ep_reward": 958.3717651367188, "reward": 0.38454216718673706, "action": -1.2589373588562012}
{"mode": "train", "epochs": 3, "timestep": 5705, "ep_reward": 958.653564453125, "reward": 0.2817801833152771, "action": -0.8057693839073181}
{"mode": "train", "epochs": 3, "timestep": 5706, "ep_reward": 958.8125, "reward": 0.1589532494544983, "action": -0.8459163904190063}
{"mode": "train", "epochs": 3, "timestep": 5707, "ep_reward": 958.8285522460938, "reward": 0.016082406044006348, "action": -1.2017755508422852}
{"mode": "train", "epochs": 3, "timestep": 5708, "ep_reward": 958.9290771484375, "reward": 0.10053747892379761, "action": -0.7104673385620117}
{"mode": "train", "epochs": 3, "timestep": 5709, "ep_reward": 959.1715087890625, "reward": 0.2424384355545044, "action": -0.7536541223526001}
{"mode": "train", "epochs": 3, "timestep": 5710, "ep_reward": 959.55517578125, "reward": 0.38364750146865845, "action": -1.2897140979766846}
{"mode": "train", "epochs": 3, "timestep": 5711, "ep_reward": 960.0641479492188, "reward": 0.5089847445487976, "action": -1.1694862842559814}
{"mode": "train", "epochs": 3, "timestep": 5712, "ep_reward": 960.6834716796875, "reward": 0.6193170547485352, "action": -0.6899218559265137}
{"mode": "train", "epochs": 3, "timestep": 5713, "ep_reward": 961.3963623046875, "reward": 0.712883710861206, "action": -1.855276107788086}
{"mode": "train", "epochs": 3, "timestep": 5714, "ep_reward": 962.1692504882812, "reward": 0.772873044013977, "action": -0.6989835500717163}
{"mode": "train", "epochs": 3, "timestep": 5715, "ep_reward": 962.9927368164062, "reward": 0.8234661221504211, "action": -1.1906267404556274}
{"mode": "train", "epochs": 3, "timestep": 5716, "ep_reward": 963.8433837890625, "reward": 0.8506746888160706, "action": -1.452807068824768}
{"mode": "train", "epochs": 3, "timestep": 5717, "ep_reward": 964.7020263671875, "reward": 0.8586238026618958, "action": -0.8895832300186157}
{"mode": "train", "epochs": 3, "timestep": 5718, "ep_reward": 965.55615234375, "reward": 0.85410475730896, "action": -0.6508049964904785}
{"mode": "train", "epochs": 3, "timestep": 5719, "ep_reward": 966.3890380859375, "reward": 0.8329023122787476, "action": -0.28516995906829834}
{"mode": "train", "epochs": 3, "timestep": 5720, "ep_reward": 967.1824951171875, "reward": 0.7934478521347046, "action": -1.573530912399292}
{"mode": "train", "epochs": 3, "timestep": 5721, "ep_reward": 967.8955078125, "reward": 0.7130185961723328, "action": -0.07223689556121826}
{"mode": "train", "epochs": 3, "timestep": 5722, "ep_reward": 968.51123046875, "reward": 0.6157267689704895, "action": -0.8390437364578247}
{"mode": "train", "epochs": 3, "timestep": 5723, "ep_reward": 968.9816284179688, "reward": 0.4704161286354065, "action": -0.6714626550674438}
{"mode": "train", "epochs": 3, "timestep": 5724, "ep_reward": 969.3118896484375, "reward": 0.3302385210990906, "action": -1.6724945306777954}
{"mode": "train", "epochs": 3, "timestep": 5725, "ep_reward": 969.5283813476562, "reward": 0.21651041507720947, "action": -0.9119704365730286}
{"mode": "train", "epochs": 3, "timestep": 5726, "ep_reward": 969.611083984375, "reward": 0.0826871395111084, "action": -0.5890136957168579}
{"mode": "train", "epochs": 3, "timestep": 5727, "ep_reward": 969.6460571289062, "reward": 0.03497970104217529, "action": -1.6817069053649902}
{"mode": "train", "epochs": 3, "timestep": 5728, "ep_reward": 969.821533203125, "reward": 0.17547112703323364, "action": -0.29423439502716064}
{"mode": "train", "epochs": 3, "timestep": 5729, "ep_reward": 970.1456909179688, "reward": 0.3241491913795471, "action": -1.144361138343811}
{"mode": "train", "epochs": 3, "timestep": 5730, "ep_reward": 970.6017456054688, "reward": 0.4560450315475464, "action": -1.122402310371399}
{"mode": "train", "epochs": 3, "timestep": 5731, "ep_reward": 971.1763916015625, "reward": 0.5746465921401978, "action": -1.6194078922271729}
{"mode": "train", "epochs": 3, "timestep": 5732, "ep_reward": 971.8447265625, "reward": 0.6683598160743713, "action": -1.730135202407837}
{"mode": "train", "epochs": 3, "timestep": 5733, "ep_reward": 972.584716796875, "reward": 0.740003228187561, "action": -1.569887638092041}
{"mode": "train", "epochs": 3, "timestep": 5734, "ep_reward": 973.3768920898438, "reward": 0.7921655178070068, "action": -1.5841054916381836}
{"mode": "train", "epochs": 3, "timestep": 5735, "ep_reward": 974.2010498046875, "reward": 0.8241603374481201, "action": -0.8369300961494446}
{"mode": "train", "epochs": 3, "timestep": 5736, "ep_reward": 975.0445556640625, "reward": 0.8434959053993225, "action": -1.8273789882659912}
{"mode": "train", "epochs": 3, "timestep": 5737, "ep_reward": 975.8792114257812, "reward": 0.8346651196479797, "action": -0.39656364917755127}
{"mode": "train", "epochs": 3, "timestep": 5738, "ep_reward": 976.6973266601562, "reward": 0.8181294202804565, "action": -1.655320644378662}
{"mode": "train", "epochs": 3, "timestep": 5739, "ep_reward": 977.461669921875, "reward": 0.764318585395813, "action": -0.9116976261138916}
{"mode": "train", "epochs": 3, "timestep": 5740, "ep_reward": 978.148681640625, "reward": 0.6870020627975464, "action": -0.5110763311386108}
{"mode": "train", "epochs": 3, "timestep": 5741, "ep_reward": 978.7264404296875, "reward": 0.5777726769447327, "action": -0.5374654531478882}
{"mode": "train", "epochs": 3, "timestep": 5742, "ep_reward": 979.1535034179688, "reward": 0.4270850419998169, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5743, "ep_reward": 979.4727783203125, "reward": 0.3192583918571472, "action": -1.3993414640426636}
{"mode": "train", "epochs": 3, "timestep": 5744, "ep_reward": 979.6760864257812, "reward": 0.203280508518219, "action": -1.526258945465088}
{"mode": "train", "epochs": 3, "timestep": 5745, "ep_reward": 979.7435302734375, "reward": 0.06744539737701416, "action": -0.6142795085906982}
{"mode": "train", "epochs": 3, "timestep": 5746, "ep_reward": 979.7943725585938, "reward": 0.050818443298339844, "action": -0.7676757574081421}
{"mode": "train", "epochs": 3, "timestep": 5747, "ep_reward": 979.98486328125, "reward": 0.190468430519104, "action": -0.7083119750022888}
{"mode": "train", "epochs": 3, "timestep": 5748, "ep_reward": 980.3189086914062, "reward": 0.334037721157074, "action": -0.1415199637413025}
{"mode": "train", "epochs": 3, "timestep": 5749, "ep_reward": 980.79638671875, "reward": 0.47750818729400635, "action": -0.8776930570602417}
{"mode": "train", "epochs": 3, "timestep": 5750, "ep_reward": 981.3919067382812, "reward": 0.5955061912536621, "action": 0.057588815689086914}
{"mode": "train", "epochs": 3, "timestep": 5751, "ep_reward": 982.0939331054688, "reward": 0.7020394802093506, "action": -0.6093711853027344}
{"mode": "train", "epochs": 3, "timestep": 5752, "ep_reward": 982.8722534179688, "reward": 0.7782990336418152, "action": -1.2799451351165771}
{"mode": "train", "epochs": 3, "timestep": 5753, "ep_reward": 983.7012939453125, "reward": 0.8290432691574097, "action": -0.27030009031295776}
{"mode": "train", "epochs": 3, "timestep": 5754, "ep_reward": 984.572265625, "reward": 0.8709529638290405, "action": -0.1804213523864746}
{"mode": "train", "epochs": 3, "timestep": 5755, "ep_reward": 985.4705810546875, "reward": 0.8983179330825806, "action": -1.0925674438476562}
{"mode": "train", "epochs": 3, "timestep": 5756, "ep_reward": 986.3775024414062, "reward": 0.9069184064865112, "action": -1.3801090717315674}
{"mode": "train", "epochs": 3, "timestep": 5757, "ep_reward": 987.2796020507812, "reward": 0.9020882248878479, "action": -0.8218063116073608}
{"mode": "train", "epochs": 3, "timestep": 5758, "ep_reward": 988.16796875, "reward": 0.8883466720581055, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5759, "ep_reward": 989.0172729492188, "reward": 0.8493188619613647, "action": -1.0118244886398315}
{"mode": "train", "epochs": 3, "timestep": 5760, "ep_reward": 989.8141479492188, "reward": 0.7969051599502563, "action": -1.4267996549606323}
{"mode": "train", "epochs": 3, "timestep": 5761, "ep_reward": 990.5266723632812, "reward": 0.7125270962715149, "action": -0.4888122081756592}
{"mode": "train", "epochs": 3, "timestep": 5762, "ep_reward": 991.13134765625, "reward": 0.6046791076660156, "action": -0.945737361907959}
{"mode": "train", "epochs": 3, "timestep": 5763, "ep_reward": 991.5842895507812, "reward": 0.4529186487197876, "action": -0.5990452170372009}
{"mode": "train", "epochs": 3, "timestep": 5764, "ep_reward": 991.89013671875, "reward": 0.3058663010597229, "action": -0.7003344297409058}
{"mode": "train", "epochs": 3, "timestep": 5765, "ep_reward": 992.0775146484375, "reward": 0.18738669157028198, "action": -0.7986509203910828}
{"mode": "train", "epochs": 3, "timestep": 5766, "ep_reward": 992.12646484375, "reward": 0.048944175243377686, "action": -0.39179980754852295}
{"mode": "train", "epochs": 3, "timestep": 5767, "ep_reward": 992.19580078125, "reward": 0.069324791431427, "action": -0.46297913789749146}
{"mode": "train", "epochs": 3, "timestep": 5768, "ep_reward": 992.4090576171875, "reward": 0.2132304310798645, "action": -1.6078073978424072}
{"mode": "train", "epochs": 3, "timestep": 5769, "ep_reward": 992.7535400390625, "reward": 0.3444734215736389, "action": -1.0504224300384521}
{"mode": "train", "epochs": 3, "timestep": 5770, "ep_reward": 993.230712890625, "reward": 0.4771673083305359, "action": -1.0796462297439575}
{"mode": "train", "epochs": 3, "timestep": 5771, "ep_reward": 993.8244018554688, "reward": 0.5936684012413025, "action": -0.9973332285881042}
{"mode": "train", "epochs": 3, "timestep": 5772, "ep_reward": 994.5140380859375, "reward": 0.6896313428878784, "action": -1.2061113119125366}
{"mode": "train", "epochs": 3, "timestep": 5773, "ep_reward": 995.2745361328125, "reward": 0.7604760527610779, "action": -1.7486289739608765}
{"mode": "train", "epochs": 3, "timestep": 5774, "ep_reward": 996.0796508789062, "reward": 0.8050940632820129, "action": -1.2685480117797852}
{"mode": "train", "epochs": 3, "timestep": 5775, "ep_reward": 996.9144287109375, "reward": 0.8347487449645996, "action": -0.6531150341033936}
{"mode": "train", "epochs": 3, "timestep": 5776, "ep_reward": 997.7655639648438, "reward": 0.85112464427948, "action": -0.8097046613693237}
{"mode": "train", "epochs": 3, "timestep": 5777, "ep_reward": 998.6131591796875, "reward": 0.8475902676582336, "action": -1.3120009899139404}
{"mode": "train", "epochs": 3, "timestep": 5778, "ep_reward": 999.4325561523438, "reward": 0.8193883895874023, "action": -0.5034581422805786}
{"mode": "train", "epochs": 3, "timestep": 5779, "ep_reward": 1000.2077026367188, "reward": 0.7751510739326477, "action": -1.1694607734680176}
{"mode": "train", "epochs": 3, "timestep": 5780, "ep_reward": 1000.9019775390625, "reward": 0.6942943334579468, "action": -0.8435785174369812}
{"mode": "train", "epochs": 3, "timestep": 5781, "ep_reward": 1001.4822998046875, "reward": 0.5803444385528564, "action": -1.3459205627441406}
{"mode": "train", "epochs": 3, "timestep": 5782, "ep_reward": 1001.8990478515625, "reward": 0.41675466299057007, "action": -0.4673832654953003}
{"mode": "train", "epochs": 3, "timestep": 5783, "ep_reward": 1002.2117309570312, "reward": 0.31267064809799194, "action": -1.148298740386963}
{"mode": "train", "epochs": 3, "timestep": 5784, "ep_reward": 1002.4072265625, "reward": 0.19547617435455322, "action": -1.1194292306900024}
{"mode": "train", "epochs": 3, "timestep": 5785, "ep_reward": 1002.46533203125, "reward": 0.05813014507293701, "action": -1.8901689052581787}
{"mode": "train", "epochs": 3, "timestep": 5786, "ep_reward": 1002.5252685546875, "reward": 0.05996209383010864, "action": -1.0709129571914673}
{"mode": "train", "epochs": 3, "timestep": 5787, "ep_reward": 1002.72216796875, "reward": 0.19688493013381958, "action": -1.3936635255813599}
{"mode": "train", "epochs": 3, "timestep": 5788, "ep_reward": 1003.0545654296875, "reward": 0.33237701654434204, "action": -0.07481557130813599}
{"mode": "train", "epochs": 3, "timestep": 5789, "ep_reward": 1003.5327758789062, "reward": 0.4782017469406128, "action": -1.0955263376235962}
{"mode": "train", "epochs": 3, "timestep": 5790, "ep_reward": 1004.126953125, "reward": 0.5941838026046753, "action": -0.62981116771698}
{"mode": "train", "epochs": 3, "timestep": 5791, "ep_reward": 1004.8209838867188, "reward": 0.6940057277679443, "action": -1.1913552284240723}
{"mode": "train", "epochs": 3, "timestep": 5792, "ep_reward": 1005.5863647460938, "reward": 0.7653504610061646, "action": -0.3347487449645996}
{"mode": "train", "epochs": 3, "timestep": 5793, "ep_reward": 1006.4097900390625, "reward": 0.8234171867370605, "action": -0.7486499547958374}
{"mode": "train", "epochs": 3, "timestep": 5794, "ep_reward": 1007.2684326171875, "reward": 0.8586286306381226, "action": -1.46299147605896}
{"mode": "train", "epochs": 3, "timestep": 5795, "ep_reward": 1008.1405029296875, "reward": 0.8720442056655884, "action": -1.4496389627456665}
{"mode": "train", "epochs": 3, "timestep": 5796, "ep_reward": 1009.0108032226562, "reward": 0.8702926635742188, "action": -1.2165075540542603}
{"mode": "train", "epochs": 3, "timestep": 5797, "ep_reward": 1009.8645629882812, "reward": 0.8537359833717346, "action": -0.9922577738761902}
{"mode": "train", "epochs": 3, "timestep": 5798, "ep_reward": 1010.6840209960938, "reward": 0.819465696811676, "action": -0.6668094396591187}
{"mode": "train", "epochs": 3, "timestep": 5799, "ep_reward": 1011.4483032226562, "reward": 0.7642534971237183, "action": -1.215099573135376}
{"mode": "train", "epochs": 3, "timestep": 5800, "ep_reward": 1012.120849609375, "reward": 0.6725178956985474, "action": -0.8159723281860352}
{"mode": "train", "epochs": 3, "timestep": 5801, "ep_reward": 1012.6687622070312, "reward": 0.5478957891464233, "action": -0.7533562779426575}
{"mode": "train", "epochs": 3, "timestep": 5802, "ep_reward": 1013.0521850585938, "reward": 0.3834213614463806, "action": -0.8917017579078674}
{"mode": "train", "epochs": 3, "timestep": 5803, "ep_reward": 1013.32861328125, "reward": 0.27640438079833984, "action": -1.0374600887298584}
{"mode": "train", "epochs": 3, "timestep": 5804, "ep_reward": 1013.4813232421875, "reward": 0.15269434452056885, "action": -0.4012414813041687}
{"mode": "train", "epochs": 3, "timestep": 5805, "ep_reward": 1013.490234375, "reward": 0.00890880823135376, "action": -0.6442826986312866}
{"mode": "train", "epochs": 3, "timestep": 5806, "ep_reward": 1013.597412109375, "reward": 0.10719889402389526, "action": -0.5877603888511658}
{"mode": "train", "epochs": 3, "timestep": 5807, "ep_reward": 1013.84814453125, "reward": 0.2507057785987854, "action": -1.4864782094955444}
{"mode": "train", "epochs": 3, "timestep": 5808, "ep_reward": 1014.2306518554688, "reward": 0.3825342059135437, "action": -1.1842925548553467}
{"mode": "train", "epochs": 3, "timestep": 5809, "ep_reward": 1014.740478515625, "reward": 0.5098114013671875, "action": -1.431432843208313}
{"mode": "train", "epochs": 3, "timestep": 5810, "ep_reward": 1015.3577270507812, "reward": 0.6172213554382324, "action": -0.9981387853622437}
{"mode": "train", "epochs": 3, "timestep": 5811, "ep_reward": 1016.0655517578125, "reward": 0.7077961564064026, "action": -0.9402282238006592}
{"mode": "train", "epochs": 3, "timestep": 5812, "ep_reward": 1016.8413696289062, "reward": 0.7758067846298218, "action": -0.31625455617904663}
{"mode": "train", "epochs": 3, "timestep": 5813, "ep_reward": 1017.6691284179688, "reward": 0.8277878165245056, "action": -0.4100360870361328}
{"mode": "train", "epochs": 3, "timestep": 5814, "ep_reward": 1018.5284423828125, "reward": 0.8593316674232483, "action": -1.0433802604675293}
{"mode": "train", "epochs": 3, "timestep": 5815, "ep_reward": 1019.3971557617188, "reward": 0.8687422275543213, "action": -1.2111237049102783}
{"mode": "train", "epochs": 3, "timestep": 5816, "ep_reward": 1020.2574462890625, "reward": 0.8603071570396423, "action": -1.4042118787765503}
{"mode": "train", "epochs": 3, "timestep": 5817, "ep_reward": 1021.0889282226562, "reward": 0.8314907550811768, "action": -0.563678503036499}
{"mode": "train", "epochs": 3, "timestep": 5818, "ep_reward": 1021.8770141601562, "reward": 0.7880659103393555, "action": -0.16341131925582886}
{"mode": "train", "epochs": 3, "timestep": 5819, "ep_reward": 1022.5992431640625, "reward": 0.7222424149513245, "action": -1.545701026916504}
{"mode": "train", "epochs": 3, "timestep": 5820, "ep_reward": 1023.2056274414062, "reward": 0.6063879728317261, "action": -1.3377058506011963}
{"mode": "train", "epochs": 3, "timestep": 5821, "ep_reward": 1023.6561889648438, "reward": 0.45054149627685547, "action": -0.25682371854782104}
{"mode": "train", "epochs": 3, "timestep": 5822, "ep_reward": 1023.98095703125, "reward": 0.3247948884963989, "action": -1.271306037902832}
{"mode": "train", "epochs": 3, "timestep": 5823, "ep_reward": 1024.19091796875, "reward": 0.20991796255111694, "action": -1.0548183917999268}
{"mode": "train", "epochs": 3, "timestep": 5824, "ep_reward": 1024.2659912109375, "reward": 0.07507646083831787, "action": -0.07319074869155884}
{"mode": "train", "epochs": 3, "timestep": 5825, "ep_reward": 1024.30908203125, "reward": 0.04307293891906738, "action": -0.15772032737731934}
{"mode": "train", "epochs": 3, "timestep": 5826, "ep_reward": 1024.4989013671875, "reward": 0.1898382306098938, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5827, "ep_reward": 1024.81494140625, "reward": 0.31599730253219604, "action": -1.7024115324020386}
{"mode": "train", "epochs": 3, "timestep": 5828, "ep_reward": 1025.258544921875, "reward": 0.4435553550720215, "action": -0.7611001133918762}
{"mode": "train", "epochs": 3, "timestep": 5829, "ep_reward": 1025.82763671875, "reward": 0.5690407752990723, "action": -1.298414945602417}
{"mode": "train", "epochs": 3, "timestep": 5830, "ep_reward": 1026.494384765625, "reward": 0.6667037010192871, "action": -0.6749684810638428}
{"mode": "train", "epochs": 3, "timestep": 5831, "ep_reward": 1027.241943359375, "reward": 0.7475040555000305, "action": -0.6601229310035706}
{"mode": "train", "epochs": 3, "timestep": 5832, "ep_reward": 1028.046875, "reward": 0.8049101233482361, "action": -0.9472545981407166}
{"mode": "train", "epochs": 3, "timestep": 5833, "ep_reward": 1028.8858642578125, "reward": 0.8389670252799988, "action": -1.1750178337097168}
{"mode": "train", "epochs": 3, "timestep": 5834, "ep_reward": 1029.7386474609375, "reward": 0.852724015712738, "action": -0.5456589460372925}
{"mode": "train", "epochs": 3, "timestep": 5835, "ep_reward": 1030.5927734375, "reward": 0.8541450500488281, "action": -0.9286099672317505}
{"mode": "train", "epochs": 3, "timestep": 5836, "ep_reward": 1031.426025390625, "reward": 0.8332344889640808, "action": -0.998950719833374}
{"mode": "train", "epochs": 3, "timestep": 5837, "ep_reward": 1032.2152099609375, "reward": 0.7892093658447266, "action": -1.0307388305664062}
{"mode": "train", "epochs": 3, "timestep": 5838, "ep_reward": 1032.9317626953125, "reward": 0.7165381908416748, "action": -1.5333340167999268}
{"mode": "train", "epochs": 3, "timestep": 5839, "ep_reward": 1033.5333251953125, "reward": 0.6016013622283936, "action": -1.430487871170044}
{"mode": "train", "epochs": 3, "timestep": 5840, "ep_reward": 1033.9771728515625, "reward": 0.4438020586967468, "action": -1.9321393966674805}
{"mode": "train", "epochs": 3, "timestep": 5841, "ep_reward": 1034.309326171875, "reward": 0.3322051167488098, "action": -1.329937219619751}
{"mode": "train", "epochs": 3, "timestep": 5842, "ep_reward": 1034.528076171875, "reward": 0.2187982201576233, "action": -0.7314898371696472}
{"mode": "train", "epochs": 3, "timestep": 5843, "ep_reward": 1034.6134033203125, "reward": 0.08528989553451538, "action": -0.9411907196044922}
{"mode": "train", "epochs": 3, "timestep": 5844, "ep_reward": 1034.6456298828125, "reward": 0.032213568687438965, "action": -1.7020831108093262}
{"mode": "train", "epochs": 3, "timestep": 5845, "ep_reward": 1034.8187255859375, "reward": 0.1730460524559021, "action": -0.7566317915916443}
{"mode": "train", "epochs": 3, "timestep": 5846, "ep_reward": 1035.134765625, "reward": 0.31608641147613525, "action": -0.34388428926467896}
{"mode": "train", "epochs": 3, "timestep": 5847, "ep_reward": 1035.593505859375, "reward": 0.45871400833129883, "action": -0.7740849256515503}
{"mode": "train", "epochs": 3, "timestep": 5848, "ep_reward": 1036.1741943359375, "reward": 0.580649197101593, "action": -0.7203027009963989}
{"mode": "train", "epochs": 3, "timestep": 5849, "ep_reward": 1036.8568115234375, "reward": 0.6826134920120239, "action": -0.05641072988510132}
{"mode": "train", "epochs": 3, "timestep": 5850, "ep_reward": 1037.624755859375, "reward": 0.7679919600486755, "action": -0.9699535965919495}
{"mode": "train", "epochs": 3, "timestep": 5851, "ep_reward": 1038.4481201171875, "reward": 0.8234217762947083, "action": -1.0770950317382812}
{"mode": "train", "epochs": 3, "timestep": 5852, "ep_reward": 1039.3084716796875, "reward": 0.8604006171226501, "action": -1.975377082824707}
{"mode": "train", "epochs": 3, "timestep": 5853, "ep_reward": 1040.184326171875, "reward": 0.8758326768875122, "action": -0.7722651958465576}
{"mode": "train", "epochs": 3, "timestep": 5854, "ep_reward": 1041.07080078125, "reward": 0.8865082263946533, "action": -1.721881628036499}
{"mode": "train", "epochs": 3, "timestep": 5855, "ep_reward": 1041.9464111328125, "reward": 0.8755595088005066, "action": 0.1628960371017456}
{"mode": "train", "epochs": 3, "timestep": 5856, "ep_reward": 1042.8106689453125, "reward": 0.864251434803009, "action": -0.819790780544281}
{"mode": "train", "epochs": 3, "timestep": 5857, "ep_reward": 1043.6373291015625, "reward": 0.8266417384147644, "action": -0.20846623182296753}
{"mode": "train", "epochs": 3, "timestep": 5858, "ep_reward": 1044.40966796875, "reward": 0.772394061088562, "action": -0.5346858501434326}
{"mode": "train", "epochs": 3, "timestep": 5859, "ep_reward": 1045.0966796875, "reward": 0.6869827508926392, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5860, "ep_reward": 1045.6439208984375, "reward": 0.5472562313079834, "action": 0.19356191158294678}
{"mode": "train", "epochs": 3, "timestep": 5861, "ep_reward": 1046.04150390625, "reward": 0.3975767493247986, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5862, "ep_reward": 1046.3072509765625, "reward": 0.2657892107963562, "action": -0.8476776480674744}
{"mode": "train", "epochs": 3, "timestep": 5863, "ep_reward": 1046.4473876953125, "reward": 0.14015215635299683, "action": -0.9760740399360657}
{"mode": "train", "epochs": 3, "timestep": 5864, "ep_reward": 1046.44189453125, "reward": -0.005469202995300293, "action": -0.9472926259040833}
{"mode": "train", "epochs": 3, "timestep": 5865, "ep_reward": 1046.56201171875, "reward": 0.12012237310409546, "action": -0.7406546473503113}
{"mode": "train", "epochs": 3, "timestep": 5866, "ep_reward": 1046.8240966796875, "reward": 0.2621316909790039, "action": -1.181043267250061}
{"mode": "train", "epochs": 3, "timestep": 5867, "ep_reward": 1047.2215576171875, "reward": 0.39745891094207764, "action": -1.5799521207809448}
{"mode": "train", "epochs": 3, "timestep": 5868, "ep_reward": 1047.7401123046875, "reward": 0.5185332298278809, "action": -0.5880616307258606}
{"mode": "train", "epochs": 3, "timestep": 5869, "ep_reward": 1048.3736572265625, "reward": 0.6335703730583191, "action": -0.5677264928817749}
{"mode": "train", "epochs": 3, "timestep": 5870, "ep_reward": 1049.0986328125, "reward": 0.7250224351882935, "action": -1.3453967571258545}
{"mode": "train", "epochs": 3, "timestep": 5871, "ep_reward": 1049.884765625, "reward": 0.7861283421516418, "action": -1.0741091966629028}
{"mode": "train", "epochs": 3, "timestep": 5872, "ep_reward": 1050.714599609375, "reward": 0.8298288583755493, "action": -0.3064296245574951}
{"mode": "train", "epochs": 3, "timestep": 5873, "ep_reward": 1051.576171875, "reward": 0.8615658283233643, "action": -1.7566165924072266}
{"mode": "train", "epochs": 3, "timestep": 5874, "ep_reward": 1052.4407958984375, "reward": 0.8646367192268372, "action": -1.4418121576309204}
{"mode": "train", "epochs": 3, "timestep": 5875, "ep_reward": 1053.2943115234375, "reward": 0.8534743785858154, "action": -0.5842273235321045}
{"mode": "train", "epochs": 3, "timestep": 5876, "ep_reward": 1054.1251220703125, "reward": 0.8308181762695312, "action": -1.1134668588638306}
{"mode": "train", "epochs": 3, "timestep": 5877, "ep_reward": 1054.905517578125, "reward": 0.7803452014923096, "action": -0.735839307308197}
{"mode": "train", "epochs": 3, "timestep": 5878, "ep_reward": 1055.610595703125, "reward": 0.7050386667251587, "action": -0.6018635034561157}
{"mode": "train", "epochs": 3, "timestep": 5879, "ep_reward": 1056.2073974609375, "reward": 0.5967622995376587, "action": -0.6491963863372803}
{"mode": "train", "epochs": 3, "timestep": 5880, "ep_reward": 1056.656005859375, "reward": 0.4486079812049866, "action": -0.5798279047012329}
{"mode": "train", "epochs": 3, "timestep": 5881, "ep_reward": 1056.973388671875, "reward": 0.31740260124206543, "action": -1.6992418766021729}
{"mode": "train", "epochs": 3, "timestep": 5882, "ep_reward": 1057.1746826171875, "reward": 0.20123302936553955, "action": -0.9506856203079224}
{"mode": "train", "epochs": 3, "timestep": 5883, "ep_reward": 1057.2396240234375, "reward": 0.06497210264205933, "action": -0.5865186452865601}
{"mode": "train", "epochs": 3, "timestep": 5884, "ep_reward": 1057.2928466796875, "reward": 0.05325239896774292, "action": -1.3307149410247803}
{"mode": "train", "epochs": 3, "timestep": 5885, "ep_reward": 1057.484130859375, "reward": 0.19124066829681396, "action": 0.026624441146850586}
{"mode": "train", "epochs": 3, "timestep": 5886, "ep_reward": 1057.828125, "reward": 0.34401893615722656, "action": -1.2706146240234375}
{"mode": "train", "epochs": 3, "timestep": 5887, "ep_reward": 1058.30078125, "reward": 0.47266024351119995, "action": -1.0295631885528564}
{"mode": "train", "epochs": 3, "timestep": 5888, "ep_reward": 1058.8907470703125, "reward": 0.5900126695632935, "action": -0.41080141067504883}
{"mode": "train", "epochs": 3, "timestep": 5889, "ep_reward": 1059.583740234375, "reward": 0.6929693222045898, "action": -1.3563746213912964}
{"mode": "train", "epochs": 3, "timestep": 5890, "ep_reward": 1060.3475341796875, "reward": 0.7638427019119263, "action": -0.5736802816390991}
{"mode": "train", "epochs": 3, "timestep": 5891, "ep_reward": 1061.1689453125, "reward": 0.821445643901825, "action": -0.622472882270813}
{"mode": "train", "epochs": 3, "timestep": 5892, "ep_reward": 1062.0286865234375, "reward": 0.8596920967102051, "action": -1.2169439792633057}
{"mode": "train", "epochs": 3, "timestep": 5893, "ep_reward": 1062.9061279296875, "reward": 0.8774059414863586, "action": -0.6937101483345032}
{"mode": "train", "epochs": 3, "timestep": 5894, "ep_reward": 1063.791015625, "reward": 0.8848574161529541, "action": -0.18266218900680542}
{"mode": "train", "epochs": 3, "timestep": 5895, "ep_reward": 1064.6729736328125, "reward": 0.8820167779922485, "action": -0.7185102105140686}
{"mode": "train", "epochs": 3, "timestep": 5896, "ep_reward": 1065.5323486328125, "reward": 0.8593348860740662, "action": -1.454106092453003}
{"mode": "train", "epochs": 3, "timestep": 5897, "ep_reward": 1066.3428955078125, "reward": 0.8105771541595459, "action": -0.8224834203720093}
{"mode": "train", "epochs": 3, "timestep": 5898, "ep_reward": 1067.0849609375, "reward": 0.7420125007629395, "action": -0.8630598783493042}
{"mode": "train", "epochs": 3, "timestep": 5899, "ep_reward": 1067.7261962890625, "reward": 0.6412512063980103, "action": -0.5511311888694763}
{"mode": "train", "epochs": 3, "timestep": 5900, "ep_reward": 1068.233642578125, "reward": 0.5073943138122559, "action": -0.8178351521492004}
{"mode": "train", "epochs": 3, "timestep": 5901, "ep_reward": 1068.5740966796875, "reward": 0.3404526710510254, "action": -0.44713127613067627}
{"mode": "train", "epochs": 3, "timestep": 5902, "ep_reward": 1068.8026123046875, "reward": 0.22845673561096191, "action": -1.3379563093185425}
{"mode": "train", "epochs": 3, "timestep": 5903, "ep_reward": 1068.8992919921875, "reward": 0.09666824340820312, "action": 0.14625942707061768}
{"mode": "train", "epochs": 3, "timestep": 5904, "ep_reward": 1068.9195556640625, "reward": 0.02028590440750122, "action": -1.1795122623443604}
{"mode": "train", "epochs": 3, "timestep": 5905, "ep_reward": 1069.0821533203125, "reward": 0.1626209020614624, "action": -0.6522423624992371}
{"mode": "train", "epochs": 3, "timestep": 5906, "ep_reward": 1069.388916015625, "reward": 0.3067430853843689, "action": -0.6613240242004395}
{"mode": "train", "epochs": 3, "timestep": 5907, "ep_reward": 1069.834716796875, "reward": 0.44580793380737305, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5908, "ep_reward": 1070.3907470703125, "reward": 0.5560741424560547, "action": -0.555700421333313}
{"mode": "train", "epochs": 3, "timestep": 5909, "ep_reward": 1071.0550537109375, "reward": 0.6643592119216919, "action": -0.9301077127456665}
{"mode": "train", "epochs": 3, "timestep": 5910, "ep_reward": 1071.8001708984375, "reward": 0.7451714277267456, "action": -0.3936668038368225}
{"mode": "train", "epochs": 3, "timestep": 5911, "ep_reward": 1072.60888671875, "reward": 0.8086949586868286, "action": -0.7243651151657104}
{"mode": "train", "epochs": 3, "timestep": 5912, "ep_reward": 1073.4578857421875, "reward": 0.8490439653396606, "action": -1.5872583389282227}
{"mode": "train", "epochs": 3, "timestep": 5913, "ep_reward": 1074.323486328125, "reward": 0.8656018972396851, "action": -1.0297410488128662}
{"mode": "train", "epochs": 3, "timestep": 5914, "ep_reward": 1075.194580078125, "reward": 0.8711372017860413, "action": -0.7980706691741943}
{"mode": "train", "epochs": 3, "timestep": 5915, "ep_reward": 1076.0570068359375, "reward": 0.8624050617218018, "action": -0.9082819819450378}
{"mode": "train", "epochs": 3, "timestep": 5916, "ep_reward": 1076.8914794921875, "reward": 0.8344422578811646, "action": -1.4230515956878662}
{"mode": "train", "epochs": 3, "timestep": 5917, "ep_reward": 1077.670166015625, "reward": 0.7786720991134644, "action": -0.5787724256515503}
{"mode": "train", "epochs": 3, "timestep": 5918, "ep_reward": 1078.372802734375, "reward": 0.7026344537734985, "action": -1.0323975086212158}
{"mode": "train", "epochs": 3, "timestep": 5919, "ep_reward": 1078.958984375, "reward": 0.5861233472824097, "action": -0.81269770860672}
{"mode": "train", "epochs": 3, "timestep": 5920, "ep_reward": 1079.390625, "reward": 0.43167537450790405, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5921, "ep_reward": 1079.697509765625, "reward": 0.30691105127334595, "action": -0.3068249821662903}
{"mode": "train", "epochs": 3, "timestep": 5922, "ep_reward": 1079.885986328125, "reward": 0.18849891424179077, "action": -1.474900245666504}
{"mode": "train", "epochs": 3, "timestep": 5923, "ep_reward": 1079.936279296875, "reward": 0.05023914575576782, "action": -1.3337125778198242}
{"mode": "train", "epochs": 3, "timestep": 5924, "ep_reward": 1080.004150390625, "reward": 0.06783103942871094, "action": -1.4694857597351074}
{"mode": "train", "epochs": 3, "timestep": 5925, "ep_reward": 1080.2080078125, "reward": 0.20385318994522095, "action": 0.1677076816558838}
{"mode": "train", "epochs": 3, "timestep": 5926, "ep_reward": 1080.5665283203125, "reward": 0.3585042357444763, "action": -0.9840512275695801}
{"mode": "train", "epochs": 3, "timestep": 5927, "ep_reward": 1081.0556640625, "reward": 0.48911863565444946, "action": -1.6101322174072266}
{"mode": "train", "epochs": 3, "timestep": 5928, "ep_reward": 1081.6531982421875, "reward": 0.5975339412689209, "action": -1.4137825965881348}
{"mode": "train", "epochs": 3, "timestep": 5929, "ep_reward": 1082.342041015625, "reward": 0.6887975335121155, "action": -1.6224870681762695}
{"mode": "train", "epochs": 3, "timestep": 5930, "ep_reward": 1083.0987548828125, "reward": 0.7567033171653748, "action": -0.7467200756072998}
{"mode": "train", "epochs": 3, "timestep": 5931, "ep_reward": 1083.91064453125, "reward": 0.811851978302002, "action": -1.1401617527008057}
{"mode": "train", "epochs": 3, "timestep": 5932, "ep_reward": 1084.75439453125, "reward": 0.8437703847885132, "action": -0.43761295080184937}
{"mode": "train", "epochs": 3, "timestep": 5933, "ep_reward": 1085.6185302734375, "reward": 0.8640760183334351, "action": -0.5588892698287964}
{"mode": "train", "epochs": 3, "timestep": 5934, "ep_reward": 1086.485107421875, "reward": 0.8666113018989563, "action": -0.6174993515014648}
{"mode": "train", "epochs": 3, "timestep": 5935, "ep_reward": 1087.3365478515625, "reward": 0.851472795009613, "action": -1.5435819625854492}
{"mode": "train", "epochs": 3, "timestep": 5936, "ep_reward": 1088.14404296875, "reward": 0.8074609041213989, "action": -1.7240500450134277}
{"mode": "train", "epochs": 3, "timestep": 5937, "ep_reward": 1088.8780517578125, "reward": 0.7339683771133423, "action": -1.012500524520874}
{"mode": "train", "epochs": 3, "timestep": 5938, "ep_reward": 1089.5115966796875, "reward": 0.6335704922676086, "action": -1.491532325744629}
{"mode": "train", "epochs": 3, "timestep": 5939, "ep_reward": 1089.9971923828125, "reward": 0.4856237769126892, "action": 0.3035844564437866}
{"mode": "train", "epochs": 3, "timestep": 5940, "ep_reward": 1090.3504638671875, "reward": 0.3532189726829529, "action": -1.2794827222824097}
{"mode": "train", "epochs": 3, "timestep": 5941, "ep_reward": 1090.59423828125, "reward": 0.2437305450439453, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5942, "ep_reward": 1090.708740234375, "reward": 0.11456102132797241, "action": -1.1043816804885864}
{"mode": "train", "epochs": 3, "timestep": 5943, "ep_reward": 1090.7093505859375, "reward": 0.0006627440452575684, "action": -1.201213002204895}
{"mode": "train", "epochs": 3, "timestep": 5944, "ep_reward": 1090.854736328125, "reward": 0.145368754863739, "action": -1.8527545928955078}
{"mode": "train", "epochs": 3, "timestep": 5945, "ep_reward": 1091.12890625, "reward": 0.2742008566856384, "action": -0.9437991380691528}
{"mode": "train", "epochs": 3, "timestep": 5946, "ep_reward": 1091.5430908203125, "reward": 0.414148211479187, "action": -0.5417106747627258}
{"mode": "train", "epochs": 3, "timestep": 5947, "ep_reward": 1092.089111328125, "reward": 0.5459607839584351, "action": -0.8953472971916199}
{"mode": "train", "epochs": 3, "timestep": 5948, "ep_reward": 1092.74169921875, "reward": 0.6526339054107666, "action": -0.9309104681015015}
{"mode": "train", "epochs": 3, "timestep": 5949, "ep_reward": 1093.4775390625, "reward": 0.7358214259147644, "action": -0.7818105220794678}
{"mode": "train", "epochs": 3, "timestep": 5950, "ep_reward": 1094.2752685546875, "reward": 0.7976903319358826, "action": -1.6059629917144775}
{"mode": "train", "epochs": 3, "timestep": 5951, "ep_reward": 1095.1072998046875, "reward": 0.8320332765579224, "action": -1.1241052150726318}
{"mode": "train", "epochs": 3, "timestep": 5952, "ep_reward": 1095.9598388671875, "reward": 0.8524990677833557, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5953, "ep_reward": 1096.8074951171875, "reward": 0.8477005958557129, "action": -1.574414849281311}
{"mode": "train", "epochs": 3, "timestep": 5954, "ep_reward": 1097.6343994140625, "reward": 0.8269158005714417, "action": -1.3902230262756348}
{"mode": "train", "epochs": 3, "timestep": 5955, "ep_reward": 1098.418701171875, "reward": 0.7842555046081543, "action": -0.469551682472229}
{"mode": "train", "epochs": 3, "timestep": 5956, "ep_reward": 1099.1417236328125, "reward": 0.7229709625244141, "action": -0.9480504393577576}
{"mode": "train", "epochs": 3, "timestep": 5957, "ep_reward": 1099.763671875, "reward": 0.6219573020935059, "action": 0.41046082973480225}
{"mode": "train", "epochs": 3, "timestep": 5958, "ep_reward": 1100.264404296875, "reward": 0.5007369518280029, "action": -1.534822702407837}
{"mode": "train", "epochs": 3, "timestep": 5959, "ep_reward": 1100.6207275390625, "reward": 0.35638266801834106, "action": -0.515979528427124}
{"mode": "train", "epochs": 3, "timestep": 5960, "ep_reward": 1100.8682861328125, "reward": 0.2475908398628235, "action": -1.1959388256072998}
{"mode": "train", "epochs": 3, "timestep": 5961, "ep_reward": 1100.9871826171875, "reward": 0.1189233660697937, "action": -0.7517505884170532}
{"mode": "train", "epochs": 3, "timestep": 5962, "ep_reward": 1100.9830322265625, "reward": -0.004140496253967285, "action": -1.0678802728652954}
{"mode": "train", "epochs": 3, "timestep": 5963, "ep_reward": 1101.1243896484375, "reward": 0.14129799604415894, "action": -1.164973497390747}
{"mode": "train", "epochs": 3, "timestep": 5964, "ep_reward": 1101.4029541015625, "reward": 0.278555691242218, "action": -1.296633243560791}
{"mode": "train", "epochs": 3, "timestep": 5965, "ep_reward": 1101.8155517578125, "reward": 0.4125989079475403, "action": -1.4651226997375488}
{"mode": "train", "epochs": 3, "timestep": 5966, "ep_reward": 1102.34912109375, "reward": 0.5335825681686401, "action": -1.6703726053237915}
{"mode": "train", "epochs": 3, "timestep": 5967, "ep_reward": 1102.9832763671875, "reward": 0.6341315507888794, "action": -1.0689995288848877}
{"mode": "train", "epochs": 3, "timestep": 5968, "ep_reward": 1103.7022705078125, "reward": 0.7189769744873047, "action": -1.2143540382385254}
{"mode": "train", "epochs": 3, "timestep": 5969, "ep_reward": 1104.4810791015625, "reward": 0.7788026928901672, "action": -1.1607948541641235}
{"mode": "train", "epochs": 3, "timestep": 5970, "ep_reward": 1105.2984619140625, "reward": 0.8174201250076294, "action": -0.6033340692520142}
{"mode": "train", "epochs": 3, "timestep": 5971, "ep_reward": 1106.139404296875, "reward": 0.840884804725647, "action": -0.8788140416145325}
{"mode": "train", "epochs": 3, "timestep": 5972, "ep_reward": 1106.9818115234375, "reward": 0.8424000144004822, "action": -0.8553137183189392}
{"mode": "train", "epochs": 3, "timestep": 5973, "ep_reward": 1107.8056640625, "reward": 0.8238805532455444, "action": -1.2690908908843994}
{"mode": "train", "epochs": 3, "timestep": 5974, "ep_reward": 1108.5831298828125, "reward": 0.777511477470398, "action": -1.151157259941101}
{"mode": "train", "epochs": 3, "timestep": 5975, "ep_reward": 1109.285400390625, "reward": 0.702286958694458, "action": -1.1355080604553223}
{"mode": "train", "epochs": 3, "timestep": 5976, "ep_reward": 1109.8753662109375, "reward": 0.5899678468704224, "action": -0.8970485925674438}
{"mode": "train", "epochs": 3, "timestep": 5977, "ep_reward": 1110.3133544921875, "reward": 0.4380323886871338, "action": 0.20199358463287354}
{"mode": "train", "epochs": 3, "timestep": 5978, "ep_reward": 1110.6446533203125, "reward": 0.33127105236053467, "action": -0.13585931062698364}
{"mode": "train", "epochs": 3, "timestep": 5979, "ep_reward": 1110.8621826171875, "reward": 0.21749800443649292, "action": -1.1911449432373047}
{"mode": "train", "epochs": 3, "timestep": 5980, "ep_reward": 1110.946044921875, "reward": 0.08381074666976929, "action": -1.1867475509643555}
{"mode": "train", "epochs": 3, "timestep": 5981, "ep_reward": 1110.97998046875, "reward": 0.033911705017089844, "action": -0.010049223899841309}
{"mode": "train", "epochs": 3, "timestep": 5982, "ep_reward": 1111.1622314453125, "reward": 0.1822882890701294, "action": -1.7022579908370972}
{"mode": "train", "epochs": 3, "timestep": 5983, "ep_reward": 1111.47412109375, "reward": 0.3119455575942993, "action": -1.607269525527954}
{"mode": "train", "epochs": 3, "timestep": 5984, "ep_reward": 1111.9144287109375, "reward": 0.44034773111343384, "action": -1.0887361764907837}
{"mode": "train", "epochs": 3, "timestep": 5985, "ep_reward": 1112.476806640625, "reward": 0.5624029636383057, "action": -0.34018081426620483}
{"mode": "train", "epochs": 3, "timestep": 5986, "ep_reward": 1113.1483154296875, "reward": 0.671521782875061, "action": -1.058488130569458}
{"mode": "train", "epochs": 3, "timestep": 5987, "ep_reward": 1113.8970947265625, "reward": 0.7487881779670715, "action": -0.8604032397270203}
{"mode": "train", "epochs": 3, "timestep": 5988, "ep_reward": 1114.7030029296875, "reward": 0.8058933615684509, "action": -0.814135730266571}
{"mode": "train", "epochs": 3, "timestep": 5989, "ep_reward": 1115.54638671875, "reward": 0.8433651328086853, "action": -1.0326476097106934}
{"mode": "train", "epochs": 3, "timestep": 5990, "ep_reward": 1116.4075927734375, "reward": 0.8611735701560974, "action": -1.4748001098632812}
{"mode": "train", "epochs": 3, "timestep": 5991, "ep_reward": 1117.2659912109375, "reward": 0.8584389090538025, "action": -1.2385461330413818}
{"mode": "train", "epochs": 3, "timestep": 5992, "ep_reward": 1118.10546875, "reward": 0.8394516706466675, "action": -0.7809009552001953}
{"mode": "train", "epochs": 3, "timestep": 5993, "ep_reward": 1118.90869140625, "reward": 0.8032802939414978, "action": -1.083984136581421}
{"mode": "train", "epochs": 3, "timestep": 5994, "ep_reward": 1119.646240234375, "reward": 0.7375277280807495, "action": -1.54987370967865}
{"mode": "train", "epochs": 3, "timestep": 5995, "ep_reward": 1120.2781982421875, "reward": 0.6319467425346375, "action": -0.45167332887649536}
{"mode": "train", "epochs": 3, "timestep": 5996, "ep_reward": 1120.7783203125, "reward": 0.5001101493835449, "action": -1.2485389709472656}
{"mode": "train", "epochs": 3, "timestep": 5997, "ep_reward": 1121.13671875, "reward": 0.358384370803833, "action": -1.3293499946594238}
{"mode": "train", "epochs": 3, "timestep": 5998, "ep_reward": 1121.386962890625, "reward": 0.2501952648162842, "action": -0.30896973609924316}
{"mode": "train", "epochs": 3, "timestep": 5999, "ep_reward": 1121.5087890625, "reward": 0.12182199954986572, "action": -1.1538424491882324}
{"mode": "train", "epochs": 3, "timestep": 6000, "ep_reward": 1121.501220703125, "reward": -0.00750887393951416, "action": -1.432410478591919}
{"mode": "train", "epochs": 4, "timestep": 6001, "ep_reward": 0.6510999202728271, "reward": 0.6510999202728271, "action": -0.972645103931427}
{"mode": "train", "epochs": 4, "timestep": 6002, "ep_reward": 1.2816789150238037, "reward": 0.6305789947509766, "action": -0.7455633878707886}
{"mode": "train", "epochs": 4, "timestep": 6003, "ep_reward": 1.8774105310440063, "reward": 0.5957316160202026, "action": -1.4169065952301025}
{"mode": "train", "epochs": 4, "timestep": 6004, "ep_reward": 2.420660972595215, "reward": 0.5432504415512085, "action": -0.7309653759002686}
{"mode": "train", "epochs": 4, "timestep": 6005, "ep_reward": 2.9019205570220947, "reward": 0.4812595248222351, "action": -1.041669249534607}
{"mode": "train", "epochs": 4, "timestep": 6006, "ep_reward": 3.3096096515655518, "reward": 0.40768903493881226, "action": -0.7339158058166504}
{"mode": "train", "epochs": 4, "timestep": 6007, "ep_reward": 3.6396772861480713, "reward": 0.3300676941871643, "action": -0.7283593416213989}
{"mode": "train", "epochs": 4, "timestep": 6008, "ep_reward": 3.985807418823242, "reward": 0.3461301922798157, "action": -1.3124067783355713}
{"mode": "train", "epochs": 4, "timestep": 6009, "ep_reward": 4.39601469039917, "reward": 0.41020721197128296, "action": -0.5631974935531616}
{"mode": "train", "epochs": 4, "timestep": 6010, "ep_reward": 4.874826431274414, "reward": 0.47881197929382324, "action": -1.6076836585998535}
{"mode": "train", "epochs": 4, "timestep": 6011, "ep_reward": 5.414805889129639, "reward": 0.5399795174598694, "action": -1.990583896636963}
{"mode": "train", "epochs": 4, "timestep": 6012, "ep_reward": 6.012053489685059, "reward": 0.597247838973999, "action": -0.9733912944793701}
{"mode": "train", "epochs": 4, "timestep": 6013, "ep_reward": 6.666428565979004, "reward": 0.6543749570846558, "action": -0.21284806728363037}
{"mode": "train", "epochs": 4, "timestep": 6014, "ep_reward": 7.37093448638916, "reward": 0.7045060992240906, "action": -1.7382466793060303}
{"mode": "train", "epochs": 4, "timestep": 6015, "ep_reward": 8.11067008972168, "reward": 0.7397358417510986, "action": -0.3864508867263794}
{"mode": "train", "epochs": 4, "timestep": 6016, "ep_reward": 8.878806114196777, "reward": 0.768136203289032, "action": -1.0428745746612549}
{"mode": "train", "epochs": 4, "timestep": 6017, "ep_reward": 9.662725448608398, "reward": 0.783919095993042, "action": -0.2677927017211914}
{"mode": "train", "epochs": 4, "timestep": 6018, "ep_reward": 10.450668334960938, "reward": 0.7879430651664734, "action": -0.9150964617729187}
{"mode": "train", "epochs": 4, "timestep": 6019, "ep_reward": 11.230765342712402, "reward": 0.7800973653793335, "action": 1.056445837020874}
{"mode": "train", "epochs": 4, "timestep": 6020, "ep_reward": 11.983644485473633, "reward": 0.7528791427612305, "action": 0.8069422245025635}
{"mode": "train", "epochs": 4, "timestep": 6021, "ep_reward": 12.69021224975586, "reward": 0.7065672874450684, "action": 0.7213407158851624}
{"mode": "train", "epochs": 4, "timestep": 6022, "ep_reward": 13.331753730773926, "reward": 0.6415414810180664, "action": 0.05095365643501282}
{"mode": "train", "epochs": 4, "timestep": 6023, "ep_reward": 13.89622688293457, "reward": 0.5644732713699341, "action": 0.10465870797634125}
{"mode": "train", "epochs": 4, "timestep": 6024, "ep_reward": 14.370487213134766, "reward": 0.47425997257232666, "action": -0.415749192237854}
{"mode": "train", "epochs": 4, "timestep": 6025, "ep_reward": 14.751262664794922, "reward": 0.38077592849731445, "action": -0.7437624335289001}
{"mode": "train", "epochs": 4, "timestep": 6026, "ep_reward": 15.040253639221191, "reward": 0.2889905571937561, "action": -0.5671309232711792}
{"mode": "train", "epochs": 4, "timestep": 6027, "ep_reward": 15.341127395629883, "reward": 0.30087369680404663, "action": -0.17657044529914856}
{"mode": "train", "epochs": 4, "timestep": 6028, "ep_reward": 15.73011589050293, "reward": 0.38898801803588867, "action": 0.6108375191688538}
{"mode": "train", "epochs": 4, "timestep": 6029, "ep_reward": 16.20052146911621, "reward": 0.4704051613807678, "action": 0.054941847920417786}
{"mode": "train", "epochs": 4, "timestep": 6030, "ep_reward": 16.751752853393555, "reward": 0.5512312650680542, "action": 0.561856210231781}
{"mode": "train", "epochs": 4, "timestep": 6031, "ep_reward": 17.372812271118164, "reward": 0.6210602521896362, "action": 0.8180992603302002}
{"mode": "train", "epochs": 4, "timestep": 6032, "ep_reward": 18.053157806396484, "reward": 0.6803447008132935, "action": 1.258289098739624}
{"mode": "train", "epochs": 4, "timestep": 6033, "ep_reward": 18.781253814697266, "reward": 0.728095293045044, "action": 1.0974574089050293}
{"mode": "train", "epochs": 4, "timestep": 6034, "ep_reward": 19.54766082763672, "reward": 0.76640784740448, "action": 1.5387976169586182}
{"mode": "train", "epochs": 4, "timestep": 6035, "ep_reward": 20.341489791870117, "reward": 0.7938295006752014, "action": 1.140539288520813}
{"mode": "train", "epochs": 4, "timestep": 6036, "ep_reward": 21.153844833374023, "reward": 0.8123553991317749, "action": 0.6628971099853516}
{"mode": "train", "epochs": 4, "timestep": 6037, "ep_reward": 21.97397804260254, "reward": 0.8201338648796082, "action": 0.1595516949892044}
{"mode": "train", "epochs": 4, "timestep": 6038, "ep_reward": 22.788585662841797, "reward": 0.814607560634613, "action": -0.8408875465393066}
{"mode": "train", "epochs": 4, "timestep": 6039, "ep_reward": 23.57918930053711, "reward": 0.790604293346405, "action": -1.6785271167755127}
{"mode": "train", "epochs": 4, "timestep": 6040, "ep_reward": 24.321224212646484, "reward": 0.7420346736907959, "action": -1.3576929569244385}
{"mode": "train", "epochs": 4, "timestep": 6041, "ep_reward": 24.992191314697266, "reward": 0.6709669232368469, "action": -0.6813551187515259}
{"mode": "train", "epochs": 4, "timestep": 6042, "ep_reward": 25.57520866394043, "reward": 0.5830181241035461, "action": 0.1701899766921997}
{"mode": "train", "epochs": 4, "timestep": 6043, "ep_reward": 26.061538696289062, "reward": 0.48632991313934326, "action": -1.0081688165664673}
{"mode": "train", "epochs": 4, "timestep": 6044, "ep_reward": 26.427034378051758, "reward": 0.36549532413482666, "action": -1.1034091711044312}
{"mode": "train", "epochs": 4, "timestep": 6045, "ep_reward": 26.660953521728516, "reward": 0.2339199185371399, "action": -0.8133176565170288}
{"mode": "train", "epochs": 4, "timestep": 6046, "ep_reward": 26.897428512573242, "reward": 0.23647451400756836, "action": 0.44941246509552}
{"mode": "train", "epochs": 4, "timestep": 6047, "ep_reward": 27.24712562561035, "reward": 0.3496973514556885, "action": -1.2740437984466553}
{"mode": "train", "epochs": 4, "timestep": 6048, "ep_reward": 27.693790435791016, "reward": 0.4466642141342163, "action": -1.1562236547470093}
{"mode": "train", "epochs": 4, "timestep": 6049, "ep_reward": 28.235816955566406, "reward": 0.5420262813568115, "action": -1.0337103605270386}
{"mode": "train", "epochs": 4, "timestep": 6050, "ep_reward": 28.86665916442871, "reward": 0.6308425068855286, "action": -0.4387550354003906}
{"mode": "train", "epochs": 4, "timestep": 6051, "ep_reward": 29.57857894897461, "reward": 0.7119191884994507, "action": -0.39923834800720215}
{"mode": "train", "epochs": 4, "timestep": 6052, "ep_reward": 30.356599807739258, "reward": 0.7780200839042664, "action": -1.119661808013916}
{"mode": "train", "epochs": 4, "timestep": 6053, "ep_reward": 31.182973861694336, "reward": 0.8263744115829468, "action": -0.6605201959609985}
{"mode": "train", "epochs": 4, "timestep": 6054, "ep_reward": 32.04735565185547, "reward": 0.8643814921379089, "action": -1.3204182386398315}
{"mode": "train", "epochs": 4, "timestep": 6055, "ep_reward": 32.93705749511719, "reward": 0.8897018432617188, "action": -0.7583318948745728}
{"mode": "train", "epochs": 4, "timestep": 6056, "ep_reward": 33.8443489074707, "reward": 0.9072895646095276, "action": -0.3730012774467468}
{"mode": "train", "epochs": 4, "timestep": 6057, "ep_reward": 34.76011276245117, "reward": 0.9157634973526001, "action": -1.2256395816802979}
{"mode": "train", "epochs": 4, "timestep": 6058, "ep_reward": 35.676116943359375, "reward": 0.91600501537323, "action": -0.3060618042945862}
{"mode": "train", "epochs": 4, "timestep": 6059, "ep_reward": 36.5831413269043, "reward": 0.9070229530334473, "action": 1.131547451019287}
{"mode": "train", "epochs": 4, "timestep": 6060, "ep_reward": 37.46494674682617, "reward": 0.8818063735961914, "action": -0.5599335432052612}
{"mode": "train", "epochs": 4, "timestep": 6061, "ep_reward": 38.31270217895508, "reward": 0.8477540612220764, "action": 0.8249896168708801}
{"mode": "train", "epochs": 4, "timestep": 6062, "ep_reward": 39.103145599365234, "reward": 0.790442705154419, "action": 0.12326113879680634}
{"mode": "train", "epochs": 4, "timestep": 6063, "ep_reward": 39.82025146484375, "reward": 0.7171050310134888, "action": -0.25946420431137085}
{"mode": "train", "epochs": 4, "timestep": 6064, "ep_reward": 40.44731140136719, "reward": 0.6270591020584106, "action": 0.23848408460617065}
{"mode": "train", "epochs": 4, "timestep": 6065, "ep_reward": 40.959693908691406, "reward": 0.5123843550682068, "action": -1.2131038904190063}
{"mode": "train", "epochs": 4, "timestep": 6066, "ep_reward": 41.35908889770508, "reward": 0.39939600229263306, "action": -0.21786779165267944}
{"mode": "train", "epochs": 4, "timestep": 6067, "ep_reward": 41.62616729736328, "reward": 0.26707834005355835, "action": -1.6545519828796387}
{"mode": "train", "epochs": 4, "timestep": 6068, "ep_reward": 41.78081130981445, "reward": 0.1546441912651062, "action": -1.1680681705474854}
{"mode": "train", "epochs": 4, "timestep": 6069, "ep_reward": 42.0502815246582, "reward": 0.26946860551834106, "action": -1.3640022277832031}
{"mode": "train", "epochs": 4, "timestep": 6070, "ep_reward": 42.44345474243164, "reward": 0.3931733965873718, "action": -0.7828264832496643}
{"mode": "train", "epochs": 4, "timestep": 6071, "ep_reward": 42.94743347167969, "reward": 0.50397789478302, "action": -1.0875396728515625}
{"mode": "train", "epochs": 4, "timestep": 6072, "ep_reward": 43.552330017089844, "reward": 0.6048975586891174, "action": 0.567737340927124}
{"mode": "train", "epochs": 4, "timestep": 6073, "ep_reward": 44.23236083984375, "reward": 0.6800298690795898, "action": 1.5792925357818604}
{"mode": "train", "epochs": 4, "timestep": 6074, "ep_reward": 44.97071075439453, "reward": 0.7383497953414917, "action": 1.1762237548828125}
{"mode": "train", "epochs": 4, "timestep": 6075, "ep_reward": 45.758853912353516, "reward": 0.7881437540054321, "action": 1.0529861450195312}
{"mode": "train", "epochs": 4, "timestep": 6076, "ep_reward": 46.585777282714844, "reward": 0.8269215226173401, "action": 1.3634538650512695}
{"mode": "train", "epochs": 4, "timestep": 6077, "ep_reward": 47.44002914428711, "reward": 0.8542529940605164, "action": 1.0381975173950195}
{"mode": "train", "epochs": 4, "timestep": 6078, "ep_reward": 48.312591552734375, "reward": 0.872562050819397, "action": 0.7946537733078003}
{"mode": "train", "epochs": 4, "timestep": 6079, "ep_reward": 49.19364547729492, "reward": 0.8810553550720215, "action": 1.2070858478546143}
{"mode": "train", "epochs": 4, "timestep": 6080, "ep_reward": 50.0738525390625, "reward": 0.8802089095115662, "action": 1.1043446063995361}
{"mode": "train", "epochs": 4, "timestep": 6081, "ep_reward": 50.94418716430664, "reward": 0.8703338503837585, "action": -1.0079079866409302}
{"mode": "train", "epochs": 4, "timestep": 6082, "ep_reward": 51.786224365234375, "reward": 0.8420355916023254, "action": 0.27222466468811035}
{"mode": "train", "epochs": 4, "timestep": 6083, "ep_reward": 52.58754348754883, "reward": 0.8013174533843994, "action": -1.4667282104492188}
{"mode": "train", "epochs": 4, "timestep": 6084, "ep_reward": 53.31928634643555, "reward": 0.7317414283752441, "action": -0.800044059753418}
{"mode": "train", "epochs": 4, "timestep": 6085, "ep_reward": 53.9616813659668, "reward": 0.6423936486244202, "action": -1.6627368927001953}
{"mode": "train", "epochs": 4, "timestep": 6086, "ep_reward": 54.482261657714844, "reward": 0.5205807685852051, "action": -1.6517384052276611}
{"mode": "train", "epochs": 4, "timestep": 6087, "ep_reward": 54.85658264160156, "reward": 0.37432247400283813, "action": -1.063535213470459}
{"mode": "train", "epochs": 4, "timestep": 6088, "ep_reward": 55.07547378540039, "reward": 0.2188907265663147, "action": -0.5095506906509399}
{"mode": "train", "epochs": 4, "timestep": 6089, "ep_reward": 55.1976203918457, "reward": 0.12214481830596924, "action": -0.7534189224243164}
{"mode": "train", "epochs": 4, "timestep": 6090, "ep_reward": 55.438819885253906, "reward": 0.24119937419891357, "action": -0.7996222376823425}
{"mode": "train", "epochs": 4, "timestep": 6091, "ep_reward": 55.80205154418945, "reward": 0.3632311224937439, "action": -1.4490492343902588}
{"mode": "train", "epochs": 4, "timestep": 6092, "ep_reward": 56.27830505371094, "reward": 0.4762539267539978, "action": -0.9525929689407349}
{"mode": "train", "epochs": 4, "timestep": 6093, "ep_reward": 56.86453628540039, "reward": 0.5862320065498352, "action": -1.2867209911346436}
{"mode": "train", "epochs": 4, "timestep": 6094, "ep_reward": 57.54353332519531, "reward": 0.6789978742599487, "action": -0.6709296703338623}
{"mode": "train", "epochs": 4, "timestep": 6095, "ep_reward": 58.30390930175781, "reward": 0.7603754997253418, "action": -1.1890476942062378}
{"mode": "train", "epochs": 4, "timestep": 6096, "ep_reward": 59.124549865722656, "reward": 0.8206405639648438, "action": -1.2196528911590576}
{"mode": "train", "epochs": 4, "timestep": 6097, "ep_reward": 59.990882873535156, "reward": 0.8663316965103149, "action": -1.5747809410095215}
{"mode": "train", "epochs": 4, "timestep": 6098, "ep_reward": 60.88904571533203, "reward": 0.8981646299362183, "action": -1.9706001281738281}
{"mode": "train", "epochs": 4, "timestep": 6099, "ep_reward": 61.80815124511719, "reward": 0.9191044569015503, "action": -1.0163772106170654}
{"mode": "train", "epochs": 4, "timestep": 6100, "ep_reward": 62.745628356933594, "reward": 0.9374760389328003, "action": -1.0164293050765991}
{"mode": "train", "epochs": 4, "timestep": 6101, "ep_reward": 63.69468688964844, "reward": 0.9490598440170288, "action": -1.2895007133483887}
{"mode": "train", "epochs": 4, "timestep": 6102, "ep_reward": 64.64844512939453, "reward": 0.9537609815597534, "action": -0.21550333499908447}
{"mode": "train", "epochs": 4, "timestep": 6103, "ep_reward": 65.60659790039062, "reward": 0.9581493139266968, "action": -0.7847194671630859}
{"mode": "train", "epochs": 4, "timestep": 6104, "ep_reward": 66.56101989746094, "reward": 0.954425036907196, "action": -1.0060948133468628}
{"mode": "train", "epochs": 4, "timestep": 6105, "ep_reward": 67.50431823730469, "reward": 0.9432966113090515, "action": -0.9248723387718201}
{"mode": "train", "epochs": 4, "timestep": 6106, "ep_reward": 68.4286117553711, "reward": 0.9242955446243286, "action": -0.7662321329116821}
{"mode": "train", "epochs": 4, "timestep": 6107, "ep_reward": 69.32377624511719, "reward": 0.8951666951179504, "action": -0.25056809186935425}
{"mode": "train", "epochs": 4, "timestep": 6108, "ep_reward": 70.17908477783203, "reward": 0.8553051948547363, "action": -0.6082720756530762}
{"mode": "train", "epochs": 4, "timestep": 6109, "ep_reward": 70.97273254394531, "reward": 0.7936486601829529, "action": -0.8539894819259644}
{"mode": "train", "epochs": 4, "timestep": 6110, "ep_reward": 71.67683410644531, "reward": 0.7041002511978149, "action": -0.596137285232544}
{"mode": "train", "epochs": 4, "timestep": 6111, "ep_reward": 72.26302337646484, "reward": 0.586187481880188, "action": -0.8879417777061462}
{"mode": "train", "epochs": 4, "timestep": 6112, "ep_reward": 72.693603515625, "reward": 0.4305781126022339, "action": -1.2782152891159058}
{"mode": "train", "epochs": 4, "timestep": 6113, "ep_reward": 72.93854522705078, "reward": 0.244939923286438, "action": -1.1424872875213623}
{"mode": "train", "epochs": 4, "timestep": 6114, "ep_reward": 73.0542984008789, "reward": 0.11575502157211304, "action": -1.3052890300750732}
{"mode": "train", "epochs": 4, "timestep": 6115, "ep_reward": 73.05359649658203, "reward": -0.0007054805755615234, "action": -1.1788206100463867}
{"mode": "train", "epochs": 4, "timestep": 6116, "ep_reward": 73.19791412353516, "reward": 0.14431411027908325, "action": -1.0303740501403809}
{"mode": "train", "epochs": 4, "timestep": 6117, "ep_reward": 73.4813003540039, "reward": 0.2833843231201172, "action": -0.7137483358383179}
{"mode": "train", "epochs": 4, "timestep": 6118, "ep_reward": 73.90533447265625, "reward": 0.42403095960617065, "action": -0.7839499711990356}
{"mode": "train", "epochs": 4, "timestep": 6119, "ep_reward": 74.45613098144531, "reward": 0.5508002042770386, "action": -1.3676202297210693}
{"mode": "train", "epochs": 4, "timestep": 6120, "ep_reward": 75.10792541503906, "reward": 0.6517938375473022, "action": -0.3448660969734192}
{"mode": "train", "epochs": 4, "timestep": 6121, "ep_reward": 75.8492431640625, "reward": 0.7413151264190674, "action": -0.4482666850090027}
{"mode": "train", "epochs": 4, "timestep": 6122, "ep_reward": 76.65574645996094, "reward": 0.8064994812011719, "action": -1.023499608039856}
{"mode": "train", "epochs": 4, "timestep": 6123, "ep_reward": 77.50265502929688, "reward": 0.8469101190567017, "action": -1.2304247617721558}
{"mode": "train", "epochs": 4, "timestep": 6124, "ep_reward": 78.3719253540039, "reward": 0.8692734241485596, "action": -0.37188470363616943}
{"mode": "train", "epochs": 4, "timestep": 6125, "ep_reward": 79.25524139404297, "reward": 0.8833147287368774, "action": -1.4137276411056519}
{"mode": "train", "epochs": 4, "timestep": 6126, "ep_reward": 80.12950134277344, "reward": 0.8742611408233643, "action": -1.4638179540634155}
{"mode": "train", "epochs": 4, "timestep": 6127, "ep_reward": 80.97735595703125, "reward": 0.8478545546531677, "action": 0.017898917198181152}
{"mode": "train", "epochs": 4, "timestep": 6128, "ep_reward": 81.79218292236328, "reward": 0.8148239850997925, "action": -1.0594369173049927}
{"mode": "train", "epochs": 4, "timestep": 6129, "ep_reward": 82.53923797607422, "reward": 0.747055172920227, "action": -0.8506015539169312}
{"mode": "train", "epochs": 4, "timestep": 6130, "ep_reward": 83.18896484375, "reward": 0.6497289538383484, "action": -0.7364931106567383}
{"mode": "train", "epochs": 4, "timestep": 6131, "ep_reward": 83.7054214477539, "reward": 0.5164592862129211, "action": -0.7481799125671387}
{"mode": "train", "epochs": 4, "timestep": 6132, "ep_reward": 84.05652618408203, "reward": 0.35110777616500854, "action": -0.4488986134529114}
{"mode": "train", "epochs": 4, "timestep": 6133, "ep_reward": 84.29773712158203, "reward": 0.2412099838256836, "action": -1.4682667255401611}
{"mode": "train", "epochs": 4, "timestep": 6134, "ep_reward": 84.40919494628906, "reward": 0.11146056652069092, "action": -1.318636417388916}
{"mode": "train", "epochs": 4, "timestep": 6135, "ep_reward": 84.41329193115234, "reward": 0.004099130630493164, "action": -0.831209123134613}
{"mode": "train", "epochs": 4, "timestep": 6136, "ep_reward": 84.56182098388672, "reward": 0.14852577447891235, "action": 0.07045364379882812}
{"mode": "train", "epochs": 4, "timestep": 6137, "ep_reward": 84.86300659179688, "reward": 0.30118197202682495, "action": -1.1317288875579834}
{"mode": "train", "epochs": 4, "timestep": 6138, "ep_reward": 85.29681396484375, "reward": 0.43380671739578247, "action": -1.2311245203018188}
{"mode": "train", "epochs": 4, "timestep": 6139, "ep_reward": 85.85065460205078, "reward": 0.5538384914398193, "action": -0.820488452911377}
{"mode": "train", "epochs": 4, "timestep": 6140, "ep_reward": 86.51055145263672, "reward": 0.6598999500274658, "action": -0.6212036609649658}
{"mode": "train", "epochs": 4, "timestep": 6141, "ep_reward": 87.25597381591797, "reward": 0.7454192638397217, "action": -1.2097697257995605}
{"mode": "train", "epochs": 4, "timestep": 6142, "ep_reward": 88.05984497070312, "reward": 0.8038748502731323, "action": -1.0216810703277588}
{"mode": "train", "epochs": 4, "timestep": 6143, "ep_reward": 88.90509796142578, "reward": 0.8452528715133667, "action": -1.429124116897583}
{"mode": "train", "epochs": 4, "timestep": 6144, "ep_reward": 89.77201080322266, "reward": 0.8669102191925049, "action": 0.6199804544448853}
{"mode": "train", "epochs": 4, "timestep": 6145, "ep_reward": 90.66162109375, "reward": 0.8896080255508423, "action": -1.6394193172454834}
{"mode": "train", "epochs": 4, "timestep": 6146, "ep_reward": 91.54199981689453, "reward": 0.8803751468658447, "action": -0.8037182688713074}
{"mode": "train", "epochs": 4, "timestep": 6147, "ep_reward": 92.40415954589844, "reward": 0.8621626496315002, "action": -0.13540196418762207}
{"mode": "train", "epochs": 4, "timestep": 6148, "ep_reward": 93.2359848022461, "reward": 0.8318217992782593, "action": -0.9783975481987}
{"mode": "train", "epochs": 4, "timestep": 6149, "ep_reward": 94.00736999511719, "reward": 0.7713814973831177, "action": -0.7149848937988281}
{"mode": "train", "epochs": 4, "timestep": 6150, "ep_reward": 94.69171905517578, "reward": 0.6843478679656982, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6151, "ep_reward": 95.23589324951172, "reward": 0.5441739559173584, "action": -1.122981071472168}
{"mode": "train", "epochs": 4, "timestep": 6152, "ep_reward": 95.60824584960938, "reward": 0.37235158681869507, "action": -0.3191000819206238}
{"mode": "train", "epochs": 4, "timestep": 6153, "ep_reward": 95.87330627441406, "reward": 0.26505887508392334, "action": -0.7322883009910583}
{"mode": "train", "epochs": 4, "timestep": 6154, "ep_reward": 96.01264953613281, "reward": 0.13934624195098877, "action": -0.2464766502380371}
{"mode": "train", "epochs": 4, "timestep": 6155, "ep_reward": 96.00624084472656, "reward": -0.006408810615539551, "action": -0.516637921333313}
{"mode": "train", "epochs": 4, "timestep": 6156, "ep_reward": 96.127197265625, "reward": 0.12095880508422852, "action": -0.9802811741828918}
{"mode": "train", "epochs": 4, "timestep": 6157, "ep_reward": 96.3871078491211, "reward": 0.2599090337753296, "action": -1.776587724685669}
{"mode": "train", "epochs": 4, "timestep": 6158, "ep_reward": 96.77570343017578, "reward": 0.38859426975250244, "action": -1.379589319229126}
{"mode": "train", "epochs": 4, "timestep": 6159, "ep_reward": 97.28944396972656, "reward": 0.5137412548065186, "action": -0.40501588582992554}
{"mode": "train", "epochs": 4, "timestep": 6160, "ep_reward": 97.92106628417969, "reward": 0.6316238641738892, "action": -1.1266602277755737}
{"mode": "train", "epochs": 4, "timestep": 6161, "ep_reward": 98.6386489868164, "reward": 0.7175827622413635, "action": -1.103489637374878}
{"mode": "train", "epochs": 4, "timestep": 6162, "ep_reward": 99.41967010498047, "reward": 0.7810225486755371, "action": -1.0672876834869385}
{"mode": "train", "epochs": 4, "timestep": 6163, "ep_reward": 100.24340057373047, "reward": 0.8237320184707642, "action": -0.43185198307037354}
{"mode": "train", "epochs": 4, "timestep": 6164, "ep_reward": 101.09620666503906, "reward": 0.8528041839599609, "action": -0.861393392086029}
{"mode": "train", "epochs": 4, "timestep": 6165, "ep_reward": 101.95653533935547, "reward": 0.8603321313858032, "action": -1.224944829940796}
{"mode": "train", "epochs": 4, "timestep": 6166, "ep_reward": 102.80351257324219, "reward": 0.8469747304916382, "action": -0.8371478915214539}
{"mode": "train", "epochs": 4, "timestep": 6167, "ep_reward": 103.62044525146484, "reward": 0.8169354796409607, "action": 0.16029596328735352}
{"mode": "train", "epochs": 4, "timestep": 6168, "ep_reward": 104.39398956298828, "reward": 0.7735435962677002, "action": -1.0029449462890625}
{"mode": "train", "epochs": 4, "timestep": 6169, "ep_reward": 105.08331298828125, "reward": 0.6893212795257568, "action": -0.6280007362365723}
{"mode": "train", "epochs": 4, "timestep": 6170, "ep_reward": 105.6570053100586, "reward": 0.5736939311027527, "action": -0.502800464630127}
{"mode": "train", "epochs": 4, "timestep": 6171, "ep_reward": 106.07756805419922, "reward": 0.4205629229545593, "action": -1.210860013961792}
{"mode": "train", "epochs": 4, "timestep": 6172, "ep_reward": 106.37350463867188, "reward": 0.29593390226364136, "action": -1.2781153917312622}
{"mode": "train", "epochs": 4, "timestep": 6173, "ep_reward": 106.5491943359375, "reward": 0.17569255828857422, "action": -1.1150989532470703}
{"mode": "train", "epochs": 4, "timestep": 6174, "ep_reward": 106.58460235595703, "reward": 0.035410523414611816, "action": -1.226917028427124}
{"mode": "train", "epochs": 4, "timestep": 6175, "ep_reward": 106.66693878173828, "reward": 0.0823366641998291, "action": -0.6932112574577332}
{"mode": "train", "epochs": 4, "timestep": 6176, "ep_reward": 106.8907699584961, "reward": 0.22383040189743042, "action": -1.3350954055786133}
{"mode": "train", "epochs": 4, "timestep": 6177, "ep_reward": 107.24919128417969, "reward": 0.3584228754043579, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6178, "ep_reward": 107.72781372070312, "reward": 0.4786248803138733, "action": -0.5517634749412537}
{"mode": "train", "epochs": 4, "timestep": 6179, "ep_reward": 108.32882690429688, "reward": 0.6010165214538574, "action": -0.9896987080574036}
{"mode": "train", "epochs": 4, "timestep": 6180, "ep_reward": 109.02400207519531, "reward": 0.6951786279678345, "action": -1.5316663980484009}
{"mode": "train", "epochs": 4, "timestep": 6181, "ep_reward": 109.78494262695312, "reward": 0.7609398365020752, "action": -0.9116134643554688}
{"mode": "train", "epochs": 4, "timestep": 6182, "ep_reward": 110.59612274169922, "reward": 0.811180591583252, "action": -0.6797606348991394}
{"mode": "train", "epochs": 4, "timestep": 6183, "ep_reward": 111.43938446044922, "reward": 0.8432624340057373, "action": -0.619673490524292}
{"mode": "train", "epochs": 4, "timestep": 6184, "ep_reward": 112.29666137695312, "reward": 0.8572794795036316, "action": -1.6535354852676392}
{"mode": "train", "epochs": 4, "timestep": 6185, "ep_reward": 113.14089965820312, "reward": 0.8442389369010925, "action": -0.677476167678833}
{"mode": "train", "epochs": 4, "timestep": 6186, "ep_reward": 113.9606704711914, "reward": 0.8197725415229797, "action": -0.6350576281547546}
{"mode": "train", "epochs": 4, "timestep": 6187, "ep_reward": 114.73258209228516, "reward": 0.771909236907959, "action": -1.775329351425171}
{"mode": "train", "epochs": 4, "timestep": 6188, "ep_reward": 115.41342163085938, "reward": 0.6808418035507202, "action": -0.9097744226455688}
{"mode": "train", "epochs": 4, "timestep": 6189, "ep_reward": 115.97454833984375, "reward": 0.5611233711242676, "action": -0.8959001302719116}
{"mode": "train", "epochs": 4, "timestep": 6190, "ep_reward": 116.37476348876953, "reward": 0.40021294355392456, "action": -1.047254204750061}
{"mode": "train", "epochs": 4, "timestep": 6191, "ep_reward": 116.67560577392578, "reward": 0.3008396029472351, "action": -0.9933089017868042}
{"mode": "train", "epochs": 4, "timestep": 6192, "ep_reward": 116.85710906982422, "reward": 0.18150120973587036, "action": -0.563003420829773}
{"mode": "train", "epochs": 4, "timestep": 6193, "ep_reward": 116.89924621582031, "reward": 0.04213613271713257, "action": -0.2634381055831909}
{"mode": "train", "epochs": 4, "timestep": 6194, "ep_reward": 116.97514343261719, "reward": 0.07589888572692871, "action": -1.0997544527053833}
{"mode": "train", "epochs": 4, "timestep": 6195, "ep_reward": 117.18730163574219, "reward": 0.21216058731079102, "action": -1.1572190523147583}
{"mode": "train", "epochs": 4, "timestep": 6196, "ep_reward": 117.53763580322266, "reward": 0.3503327965736389, "action": -0.9106166362762451}
{"mode": "train", "epochs": 4, "timestep": 6197, "ep_reward": 118.02207946777344, "reward": 0.48444390296936035, "action": -0.37902218103408813}
{"mode": "train", "epochs": 4, "timestep": 6198, "ep_reward": 118.62948608398438, "reward": 0.6074057817459106, "action": -1.3976290225982666}
{"mode": "train", "epochs": 4, "timestep": 6199, "ep_reward": 119.3262710571289, "reward": 0.6967856884002686, "action": -1.0615708827972412}
{"mode": "train", "epochs": 4, "timestep": 6200, "ep_reward": 120.09386444091797, "reward": 0.7675963640213013, "action": -1.4760956764221191}
{"mode": "train", "epochs": 4, "timestep": 6201, "ep_reward": 120.90750885009766, "reward": 0.8136475086212158, "action": -0.6524075865745544}
{"mode": "train", "epochs": 4, "timestep": 6202, "ep_reward": 121.75534057617188, "reward": 0.8478302955627441, "action": -1.8365705013275146}
{"mode": "train", "epochs": 4, "timestep": 6203, "ep_reward": 122.60962677001953, "reward": 0.8542852401733398, "action": -0.8486326932907104}
{"mode": "train", "epochs": 4, "timestep": 6204, "ep_reward": 123.4613037109375, "reward": 0.8516806364059448, "action": -0.7588188648223877}
{"mode": "train", "epochs": 4, "timestep": 6205, "ep_reward": 124.29198455810547, "reward": 0.8306790590286255, "action": -1.1839326620101929}
{"mode": "train", "epochs": 4, "timestep": 6206, "ep_reward": 125.0747299194336, "reward": 0.7827435731887817, "action": -0.562741219997406}
{"mode": "train", "epochs": 4, "timestep": 6207, "ep_reward": 125.78759765625, "reward": 0.7128698825836182, "action": -1.2767475843429565}
{"mode": "train", "epochs": 4, "timestep": 6208, "ep_reward": 126.38689422607422, "reward": 0.5992982387542725, "action": -1.1950173377990723}
{"mode": "train", "epochs": 4, "timestep": 6209, "ep_reward": 126.83084869384766, "reward": 0.4439513683319092, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6210, "ep_reward": 127.15760040283203, "reward": 0.32675468921661377, "action": -1.146481990814209}
{"mode": "train", "epochs": 4, "timestep": 6211, "ep_reward": 127.36976623535156, "reward": 0.21216273307800293, "action": -1.5153586864471436}
{"mode": "train", "epochs": 4, "timestep": 6212, "ep_reward": 127.44744110107422, "reward": 0.07767671346664429, "action": -1.2577872276306152}
{"mode": "train", "epochs": 4, "timestep": 6213, "ep_reward": 127.48758697509766, "reward": 0.0401458740234375, "action": -1.4597790241241455}
{"mode": "train", "epochs": 4, "timestep": 6214, "ep_reward": 127.66724395751953, "reward": 0.17965853214263916, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6215, "ep_reward": 127.9745864868164, "reward": 0.30734533071517944, "action": -0.6339102983474731}
{"mode": "train", "epochs": 4, "timestep": 6216, "ep_reward": 128.42393493652344, "reward": 0.4493526816368103, "action": -0.9956101775169373}
{"mode": "train", "epochs": 4, "timestep": 6217, "ep_reward": 128.99514770507812, "reward": 0.571212649345398, "action": -0.4469989538192749}
{"mode": "train", "epochs": 4, "timestep": 6218, "ep_reward": 129.67259216308594, "reward": 0.6774492263793945, "action": -0.5972702503204346}
{"mode": "train", "epochs": 4, "timestep": 6219, "ep_reward": 130.4301300048828, "reward": 0.7575342655181885, "action": -0.3255229592323303}
{"mode": "train", "epochs": 4, "timestep": 6220, "ep_reward": 131.2474822998047, "reward": 0.8173575401306152, "action": -0.2124202847480774}
{"mode": "train", "epochs": 4, "timestep": 6221, "ep_reward": 132.1055450439453, "reward": 0.858065128326416, "action": -0.5636682510375977}
{"mode": "train", "epochs": 4, "timestep": 6222, "ep_reward": 132.9846649169922, "reward": 0.8791199922561646, "action": -0.7146040201187134}
{"mode": "train", "epochs": 4, "timestep": 6223, "ep_reward": 133.86886596679688, "reward": 0.8841965198516846, "action": -1.542318344116211}
{"mode": "train", "epochs": 4, "timestep": 6224, "ep_reward": 134.73655700683594, "reward": 0.8676921129226685, "action": -1.0293242931365967}
{"mode": "train", "epochs": 4, "timestep": 6225, "ep_reward": 135.57408142089844, "reward": 0.8375319242477417, "action": -0.1468874216079712}
{"mode": "train", "epochs": 4, "timestep": 6226, "ep_reward": 136.3683624267578, "reward": 0.7942830920219421, "action": -1.1817160844802856}
{"mode": "train", "epochs": 4, "timestep": 6227, "ep_reward": 137.08216857910156, "reward": 0.7138071060180664, "action": -0.9059053659439087}
{"mode": "train", "epochs": 4, "timestep": 6228, "ep_reward": 137.68382263183594, "reward": 0.6016501188278198, "action": -1.5626181364059448}
{"mode": "train", "epochs": 4, "timestep": 6229, "ep_reward": 138.1235809326172, "reward": 0.43975740671157837, "action": -0.5110528469085693}
{"mode": "train", "epochs": 4, "timestep": 6230, "ep_reward": 138.43312072753906, "reward": 0.3095390200614929, "action": -1.7346556186676025}
{"mode": "train", "epochs": 4, "timestep": 6231, "ep_reward": 138.6250457763672, "reward": 0.1919211745262146, "action": -0.9076045751571655}
{"mode": "train", "epochs": 4, "timestep": 6232, "ep_reward": 138.67916870117188, "reward": 0.054116129875183105, "action": -1.2772002220153809}
{"mode": "train", "epochs": 4, "timestep": 6233, "ep_reward": 138.7432403564453, "reward": 0.06407564878463745, "action": -1.0049703121185303}
{"mode": "train", "epochs": 4, "timestep": 6234, "ep_reward": 138.94442749023438, "reward": 0.2011893391609192, "action": -0.81648850440979}
{"mode": "train", "epochs": 4, "timestep": 6235, "ep_reward": 139.28797912597656, "reward": 0.3435521721839905, "action": -1.5364561080932617}
{"mode": "train", "epochs": 4, "timestep": 6236, "ep_reward": 139.75831604003906, "reward": 0.47033292055130005, "action": -0.9782038331031799}
{"mode": "train", "epochs": 4, "timestep": 6237, "ep_reward": 140.3474578857422, "reward": 0.5891391038894653, "action": -0.7022075057029724}
{"mode": "train", "epochs": 4, "timestep": 6238, "ep_reward": 141.0364227294922, "reward": 0.688971757888794, "action": -1.2987060546875}
{"mode": "train", "epochs": 4, "timestep": 6239, "ep_reward": 141.79583740234375, "reward": 0.7594072818756104, "action": -0.5834407806396484}
{"mode": "train", "epochs": 4, "timestep": 6240, "ep_reward": 142.61080932617188, "reward": 0.8149749040603638, "action": -0.8142334818840027}
{"mode": "train", "epochs": 4, "timestep": 6241, "ep_reward": 143.45928955078125, "reward": 0.8484804630279541, "action": -1.4392000436782837}
{"mode": "train", "epochs": 4, "timestep": 6242, "ep_reward": 144.31863403320312, "reward": 0.8593406081199646, "action": -0.7826594114303589}
{"mode": "train", "epochs": 4, "timestep": 6243, "ep_reward": 145.17735290527344, "reward": 0.8587230443954468, "action": -1.4270882606506348}
{"mode": "train", "epochs": 4, "timestep": 6244, "ep_reward": 146.01116943359375, "reward": 0.833824098110199, "action": -1.073938250541687}
{"mode": "train", "epochs": 4, "timestep": 6245, "ep_reward": 146.8006591796875, "reward": 0.7894851565361023, "action": -1.161273717880249}
{"mode": "train", "epochs": 4, "timestep": 6246, "ep_reward": 147.51644897460938, "reward": 0.7157955765724182, "action": -0.620974600315094}
{"mode": "train", "epochs": 4, "timestep": 6247, "ep_reward": 148.13011169433594, "reward": 0.6136687397956848, "action": -0.21959102153778076}
{"mode": "train", "epochs": 4, "timestep": 6248, "ep_reward": 148.6085662841797, "reward": 0.47844845056533813, "action": -0.9809956550598145}
{"mode": "train", "epochs": 4, "timestep": 6249, "ep_reward": 148.94735717773438, "reward": 0.338797390460968, "action": -1.2569845914840698}
{"mode": "train", "epochs": 4, "timestep": 6250, "ep_reward": 149.17401123046875, "reward": 0.2266492247581482, "action": -0.8935420513153076}
{"mode": "train", "epochs": 4, "timestep": 6251, "ep_reward": 149.26844787597656, "reward": 0.09444087743759155, "action": -0.9878218770027161}
{"mode": "train", "epochs": 4, "timestep": 6252, "ep_reward": 149.29110717773438, "reward": 0.0226590633392334, "action": -0.6523264646530151}
{"mode": "train", "epochs": 4, "timestep": 6253, "ep_reward": 149.45574951171875, "reward": 0.16464722156524658, "action": -0.14530068635940552}
{"mode": "train", "epochs": 4, "timestep": 6254, "ep_reward": 149.7707977294922, "reward": 0.3150444030761719, "action": -0.4348835349082947}
{"mode": "train", "epochs": 4, "timestep": 6255, "ep_reward": 150.22621154785156, "reward": 0.45540767908096313, "action": -1.3965109586715698}
{"mode": "train", "epochs": 4, "timestep": 6256, "ep_reward": 150.79684448242188, "reward": 0.5706314444541931, "action": -0.03340822458267212}
{"mode": "train", "epochs": 4, "timestep": 6257, "ep_reward": 151.47816467285156, "reward": 0.681318998336792, "action": -0.9270177483558655}
{"mode": "train", "epochs": 4, "timestep": 6258, "ep_reward": 152.23789978027344, "reward": 0.7597360610961914, "action": -0.6652563214302063}
{"mode": "train", "epochs": 4, "timestep": 6259, "ep_reward": 153.057861328125, "reward": 0.8199567794799805, "action": -0.7828071117401123}
{"mode": "train", "epochs": 4, "timestep": 6260, "ep_reward": 153.91883850097656, "reward": 0.8609806299209595, "action": -1.25115168094635}
{"mode": "train", "epochs": 4, "timestep": 6261, "ep_reward": 154.80230712890625, "reward": 0.8834667205810547, "action": -0.47388410568237305}
{"mode": "train", "epochs": 4, "timestep": 6262, "ep_reward": 155.70077514648438, "reward": 0.898470938205719, "action": -0.7801223397254944}
{"mode": "train", "epochs": 4, "timestep": 6263, "ep_reward": 156.5994873046875, "reward": 0.8987046480178833, "action": -0.45831501483917236}
{"mode": "train", "epochs": 4, "timestep": 6264, "ep_reward": 157.48788452148438, "reward": 0.8883914947509766, "action": -1.0551519393920898}
{"mode": "train", "epochs": 4, "timestep": 6265, "ep_reward": 158.34613037109375, "reward": 0.8582499027252197, "action": -1.2717310190200806}
{"mode": "train", "epochs": 4, "timestep": 6266, "ep_reward": 159.15219116210938, "reward": 0.8060625791549683, "action": -1.14811372756958}
{"mode": "train", "epochs": 4, "timestep": 6267, "ep_reward": 159.8804168701172, "reward": 0.7282199859619141, "action": -1.608858585357666}
{"mode": "train", "epochs": 4, "timestep": 6268, "ep_reward": 160.49090576171875, "reward": 0.6104880571365356, "action": -1.0781285762786865}
{"mode": "train", "epochs": 4, "timestep": 6269, "ep_reward": 160.9495849609375, "reward": 0.45867735147476196, "action": -0.8335458040237427}
{"mode": "train", "epochs": 4, "timestep": 6270, "ep_reward": 161.26339721679688, "reward": 0.3138127326965332, "action": -1.2181214094161987}
{"mode": "train", "epochs": 4, "timestep": 6271, "ep_reward": 161.4602813720703, "reward": 0.19688576459884644, "action": -0.8348692655563354}
{"mode": "train", "epochs": 4, "timestep": 6272, "ep_reward": 161.52023315429688, "reward": 0.05994993448257446, "action": -0.22463440895080566}
{"mode": "train", "epochs": 4, "timestep": 6273, "ep_reward": 161.57858276367188, "reward": 0.058347463607788086, "action": -1.120332956314087}
{"mode": "train", "epochs": 4, "timestep": 6274, "ep_reward": 161.7740478515625, "reward": 0.19546473026275635, "action": -1.5239863395690918}
{"mode": "train", "epochs": 4, "timestep": 6275, "ep_reward": 162.1033477783203, "reward": 0.3292936682701111, "action": -0.6405989527702332}
{"mode": "train", "epochs": 4, "timestep": 6276, "ep_reward": 162.57225036621094, "reward": 0.4689072370529175, "action": -0.8657580614089966}
{"mode": "train", "epochs": 4, "timestep": 6277, "ep_reward": 163.16134643554688, "reward": 0.5890904664993286, "action": -0.9742856025695801}
{"mode": "train", "epochs": 4, "timestep": 6278, "ep_reward": 163.84768676757812, "reward": 0.6863418221473694, "action": -0.7926833629608154}
{"mode": "train", "epochs": 4, "timestep": 6279, "ep_reward": 164.6099090576172, "reward": 0.7622277140617371, "action": -1.1143999099731445}
{"mode": "train", "epochs": 4, "timestep": 6280, "ep_reward": 165.4229736328125, "reward": 0.8130687475204468, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6281, "ep_reward": 166.26016235351562, "reward": 0.8371949195861816, "action": -1.6068968772888184}
{"mode": "train", "epochs": 4, "timestep": 6282, "ep_reward": 167.1071319580078, "reward": 0.8469738960266113, "action": -1.3511983156204224}
{"mode": "train", "epochs": 4, "timestep": 6283, "ep_reward": 167.94741821289062, "reward": 0.8402840495109558, "action": -1.4590089321136475}
{"mode": "train", "epochs": 4, "timestep": 6284, "ep_reward": 168.75889587402344, "reward": 0.8114815354347229, "action": -0.5604509115219116}
{"mode": "train", "epochs": 4, "timestep": 6285, "ep_reward": 169.5255584716797, "reward": 0.7666692733764648, "action": -0.7438544034957886}
{"mode": "train", "epochs": 4, "timestep": 6286, "ep_reward": 170.21556091308594, "reward": 0.6899998188018799, "action": -0.6113830208778381}
{"mode": "train", "epochs": 4, "timestep": 6287, "ep_reward": 170.79421997070312, "reward": 0.5786514282226562, "action": -1.1100547313690186}
{"mode": "train", "epochs": 4, "timestep": 6288, "ep_reward": 171.21263122558594, "reward": 0.41841763257980347, "action": -1.4469923973083496}
{"mode": "train", "epochs": 4, "timestep": 6289, "ep_reward": 171.52621459960938, "reward": 0.3135906457901001, "action": -0.3349508047103882}
{"mode": "train", "epochs": 4, "timestep": 6290, "ep_reward": 171.72268676757812, "reward": 0.19647961854934692, "action": -1.1620532274246216}
{"mode": "train", "epochs": 4, "timestep": 6291, "ep_reward": 171.78219604492188, "reward": 0.059504151344299316, "action": -0.6463488340377808}
{"mode": "train", "epochs": 4, "timestep": 6292, "ep_reward": 171.84085083007812, "reward": 0.05865722894668579, "action": -1.7525825500488281}
{"mode": "train", "epochs": 4, "timestep": 6293, "ep_reward": 172.0366973876953, "reward": 0.19584804773330688, "action": -1.4288749694824219}
{"mode": "train", "epochs": 4, "timestep": 6294, "ep_reward": 172.36753845214844, "reward": 0.33084237575531006, "action": -0.8547245264053345}
{"mode": "train", "epochs": 4, "timestep": 6295, "ep_reward": 172.8351287841797, "reward": 0.46758711338043213, "action": -1.2654098272323608}
{"mode": "train", "epochs": 4, "timestep": 6296, "ep_reward": 173.41868591308594, "reward": 0.5835609436035156, "action": -1.0986499786376953}
{"mode": "train", "epochs": 4, "timestep": 6297, "ep_reward": 174.09901428222656, "reward": 0.680330753326416, "action": -1.4570212364196777}
{"mode": "train", "epochs": 4, "timestep": 6298, "ep_reward": 174.84947204589844, "reward": 0.7504509091377258, "action": -1.1589326858520508}
{"mode": "train", "epochs": 4, "timestep": 6299, "ep_reward": 175.65103149414062, "reward": 0.8015634417533875, "action": -1.1960978507995605}
{"mode": "train", "epochs": 4, "timestep": 6300, "ep_reward": 176.4828338623047, "reward": 0.8318029642105103, "action": -1.0533474683761597}
{"mode": "train", "epochs": 4, "timestep": 6301, "ep_reward": 177.3269805908203, "reward": 0.8441457748413086, "action": -0.6876106262207031}
{"mode": "train", "epochs": 4, "timestep": 6302, "ep_reward": 178.16749572753906, "reward": 0.8405153155326843, "action": -1.5975024700164795}
{"mode": "train", "epochs": 4, "timestep": 6303, "ep_reward": 178.97462463378906, "reward": 0.8071359395980835, "action": -0.5723615288734436}
{"mode": "train", "epochs": 4, "timestep": 6304, "ep_reward": 179.7329559326172, "reward": 0.7583280801773071, "action": -0.9306421875953674}
{"mode": "train", "epochs": 4, "timestep": 6305, "ep_reward": 180.407470703125, "reward": 0.6745101809501648, "action": -1.0269469022750854}
{"mode": "train", "epochs": 4, "timestep": 6306, "ep_reward": 180.95843505859375, "reward": 0.550961971282959, "action": -1.1303191184997559}
{"mode": "train", "epochs": 4, "timestep": 6307, "ep_reward": 181.35507202148438, "reward": 0.3966357707977295, "action": -1.2443000078201294}
{"mode": "train", "epochs": 4, "timestep": 6308, "ep_reward": 181.65145874023438, "reward": 0.2963795065879822, "action": -1.7075746059417725}
{"mode": "train", "epochs": 4, "timestep": 6309, "ep_reward": 181.82777404785156, "reward": 0.17631226778030396, "action": -1.120241641998291}
{"mode": "train", "epochs": 4, "timestep": 6310, "ep_reward": 181.86392211914062, "reward": 0.036144912242889404, "action": -1.0930908918380737}
{"mode": "train", "epochs": 4, "timestep": 6311, "ep_reward": 181.94549560546875, "reward": 0.08158016204833984, "action": -1.2776978015899658}
{"mode": "train", "epochs": 4, "timestep": 6312, "ep_reward": 182.16136169433594, "reward": 0.21586638689041138, "action": -0.48695749044418335}
{"mode": "train", "epochs": 4, "timestep": 6313, "ep_reward": 182.52395629882812, "reward": 0.36259353160858154, "action": -0.46253204345703125}
{"mode": "train", "epochs": 4, "timestep": 6314, "ep_reward": 183.02389526367188, "reward": 0.4999384880065918, "action": -1.3785977363586426}
{"mode": "train", "epochs": 4, "timestep": 6315, "ep_reward": 183.6332550048828, "reward": 0.6093534231185913, "action": -0.949874997138977}
{"mode": "train", "epochs": 4, "timestep": 6316, "ep_reward": 184.3358917236328, "reward": 0.7026430368423462, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6317, "ep_reward": 185.09979248046875, "reward": 0.7638940811157227, "action": -1.4070205688476562}
{"mode": "train", "epochs": 4, "timestep": 6318, "ep_reward": 185.91064453125, "reward": 0.8108549118041992, "action": -1.331260323524475}
{"mode": "train", "epochs": 4, "timestep": 6319, "ep_reward": 186.74996948242188, "reward": 0.8393195867538452, "action": -0.9412849545478821}
{"mode": "train", "epochs": 4, "timestep": 6320, "ep_reward": 187.60302734375, "reward": 0.8530527353286743, "action": -0.6056913733482361}
{"mode": "train", "epochs": 4, "timestep": 6321, "ep_reward": 188.45474243164062, "reward": 0.8517149090766907, "action": -0.7347749471664429}
{"mode": "train", "epochs": 4, "timestep": 6322, "ep_reward": 189.28463745117188, "reward": 0.8298988938331604, "action": -1.75461745262146}
{"mode": "train", "epochs": 4, "timestep": 6323, "ep_reward": 190.05931091308594, "reward": 0.7746714353561401, "action": -0.9221662282943726}
{"mode": "train", "epochs": 4, "timestep": 6324, "ep_reward": 190.75704956054688, "reward": 0.6977347135543823, "action": 0.1238030195236206}
{"mode": "train", "epochs": 4, "timestep": 6325, "ep_reward": 191.3559112548828, "reward": 0.5988580584526062, "action": -1.9499552249908447}
{"mode": "train", "epochs": 4, "timestep": 6326, "ep_reward": 191.78665161132812, "reward": 0.4307386875152588, "action": -1.9831711053848267}
{"mode": "train", "epochs": 4, "timestep": 6327, "ep_reward": 192.10630798339844, "reward": 0.31966137886047363, "action": -1.6498786211013794}
{"mode": "train", "epochs": 4, "timestep": 6328, "ep_reward": 192.31019592285156, "reward": 0.2038952112197876, "action": -1.0875403881072998}
{"mode": "train", "epochs": 4, "timestep": 6329, "ep_reward": 192.37828063964844, "reward": 0.06808716058731079, "action": -0.5587436556816101}
{"mode": "train", "epochs": 4, "timestep": 6330, "ep_reward": 192.4283447265625, "reward": 0.050059616565704346, "action": -1.4921796321868896}
{"mode": "train", "epochs": 4, "timestep": 6331, "ep_reward": 192.6167755126953, "reward": 0.188423752784729, "action": -1.0786709785461426}
{"mode": "train", "epochs": 4, "timestep": 6332, "ep_reward": 192.9444122314453, "reward": 0.32763272523880005, "action": -1.1505143642425537}
{"mode": "train", "epochs": 4, "timestep": 6333, "ep_reward": 193.40478515625, "reward": 0.46037036180496216, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6334, "ep_reward": 193.9737091064453, "reward": 0.5689208507537842, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6335, "ep_reward": 194.63258361816406, "reward": 0.6588723659515381, "action": -0.7420912981033325}
{"mode": "train", "epochs": 4, "timestep": 6336, "ep_reward": 195.3721160888672, "reward": 0.7395292520523071, "action": -0.6833153963088989}
{"mode": "train", "epochs": 4, "timestep": 6337, "ep_reward": 196.16847229003906, "reward": 0.7963618040084839, "action": -0.7544103860855103}
{"mode": "train", "epochs": 4, "timestep": 6338, "ep_reward": 196.99899291992188, "reward": 0.8305158615112305, "action": -1.3850256204605103}
{"mode": "train", "epochs": 4, "timestep": 6339, "ep_reward": 197.83815002441406, "reward": 0.8391497135162354, "action": -0.9468562006950378}
{"mode": "train", "epochs": 4, "timestep": 6340, "ep_reward": 198.6700439453125, "reward": 0.8318933844566345, "action": -1.364768147468567}
{"mode": "train", "epochs": 4, "timestep": 6341, "ep_reward": 199.4683380126953, "reward": 0.7982933521270752, "action": -1.0561171770095825}
{"mode": "train", "epochs": 4, "timestep": 6342, "ep_reward": 200.2088623046875, "reward": 0.7405303716659546, "action": -0.9225080013275146}
{"mode": "train", "epochs": 4, "timestep": 6343, "ep_reward": 200.8596649169922, "reward": 0.650797963142395, "action": -0.924797773361206}
{"mode": "train", "epochs": 4, "timestep": 6344, "ep_reward": 201.38055419921875, "reward": 0.5208889842033386, "action": -1.330258846282959}
{"mode": "train", "epochs": 4, "timestep": 6345, "ep_reward": 201.7643585205078, "reward": 0.38379913568496704, "action": -0.45764827728271484}
{"mode": "train", "epochs": 4, "timestep": 6346, "ep_reward": 202.04502868652344, "reward": 0.28066885471343994, "action": -1.55464768409729}
{"mode": "train", "epochs": 4, "timestep": 6347, "ep_reward": 202.20281982421875, "reward": 0.1577931046485901, "action": -0.7390233874320984}
{"mode": "train", "epochs": 4, "timestep": 6348, "ep_reward": 202.2176513671875, "reward": 0.014825403690338135, "action": -0.3817857503890991}
{"mode": "train", "epochs": 4, "timestep": 6349, "ep_reward": 202.3194122314453, "reward": 0.10175818204879761, "action": -0.7883468866348267}
{"mode": "train", "epochs": 4, "timestep": 6350, "ep_reward": 202.56207275390625, "reward": 0.2426668405532837, "action": -1.2038358449935913}
{"mode": "train", "epochs": 4, "timestep": 6351, "ep_reward": 202.94076538085938, "reward": 0.3786989450454712, "action": -0.17386704683303833}
{"mode": "train", "epochs": 4, "timestep": 6352, "ep_reward": 203.4586639404297, "reward": 0.517898678779602, "action": -1.4285887479782104}
{"mode": "train", "epochs": 4, "timestep": 6353, "ep_reward": 204.0825653076172, "reward": 0.6239020228385925, "action": -0.7443697452545166}
{"mode": "train", "epochs": 4, "timestep": 6354, "ep_reward": 204.79884338378906, "reward": 0.7162773609161377, "action": -0.7655877470970154}
{"mode": "train", "epochs": 4, "timestep": 6355, "ep_reward": 205.58456420898438, "reward": 0.7857251167297363, "action": -0.7988190650939941}
{"mode": "train", "epochs": 4, "timestep": 6356, "ep_reward": 206.41885375976562, "reward": 0.8342918157577515, "action": -1.242307424545288}
{"mode": "train", "epochs": 4, "timestep": 6357, "ep_reward": 207.28050231933594, "reward": 0.8616461753845215, "action": -0.6459897756576538}
{"mode": "train", "epochs": 4, "timestep": 6358, "ep_reward": 208.15866088867188, "reward": 0.8781536817550659, "action": -1.2444145679473877}
{"mode": "train", "epochs": 4, "timestep": 6359, "ep_reward": 209.03353881835938, "reward": 0.8748832941055298, "action": -0.581512451171875}
{"mode": "train", "epochs": 4, "timestep": 6360, "ep_reward": 209.89462280273438, "reward": 0.8610803484916687, "action": -0.5503075122833252}
{"mode": "train", "epochs": 4, "timestep": 6361, "ep_reward": 210.72396850585938, "reward": 0.8293430209159851, "action": -0.49005424976348877}
{"mode": "train", "epochs": 4, "timestep": 6362, "ep_reward": 211.49974060058594, "reward": 0.7757729887962341, "action": -1.7318323850631714}
{"mode": "train", "epochs": 4, "timestep": 6363, "ep_reward": 212.17901611328125, "reward": 0.6792788505554199, "action": -0.9792472124099731}
{"mode": "train", "epochs": 4, "timestep": 6364, "ep_reward": 212.73226928710938, "reward": 0.5532492399215698, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6365, "ep_reward": 213.11000061035156, "reward": 0.37773746252059937, "action": -1.4781733751296997}
{"mode": "train", "epochs": 4, "timestep": 6366, "ep_reward": 213.38345336914062, "reward": 0.27345454692840576, "action": -1.592700481414795}
{"mode": "train", "epochs": 4, "timestep": 6367, "ep_reward": 213.53268432617188, "reward": 0.14923220872879028, "action": -1.384040355682373}
{"mode": "train", "epochs": 4, "timestep": 6368, "ep_reward": 213.5376739501953, "reward": 0.00499039888381958, "action": -1.2667970657348633}
{"mode": "train", "epochs": 4, "timestep": 6369, "ep_reward": 213.6483612060547, "reward": 0.11068016290664673, "action": -0.69568932056427}
{"mode": "train", "epochs": 4, "timestep": 6370, "ep_reward": 213.90142822265625, "reward": 0.25306302309036255, "action": -0.4892640709877014}
{"mode": "train", "epochs": 4, "timestep": 6371, "ep_reward": 214.29843139648438, "reward": 0.3969994783401489, "action": -1.3370126485824585}
{"mode": "train", "epochs": 4, "timestep": 6372, "ep_reward": 214.8184356689453, "reward": 0.5200003385543823, "action": -1.7374191284179688}
{"mode": "train", "epochs": 4, "timestep": 6373, "ep_reward": 215.44078063964844, "reward": 0.6223416328430176, "action": -1.3050100803375244}
{"mode": "train", "epochs": 4, "timestep": 6374, "ep_reward": 216.14991760253906, "reward": 0.7091355323791504, "action": -0.7359592914581299}
{"mode": "train", "epochs": 4, "timestep": 6375, "ep_reward": 216.92893981933594, "reward": 0.779015064239502, "action": -1.5368990898132324}
{"mode": "train", "epochs": 4, "timestep": 6376, "ep_reward": 217.74929809570312, "reward": 0.8203549981117249, "action": -1.3774418830871582}
{"mode": "train", "epochs": 4, "timestep": 6377, "ep_reward": 218.59384155273438, "reward": 0.8445435166358948, "action": -1.53054678440094}
{"mode": "train", "epochs": 4, "timestep": 6378, "ep_reward": 219.4434051513672, "reward": 0.8495569229125977, "action": -0.7607002854347229}
{"mode": "train", "epochs": 4, "timestep": 6379, "ep_reward": 220.28622436523438, "reward": 0.8428241014480591, "action": -0.9085124731063843}
{"mode": "train", "epochs": 4, "timestep": 6380, "ep_reward": 221.1003875732422, "reward": 0.8141704201698303, "action": -0.19312459230422974}
{"mode": "train", "epochs": 4, "timestep": 6381, "ep_reward": 221.86904907226562, "reward": 0.7686554193496704, "action": -0.8314277529716492}
{"mode": "train", "epochs": 4, "timestep": 6382, "ep_reward": 222.555908203125, "reward": 0.6868531107902527, "action": -1.9627825021743774}
{"mode": "train", "epochs": 4, "timestep": 6383, "ep_reward": 223.1082305908203, "reward": 0.5523287653923035, "action": -0.9571720957756042}
{"mode": "train", "epochs": 4, "timestep": 6384, "ep_reward": 223.5033721923828, "reward": 0.395144522190094, "action": -0.7481042146682739}
{"mode": "train", "epochs": 4, "timestep": 6385, "ep_reward": 223.7978973388672, "reward": 0.29452890157699585, "action": -1.4749528169631958}
{"mode": "train", "epochs": 4, "timestep": 6386, "ep_reward": 223.97201538085938, "reward": 0.1741245985031128, "action": -0.6387121677398682}
{"mode": "train", "epochs": 4, "timestep": 6387, "ep_reward": 224.00558471679688, "reward": 0.033566415309906006, "action": -1.049436092376709}
{"mode": "train", "epochs": 4, "timestep": 6388, "ep_reward": 224.08973693847656, "reward": 0.08415442705154419, "action": -0.033206403255462646}
{"mode": "train", "epochs": 4, "timestep": 6389, "ep_reward": 224.32359313964844, "reward": 0.23384934663772583, "action": -1.3972797393798828}
{"mode": "train", "epochs": 4, "timestep": 6390, "ep_reward": 224.68983459472656, "reward": 0.36623501777648926, "action": -0.6704707145690918}
{"mode": "train", "epochs": 4, "timestep": 6391, "ep_reward": 225.1900634765625, "reward": 0.5002297759056091, "action": -1.819628357887268}
{"mode": "train", "epochs": 4, "timestep": 6392, "ep_reward": 225.794921875, "reward": 0.6048535108566284, "action": -0.6046527624130249}
{"mode": "train", "epochs": 4, "timestep": 6393, "ep_reward": 226.49740600585938, "reward": 0.7024846076965332, "action": -1.7942605018615723}
{"mode": "train", "epochs": 4, "timestep": 6394, "ep_reward": 227.2633514404297, "reward": 0.7659416198730469, "action": -0.3553299307823181}
{"mode": "train", "epochs": 4, "timestep": 6395, "ep_reward": 228.08563232421875, "reward": 0.8222775459289551, "action": -0.9685426950454712}
{"mode": "train", "epochs": 4, "timestep": 6396, "ep_reward": 228.93948364257812, "reward": 0.8538459539413452, "action": -0.8676891326904297}
{"mode": "train", "epochs": 4, "timestep": 6397, "ep_reward": 229.80906677246094, "reward": 0.8695766925811768, "action": -1.0784715414047241}
{"mode": "train", "epochs": 4, "timestep": 6398, "ep_reward": 230.6766357421875, "reward": 0.8675754070281982, "action": -1.1834487915039062}
{"mode": "train", "epochs": 4, "timestep": 6399, "ep_reward": 231.52391052246094, "reward": 0.8472762107849121, "action": -1.7250490188598633}
{"mode": "train", "epochs": 4, "timestep": 6400, "ep_reward": 232.3245391845703, "reward": 0.8006229400634766, "action": -0.7419564723968506}
{"mode": "train", "epochs": 4, "timestep": 6401, "ep_reward": 233.06100463867188, "reward": 0.7364664077758789, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6402, "ep_reward": 233.68414306640625, "reward": 0.6231383085250854, "action": -0.858780562877655}
{"mode": "train", "epochs": 4, "timestep": 6403, "ep_reward": 234.16587829589844, "reward": 0.481733500957489, "action": -1.9903347492218018}
{"mode": "train", "epochs": 4, "timestep": 6404, "ep_reward": 234.51622009277344, "reward": 0.3503381609916687, "action": -0.6248884797096252}
{"mode": "train", "epochs": 4, "timestep": 6405, "ep_reward": 234.75653076171875, "reward": 0.2403058409690857, "action": -1.4356911182403564}
{"mode": "train", "epochs": 4, "timestep": 6406, "ep_reward": 234.86691284179688, "reward": 0.11038923263549805, "action": -1.3699976205825806}
{"mode": "train", "epochs": 4, "timestep": 6407, "ep_reward": 234.8721466064453, "reward": 0.005229592323303223, "action": -1.1719141006469727}
{"mode": "train", "epochs": 4, "timestep": 6408, "ep_reward": 235.0216522216797, "reward": 0.14950889348983765, "action": -0.7867165803909302}
{"mode": "train", "epochs": 4, "timestep": 6409, "ep_reward": 235.31332397460938, "reward": 0.29167890548706055, "action": -0.9793460965156555}
{"mode": "train", "epochs": 4, "timestep": 6410, "ep_reward": 235.7415313720703, "reward": 0.42821377515792847, "action": -1.1745479106903076}
{"mode": "train", "epochs": 4, "timestep": 6411, "ep_reward": 236.29156494140625, "reward": 0.5500329732894897, "action": -1.7504966259002686}
{"mode": "train", "epochs": 4, "timestep": 6412, "ep_reward": 236.93865966796875, "reward": 0.6470873951911926, "action": 0.004868507385253906}
{"mode": "train", "epochs": 4, "timestep": 6413, "ep_reward": 237.67909240722656, "reward": 0.7404290437698364, "action": -1.0102958679199219}
{"mode": "train", "epochs": 4, "timestep": 6414, "ep_reward": 238.47915649414062, "reward": 0.8000666499137878, "action": -0.5831746459007263}
{"mode": "train", "epochs": 4, "timestep": 6415, "ep_reward": 239.3226318359375, "reward": 0.8434697389602661, "action": -1.4569337368011475}
{"mode": "train", "epochs": 4, "timestep": 6416, "ep_reward": 240.18478393554688, "reward": 0.8621576428413391, "action": -0.5237724781036377}
{"mode": "train", "epochs": 4, "timestep": 6417, "ep_reward": 241.05735778808594, "reward": 0.87256920337677, "action": -0.9535204172134399}
{"mode": "train", "epochs": 4, "timestep": 6418, "ep_reward": 241.9205780029297, "reward": 0.8632196187973022, "action": -1.3238744735717773}
{"mode": "train", "epochs": 4, "timestep": 6419, "ep_reward": 242.75279235839844, "reward": 0.8322077989578247, "action": -1.2047836780548096}
{"mode": "train", "epochs": 4, "timestep": 6420, "ep_reward": 243.53176879882812, "reward": 0.7789695858955383, "action": -0.9024658799171448}
{"mode": "train", "epochs": 4, "timestep": 6421, "ep_reward": 244.23123168945312, "reward": 0.6994569301605225, "action": -1.5908098220825195}
{"mode": "train", "epochs": 4, "timestep": 6422, "ep_reward": 244.8057403564453, "reward": 0.5745062828063965, "action": -1.1302461624145508}
{"mode": "train", "epochs": 4, "timestep": 6423, "ep_reward": 245.21788024902344, "reward": 0.41213852167129517, "action": -0.9625005125999451}
{"mode": "train", "epochs": 4, "timestep": 6424, "ep_reward": 245.52200317382812, "reward": 0.3041304349899292, "action": -1.1882086992263794}
{"mode": "train", "epochs": 4, "timestep": 6425, "ep_reward": 245.7074432373047, "reward": 0.18544012308120728, "action": -0.31986182928085327}
{"mode": "train", "epochs": 4, "timestep": 6426, "ep_reward": 245.7540740966797, "reward": 0.04662668704986572, "action": -0.8733221292495728}
{"mode": "train", "epochs": 4, "timestep": 6427, "ep_reward": 245.8255615234375, "reward": 0.071480393409729, "action": -1.1432124376296997}
{"mode": "train", "epochs": 4, "timestep": 6428, "ep_reward": 246.03269958496094, "reward": 0.20713353157043457, "action": -0.43055665493011475}
{"mode": "train", "epochs": 4, "timestep": 6429, "ep_reward": 246.3871612548828, "reward": 0.35445505380630493, "action": -1.069103717803955}
{"mode": "train", "epochs": 4, "timestep": 6430, "ep_reward": 246.87258911132812, "reward": 0.4854240417480469, "action": -0.7534044981002808}
{"mode": "train", "epochs": 4, "timestep": 6431, "ep_reward": 247.47645568847656, "reward": 0.6038740277290344, "action": -1.7041343450546265}
{"mode": "train", "epochs": 4, "timestep": 6432, "ep_reward": 248.16737365722656, "reward": 0.6909136772155762, "action": -1.7506828308105469}
{"mode": "train", "epochs": 4, "timestep": 6433, "ep_reward": 248.924072265625, "reward": 0.7567031979560852, "action": -1.125409722328186}
{"mode": "train", "epochs": 4, "timestep": 6434, "ep_reward": 249.73171997070312, "reward": 0.8076419830322266, "action": -0.9031482338905334}
{"mode": "train", "epochs": 4, "timestep": 6435, "ep_reward": 250.57235717773438, "reward": 0.840630054473877, "action": -0.9975759387016296}
{"mode": "train", "epochs": 4, "timestep": 6436, "ep_reward": 251.42678833007812, "reward": 0.8544264435768127, "action": -1.1928455829620361}
{"mode": "train", "epochs": 4, "timestep": 6437, "ep_reward": 252.2753143310547, "reward": 0.8485209941864014, "action": -1.1993838548660278}
{"mode": "train", "epochs": 4, "timestep": 6438, "ep_reward": 253.09793090820312, "reward": 0.8226122856140137, "action": -1.0757989883422852}
{"mode": "train", "epochs": 4, "timestep": 6439, "ep_reward": 253.8717803955078, "reward": 0.7738431692123413, "action": -0.666828989982605}
{"mode": "train", "epochs": 4, "timestep": 6440, "ep_reward": 254.57168579101562, "reward": 0.6998990774154663, "action": -1.4795682430267334}
{"mode": "train", "epochs": 4, "timestep": 6441, "ep_reward": 255.15084838867188, "reward": 0.5791691541671753, "action": -0.9608452916145325}
{"mode": "train", "epochs": 4, "timestep": 6442, "ep_reward": 255.57269287109375, "reward": 0.4218495488166809, "action": -1.2224714756011963}
{"mode": "train", "epochs": 4, "timestep": 6443, "ep_reward": 255.88949584960938, "reward": 0.3168030381202698, "action": -0.8047250509262085}
{"mode": "train", "epochs": 4, "timestep": 6444, "ep_reward": 256.0898742675781, "reward": 0.20037227869033813, "action": -0.8566645979881287}
{"mode": "train", "epochs": 4, "timestep": 6445, "ep_reward": 256.1536865234375, "reward": 0.0638083815574646, "action": -1.7169020175933838}
{"mode": "train", "epochs": 4, "timestep": 6446, "ep_reward": 256.2080078125, "reward": 0.054332852363586426, "action": -0.7228584289550781}
{"mode": "train", "epochs": 4, "timestep": 6447, "ep_reward": 256.40264892578125, "reward": 0.19464844465255737, "action": -0.8500549793243408}
{"mode": "train", "epochs": 4, "timestep": 6448, "ep_reward": 256.7388000488281, "reward": 0.33614665269851685, "action": -1.39431631565094}
{"mode": "train", "epochs": 4, "timestep": 6449, "ep_reward": 257.2036437988281, "reward": 0.46482962369918823, "action": -1.628781795501709}
{"mode": "train", "epochs": 4, "timestep": 6450, "ep_reward": 257.7807312011719, "reward": 0.5770787000656128, "action": -0.7211222648620605}
{"mode": "train", "epochs": 4, "timestep": 6451, "ep_reward": 258.45989990234375, "reward": 0.6791701316833496, "action": -1.1985540390014648}
{"mode": "train", "epochs": 4, "timestep": 6452, "ep_reward": 259.2126159667969, "reward": 0.7527039051055908, "action": -0.21387922763824463}
{"mode": "train", "epochs": 4, "timestep": 6453, "ep_reward": 260.0256652832031, "reward": 0.8130598068237305, "action": -1.9003043174743652}
{"mode": "train", "epochs": 4, "timestep": 6454, "ep_reward": 260.8638000488281, "reward": 0.8381476402282715, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6455, "ep_reward": 261.7084045410156, "reward": 0.8445995450019836, "action": -1.7935540676116943}
{"mode": "train", "epochs": 4, "timestep": 6456, "ep_reward": 262.5422058105469, "reward": 0.8338028192520142, "action": -1.434564471244812}
{"mode": "train", "epochs": 4, "timestep": 6457, "ep_reward": 263.34649658203125, "reward": 0.8042789697647095, "action": -1.2215778827667236}
{"mode": "train", "epochs": 4, "timestep": 6458, "ep_reward": 264.0967102050781, "reward": 0.7502202987670898, "action": -0.7965286374092102}
{"mode": "train", "epochs": 4, "timestep": 6459, "ep_reward": 264.76513671875, "reward": 0.6684247255325317, "action": -0.7067033648490906}
{"mode": "train", "epochs": 4, "timestep": 6460, "ep_reward": 265.3144226074219, "reward": 0.5493005514144897, "action": -0.9651027321815491}
{"mode": "train", "epochs": 4, "timestep": 6461, "ep_reward": 265.7149353027344, "reward": 0.4005233645439148, "action": -0.594001293182373}
{"mode": "train", "epochs": 4, "timestep": 6462, "ep_reward": 266.0161437988281, "reward": 0.3012104630470276, "action": -0.47104108333587646}
{"mode": "train", "epochs": 4, "timestep": 6463, "ep_reward": 266.1980285644531, "reward": 0.1818905472755432, "action": -0.4487992525100708}
{"mode": "train", "epochs": 4, "timestep": 6464, "ep_reward": 266.24053955078125, "reward": 0.042518675327301025, "action": -1.003859043121338}
{"mode": "train", "epochs": 4, "timestep": 6465, "ep_reward": 266.3160705566406, "reward": 0.07552826404571533, "action": -0.5433095693588257}
{"mode": "train", "epochs": 4, "timestep": 6466, "ep_reward": 266.53485107421875, "reward": 0.21877658367156982, "action": -0.3450157642364502}
{"mode": "train", "epochs": 4, "timestep": 6467, "ep_reward": 266.90020751953125, "reward": 0.365364670753479, "action": -1.1064815521240234}
{"mode": "train", "epochs": 4, "timestep": 6468, "ep_reward": 267.39410400390625, "reward": 0.49390655755996704, "action": -1.1378659009933472}
{"mode": "train", "epochs": 4, "timestep": 6469, "ep_reward": 268.0008239746094, "reward": 0.6067167520523071, "action": -1.0213333368301392}
{"mode": "train", "epochs": 4, "timestep": 6470, "ep_reward": 268.7011413574219, "reward": 0.7003307938575745, "action": -0.471149742603302}
{"mode": "train", "epochs": 4, "timestep": 6471, "ep_reward": 269.4779968261719, "reward": 0.7768563628196716, "action": -1.4332804679870605}
{"mode": "train", "epochs": 4, "timestep": 6472, "ep_reward": 270.3018798828125, "reward": 0.8238951563835144, "action": -1.67350172996521}
{"mode": "train", "epochs": 4, "timestep": 6473, "ep_reward": 271.1536865234375, "reward": 0.8518105745315552, "action": -0.5774431228637695}
{"mode": "train", "epochs": 4, "timestep": 6474, "ep_reward": 272.0263977050781, "reward": 0.8727014064788818, "action": 0.15012216567993164}
{"mode": "train", "epochs": 4, "timestep": 6475, "ep_reward": 272.9104309082031, "reward": 0.8840468525886536, "action": -0.5131147503852844}
{"mode": "train", "epochs": 4, "timestep": 6476, "ep_reward": 273.78564453125, "reward": 0.8752031922340393, "action": -0.943263590335846}
{"mode": "train", "epochs": 4, "timestep": 6477, "ep_reward": 274.6318359375, "reward": 0.84619140625, "action": -0.6736496090888977}
{"mode": "train", "epochs": 4, "timestep": 6478, "ep_reward": 275.43072509765625, "reward": 0.7988835573196411, "action": -0.6684359312057495}
{"mode": "train", "epochs": 4, "timestep": 6479, "ep_reward": 276.15631103515625, "reward": 0.7255880832672119, "action": -1.285489559173584}
{"mode": "train", "epochs": 4, "timestep": 6480, "ep_reward": 276.76812744140625, "reward": 0.6118061542510986, "action": -0.9466421008110046}
{"mode": "train", "epochs": 4, "timestep": 6481, "ep_reward": 277.2306823730469, "reward": 0.46254515647888184, "action": -0.42611557245254517}
{"mode": "train", "epochs": 4, "timestep": 6482, "ep_reward": 277.5466613769531, "reward": 0.3159918189048767, "action": -1.164005160331726}
{"mode": "train", "epochs": 4, "timestep": 6483, "ep_reward": 277.74609375, "reward": 0.19943785667419434, "action": -1.0705606937408447}
{"mode": "train", "epochs": 4, "timestep": 6484, "ep_reward": 277.8089904785156, "reward": 0.0629013180732727, "action": -0.8174295425415039}
{"mode": "train", "epochs": 4, "timestep": 6485, "ep_reward": 277.86431884765625, "reward": 0.055315613746643066, "action": -1.2963452339172363}
{"mode": "train", "epochs": 4, "timestep": 6486, "ep_reward": 278.05731201171875, "reward": 0.19300812482833862, "action": -0.1695905327796936}
{"mode": "train", "epochs": 4, "timestep": 6487, "ep_reward": 278.4007568359375, "reward": 0.34343457221984863, "action": -1.1682071685791016}
{"mode": "train", "epochs": 4, "timestep": 6488, "ep_reward": 278.8743896484375, "reward": 0.47363394498825073, "action": -0.915683925151825}
{"mode": "train", "epochs": 4, "timestep": 6489, "ep_reward": 279.4664611816406, "reward": 0.5920736789703369, "action": -1.1589429378509521}
{"mode": "train", "epochs": 4, "timestep": 6490, "ep_reward": 280.15362548828125, "reward": 0.6871601343154907, "action": -1.3081258535385132}
{"mode": "train", "epochs": 4, "timestep": 6491, "ep_reward": 280.9126281738281, "reward": 0.759005069732666, "action": -1.2755851745605469}
{"mode": "train", "epochs": 4, "timestep": 6492, "ep_reward": 281.7231140136719, "reward": 0.8104871511459351, "action": -1.1890497207641602}
{"mode": "train", "epochs": 4, "timestep": 6493, "ep_reward": 282.5670166015625, "reward": 0.8439116477966309, "action": -0.07580965757369995}
{"mode": "train", "epochs": 4, "timestep": 6494, "ep_reward": 283.4363098144531, "reward": 0.8692941665649414, "action": -0.9176338911056519}
{"mode": "train", "epochs": 4, "timestep": 6495, "ep_reward": 284.3077087402344, "reward": 0.8714042901992798, "action": -1.1688252687454224}
{"mode": "train", "epochs": 4, "timestep": 6496, "ep_reward": 285.1625671386719, "reward": 0.8548597097396851, "action": -0.5595925450325012}
{"mode": "train", "epochs": 4, "timestep": 6497, "ep_reward": 285.987060546875, "reward": 0.8245086073875427, "action": -0.9852728843688965}
{"mode": "train", "epochs": 4, "timestep": 6498, "ep_reward": 286.7536315917969, "reward": 0.7665845155715942, "action": -0.7277912497520447}
{"mode": "train", "epochs": 4, "timestep": 6499, "ep_reward": 287.4351806640625, "reward": 0.6815357804298401, "action": -0.38561010360717773}
{"mode": "train", "epochs": 4, "timestep": 6500, "ep_reward": 288.0007019042969, "reward": 0.565513014793396, "action": -0.6522904634475708}
{"mode": "train", "epochs": 4, "timestep": 6501, "ep_reward": 288.4080505371094, "reward": 0.40735918283462524, "action": -0.32153135538101196}
{"mode": "train", "epochs": 4, "timestep": 6502, "ep_reward": 288.6910095214844, "reward": 0.2829737067222595, "action": -0.22044557332992554}
{"mode": "train", "epochs": 4, "timestep": 6503, "ep_reward": 288.85137939453125, "reward": 0.16036731004714966, "action": -0.1724279522895813}
{"mode": "train", "epochs": 4, "timestep": 6504, "ep_reward": 288.8690185546875, "reward": 0.017644822597503662, "action": -1.369650959968567}
{"mode": "train", "epochs": 4, "timestep": 6505, "ep_reward": 288.968017578125, "reward": 0.09898525476455688, "action": -1.2697663307189941}
{"mode": "train", "epochs": 4, "timestep": 6506, "ep_reward": 289.2017822265625, "reward": 0.23375332355499268, "action": -1.5857727527618408}
{"mode": "train", "epochs": 4, "timestep": 6507, "ep_reward": 289.56805419921875, "reward": 0.3662866950035095, "action": -1.2367311716079712}
{"mode": "train", "epochs": 4, "timestep": 6508, "ep_reward": 290.0636901855469, "reward": 0.49563658237457275, "action": -0.3026707172393799}
{"mode": "train", "epochs": 4, "timestep": 6509, "ep_reward": 290.68157958984375, "reward": 0.6178827285766602, "action": -1.1171835660934448}
{"mode": "train", "epochs": 4, "timestep": 6510, "ep_reward": 291.3887939453125, "reward": 0.7072168588638306, "action": -0.8160748481750488}
{"mode": "train", "epochs": 4, "timestep": 6511, "ep_reward": 292.16534423828125, "reward": 0.7765429615974426, "action": -0.881324052810669}
{"mode": "train", "epochs": 4, "timestep": 6512, "ep_reward": 292.9889831542969, "reward": 0.8236479163169861, "action": -0.034744858741760254}
{"mode": "train", "epochs": 4, "timestep": 6513, "ep_reward": 293.8477478027344, "reward": 0.8587549924850464, "action": -1.257447600364685}
{"mode": "train", "epochs": 4, "timestep": 6514, "ep_reward": 294.714111328125, "reward": 0.8663650155067444, "action": -1.2553741931915283}
{"mode": "train", "epochs": 4, "timestep": 6515, "ep_reward": 295.5715026855469, "reward": 0.8573803901672363, "action": -0.448062002658844}
{"mode": "train", "epochs": 4, "timestep": 6516, "ep_reward": 296.4084777832031, "reward": 0.8369683027267456, "action": -1.5394041538238525}
{"mode": "train", "epochs": 4, "timestep": 6517, "ep_reward": 297.1924743652344, "reward": 0.7839847207069397, "action": -0.12549960613250732}
{"mode": "train", "epochs": 4, "timestep": 6518, "ep_reward": 297.9102478027344, "reward": 0.7177807092666626, "action": -0.8312958478927612}
{"mode": "train", "epochs": 4, "timestep": 6519, "ep_reward": 298.5206298828125, "reward": 0.6103843450546265, "action": -0.808275580406189}
{"mode": "train", "epochs": 4, "timestep": 6520, "ep_reward": 298.9844055175781, "reward": 0.4637885093688965, "action": -0.696057140827179}
{"mode": "train", "epochs": 4, "timestep": 6521, "ep_reward": 299.3100891113281, "reward": 0.3256773352622986, "action": -1.642453670501709}
{"mode": "train", "epochs": 4, "timestep": 6522, "ep_reward": 299.52105712890625, "reward": 0.2109752893447876, "action": -1.5656092166900635}
{"mode": "train", "epochs": 4, "timestep": 6523, "ep_reward": 299.5973815917969, "reward": 0.07633644342422485, "action": -1.0957640409469604}
{"mode": "train", "epochs": 4, "timestep": 6524, "ep_reward": 299.6390380859375, "reward": 0.041663944721221924, "action": -0.6008570194244385}
{"mode": "train", "epochs": 4, "timestep": 6525, "ep_reward": 299.8221435546875, "reward": 0.18309056758880615, "action": -0.8642027974128723}
{"mode": "train", "epochs": 4, "timestep": 6526, "ep_reward": 300.1466064453125, "reward": 0.3244742751121521, "action": -0.8493080139160156}
{"mode": "train", "epochs": 4, "timestep": 6527, "ep_reward": 300.6072082519531, "reward": 0.4605896472930908, "action": -0.19300639629364014}
{"mode": "train", "epochs": 4, "timestep": 6528, "ep_reward": 301.1959228515625, "reward": 0.5887224078178406, "action": -1.9635933637619019}
{"mode": "train", "epochs": 4, "timestep": 6529, "ep_reward": 301.8725280761719, "reward": 0.6765946745872498, "action": -1.2748178243637085}
{"mode": "train", "epochs": 4, "timestep": 6530, "ep_reward": 302.6236267089844, "reward": 0.7510921955108643, "action": -1.781313419342041}
{"mode": "train", "epochs": 4, "timestep": 6531, "ep_reward": 303.4236145019531, "reward": 0.7999929785728455, "action": -1.7959522008895874}
{"mode": "train", "epochs": 4, "timestep": 6532, "ep_reward": 304.2535400390625, "reward": 0.8299150466918945, "action": -1.0254830121994019}
{"mode": "train", "epochs": 4, "timestep": 6533, "ep_reward": 305.10186767578125, "reward": 0.8483262658119202, "action": -0.8866794109344482}
{"mode": "train", "epochs": 4, "timestep": 6534, "ep_reward": 305.9515380859375, "reward": 0.8496749401092529, "action": -0.5637277364730835}
{"mode": "train", "epochs": 4, "timestep": 6535, "ep_reward": 306.7864074707031, "reward": 0.8348721861839294, "action": -0.3263736963272095}
{"mode": "train", "epochs": 4, "timestep": 6536, "ep_reward": 307.5873718261719, "reward": 0.8009496927261353, "action": -1.3460053205490112}
{"mode": "train", "epochs": 4, "timestep": 6537, "ep_reward": 308.3172912597656, "reward": 0.7299083471298218, "action": -1.4063676595687866}
{"mode": "train", "epochs": 4, "timestep": 6538, "ep_reward": 308.9400634765625, "reward": 0.6227701902389526, "action": -0.7669129967689514}
{"mode": "train", "epochs": 4, "timestep": 6539, "ep_reward": 309.4227294921875, "reward": 0.4826783537864685, "action": -1.4374163150787354}
{"mode": "train", "epochs": 4, "timestep": 6540, "ep_reward": 309.77227783203125, "reward": 0.34954309463500977, "action": -0.8460069894790649}
{"mode": "train", "epochs": 4, "timestep": 6541, "ep_reward": 310.01171875, "reward": 0.23945099115371704, "action": -0.9483417272567749}
{"mode": "train", "epochs": 4, "timestep": 6542, "ep_reward": 310.12091064453125, "reward": 0.10918068885803223, "action": -1.9860613346099854}
{"mode": "train", "epochs": 4, "timestep": 6543, "ep_reward": 310.1273193359375, "reward": 0.006415843963623047, "action": -1.166839599609375}
{"mode": "train", "epochs": 4, "timestep": 6544, "ep_reward": 310.27789306640625, "reward": 0.15057587623596191, "action": -0.1151776909828186}
{"mode": "train", "epochs": 4, "timestep": 6545, "ep_reward": 310.5788269042969, "reward": 0.3009447455406189, "action": -1.4991915225982666}
{"mode": "train", "epochs": 4, "timestep": 6546, "ep_reward": 311.0084228515625, "reward": 0.42958468198776245, "action": -1.3877389430999756}
{"mode": "train", "epochs": 4, "timestep": 6547, "ep_reward": 311.5572814941406, "reward": 0.5488702058792114, "action": -0.6263589859008789}
{"mode": "train", "epochs": 4, "timestep": 6548, "ep_reward": 312.2150573730469, "reward": 0.6577754020690918, "action": -1.3862700462341309}
{"mode": "train", "epochs": 4, "timestep": 6549, "ep_reward": 312.9511413574219, "reward": 0.7360971570014954, "action": -0.8323650360107422}
{"mode": "train", "epochs": 4, "timestep": 6550, "ep_reward": 313.74945068359375, "reward": 0.7983081340789795, "action": -0.45351260900497437}
{"mode": "train", "epochs": 4, "timestep": 6551, "ep_reward": 314.5928955078125, "reward": 0.8434364795684814, "action": -1.2638258934020996}
{"mode": "train", "epochs": 4, "timestep": 6552, "ep_reward": 315.45709228515625, "reward": 0.8642005324363708, "action": -0.6453379392623901}
{"mode": "train", "epochs": 4, "timestep": 6553, "ep_reward": 316.3312683105469, "reward": 0.8741781711578369, "action": -1.2849758863449097}
{"mode": "train", "epochs": 4, "timestep": 6554, "ep_reward": 317.194091796875, "reward": 0.8628257513046265, "action": -1.5655016899108887}
{"mode": "train", "epochs": 4, "timestep": 6555, "ep_reward": 318.0244140625, "reward": 0.830330491065979, "action": -0.865556001663208}
{"mode": "train", "epochs": 4, "timestep": 6556, "ep_reward": 318.8054504394531, "reward": 0.7810429930686951, "action": -1.4003173112869263}
{"mode": "train", "epochs": 4, "timestep": 6557, "ep_reward": 319.5019836425781, "reward": 0.6965216398239136, "action": -1.521580696105957}
{"mode": "train", "epochs": 4, "timestep": 6558, "ep_reward": 320.0741271972656, "reward": 0.5721516609191895, "action": -1.2653425931930542}
{"mode": "train", "epochs": 4, "timestep": 6559, "ep_reward": 320.4812316894531, "reward": 0.40709513425827026, "action": -0.899756908416748}
{"mode": "train", "epochs": 4, "timestep": 6560, "ep_reward": 320.7861328125, "reward": 0.3049113154411316, "action": -0.8869782090187073}
{"mode": "train", "epochs": 4, "timestep": 6561, "ep_reward": 320.9724426269531, "reward": 0.18630075454711914, "action": -0.6518803238868713}
{"mode": "train", "epochs": 4, "timestep": 6562, "ep_reward": 321.0201110839844, "reward": 0.047681570053100586, "action": -0.46063101291656494}
{"mode": "train", "epochs": 4, "timestep": 6563, "ep_reward": 321.0906066894531, "reward": 0.07049322128295898, "action": -1.041642665863037}
{"mode": "train", "epochs": 4, "timestep": 6564, "ep_reward": 321.29779052734375, "reward": 0.20719021558761597, "action": -1.8165028095245361}
{"mode": "train", "epochs": 4, "timestep": 6565, "ep_reward": 321.63494873046875, "reward": 0.3371586799621582, "action": -1.258932113647461}
{"mode": "train", "epochs": 4, "timestep": 6566, "ep_reward": 322.10406494140625, "reward": 0.46913033723831177, "action": 0.3408559560775757}
{"mode": "train", "epochs": 4, "timestep": 6567, "ep_reward": 322.7071228027344, "reward": 0.6030558347702026, "action": -0.996709406375885}
{"mode": "train", "epochs": 4, "timestep": 6568, "ep_reward": 323.40435791015625, "reward": 0.6972209215164185, "action": -0.7093478441238403}
{"mode": "train", "epochs": 4, "timestep": 6569, "ep_reward": 324.1756286621094, "reward": 0.7712639570236206, "action": -0.9404881000518799}
{"mode": "train", "epochs": 4, "timestep": 6570, "ep_reward": 324.99725341796875, "reward": 0.8216292858123779, "action": -0.12631267309188843}
{"mode": "train", "epochs": 4, "timestep": 6571, "ep_reward": 325.85723876953125, "reward": 0.859982967376709, "action": -0.676979660987854}
{"mode": "train", "epochs": 4, "timestep": 6572, "ep_reward": 326.73419189453125, "reward": 0.8769655227661133, "action": -1.1767551898956299}
{"mode": "train", "epochs": 4, "timestep": 6573, "ep_reward": 327.60888671875, "reward": 0.8747088313102722, "action": -1.6525354385375977}
{"mode": "train", "epochs": 4, "timestep": 6574, "ep_reward": 328.46087646484375, "reward": 0.8519824743270874, "action": -0.5541041493415833}
{"mode": "train", "epochs": 4, "timestep": 6575, "ep_reward": 329.2799377441406, "reward": 0.8190464973449707, "action": -1.362448811531067}
{"mode": "train", "epochs": 4, "timestep": 6576, "ep_reward": 330.0335388183594, "reward": 0.7535973191261292, "action": -0.6745741367340088}
{"mode": "train", "epochs": 4, "timestep": 6577, "ep_reward": 330.6973571777344, "reward": 0.663817286491394, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6578, "ep_reward": 331.2153015136719, "reward": 0.5179406404495239, "action": -0.14785641431808472}
{"mode": "train", "epochs": 4, "timestep": 6579, "ep_reward": 331.582763671875, "reward": 0.3674565553665161, "action": -0.6750759482383728}
{"mode": "train", "epochs": 4, "timestep": 6580, "ep_reward": 331.84375, "reward": 0.2609809637069702, "action": -1.0292658805847168}
{"mode": "train", "epochs": 4, "timestep": 6581, "ep_reward": 331.9783630371094, "reward": 0.13459926843643188, "action": -0.4132964015007019}
{"mode": "train", "epochs": 4, "timestep": 6582, "ep_reward": 331.9665222167969, "reward": -0.011852502822875977, "action": -0.6432688236236572}
{"mode": "train", "epochs": 4, "timestep": 6583, "ep_reward": 332.09234619140625, "reward": 0.12582343816757202, "action": -0.09202569723129272}
{"mode": "train", "epochs": 4, "timestep": 6584, "ep_reward": 332.36834716796875, "reward": 0.27601492404937744, "action": -0.7999948263168335}
{"mode": "train", "epochs": 4, "timestep": 6585, "ep_reward": 332.78240966796875, "reward": 0.41406798362731934, "action": -0.9544904232025146}
{"mode": "train", "epochs": 4, "timestep": 6586, "ep_reward": 333.3215026855469, "reward": 0.5390831232070923, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6587, "ep_reward": 333.9570617675781, "reward": 0.6355495452880859, "action": -0.8565176725387573}
{"mode": "train", "epochs": 4, "timestep": 6588, "ep_reward": 334.6812438964844, "reward": 0.7241779565811157, "action": -0.28972309827804565}
{"mode": "train", "epochs": 4, "timestep": 6589, "ep_reward": 335.4766845703125, "reward": 0.7954280376434326, "action": -0.25781089067459106}
{"mode": "train", "epochs": 4, "timestep": 6590, "ep_reward": 336.322265625, "reward": 0.8455840349197388, "action": -1.7786610126495361}
{"mode": "train", "epochs": 4, "timestep": 6591, "ep_reward": 337.1887512207031, "reward": 0.8664801716804504, "action": -0.638060450553894}
{"mode": "train", "epochs": 4, "timestep": 6592, "ep_reward": 338.0704040527344, "reward": 0.8816603422164917, "action": 0.43006980419158936}
{"mode": "train", "epochs": 4, "timestep": 6593, "ep_reward": 338.9612121582031, "reward": 0.8907991647720337, "action": -1.1478501558303833}
{"mode": "train", "epochs": 4, "timestep": 6594, "ep_reward": 339.8344421386719, "reward": 0.8732234239578247, "action": -0.7128157615661621}
{"mode": "train", "epochs": 4, "timestep": 6595, "ep_reward": 340.6764831542969, "reward": 0.8420549631118774, "action": -1.3348956108093262}
{"mode": "train", "epochs": 4, "timestep": 6596, "ep_reward": 341.4598083496094, "reward": 0.7833119034767151, "action": -0.546144962310791}
{"mode": "train", "epochs": 4, "timestep": 6597, "ep_reward": 342.16400146484375, "reward": 0.7041879892349243, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6598, "ep_reward": 342.7358703613281, "reward": 0.5718674659729004, "action": -1.089477300643921}
{"mode": "train", "epochs": 4, "timestep": 6599, "ep_reward": 343.1443786621094, "reward": 0.40849751234054565, "action": -0.34831106662750244}
{"mode": "train", "epochs": 4, "timestep": 6600, "ep_reward": 343.4324035644531, "reward": 0.2880131006240845, "action": -0.6458663940429688}
{"mode": "train", "epochs": 4, "timestep": 6601, "ep_reward": 343.5986328125, "reward": 0.16624337434768677, "action": -1.2061314582824707}
{"mode": "train", "epochs": 4, "timestep": 6602, "ep_reward": 343.62322998046875, "reward": 0.024593710899353027, "action": -0.7615112662315369}
{"mode": "train", "epochs": 4, "timestep": 6603, "ep_reward": 343.7158203125, "reward": 0.0925939679145813, "action": -1.1500910520553589}
{"mode": "train", "epochs": 4, "timestep": 6604, "ep_reward": 343.9446105957031, "reward": 0.22879838943481445, "action": -0.6422830820083618}
{"mode": "train", "epochs": 4, "timestep": 6605, "ep_reward": 344.31744384765625, "reward": 0.37283778190612793, "action": -1.1433762311935425}
{"mode": "train", "epochs": 4, "timestep": 6606, "ep_reward": 344.81878662109375, "reward": 0.5013442039489746, "action": -1.2310850620269775}
{"mode": "train", "epochs": 4, "timestep": 6607, "ep_reward": 345.43109130859375, "reward": 0.612311601638794, "action": -0.7242119312286377}
{"mode": "train", "epochs": 4, "timestep": 6608, "ep_reward": 346.13818359375, "reward": 0.707078218460083, "action": -0.9954183101654053}
{"mode": "train", "epochs": 4, "timestep": 6609, "ep_reward": 346.9141845703125, "reward": 0.7759996652603149, "action": -0.7634056806564331}
{"mode": "train", "epochs": 4, "timestep": 6610, "ep_reward": 347.7401428222656, "reward": 0.8259453177452087, "action": -1.1944104433059692}
{"mode": "train", "epochs": 4, "timestep": 6611, "ep_reward": 348.5936279296875, "reward": 0.8534829020500183, "action": -1.586280345916748}
{"mode": "train", "epochs": 4, "timestep": 6612, "ep_reward": 349.45477294921875, "reward": 0.8611594438552856, "action": -0.5399208068847656}
{"mode": "train", "epochs": 4, "timestep": 6613, "ep_reward": 350.315673828125, "reward": 0.860897958278656, "action": -1.023593783378601}
{"mode": "train", "epochs": 4, "timestep": 6614, "ep_reward": 351.1539306640625, "reward": 0.8382551670074463, "action": -0.8776130676269531}
{"mode": "train", "epochs": 4, "timestep": 6615, "ep_reward": 351.9490661621094, "reward": 0.7951290011405945, "action": -1.393707275390625}
{"mode": "train", "epochs": 4, "timestep": 6616, "ep_reward": 352.6678771972656, "reward": 0.7187991738319397, "action": -0.7027348875999451}
{"mode": "train", "epochs": 4, "timestep": 6617, "ep_reward": 353.28338623046875, "reward": 0.615522563457489, "action": -0.9246918559074402}
{"mode": "train", "epochs": 4, "timestep": 6618, "ep_reward": 353.7528076171875, "reward": 0.46940749883651733, "action": -1.3033552169799805}
{"mode": "train", "epochs": 4, "timestep": 6619, "ep_reward": 354.0882263183594, "reward": 0.3354142904281616, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6620, "ep_reward": 354.3109436035156, "reward": 0.22272294759750366, "action": -1.3626104593276978}
{"mode": "train", "epochs": 4, "timestep": 6621, "ep_reward": 354.40087890625, "reward": 0.0899236798286438, "action": -1.2037137746810913}
{"mode": "train", "epochs": 4, "timestep": 6622, "ep_reward": 354.4281005859375, "reward": 0.02720797061920166, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6623, "ep_reward": 354.59674072265625, "reward": 0.16865187883377075, "action": -1.48148512840271}
{"mode": "train", "epochs": 4, "timestep": 6624, "ep_reward": 354.8993225097656, "reward": 0.30258142948150635, "action": -1.0307990312576294}
{"mode": "train", "epochs": 4, "timestep": 6625, "ep_reward": 355.33856201171875, "reward": 0.4392513036727905, "action": -0.09253013134002686}
{"mode": "train", "epochs": 4, "timestep": 6626, "ep_reward": 355.91107177734375, "reward": 0.5725178122520447, "action": -0.9028452634811401}
{"mode": "train", "epochs": 4, "timestep": 6627, "ep_reward": 356.5850830078125, "reward": 0.6740121245384216, "action": -1.3824745416641235}
{"mode": "train", "epochs": 4, "timestep": 6628, "ep_reward": 357.3333435058594, "reward": 0.7482622265815735, "action": -1.5662825107574463}
{"mode": "train", "epochs": 4, "timestep": 6629, "ep_reward": 358.1333312988281, "reward": 0.7999935150146484, "action": -1.428554654121399}
{"mode": "train", "epochs": 4, "timestep": 6630, "ep_reward": 358.9671630859375, "reward": 0.8338373899459839, "action": -0.7324596643447876}
{"mode": "train", "epochs": 4, "timestep": 6631, "ep_reward": 359.82281494140625, "reward": 0.8556548953056335, "action": -0.3197770118713379}
{"mode": "train", "epochs": 4, "timestep": 6632, "ep_reward": 360.6864013671875, "reward": 0.863576352596283, "action": -1.0089601278305054}
{"mode": "train", "epochs": 4, "timestep": 6633, "ep_reward": 361.5343933105469, "reward": 0.8479779362678528, "action": -0.9198389649391174}
{"mode": "train", "epochs": 4, "timestep": 6634, "ep_reward": 362.3471374511719, "reward": 0.8127543926239014, "action": -1.611926555633545}
{"mode": "train", "epochs": 4, "timestep": 6635, "ep_reward": 363.0915222167969, "reward": 0.7443807125091553, "action": -1.992210865020752}
{"mode": "train", "epochs": 4, "timestep": 6636, "ep_reward": 363.72772216796875, "reward": 0.6361966729164124, "action": 0.32558584213256836}
{"mode": "train", "epochs": 4, "timestep": 6637, "ep_reward": 364.2461242675781, "reward": 0.5184042453765869, "action": -0.49858272075653076}
{"mode": "train", "epochs": 4, "timestep": 6638, "ep_reward": 364.612548828125, "reward": 0.36643677949905396, "action": -1.576885461807251}
{"mode": "train", "epochs": 4, "timestep": 6639, "ep_reward": 364.8724060058594, "reward": 0.25985294580459595, "action": -1.3646605014801025}
{"mode": "train", "epochs": 4, "timestep": 6640, "ep_reward": 365.0057373046875, "reward": 0.13333237171173096, "action": -0.4863549470901489}
{"mode": "train", "epochs": 4, "timestep": 6641, "ep_reward": 364.9924011230469, "reward": -0.013350486755371094, "action": -1.1031064987182617}
{"mode": "train", "epochs": 4, "timestep": 6642, "ep_reward": 365.119384765625, "reward": 0.1269964575767517, "action": -1.2680027484893799}
{"mode": "train", "epochs": 4, "timestep": 6643, "ep_reward": 365.3819580078125, "reward": 0.2625669836997986, "action": -1.5840672254562378}
{"mode": "train", "epochs": 4, "timestep": 6644, "ep_reward": 365.7759094238281, "reward": 0.39396607875823975, "action": -1.7038425207138062}
{"mode": "train", "epochs": 4, "timestep": 6645, "ep_reward": 366.2906188964844, "reward": 0.5147091150283813, "action": -1.2482192516326904}
{"mode": "train", "epochs": 4, "timestep": 6646, "ep_reward": 366.913818359375, "reward": 0.6232107877731323, "action": -0.5885601043701172}
{"mode": "train", "epochs": 4, "timestep": 6647, "ep_reward": 367.6292419433594, "reward": 0.7154116630554199, "action": -0.43378132581710815}
{"mode": "train", "epochs": 4, "timestep": 6648, "ep_reward": 368.4134216308594, "reward": 0.7841852307319641, "action": -0.5607300996780396}
{"mode": "train", "epochs": 4, "timestep": 6649, "ep_reward": 369.24267578125, "reward": 0.8292689323425293, "action": -0.411896288394928}
{"mode": "train", "epochs": 4, "timestep": 6650, "ep_reward": 370.0986633300781, "reward": 0.8559785485267639, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6651, "ep_reward": 370.95013427734375, "reward": 0.8514853119850159, "action": -0.9934326410293579}
{"mode": "train", "epochs": 4, "timestep": 6652, "ep_reward": 371.78717041015625, "reward": 0.8370372653007507, "action": -0.6051304340362549}
{"mode": "train", "epochs": 4, "timestep": 6653, "ep_reward": 372.592041015625, "reward": 0.8048809766769409, "action": -1.006710410118103}
{"mode": "train", "epochs": 4, "timestep": 6654, "ep_reward": 373.3347473144531, "reward": 0.7427080273628235, "action": -0.8224292397499084}
{"mode": "train", "epochs": 4, "timestep": 6655, "ep_reward": 373.98468017578125, "reward": 0.6499344110488892, "action": -0.815605878829956}
{"mode": "train", "epochs": 4, "timestep": 6656, "ep_reward": 374.50311279296875, "reward": 0.5184410810470581, "action": -1.0936102867126465}
{"mode": "train", "epochs": 4, "timestep": 6657, "ep_reward": 374.8724060058594, "reward": 0.36930739879608154, "action": 0.04270744323730469}
{"mode": "train", "epochs": 4, "timestep": 6658, "ep_reward": 375.1356506347656, "reward": 0.2632462978363037, "action": -0.1856362223625183}
{"mode": "train", "epochs": 4, "timestep": 6659, "ep_reward": 375.2727966308594, "reward": 0.13715308904647827, "action": -0.7673678398132324}
{"mode": "train", "epochs": 4, "timestep": 6660, "ep_reward": 375.26385498046875, "reward": -0.008945584297180176, "action": -1.1141431331634521}
{"mode": "train", "epochs": 4, "timestep": 6661, "ep_reward": 375.3869323730469, "reward": 0.12306714057922363, "action": -1.5254297256469727}
{"mode": "train", "epochs": 4, "timestep": 6662, "ep_reward": 375.6424255371094, "reward": 0.25548356771469116, "action": -0.07140976190567017}
{"mode": "train", "epochs": 4, "timestep": 6663, "ep_reward": 376.0486755371094, "reward": 0.4062379002571106, "action": -0.7598243355751038}
{"mode": "train", "epochs": 4, "timestep": 6664, "ep_reward": 376.5839538574219, "reward": 0.5352845191955566, "action": -1.269331455230713}
{"mode": "train", "epochs": 4, "timestep": 6665, "ep_reward": 377.2239990234375, "reward": 0.6400601863861084, "action": -0.5399986505508423}
{"mode": "train", "epochs": 4, "timestep": 6666, "ep_reward": 377.9546813964844, "reward": 0.7306687831878662, "action": -1.062240719795227}
{"mode": "train", "epochs": 4, "timestep": 6667, "ep_reward": 378.7483215332031, "reward": 0.7936323881149292, "action": -1.564115285873413}
{"mode": "train", "epochs": 4, "timestep": 6668, "ep_reward": 379.5812072753906, "reward": 0.8328786492347717, "action": -1.3244118690490723}
{"mode": "train", "epochs": 4, "timestep": 6669, "ep_reward": 380.4381408691406, "reward": 0.8569313883781433, "action": -1.739194393157959}
{"mode": "train", "epochs": 4, "timestep": 6670, "ep_reward": 381.2994079589844, "reward": 0.8612668514251709, "action": -0.3160076141357422}
{"mode": "train", "epochs": 4, "timestep": 6671, "ep_reward": 382.1601867675781, "reward": 0.8607921600341797, "action": -1.431199550628662}
{"mode": "train", "epochs": 4, "timestep": 6672, "ep_reward": 382.9921875, "reward": 0.8319994211196899, "action": -1.1866512298583984}
{"mode": "train", "epochs": 4, "timestep": 6673, "ep_reward": 383.7743225097656, "reward": 0.7821359634399414, "action": -1.5133907794952393}
{"mode": "train", "epochs": 4, "timestep": 6674, "ep_reward": 384.47308349609375, "reward": 0.6987646818161011, "action": -1.3343064785003662}
{"mode": "train", "epochs": 4, "timestep": 6675, "ep_reward": 385.0523986816406, "reward": 0.5793260335922241, "action": -0.940917432308197}
{"mode": "train", "epochs": 4, "timestep": 6676, "ep_reward": 385.4745788574219, "reward": 0.4221823811531067, "action": -0.9323607683181763}
{"mode": "train", "epochs": 4, "timestep": 6677, "ep_reward": 385.78936767578125, "reward": 0.31478768587112427, "action": -1.1015124320983887}
{"mode": "train", "epochs": 4, "timestep": 6678, "ep_reward": 385.9873962402344, "reward": 0.19803661108016968, "action": -0.721039891242981}
{"mode": "train", "epochs": 4, "timestep": 6679, "ep_reward": 386.0486755371094, "reward": 0.061274588108062744, "action": -0.10189664363861084}
{"mode": "train", "epochs": 4, "timestep": 6680, "ep_reward": 386.1057434082031, "reward": 0.05707085132598877, "action": -0.6525288820266724}
{"mode": "train", "epochs": 4, "timestep": 6681, "ep_reward": 386.3040771484375, "reward": 0.19831883907318115, "action": -1.1109758615493774}
{"mode": "train", "epochs": 4, "timestep": 6682, "ep_reward": 386.64056396484375, "reward": 0.33647972345352173, "action": -0.3747220039367676}
{"mode": "train", "epochs": 4, "timestep": 6683, "ep_reward": 387.1180419921875, "reward": 0.47748619318008423, "action": -0.5133326053619385}
{"mode": "train", "epochs": 4, "timestep": 6684, "ep_reward": 387.71771240234375, "reward": 0.5996677875518799, "action": -0.6485242247581482}
{"mode": "train", "epochs": 4, "timestep": 6685, "ep_reward": 388.41619873046875, "reward": 0.6984736919403076, "action": -0.6403437256813049}
{"mode": "train", "epochs": 4, "timestep": 6686, "ep_reward": 389.19085693359375, "reward": 0.7746505737304688, "action": -1.3044564723968506}
{"mode": "train", "epochs": 4, "timestep": 6687, "ep_reward": 390.0155334472656, "reward": 0.8246626853942871, "action": -0.6552047729492188}
{"mode": "train", "epochs": 4, "timestep": 6688, "ep_reward": 390.87811279296875, "reward": 0.8625742197036743, "action": -1.3844120502471924}
{"mode": "train", "epochs": 4, "timestep": 6689, "ep_reward": 391.757568359375, "reward": 0.8794475197792053, "action": -0.6236342191696167}
{"mode": "train", "epochs": 4, "timestep": 6690, "ep_reward": 392.6457824707031, "reward": 0.8882269859313965, "action": 0.022678136825561523}
{"mode": "train", "epochs": 4, "timestep": 6691, "ep_reward": 393.5339050292969, "reward": 0.8881188035011292, "action": -1.2956335544586182}
{"mode": "train", "epochs": 4, "timestep": 6692, "ep_reward": 394.3964538574219, "reward": 0.8625456094741821, "action": -1.605857491493225}
{"mode": "train", "epochs": 4, "timestep": 6693, "ep_reward": 395.2109069824219, "reward": 0.8144516348838806, "action": -1.0260412693023682}
{"mode": "train", "epochs": 4, "timestep": 6694, "ep_reward": 395.9569091796875, "reward": 0.7459989786148071, "action": -0.11139917373657227}
{"mode": "train", "epochs": 4, "timestep": 6695, "ep_reward": 396.6139831542969, "reward": 0.6570637226104736, "action": -1.635014533996582}
{"mode": "train", "epochs": 4, "timestep": 6696, "ep_reward": 397.1260070800781, "reward": 0.5120334029197693, "action": -1.4873955249786377}
{"mode": "train", "epochs": 4, "timestep": 6697, "ep_reward": 397.4743347167969, "reward": 0.34831559658050537, "action": -1.00627863407135}
{"mode": "train", "epochs": 4, "timestep": 6698, "ep_reward": 397.71234130859375, "reward": 0.2379963994026184, "action": -0.9850842952728271}
{"mode": "train", "epochs": 4, "timestep": 6699, "ep_reward": 397.8200378417969, "reward": 0.10770118236541748, "action": -0.7448115944862366}
{"mode": "train", "epochs": 4, "timestep": 6700, "ep_reward": 397.82830810546875, "reward": 0.00827038288116455, "action": -1.185767412185669}
{"mode": "train", "epochs": 4, "timestep": 6701, "ep_reward": 397.9803771972656, "reward": 0.15207284688949585, "action": -1.3846886157989502}
{"mode": "train", "epochs": 4, "timestep": 6702, "ep_reward": 398.267333984375, "reward": 0.28694450855255127, "action": -0.1219702959060669}
{"mode": "train", "epochs": 4, "timestep": 6703, "ep_reward": 398.7024230957031, "reward": 0.4350805878639221, "action": -1.4732186794281006}
{"mode": "train", "epochs": 4, "timestep": 6704, "ep_reward": 399.255126953125, "reward": 0.5527007579803467, "action": -0.499455988407135}
{"mode": "train", "epochs": 4, "timestep": 6705, "ep_reward": 399.91717529296875, "reward": 0.6620539426803589, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6706, "ep_reward": 400.650634765625, "reward": 0.7334697246551514, "action": -1.4099541902542114}
{"mode": "train", "epochs": 4, "timestep": 6707, "ep_reward": 401.4407653808594, "reward": 0.790128767490387, "action": -1.663574457168579}
{"mode": "train", "epochs": 4, "timestep": 6708, "ep_reward": 402.2654113769531, "reward": 0.8246355652809143, "action": -0.5691007375717163}
{"mode": "train", "epochs": 4, "timestep": 6709, "ep_reward": 403.1155700683594, "reward": 0.8501498103141785, "action": -0.6538548469543457}
{"mode": "train", "epochs": 4, "timestep": 6710, "ep_reward": 403.9723815917969, "reward": 0.8568044900894165, "action": -0.3833274841308594}
{"mode": "train", "epochs": 4, "timestep": 6711, "ep_reward": 404.8200988769531, "reward": 0.8477112054824829, "action": -1.623366355895996}
{"mode": "train", "epochs": 4, "timestep": 6712, "ep_reward": 405.626708984375, "reward": 0.8066048622131348, "action": -0.6653041839599609}
{"mode": "train", "epochs": 4, "timestep": 6713, "ep_reward": 406.3755798339844, "reward": 0.7488566637039185, "action": -1.1508830785751343}
{"mode": "train", "epochs": 4, "timestep": 6714, "ep_reward": 407.0290222167969, "reward": 0.6534560918807983, "action": -1.3790218830108643}
{"mode": "train", "epochs": 4, "timestep": 6715, "ep_reward": 407.5436706542969, "reward": 0.5146611332893372, "action": -1.2386527061462402}
{"mode": "train", "epochs": 4, "timestep": 6716, "ep_reward": 407.914306640625, "reward": 0.37063974142074585, "action": 0.1648402214050293}
{"mode": "train", "epochs": 4, "timestep": 6717, "ep_reward": 408.1791687011719, "reward": 0.2648535966873169, "action": -0.3298867344856262}
{"mode": "train", "epochs": 4, "timestep": 6718, "ep_reward": 408.3182373046875, "reward": 0.13907301425933838, "action": -0.3321819305419922}
{"mode": "train", "epochs": 4, "timestep": 6719, "ep_reward": 408.3115234375, "reward": -0.006712794303894043, "action": -0.45527392625808716}
{"mode": "train", "epochs": 4, "timestep": 6720, "ep_reward": 408.43255615234375, "reward": 0.12104034423828125, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6721, "ep_reward": 408.6821594238281, "reward": 0.24959927797317505, "action": -1.0346579551696777}
{"mode": "train", "epochs": 4, "timestep": 6722, "ep_reward": 409.0716857910156, "reward": 0.3895242214202881, "action": -0.4999235272407532}
{"mode": "train", "epochs": 4, "timestep": 6723, "ep_reward": 409.5965881347656, "reward": 0.5248873233795166, "action": -0.964091420173645}
{"mode": "train", "epochs": 4, "timestep": 6724, "ep_reward": 410.2312927246094, "reward": 0.6346990466117859, "action": -1.1460003852844238}
{"mode": "train", "epochs": 4, "timestep": 6725, "ep_reward": 410.9512634277344, "reward": 0.7199825048446655, "action": -0.9749111533164978}
{"mode": "train", "epochs": 4, "timestep": 6726, "ep_reward": 411.7355651855469, "reward": 0.7843167781829834, "action": -1.3452247381210327}
{"mode": "train", "epochs": 4, "timestep": 6727, "ep_reward": 412.5598449707031, "reward": 0.8242908716201782, "action": -1.7819300889968872}
{"mode": "train", "epochs": 4, "timestep": 6728, "ep_reward": 413.4017028808594, "reward": 0.8418490886688232, "action": -1.0711203813552856}
{"mode": "train", "epochs": 4, "timestep": 6729, "ep_reward": 414.2491149902344, "reward": 0.847406804561615, "action": -1.090230941772461}
{"mode": "train", "epochs": 4, "timestep": 6730, "ep_reward": 415.0826110839844, "reward": 0.8334929347038269, "action": -0.5364104509353638}
{"mode": "train", "epochs": 4, "timestep": 6731, "ep_reward": 415.8857727050781, "reward": 0.8031525611877441, "action": -0.709060788154602}
{"mode": "train", "epochs": 4, "timestep": 6732, "ep_reward": 416.63092041015625, "reward": 0.7451330423355103, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6733, "ep_reward": 417.2692565917969, "reward": 0.638321578502655, "action": -1.0772085189819336}
{"mode": "train", "epochs": 4, "timestep": 6734, "ep_reward": 417.76953125, "reward": 0.5002881288528442, "action": -1.8701682090759277}
{"mode": "train", "epochs": 4, "timestep": 6735, "ep_reward": 418.13861083984375, "reward": 0.36908501386642456, "action": 0.06971538066864014}
{"mode": "train", "epochs": 4, "timestep": 6736, "ep_reward": 418.4015197753906, "reward": 0.26291847229003906, "action": -0.9919611811637878}
{"mode": "train", "epochs": 4, "timestep": 6737, "ep_reward": 418.53839111328125, "reward": 0.13686949014663696, "action": 0.3009660243988037}
{"mode": "train", "epochs": 4, "timestep": 6738, "ep_reward": 418.5291442871094, "reward": -0.00924980640411377, "action": -0.5784106850624084}
{"mode": "train", "epochs": 4, "timestep": 6739, "ep_reward": 418.65264892578125, "reward": 0.12349528074264526, "action": -0.7655438184738159}
{"mode": "train", "epochs": 4, "timestep": 6740, "ep_reward": 418.91796875, "reward": 0.2653306722640991, "action": -0.7970337867736816}
{"mode": "train", "epochs": 4, "timestep": 6741, "ep_reward": 419.3232421875, "reward": 0.40527957677841187, "action": -0.9299558997154236}
{"mode": "train", "epochs": 4, "timestep": 6742, "ep_reward": 419.8558044433594, "reward": 0.5325522422790527, "action": -0.24472248554229736}
{"mode": "train", "epochs": 4, "timestep": 6743, "ep_reward": 420.5040588378906, "reward": 0.6482393741607666, "action": -1.9583783149719238}
{"mode": "train", "epochs": 4, "timestep": 6744, "ep_reward": 421.22808837890625, "reward": 0.7240297794342041, "action": -1.2506072521209717}
{"mode": "train", "epochs": 4, "timestep": 6745, "ep_reward": 422.0147705078125, "reward": 0.7866963148117065, "action": -0.20639574527740479}
{"mode": "train", "epochs": 4, "timestep": 6746, "ep_reward": 422.8531494140625, "reward": 0.8383830785751343, "action": -0.8504576683044434}
{"mode": "train", "epochs": 4, "timestep": 6747, "ep_reward": 423.7193298339844, "reward": 0.8661808967590332, "action": -1.8038082122802734}
{"mode": "train", "epochs": 4, "timestep": 6748, "ep_reward": 424.5902404785156, "reward": 0.8709068894386292, "action": -0.6490569710731506}
{"mode": "train", "epochs": 4, "timestep": 6749, "ep_reward": 425.4596862792969, "reward": 0.8694333434104919, "action": -0.7227777242660522}
{"mode": "train", "epochs": 4, "timestep": 6750, "ep_reward": 426.3101501464844, "reward": 0.8504654169082642, "action": -0.6085748672485352}
{"mode": "train", "epochs": 4, "timestep": 6751, "ep_reward": 427.1228942871094, "reward": 0.8127293586730957, "action": -1.0012290477752686}
{"mode": "train", "epochs": 4, "timestep": 6752, "ep_reward": 427.86895751953125, "reward": 0.7460510730743408, "action": -1.5790963172912598}
{"mode": "train", "epochs": 4, "timestep": 6753, "ep_reward": 428.5085754394531, "reward": 0.639617383480072, "action": -1.0631036758422852}
{"mode": "train", "epochs": 4, "timestep": 6754, "ep_reward": 429.007568359375, "reward": 0.4990052580833435, "action": -1.216338872909546}
{"mode": "train", "epochs": 4, "timestep": 6755, "ep_reward": 429.35791015625, "reward": 0.3503473401069641, "action": -0.6619640588760376}
{"mode": "train", "epochs": 4, "timestep": 6756, "ep_reward": 429.5982666015625, "reward": 0.2403697967529297, "action": -1.143372654914856}
{"mode": "train", "epochs": 4, "timestep": 6757, "ep_reward": 429.7086181640625, "reward": 0.11035215854644775, "action": -1.6819205284118652}
{"mode": "train", "epochs": 4, "timestep": 6758, "ep_reward": 429.7138366699219, "reward": 0.005210995674133301, "action": -1.1093624830245972}
{"mode": "train", "epochs": 4, "timestep": 6759, "ep_reward": 429.8633117675781, "reward": 0.14946430921554565, "action": -0.9523314833641052}
{"mode": "train", "epochs": 4, "timestep": 6760, "ep_reward": 430.1529541015625, "reward": 0.2896440029144287, "action": -0.14650744199752808}
{"mode": "train", "epochs": 4, "timestep": 6761, "ep_reward": 430.5895080566406, "reward": 0.4365570545196533, "action": -0.5564037561416626}
{"mode": "train", "epochs": 4, "timestep": 6762, "ep_reward": 431.1532287597656, "reward": 0.563723623752594, "action": -0.8345078229904175}
{"mode": "train", "epochs": 4, "timestep": 6763, "ep_reward": 431.82098388671875, "reward": 0.6677467226982117, "action": -0.9082564115524292}
{"mode": "train", "epochs": 4, "timestep": 6764, "ep_reward": 432.5700988769531, "reward": 0.7491092681884766, "action": -1.57878839969635}
{"mode": "train", "epochs": 4, "timestep": 6765, "ep_reward": 433.3740539550781, "reward": 0.8039689064025879, "action": -0.9044056534767151}
{"mode": "train", "epochs": 4, "timestep": 6766, "ep_reward": 434.22039794921875, "reward": 0.8463554978370667, "action": -1.8634257316589355}
{"mode": "train", "epochs": 4, "timestep": 6767, "ep_reward": 435.0851135253906, "reward": 0.864712655544281, "action": -0.9443526268005371}
{"mode": "train", "epochs": 4, "timestep": 6768, "ep_reward": 435.96044921875, "reward": 0.8753477334976196, "action": -0.6420426964759827}
{"mode": "train", "epochs": 4, "timestep": 6769, "ep_reward": 436.8335266113281, "reward": 0.8730769753456116, "action": -0.7951149344444275}
{"mode": "train", "epochs": 4, "timestep": 6770, "ep_reward": 437.6863708496094, "reward": 0.852832555770874, "action": -1.9372811317443848}
{"mode": "train", "epochs": 4, "timestep": 6771, "ep_reward": 438.4879150390625, "reward": 0.8015444278717041, "action": -0.19973385334014893}
{"mode": "train", "epochs": 4, "timestep": 6772, "ep_reward": 439.22894287109375, "reward": 0.7410405278205872, "action": -0.8149555921554565}
{"mode": "train", "epochs": 4, "timestep": 6773, "ep_reward": 439.8714294433594, "reward": 0.6424748301506042, "action": -1.2599328756332397}
{"mode": "train", "epochs": 4, "timestep": 6774, "ep_reward": 440.3706359863281, "reward": 0.49921315908432007, "action": -0.9895461201667786}
{"mode": "train", "epochs": 4, "timestep": 6775, "ep_reward": 440.7178039550781, "reward": 0.3471701741218567, "action": -0.5989285707473755}
{"mode": "train", "epochs": 4, "timestep": 6776, "ep_reward": 440.9543762207031, "reward": 0.23657888174057007, "action": -0.9433214068412781}
{"mode": "train", "epochs": 4, "timestep": 6777, "ep_reward": 441.06024169921875, "reward": 0.10587221384048462, "action": -1.810368299484253}
{"mode": "train", "epochs": 4, "timestep": 6778, "ep_reward": 441.0703125, "reward": 0.010056614875793457, "action": -1.3701330423355103}
{"mode": "train", "epochs": 4, "timestep": 6779, "ep_reward": 441.22406005859375, "reward": 0.15374398231506348, "action": -0.6710622310638428}
{"mode": "train", "epochs": 4, "timestep": 6780, "ep_reward": 441.5213928222656, "reward": 0.2973238229751587, "action": -1.6285009384155273}
{"mode": "train", "epochs": 4, "timestep": 6781, "ep_reward": 441.9468688964844, "reward": 0.4254612922668457, "action": -1.9713783264160156}
{"mode": "train", "epochs": 4, "timestep": 6782, "ep_reward": 442.4859313964844, "reward": 0.5390674471855164, "action": -0.9886364936828613}
{"mode": "train", "epochs": 4, "timestep": 6783, "ep_reward": 443.1318664550781, "reward": 0.6459372043609619, "action": -0.250476598739624}
{"mode": "train", "epochs": 4, "timestep": 6784, "ep_reward": 443.8682556152344, "reward": 0.7363787889480591, "action": -1.1776286363601685}
{"mode": "train", "epochs": 4, "timestep": 6785, "ep_reward": 444.6617431640625, "reward": 0.793492317199707, "action": -1.9686188697814941}
{"mode": "train", "epochs": 4, "timestep": 6786, "ep_reward": 445.4849548339844, "reward": 0.8232211470603943, "action": -1.5807652473449707}
{"mode": "train", "epochs": 4, "timestep": 6787, "ep_reward": 446.3224792480469, "reward": 0.8375215530395508, "action": -1.6987178325653076}
{"mode": "train", "epochs": 4, "timestep": 6788, "ep_reward": 447.153564453125, "reward": 0.8310942053794861, "action": -1.5318548679351807}
{"mode": "train", "epochs": 4, "timestep": 6789, "ep_reward": 447.9576110839844, "reward": 0.8040540218353271, "action": -1.164271354675293}
{"mode": "train", "epochs": 4, "timestep": 6790, "ep_reward": 448.7118225097656, "reward": 0.7542203068733215, "action": -0.38111215829849243}
{"mode": "train", "epochs": 4, "timestep": 6791, "ep_reward": 449.3935546875, "reward": 0.6817376613616943, "action": -1.0808781385421753}
{"mode": "train", "epochs": 4, "timestep": 6792, "ep_reward": 449.9563293457031, "reward": 0.5627655982971191, "action": -1.0856640338897705}
{"mode": "train", "epochs": 4, "timestep": 6793, "ep_reward": 450.3677673339844, "reward": 0.4114310145378113, "action": -1.0737839937210083}
{"mode": "train", "epochs": 4, "timestep": 6794, "ep_reward": 450.682373046875, "reward": 0.31459468603134155, "action": -1.1140092611312866}
{"mode": "train", "epochs": 4, "timestep": 6795, "ep_reward": 450.880126953125, "reward": 0.197767972946167, "action": -1.0885214805603027}
{"mode": "train", "epochs": 4, "timestep": 6796, "ep_reward": 450.9410095214844, "reward": 0.06087338924407959, "action": -1.4913005828857422}
{"mode": "train", "epochs": 4, "timestep": 6797, "ep_reward": 450.998291015625, "reward": 0.05727726221084595, "action": -1.1593246459960938}
{"mode": "train", "epochs": 4, "timestep": 6798, "ep_reward": 451.1927490234375, "reward": 0.19446057081222534, "action": -1.9048317670822144}
{"mode": "train", "epochs": 4, "timestep": 6799, "ep_reward": 451.5162353515625, "reward": 0.323478639125824, "action": -1.138277292251587}
{"mode": "train", "epochs": 4, "timestep": 6800, "ep_reward": 451.97430419921875, "reward": 0.4580817222595215, "action": -1.3439908027648926}
{"mode": "train", "epochs": 4, "timestep": 6801, "ep_reward": 452.549072265625, "reward": 0.5747772455215454, "action": -1.4812684059143066}
{"mode": "train", "epochs": 4, "timestep": 6802, "ep_reward": 453.2178649902344, "reward": 0.6688068509101868, "action": -1.1515979766845703}
{"mode": "train", "epochs": 4, "timestep": 6803, "ep_reward": 453.9606628417969, "reward": 0.742795467376709, "action": -1.4000219106674194}
{"mode": "train", "epochs": 4, "timestep": 6804, "ep_reward": 454.751708984375, "reward": 0.7910441160202026, "action": -0.03012901544570923}
{"mode": "train", "epochs": 4, "timestep": 6805, "ep_reward": 455.5821228027344, "reward": 0.830413281917572, "action": -1.269341230392456}
{"mode": "train", "epochs": 4, "timestep": 6806, "ep_reward": 456.41986083984375, "reward": 0.8377286195755005, "action": -0.5423411130905151}
{"mode": "train", "epochs": 4, "timestep": 6807, "ep_reward": 457.2516174316406, "reward": 0.831749677658081, "action": -0.6271544694900513}
{"mode": "train", "epochs": 4, "timestep": 6808, "ep_reward": 458.0545959472656, "reward": 0.8029761910438538, "action": -1.9687752723693848}
{"mode": "train", "epochs": 4, "timestep": 6809, "ep_reward": 458.7875671386719, "reward": 0.732961118221283, "action": -1.3818387985229492}
{"mode": "train", "epochs": 4, "timestep": 6810, "ep_reward": 459.4208068847656, "reward": 0.6332376599311829, "action": -1.3105225563049316}
{"mode": "train", "epochs": 4, "timestep": 6811, "ep_reward": 459.9122619628906, "reward": 0.4914604425430298, "action": -0.6379436254501343}
{"mode": "train", "epochs": 4, "timestep": 6812, "ep_reward": 460.28448486328125, "reward": 0.3722190856933594, "action": -0.7110224962234497}
{"mode": "train", "epochs": 4, "timestep": 6813, "ep_reward": 460.55126953125, "reward": 0.2667989730834961, "action": -0.34276944398880005}
{"mode": "train", "epochs": 4, "timestep": 6814, "ep_reward": 460.6925964355469, "reward": 0.14132118225097656, "action": -0.8137142062187195}
{"mode": "train", "epochs": 4, "timestep": 6815, "ep_reward": 460.6883850097656, "reward": -0.0042029619216918945, "action": -1.3987922668457031}
{"mode": "train", "epochs": 4, "timestep": 6816, "ep_reward": 460.80718994140625, "reward": 0.11879432201385498, "action": -1.6200748682022095}
{"mode": "train", "epochs": 4, "timestep": 6817, "ep_reward": 461.0570373535156, "reward": 0.24986016750335693, "action": -0.8798333406448364}
{"mode": "train", "epochs": 4, "timestep": 6818, "ep_reward": 461.4482727050781, "reward": 0.3912202715873718, "action": -0.9350923299789429}
{"mode": "train", "epochs": 4, "timestep": 6819, "ep_reward": 461.9692687988281, "reward": 0.5209993720054626, "action": -0.7074408531188965}
{"mode": "train", "epochs": 4, "timestep": 6820, "ep_reward": 462.60357666015625, "reward": 0.6343008279800415, "action": -0.7776763439178467}
{"mode": "train", "epochs": 4, "timestep": 6821, "ep_reward": 463.32696533203125, "reward": 0.7233771681785583, "action": -1.6559187173843384}
{"mode": "train", "epochs": 4, "timestep": 6822, "ep_reward": 464.1084289550781, "reward": 0.7814648151397705, "action": -1.4009618759155273}
{"mode": "train", "epochs": 4, "timestep": 6823, "ep_reward": 464.9304504394531, "reward": 0.8220213651657104, "action": -1.1702098846435547}
{"mode": "train", "epochs": 4, "timestep": 6824, "ep_reward": 465.7762145996094, "reward": 0.8457678556442261, "action": -1.443689227104187}
{"mode": "train", "epochs": 4, "timestep": 6825, "ep_reward": 466.625244140625, "reward": 0.8490365743637085, "action": -1.0335164070129395}
{"mode": "train", "epochs": 4, "timestep": 6826, "ep_reward": 467.4622497558594, "reward": 0.8369919061660767, "action": -0.9384710192680359}
{"mode": "train", "epochs": 4, "timestep": 6827, "ep_reward": 468.26654052734375, "reward": 0.8042859435081482, "action": -0.9310232400894165}
{"mode": "train", "epochs": 4, "timestep": 6828, "ep_reward": 469.0120544433594, "reward": 0.7455138564109802, "action": -0.48581230640411377}
{"mode": "train", "epochs": 4, "timestep": 6829, "ep_reward": 469.67193603515625, "reward": 0.6598913073539734, "action": -1.2038871049880981}
{"mode": "train", "epochs": 4, "timestep": 6830, "ep_reward": 470.19854736328125, "reward": 0.5266178846359253, "action": -0.6600056886672974}
{"mode": "train", "epochs": 4, "timestep": 6831, "ep_reward": 470.5764465332031, "reward": 0.3778992295265198, "action": -1.9296669960021973}
{"mode": "train", "epochs": 4, "timestep": 6832, "ep_reward": 470.8502502441406, "reward": 0.2738117575645447, "action": -1.3632357120513916}
{"mode": "train", "epochs": 4, "timestep": 6833, "ep_reward": 470.99993896484375, "reward": 0.14968037605285645, "action": -0.8400573134422302}
{"mode": "train", "epochs": 4, "timestep": 6834, "ep_reward": 471.00543212890625, "reward": 0.005500435829162598, "action": -0.5844571590423584}
{"mode": "train", "epochs": 4, "timestep": 6835, "ep_reward": 471.1156921386719, "reward": 0.11025726795196533, "action": -0.9755708575248718}
{"mode": "train", "epochs": 4, "timestep": 6836, "ep_reward": 471.36480712890625, "reward": 0.24910736083984375, "action": -1.033691167831421}
{"mode": "train", "epochs": 4, "timestep": 6837, "ep_reward": 471.7521057128906, "reward": 0.3872934579849243, "action": -1.0015549659729004}
{"mode": "train", "epochs": 4, "timestep": 6838, "ep_reward": 472.26824951171875, "reward": 0.5161469578742981, "action": -1.2267886400222778}
{"mode": "train", "epochs": 4, "timestep": 6839, "ep_reward": 472.8929138183594, "reward": 0.6246669888496399, "action": -1.059101939201355}
{"mode": "train", "epochs": 4, "timestep": 6840, "ep_reward": 473.60601806640625, "reward": 0.7131037712097168, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6841, "ep_reward": 474.3764343261719, "reward": 0.770404577255249, "action": -0.6279712915420532}
{"mode": "train", "epochs": 4, "timestep": 6842, "ep_reward": 475.19647216796875, "reward": 0.8200497031211853, "action": -1.2277250289916992}
{"mode": "train", "epochs": 4, "timestep": 6843, "ep_reward": 476.04107666015625, "reward": 0.8446031808853149, "action": -0.368196964263916}
{"mode": "train", "epochs": 4, "timestep": 6844, "ep_reward": 476.8996887207031, "reward": 0.8586188554763794, "action": -1.1379060745239258}
{"mode": "train", "epochs": 4, "timestep": 6845, "ep_reward": 477.7477111816406, "reward": 0.8480101823806763, "action": -0.10738563537597656}
{"mode": "train", "epochs": 4, "timestep": 6846, "ep_reward": 478.5750732421875, "reward": 0.8273568153381348, "action": -0.7816327214241028}
{"mode": "train", "epochs": 4, "timestep": 6847, "ep_reward": 479.3527526855469, "reward": 0.7776700854301453, "action": -0.09759879112243652}
{"mode": "train", "epochs": 4, "timestep": 6848, "ep_reward": 480.0601806640625, "reward": 0.7074295282363892, "action": -1.8495192527770996}
{"mode": "train", "epochs": 4, "timestep": 6849, "ep_reward": 480.64117431640625, "reward": 0.580998420715332, "action": -0.8579400777816772}
{"mode": "train", "epochs": 4, "timestep": 6850, "ep_reward": 481.06591796875, "reward": 0.42473793029785156, "action": -1.310954213142395}
{"mode": "train", "epochs": 4, "timestep": 6851, "ep_reward": 481.3725891113281, "reward": 0.30667704343795776, "action": -1.4275555610656738}
{"mode": "train", "epochs": 4, "timestep": 6852, "ep_reward": 481.56103515625, "reward": 0.18845629692077637, "action": -0.9382331371307373}
{"mode": "train", "epochs": 4, "timestep": 6853, "ep_reward": 481.6112365722656, "reward": 0.05019348859786987, "action": -0.6365045309066772}
{"mode": "train", "epochs": 4, "timestep": 6854, "ep_reward": 481.67919921875, "reward": 0.06796413660049438, "action": -1.3853994607925415}
{"mode": "train", "epochs": 4, "timestep": 6855, "ep_reward": 481.883056640625, "reward": 0.20386987924575806, "action": -1.113368272781372}
{"mode": "train", "epochs": 4, "timestep": 6856, "ep_reward": 482.2259521484375, "reward": 0.34288638830184937, "action": -0.12849754095077515}
{"mode": "train", "epochs": 4, "timestep": 6857, "ep_reward": 482.71270751953125, "reward": 0.4867505431175232, "action": -1.3060522079467773}
{"mode": "train", "epochs": 4, "timestep": 6858, "ep_reward": 483.311767578125, "reward": 0.5990711450576782, "action": -0.7613047361373901}
{"mode": "train", "epochs": 4, "timestep": 6859, "ep_reward": 484.0083312988281, "reward": 0.6965525150299072, "action": -1.0163421630859375}
{"mode": "train", "epochs": 4, "timestep": 6860, "ep_reward": 484.7768859863281, "reward": 0.7685667276382446, "action": -1.2922241687774658}
{"mode": "train", "epochs": 4, "timestep": 6861, "ep_reward": 485.59417724609375, "reward": 0.8172985911369324, "action": -1.0710252523422241}
{"mode": "train", "epochs": 4, "timestep": 6862, "ep_reward": 486.4436340332031, "reward": 0.8494671583175659, "action": -1.1615679264068604}
{"mode": "train", "epochs": 4, "timestep": 6863, "ep_reward": 487.3076171875, "reward": 0.8639922142028809, "action": -0.2116277813911438}
{"mode": "train", "epochs": 4, "timestep": 6864, "ep_reward": 488.17779541015625, "reward": 0.8701866865158081, "action": -0.5679256916046143}
{"mode": "train", "epochs": 4, "timestep": 6865, "ep_reward": 489.0345153808594, "reward": 0.8567147254943848, "action": -1.1670056581497192}
{"mode": "train", "epochs": 4, "timestep": 6866, "ep_reward": 489.8531799316406, "reward": 0.8186633586883545, "action": -0.1317504644393921}
{"mode": "train", "epochs": 4, "timestep": 6867, "ep_reward": 490.6202697753906, "reward": 0.7670807242393494, "action": -0.2428339719772339}
{"mode": "train", "epochs": 4, "timestep": 6868, "ep_reward": 491.30682373046875, "reward": 0.686555802822113, "action": -0.6396455764770508}
{"mode": "train", "epochs": 4, "timestep": 6869, "ep_reward": 491.87408447265625, "reward": 0.5672669410705566, "action": -0.35469335317611694}
{"mode": "train", "epochs": 4, "timestep": 6870, "ep_reward": 492.28826904296875, "reward": 0.41418254375457764, "action": -0.35410767793655396}
{"mode": "train", "epochs": 4, "timestep": 6871, "ep_reward": 492.5671081542969, "reward": 0.27884745597839355, "action": -1.7478885650634766}
{"mode": "train", "epochs": 4, "timestep": 6872, "ep_reward": 492.72283935546875, "reward": 0.15572667121887207, "action": -0.33117592334747314}
{"mode": "train", "epochs": 4, "timestep": 6873, "ep_reward": 492.7350158691406, "reward": 0.012179255485534668, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6874, "ep_reward": 492.83892822265625, "reward": 0.10391134023666382, "action": -1.2502639293670654}
{"mode": "train", "epochs": 4, "timestep": 6875, "ep_reward": 493.078125, "reward": 0.23920780420303345, "action": -0.5233775973320007}
{"mode": "train", "epochs": 4, "timestep": 6876, "ep_reward": 493.4626159667969, "reward": 0.38448989391326904, "action": -1.3899166584014893}
{"mode": "train", "epochs": 4, "timestep": 6877, "ep_reward": 493.9715881347656, "reward": 0.5089578032493591, "action": -1.067594289779663}
{"mode": "train", "epochs": 4, "timestep": 6878, "ep_reward": 494.5920715332031, "reward": 0.6204863786697388, "action": -0.3451277017593384}
{"mode": "train", "epochs": 4, "timestep": 6879, "ep_reward": 495.3091735839844, "reward": 0.717117190361023, "action": -1.0496667623519897}
{"mode": "train", "epochs": 4, "timestep": 6880, "ep_reward": 496.0923767089844, "reward": 0.7831891179084778, "action": -1.2096459865570068}
{"mode": "train", "epochs": 4, "timestep": 6881, "ep_reward": 496.9200134277344, "reward": 0.8276245594024658, "action": -0.06818336248397827}
{"mode": "train", "epochs": 4, "timestep": 6882, "ep_reward": 497.78350830078125, "reward": 0.8635011911392212, "action": -0.6249716281890869}
{"mode": "train", "epochs": 4, "timestep": 6883, "ep_reward": 498.66156005859375, "reward": 0.8780478835105896, "action": -1.8848850727081299}
{"mode": "train", "epochs": 4, "timestep": 6884, "ep_reward": 499.5285339355469, "reward": 0.8669863343238831, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6885, "ep_reward": 500.3651123046875, "reward": 0.8365845084190369, "action": -1.4467413425445557}
{"mode": "train", "epochs": 4, "timestep": 6886, "ep_reward": 501.15313720703125, "reward": 0.7880374789237976, "action": -0.6342740058898926}
{"mode": "train", "epochs": 4, "timestep": 6887, "ep_reward": 501.872802734375, "reward": 0.7196596264839172, "action": -1.1727240085601807}
{"mode": "train", "epochs": 4, "timestep": 6888, "ep_reward": 502.483154296875, "reward": 0.610339343547821, "action": -1.2934033870697021}
{"mode": "train", "epochs": 4, "timestep": 6889, "ep_reward": 502.9402770996094, "reward": 0.45712870359420776, "action": -1.503840684890747}
{"mode": "train", "epochs": 4, "timestep": 6890, "ep_reward": 503.2745666503906, "reward": 0.33429110050201416, "action": -1.8158788681030273}
{"mode": "train", "epochs": 4, "timestep": 6891, "ep_reward": 503.4959411621094, "reward": 0.22137761116027832, "action": -1.0399113893508911}
{"mode": "train", "epochs": 4, "timestep": 6892, "ep_reward": 503.5842590332031, "reward": 0.08831411600112915, "action": -1.1290297508239746}
{"mode": "train", "epochs": 4, "timestep": 6893, "ep_reward": 503.6133728027344, "reward": 0.02911442518234253, "action": -0.9624544382095337}
{"mode": "train", "epochs": 4, "timestep": 6894, "ep_reward": 503.7836608886719, "reward": 0.1702764630317688, "action": 0.05080223083496094}
{"mode": "train", "epochs": 4, "timestep": 6895, "ep_reward": 504.10675048828125, "reward": 0.3230865001678467, "action": -1.2109644412994385}
{"mode": "train", "epochs": 4, "timestep": 6896, "ep_reward": 504.5603942871094, "reward": 0.4536563754081726, "action": -1.1484521627426147}
{"mode": "train", "epochs": 4, "timestep": 6897, "ep_reward": 505.13250732421875, "reward": 0.5721044540405273, "action": -1.4695708751678467}
{"mode": "train", "epochs": 4, "timestep": 6898, "ep_reward": 505.80059814453125, "reward": 0.6680849194526672, "action": -0.7988318204879761}
{"mode": "train", "epochs": 4, "timestep": 6899, "ep_reward": 506.5498352050781, "reward": 0.7492305636405945, "action": -1.7379119396209717}
{"mode": "train", "epochs": 4, "timestep": 6900, "ep_reward": 507.3499755859375, "reward": 0.800129771232605, "action": -1.5599857568740845}
{"mode": "train", "epochs": 4, "timestep": 6901, "ep_reward": 508.1839599609375, "reward": 0.833983838558197, "action": -1.0249146223068237}
{"mode": "train", "epochs": 4, "timestep": 6902, "ep_reward": 509.0384826660156, "reward": 0.8545355796813965, "action": -1.752245545387268}
{"mode": "train", "epochs": 4, "timestep": 6903, "ep_reward": 509.889892578125, "reward": 0.8514037132263184, "action": -0.8472417593002319}
{"mode": "train", "epochs": 4, "timestep": 6904, "ep_reward": 510.7273864746094, "reward": 0.8374944925308228, "action": -0.3148549199104309}
{"mode": "train", "epochs": 4, "timestep": 6905, "ep_reward": 511.534912109375, "reward": 0.8075311779975891, "action": -1.3325586318969727}
{"mode": "train", "epochs": 4, "timestep": 6906, "ep_reward": 512.2764282226562, "reward": 0.7414894104003906, "action": -0.7081472873687744}
{"mode": "train", "epochs": 4, "timestep": 6907, "ep_reward": 512.92578125, "reward": 0.6493695378303528, "action": -1.3945302963256836}
{"mode": "train", "epochs": 4, "timestep": 6908, "ep_reward": 513.4343872070312, "reward": 0.5086164474487305, "action": -1.449639916419983}
{"mode": "train", "epochs": 4, "timestep": 6909, "ep_reward": 513.8008422851562, "reward": 0.3664373755455017, "action": -0.5852344036102295}
{"mode": "train", "epochs": 4, "timestep": 6910, "ep_reward": 514.0606079101562, "reward": 0.25979435443878174, "action": -0.47236114740371704}
{"mode": "train", "epochs": 4, "timestep": 6911, "ep_reward": 514.1936645507812, "reward": 0.13307899236679077, "action": -1.1280261278152466}
{"mode": "train", "epochs": 4, "timestep": 6912, "ep_reward": 514.179931640625, "reward": -0.0137406587600708, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6913, "ep_reward": 514.3070068359375, "reward": 0.12705159187316895, "action": -1.9397811889648438}
{"mode": "train", "epochs": 4, "timestep": 6914, "ep_reward": 514.561767578125, "reward": 0.25473546981811523, "action": -0.9618054628372192}
{"mode": "train", "epochs": 4, "timestep": 6915, "ep_reward": 514.957275390625, "reward": 0.395486056804657, "action": -0.6009517312049866}
{"mode": "train", "epochs": 4, "timestep": 6916, "ep_reward": 515.4862670898438, "reward": 0.5290189981460571, "action": 0.6087151765823364}
{"mode": "train", "epochs": 4, "timestep": 6917, "ep_reward": 516.1409301757812, "reward": 0.654670238494873, "action": -1.154807448387146}
{"mode": "train", "epochs": 4, "timestep": 6918, "ep_reward": 516.8772583007812, "reward": 0.7363381385803223, "action": -1.470353364944458}
{"mode": "train", "epochs": 4, "timestep": 6919, "ep_reward": 517.67138671875, "reward": 0.7941309809684753, "action": -1.3013018369674683}
{"mode": "train", "epochs": 4, "timestep": 6920, "ep_reward": 518.505859375, "reward": 0.834496796131134, "action": -0.703832745552063}
{"mode": "train", "epochs": 4, "timestep": 6921, "ep_reward": 519.3682250976562, "reward": 0.8623759746551514, "action": -0.7324483394622803}
{"mode": "train", "epochs": 4, "timestep": 6922, "ep_reward": 520.2420043945312, "reward": 0.873784601688385, "action": -0.47533583641052246}
{"mode": "train", "epochs": 4, "timestep": 6923, "ep_reward": 521.1136474609375, "reward": 0.8716568350791931, "action": -0.8602927327156067}
{"mode": "train", "epochs": 4, "timestep": 6924, "ep_reward": 521.963134765625, "reward": 0.8494962453842163, "action": -1.110426902770996}
{"mode": "train", "epochs": 4, "timestep": 6925, "ep_reward": 522.7675170898438, "reward": 0.8043590188026428, "action": -1.8077377080917358}
{"mode": "train", "epochs": 4, "timestep": 6926, "ep_reward": 523.491943359375, "reward": 0.724445104598999, "action": -1.3845211267471313}
{"mode": "train", "epochs": 4, "timestep": 6927, "ep_reward": 524.1048583984375, "reward": 0.6129101514816284, "action": -0.8963139653205872}
{"mode": "train", "epochs": 4, "timestep": 6928, "ep_reward": 524.5713500976562, "reward": 0.4664657711982727, "action": -0.8574485182762146}
{"mode": "train", "epochs": 4, "timestep": 6929, "ep_reward": 524.9049682617188, "reward": 0.3336482048034668, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6930, "ep_reward": 525.1255493164062, "reward": 0.22059905529022217, "action": -1.4471403360366821}
{"mode": "train", "epochs": 4, "timestep": 6931, "ep_reward": 525.2130737304688, "reward": 0.08752208948135376, "action": -0.8025736808776855}
{"mode": "train", "epochs": 4, "timestep": 6932, "ep_reward": 525.2431030273438, "reward": 0.030017077922821045, "action": -0.7249742150306702}
{"mode": "train", "epochs": 4, "timestep": 6933, "ep_reward": 525.4140625, "reward": 0.1709774136543274, "action": -0.9848962426185608}
{"mode": "train", "epochs": 4, "timestep": 6934, "ep_reward": 525.7252197265625, "reward": 0.3111424446105957, "action": -0.7313963174819946}
{"mode": "train", "epochs": 4, "timestep": 6935, "ep_reward": 526.175048828125, "reward": 0.4498511552810669, "action": -1.4715230464935303}
{"mode": "train", "epochs": 4, "timestep": 6936, "ep_reward": 526.74072265625, "reward": 0.565692663192749, "action": -1.0782735347747803}
{"mode": "train", "epochs": 4, "timestep": 6937, "ep_reward": 527.4072265625, "reward": 0.6665058135986328, "action": -1.857513427734375}
{"mode": "train", "epochs": 4, "timestep": 6938, "ep_reward": 528.14453125, "reward": 0.7372804880142212, "action": -0.3861108422279358}
{"mode": "train", "epochs": 4, "timestep": 6939, "ep_reward": 528.945068359375, "reward": 0.8005169630050659, "action": -1.7744083404541016}
{"mode": "train", "epochs": 4, "timestep": 6940, "ep_reward": 529.775390625, "reward": 0.83033287525177, "action": -0.6798771023750305}
{"mode": "train", "epochs": 4, "timestep": 6941, "ep_reward": 530.6267700195312, "reward": 0.8513944149017334, "action": -1.3670077323913574}
{"mode": "train", "epochs": 4, "timestep": 6942, "ep_reward": 531.4749145507812, "reward": 0.8481653928756714, "action": -1.2066794633865356}
{"mode": "train", "epochs": 4, "timestep": 6943, "ep_reward": 532.3015747070312, "reward": 0.8266571164131165, "action": -1.033860683441162}
{"mode": "train", "epochs": 4, "timestep": 6944, "ep_reward": 533.0848999023438, "reward": 0.7833139300346375, "action": -1.7580840587615967}
{"mode": "train", "epochs": 4, "timestep": 6945, "ep_reward": 533.7871704101562, "reward": 0.7022417783737183, "action": -0.7877582907676697}
{"mode": "train", "epochs": 4, "timestep": 6946, "ep_reward": 534.3823852539062, "reward": 0.5952295660972595, "action": -0.3518281579017639}
{"mode": "train", "epochs": 4, "timestep": 6947, "ep_reward": 534.8359985351562, "reward": 0.4535840153694153, "action": -0.4042975902557373}
{"mode": "train", "epochs": 4, "timestep": 6948, "ep_reward": 535.1709594726562, "reward": 0.3349565267562866, "action": -0.8556772470474243}
{"mode": "train", "epochs": 4, "timestep": 6949, "ep_reward": 535.3929443359375, "reward": 0.22199612855911255, "action": -0.9136397838592529}
{"mode": "train", "epochs": 4, "timestep": 6950, "ep_reward": 535.4818725585938, "reward": 0.08891946077346802, "action": -1.6758543252944946}
{"mode": "train", "epochs": 4, "timestep": 6951, "ep_reward": 535.51025390625, "reward": 0.028408288955688477, "action": -0.6054128408432007}
{"mode": "train", "epochs": 4, "timestep": 6952, "ep_reward": 535.6798095703125, "reward": 0.1695258617401123, "action": -1.312319040298462}
{"mode": "train", "epochs": 4, "timestep": 6953, "ep_reward": 535.9854125976562, "reward": 0.30560821294784546, "action": -0.7523791790008545}
{"mode": "train", "epochs": 4, "timestep": 6954, "ep_reward": 536.4305419921875, "reward": 0.4451150894165039, "action": -0.5207556486129761}
{"mode": "train", "epochs": 4, "timestep": 6955, "ep_reward": 537.0028686523438, "reward": 0.5723370313644409, "action": -1.5562570095062256}
{"mode": "train", "epochs": 4, "timestep": 6956, "ep_reward": 537.6701049804688, "reward": 0.6672594547271729, "action": -0.8202576041221619}
{"mode": "train", "epochs": 4, "timestep": 6957, "ep_reward": 538.4181518554688, "reward": 0.7480182647705078, "action": -0.8653164505958557}
{"mode": "train", "epochs": 4, "timestep": 6958, "ep_reward": 539.2240600585938, "reward": 0.8059210777282715, "action": -1.5150198936462402}
{"mode": "train", "epochs": 4, "timestep": 6959, "ep_reward": 540.0626220703125, "reward": 0.8385753035545349, "action": -0.9355747699737549}
{"mode": "train", "epochs": 4, "timestep": 6960, "ep_reward": 540.92138671875, "reward": 0.8587706685066223, "action": -0.36477112770080566}
{"mode": "train", "epochs": 4, "timestep": 6961, "ep_reward": 541.7882080078125, "reward": 0.866790771484375, "action": -1.62240469455719}
{"mode": "train", "epochs": 4, "timestep": 6962, "ep_reward": 542.6348266601562, "reward": 0.8466370105743408, "action": -1.4033925533294678}
{"mode": "train", "epochs": 4, "timestep": 6963, "ep_reward": 543.4420166015625, "reward": 0.8071961402893066, "action": -1.2606604099273682}
{"mode": "train", "epochs": 4, "timestep": 6964, "ep_reward": 544.1845092773438, "reward": 0.7424741983413696, "action": 0.04595482349395752}
{"mode": "train", "epochs": 4, "timestep": 6965, "ep_reward": 544.8455200195312, "reward": 0.6610394716262817, "action": 0.42307090759277344}
{"mode": "train", "epochs": 4, "timestep": 6966, "ep_reward": 545.3960571289062, "reward": 0.550524115562439, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6967, "ep_reward": 545.7703857421875, "reward": 0.37434113025665283, "action": -0.3641192317008972}
{"mode": "train", "epochs": 4, "timestep": 6968, "ep_reward": 546.0397338867188, "reward": 0.26934391260147095, "action": -0.17412269115447998}
{"mode": "train", "epochs": 4, "timestep": 6969, "ep_reward": 546.1838989257812, "reward": 0.14417463541030884, "action": -1.6402393579483032}
{"mode": "train", "epochs": 4, "timestep": 6970, "ep_reward": 546.18310546875, "reward": -0.0007772445678710938, "action": -1.3720470666885376}
{"mode": "train", "epochs": 4, "timestep": 6971, "ep_reward": 546.2988891601562, "reward": 0.11578816175460815, "action": -1.3156242370605469}
{"mode": "train", "epochs": 4, "timestep": 6972, "ep_reward": 546.5494995117188, "reward": 0.25058478116989136, "action": -0.7665300965309143}
{"mode": "train", "epochs": 4, "timestep": 6973, "ep_reward": 546.942138671875, "reward": 0.39266854524612427, "action": -0.8921312093734741}
{"mode": "train", "epochs": 4, "timestep": 6974, "ep_reward": 547.4644775390625, "reward": 0.5223491191864014, "action": -0.49766790866851807}
{"mode": "train", "epochs": 4, "timestep": 6975, "ep_reward": 548.10205078125, "reward": 0.6375732421875, "action": -0.6929476261138916}
{"mode": "train", "epochs": 4, "timestep": 6976, "ep_reward": 548.8294677734375, "reward": 0.7273880243301392, "action": -0.549952507019043}
{"mode": "train", "epochs": 4, "timestep": 6977, "ep_reward": 549.6250610351562, "reward": 0.7955906987190247, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6978, "ep_reward": 550.4566650390625, "reward": 0.831612765789032, "action": -0.5059984922409058}
{"mode": "train", "epochs": 4, "timestep": 6979, "ep_reward": 551.3200073242188, "reward": 0.8633197546005249, "action": -0.5715295076370239}
{"mode": "train", "epochs": 4, "timestep": 6980, "ep_reward": 552.1981201171875, "reward": 0.8781235218048096, "action": -1.798831582069397}
{"mode": "train", "epochs": 4, "timestep": 6981, "ep_reward": 553.0658569335938, "reward": 0.8677241802215576, "action": -1.2054622173309326}
{"mode": "train", "epochs": 4, "timestep": 6982, "ep_reward": 553.9105224609375, "reward": 0.8446746468544006, "action": -1.1105643510818481}
{"mode": "train", "epochs": 4, "timestep": 6983, "ep_reward": 554.7117309570312, "reward": 0.80120849609375, "action": -0.6539894342422485}
{"mode": "train", "epochs": 4, "timestep": 6984, "ep_reward": 555.44775390625, "reward": 0.7360255718231201, "action": -0.5481926202774048}
{"mode": "train", "epochs": 4, "timestep": 6985, "ep_reward": 556.0879516601562, "reward": 0.640209436416626, "action": -0.6108444929122925}
{"mode": "train", "epochs": 4, "timestep": 6986, "ep_reward": 556.59423828125, "reward": 0.5062654614448547, "action": -1.106103777885437}
{"mode": "train", "epochs": 4, "timestep": 6987, "ep_reward": 556.9430541992188, "reward": 0.34884244203567505, "action": -0.8012524247169495}
{"mode": "train", "epochs": 4, "timestep": 6988, "ep_reward": 557.1817016601562, "reward": 0.23862051963806152, "action": -0.8061330914497375}
{"mode": "train", "epochs": 4, "timestep": 6989, "ep_reward": 557.2899780273438, "reward": 0.10827773809432983, "action": -1.6130039691925049}
{"mode": "train", "epochs": 4, "timestep": 6990, "ep_reward": 557.2975463867188, "reward": 0.007546901702880859, "action": -0.7851442694664001}
{"mode": "train", "epochs": 4, "timestep": 6991, "ep_reward": 557.448974609375, "reward": 0.1514001488685608, "action": -1.3864675760269165}
{"mode": "train", "epochs": 4, "timestep": 6992, "ep_reward": 557.735107421875, "reward": 0.28615039587020874, "action": -1.1706463098526}
{"mode": "train", "epochs": 4, "timestep": 6993, "ep_reward": 558.1569213867188, "reward": 0.4218143820762634, "action": -1.0308587551116943}
{"mode": "train", "epochs": 4, "timestep": 6994, "ep_reward": 558.7037963867188, "reward": 0.5468835830688477, "action": -0.43345630168914795}
{"mode": "train", "epochs": 4, "timestep": 6995, "ep_reward": 559.3619995117188, "reward": 0.6581882238388062, "action": -1.0895287990570068}
{"mode": "train", "epochs": 4, "timestep": 6996, "ep_reward": 560.1007080078125, "reward": 0.7387052774429321, "action": -0.6604688167572021}
{"mode": "train", "epochs": 4, "timestep": 6997, "ep_reward": 560.9017944335938, "reward": 0.8010864853858948, "action": 0.08146929740905762}
{"mode": "train", "epochs": 4, "timestep": 6998, "ep_reward": 561.750732421875, "reward": 0.8489483594894409, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6999, "ep_reward": 562.6126708984375, "reward": 0.8619612455368042, "action": -1.429360032081604}
{"mode": "train", "epochs": 4, "timestep": 7000, "ep_reward": 563.4764404296875, "reward": 0.8637658357620239, "action": -0.7924066185951233}
{"mode": "train", "epochs": 4, "timestep": 7001, "ep_reward": 564.3302612304688, "reward": 0.8538085222244263, "action": -1.416809320449829}
{"mode": "train", "epochs": 4, "timestep": 7002, "ep_reward": 565.1487426757812, "reward": 0.8185046911239624, "action": -1.035048484802246}
{"mode": "train", "epochs": 4, "timestep": 7003, "ep_reward": 565.91064453125, "reward": 0.7619155049324036, "action": -1.082981824874878}
{"mode": "train", "epochs": 4, "timestep": 7004, "ep_reward": 566.584228515625, "reward": 0.6735811233520508, "action": -0.3287803530693054}
{"mode": "train", "epochs": 4, "timestep": 7005, "ep_reward": 567.1420288085938, "reward": 0.557773232460022, "action": -0.8174375891685486}
{"mode": "train", "epochs": 4, "timestep": 7006, "ep_reward": 567.537109375, "reward": 0.3950629234313965, "action": -1.6358342170715332}
{"mode": "train", "epochs": 4, "timestep": 7007, "ep_reward": 567.8237915039062, "reward": 0.28668850660324097, "action": -1.0878045558929443}
{"mode": "train", "epochs": 4, "timestep": 7008, "ep_reward": 567.9884643554688, "reward": 0.1646842360496521, "action": -1.5233705043792725}
{"mode": "train", "epochs": 4, "timestep": 7009, "ep_reward": 568.0112915039062, "reward": 0.022842884063720703, "action": -0.9273850321769714}
{"mode": "train", "epochs": 4, "timestep": 7010, "ep_reward": 568.1054077148438, "reward": 0.09413576126098633, "action": -1.6287126541137695}
{"mode": "train", "epochs": 4, "timestep": 7011, "ep_reward": 568.3317260742188, "reward": 0.22634881734848022, "action": -1.6775379180908203}
{"mode": "train", "epochs": 4, "timestep": 7012, "ep_reward": 568.6901245117188, "reward": 0.3584018349647522, "action": -1.000464677810669}
{"mode": "train", "epochs": 4, "timestep": 7013, "ep_reward": 569.1818237304688, "reward": 0.4916696548461914, "action": -0.6634010076522827}
{"mode": "train", "epochs": 4, "timestep": 7014, "ep_reward": 569.7925415039062, "reward": 0.6107140779495239, "action": -0.5539950132369995}
{"mode": "train", "epochs": 4, "timestep": 7015, "ep_reward": 570.4994506835938, "reward": 0.7069097757339478, "action": -1.65056574344635}
{"mode": "train", "epochs": 4, "timestep": 7016, "ep_reward": 571.2680053710938, "reward": 0.7685386538505554, "action": -0.909371018409729}
{"mode": "train", "epochs": 4, "timestep": 7017, "ep_reward": 572.0841064453125, "reward": 0.8160900473594666, "action": -1.450084924697876}
{"mode": "train", "epochs": 4, "timestep": 7018, "ep_reward": 572.9231567382812, "reward": 0.8390480279922485, "action": -0.33018314838409424}
{"mode": "train", "epochs": 4, "timestep": 7019, "ep_reward": 573.776611328125, "reward": 0.8534769415855408, "action": -0.5383845567703247}
{"mode": "train", "epochs": 4, "timestep": 7020, "ep_reward": 574.6241455078125, "reward": 0.8475432991981506, "action": -1.4065132141113281}
{"mode": "train", "epochs": 4, "timestep": 7021, "ep_reward": 575.4373779296875, "reward": 0.8132542371749878, "action": -1.1039501428604126}
{"mode": "train", "epochs": 4, "timestep": 7022, "ep_reward": 576.1936645507812, "reward": 0.7562824487686157, "action": -1.0833396911621094}
{"mode": "train", "epochs": 4, "timestep": 7023, "ep_reward": 576.8612060546875, "reward": 0.6675267219543457, "action": -0.6428318023681641}
{"mode": "train", "epochs": 4, "timestep": 7024, "ep_reward": 577.4072875976562, "reward": 0.5460878610610962, "action": -1.0089335441589355}
{"mode": "train", "epochs": 4, "timestep": 7025, "ep_reward": 577.79541015625, "reward": 0.38814103603363037, "action": -0.9204980731010437}
{"mode": "train", "epochs": 4, "timestep": 7026, "ep_reward": 578.0814819335938, "reward": 0.286080002784729, "action": -1.065267562866211}
{"mode": "train", "epochs": 4, "timestep": 7027, "ep_reward": 578.2455444335938, "reward": 0.16408967971801758, "action": -0.549196720123291}
{"mode": "train", "epochs": 4, "timestep": 7028, "ep_reward": 578.2674560546875, "reward": 0.021937668323516846, "action": -1.4363933801651}
{"mode": "train", "epochs": 4, "timestep": 7029, "ep_reward": 578.3624877929688, "reward": 0.0950579047203064, "action": -0.566603422164917}
{"mode": "train", "epochs": 4, "timestep": 7030, "ep_reward": 578.600830078125, "reward": 0.2383599877357483, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7031, "ep_reward": 578.9652099609375, "reward": 0.36439526081085205, "action": 0.03632760047912598}
{"mode": "train", "epochs": 4, "timestep": 7032, "ep_reward": 579.4735107421875, "reward": 0.5082961320877075, "action": -1.6481568813323975}
{"mode": "train", "epochs": 4, "timestep": 7033, "ep_reward": 580.0869140625, "reward": 0.6134222149848938, "action": -1.7355366945266724}
{"mode": "train", "epochs": 4, "timestep": 7034, "ep_reward": 580.78466796875, "reward": 0.6977802515029907, "action": -0.9005399346351624}
{"mode": "train", "epochs": 4, "timestep": 7035, "ep_reward": 581.5533447265625, "reward": 0.7686753273010254, "action": -0.5839528441429138}
{"mode": "train", "epochs": 4, "timestep": 7036, "ep_reward": 582.3735961914062, "reward": 0.8202730417251587, "action": -1.5416529178619385}
{"mode": "train", "epochs": 4, "timestep": 7037, "ep_reward": 583.2174682617188, "reward": 0.8438704013824463, "action": -1.2090259790420532}
{"mode": "train", "epochs": 4, "timestep": 7038, "ep_reward": 584.070068359375, "reward": 0.8525877594947815, "action": -1.1615018844604492}
{"mode": "train", "epochs": 4, "timestep": 7039, "ep_reward": 584.9134521484375, "reward": 0.8433736562728882, "action": -0.818208634853363}
{"mode": "train", "epochs": 4, "timestep": 7040, "ep_reward": 585.7303466796875, "reward": 0.8168770670890808, "action": -0.25037217140197754}
{"mode": "train", "epochs": 4, "timestep": 7041, "ep_reward": 586.5026245117188, "reward": 0.7722795605659485, "action": -1.3230903148651123}
{"mode": "train", "epochs": 4, "timestep": 7042, "ep_reward": 587.1890869140625, "reward": 0.6864912509918213, "action": -0.06677627563476562}
{"mode": "train", "epochs": 4, "timestep": 7043, "ep_reward": 587.76904296875, "reward": 0.5799456834793091, "action": -1.0995211601257324}
{"mode": "train", "epochs": 4, "timestep": 7044, "ep_reward": 588.1884155273438, "reward": 0.4193698763847351, "action": -1.4552780389785767}
{"mode": "train", "epochs": 4, "timestep": 7045, "ep_reward": 588.4931030273438, "reward": 0.304703950881958, "action": -0.8919451236724854}
{"mode": "train", "epochs": 4, "timestep": 7046, "ep_reward": 588.67919921875, "reward": 0.18606942892074585, "action": -0.45647716522216797}
{"mode": "train", "epochs": 4, "timestep": 7047, "ep_reward": 588.7266235351562, "reward": 0.04739701747894287, "action": -0.4858602285385132}
{"mode": "train", "epochs": 4, "timestep": 7048, "ep_reward": 588.79736328125, "reward": 0.07074850797653198, "action": -1.1973317861557007}
{"mode": "train", "epochs": 4, "timestep": 7049, "ep_reward": 589.0036010742188, "reward": 0.20622378587722778, "action": -1.2607468366622925}
{"mode": "train", "epochs": 4, "timestep": 7050, "ep_reward": 589.3469848632812, "reward": 0.3434063792228699, "action": -0.6827875375747681}
{"mode": "train", "epochs": 4, "timestep": 7051, "ep_reward": 589.8280639648438, "reward": 0.48105907440185547, "action": -0.7060153484344482}
{"mode": "train", "epochs": 4, "timestep": 7052, "ep_reward": 590.4290161132812, "reward": 0.6009408831596375, "action": -1.6650298833847046}
{"mode": "train", "epochs": 4, "timestep": 7053, "ep_reward": 591.1177978515625, "reward": 0.6888102293014526, "action": -0.9961433410644531}
{"mode": "train", "epochs": 4, "timestep": 7054, "ep_reward": 591.8795166015625, "reward": 0.7616891860961914, "action": -0.5600245594978333}
{"mode": "train", "epochs": 4, "timestep": 7055, "ep_reward": 592.6961059570312, "reward": 0.8165693283081055, "action": -0.32698267698287964}
{"mode": "train", "epochs": 4, "timestep": 7056, "ep_reward": 593.549560546875, "reward": 0.853439450263977, "action": -0.2559121251106262}
{"mode": "train", "epochs": 4, "timestep": 7057, "ep_reward": 594.4229736328125, "reward": 0.8734050989151001, "action": -0.9029776453971863}
{"mode": "train", "epochs": 4, "timestep": 7058, "ep_reward": 595.2952880859375, "reward": 0.8723135590553284, "action": -0.4861246943473816}
{"mode": "train", "epochs": 4, "timestep": 7059, "ep_reward": 596.1536865234375, "reward": 0.8584065437316895, "action": -0.8301448225975037}
{"mode": "train", "epochs": 4, "timestep": 7060, "ep_reward": 596.9763793945312, "reward": 0.8227111101150513, "action": -0.18847888708114624}
{"mode": "train", "epochs": 4, "timestep": 7061, "ep_reward": 597.7467041015625, "reward": 0.7703148126602173, "action": -0.38402271270751953}
{"mode": "train", "epochs": 4, "timestep": 7062, "ep_reward": 598.4349365234375, "reward": 0.6882160305976868, "action": -0.26429760456085205}
{"mode": "train", "epochs": 4, "timestep": 7063, "ep_reward": 599.009033203125, "reward": 0.5741164684295654, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7064, "ep_reward": 599.4053344726562, "reward": 0.39631766080856323, "action": -1.0944846868515015}
{"mode": "train", "epochs": 4, "timestep": 7065, "ep_reward": 599.6810913085938, "reward": 0.27577120065689087, "action": -1.6342328786849976}
{"mode": "train", "epochs": 4, "timestep": 7066, "ep_reward": 599.8330688476562, "reward": 0.15196436643600464, "action": -1.4021539688110352}
{"mode": "train", "epochs": 4, "timestep": 7067, "ep_reward": 599.8412475585938, "reward": 0.008180618286132812, "action": -0.9498828053474426}
{"mode": "train", "epochs": 4, "timestep": 7068, "ep_reward": 599.9489135742188, "reward": 0.1076662540435791, "action": -1.69754958152771}
{"mode": "train", "epochs": 4, "timestep": 7069, "ep_reward": 600.1870727539062, "reward": 0.23813754320144653, "action": -0.47974860668182373}
{"mode": "train", "epochs": 4, "timestep": 7070, "ep_reward": 600.5718994140625, "reward": 0.38484495878219604, "action": -1.507495403289795}
{"mode": "train", "epochs": 4, "timestep": 7071, "ep_reward": 601.0802612304688, "reward": 0.5083435773849487, "action": 0.37498748302459717}
{"mode": "train", "epochs": 4, "timestep": 7072, "ep_reward": 601.7156982421875, "reward": 0.6354105472564697, "action": -1.4829570055007935}
{"mode": "train", "epochs": 4, "timestep": 7073, "ep_reward": 602.433837890625, "reward": 0.7181689143180847, "action": -0.32389163970947266}
{"mode": "train", "epochs": 4, "timestep": 7074, "ep_reward": 603.22412109375, "reward": 0.7902982831001282, "action": -1.189351201057434}
{"mode": "train", "epochs": 4, "timestep": 7075, "ep_reward": 604.0578002929688, "reward": 0.8337076306343079, "action": -1.3002182245254517}
{"mode": "train", "epochs": 4, "timestep": 7076, "ep_reward": 604.916748046875, "reward": 0.8589199781417847, "action": 0.2774219512939453}
{"mode": "train", "epochs": 4, "timestep": 7077, "ep_reward": 605.7976684570312, "reward": 0.880923330783844, "action": -1.2085440158843994}
{"mode": "train", "epochs": 4, "timestep": 7078, "ep_reward": 606.6734619140625, "reward": 0.8757990598678589, "action": -0.6235160827636719}
{"mode": "train", "epochs": 4, "timestep": 7079, "ep_reward": 607.5328979492188, "reward": 0.8594412803649902, "action": -0.8252756595611572}
{"mode": "train", "epochs": 4, "timestep": 7080, "ep_reward": 608.35546875, "reward": 0.8225513696670532, "action": -0.7739853858947754}
{"mode": "train", "epochs": 4, "timestep": 7081, "ep_reward": 609.1178588867188, "reward": 0.7623993158340454, "action": -1.205580234527588}
{"mode": "train", "epochs": 4, "timestep": 7082, "ep_reward": 609.7847900390625, "reward": 0.6669290661811829, "action": -0.8320279121398926}
{"mode": "train", "epochs": 4, "timestep": 7083, "ep_reward": 610.3231811523438, "reward": 0.5383917093276978, "action": -1.3139150142669678}
{"mode": "train", "epochs": 4, "timestep": 7084, "ep_reward": 610.6893310546875, "reward": 0.3661438226699829, "action": -1.8971307277679443}
{"mode": "train", "epochs": 4, "timestep": 7085, "ep_reward": 610.9489135742188, "reward": 0.2595673203468323, "action": -1.4552699327468872}
{"mode": "train", "epochs": 4, "timestep": 7086, "ep_reward": 611.0819091796875, "reward": 0.13296514749526978, "action": -1.0284463167190552}
{"mode": "train", "epochs": 4, "timestep": 7087, "ep_reward": 611.0681762695312, "reward": -0.013724327087402344, "action": -1.184670090675354}
{"mode": "train", "epochs": 4, "timestep": 7088, "ep_reward": 611.1954956054688, "reward": 0.12730801105499268, "action": -1.3071351051330566}
{"mode": "train", "epochs": 4, "timestep": 7089, "ep_reward": 611.4578857421875, "reward": 0.2623782157897949, "action": -1.6909725666046143}
{"mode": "train", "epochs": 4, "timestep": 7090, "ep_reward": 611.8505249023438, "reward": 0.39264988899230957, "action": -1.1178703308105469}
{"mode": "train", "epochs": 4, "timestep": 7091, "ep_reward": 612.37109375, "reward": 0.5205638408660889, "action": -1.0357123613357544}
{"mode": "train", "epochs": 4, "timestep": 7092, "ep_reward": 613.00146484375, "reward": 0.6304001808166504, "action": -0.621207058429718}
{"mode": "train", "epochs": 4, "timestep": 7093, "ep_reward": 613.72265625, "reward": 0.721177875995636, "action": -0.5692691206932068}
{"mode": "train", "epochs": 4, "timestep": 7094, "ep_reward": 614.5109252929688, "reward": 0.7882555723190308, "action": -0.09205198287963867}
{"mode": "train", "epochs": 4, "timestep": 7095, "ep_reward": 615.3486328125, "reward": 0.8377230167388916, "action": -0.3525888919830322}
{"mode": "train", "epochs": 4, "timestep": 7096, "ep_reward": 616.2145385742188, "reward": 0.865901529788971, "action": -0.26043403148651123}
{"mode": "train", "epochs": 4, "timestep": 7097, "ep_reward": 617.0931396484375, "reward": 0.8785860538482666, "action": -0.08015984296798706}
{"mode": "train", "epochs": 4, "timestep": 7098, "ep_reward": 617.9705810546875, "reward": 0.8774307370185852, "action": -1.5600204467773438}
{"mode": "train", "epochs": 4, "timestep": 7099, "ep_reward": 618.8180541992188, "reward": 0.8474651575088501, "action": -1.4710828065872192}
{"mode": "train", "epochs": 4, "timestep": 7100, "ep_reward": 619.614501953125, "reward": 0.796451985836029, "action": -0.1121290922164917}
{"mode": "train", "epochs": 4, "timestep": 7101, "ep_reward": 620.3472290039062, "reward": 0.7327160835266113, "action": -0.8939080238342285}
{"mode": "train", "epochs": 4, "timestep": 7102, "ep_reward": 620.9755859375, "reward": 0.6283520460128784, "action": -1.979041337966919}
{"mode": "train", "epochs": 4, "timestep": 7103, "ep_reward": 621.4444580078125, "reward": 0.46886616945266724, "action": -0.7018921375274658}
{"mode": "train", "epochs": 4, "timestep": 7104, "ep_reward": 621.775390625, "reward": 0.3309585452079773, "action": -0.17301058769226074}
{"mode": "train", "epochs": 4, "timestep": 7105, "ep_reward": 621.9925537109375, "reward": 0.2171863317489624, "action": -0.7786690592765808}
{"mode": "train", "epochs": 4, "timestep": 7106, "ep_reward": 622.075927734375, "reward": 0.08338719606399536, "action": -1.27444326877594}
{"mode": "train", "epochs": 4, "timestep": 7107, "ep_reward": 622.1102294921875, "reward": 0.034282684326171875, "action": -0.865680992603302}
{"mode": "train", "epochs": 4, "timestep": 7108, "ep_reward": 622.284912109375, "reward": 0.17471104860305786, "action": -0.7869173288345337}
{"mode": "train", "epochs": 4, "timestep": 7109, "ep_reward": 622.602294921875, "reward": 0.3173981308937073, "action": -0.4635353684425354}
{"mode": "train", "epochs": 4, "timestep": 7110, "ep_reward": 623.0608520507812, "reward": 0.45858055353164673, "action": -0.9769618511199951}
{"mode": "train", "epochs": 4, "timestep": 7111, "ep_reward": 623.6392822265625, "reward": 0.5784087181091309, "action": -1.031050682067871}
{"mode": "train", "epochs": 4, "timestep": 7112, "ep_reward": 624.31689453125, "reward": 0.6776026487350464, "action": -0.9532833099365234}
{"mode": "train", "epochs": 4, "timestep": 7113, "ep_reward": 625.072265625, "reward": 0.7553955316543579, "action": -1.5687131881713867}
{"mode": "train", "epochs": 4, "timestep": 7114, "ep_reward": 625.87890625, "reward": 0.8066309094429016, "action": -1.4371312856674194}
{"mode": "train", "epochs": 4, "timestep": 7115, "ep_reward": 626.7196044921875, "reward": 0.8406701683998108, "action": -1.1635624170303345}
{"mode": "train", "epochs": 4, "timestep": 7116, "ep_reward": 627.5795288085938, "reward": 0.8598980903625488, "action": -0.8379794955253601}
{"mode": "train", "epochs": 4, "timestep": 7117, "ep_reward": 628.4447631835938, "reward": 0.8652302026748657, "action": -1.155158281326294}
{"mode": "train", "epochs": 4, "timestep": 7118, "ep_reward": 629.2953491210938, "reward": 0.8505918979644775, "action": -1.1502156257629395}
{"mode": "train", "epochs": 4, "timestep": 7119, "ep_reward": 630.111083984375, "reward": 0.8157396912574768, "action": -1.5607125759124756}
{"mode": "train", "epochs": 4, "timestep": 7120, "ep_reward": 630.8621215820312, "reward": 0.7510616183280945, "action": -0.43096232414245605}
{"mode": "train", "epochs": 4, "timestep": 7121, "ep_reward": 631.529052734375, "reward": 0.6669455766677856, "action": -0.8433926701545715}
{"mode": "train", "epochs": 4, "timestep": 7122, "ep_reward": 632.0697631835938, "reward": 0.5406811833381653, "action": -0.7926701307296753}
{"mode": "train", "epochs": 4, "timestep": 7123, "ep_reward": 632.4492797851562, "reward": 0.3795318007469177, "action": -0.6981226801872253}
{"mode": "train", "epochs": 4, "timestep": 7124, "ep_reward": 632.724853515625, "reward": 0.2755510210990906, "action": -1.3351314067840576}
{"mode": "train", "epochs": 4, "timestep": 7125, "ep_reward": 632.8765869140625, "reward": 0.15174734592437744, "action": -0.5029919147491455}
{"mode": "train", "epochs": 4, "timestep": 7126, "ep_reward": 632.8843994140625, "reward": 0.007783055305480957, "action": -1.141533374786377}
{"mode": "train", "epochs": 4, "timestep": 7127, "ep_reward": 632.9923706054688, "reward": 0.10799813270568848, "action": -1.7336819171905518}
{"mode": "train", "epochs": 4, "timestep": 7128, "ep_reward": 633.230712890625, "reward": 0.2383410930633545, "action": -1.2779264450073242}
{"mode": "train", "epochs": 4, "timestep": 7129, "ep_reward": 633.6060791015625, "reward": 0.3753594160079956, "action": -0.46243733167648315}
{"mode": "train", "epochs": 4, "timestep": 7130, "ep_reward": 634.118896484375, "reward": 0.5128394365310669, "action": -1.1303452253341675}
{"mode": "train", "epochs": 4, "timestep": 7131, "ep_reward": 634.741943359375, "reward": 0.6230589151382446, "action": 0.3876708745956421}
{"mode": "train", "epochs": 4, "timestep": 7132, "ep_reward": 635.4679565429688, "reward": 0.7260187864303589, "action": -1.2645013332366943}
{"mode": "train", "epochs": 4, "timestep": 7133, "ep_reward": 636.2560424804688, "reward": 0.7881086468696594, "action": -1.2577362060546875}
{"mode": "train", "epochs": 4, "timestep": 7134, "ep_reward": 637.0867309570312, "reward": 0.830693244934082, "action": -0.6284430027008057}
{"mode": "train", "epochs": 4, "timestep": 7135, "ep_reward": 637.9474487304688, "reward": 0.8607105016708374, "action": -1.185779333114624}
{"mode": "train", "epochs": 4, "timestep": 7136, "ep_reward": 638.817138671875, "reward": 0.8696780800819397, "action": -1.2886979579925537}
{"mode": "train", "epochs": 4, "timestep": 7137, "ep_reward": 639.6787719726562, "reward": 0.8616169691085815, "action": -0.8315198421478271}
{"mode": "train", "epochs": 4, "timestep": 7138, "ep_reward": 640.5181884765625, "reward": 0.8394073247909546, "action": -0.835266649723053}
{"mode": "train", "epochs": 4, "timestep": 7139, "ep_reward": 641.3138427734375, "reward": 0.7956522107124329, "action": -0.9272218942642212}
{"mode": "train", "epochs": 4, "timestep": 7140, "ep_reward": 642.0377197265625, "reward": 0.723882794380188, "action": -0.6626277565956116}
{"mode": "train", "epochs": 4, "timestep": 7141, "ep_reward": 642.6593627929688, "reward": 0.6216707229614258, "action": -0.8262501955032349}
{"mode": "train", "epochs": 4, "timestep": 7142, "ep_reward": 643.1377563476562, "reward": 0.4784179925918579, "action": -1.2886428833007812}
{"mode": "train", "epochs": 4, "timestep": 7143, "ep_reward": 643.4727783203125, "reward": 0.33501356840133667, "action": -0.988642692565918}
{"mode": "train", "epochs": 4, "timestep": 7144, "ep_reward": 643.6947631835938, "reward": 0.22198861837387085, "action": -1.5294115543365479}
{"mode": "train", "epochs": 4, "timestep": 7145, "ep_reward": 643.7838745117188, "reward": 0.08910578489303589, "action": -1.197952389717102}
{"mode": "train", "epochs": 4, "timestep": 7146, "ep_reward": 643.8121948242188, "reward": 0.028293848037719727, "action": -0.7042446136474609}
{"mode": "train", "epochs": 4, "timestep": 7147, "ep_reward": 643.981689453125, "reward": 0.16951268911361694, "action": -0.6759347915649414}
{"mode": "train", "epochs": 4, "timestep": 7148, "ep_reward": 644.2949829101562, "reward": 0.31327754259109497, "action": -1.8787527084350586}
{"mode": "train", "epochs": 4, "timestep": 7149, "ep_reward": 644.7327270507812, "reward": 0.437771201133728, "action": -0.960145890712738}
{"mode": "train", "epochs": 4, "timestep": 7150, "ep_reward": 645.294189453125, "reward": 0.5614652633666992, "action": -1.2542433738708496}
{"mode": "train", "epochs": 4, "timestep": 7151, "ep_reward": 645.95556640625, "reward": 0.6613596081733704, "action": 0.06251668930053711}
{"mode": "train", "epochs": 4, "timestep": 7152, "ep_reward": 646.7069702148438, "reward": 0.7513748407363892, "action": -0.6648688316345215}
{"mode": "train", "epochs": 4, "timestep": 7153, "ep_reward": 647.5172729492188, "reward": 0.8102915287017822, "action": -0.7271561026573181}
{"mode": "train", "epochs": 4, "timestep": 7154, "ep_reward": 648.3661499023438, "reward": 0.8488811254501343, "action": -0.20500773191452026}
{"mode": "train", "epochs": 4, "timestep": 7155, "ep_reward": 649.2406005859375, "reward": 0.8744674921035767, "action": -1.3139172792434692}
{"mode": "train", "epochs": 4, "timestep": 7156, "ep_reward": 650.1162109375, "reward": 0.8756388425827026, "action": -1.3402578830718994}
{"mode": "train", "epochs": 4, "timestep": 7157, "ep_reward": 650.9768676757812, "reward": 0.8606478571891785, "action": -0.8381513953208923}
{"mode": "train", "epochs": 4, "timestep": 7158, "ep_reward": 651.8082275390625, "reward": 0.8313496708869934, "action": -1.0396902561187744}
{"mode": "train", "epochs": 4, "timestep": 7159, "ep_reward": 652.5853881835938, "reward": 0.7771527767181396, "action": -1.4297285079956055}
{"mode": "train", "epochs": 4, "timestep": 7160, "ep_reward": 653.2738647460938, "reward": 0.6884839534759521, "action": -1.9898717403411865}
{"mode": "train", "epochs": 4, "timestep": 7161, "ep_reward": 653.8270263671875, "reward": 0.5531835556030273, "action": -1.332751750946045}
{"mode": "train", "epochs": 4, "timestep": 7162, "ep_reward": 654.2188720703125, "reward": 0.3918365240097046, "action": -0.02499169111251831}
{"mode": "train", "epochs": 4, "timestep": 7163, "ep_reward": 654.5094604492188, "reward": 0.29057151079177856, "action": -0.5198049545288086}
{"mode": "train", "epochs": 4, "timestep": 7164, "ep_reward": 654.6785888671875, "reward": 0.16910380125045776, "action": -1.9474602937698364}
{"mode": "train", "epochs": 4, "timestep": 7165, "ep_reward": 654.70654296875, "reward": 0.027973473072052002, "action": -1.3881829977035522}
{"mode": "train", "epochs": 4, "timestep": 7166, "ep_reward": 654.7959594726562, "reward": 0.08939814567565918, "action": -0.5003174543380737}
{"mode": "train", "epochs": 4, "timestep": 7167, "ep_reward": 655.0294799804688, "reward": 0.23354196548461914, "action": -1.0439494848251343}
{"mode": "train", "epochs": 4, "timestep": 7168, "ep_reward": 655.4004516601562, "reward": 0.37096667289733887, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7169, "ep_reward": 655.8898315429688, "reward": 0.48939722776412964, "action": -1.3992060422897339}
{"mode": "train", "epochs": 4, "timestep": 7170, "ep_reward": 656.4903564453125, "reward": 0.6004945039749146, "action": -1.2582250833511353}
{"mode": "train", "epochs": 4, "timestep": 7171, "ep_reward": 657.1822509765625, "reward": 0.691903829574585, "action": -1.0762306451797485}
{"mode": "train", "epochs": 4, "timestep": 7172, "ep_reward": 657.9442749023438, "reward": 0.7620145082473755, "action": -1.2856831550598145}
{"mode": "train", "epochs": 4, "timestep": 7173, "ep_reward": 658.7523193359375, "reward": 0.8080485463142395, "action": -0.7215287089347839}
{"mode": "train", "epochs": 4, "timestep": 7174, "ep_reward": 659.5911865234375, "reward": 0.8388899564743042, "action": -1.6937544345855713}
{"mode": "train", "epochs": 4, "timestep": 7175, "ep_reward": 660.4332275390625, "reward": 0.8420313000679016, "action": -0.8093972206115723}
{"mode": "train", "epochs": 4, "timestep": 7176, "ep_reward": 661.2669067382812, "reward": 0.8336820602416992, "action": -0.5848259925842285}
{"mode": "train", "epochs": 4, "timestep": 7177, "ep_reward": 662.0728149414062, "reward": 0.8059186935424805, "action": -0.9432212114334106}
{"mode": "train", "epochs": 4, "timestep": 7178, "ep_reward": 662.8215942382812, "reward": 0.7487800717353821, "action": -1.0190784931182861}
{"mode": "train", "epochs": 4, "timestep": 7179, "ep_reward": 663.4799194335938, "reward": 0.6583186388015747, "action": -0.3267706632614136}
{"mode": "train", "epochs": 4, "timestep": 7180, "ep_reward": 664.0185546875, "reward": 0.5386289358139038, "action": -0.490700900554657}
{"mode": "train", "epochs": 4, "timestep": 7181, "ep_reward": 664.4017944335938, "reward": 0.3832654356956482, "action": -1.513962745666504}
{"mode": "train", "epochs": 4, "timestep": 7182, "ep_reward": 664.6820678710938, "reward": 0.28029704093933105, "action": -0.744159996509552}
{"mode": "train", "epochs": 4, "timestep": 7183, "ep_reward": 664.8392333984375, "reward": 0.1571427583694458, "action": -1.3417415618896484}
{"mode": "train", "epochs": 4, "timestep": 7184, "ep_reward": 664.8533935546875, "reward": 0.014168858528137207, "action": -0.4121662378311157}
{"mode": "train", "epochs": 4, "timestep": 7185, "ep_reward": 664.9557495117188, "reward": 0.1023525595664978, "action": -0.8576592206954956}
{"mode": "train", "epochs": 4, "timestep": 7186, "ep_reward": 665.1982421875, "reward": 0.24248284101486206, "action": -0.5922026634216309}
{"mode": "train", "epochs": 4, "timestep": 7187, "ep_reward": 665.5841064453125, "reward": 0.3858798146247864, "action": -1.7401494979858398}
{"mode": "train", "epochs": 4, "timestep": 7188, "ep_reward": 666.0897827148438, "reward": 0.50569748878479, "action": -1.7928301095962524}
{"mode": "train", "epochs": 4, "timestep": 7189, "ep_reward": 666.6995849609375, "reward": 0.609798789024353, "action": -1.3032102584838867}
{"mode": "train", "epochs": 4, "timestep": 7190, "ep_reward": 667.3982543945312, "reward": 0.6986973285675049, "action": -1.1760574579238892}
{"mode": "train", "epochs": 4, "timestep": 7191, "ep_reward": 668.164306640625, "reward": 0.7660365104675293, "action": -0.0999901294708252}
{"mode": "train", "epochs": 4, "timestep": 7192, "ep_reward": 668.9853515625, "reward": 0.8210504651069641, "action": -1.713606834411621}
{"mode": "train", "epochs": 4, "timestep": 7193, "ep_reward": 669.8268432617188, "reward": 0.8414768576622009, "action": -0.6263097524642944}
{"mode": "train", "epochs": 4, "timestep": 7194, "ep_reward": 670.68017578125, "reward": 0.8533306121826172, "action": -1.351768970489502}
{"mode": "train", "epochs": 4, "timestep": 7195, "ep_reward": 671.520263671875, "reward": 0.8401111364364624, "action": -1.024827480316162}
{"mode": "train", "epochs": 4, "timestep": 7196, "ep_reward": 672.3287353515625, "reward": 0.8084783554077148, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7197, "ep_reward": 673.0686645507812, "reward": 0.7399368286132812, "action": -0.8137699961662292}
{"mode": "train", "epochs": 4, "timestep": 7198, "ep_reward": 673.7188110351562, "reward": 0.6501644849777222, "action": -1.3943549394607544}
{"mode": "train", "epochs": 4, "timestep": 7199, "ep_reward": 674.2308959960938, "reward": 0.5121114253997803, "action": -1.3851909637451172}
{"mode": "train", "epochs": 4, "timestep": 7200, "ep_reward": 674.6099853515625, "reward": 0.37906384468078613, "action": -1.0825254917144775}
{"mode": "train", "epochs": 4, "timestep": 7201, "ep_reward": 674.8851318359375, "reward": 0.27514469623565674, "action": -0.17947673797607422}
{"mode": "train", "epochs": 4, "timestep": 7202, "ep_reward": 675.0362548828125, "reward": 0.15115123987197876, "action": -0.30408763885498047}
{"mode": "train", "epochs": 4, "timestep": 7203, "ep_reward": 675.0433349609375, "reward": 0.007081806659698486, "action": -1.1730269193649292}
{"mode": "train", "epochs": 4, "timestep": 7204, "ep_reward": 675.152099609375, "reward": 0.10878068208694458, "action": -0.799043595790863}
{"mode": "train", "epochs": 4, "timestep": 7205, "ep_reward": 675.4017944335938, "reward": 0.24971824884414673, "action": -1.4388567209243774}
{"mode": "train", "epochs": 4, "timestep": 7206, "ep_reward": 675.784423828125, "reward": 0.38260573148727417, "action": -0.998028576374054}
{"mode": "train", "epochs": 4, "timestep": 7207, "ep_reward": 676.296630859375, "reward": 0.5122358798980713, "action": -1.2899153232574463}
{"mode": "train", "epochs": 4, "timestep": 7208, "ep_reward": 676.9174194335938, "reward": 0.6207931041717529, "action": -0.7690334916114807}
{"mode": "train", "epochs": 4, "timestep": 7209, "ep_reward": 677.6304321289062, "reward": 0.7130035161972046, "action": -0.4828771948814392}
{"mode": "train", "epochs": 4, "timestep": 7210, "ep_reward": 678.414794921875, "reward": 0.7843849658966064, "action": -0.41893666982650757}
{"mode": "train", "epochs": 4, "timestep": 7211, "ep_reward": 679.2493286132812, "reward": 0.8345143795013428, "action": -0.8727090358734131}
{"mode": "train", "epochs": 4, "timestep": 7212, "ep_reward": 680.1116333007812, "reward": 0.8623019456863403, "action": -1.014560341835022}
{"mode": "train", "epochs": 4, "timestep": 7213, "ep_reward": 680.9844970703125, "reward": 0.872887134552002, "action": -1.1347583532333374}
{"mode": "train", "epochs": 4, "timestep": 7214, "ep_reward": 681.8512573242188, "reward": 0.8667815923690796, "action": -0.1835344433784485}
{"mode": "train", "epochs": 4, "timestep": 7215, "ep_reward": 682.7030639648438, "reward": 0.8518249988555908, "action": -0.6758410930633545}
{"mode": "train", "epochs": 4, "timestep": 7216, "ep_reward": 683.5160522460938, "reward": 0.8129585981369019, "action": -1.2962292432785034}
{"mode": "train", "epochs": 4, "timestep": 7217, "ep_reward": 684.2586059570312, "reward": 0.742556631565094, "action": -0.9496995210647583}
{"mode": "train", "epochs": 4, "timestep": 7218, "ep_reward": 684.9016723632812, "reward": 0.6430777311325073, "action": -0.5880759954452515}
{"mode": "train", "epochs": 4, "timestep": 7219, "ep_reward": 685.411865234375, "reward": 0.5102061629295349, "action": -1.693376898765564}
{"mode": "train", "epochs": 4, "timestep": 7220, "ep_reward": 685.7620849609375, "reward": 0.35019534826278687, "action": -0.9973273873329163}
{"mode": "train", "epochs": 4, "timestep": 7221, "ep_reward": 686.0023803710938, "reward": 0.24027079343795776, "action": -0.7999669313430786}
{"mode": "train", "epochs": 4, "timestep": 7222, "ep_reward": 686.1126708984375, "reward": 0.11028075218200684, "action": -1.1594449281692505}
{"mode": "train", "epochs": 4, "timestep": 7223, "ep_reward": 686.1181030273438, "reward": 0.005458533763885498, "action": -0.40388578176498413}
{"mode": "train", "epochs": 4, "timestep": 7224, "ep_reward": 686.2676391601562, "reward": 0.14955198764801025, "action": -1.4224621057510376}
{"mode": "train", "epochs": 4, "timestep": 7225, "ep_reward": 686.55126953125, "reward": 0.28365403413772583, "action": -1.9855971336364746}
{"mode": "train", "epochs": 4, "timestep": 7226, "ep_reward": 686.9608154296875, "reward": 0.4095568060874939, "action": -1.2003787755966187}
{"mode": "train", "epochs": 4, "timestep": 7227, "ep_reward": 687.4955444335938, "reward": 0.534751296043396, "action": -1.2790948152542114}
{"mode": "train", "epochs": 4, "timestep": 7228, "ep_reward": 688.1347045898438, "reward": 0.6391476392745972, "action": -0.2317299246788025}
{"mode": "train", "epochs": 4, "timestep": 7229, "ep_reward": 688.865478515625, "reward": 0.7307767868041992, "action": -0.20343196392059326}
{"mode": "train", "epochs": 4, "timestep": 7230, "ep_reward": 689.6626586914062, "reward": 0.7971907258033752, "action": -0.8589430451393127}
{"mode": "train", "epochs": 4, "timestep": 7231, "ep_reward": 690.498291015625, "reward": 0.8356093168258667, "action": -1.549918293952942}
{"mode": "train", "epochs": 4, "timestep": 7232, "ep_reward": 691.347900390625, "reward": 0.8496060967445374, "action": -0.32603561878204346}
{"mode": "train", "epochs": 4, "timestep": 7233, "ep_reward": 692.204345703125, "reward": 0.8564696311950684, "action": -1.3513118028640747}
{"mode": "train", "epochs": 4, "timestep": 7234, "ep_reward": 693.0399169921875, "reward": 0.8355977535247803, "action": -0.26420897245407104}
{"mode": "train", "epochs": 4, "timestep": 7235, "ep_reward": 693.8433227539062, "reward": 0.8034210205078125, "action": -1.3087053298950195}
{"mode": "train", "epochs": 4, "timestep": 7236, "ep_reward": 694.5776977539062, "reward": 0.7343920469284058, "action": -0.8346470594406128}
{"mode": "train", "epochs": 4, "timestep": 7237, "ep_reward": 695.2144775390625, "reward": 0.6368000507354736, "action": -1.6008944511413574}
{"mode": "train", "epochs": 4, "timestep": 7238, "ep_reward": 695.7027587890625, "reward": 0.4882615804672241, "action": -0.42126399278640747}
{"mode": "train", "epochs": 4, "timestep": 7239, "ep_reward": 696.0579223632812, "reward": 0.35516780614852905, "action": -1.0007792711257935}
{"mode": "train", "epochs": 4, "timestep": 7240, "ep_reward": 696.30419921875, "reward": 0.24628251791000366, "action": -0.1400356888771057}
{"mode": "train", "epochs": 4, "timestep": 7241, "ep_reward": 696.4215087890625, "reward": 0.1172974705696106, "action": -0.8037499189376831}
{"mode": "train", "epochs": 4, "timestep": 7242, "ep_reward": 696.419189453125, "reward": -0.002303481101989746, "action": -0.7588767409324646}
{"mode": "train", "epochs": 4, "timestep": 7243, "ep_reward": 696.5620727539062, "reward": 0.14285433292388916, "action": -1.1856456995010376}
{"mode": "train", "epochs": 4, "timestep": 7244, "ep_reward": 696.842041015625, "reward": 0.2799553871154785, "action": -0.81256502866745}
{"mode": "train", "epochs": 4, "timestep": 7245, "ep_reward": 697.261962890625, "reward": 0.4199322462081909, "action": -0.28875380754470825}
{"mode": "train", "epochs": 4, "timestep": 7246, "ep_reward": 697.8150024414062, "reward": 0.553047776222229, "action": -1.0721944570541382}
{"mode": "train", "epochs": 4, "timestep": 7247, "ep_reward": 698.4716796875, "reward": 0.6566717028617859, "action": -0.7253525853157043}
{"mode": "train", "epochs": 4, "timestep": 7248, "ep_reward": 699.2135009765625, "reward": 0.7418001890182495, "action": -0.5863821506500244}
{"mode": "train", "epochs": 4, "timestep": 7249, "ep_reward": 700.0194702148438, "reward": 0.8059670925140381, "action": -0.848857581615448}
{"mode": "train", "epochs": 4, "timestep": 7250, "ep_reward": 700.86767578125, "reward": 0.848203718662262, "action": -1.2324086427688599}
{"mode": "train", "epochs": 4, "timestep": 7251, "ep_reward": 701.738525390625, "reward": 0.8708672523498535, "action": -1.3379566669464111}
{"mode": "train", "epochs": 4, "timestep": 7252, "ep_reward": 702.616455078125, "reward": 0.8779329061508179, "action": -0.6703903675079346}
{"mode": "train", "epochs": 4, "timestep": 7253, "ep_reward": 703.4918823242188, "reward": 0.8754014372825623, "action": -0.6299026012420654}
{"mode": "train", "epochs": 4, "timestep": 7254, "ep_reward": 704.3489379882812, "reward": 0.8570660948753357, "action": -1.0454363822937012}
{"mode": "train", "epochs": 4, "timestep": 7255, "ep_reward": 705.1646728515625, "reward": 0.8157199621200562, "action": -0.8738350868225098}
{"mode": "train", "epochs": 4, "timestep": 7256, "ep_reward": 705.9157104492188, "reward": 0.7510389089584351, "action": -1.5032267570495605}
{"mode": "train", "epochs": 4, "timestep": 7257, "ep_reward": 706.5626831054688, "reward": 0.6469734907150269, "action": -1.1511313915252686}
{"mode": "train", "epochs": 4, "timestep": 7258, "ep_reward": 707.06982421875, "reward": 0.5071609616279602, "action": -0.998063862323761}
{"mode": "train", "epochs": 4, "timestep": 7259, "ep_reward": 707.42236328125, "reward": 0.35256606340408325, "action": -1.9208543300628662}
{"mode": "train", "epochs": 4, "timestep": 7260, "ep_reward": 707.6657104492188, "reward": 0.2433190941810608, "action": -0.8036034107208252}
{"mode": "train", "epochs": 4, "timestep": 7261, "ep_reward": 707.7796020507812, "reward": 0.1138651967048645, "action": -0.9603660106658936}
{"mode": "train", "epochs": 4, "timestep": 7262, "ep_reward": 707.7811279296875, "reward": 0.0014977455139160156, "action": -0.7666031122207642}
{"mode": "train", "epochs": 4, "timestep": 7263, "ep_reward": 707.92724609375, "reward": 0.14610838890075684, "action": -1.5239386558532715}
{"mode": "train", "epochs": 4, "timestep": 7264, "ep_reward": 708.206298828125, "reward": 0.27902668714523315, "action": -1.1778669357299805}
{"mode": "train", "epochs": 4, "timestep": 7265, "ep_reward": 708.62158203125, "reward": 0.4152817130088806, "action": -0.027178525924682617}
{"mode": "train", "epochs": 4, "timestep": 7266, "ep_reward": 709.1742553710938, "reward": 0.5526720881462097, "action": -1.0215617418289185}
{"mode": "train", "epochs": 4, "timestep": 7267, "ep_reward": 709.8311157226562, "reward": 0.6568794846534729, "action": -0.4298241138458252}
{"mode": "train", "epochs": 4, "timestep": 7268, "ep_reward": 710.5753173828125, "reward": 0.7442022562026978, "action": -1.6727958917617798}
{"mode": "train", "epochs": 4, "timestep": 7269, "ep_reward": 711.373046875, "reward": 0.7977313995361328, "action": -0.5976195931434631}
{"mode": "train", "epochs": 4, "timestep": 7270, "ep_reward": 712.214599609375, "reward": 0.8415320515632629, "action": -1.9298789501190186}
{"mode": "train", "epochs": 4, "timestep": 7271, "ep_reward": 713.0712890625, "reward": 0.8566690683364868, "action": -0.9632870554924011}
{"mode": "train", "epochs": 4, "timestep": 7272, "ep_reward": 713.9346923828125, "reward": 0.8634165525436401, "action": -1.4683854579925537}
{"mode": "train", "epochs": 4, "timestep": 7273, "ep_reward": 714.783203125, "reward": 0.8484824895858765, "action": -0.027782976627349854}
{"mode": "train", "epochs": 4, "timestep": 7274, "ep_reward": 715.6103515625, "reward": 0.8271380662918091, "action": -0.7827466726303101}
{"mode": "train", "epochs": 4, "timestep": 7275, "ep_reward": 716.3862915039062, "reward": 0.7759336829185486, "action": -1.1038026809692383}
{"mode": "train", "epochs": 4, "timestep": 7276, "ep_reward": 717.0781860351562, "reward": 0.6919018030166626, "action": -0.7724190950393677}
{"mode": "train", "epochs": 4, "timestep": 7277, "ep_reward": 717.6537475585938, "reward": 0.5755358934402466, "action": -0.4115179181098938}
{"mode": "train", "epochs": 4, "timestep": 7278, "ep_reward": 718.0784301757812, "reward": 0.4246811270713806, "action": -0.1279137134552002}
{"mode": "train", "epochs": 4, "timestep": 7279, "ep_reward": 718.3783569335938, "reward": 0.2999565005302429, "action": -1.688353180885315}
{"mode": "train", "epochs": 4, "timestep": 7280, "ep_reward": 718.5589599609375, "reward": 0.18058031797409058, "action": -0.7633079290390015}
{"mode": "train", "epochs": 4, "timestep": 7281, "ep_reward": 718.6000366210938, "reward": 0.041070520877838135, "action": -0.679804801940918}
{"mode": "train", "epochs": 4, "timestep": 7282, "ep_reward": 718.6768798828125, "reward": 0.07683455944061279, "action": -1.524662733078003}
{"mode": "train", "epochs": 4, "timestep": 7283, "ep_reward": 718.888427734375, "reward": 0.21157455444335938, "action": -0.8353166580200195}
{"mode": "train", "epochs": 4, "timestep": 7284, "ep_reward": 719.242431640625, "reward": 0.3540284037590027, "action": -0.8060790300369263}
{"mode": "train", "epochs": 4, "timestep": 7285, "ep_reward": 719.7311401367188, "reward": 0.4887305498123169, "action": -0.8126105070114136}
{"mode": "train", "epochs": 4, "timestep": 7286, "ep_reward": 720.33740234375, "reward": 0.6062494516372681, "action": -0.8713752031326294}
{"mode": "train", "epochs": 4, "timestep": 7287, "ep_reward": 721.0384521484375, "reward": 0.7010416388511658, "action": -1.3223140239715576}
{"mode": "train", "epochs": 4, "timestep": 7288, "ep_reward": 721.8073120117188, "reward": 0.7688643932342529, "action": -1.438354730606079}
{"mode": "train", "epochs": 4, "timestep": 7289, "ep_reward": 722.62255859375, "reward": 0.8152215480804443, "action": -1.272307276725769}
{"mode": "train", "epochs": 4, "timestep": 7290, "ep_reward": 723.467041015625, "reward": 0.84446120262146, "action": -0.48126715421676636}
{"mode": "train", "epochs": 4, "timestep": 7291, "ep_reward": 724.3298950195312, "reward": 0.862877368927002, "action": -1.166185736656189}
{"mode": "train", "epochs": 4, "timestep": 7292, "ep_reward": 725.1882934570312, "reward": 0.858418345451355, "action": -0.6982994079589844}
{"mode": "train", "epochs": 4, "timestep": 7293, "ep_reward": 726.028076171875, "reward": 0.8397626876831055, "action": -1.1821205615997314}
{"mode": "train", "epochs": 4, "timestep": 7294, "ep_reward": 726.8228759765625, "reward": 0.7947878837585449, "action": -1.7197296619415283}
{"mode": "train", "epochs": 4, "timestep": 7295, "ep_reward": 727.538330078125, "reward": 0.7154733538627625, "action": -0.9194733500480652}
{"mode": "train", "epochs": 4, "timestep": 7296, "ep_reward": 728.1473999023438, "reward": 0.609056830406189, "action": -1.3392585515975952}
{"mode": "train", "epochs": 4, "timestep": 7297, "ep_reward": 728.6024169921875, "reward": 0.4550088047981262, "action": -1.2243112325668335}
{"mode": "train", "epochs": 4, "timestep": 7298, "ep_reward": 728.9379272460938, "reward": 0.3354801535606384, "action": -0.9192699790000916}
{"mode": "train", "epochs": 4, "timestep": 7299, "ep_reward": 729.160400390625, "reward": 0.22247624397277832, "action": -1.814988374710083}
{"mode": "train", "epochs": 4, "timestep": 7300, "ep_reward": 729.2501831054688, "reward": 0.08980196714401245, "action": 0.6929019689559937}
{"mode": "train", "epochs": 4, "timestep": 7301, "ep_reward": 729.2777709960938, "reward": 0.0276106595993042, "action": -0.805264413356781}
{"mode": "train", "epochs": 4, "timestep": 7302, "ep_reward": 729.4465942382812, "reward": 0.16880154609680176, "action": -1.5751750469207764}
{"mode": "train", "epochs": 4, "timestep": 7303, "ep_reward": 729.7481079101562, "reward": 0.30149686336517334, "action": -1.5115749835968018}
{"mode": "train", "epochs": 4, "timestep": 7304, "ep_reward": 730.1806030273438, "reward": 0.43252116441726685, "action": -0.9572363495826721}
{"mode": "train", "epochs": 4, "timestep": 7305, "ep_reward": 730.7379760742188, "reward": 0.5573587417602539, "action": -0.9893714785575867}
{"mode": "train", "epochs": 4, "timestep": 7306, "ep_reward": 731.3986206054688, "reward": 0.6606283783912659, "action": -0.39921706914901733}
{"mode": "train", "epochs": 4, "timestep": 7307, "ep_reward": 732.14453125, "reward": 0.7459169626235962, "action": -0.8195417523384094}
{"mode": "train", "epochs": 4, "timestep": 7308, "ep_reward": 732.9478759765625, "reward": 0.8033249378204346, "action": -1.1854138374328613}
{"mode": "train", "epochs": 4, "timestep": 7309, "ep_reward": 733.7850341796875, "reward": 0.8371587991714478, "action": -0.7431851625442505}
{"mode": "train", "epochs": 4, "timestep": 7310, "ep_reward": 734.6416015625, "reward": 0.8565710783004761, "action": -1.4066040515899658}
{"mode": "train", "epochs": 4, "timestep": 7311, "ep_reward": 735.4942016601562, "reward": 0.8526161313056946, "action": -1.3121893405914307}
{"mode": "train", "epochs": 4, "timestep": 7312, "ep_reward": 736.324462890625, "reward": 0.8302388787269592, "action": -1.0703507661819458}
{"mode": "train", "epochs": 4, "timestep": 7313, "ep_reward": 737.1115112304688, "reward": 0.7870358228683472, "action": -1.6307659149169922}
{"mode": "train", "epochs": 4, "timestep": 7314, "ep_reward": 737.8200073242188, "reward": 0.7085180282592773, "action": -0.4535372257232666}
{"mode": "train", "epochs": 4, "timestep": 7315, "ep_reward": 738.4278564453125, "reward": 0.6078706979751587, "action": -0.920211672782898}
{"mode": "train", "epochs": 4, "timestep": 7316, "ep_reward": 738.8884887695312, "reward": 0.46060502529144287, "action": -0.29428422451019287}
{"mode": "train", "epochs": 4, "timestep": 7317, "ep_reward": 739.2271728515625, "reward": 0.3386983275413513, "action": -0.5939437747001648}
{"mode": "train", "epochs": 4, "timestep": 7318, "ep_reward": 739.45361328125, "reward": 0.22646427154541016, "action": -0.6564222574234009}
{"mode": "train", "epochs": 4, "timestep": 7319, "ep_reward": 739.5477905273438, "reward": 0.09415501356124878, "action": -1.3119572401046753}
{"mode": "train", "epochs": 4, "timestep": 7320, "ep_reward": 739.5707397460938, "reward": 0.022923290729522705, "action": -0.49161165952682495}
{"mode": "train", "epochs": 4, "timestep": 7321, "ep_reward": 739.73583984375, "reward": 0.16511166095733643, "action": -0.8274284601211548}
{"mode": "train", "epochs": 4, "timestep": 7322, "ep_reward": 740.0429077148438, "reward": 0.307070255279541, "action": -0.5347166061401367}
{"mode": "train", "epochs": 4, "timestep": 7323, "ep_reward": 740.490966796875, "reward": 0.4480769634246826, "action": -1.0363949537277222}
{"mode": "train", "epochs": 4, "timestep": 7324, "ep_reward": 741.0596923828125, "reward": 0.5687483549118042, "action": -0.6498191952705383}
{"mode": "train", "epochs": 4, "timestep": 7325, "ep_reward": 741.7332153320312, "reward": 0.673552393913269, "action": -1.659071922302246}
{"mode": "train", "epochs": 4, "timestep": 7326, "ep_reward": 742.479248046875, "reward": 0.7460248470306396, "action": -1.4402728080749512}
{"mode": "train", "epochs": 4, "timestep": 7327, "ep_reward": 743.2796020507812, "reward": 0.8003235459327698, "action": -1.8810491561889648}
{"mode": "train", "epochs": 4, "timestep": 7328, "ep_reward": 744.1114501953125, "reward": 0.831839382648468, "action": -1.7341872453689575}
{"mode": "train", "epochs": 4, "timestep": 7329, "ep_reward": 744.9585571289062, "reward": 0.8471038937568665, "action": -0.5888118743896484}
{"mode": "train", "epochs": 4, "timestep": 7330, "ep_reward": 745.8131713867188, "reward": 0.8546186089515686, "action": -0.24527335166931152}
{"mode": "train", "epochs": 4, "timestep": 7331, "ep_reward": 746.6600952148438, "reward": 0.8469328880310059, "action": -0.9945171475410461}
{"mode": "train", "epochs": 4, "timestep": 7332, "ep_reward": 747.4722290039062, "reward": 0.8121389150619507, "action": -0.9620557427406311}
{"mode": "train", "epochs": 4, "timestep": 7333, "ep_reward": 748.224609375, "reward": 0.7523649334907532, "action": -0.43524760007858276}
{"mode": "train", "epochs": 4, "timestep": 7334, "ep_reward": 748.8921508789062, "reward": 0.6675200462341309, "action": -0.7378381490707397}
{"mode": "train", "epochs": 4, "timestep": 7335, "ep_reward": 749.4345092773438, "reward": 0.5423574447631836, "action": -1.0070451498031616}
{"mode": "train", "epochs": 4, "timestep": 7336, "ep_reward": 749.8113403320312, "reward": 0.3768284320831299, "action": -1.3607807159423828}
{"mode": "train", "epochs": 4, "timestep": 7337, "ep_reward": 750.0838012695312, "reward": 0.2724829912185669, "action": -0.2932453751564026}
{"mode": "train", "epochs": 4, "timestep": 7338, "ep_reward": 750.2316284179688, "reward": 0.14785230159759521, "action": -1.700953722000122}
{"mode": "train", "epochs": 4, "timestep": 7339, "ep_reward": 750.2351684570312, "reward": 0.0035469532012939453, "action": -0.7107990980148315}
{"mode": "train", "epochs": 4, "timestep": 7340, "ep_reward": 750.34716796875, "reward": 0.11201876401901245, "action": -0.9676553010940552}
{"mode": "train", "epochs": 4, "timestep": 7341, "ep_reward": 750.5982055664062, "reward": 0.25102925300598145, "action": -0.8790381550788879}
{"mode": "train", "epochs": 4, "timestep": 7342, "ep_reward": 750.9891357421875, "reward": 0.3909553289413452, "action": -1.2741591930389404}
{"mode": "train", "epochs": 4, "timestep": 7343, "ep_reward": 751.5053100585938, "reward": 0.5161786675453186, "action": -0.6115092039108276}
{"mode": "train", "epochs": 4, "timestep": 7344, "ep_reward": 752.1366577148438, "reward": 0.6313251256942749, "action": -0.5090823173522949}
{"mode": "train", "epochs": 4, "timestep": 7345, "ep_reward": 752.86083984375, "reward": 0.7241827249526978, "action": -0.7923016548156738}
{"mode": "train", "epochs": 4, "timestep": 7346, "ep_reward": 753.652099609375, "reward": 0.7912404537200928, "action": -0.7421260476112366}
{"mode": "train", "epochs": 4, "timestep": 7347, "ep_reward": 754.4906005859375, "reward": 0.8384859561920166, "action": -0.6624454259872437}
{"mode": "train", "epochs": 4, "timestep": 7348, "ep_reward": 755.359375, "reward": 0.8687642216682434, "action": -1.2348017692565918}
{"mode": "train", "epochs": 4, "timestep": 7349, "ep_reward": 756.2385864257812, "reward": 0.8791847825050354, "action": -1.3262767791748047}
{"mode": "train", "epochs": 4, "timestep": 7350, "ep_reward": 757.1127319335938, "reward": 0.8741342425346375, "action": -0.28384238481521606}
{"mode": "train", "epochs": 4, "timestep": 7351, "ep_reward": 757.9741821289062, "reward": 0.8614776730537415, "action": -1.9718811511993408}
{"mode": "train", "epochs": 4, "timestep": 7352, "ep_reward": 758.7889404296875, "reward": 0.8147763609886169, "action": -0.3545858860015869}
{"mode": "train", "epochs": 4, "timestep": 7353, "ep_reward": 759.5474243164062, "reward": 0.7584790587425232, "action": -0.9939308762550354}
{"mode": "train", "epochs": 4, "timestep": 7354, "ep_reward": 760.2125244140625, "reward": 0.6650696992874146, "action": -0.7836401462554932}
{"mode": "train", "epochs": 4, "timestep": 7355, "ep_reward": 760.74951171875, "reward": 0.5369765758514404, "action": -0.7700637578964233}
{"mode": "train", "epochs": 4, "timestep": 7356, "ep_reward": 761.1185913085938, "reward": 0.36906856298446655, "action": -0.45546406507492065}
{"mode": "train", "epochs": 4, "timestep": 7357, "ep_reward": 761.3792724609375, "reward": 0.26066744327545166, "action": -1.0056604146957397}
{"mode": "train", "epochs": 4, "timestep": 7358, "ep_reward": 761.5134887695312, "reward": 0.13423234224319458, "action": -0.32883262634277344}
{"mode": "train", "epochs": 4, "timestep": 7359, "ep_reward": 761.501220703125, "reward": -0.012270450592041016, "action": -0.5436069965362549}
{"mode": "train", "epochs": 4, "timestep": 7360, "ep_reward": 761.6273803710938, "reward": 0.12617236375808716, "action": -0.6424374580383301}
{"mode": "train", "epochs": 4, "timestep": 7361, "ep_reward": 761.8968505859375, "reward": 0.269448459148407, "action": -1.7502000331878662}
{"mode": "train", "epochs": 4, "timestep": 7362, "ep_reward": 762.29443359375, "reward": 0.39757174253463745, "action": -0.34969133138656616}
{"mode": "train", "epochs": 4, "timestep": 7363, "ep_reward": 762.8275146484375, "reward": 0.5330700874328613, "action": -1.4963397979736328}
{"mode": "train", "epochs": 4, "timestep": 7364, "ep_reward": 763.46337890625, "reward": 0.6358643770217896, "action": -0.21670973300933838}
{"mode": "train", "epochs": 4, "timestep": 7365, "ep_reward": 764.193603515625, "reward": 0.7302167415618896, "action": -0.3199440836906433}
{"mode": "train", "epochs": 4, "timestep": 7366, "ep_reward": 764.9929809570312, "reward": 0.799396812915802, "action": -0.7840226888656616}
{"mode": "train", "epochs": 4, "timestep": 7367, "ep_reward": 765.8368530273438, "reward": 0.8439016938209534, "action": -0.8828647136688232}
{"mode": "train", "epochs": 4, "timestep": 7368, "ep_reward": 766.70751953125, "reward": 0.8706382513046265, "action": -0.3572959899902344}
{"mode": "train", "epochs": 4, "timestep": 7369, "ep_reward": 767.5939331054688, "reward": 0.8864192962646484, "action": -1.024070382118225}
{"mode": "train", "epochs": 4, "timestep": 7370, "ep_reward": 768.4766845703125, "reward": 0.8827666640281677, "action": -1.1456177234649658}
{"mode": "train", "epochs": 4, "timestep": 7371, "ep_reward": 769.3394165039062, "reward": 0.8627437949180603, "action": -0.4591216444969177}
{"mode": "train", "epochs": 4, "timestep": 7372, "ep_reward": 770.1697387695312, "reward": 0.830300509929657, "action": -1.158487319946289}
{"mode": "train", "epochs": 4, "timestep": 7373, "ep_reward": 770.9378662109375, "reward": 0.768138587474823, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7374, "ep_reward": 771.602783203125, "reward": 0.6649003028869629, "action": -0.8954543471336365}
{"mode": "train", "epochs": 4, "timestep": 7375, "ep_reward": 772.1382446289062, "reward": 0.5354571342468262, "action": -0.843010663986206}
{"mode": "train", "epochs": 4, "timestep": 7376, "ep_reward": 772.5070190429688, "reward": 0.3687604069709778, "action": -0.9825552701950073}
{"mode": "train", "epochs": 4, "timestep": 7377, "ep_reward": 772.7695922851562, "reward": 0.2625894546508789, "action": -1.0641978979110718}
{"mode": "train", "epochs": 4, "timestep": 7378, "ep_reward": 772.9060668945312, "reward": 0.1364802122116089, "action": -0.5692747831344604}
{"mode": "train", "epochs": 4, "timestep": 7379, "ep_reward": 772.8963623046875, "reward": -0.009719252586364746, "action": -0.9838550686836243}
{"mode": "train", "epochs": 4, "timestep": 7380, "ep_reward": 773.020263671875, "reward": 0.12390094995498657, "action": -0.4179777503013611}
{"mode": "train", "epochs": 4, "timestep": 7381, "ep_reward": 773.2902221679688, "reward": 0.2699872851371765, "action": -1.1901462078094482}
{"mode": "train", "epochs": 4, "timestep": 7382, "ep_reward": 773.6945190429688, "reward": 0.40430039167404175, "action": -1.2246659994125366}
{"mode": "train", "epochs": 4, "timestep": 7383, "ep_reward": 774.2227783203125, "reward": 0.5282589197158813, "action": -1.4650386571884155}
{"mode": "train", "epochs": 4, "timestep": 7384, "ep_reward": 774.8549194335938, "reward": 0.6321322917938232, "action": -1.1937196254730225}
{"mode": "train", "epochs": 4, "timestep": 7385, "ep_reward": 775.5726318359375, "reward": 0.7177087664604187, "action": -1.1665940284729004}
{"mode": "train", "epochs": 4, "timestep": 7386, "ep_reward": 776.3538818359375, "reward": 0.7812389135360718, "action": -1.4387974739074707}
{"mode": "train", "epochs": 4, "timestep": 7387, "ep_reward": 777.1756591796875, "reward": 0.8217534422874451, "action": -0.12052899599075317}
{"mode": "train", "epochs": 4, "timestep": 7388, "ep_reward": 778.0306396484375, "reward": 0.8549821376800537, "action": -0.37784385681152344}
{"mode": "train", "epochs": 4, "timestep": 7389, "ep_reward": 778.89892578125, "reward": 0.8683009147644043, "action": -0.2345266342163086}
{"mode": "train", "epochs": 4, "timestep": 7390, "ep_reward": 779.7650756835938, "reward": 0.8661738634109497, "action": -1.9831087589263916}
{"mode": "train", "epochs": 4, "timestep": 7391, "ep_reward": 780.5958862304688, "reward": 0.830785870552063, "action": -0.039302706718444824}
{"mode": "train", "epochs": 4, "timestep": 7392, "ep_reward": 781.386962890625, "reward": 0.7911059856414795, "action": -0.7823509573936462}
{"mode": "train", "epochs": 4, "timestep": 7393, "ep_reward": 782.1041870117188, "reward": 0.7172393798828125, "action": -1.1368012428283691}
{"mode": "train", "epochs": 4, "timestep": 7394, "ep_reward": 782.708740234375, "reward": 0.604558527469635, "action": -1.9248534440994263}
{"mode": "train", "epochs": 4, "timestep": 7395, "ep_reward": 783.1471557617188, "reward": 0.4384447932243347, "action": -0.6303476095199585}
{"mode": "train", "epochs": 4, "timestep": 7396, "ep_reward": 783.4657592773438, "reward": 0.3185890316963196, "action": -0.9430760741233826}
{"mode": "train", "epochs": 4, "timestep": 7397, "ep_reward": 783.6682739257812, "reward": 0.20253485441207886, "action": -0.6423543691635132}
{"mode": "train", "epochs": 4, "timestep": 7398, "ep_reward": 783.734619140625, "reward": 0.06637406349182129, "action": -1.285236120223999}
{"mode": "train", "epochs": 4, "timestep": 7399, "ep_reward": 783.786376953125, "reward": 0.05177342891693115, "action": -1.1064808368682861}
{"mode": "train", "epochs": 4, "timestep": 7400, "ep_reward": 783.976318359375, "reward": 0.18991953134536743, "action": -0.2115076184272766}
{"mode": "train", "epochs": 4, "timestep": 7401, "ep_reward": 784.3159790039062, "reward": 0.3396608233451843, "action": -1.9136892557144165}
{"mode": "train", "epochs": 4, "timestep": 7402, "ep_reward": 784.77734375, "reward": 0.461376428604126, "action": -1.543696403503418}
{"mode": "train", "epochs": 4, "timestep": 7403, "ep_reward": 785.3523559570312, "reward": 0.5750253200531006, "action": -1.2632458209991455}
{"mode": "train", "epochs": 4, "timestep": 7404, "ep_reward": 786.024169921875, "reward": 0.6717946529388428, "action": -1.7886451482772827}
{"mode": "train", "epochs": 4, "timestep": 7405, "ep_reward": 786.7648315429688, "reward": 0.7406834363937378, "action": -0.8355554938316345}
{"mode": "train", "epochs": 4, "timestep": 7406, "ep_reward": 787.561767578125, "reward": 0.7969406247138977, "action": -0.274127721786499}
{"mode": "train", "epochs": 4, "timestep": 7407, "ep_reward": 788.3983764648438, "reward": 0.8366082310676575, "action": -1.8454575538635254}
{"mode": "train", "epochs": 4, "timestep": 7408, "ep_reward": 789.2412719726562, "reward": 0.8429110646247864, "action": -1.3389456272125244}
{"mode": "train", "epochs": 4, "timestep": 7409, "ep_reward": 790.0758056640625, "reward": 0.8345623016357422, "action": 0.34737515449523926}
{"mode": "train", "epochs": 4, "timestep": 7410, "ep_reward": 790.8972778320312, "reward": 0.821492075920105, "action": -1.1774682998657227}
{"mode": "train", "epochs": 4, "timestep": 7411, "ep_reward": 791.6669921875, "reward": 0.7697434425354004, "action": -1.2752163410186768}
{"mode": "train", "epochs": 4, "timestep": 7412, "ep_reward": 792.3529052734375, "reward": 0.6859103441238403, "action": -0.7126818299293518}
{"mode": "train", "epochs": 4, "timestep": 7413, "ep_reward": 792.9241333007812, "reward": 0.5712476968765259, "action": -1.5181937217712402}
{"mode": "train", "epochs": 4, "timestep": 7414, "ep_reward": 793.329833984375, "reward": 0.40568506717681885, "action": -0.9864939451217651}
{"mode": "train", "epochs": 4, "timestep": 7415, "ep_reward": 793.6372680664062, "reward": 0.3074425458908081, "action": -1.5820627212524414}
{"mode": "train", "epochs": 4, "timestep": 7416, "ep_reward": 793.82666015625, "reward": 0.18941271305084229, "action": -0.8007018566131592}
{"mode": "train", "epochs": 4, "timestep": 7417, "ep_reward": 793.8778076171875, "reward": 0.05117678642272949, "action": -1.4437021017074585}
{"mode": "train", "epochs": 4, "timestep": 7418, "ep_reward": 793.9447631835938, "reward": 0.06696081161499023, "action": -0.9109997749328613}
{"mode": "train", "epochs": 4, "timestep": 7419, "ep_reward": 794.1500854492188, "reward": 0.20533573627471924, "action": -0.825334906578064}
{"mode": "train", "epochs": 4, "timestep": 7420, "ep_reward": 794.497314453125, "reward": 0.3472135066986084, "action": -1.7772136926651}
{"mode": "train", "epochs": 4, "timestep": 7421, "ep_reward": 794.9680786132812, "reward": 0.4707728624343872, "action": -0.3118478059768677}
{"mode": "train", "epochs": 4, "timestep": 7422, "ep_reward": 795.56494140625, "reward": 0.5968804359436035, "action": -1.1441590785980225}
{"mode": "train", "epochs": 4, "timestep": 7423, "ep_reward": 796.2557373046875, "reward": 0.6908184289932251, "action": -1.3400253057479858}
{"mode": "train", "epochs": 4, "timestep": 7424, "ep_reward": 797.0162963867188, "reward": 0.7605575919151306, "action": -0.6390256881713867}
{"mode": "train", "epochs": 4, "timestep": 7425, "ep_reward": 797.831787109375, "reward": 0.8154668807983398, "action": -0.9462277293205261}
{"mode": "train", "epochs": 4, "timestep": 7426, "ep_reward": 798.6796875, "reward": 0.8479052782058716, "action": -1.0168555974960327}
{"mode": "train", "epochs": 4, "timestep": 7427, "ep_reward": 799.5421142578125, "reward": 0.8624131679534912, "action": -0.621051549911499}
{"mode": "train", "epochs": 4, "timestep": 7428, "ep_reward": 800.4055786132812, "reward": 0.8634414672851562, "action": -1.5364174842834473}
{"mode": "train", "epochs": 4, "timestep": 7429, "ep_reward": 801.2440795898438, "reward": 0.8385013341903687, "action": -1.11077880859375}
{"mode": "train", "epochs": 4, "timestep": 7430, "ep_reward": 802.0393676757812, "reward": 0.7952796816825867, "action": -0.9145733118057251}
{"mode": "train", "epochs": 4, "timestep": 7431, "ep_reward": 802.7659912109375, "reward": 0.7266527414321899, "action": -0.5711098909378052}
{"mode": "train", "epochs": 4, "timestep": 7432, "ep_reward": 803.3945922851562, "reward": 0.6286250352859497, "action": -1.1790337562561035}
{"mode": "train", "epochs": 4, "timestep": 7433, "ep_reward": 803.877685546875, "reward": 0.4830726385116577, "action": -0.45725369453430176}
{"mode": "train", "epochs": 4, "timestep": 7434, "ep_reward": 804.2230224609375, "reward": 0.34531497955322266, "action": -1.1437746286392212}
{"mode": "train", "epochs": 4, "timestep": 7435, "ep_reward": 804.45751953125, "reward": 0.23447823524475098, "action": -0.24998509883880615}
{"mode": "train", "epochs": 4, "timestep": 7436, "ep_reward": 804.5609741210938, "reward": 0.10345619916915894, "action": -1.3385249376296997}
{"mode": "train", "epochs": 4, "timestep": 7437, "ep_reward": 804.5737915039062, "reward": 0.01282966136932373, "action": -1.125345230102539}
{"mode": "train", "epochs": 4, "timestep": 7438, "ep_reward": 804.7298583984375, "reward": 0.15604639053344727, "action": -1.291075587272644}
{"mode": "train", "epochs": 4, "timestep": 7439, "ep_reward": 805.0220336914062, "reward": 0.292156457901001, "action": -0.5019415020942688}
{"mode": "train", "epochs": 4, "timestep": 7440, "ep_reward": 805.4572143554688, "reward": 0.43520766496658325, "action": -1.8153213262557983}
{"mode": "train", "epochs": 4, "timestep": 7441, "ep_reward": 806.0062255859375, "reward": 0.5490347146987915, "action": -1.506752848625183}
{"mode": "train", "epochs": 4, "timestep": 7442, "ep_reward": 806.65478515625, "reward": 0.6485644578933716, "action": -1.1592614650726318}
{"mode": "train", "epochs": 4, "timestep": 7443, "ep_reward": 807.38427734375, "reward": 0.729502260684967, "action": -1.449896216392517}
{"mode": "train", "epochs": 4, "timestep": 7444, "ep_reward": 808.1691284179688, "reward": 0.7848471999168396, "action": -1.4259631633758545}
{"mode": "train", "epochs": 4, "timestep": 7445, "ep_reward": 808.9887084960938, "reward": 0.8195979595184326, "action": -0.2114957571029663}
{"mode": "train", "epochs": 4, "timestep": 7446, "ep_reward": 809.8341674804688, "reward": 0.8454362154006958, "action": -1.6875892877578735}
{"mode": "train", "epochs": 4, "timestep": 7447, "ep_reward": 810.6727905273438, "reward": 0.838612973690033, "action": -1.4308030605316162}
{"mode": "train", "epochs": 4, "timestep": 7448, "ep_reward": 811.4857788085938, "reward": 0.8130122423171997, "action": -0.739406168460846}
{"mode": "train", "epochs": 4, "timestep": 7449, "ep_reward": 812.255126953125, "reward": 0.7693591713905334, "action": -1.204920768737793}
{"mode": "train", "epochs": 4, "timestep": 7450, "ep_reward": 812.945068359375, "reward": 0.6899473071098328, "action": -1.6319122314453125}
{"mode": "train", "epochs": 4, "timestep": 7451, "ep_reward": 813.5109252929688, "reward": 0.5658600926399231, "action": -0.692054033279419}
{"mode": "train", "epochs": 4, "timestep": 7452, "ep_reward": 813.9258422851562, "reward": 0.41492897272109985, "action": -1.4794195890426636}
{"mode": "train", "epochs": 4, "timestep": 7453, "ep_reward": 814.2448120117188, "reward": 0.3189483880996704, "action": -1.3325437307357788}
{"mode": "train", "epochs": 4, "timestep": 7454, "ep_reward": 814.4478149414062, "reward": 0.2030264139175415, "action": -0.6600872278213501}
{"mode": "train", "epochs": 4, "timestep": 7455, "ep_reward": 814.5147705078125, "reward": 0.06693071126937866, "action": -1.3730926513671875}
{"mode": "train", "epochs": 4, "timestep": 7456, "ep_reward": 814.56591796875, "reward": 0.05114775896072388, "action": -1.4024899005889893}
{"mode": "train", "epochs": 4, "timestep": 7457, "ep_reward": 814.7553100585938, "reward": 0.18940895795822144, "action": -0.4445594549179077}
{"mode": "train", "epochs": 4, "timestep": 7458, "ep_reward": 815.091796875, "reward": 0.33650726079940796, "action": -0.4935200810432434}
{"mode": "train", "epochs": 4, "timestep": 7459, "ep_reward": 815.5672607421875, "reward": 0.47544723749160767, "action": -1.0397796630859375}
{"mode": "train", "epochs": 4, "timestep": 7460, "ep_reward": 816.1593017578125, "reward": 0.5920311212539673, "action": -1.2435109615325928}
{"mode": "train", "epochs": 4, "timestep": 7461, "ep_reward": 816.845703125, "reward": 0.686413049697876, "action": -1.1288716793060303}
{"mode": "train", "epochs": 4, "timestep": 7462, "ep_reward": 817.60595703125, "reward": 0.7602834105491638, "action": -1.9273345470428467}
{"mode": "train", "epochs": 4, "timestep": 7463, "ep_reward": 818.4124145507812, "reward": 0.8064642548561096, "action": -1.8050205707550049}
{"mode": "train", "epochs": 4, "timestep": 7464, "ep_reward": 819.2481079101562, "reward": 0.8357187509536743, "action": -0.5254718065261841}
{"mode": "train", "epochs": 4, "timestep": 7465, "ep_reward": 820.1063842773438, "reward": 0.8582979440689087, "action": -1.3098098039627075}
{"mode": "train", "epochs": 4, "timestep": 7466, "ep_reward": 820.9631958007812, "reward": 0.8568151593208313, "action": -0.3984408974647522}
{"mode": "train", "epochs": 4, "timestep": 7467, "ep_reward": 821.8084106445312, "reward": 0.8452080488204956, "action": -1.3350105285644531}
{"mode": "train", "epochs": 4, "timestep": 7468, "ep_reward": 822.6124877929688, "reward": 0.8040891289710999, "action": -1.1544620990753174}
{"mode": "train", "epochs": 4, "timestep": 7469, "ep_reward": 823.350341796875, "reward": 0.7378718852996826, "action": -0.3104553818702698}
{"mode": "train", "epochs": 4, "timestep": 7470, "ep_reward": 823.9991455078125, "reward": 0.6488326191902161, "action": -1.3725371360778809}
{"mode": "train", "epochs": 4, "timestep": 7471, "ep_reward": 824.5065307617188, "reward": 0.5073785781860352, "action": -1.8420313596725464}
{"mode": "train", "epochs": 4, "timestep": 7472, "ep_reward": 824.867919921875, "reward": 0.3614077568054199, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7473, "ep_reward": 825.1219482421875, "reward": 0.2540184259414673, "action": -0.08775842189788818}
{"mode": "train", "epochs": 4, "timestep": 7474, "ep_reward": 825.248291015625, "reward": 0.1263422966003418, "action": -0.7835078835487366}
{"mode": "train", "epochs": 4, "timestep": 7475, "ep_reward": 825.2357177734375, "reward": -0.012574315071105957, "action": -1.3556468486785889}
{"mode": "train", "epochs": 4, "timestep": 7476, "ep_reward": 825.36962890625, "reward": 0.13390976190567017, "action": -1.5406310558319092}
{"mode": "train", "epochs": 4, "timestep": 7477, "ep_reward": 825.635986328125, "reward": 0.2663472890853882, "action": -1.0805366039276123}
{"mode": "train", "epochs": 4, "timestep": 7478, "ep_reward": 826.0403442382812, "reward": 0.4043726921081543, "action": -0.9294300675392151}
{"mode": "train", "epochs": 4, "timestep": 7479, "ep_reward": 826.572998046875, "reward": 0.5326720476150513, "action": -1.5700373649597168}
{"mode": "train", "epochs": 4, "timestep": 7480, "ep_reward": 827.20751953125, "reward": 0.6345168352127075, "action": -1.4059555530548096}
{"mode": "train", "epochs": 4, "timestep": 7481, "ep_reward": 827.9240112304688, "reward": 0.7164851427078247, "action": -0.42970651388168335}
{"mode": "train", "epochs": 4, "timestep": 7482, "ep_reward": 828.7088012695312, "reward": 0.7848033308982849, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7483, "ep_reward": 829.5255126953125, "reward": 0.8166996836662292, "action": -0.7622004747390747}
{"mode": "train", "epochs": 4, "timestep": 7484, "ep_reward": 830.365966796875, "reward": 0.8404761552810669, "action": -1.362087368965149}
{"mode": "train", "epochs": 4, "timestep": 7485, "ep_reward": 831.2054443359375, "reward": 0.839501678943634, "action": -0.7448589205741882}
{"mode": "train", "epochs": 4, "timestep": 7486, "ep_reward": 832.0292358398438, "reward": 0.8237813115119934, "action": -1.4906013011932373}
{"mode": "train", "epochs": 4, "timestep": 7487, "ep_reward": 832.8060913085938, "reward": 0.7768752574920654, "action": -0.8628062009811401}
{"mode": "train", "epochs": 4, "timestep": 7488, "ep_reward": 833.5128784179688, "reward": 0.7067830562591553, "action": -0.6003860235214233}
{"mode": "train", "epochs": 4, "timestep": 7489, "ep_reward": 834.1172485351562, "reward": 0.6043829321861267, "action": -0.7502468824386597}
{"mode": "train", "epochs": 4, "timestep": 7490, "ep_reward": 834.576416015625, "reward": 0.4591755270957947, "action": -1.0790892839431763}
{"mode": "train", "epochs": 4, "timestep": 7491, "ep_reward": 834.9166870117188, "reward": 0.3402780294418335, "action": -0.9192761182785034}
{"mode": "train", "epochs": 4, "timestep": 7492, "ep_reward": 835.1450805664062, "reward": 0.22839337587356567, "action": -0.617131233215332}
{"mode": "train", "epochs": 4, "timestep": 7493, "ep_reward": 835.2415161132812, "reward": 0.0964125394821167, "action": -1.210986852645874}
{"mode": "train", "epochs": 4, "timestep": 7494, "ep_reward": 835.2620239257812, "reward": 0.020507514476776123, "action": -0.7073619365692139}
{"mode": "train", "epochs": 4, "timestep": 7495, "ep_reward": 835.4246826171875, "reward": 0.16268044710159302, "action": -1.2715879678726196}
{"mode": "train", "epochs": 4, "timestep": 7496, "ep_reward": 835.7238159179688, "reward": 0.2991407513618469, "action": -0.7463372945785522}
{"mode": "train", "epochs": 4, "timestep": 7497, "ep_reward": 836.1626586914062, "reward": 0.4388386011123657, "action": -1.8275911808013916}
{"mode": "train", "epochs": 4, "timestep": 7498, "ep_reward": 836.7149047851562, "reward": 0.5522400140762329, "action": -1.2893798351287842}
{"mode": "train", "epochs": 4, "timestep": 7499, "ep_reward": 837.3682250976562, "reward": 0.653299868106842, "action": -1.6057885885238647}
{"mode": "train", "epochs": 4, "timestep": 7500, "ep_reward": 838.0968017578125, "reward": 0.7285704612731934, "action": -0.804961085319519}
{"mode": "train", "epochs": 4, "timestep": 7501, "ep_reward": 838.885986328125, "reward": 0.7891957759857178, "action": -1.0268661975860596}
{"mode": "train", "epochs": 4, "timestep": 7502, "ep_reward": 839.7119750976562, "reward": 0.8260043859481812, "action": -0.6244815587997437}
{"mode": "train", "epochs": 4, "timestep": 7503, "ep_reward": 840.5587768554688, "reward": 0.8468079566955566, "action": -0.8090838193893433}
{"mode": "train", "epochs": 4, "timestep": 7504, "ep_reward": 841.406005859375, "reward": 0.8472017049789429, "action": -0.26999127864837646}
{"mode": "train", "epochs": 4, "timestep": 7505, "ep_reward": 842.2390747070312, "reward": 0.8330492973327637, "action": -1.7340673208236694}
{"mode": "train", "epochs": 4, "timestep": 7506, "ep_reward": 843.0209350585938, "reward": 0.7818695306777954, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7507, "ep_reward": 843.71728515625, "reward": 0.6963751316070557, "action": -1.014433741569519}
{"mode": "train", "epochs": 4, "timestep": 7508, "ep_reward": 844.3010864257812, "reward": 0.5837968587875366, "action": -0.33235472440719604}
{"mode": "train", "epochs": 4, "timestep": 7509, "ep_reward": 844.7400512695312, "reward": 0.4389687776565552, "action": -1.4403282403945923}
{"mode": "train", "epochs": 4, "timestep": 7510, "ep_reward": 845.0680541992188, "reward": 0.32797741889953613, "action": -1.7376630306243896}
{"mode": "train", "epochs": 4, "timestep": 7511, "ep_reward": 845.2819213867188, "reward": 0.21387964487075806, "action": -0.45610469579696655}
{"mode": "train", "epochs": 4, "timestep": 7512, "ep_reward": 845.3614501953125, "reward": 0.07950890064239502, "action": -1.3317077159881592}
{"mode": "train", "epochs": 4, "timestep": 7513, "ep_reward": 845.3997802734375, "reward": 0.03830212354660034, "action": -0.9917270541191101}
{"mode": "train", "epochs": 4, "timestep": 7514, "ep_reward": 845.5780029296875, "reward": 0.17823243141174316, "action": -0.47317981719970703}
{"mode": "train", "epochs": 4, "timestep": 7515, "ep_reward": 845.9027709960938, "reward": 0.3247663378715515, "action": -1.1456005573272705}
{"mode": "train", "epochs": 4, "timestep": 7516, "ep_reward": 846.3594970703125, "reward": 0.456744909286499, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7517, "ep_reward": 846.9252319335938, "reward": 0.56572425365448, "action": -1.072784185409546}
{"mode": "train", "epochs": 4, "timestep": 7518, "ep_reward": 847.5917358398438, "reward": 0.6665092706680298, "action": -1.5032875537872314}
{"mode": "train", "epochs": 4, "timestep": 7519, "ep_reward": 848.3318481445312, "reward": 0.740106463432312, "action": -0.6841497421264648}
{"mode": "train", "epochs": 4, "timestep": 7520, "ep_reward": 849.13134765625, "reward": 0.7994978427886963, "action": -0.818618655204773}
{"mode": "train", "epochs": 4, "timestep": 7521, "ep_reward": 849.9679565429688, "reward": 0.8365908861160278, "action": -0.604223370552063}
{"mode": "train", "epochs": 4, "timestep": 7522, "ep_reward": 850.82470703125, "reward": 0.8567247986793518, "action": -1.77847421169281}
{"mode": "train", "epochs": 4, "timestep": 7523, "ep_reward": 851.6736450195312, "reward": 0.8489677309989929, "action": -1.0166597366333008}
{"mode": "train", "epochs": 4, "timestep": 7524, "ep_reward": 852.5020141601562, "reward": 0.8283827304840088, "action": -1.2422202825546265}
{"mode": "train", "epochs": 4, "timestep": 7525, "ep_reward": 853.2843627929688, "reward": 0.7823491096496582, "action": -0.7051904201507568}
{"mode": "train", "epochs": 4, "timestep": 7526, "ep_reward": 853.9976196289062, "reward": 0.7132352590560913, "action": -0.569566547870636}
{"mode": "train", "epochs": 4, "timestep": 7527, "ep_reward": 854.6090087890625, "reward": 0.6113780736923218, "action": -1.1493688821792603}
{"mode": "train", "epochs": 4, "timestep": 7528, "ep_reward": 855.070068359375, "reward": 0.46103721857070923, "action": -1.3208045959472656}
{"mode": "train", "epochs": 4, "timestep": 7529, "ep_reward": 855.4071655273438, "reward": 0.33709555864334106, "action": -1.3993456363677979}
{"mode": "train", "epochs": 4, "timestep": 7530, "ep_reward": 855.6316528320312, "reward": 0.22446107864379883, "action": -1.9354991912841797}
{"mode": "train", "epochs": 4, "timestep": 7531, "ep_reward": 855.7235717773438, "reward": 0.09192311763763428, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7532, "ep_reward": 855.7486572265625, "reward": 0.025091886520385742, "action": -1.0873700380325317}
{"mode": "train", "epochs": 4, "timestep": 7533, "ep_reward": 855.9154052734375, "reward": 0.16674566268920898, "action": -0.9280419945716858}
{"mode": "train", "epochs": 4, "timestep": 7534, "ep_reward": 856.2229614257812, "reward": 0.3075532913208008, "action": -0.5889626145362854}
{"mode": "train", "epochs": 4, "timestep": 7535, "ep_reward": 856.6710815429688, "reward": 0.4481499195098877, "action": -0.8424813747406006}
{"mode": "train", "epochs": 4, "timestep": 7536, "ep_reward": 857.2421875, "reward": 0.5710976123809814, "action": -0.47945302724838257}
{"mode": "train", "epochs": 4, "timestep": 7537, "ep_reward": 857.9194946289062, "reward": 0.6773247718811035, "action": -0.25749337673187256}
{"mode": "train", "epochs": 4, "timestep": 7538, "ep_reward": 858.6815185546875, "reward": 0.7620044946670532, "action": -1.1372498273849487}
{"mode": "train", "epochs": 4, "timestep": 7539, "ep_reward": 859.4985961914062, "reward": 0.817085325717926, "action": -0.3887614607810974}
{"mode": "train", "epochs": 4, "timestep": 7540, "ep_reward": 860.3588256835938, "reward": 0.8602082133293152, "action": -1.112805724143982}
{"mode": "train", "epochs": 4, "timestep": 7541, "ep_reward": 861.2406616210938, "reward": 0.8818557858467102, "action": -1.0895919799804688}
{"mode": "train", "epochs": 4, "timestep": 7542, "ep_reward": 862.1307373046875, "reward": 0.8900872468948364, "action": -0.3855130672454834}
{"mode": "train", "epochs": 4, "timestep": 7543, "ep_reward": 863.0208740234375, "reward": 0.8901671767234802, "action": -1.2788667678833008}
{"mode": "train", "epochs": 4, "timestep": 7544, "ep_reward": 863.8895874023438, "reward": 0.8686909079551697, "action": -1.2189334630966187}
{"mode": "train", "epochs": 4, "timestep": 7545, "ep_reward": 864.7188720703125, "reward": 0.8293136954307556, "action": -0.7051934599876404}
{"mode": "train", "epochs": 4, "timestep": 7546, "ep_reward": 865.490234375, "reward": 0.7713443636894226, "action": -1.8390458822250366}
{"mode": "train", "epochs": 4, "timestep": 7547, "ep_reward": 866.1607666015625, "reward": 0.6705412864685059, "action": -1.655928373336792}
{"mode": "train", "epochs": 4, "timestep": 7548, "ep_reward": 866.692138671875, "reward": 0.5313667058944702, "action": -0.5623984932899475}
{"mode": "train", "epochs": 4, "timestep": 7549, "ep_reward": 867.0599975585938, "reward": 0.367867112159729, "action": -0.43856656551361084}
{"mode": "train", "epochs": 4, "timestep": 7550, "ep_reward": 867.3214721679688, "reward": 0.26149964332580566, "action": -0.6131948232650757}
{"mode": "train", "epochs": 4, "timestep": 7551, "ep_reward": 867.4566650390625, "reward": 0.13516443967819214, "action": 0.22872674465179443}
{"mode": "train", "epochs": 4, "timestep": 7552, "ep_reward": 867.4454345703125, "reward": -0.011213302612304688, "action": -0.6469310522079468}
{"mode": "train", "epochs": 4, "timestep": 7553, "ep_reward": 867.5706787109375, "reward": 0.12525969743728638, "action": 0.12186324596405029}
{"mode": "train", "epochs": 4, "timestep": 7554, "ep_reward": 867.8485717773438, "reward": 0.27789342403411865, "action": -1.7989606857299805}
{"mode": "train", "epochs": 4, "timestep": 7555, "ep_reward": 868.252197265625, "reward": 0.40365445613861084, "action": -0.8140809535980225}
{"mode": "train", "epochs": 4, "timestep": 7556, "ep_reward": 868.78466796875, "reward": 0.5324927568435669, "action": -0.45948565006256104}
{"mode": "train", "epochs": 4, "timestep": 7557, "ep_reward": 869.4307250976562, "reward": 0.6460744142532349, "action": -1.4602937698364258}
{"mode": "train", "epochs": 4, "timestep": 7558, "ep_reward": 870.1577758789062, "reward": 0.7270301580429077, "action": -0.7287960052490234}
{"mode": "train", "epochs": 4, "timestep": 7559, "ep_reward": 870.9517211914062, "reward": 0.79393470287323, "action": -0.4735642075538635}
{"mode": "train", "epochs": 4, "timestep": 7560, "ep_reward": 871.79443359375, "reward": 0.8427366614341736, "action": -0.37463265657424927}
{"mode": "train", "epochs": 4, "timestep": 7561, "ep_reward": 872.6691284179688, "reward": 0.8746773600578308, "action": -1.0099785327911377}
{"mode": "train", "epochs": 4, "timestep": 7562, "ep_reward": 873.555908203125, "reward": 0.8868014812469482, "action": -1.1833055019378662}
{"mode": "train", "epochs": 4, "timestep": 7563, "ep_reward": 874.439697265625, "reward": 0.883796751499176, "action": -0.21685928106307983}
{"mode": "train", "epochs": 4, "timestep": 7564, "ep_reward": 875.3134765625, "reward": 0.8737562298774719, "action": -0.8863624930381775}
{"mode": "train", "epochs": 4, "timestep": 7565, "ep_reward": 876.15478515625, "reward": 0.841305136680603, "action": -1.2446043491363525}
{"mode": "train", "epochs": 4, "timestep": 7566, "ep_reward": 876.9381713867188, "reward": 0.7833983898162842, "action": -1.5471402406692505}
{"mode": "train", "epochs": 4, "timestep": 7567, "ep_reward": 877.6306762695312, "reward": 0.6924916505813599, "action": -0.8714079260826111}
{"mode": "train", "epochs": 4, "timestep": 7568, "ep_reward": 878.203369140625, "reward": 0.5726983547210693, "action": -1.1962625980377197}
{"mode": "train", "epochs": 4, "timestep": 7569, "ep_reward": 878.6111450195312, "reward": 0.40775614976882935, "action": -0.6872214078903198}
{"mode": "train", "epochs": 4, "timestep": 7570, "ep_reward": 878.8980102539062, "reward": 0.28687798976898193, "action": -1.0907671451568604}
{"mode": "train", "epochs": 4, "timestep": 7571, "ep_reward": 879.06298828125, "reward": 0.16498607397079468, "action": -1.0351922512054443}
{"mode": "train", "epochs": 4, "timestep": 7572, "ep_reward": 879.0861206054688, "reward": 0.023124754428863525, "action": -0.688216507434845}
{"mode": "train", "epochs": 4, "timestep": 7573, "ep_reward": 879.18017578125, "reward": 0.09405678510665894, "action": -0.23820769786834717}
{"mode": "train", "epochs": 4, "timestep": 7574, "ep_reward": 879.4217529296875, "reward": 0.241594135761261, "action": -0.8485472798347473}
{"mode": "train", "epochs": 4, "timestep": 7575, "ep_reward": 879.802490234375, "reward": 0.38074439764022827, "action": -0.7640459537506104}
{"mode": "train", "epochs": 4, "timestep": 7576, "ep_reward": 880.3143310546875, "reward": 0.5118569135665894, "action": -1.321627140045166}
{"mode": "train", "epochs": 4, "timestep": 7577, "ep_reward": 880.9341430664062, "reward": 0.6197925806045532, "action": -1.3722567558288574}
{"mode": "train", "epochs": 4, "timestep": 7578, "ep_reward": 881.641357421875, "reward": 0.7072426676750183, "action": -0.11217373609542847}
{"mode": "train", "epochs": 4, "timestep": 7579, "ep_reward": 882.42626953125, "reward": 0.7849394083023071, "action": -0.4830477833747864}
{"mode": "train", "epochs": 4, "timestep": 7580, "ep_reward": 883.2637939453125, "reward": 0.8375345468521118, "action": -0.733889102935791}
{"mode": "train", "epochs": 4, "timestep": 7581, "ep_reward": 884.1342163085938, "reward": 0.8704436421394348, "action": -0.3779942989349365}
{"mode": "train", "epochs": 4, "timestep": 7582, "ep_reward": 885.025390625, "reward": 0.8911527395248413, "action": -0.9710882902145386}
{"mode": "train", "epochs": 4, "timestep": 7583, "ep_reward": 885.91943359375, "reward": 0.8940298557281494, "action": -1.285262107849121}
{"mode": "train", "epochs": 4, "timestep": 7584, "ep_reward": 886.8003540039062, "reward": 0.8809069395065308, "action": -0.9033387303352356}
{"mode": "train", "epochs": 4, "timestep": 7585, "ep_reward": 887.6551513671875, "reward": 0.854780912399292, "action": -0.8080244064331055}
{"mode": "train", "epochs": 4, "timestep": 7586, "ep_reward": 888.46484375, "reward": 0.8096825480461121, "action": -1.2291700839996338}
{"mode": "train", "epochs": 4, "timestep": 7587, "ep_reward": 889.1995239257812, "reward": 0.7346564531326294, "action": -0.34051811695098877}
{"mode": "train", "epochs": 4, "timestep": 7588, "ep_reward": 889.8370971679688, "reward": 0.6375534534454346, "action": -0.779272735118866}
{"mode": "train", "epochs": 4, "timestep": 7589, "ep_reward": 890.335693359375, "reward": 0.4986015558242798, "action": -0.9927482008934021}
{"mode": "train", "epochs": 4, "timestep": 7590, "ep_reward": 890.6683349609375, "reward": 0.3326178193092346, "action": -1.054327130317688}
{"mode": "train", "epochs": 4, "timestep": 7591, "ep_reward": 890.8876342773438, "reward": 0.21927499771118164, "action": -0.39176809787750244}
{"mode": "train", "epochs": 4, "timestep": 7592, "ep_reward": 890.9735107421875, "reward": 0.08588254451751709, "action": -0.016202926635742188}
{"mode": "train", "epochs": 4, "timestep": 7593, "ep_reward": 891.0053100585938, "reward": 0.03180360794067383, "action": -0.4901399612426758}
{"mode": "train", "epochs": 4, "timestep": 7594, "ep_reward": 891.1796264648438, "reward": 0.17428600788116455, "action": -0.9344311952590942}
{"mode": "train", "epochs": 4, "timestep": 7595, "ep_reward": 891.4943237304688, "reward": 0.31467097997665405, "action": -1.265569806098938}
{"mode": "train", "epochs": 4, "timestep": 7596, "ep_reward": 891.94091796875, "reward": 0.4466094374656677, "action": -0.6667170524597168}
{"mode": "train", "epochs": 4, "timestep": 7597, "ep_reward": 892.5130615234375, "reward": 0.5721287727355957, "action": -0.4674708843231201}
{"mode": "train", "epochs": 4, "timestep": 7598, "ep_reward": 893.1910400390625, "reward": 0.6779841184616089, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7599, "ep_reward": 893.9368896484375, "reward": 0.7458536624908447, "action": -1.3607163429260254}
{"mode": "train", "epochs": 4, "timestep": 7600, "ep_reward": 894.7366943359375, "reward": 0.7998295426368713, "action": -0.5478930473327637}
{"mode": "train", "epochs": 4, "timestep": 7601, "ep_reward": 895.5780029296875, "reward": 0.841322660446167, "action": -0.04690808057785034}
{"mode": "train", "epochs": 4, "timestep": 7602, "ep_reward": 896.4466552734375, "reward": 0.8686701059341431, "action": -1.2126096487045288}
{"mode": "train", "epochs": 4, "timestep": 7603, "ep_reward": 897.3167114257812, "reward": 0.8700814843177795, "action": -1.0515803098678589}
{"mode": "train", "epochs": 4, "timestep": 7604, "ep_reward": 898.1730346679688, "reward": 0.8563034534454346, "action": -0.19345557689666748}
{"mode": "train", "epochs": 4, "timestep": 7605, "ep_reward": 899.00439453125, "reward": 0.8313737511634827, "action": -1.8196918964385986}
{"mode": "train", "epochs": 4, "timestep": 7606, "ep_reward": 899.7719116210938, "reward": 0.7675464153289795, "action": -1.5656757354736328}
{"mode": "train", "epochs": 4, "timestep": 7607, "ep_reward": 900.4456176757812, "reward": 0.673688530921936, "action": -1.5690760612487793}
{"mode": "train", "epochs": 4, "timestep": 7608, "ep_reward": 900.9850463867188, "reward": 0.5394399166107178, "action": -0.7532355785369873}
{"mode": "train", "epochs": 4, "timestep": 7609, "ep_reward": 901.3692016601562, "reward": 0.38416773080825806, "action": -1.3594248294830322}
{"mode": "train", "epochs": 4, "timestep": 7610, "ep_reward": 901.6504516601562, "reward": 0.2812407612800598, "action": -1.5677480697631836}
{"mode": "train", "epochs": 4, "timestep": 7611, "ep_reward": 901.808837890625, "reward": 0.15840697288513184, "action": -1.2589019536972046}
{"mode": "train", "epochs": 4, "timestep": 7612, "ep_reward": 901.8244018554688, "reward": 0.015561103820800781, "action": -0.9568727612495422}
{"mode": "train", "epochs": 4, "timestep": 7613, "ep_reward": 901.9254150390625, "reward": 0.1010240912437439, "action": -0.8628556728363037}
{"mode": "train", "epochs": 4, "timestep": 7614, "ep_reward": 902.1664428710938, "reward": 0.2410230040550232, "action": -0.9292688965797424}
{"mode": "train", "epochs": 4, "timestep": 7615, "ep_reward": 902.5469970703125, "reward": 0.3805449604988098, "action": -0.9721873998641968}
{"mode": "train", "epochs": 4, "timestep": 7616, "ep_reward": 903.05712890625, "reward": 0.510158360004425, "action": -1.536975622177124}
{"mode": "train", "epochs": 4, "timestep": 7617, "ep_reward": 903.6734619140625, "reward": 0.616346001625061, "action": -0.8179883360862732}
{"mode": "train", "epochs": 4, "timestep": 7618, "ep_reward": 904.382568359375, "reward": 0.7091158032417297, "action": -1.6443991661071777}
{"mode": "train", "epochs": 4, "timestep": 7619, "ep_reward": 905.1537475585938, "reward": 0.7712010741233826, "action": 0.17977845668792725}
{"mode": "train", "epochs": 4, "timestep": 7620, "ep_reward": 905.9827880859375, "reward": 0.829022228717804, "action": -1.6267964839935303}
{"mode": "train", "epochs": 4, "timestep": 7621, "ep_reward": 906.8344116210938, "reward": 0.8516538143157959, "action": -0.9733912944793701}
{"mode": "train", "epochs": 4, "timestep": 7622, "ep_reward": 907.6973876953125, "reward": 0.8630055785179138, "action": -1.48691987991333}
{"mode": "train", "epochs": 4, "timestep": 7623, "ep_reward": 908.55029296875, "reward": 0.8529058694839478, "action": -0.4846798777580261}
{"mode": "train", "epochs": 4, "timestep": 7624, "ep_reward": 909.383056640625, "reward": 0.8327491283416748, "action": -0.46480363607406616}
{"mode": "train", "epochs": 4, "timestep": 7625, "ep_reward": 910.1740112304688, "reward": 0.7909467220306396, "action": -1.4872257709503174}
{"mode": "train", "epochs": 4, "timestep": 7626, "ep_reward": 910.8844604492188, "reward": 0.7104716300964355, "action": -0.9194537401199341}
{"mode": "train", "epochs": 4, "timestep": 7627, "ep_reward": 911.48486328125, "reward": 0.600402295589447, "action": -1.3347301483154297}
{"mode": "train", "epochs": 4, "timestep": 7628, "ep_reward": 911.9277954101562, "reward": 0.442937433719635, "action": -0.780929684638977}
{"mode": "train", "epochs": 4, "timestep": 7629, "ep_reward": 912.2510375976562, "reward": 0.32325565814971924, "action": -1.2414411306381226}
{"mode": "train", "epochs": 4, "timestep": 7630, "ep_reward": 912.4591674804688, "reward": 0.20815908908843994, "action": -0.04672348499298096}
{"mode": "train", "epochs": 4, "timestep": 7631, "ep_reward": 912.531982421875, "reward": 0.072845458984375, "action": -1.3947031497955322}
{"mode": "train", "epochs": 4, "timestep": 7632, "ep_reward": 912.5770874023438, "reward": 0.04509836435317993, "action": -1.4618005752563477}
{"mode": "train", "epochs": 4, "timestep": 7633, "ep_reward": 912.7611694335938, "reward": 0.18409687280654907, "action": -1.2556495666503906}
{"mode": "train", "epochs": 4, "timestep": 7634, "ep_reward": 913.082275390625, "reward": 0.3211333155632019, "action": -0.4638606905937195}
{"mode": "train", "epochs": 4, "timestep": 7635, "ep_reward": 913.5452270507812, "reward": 0.46296226978302, "action": -0.715015172958374}
{"mode": "train", "epochs": 4, "timestep": 7636, "ep_reward": 914.130615234375, "reward": 0.5854064226150513, "action": -0.8996577262878418}
{"mode": "train", "epochs": 4, "timestep": 7637, "ep_reward": 914.8151245117188, "reward": 0.6844978332519531, "action": -0.15041881799697876}
{"mode": "train", "epochs": 4, "timestep": 7638, "ep_reward": 915.5828247070312, "reward": 0.7676772475242615, "action": -1.739807367324829}
{"mode": "train", "epochs": 4, "timestep": 7639, "ep_reward": 916.397705078125, "reward": 0.8148742914199829, "action": -0.8019951581954956}
{"mode": "train", "epochs": 4, "timestep": 7640, "ep_reward": 917.2498779296875, "reward": 0.8521985411643982, "action": -1.6743619441986084}
{"mode": "train", "epochs": 4, "timestep": 7641, "ep_reward": 918.1158447265625, "reward": 0.8659754991531372, "action": -0.678385853767395}
{"mode": "train", "epochs": 4, "timestep": 7642, "ep_reward": 918.9880981445312, "reward": 0.8722823858261108, "action": -0.6186975240707397}
{"mode": "train", "epochs": 4, "timestep": 7643, "ep_reward": 919.8510131835938, "reward": 0.8629273176193237, "action": -1.0087159872055054}
{"mode": "train", "epochs": 4, "timestep": 7644, "ep_reward": 920.6829223632812, "reward": 0.8319317698478699, "action": -0.9703078866004944}
{"mode": "train", "epochs": 4, "timestep": 7645, "ep_reward": 921.4613037109375, "reward": 0.7784046530723572, "action": -0.7332100868225098}
{"mode": "train", "epochs": 4, "timestep": 7646, "ep_reward": 922.1598510742188, "reward": 0.6985704898834229, "action": -1.314717411994934}
{"mode": "train", "epochs": 4, "timestep": 7647, "ep_reward": 922.735595703125, "reward": 0.575728178024292, "action": -1.1821471452713013}
{"mode": "train", "epochs": 4, "timestep": 7648, "ep_reward": 923.1477661132812, "reward": 0.4121951460838318, "action": -1.5117063522338867}
{"mode": "train", "epochs": 4, "timestep": 7649, "ep_reward": 923.4445190429688, "reward": 0.2967448830604553, "action": -1.0079457759857178}
{"mode": "train", "epochs": 4, "timestep": 7650, "ep_reward": 923.62109375, "reward": 0.1766008734703064, "action": -1.1584595441818237}
{"mode": "train", "epochs": 4, "timestep": 7651, "ep_reward": 923.657470703125, "reward": 0.03637230396270752, "action": -1.7403414249420166}
{"mode": "train", "epochs": 4, "timestep": 7652, "ep_reward": 923.73876953125, "reward": 0.08130985498428345, "action": -0.81544029712677}
{"mode": "train", "epochs": 4, "timestep": 7653, "ep_reward": 923.9600830078125, "reward": 0.22131991386413574, "action": -0.8986680507659912}
{"mode": "train", "epochs": 4, "timestep": 7654, "ep_reward": 924.32177734375, "reward": 0.36166834831237793, "action": -1.591688871383667}
{"mode": "train", "epochs": 4, "timestep": 7655, "ep_reward": 924.8077392578125, "reward": 0.485943078994751, "action": -1.365154504776001}
{"mode": "train", "epochs": 4, "timestep": 7656, "ep_reward": 925.40576171875, "reward": 0.5980035066604614, "action": -0.6446226835250854}
{"mode": "train", "epochs": 4, "timestep": 7657, "ep_reward": 926.1022338867188, "reward": 0.6964801549911499, "action": -0.30884790420532227}
{"mode": "train", "epochs": 4, "timestep": 7658, "ep_reward": 926.8761596679688, "reward": 0.773897111415863, "action": -1.1280523538589478}
{"mode": "train", "epochs": 4, "timestep": 7659, "ep_reward": 927.6978149414062, "reward": 0.8216453194618225, "action": -0.2672783136367798}
{"mode": "train", "epochs": 4, "timestep": 7660, "ep_reward": 928.5558471679688, "reward": 0.8580064177513123, "action": -0.9670857787132263}
{"mode": "train", "epochs": 4, "timestep": 7661, "ep_reward": 929.4275512695312, "reward": 0.8717119693756104, "action": -0.4247146248817444}
{"mode": "train", "epochs": 4, "timestep": 7662, "ep_reward": 930.3017578125, "reward": 0.8742054104804993, "action": -1.2458186149597168}
{"mode": "train", "epochs": 4, "timestep": 7663, "ep_reward": 931.1552124023438, "reward": 0.8534401655197144, "action": -0.03847914934158325}
{"mode": "train", "epochs": 4, "timestep": 7664, "ep_reward": 931.9795532226562, "reward": 0.8243251442909241, "action": -1.013997197151184}
{"mode": "train", "epochs": 4, "timestep": 7665, "ep_reward": 932.7422485351562, "reward": 0.7627236843109131, "action": -0.9667444229125977}
{"mode": "train", "epochs": 4, "timestep": 7666, "ep_reward": 933.4132080078125, "reward": 0.6709843277931213, "action": -0.9941807389259338}
{"mode": "train", "epochs": 4, "timestep": 7667, "ep_reward": 933.954833984375, "reward": 0.5416314005851746, "action": -0.9274260997772217}
{"mode": "train", "epochs": 4, "timestep": 7668, "ep_reward": 934.3270263671875, "reward": 0.3721812963485718, "action": -1.762413740158081}
{"mode": "train", "epochs": 4, "timestep": 7669, "ep_reward": 934.5909423828125, "reward": 0.26388663053512573, "action": -0.9830877184867859}
{"mode": "train", "epochs": 4, "timestep": 7670, "ep_reward": 934.7288818359375, "reward": 0.13795489072799683, "action": -0.9298785924911499}
{"mode": "train", "epochs": 4, "timestep": 7671, "ep_reward": 934.720947265625, "reward": -0.00793766975402832, "action": -0.38430988788604736}
{"mode": "train", "epochs": 4, "timestep": 7672, "ep_reward": 934.8433227539062, "reward": 0.12234801054000854, "action": -0.830247700214386}
{"mode": "train", "epochs": 4, "timestep": 7673, "ep_reward": 935.106689453125, "reward": 0.26337122917175293, "action": -0.5150138139724731}
{"mode": "train", "epochs": 4, "timestep": 7674, "ep_reward": 935.5136108398438, "reward": 0.40694165229797363, "action": -0.6307234764099121}
{"mode": "train", "epochs": 4, "timestep": 7675, "ep_reward": 936.0507202148438, "reward": 0.5371074676513672, "action": -0.748337984085083}
{"mode": "train", "epochs": 4, "timestep": 7676, "ep_reward": 936.6976318359375, "reward": 0.646881639957428, "action": -0.6643275022506714}
{"mode": "train", "epochs": 4, "timestep": 7677, "ep_reward": 937.4329223632812, "reward": 0.7352993488311768, "action": -0.976615309715271}
{"mode": "train", "epochs": 4, "timestep": 7678, "ep_reward": 938.2320556640625, "reward": 0.7991210222244263, "action": -0.7763586640357971}
{"mode": "train", "epochs": 4, "timestep": 7679, "ep_reward": 939.0774536132812, "reward": 0.8453885316848755, "action": -1.9080491065979004}
{"mode": "train", "epochs": 4, "timestep": 7680, "ep_reward": 939.9439697265625, "reward": 0.866511881351471, "action": -0.9375127553939819}
{"mode": "train", "epochs": 4, "timestep": 7681, "ep_reward": 940.82470703125, "reward": 0.880739688873291, "action": -0.7739410400390625}
{"mode": "train", "epochs": 4, "timestep": 7682, "ep_reward": 941.7064208984375, "reward": 0.8817335963249207, "action": -1.0722798109054565}
{"mode": "train", "epochs": 4, "timestep": 7683, "ep_reward": 942.5714111328125, "reward": 0.8650161027908325, "action": -0.5949451327323914}
{"mode": "train", "epochs": 4, "timestep": 7684, "ep_reward": 943.4058227539062, "reward": 0.834406316280365, "action": -0.869005560874939}
{"mode": "train", "epochs": 4, "timestep": 7685, "ep_reward": 944.1848754882812, "reward": 0.7790718078613281, "action": -0.8340469598770142}
{"mode": "train", "epochs": 4, "timestep": 7686, "ep_reward": 944.8802490234375, "reward": 0.6953434348106384, "action": -1.9592353105545044}
{"mode": "train", "epochs": 4, "timestep": 7687, "ep_reward": 945.4411010742188, "reward": 0.5608488321304321, "action": -0.602537989616394}
{"mode": "train", "epochs": 4, "timestep": 7688, "ep_reward": 945.8433227539062, "reward": 0.4022078514099121, "action": -1.8017354011535645}
{"mode": "train", "epochs": 4, "timestep": 7689, "ep_reward": 946.127197265625, "reward": 0.2838863730430603, "action": -1.2163290977478027}
{"mode": "train", "epochs": 4, "timestep": 7690, "ep_reward": 946.2886962890625, "reward": 0.16151702404022217, "action": -0.5962632894515991}
{"mode": "train", "epochs": 4, "timestep": 7691, "ep_reward": 946.3076171875, "reward": 0.01894855499267578, "action": -1.5422120094299316}
{"mode": "train", "epochs": 4, "timestep": 7692, "ep_reward": 946.4053344726562, "reward": 0.09772491455078125, "action": -1.4537782669067383}
{"mode": "train", "epochs": 4, "timestep": 7693, "ep_reward": 946.6353759765625, "reward": 0.23005735874176025, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7694, "ep_reward": 946.993408203125, "reward": 0.35801440477371216, "action": -0.012641489505767822}
{"mode": "train", "epochs": 4, "timestep": 7695, "ep_reward": 947.4966430664062, "reward": 0.5032563805580139, "action": -1.670013427734375}
{"mode": "train", "epochs": 4, "timestep": 7696, "ep_reward": 948.105712890625, "reward": 0.6090913414955139, "action": -1.3814301490783691}
{"mode": "train", "epochs": 4, "timestep": 7697, "ep_reward": 948.802734375, "reward": 0.6970090866088867, "action": -1.3619554042816162}
{"mode": "train", "epochs": 4, "timestep": 7698, "ep_reward": 949.56494140625, "reward": 0.762182891368866, "action": -0.3390134572982788}
{"mode": "train", "epochs": 4, "timestep": 7699, "ep_reward": 950.379638671875, "reward": 0.8146790266036987, "action": -1.1393903493881226}
{"mode": "train", "epochs": 4, "timestep": 7700, "ep_reward": 951.2185668945312, "reward": 0.8389100432395935, "action": -0.943605899810791}
{"mode": "train", "epochs": 4, "timestep": 7701, "ep_reward": 952.0645141601562, "reward": 0.8459198474884033, "action": -1.2386980056762695}
{"mode": "train", "epochs": 4, "timestep": 7702, "ep_reward": 952.8952026367188, "reward": 0.8306819200515747, "action": -0.6219629049301147}
{"mode": "train", "epochs": 4, "timestep": 7703, "ep_reward": 953.6942749023438, "reward": 0.7990580797195435, "action": -1.5539605617523193}
{"mode": "train", "epochs": 4, "timestep": 7704, "ep_reward": 954.4246826171875, "reward": 0.7304232120513916, "action": -0.8248240351676941}
{"mode": "train", "epochs": 4, "timestep": 7705, "ep_reward": 955.0599975585938, "reward": 0.6353375911712646, "action": -0.8396294116973877}
{"mode": "train", "epochs": 4, "timestep": 7706, "ep_reward": 955.5598754882812, "reward": 0.49988263845443726, "action": -0.7778111696243286}
{"mode": "train", "epochs": 4, "timestep": 7707, "ep_reward": 955.9261474609375, "reward": 0.3662613034248352, "action": -0.7733449339866638}
{"mode": "train", "epochs": 4, "timestep": 7708, "ep_reward": 956.1857299804688, "reward": 0.2595863342285156, "action": -0.564598560333252}
{"mode": "train", "epochs": 4, "timestep": 7709, "ep_reward": 956.3185424804688, "reward": 0.1328067183494568, "action": -1.29360032081604}
{"mode": "train", "epochs": 4, "timestep": 7710, "ep_reward": 956.3045654296875, "reward": -0.013993144035339355, "action": -1.8204971551895142}
{"mode": "train", "epochs": 4, "timestep": 7711, "ep_reward": 956.4320678710938, "reward": 0.12750685214996338, "action": -0.8903315663337708}
{"mode": "train", "epochs": 4, "timestep": 7712, "ep_reward": 956.7000122070312, "reward": 0.2679314613342285, "action": 0.32353317737579346}
{"mode": "train", "epochs": 4, "timestep": 7713, "ep_reward": 957.121337890625, "reward": 0.421329140663147, "action": -1.0474666357040405}
{"mode": "train", "epochs": 4, "timestep": 7714, "ep_reward": 957.665771484375, "reward": 0.5444291234016418, "action": -0.2399807572364807}
{"mode": "train", "epochs": 4, "timestep": 7715, "ep_reward": 958.3236694335938, "reward": 0.6579198837280273, "action": -0.8014718294143677}
{"mode": "train", "epochs": 4, "timestep": 7716, "ep_reward": 959.0667114257812, "reward": 0.7430285811424255, "action": -0.8348232507705688}
{"mode": "train", "epochs": 4, "timestep": 7717, "ep_reward": 959.8737182617188, "reward": 0.8070206642150879, "action": 0.355907678604126}
{"mode": "train", "epochs": 4, "timestep": 7718, "ep_reward": 960.7352294921875, "reward": 0.8615075349807739, "action": -1.1171435117721558}
{"mode": "train", "epochs": 4, "timestep": 7719, "ep_reward": 961.6239013671875, "reward": 0.8886812329292297, "action": -1.4209532737731934}
{"mode": "train", "epochs": 4, "timestep": 7720, "ep_reward": 962.5254516601562, "reward": 0.9015367031097412, "action": -1.2748751640319824}
{"mode": "train", "epochs": 4, "timestep": 7721, "ep_reward": 963.429443359375, "reward": 0.9039754867553711, "action": -0.5932708382606506}
{"mode": "train", "epochs": 4, "timestep": 7722, "ep_reward": 964.3287963867188, "reward": 0.8993412852287292, "action": -0.5689661502838135}
{"mode": "train", "epochs": 4, "timestep": 7723, "ep_reward": 965.2103881835938, "reward": 0.8815759420394897, "action": -1.8676342964172363}
{"mode": "train", "epochs": 4, "timestep": 7724, "ep_reward": 966.0467529296875, "reward": 0.8363587856292725, "action": -0.8789594769477844}
{"mode": "train", "epochs": 4, "timestep": 7725, "ep_reward": 966.8231201171875, "reward": 0.7763782143592834, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7726, "ep_reward": 967.4971923828125, "reward": 0.6740695238113403, "action": -1.06210196018219}
{"mode": "train", "epochs": 4, "timestep": 7727, "ep_reward": 968.0410766601562, "reward": 0.5438734292984009, "action": -1.322938084602356}
{"mode": "train", "epochs": 4, "timestep": 7728, "ep_reward": 968.4096069335938, "reward": 0.3685404062271118, "action": -1.1132577657699585}
{"mode": "train", "epochs": 4, "timestep": 7729, "ep_reward": 968.669189453125, "reward": 0.25955742597579956, "action": -1.4570817947387695}
{"mode": "train", "epochs": 4, "timestep": 7730, "ep_reward": 968.8021850585938, "reward": 0.13299131393432617, "action": -0.5414344072341919}
{"mode": "train", "epochs": 4, "timestep": 7731, "ep_reward": 968.7885131835938, "reward": -0.01369631290435791, "action": -0.6061203479766846}
{"mode": "train", "epochs": 4, "timestep": 7732, "ep_reward": 968.9158325195312, "reward": 0.12731993198394775, "action": -1.4841502904891968}
{"mode": "train", "epochs": 4, "timestep": 7733, "ep_reward": 969.176025390625, "reward": 0.2601977586746216, "action": -1.6054638624191284}
{"mode": "train", "epochs": 4, "timestep": 7734, "ep_reward": 969.5679931640625, "reward": 0.3919588327407837, "action": -0.9765262007713318}
{"mode": "train", "epochs": 4, "timestep": 7735, "ep_reward": 970.0896606445312, "reward": 0.5216760635375977, "action": -1.1937233209609985}
{"mode": "train", "epochs": 4, "timestep": 7736, "ep_reward": 970.71923828125, "reward": 0.6295911073684692, "action": -0.6804431676864624}
{"mode": "train", "epochs": 4, "timestep": 7737, "ep_reward": 971.4390869140625, "reward": 0.7198181748390198, "action": -0.941162645816803}
{"mode": "train", "epochs": 4, "timestep": 7738, "ep_reward": 972.2224731445312, "reward": 0.7833915948867798, "action": -1.1991924047470093}
{"mode": "train", "epochs": 4, "timestep": 7739, "ep_reward": 973.0457153320312, "reward": 0.8232181072235107, "action": -0.8102139830589294}
{"mode": "train", "epochs": 4, "timestep": 7740, "ep_reward": 973.8929443359375, "reward": 0.8472508192062378, "action": -0.8071085214614868}
{"mode": "train", "epochs": 4, "timestep": 7741, "ep_reward": 974.7459716796875, "reward": 0.8530115485191345, "action": -0.6556680798530579}
{"mode": "train", "epochs": 4, "timestep": 7742, "ep_reward": 975.5875244140625, "reward": 0.841539204120636, "action": -0.9619661569595337}
{"mode": "train", "epochs": 4, "timestep": 7743, "ep_reward": 976.393798828125, "reward": 0.8062587976455688, "action": -0.5180916786193848}
{"mode": "train", "epochs": 4, "timestep": 7744, "ep_reward": 977.1436767578125, "reward": 0.7498533129692078, "action": -1.9223079681396484}
{"mode": "train", "epochs": 4, "timestep": 7745, "ep_reward": 977.7882690429688, "reward": 0.6445666551589966, "action": -0.822012722492218}
{"mode": "train", "epochs": 4, "timestep": 7746, "ep_reward": 978.3001098632812, "reward": 0.5118308067321777, "action": -0.6661653518676758}
{"mode": "train", "epochs": 4, "timestep": 7747, "ep_reward": 978.6690063476562, "reward": 0.36889195442199707, "action": -1.2016966342926025}
{"mode": "train", "epochs": 4, "timestep": 7748, "ep_reward": 978.9317626953125, "reward": 0.2627331614494324, "action": -1.3463329076766968}
{"mode": "train", "epochs": 4, "timestep": 7749, "ep_reward": 979.0684204101562, "reward": 0.13667911291122437, "action": -0.6840479373931885}
{"mode": "train", "epochs": 4, "timestep": 7750, "ep_reward": 979.0588989257812, "reward": -0.009513258934020996, "action": -1.1384775638580322}
{"mode": "train", "epochs": 4, "timestep": 7751, "ep_reward": 979.1825561523438, "reward": 0.12363553047180176, "action": -1.1770306825637817}
{"mode": "train", "epochs": 4, "timestep": 7752, "ep_reward": 979.44287109375, "reward": 0.2603169083595276, "action": -1.2556215524673462}
{"mode": "train", "epochs": 4, "timestep": 7753, "ep_reward": 979.8385620117188, "reward": 0.3957051634788513, "action": -1.4149489402770996}
{"mode": "train", "epochs": 4, "timestep": 7754, "ep_reward": 980.3578491210938, "reward": 0.5192946195602417, "action": -1.150663137435913}
{"mode": "train", "epochs": 4, "timestep": 7755, "ep_reward": 980.9859008789062, "reward": 0.6280797719955444, "action": -1.1657174825668335}
{"mode": "train", "epochs": 4, "timestep": 7756, "ep_reward": 981.7000732421875, "reward": 0.7141490578651428, "action": -0.38374221324920654}
{"mode": "train", "epochs": 4, "timestep": 7757, "ep_reward": 982.484375, "reward": 0.7843168377876282, "action": -1.9143569469451904}
{"mode": "train", "epochs": 4, "timestep": 7758, "ep_reward": 983.302978515625, "reward": 0.8186198472976685, "action": -1.139361023902893}
{"mode": "train", "epochs": 4, "timestep": 7759, "ep_reward": 984.1438598632812, "reward": 0.8408988118171692, "action": -1.6036561727523804}
{"mode": "train", "epochs": 4, "timestep": 7760, "ep_reward": 984.9839477539062, "reward": 0.840114951133728, "action": -0.8759516477584839}
{"mode": "train", "epochs": 4, "timestep": 7761, "ep_reward": 985.809814453125, "reward": 0.8258717656135559, "action": -0.1284329891204834}
{"mode": "train", "epochs": 4, "timestep": 7762, "ep_reward": 986.6064453125, "reward": 0.7966607213020325, "action": -0.4303203225135803}
{"mode": "train", "epochs": 4, "timestep": 7763, "ep_reward": 987.344970703125, "reward": 0.7385205626487732, "action": -0.8252350091934204}
{"mode": "train", "epochs": 4, "timestep": 7764, "ep_reward": 987.988525390625, "reward": 0.6435260772705078, "action": -1.460740327835083}
{"mode": "train", "epochs": 4, "timestep": 7765, "ep_reward": 988.4883422851562, "reward": 0.49981385469436646, "action": -1.1351102590560913}
{"mode": "train", "epochs": 4, "timestep": 7766, "ep_reward": 988.8507690429688, "reward": 0.36239808797836304, "action": -1.4983925819396973}
{"mode": "train", "epochs": 4, "timestep": 7767, "ep_reward": 989.1057739257812, "reward": 0.2549917697906494, "action": -1.1272685527801514}
{"mode": "train", "epochs": 4, "timestep": 7768, "ep_reward": 989.2332153320312, "reward": 0.12743401527404785, "action": -1.6369835138320923}
{"mode": "train", "epochs": 4, "timestep": 7769, "ep_reward": 989.2192993164062, "reward": -0.013895750045776367, "action": -0.9665263295173645}
{"mode": "train", "epochs": 4, "timestep": 7770, "ep_reward": 989.35205078125, "reward": 0.1327446699142456, "action": -1.3962422609329224}
{"mode": "train", "epochs": 4, "timestep": 7771, "ep_reward": 989.6190795898438, "reward": 0.26701557636260986, "action": -0.5163377523422241}
{"mode": "train", "epochs": 4, "timestep": 7772, "ep_reward": 990.0306396484375, "reward": 0.4115551710128784, "action": -1.0355349779129028}
{"mode": "train", "epochs": 4, "timestep": 7773, "ep_reward": 990.5677490234375, "reward": 0.5371353030204773, "action": -1.546919345855713}
{"mode": "train", "epochs": 4, "timestep": 7774, "ep_reward": 991.2064208984375, "reward": 0.6386531591415405, "action": -0.2931618094444275}
{"mode": "train", "epochs": 4, "timestep": 7775, "ep_reward": 991.9378051757812, "reward": 0.7313896417617798, "action": -0.3479335904121399}
{"mode": "train", "epochs": 4, "timestep": 7776, "ep_reward": 992.7371826171875, "reward": 0.7993943691253662, "action": -1.1065893173217773}
{"mode": "train", "epochs": 4, "timestep": 7777, "ep_reward": 993.5773315429688, "reward": 0.8401716351509094, "action": -0.8323544263839722}
{"mode": "train", "epochs": 4, "timestep": 7778, "ep_reward": 994.443359375, "reward": 0.8660402894020081, "action": -0.9269437193870544}
{"mode": "train", "epochs": 4, "timestep": 7779, "ep_reward": 995.3187866210938, "reward": 0.8753982782363892, "action": -0.8579959273338318}
{"mode": "train", "epochs": 4, "timestep": 7780, "ep_reward": 996.1884765625, "reward": 0.8697197437286377, "action": -1.4896438121795654}
{"mode": "train", "epochs": 4, "timestep": 7781, "ep_reward": 997.0294799804688, "reward": 0.8410041332244873, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7782, "ep_reward": 997.8139038085938, "reward": 0.7844380736351013, "action": -0.8781664967536926}
{"mode": "train", "epochs": 4, "timestep": 7783, "ep_reward": 998.523681640625, "reward": 0.7097704410552979, "action": -0.6908578872680664}
{"mode": "train", "epochs": 4, "timestep": 7784, "ep_reward": 999.1262817382812, "reward": 0.6025755405426025, "action": -0.9080970287322998}
{"mode": "train", "epochs": 4, "timestep": 7785, "ep_reward": 999.5784301757812, "reward": 0.45217645168304443, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7786, "ep_reward": 999.9022827148438, "reward": 0.32387375831604004, "action": -1.4024797677993774}
{"mode": "train", "epochs": 4, "timestep": 7787, "ep_reward": 1000.1111450195312, "reward": 0.20888465642929077, "action": -0.7196765542030334}
{"mode": "train", "epochs": 4, "timestep": 7788, "ep_reward": 1000.1847534179688, "reward": 0.07361441850662231, "action": -1.87825608253479}
{"mode": "train", "epochs": 4, "timestep": 7789, "ep_reward": 1000.22900390625, "reward": 0.044233083724975586, "action": -1.380342721939087}
{"mode": "train", "epochs": 4, "timestep": 7790, "ep_reward": 1000.4124145507812, "reward": 0.18340301513671875, "action": -0.8061118721961975}
{"mode": "train", "epochs": 4, "timestep": 7791, "ep_reward": 1000.7383422851562, "reward": 0.3259122371673584, "action": -1.1144037246704102}
{"mode": "train", "epochs": 4, "timestep": 7792, "ep_reward": 1001.1973266601562, "reward": 0.4589651823043823, "action": -0.6881953477859497}
{"mode": "train", "epochs": 4, "timestep": 7793, "ep_reward": 1001.7796020507812, "reward": 0.5822758674621582, "action": -1.660890817642212}
{"mode": "train", "epochs": 4, "timestep": 7794, "ep_reward": 1002.4537963867188, "reward": 0.6741775870323181, "action": -0.5132402181625366}
{"mode": "train", "epochs": 4, "timestep": 7795, "ep_reward": 1003.2096557617188, "reward": 0.7558606266975403, "action": -1.0655735731124878}
{"mode": "train", "epochs": 4, "timestep": 7796, "ep_reward": 1004.0194091796875, "reward": 0.8097291588783264, "action": -1.570378303527832}
{"mode": "train", "epochs": 4, "timestep": 7797, "ep_reward": 1004.8595581054688, "reward": 0.8401437997817993, "action": -0.6849631071090698}
{"mode": "train", "epochs": 4, "timestep": 7798, "ep_reward": 1005.72021484375, "reward": 0.8606724143028259, "action": -1.0793839693069458}
{"mode": "train", "epochs": 4, "timestep": 7799, "ep_reward": 1006.5809936523438, "reward": 0.8607761859893799, "action": -1.436797857284546}
{"mode": "train", "epochs": 4, "timestep": 7800, "ep_reward": 1007.4205932617188, "reward": 0.8396300673484802, "action": -0.9458699822425842}
{"mode": "train", "epochs": 4, "timestep": 7801, "ep_reward": 1008.221923828125, "reward": 0.8013228178024292, "action": -1.1039506196975708}
{"mode": "train", "epochs": 4, "timestep": 7802, "ep_reward": 1008.9564819335938, "reward": 0.7345571517944336, "action": -1.0621261596679688}
{"mode": "train", "epochs": 4, "timestep": 7803, "ep_reward": 1009.5907592773438, "reward": 0.6342935562133789, "action": -0.9475241899490356}
{"mode": "train", "epochs": 4, "timestep": 7804, "ep_reward": 1010.0859375, "reward": 0.4951696991920471, "action": -1.153080940246582}
{"mode": "train", "epochs": 4, "timestep": 7805, "ep_reward": 1010.4423828125, "reward": 0.3564693331718445, "action": -0.9761653542518616}
{"mode": "train", "epochs": 4, "timestep": 7806, "ep_reward": 1010.6901245117188, "reward": 0.24771511554718018, "action": -1.3908913135528564}
{"mode": "train", "epochs": 4, "timestep": 7807, "ep_reward": 1010.8091430664062, "reward": 0.11900955438613892, "action": -1.4486860036849976}
{"mode": "train", "epochs": 4, "timestep": 7808, "ep_reward": 1010.8046875, "reward": -0.004433870315551758, "action": -1.60331130027771}
{"mode": "train", "epochs": 4, "timestep": 7809, "ep_reward": 1010.94580078125, "reward": 0.14111602306365967, "action": -1.1934666633605957}
{"mode": "train", "epochs": 4, "timestep": 7810, "ep_reward": 1011.223876953125, "reward": 0.27808332443237305, "action": -0.8081462979316711}
{"mode": "train", "epochs": 4, "timestep": 7811, "ep_reward": 1011.6420288085938, "reward": 0.4181588888168335, "action": -1.0677810907363892}
{"mode": "train", "epochs": 4, "timestep": 7812, "ep_reward": 1012.1847534179688, "reward": 0.5427197217941284, "action": -1.2144718170166016}
{"mode": "train", "epochs": 4, "timestep": 7813, "ep_reward": 1012.8314208984375, "reward": 0.6466842889785767, "action": -0.9395058751106262}
{"mode": "train", "epochs": 4, "timestep": 7814, "ep_reward": 1013.5626220703125, "reward": 0.7312201261520386, "action": -1.4140589237213135}
{"mode": "train", "epochs": 4, "timestep": 7815, "ep_reward": 1014.3513793945312, "reward": 0.7887404561042786, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7816, "ep_reward": 1015.172607421875, "reward": 0.8212146162986755, "action": -1.2207281589508057}
{"mode": "train", "epochs": 4, "timestep": 7817, "ep_reward": 1016.0147094726562, "reward": 0.8420864343643188, "action": -0.4853350520133972}
{"mode": "train", "epochs": 4, "timestep": 7818, "ep_reward": 1016.8656005859375, "reward": 0.8508821129798889, "action": -0.9003491401672363}
{"mode": "train", "epochs": 4, "timestep": 7819, "ep_reward": 1017.7025146484375, "reward": 0.8369327187538147, "action": -0.7829914093017578}
{"mode": "train", "epochs": 4, "timestep": 7820, "ep_reward": 1018.5048828125, "reward": 0.8023831248283386, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7821, "ep_reward": 1019.2325439453125, "reward": 0.7276879549026489, "action": -0.5741662383079529}
{"mode": "train", "epochs": 4, "timestep": 7822, "ep_reward": 1019.8665771484375, "reward": 0.6340310573577881, "action": -1.5647649765014648}
{"mode": "train", "epochs": 4, "timestep": 7823, "ep_reward": 1020.3529052734375, "reward": 0.48630380630493164, "action": -0.21751880645751953}
{"mode": "train", "epochs": 4, "timestep": 7824, "ep_reward": 1020.7134399414062, "reward": 0.36053556203842163, "action": -1.0401225090026855}
{"mode": "train", "epochs": 4, "timestep": 7825, "ep_reward": 1020.9661254882812, "reward": 0.2526963949203491, "action": -0.8312057256698608}
{"mode": "train", "epochs": 4, "timestep": 7826, "ep_reward": 1021.0908813476562, "reward": 0.12477147579193115, "action": -1.2777657508850098}
{"mode": "train", "epochs": 4, "timestep": 7827, "ep_reward": 1021.0800170898438, "reward": -0.010855913162231445, "action": -1.3835561275482178}
{"mode": "train", "epochs": 4, "timestep": 7828, "ep_reward": 1021.2154541015625, "reward": 0.1354273557662964, "action": -1.5177680253982544}
{"mode": "train", "epochs": 4, "timestep": 7829, "ep_reward": 1021.483642578125, "reward": 0.26817548274993896, "action": -1.1478787660598755}
{"mode": "train", "epochs": 4, "timestep": 7830, "ep_reward": 1021.8888549804688, "reward": 0.40522313117980957, "action": -1.123691439628601}
{"mode": "train", "epochs": 4, "timestep": 7831, "ep_reward": 1022.4202270507812, "reward": 0.5313529968261719, "action": -0.5479990839958191}
{"mode": "train", "epochs": 4, "timestep": 7832, "ep_reward": 1023.0646362304688, "reward": 0.6444297432899475, "action": -1.006779670715332}
{"mode": "train", "epochs": 4, "timestep": 7833, "ep_reward": 1023.7933959960938, "reward": 0.7287810444831848, "action": -0.723044753074646}
{"mode": "train", "epochs": 4, "timestep": 7834, "ep_reward": 1024.58642578125, "reward": 0.793032169342041, "action": -1.2956980466842651}
{"mode": "train", "epochs": 4, "timestep": 7835, "ep_reward": 1025.417724609375, "reward": 0.8312402963638306, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7836, "ep_reward": 1026.2630615234375, "reward": 0.8453589677810669, "action": -1.2244746685028076}
{"mode": "train", "epochs": 4, "timestep": 7837, "ep_reward": 1027.111328125, "reward": 0.8482905626296997, "action": -1.423696756362915}
{"mode": "train", "epochs": 4, "timestep": 7838, "ep_reward": 1027.9412841796875, "reward": 0.8299012184143066, "action": -1.4356689453125}
{"mode": "train", "epochs": 4, "timestep": 7839, "ep_reward": 1028.7294921875, "reward": 0.7882222533226013, "action": -0.4987473487854004}
{"mode": "train", "epochs": 4, "timestep": 7840, "ep_reward": 1029.4578857421875, "reward": 0.7283565998077393, "action": -1.2615810632705688}
{"mode": "train", "epochs": 4, "timestep": 7841, "ep_reward": 1030.083251953125, "reward": 0.6253272294998169, "action": -0.8259958028793335}
{"mode": "train", "epochs": 4, "timestep": 7842, "ep_reward": 1030.56982421875, "reward": 0.48657238483428955, "action": -0.40035688877105713}
{"mode": "train", "epochs": 4, "timestep": 7843, "ep_reward": 1030.928466796875, "reward": 0.35862648487091064, "action": -0.957250714302063}
{"mode": "train", "epochs": 4, "timestep": 7844, "ep_reward": 1031.1788330078125, "reward": 0.2504197359085083, "action": -0.3784484267234802}
{"mode": "train", "epochs": 4, "timestep": 7845, "ep_reward": 1031.301025390625, "reward": 0.12215882539749146, "action": -0.44190579652786255}
{"mode": "train", "epochs": 4, "timestep": 7846, "ep_reward": 1031.293212890625, "reward": -0.007764220237731934, "action": -1.1578336954116821}
{"mode": "train", "epochs": 4, "timestep": 7847, "ep_reward": 1031.4312744140625, "reward": 0.13803017139434814, "action": -1.8129730224609375}
{"mode": "train", "epochs": 4, "timestep": 7848, "ep_reward": 1031.6983642578125, "reward": 0.2671350836753845, "action": -1.2721818685531616}
{"mode": "train", "epochs": 4, "timestep": 7849, "ep_reward": 1032.1016845703125, "reward": 0.4032737612724304, "action": -1.0491807460784912}
{"mode": "train", "epochs": 4, "timestep": 7850, "ep_reward": 1032.63232421875, "reward": 0.5306284427642822, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7851, "ep_reward": 1033.2603759765625, "reward": 0.6280423402786255, "action": -0.7976346015930176}
{"mode": "train", "epochs": 4, "timestep": 7852, "ep_reward": 1033.976806640625, "reward": 0.7164096832275391, "action": -1.3535141944885254}
{"mode": "train", "epochs": 4, "timestep": 7853, "ep_reward": 1034.7515869140625, "reward": 0.7748235464096069, "action": -0.3195565342903137}
{"mode": "train", "epochs": 4, "timestep": 7854, "ep_reward": 1035.572509765625, "reward": 0.8208690285682678, "action": -0.26883643865585327}
{"mode": "train", "epochs": 4, "timestep": 7855, "ep_reward": 1036.4188232421875, "reward": 0.8463269472122192, "action": -1.2334799766540527}
{"mode": "train", "epochs": 4, "timestep": 7856, "ep_reward": 1037.2628173828125, "reward": 0.8440331816673279, "action": -1.113832712173462}
{"mode": "train", "epochs": 4, "timestep": 7857, "ep_reward": 1038.08544921875, "reward": 0.8226420283317566, "action": -0.97177654504776}
{"mode": "train", "epochs": 4, "timestep": 7858, "ep_reward": 1038.8642578125, "reward": 0.7788046598434448, "action": -1.3560229539871216}
{"mode": "train", "epochs": 4, "timestep": 7859, "ep_reward": 1039.5650634765625, "reward": 0.700851559638977, "action": -1.4188272953033447}
{"mode": "train", "epochs": 4, "timestep": 7860, "ep_reward": 1040.1488037109375, "reward": 0.5837165117263794, "action": -1.667816162109375}
{"mode": "train", "epochs": 4, "timestep": 7861, "ep_reward": 1040.570556640625, "reward": 0.42175233364105225, "action": -0.9883546233177185}
{"mode": "train", "epochs": 4, "timestep": 7862, "ep_reward": 1040.8978271484375, "reward": 0.32723790407180786, "action": -1.5219790935516357}
{"mode": "train", "epochs": 4, "timestep": 7863, "ep_reward": 1041.1107177734375, "reward": 0.21292346715927124, "action": -0.6455387473106384}
{"mode": "train", "epochs": 4, "timestep": 7864, "ep_reward": 1041.189208984375, "reward": 0.0785139799118042, "action": 0.016264796257019043}
{"mode": "train", "epochs": 4, "timestep": 7865, "ep_reward": 1041.2286376953125, "reward": 0.039434969425201416, "action": -1.1845964193344116}
{"mode": "train", "epochs": 4, "timestep": 7866, "ep_reward": 1041.4078369140625, "reward": 0.17922401428222656, "action": -0.7651804685592651}
{"mode": "train", "epochs": 4, "timestep": 7867, "ep_reward": 1041.7301025390625, "reward": 0.32222849130630493, "action": -0.7201182842254639}
{"mode": "train", "epochs": 4, "timestep": 7868, "ep_reward": 1042.190185546875, "reward": 0.46009594202041626, "action": -0.6175318956375122}
{"mode": "train", "epochs": 4, "timestep": 7869, "ep_reward": 1042.77392578125, "reward": 0.5837612152099609, "action": -1.3895559310913086}
{"mode": "train", "epochs": 4, "timestep": 7870, "ep_reward": 1043.4521484375, "reward": 0.6782763004302979, "action": -1.2049323320388794}
{"mode": "train", "epochs": 4, "timestep": 7871, "ep_reward": 1044.2054443359375, "reward": 0.7533154487609863, "action": -1.3228435516357422}
{"mode": "train", "epochs": 4, "timestep": 7872, "ep_reward": 1045.0118408203125, "reward": 0.8063360452651978, "action": -1.2140601873397827}
{"mode": "train", "epochs": 4, "timestep": 7873, "ep_reward": 1045.853271484375, "reward": 0.8413835763931274, "action": -0.6073561906814575}
{"mode": "train", "epochs": 4, "timestep": 7874, "ep_reward": 1046.7174072265625, "reward": 0.8640750646591187, "action": -0.9468843936920166}
{"mode": "train", "epochs": 4, "timestep": 7875, "ep_reward": 1047.5848388671875, "reward": 0.86744624376297, "action": -0.7487730383872986}
{"mode": "train", "epochs": 4, "timestep": 7876, "ep_reward": 1048.4405517578125, "reward": 0.8556830883026123, "action": -0.8600776195526123}
{"mode": "train", "epochs": 4, "timestep": 7877, "ep_reward": 1049.264404296875, "reward": 0.8238298892974854, "action": -0.5278424024581909}
{"mode": "train", "epochs": 4, "timestep": 7878, "ep_reward": 1050.036376953125, "reward": 0.7719730138778687, "action": -0.5598224401473999}
{"mode": "train", "epochs": 4, "timestep": 7879, "ep_reward": 1050.7276611328125, "reward": 0.6912316083908081, "action": -1.1873464584350586}
{"mode": "train", "epochs": 4, "timestep": 7880, "ep_reward": 1051.294677734375, "reward": 0.5670404434204102, "action": -1.2594958543777466}
{"mode": "train", "epochs": 4, "timestep": 7881, "ep_reward": 1051.6942138671875, "reward": 0.3995632529258728, "action": -1.1774705648422241}
{"mode": "train", "epochs": 4, "timestep": 7882, "ep_reward": 1051.9815673828125, "reward": 0.28732138872146606, "action": -1.0127041339874268}
{"mode": "train", "epochs": 4, "timestep": 7883, "ep_reward": 1052.1470947265625, "reward": 0.16554993391036987, "action": -0.24090957641601562}
{"mode": "train", "epochs": 4, "timestep": 7884, "ep_reward": 1052.170654296875, "reward": 0.02354443073272705, "action": -1.672135591506958}
{"mode": "train", "epochs": 4, "timestep": 7885, "ep_reward": 1052.26416015625, "reward": 0.09353232383728027, "action": -0.39343583583831787}
{"mode": "train", "epochs": 4, "timestep": 7886, "ep_reward": 1052.5032958984375, "reward": 0.2391684651374817, "action": -0.3596726059913635}
{"mode": "train", "epochs": 4, "timestep": 7887, "ep_reward": 1052.887939453125, "reward": 0.3845963478088379, "action": -0.6311642527580261}
{"mode": "train", "epochs": 4, "timestep": 7888, "ep_reward": 1053.404296875, "reward": 0.5163532495498657, "action": -1.4468753337860107}
{"mode": "train", "epochs": 4, "timestep": 7889, "ep_reward": 1054.0264892578125, "reward": 0.6221879720687866, "action": -0.8426669239997864}
{"mode": "train", "epochs": 4, "timestep": 7890, "ep_reward": 1054.74072265625, "reward": 0.7142583131790161, "action": -1.6762917041778564}
{"mode": "train", "epochs": 4, "timestep": 7891, "ep_reward": 1055.5177001953125, "reward": 0.7770248651504517, "action": -1.8750247955322266}
{"mode": "train", "epochs": 4, "timestep": 7892, "ep_reward": 1056.337158203125, "reward": 0.8194690346717834, "action": -0.6254079937934875}
{"mode": "train", "epochs": 4, "timestep": 7893, "ep_reward": 1057.192138671875, "reward": 0.8549315929412842, "action": -0.8696867227554321}
{"mode": "train", "epochs": 4, "timestep": 7894, "ep_reward": 1058.063720703125, "reward": 0.8716157078742981, "action": -0.7271361351013184}
{"mode": "train", "epochs": 4, "timestep": 7895, "ep_reward": 1058.9376220703125, "reward": 0.8738958239555359, "action": -0.6955812573432922}
{"mode": "train", "epochs": 4, "timestep": 7896, "ep_reward": 1059.7979736328125, "reward": 0.8603582382202148, "action": -0.2829734683036804}
{"mode": "train", "epochs": 4, "timestep": 7897, "ep_reward": 1060.6302490234375, "reward": 0.832293689250946, "action": -1.0705504417419434}
{"mode": "train", "epochs": 4, "timestep": 7898, "ep_reward": 1061.4046630859375, "reward": 0.7744431495666504, "action": -0.13024836778640747}
{"mode": "train", "epochs": 4, "timestep": 7899, "ep_reward": 1062.10302734375, "reward": 0.69838547706604, "action": -0.534119725227356}
{"mode": "train", "epochs": 4, "timestep": 7900, "ep_reward": 1062.6876220703125, "reward": 0.5846295356750488, "action": -1.0975313186645508}
{"mode": "train", "epochs": 4, "timestep": 7901, "ep_reward": 1063.1119384765625, "reward": 0.4243324398994446, "action": -1.7866665124893188}
{"mode": "train", "epochs": 4, "timestep": 7902, "ep_reward": 1063.4014892578125, "reward": 0.28957968950271606, "action": -1.5547561645507812}
{"mode": "train", "epochs": 4, "timestep": 7903, "ep_reward": 1063.569580078125, "reward": 0.16809898614883423, "action": -1.8772013187408447}
{"mode": "train", "epochs": 4, "timestep": 7904, "ep_reward": 1063.596435546875, "reward": 0.026904761791229248, "action": -0.06583410501480103}
{"mode": "train", "epochs": 4, "timestep": 7905, "ep_reward": 1063.6868896484375, "reward": 0.09045475721359253, "action": -1.2130546569824219}
{"mode": "train", "epochs": 4, "timestep": 7906, "ep_reward": 1063.9127197265625, "reward": 0.22580808401107788, "action": -0.6766352653503418}
{"mode": "train", "epochs": 4, "timestep": 7907, "ep_reward": 1064.282470703125, "reward": 0.3697466254234314, "action": 0.006794095039367676}
{"mode": "train", "epochs": 4, "timestep": 7908, "ep_reward": 1064.794189453125, "reward": 0.5117557048797607, "action": -1.95139479637146}
{"mode": "train", "epochs": 4, "timestep": 7909, "ep_reward": 1065.4072265625, "reward": 0.6130926609039307, "action": -1.2181628942489624}
{"mode": "train", "epochs": 4, "timestep": 7910, "ep_reward": 1066.1102294921875, "reward": 0.7029691934585571, "action": -1.2455663681030273}
{"mode": "train", "epochs": 4, "timestep": 7911, "ep_reward": 1066.880859375, "reward": 0.7705931663513184, "action": -0.9670925736427307}
{"mode": "train", "epochs": 4, "timestep": 7912, "ep_reward": 1067.70068359375, "reward": 0.8198182582855225, "action": -1.5940145254135132}
{"mode": "train", "epochs": 4, "timestep": 7913, "ep_reward": 1068.54541015625, "reward": 0.8447679281234741, "action": -0.9602586030960083}
{"mode": "train", "epochs": 4, "timestep": 7914, "ep_reward": 1069.4031982421875, "reward": 0.8577781915664673, "action": -0.8967240452766418}
{"mode": "train", "epochs": 4, "timestep": 7915, "ep_reward": 1070.257080078125, "reward": 0.8538434505462646, "action": -0.39217954874038696}
{"mode": "train", "epochs": 4, "timestep": 7916, "ep_reward": 1071.0927734375, "reward": 0.8357280492782593, "action": -0.8195221424102783}
{"mode": "train", "epochs": 4, "timestep": 7917, "ep_reward": 1071.8846435546875, "reward": 0.7918676137924194, "action": -1.0403066873550415}
{"mode": "train", "epochs": 4, "timestep": 7918, "ep_reward": 1072.6026611328125, "reward": 0.7180013656616211, "action": -1.1129534244537354}
{"mode": "train", "epochs": 4, "timestep": 7919, "ep_reward": 1073.210693359375, "reward": 0.6080081462860107, "action": -1.5935630798339844}
{"mode": "train", "epochs": 4, "timestep": 7920, "ep_reward": 1073.65966796875, "reward": 0.448988676071167, "action": -0.9329243898391724}
{"mode": "train", "epochs": 4, "timestep": 7921, "ep_reward": 1073.98876953125, "reward": 0.32913094758987427, "action": -0.5597192049026489}
{"mode": "train", "epochs": 4, "timestep": 7922, "ep_reward": 1074.2037353515625, "reward": 0.21501249074935913, "action": -0.8407372236251831}
{"mode": "train", "epochs": 4, "timestep": 7923, "ep_reward": 1074.28466796875, "reward": 0.08091318607330322, "action": -0.8679818511009216}
{"mode": "train", "epochs": 4, "timestep": 7924, "ep_reward": 1074.3216552734375, "reward": 0.036979854106903076, "action": 0.11208593845367432}
{"mode": "train", "epochs": 4, "timestep": 7925, "ep_reward": 1074.5087890625, "reward": 0.187086820602417, "action": -0.9458962678909302}
{"mode": "train", "epochs": 4, "timestep": 7926, "ep_reward": 1074.83447265625, "reward": 0.3257436156272888, "action": -0.6564972400665283}
{"mode": "train", "epochs": 4, "timestep": 7927, "ep_reward": 1075.29736328125, "reward": 0.4628652334213257, "action": -1.505251407623291}
{"mode": "train", "epochs": 4, "timestep": 7928, "ep_reward": 1075.8734130859375, "reward": 0.5760457515716553, "action": -0.9753615856170654}
{"mode": "train", "epochs": 4, "timestep": 7929, "ep_reward": 1076.5496826171875, "reward": 0.6762994527816772, "action": -0.5531182289123535}
{"mode": "train", "epochs": 4, "timestep": 7930, "ep_reward": 1077.3077392578125, "reward": 0.7581173777580261, "action": -1.7985260486602783}
{"mode": "train", "epochs": 4, "timestep": 7931, "ep_reward": 1078.115234375, "reward": 0.8074550032615662, "action": -0.9731602668762207}
{"mode": "train", "epochs": 4, "timestep": 7932, "ep_reward": 1078.961181640625, "reward": 0.8459550142288208, "action": -0.28780412673950195}
{"mode": "train", "epochs": 4, "timestep": 7933, "ep_reward": 1079.833984375, "reward": 0.8728394508361816, "action": -1.7729344367980957}
{"mode": "train", "epochs": 4, "timestep": 7934, "ep_reward": 1080.7064208984375, "reward": 0.8723828196525574, "action": -0.5865899324417114}
{"mode": "train", "epochs": 4, "timestep": 7935, "ep_reward": 1081.5721435546875, "reward": 0.8656657934188843, "action": -1.603914737701416}
{"mode": "train", "epochs": 4, "timestep": 7936, "ep_reward": 1082.404052734375, "reward": 0.8318518400192261, "action": -1.6641823053359985}
{"mode": "train", "epochs": 4, "timestep": 7937, "ep_reward": 1083.17724609375, "reward": 0.7731698751449585, "action": -1.2722495794296265}
{"mode": "train", "epochs": 4, "timestep": 7938, "ep_reward": 1083.8646240234375, "reward": 0.6874095797538757, "action": -0.5803136229515076}
{"mode": "train", "epochs": 4, "timestep": 7939, "ep_reward": 1084.437744140625, "reward": 0.57306969165802, "action": -1.7941614389419556}
{"mode": "train", "epochs": 4, "timestep": 7940, "ep_reward": 1084.8370361328125, "reward": 0.3992443084716797, "action": -0.3040858507156372}
{"mode": "train", "epochs": 4, "timestep": 7941, "ep_reward": 1085.135986328125, "reward": 0.2989916205406189, "action": -1.2145870923995972}
{"mode": "train", "epochs": 4, "timestep": 7942, "ep_reward": 1085.3153076171875, "reward": 0.17930269241333008, "action": -0.9921610951423645}
{"mode": "train", "epochs": 4, "timestep": 7943, "ep_reward": 1085.3548583984375, "reward": 0.03950226306915283, "action": -1.4965516328811646}
{"mode": "train", "epochs": 4, "timestep": 7944, "ep_reward": 1085.4332275390625, "reward": 0.0783955454826355, "action": -0.2201511263847351}
{"mode": "train", "epochs": 4, "timestep": 7945, "ep_reward": 1085.658935546875, "reward": 0.22569167613983154, "action": -0.8572486042976379}
{"mode": "train", "epochs": 4, "timestep": 7946, "ep_reward": 1086.024169921875, "reward": 0.3652033805847168, "action": -0.8111300468444824}
{"mode": "train", "epochs": 4, "timestep": 7947, "ep_reward": 1086.5216064453125, "reward": 0.4974285960197449, "action": -0.49698442220687866}
{"mode": "train", "epochs": 4, "timestep": 7948, "ep_reward": 1087.137939453125, "reward": 0.616344690322876, "action": -1.429181694984436}
{"mode": "train", "epochs": 4, "timestep": 7949, "ep_reward": 1087.842041015625, "reward": 0.7041501402854919, "action": -1.5235035419464111}
{"mode": "train", "epochs": 4, "timestep": 7950, "ep_reward": 1088.61279296875, "reward": 0.7707851529121399, "action": -0.4430403709411621}
{"mode": "train", "epochs": 4, "timestep": 7951, "ep_reward": 1089.4398193359375, "reward": 0.8270429968833923, "action": -1.5951061248779297}
{"mode": "train", "epochs": 4, "timestep": 7952, "ep_reward": 1090.2952880859375, "reward": 0.8554643392562866, "action": -0.6582876443862915}
{"mode": "train", "epochs": 4, "timestep": 7953, "ep_reward": 1091.1710205078125, "reward": 0.8757878541946411, "action": -0.8065164089202881}
{"mode": "train", "epochs": 4, "timestep": 7954, "ep_reward": 1092.0509033203125, "reward": 0.8798892498016357, "action": -0.6760203838348389}
{"mode": "train", "epochs": 4, "timestep": 7955, "ep_reward": 1092.9205322265625, "reward": 0.8696627616882324, "action": -1.814276933670044}
{"mode": "train", "epochs": 4, "timestep": 7956, "ep_reward": 1093.7523193359375, "reward": 0.8317694664001465, "action": -0.6671593189239502}
{"mode": "train", "epochs": 4, "timestep": 7957, "ep_reward": 1094.5335693359375, "reward": 0.7813045382499695, "action": -0.6387845277786255}
{"mode": "train", "epochs": 4, "timestep": 7958, "ep_reward": 1095.23681640625, "reward": 0.7031941413879395, "action": -1.4330264329910278}
{"mode": "train", "epochs": 4, "timestep": 7959, "ep_reward": 1095.81689453125, "reward": 0.5800755023956299, "action": -0.4143756031990051}
{"mode": "train", "epochs": 4, "timestep": 7960, "ep_reward": 1096.2470703125, "reward": 0.43017905950546265, "action": -1.05189049243927}
{"mode": "train", "epochs": 4, "timestep": 7961, "ep_reward": 1096.547119140625, "reward": 0.3000568151473999, "action": -1.419853687286377}
{"mode": "train", "epochs": 4, "timestep": 7962, "ep_reward": 1096.727783203125, "reward": 0.18062758445739746, "action": -0.7617383599281311}
{"mode": "train", "epochs": 4, "timestep": 7963, "ep_reward": 1096.7689208984375, "reward": 0.04109597206115723, "action": -0.8610984683036804}
{"mode": "train", "epochs": 4, "timestep": 7964, "ep_reward": 1096.8458251953125, "reward": 0.07688313722610474, "action": -1.0295400619506836}
{"mode": "train", "epochs": 4, "timestep": 7965, "ep_reward": 1097.0599365234375, "reward": 0.21409988403320312, "action": -0.800646960735321}
{"mode": "train", "epochs": 4, "timestep": 7966, "ep_reward": 1097.416259765625, "reward": 0.35633188486099243, "action": -1.6319191455841064}
{"mode": "train", "epochs": 4, "timestep": 7967, "ep_reward": 1097.89697265625, "reward": 0.4806610345840454, "action": -1.9221298694610596}
{"mode": "train", "epochs": 4, "timestep": 7968, "ep_reward": 1098.484375, "reward": 0.5873892307281494, "action": -0.5280832052230835}
{"mode": "train", "epochs": 4, "timestep": 7969, "ep_reward": 1099.1732177734375, "reward": 0.6888589859008789, "action": -1.3752223253250122}
{"mode": "train", "epochs": 4, "timestep": 7970, "ep_reward": 1099.9302978515625, "reward": 0.757140576839447, "action": -1.3059196472167969}
{"mode": "train", "epochs": 4, "timestep": 7971, "ep_reward": 1100.7344970703125, "reward": 0.804227352142334, "action": -1.2839200496673584}
{"mode": "train", "epochs": 4, "timestep": 7972, "ep_reward": 1101.565673828125, "reward": 0.8312158584594727, "action": 0.1177976131439209}
{"mode": "train", "epochs": 4, "timestep": 7973, "ep_reward": 1102.4171142578125, "reward": 0.8513972163200378, "action": -1.687772512435913}
{"mode": "train", "epochs": 4, "timestep": 7974, "ep_reward": 1103.2532958984375, "reward": 0.8361867666244507, "action": -0.886120617389679}
{"mode": "train", "epochs": 4, "timestep": 7975, "ep_reward": 1104.06005859375, "reward": 0.8068205118179321, "action": -0.8067268133163452}
{"mode": "train", "epochs": 4, "timestep": 7976, "ep_reward": 1104.8126220703125, "reward": 0.7525720596313477, "action": -1.3050328493118286}
{"mode": "train", "epochs": 4, "timestep": 7977, "ep_reward": 1105.4727783203125, "reward": 0.6602100729942322, "action": -1.4345301389694214}
{"mode": "train", "epochs": 4, "timestep": 7978, "ep_reward": 1105.998046875, "reward": 0.5252184867858887, "action": 0.11596083641052246}
{"mode": "train", "epochs": 4, "timestep": 7979, "ep_reward": 1106.3834228515625, "reward": 0.3853384256362915, "action": -0.9475685358047485}
{"mode": "train", "epochs": 4, "timestep": 7980, "ep_reward": 1106.6661376953125, "reward": 0.2826768159866333, "action": -0.9783602952957153}
{"mode": "train", "epochs": 4, "timestep": 7981, "ep_reward": 1106.826171875, "reward": 0.16001039743423462, "action": -1.027237892150879}
{"mode": "train", "epochs": 4, "timestep": 7982, "ep_reward": 1106.843505859375, "reward": 0.017383873462677002, "action": -0.6886434555053711}
{"mode": "train", "epochs": 4, "timestep": 7983, "ep_reward": 1106.94287109375, "reward": 0.09942001104354858, "action": 0.024760961532592773}
{"mode": "train", "epochs": 4, "timestep": 7984, "ep_reward": 1107.1932373046875, "reward": 0.2503661513328552, "action": -0.5199764370918274}
{"mode": "train", "epochs": 4, "timestep": 7985, "ep_reward": 1107.585693359375, "reward": 0.3924824595451355, "action": -1.0472307205200195}
{"mode": "train", "epochs": 4, "timestep": 7986, "ep_reward": 1108.1041259765625, "reward": 0.5184653997421265, "action": -1.331526279449463}
{"mode": "train", "epochs": 4, "timestep": 7987, "ep_reward": 1108.7293701171875, "reward": 0.6252406239509583, "action": -0.38451266288757324}
{"mode": "train", "epochs": 4, "timestep": 7988, "ep_reward": 1109.450439453125, "reward": 0.7210401296615601, "action": -1.5161609649658203}
{"mode": "train", "epochs": 4, "timestep": 7989, "ep_reward": 1110.234619140625, "reward": 0.7842177152633667, "action": -0.740058183670044}
{"mode": "train", "epochs": 4, "timestep": 7990, "ep_reward": 1111.06982421875, "reward": 0.8352311253547668, "action": -0.7837744951248169}
{"mode": "train", "epochs": 4, "timestep": 7991, "ep_reward": 1111.938232421875, "reward": 0.8683478832244873, "action": -1.4644360542297363}
{"mode": "train", "epochs": 4, "timestep": 7992, "ep_reward": 1112.819580078125, "reward": 0.8813716173171997, "action": -0.9506487846374512}
{"mode": "train", "epochs": 4, "timestep": 7993, "ep_reward": 1113.703857421875, "reward": 0.8842425346374512, "action": -1.6451835632324219}
{"mode": "train", "epochs": 4, "timestep": 7994, "ep_reward": 1114.5703125, "reward": 0.8665065765380859, "action": -1.323880672454834}
{"mode": "train", "epochs": 4, "timestep": 7995, "ep_reward": 1115.4033203125, "reward": 0.8329925537109375, "action": -0.6052640676498413}
{"mode": "train", "epochs": 4, "timestep": 7996, "ep_reward": 1116.18701171875, "reward": 0.783636212348938, "action": -0.469216525554657}
{"mode": "train", "epochs": 4, "timestep": 7997, "ep_reward": 1116.8953857421875, "reward": 0.708426833152771, "action": -0.9797923564910889}
{"mode": "train", "epochs": 4, "timestep": 7998, "ep_reward": 1117.4886474609375, "reward": 0.5932469367980957, "action": -0.7280450463294983}
{"mode": "train", "epochs": 4, "timestep": 7999, "ep_reward": 1117.9305419921875, "reward": 0.4419357180595398, "action": -0.7278449535369873}
{"mode": "train", "epochs": 4, "timestep": 8000, "ep_reward": 1118.2354736328125, "reward": 0.3049491047859192, "action": -1.0357896089553833}
{"mode": "train", "epochs": 5, "timestep": 8001, "ep_reward": 0.9977859854698181, "reward": 0.9977859854698181, "action": 0.5458742380142212}
{"mode": "train", "epochs": 5, "timestep": 8002, "ep_reward": 1.9938271045684814, "reward": 0.9960410594940186, "action": 1.1862605810165405}
{"mode": "train", "epochs": 5, "timestep": 8003, "ep_reward": 2.9861350059509277, "reward": 0.9923077821731567, "action": 0.8292887210845947}
{"mode": "train", "epochs": 5, "timestep": 8004, "ep_reward": 3.973262310028076, "reward": 0.987127423286438, "action": 0.6933984160423279}
{"mode": "train", "epochs": 5, "timestep": 8005, "ep_reward": 4.952816486358643, "reward": 0.9795543551445007, "action": 1.016900897026062}
{"mode": "train", "epochs": 5, "timestep": 8006, "ep_reward": 5.919741630554199, "reward": 0.9669253826141357, "action": 1.15162992477417}
{"mode": "train", "epochs": 5, "timestep": 8007, "ep_reward": 6.867035865783691, "reward": 0.9472941160202026, "action": 0.7065589427947998}
{"mode": "train", "epochs": 5, "timestep": 8008, "ep_reward": 7.787617206573486, "reward": 0.9205813407897949, "action": 0.525169849395752}
{"mode": "train", "epochs": 5, "timestep": 8009, "ep_reward": 8.670439720153809, "reward": 0.8828226923942566, "action": -1.3735270500183105}
{"mode": "train", "epochs": 5, "timestep": 8010, "ep_reward": 9.515307426452637, "reward": 0.8448673486709595, "action": -0.6213785409927368}
{"mode": "train", "epochs": 5, "timestep": 8011, "ep_reward": 10.301525115966797, "reward": 0.7862181067466736, "action": -1.2138001918792725}
{"mode": "train", "epochs": 5, "timestep": 8012, "ep_reward": 11.01601791381836, "reward": 0.7144931554794312, "action": -1.1118584871292114}
{"mode": "train", "epochs": 5, "timestep": 8013, "ep_reward": 11.638106346130371, "reward": 0.6220887899398804, "action": -1.5408778190612793}
{"mode": "train", "epochs": 5, "timestep": 8014, "ep_reward": 12.153634071350098, "reward": 0.5155278444290161, "action": -1.8007962703704834}
{"mode": "train", "epochs": 5, "timestep": 8015, "ep_reward": 12.551702499389648, "reward": 0.39806872606277466, "action": -1.8911595344543457}
{"mode": "train", "epochs": 5, "timestep": 8016, "ep_reward": 12.827095031738281, "reward": 0.27539294958114624, "action": -0.29763585329055786}
{"mode": "train", "epochs": 5, "timestep": 8017, "ep_reward": 12.956892013549805, "reward": 0.12979716062545776, "action": -1.8841644525527954}
{"mode": "train", "epochs": 5, "timestep": 8018, "ep_reward": 13.154960632324219, "reward": 0.19806885719299316, "action": -1.0697071552276611}
{"mode": "train", "epochs": 5, "timestep": 8019, "ep_reward": 13.487829208374023, "reward": 0.33286887407302856, "action": -1.3236291408538818}
{"mode": "train", "epochs": 5, "timestep": 8020, "ep_reward": 13.951922416687012, "reward": 0.46409332752227783, "action": -1.2882932424545288}
{"mode": "train", "epochs": 5, "timestep": 8021, "ep_reward": 14.533265113830566, "reward": 0.5813425779342651, "action": 0.8274828791618347}
{"mode": "train", "epochs": 5, "timestep": 8022, "ep_reward": 15.1997652053833, "reward": 0.6665000319480896, "action": 0.2440090775489807}
{"mode": "train", "epochs": 5, "timestep": 8023, "ep_reward": 15.941728591918945, "reward": 0.7419635057449341, "action": 0.6841080784797668}
{"mode": "train", "epochs": 5, "timestep": 8024, "ep_reward": 16.74140739440918, "reward": 0.7996793985366821, "action": 0.7748083472251892}
{"mode": "train", "epochs": 5, "timestep": 8025, "ep_reward": 17.584774017333984, "reward": 0.8433665037155151, "action": 1.5597295761108398}
{"mode": "train", "epochs": 5, "timestep": 8026, "ep_reward": 18.45819664001465, "reward": 0.8734221458435059, "action": 0.44314849376678467}
{"mode": "train", "epochs": 5, "timestep": 8027, "ep_reward": 19.354759216308594, "reward": 0.8965616226196289, "action": 1.289063811302185}
{"mode": "train", "epochs": 5, "timestep": 8028, "ep_reward": 20.26382827758789, "reward": 0.9090694189071655, "action": -0.01591348648071289}
{"mode": "train", "epochs": 5, "timestep": 8029, "ep_reward": 21.177204132080078, "reward": 0.9133756160736084, "action": 0.07399803400039673}
{"mode": "train", "epochs": 5, "timestep": 8030, "ep_reward": 22.083721160888672, "reward": 0.906517744064331, "action": -1.5383886098861694}
{"mode": "train", "epochs": 5, "timestep": 8031, "ep_reward": 22.96599006652832, "reward": 0.8822683095932007, "action": -0.6040014028549194}
{"mode": "train", "epochs": 5, "timestep": 8032, "ep_reward": 23.80874252319336, "reward": 0.842751681804657, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 8033, "ep_reward": 24.582992553710938, "reward": 0.7742494344711304, "action": -1.5519680976867676}
{"mode": "train", "epochs": 5, "timestep": 8034, "ep_reward": 25.263927459716797, "reward": 0.6809340715408325, "action": -0.918410062789917}
{"mode": "train", "epochs": 5, "timestep": 8035, "ep_reward": 25.829715728759766, "reward": 0.5657882690429688, "action": -1.7067959308624268}
{"mode": "train", "epochs": 5, "timestep": 8036, "ep_reward": 26.245235443115234, "reward": 0.4155197739601135, "action": -0.5232440233230591}
{"mode": "train", "epochs": 5, "timestep": 8037, "ep_reward": 26.50472068786621, "reward": 0.25948506593704224, "action": -1.320296049118042}
{"mode": "train", "epochs": 5, "timestep": 8038, "ep_reward": 26.587350845336914, "reward": 0.08263033628463745, "action": -1.4001249074935913}
{"mode": "train", "epochs": 5, "timestep": 8039, "ep_reward": 26.72462272644043, "reward": 0.13727200031280518, "action": -0.7108146548271179}
{"mode": "train", "epochs": 5, "timestep": 8040, "ep_reward": 26.99614715576172, "reward": 0.2715240716934204, "action": -0.8484810590744019}
{"mode": "train", "epochs": 5, "timestep": 8041, "ep_reward": 27.400285720825195, "reward": 0.40413790941238403, "action": -1.1593722105026245}
{"mode": "train", "epochs": 5, "timestep": 8042, "ep_reward": 27.925512313842773, "reward": 0.5252260565757751, "action": -1.0816704034805298}
{"mode": "train", "epochs": 5, "timestep": 8043, "ep_reward": 28.55803108215332, "reward": 0.6325187683105469, "action": -0.9586513042449951}
{"mode": "train", "epochs": 5, "timestep": 8044, "ep_reward": 29.279991149902344, "reward": 0.7219606041908264, "action": -0.9236237406730652}
{"mode": "train", "epochs": 5, "timestep": 8045, "ep_reward": 30.07169532775879, "reward": 0.7917049527168274, "action": -0.9404062628746033}
{"mode": "train", "epochs": 5, "timestep": 8046, "ep_reward": 30.914714813232422, "reward": 0.8430185914039612, "action": -0.6855340600013733}
{"mode": "train", "epochs": 5, "timestep": 8047, "ep_reward": 31.795230865478516, "reward": 0.8805168271064758, "action": -0.2668466567993164}
{"mode": "train", "epochs": 5, "timestep": 8048, "ep_reward": 32.70271301269531, "reward": 0.9074808359146118, "action": -0.5582059621810913}
{"mode": "train", "epochs": 5, "timestep": 8049, "ep_reward": 33.62405014038086, "reward": 0.9213371276855469, "action": -0.9542091488838196}
{"mode": "train", "epochs": 5, "timestep": 8050, "ep_reward": 34.5471076965332, "reward": 0.9230573773384094, "action": -1.1348366737365723}
{"mode": "train", "epochs": 5, "timestep": 8051, "ep_reward": 35.46087646484375, "reward": 0.9137693047523499, "action": 0.1170891523361206}
{"mode": "train", "epochs": 5, "timestep": 8052, "ep_reward": 36.362632751464844, "reward": 0.9017571210861206, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 8053, "ep_reward": 37.22275924682617, "reward": 0.8601282835006714, "action": -0.4527440667152405}
{"mode": "train", "epochs": 5, "timestep": 8054, "ep_reward": 38.03382873535156, "reward": 0.8110678195953369, "action": -1.3042879104614258}
{"mode": "train", "epochs": 5, "timestep": 8055, "ep_reward": 38.76252365112305, "reward": 0.7286930680274963, "action": -1.511941909790039}
{"mode": "train", "epochs": 5, "timestep": 8056, "ep_reward": 39.372337341308594, "reward": 0.609814465045929, "action": -1.1170709133148193}
{"mode": "train", "epochs": 5, "timestep": 8057, "ep_reward": 39.82854461669922, "reward": 0.45620912313461304, "action": -1.9906609058380127}
{"mode": "train", "epochs": 5, "timestep": 8058, "ep_reward": 40.126380920410156, "reward": 0.2978361248970032, "action": -0.9672830104827881}
{"mode": "train", "epochs": 5, "timestep": 8059, "ep_reward": 40.304256439208984, "reward": 0.17787712812423706, "action": -1.1943426132202148}
{"mode": "train", "epochs": 5, "timestep": 8060, "ep_reward": 40.342227935791016, "reward": 0.037972986698150635, "action": -1.020080804824829}
{"mode": "train", "epochs": 5, "timestep": 8061, "ep_reward": 40.422122955322266, "reward": 0.07989418506622314, "action": -0.8112583756446838}
{"mode": "train", "epochs": 5, "timestep": 8062, "ep_reward": 40.64206314086914, "reward": 0.219940185546875, "action": -0.5360244512557983}
{"mode": "train", "epochs": 5, "timestep": 8063, "ep_reward": 41.006935119628906, "reward": 0.3648725748062134, "action": -0.40993112325668335}
{"mode": "train", "epochs": 5, "timestep": 8064, "ep_reward": 41.509002685546875, "reward": 0.5020684003829956, "action": -0.7993801236152649}
{"mode": "train", "epochs": 5, "timestep": 8065, "ep_reward": 42.12603759765625, "reward": 0.6170355081558228, "action": -1.341554880142212}
{"mode": "train", "epochs": 5, "timestep": 8066, "ep_reward": 42.8314094543457, "reward": 0.7053707838058472, "action": -1.9839222431182861}
{"mode": "train", "epochs": 5, "timestep": 8067, "ep_reward": 43.59868240356445, "reward": 0.7672715187072754, "action": -1.2818069458007812}
{"mode": "train", "epochs": 5, "timestep": 8068, "ep_reward": 44.41503143310547, "reward": 0.8163496255874634, "action": -1.3788641691207886}
{"mode": "train", "epochs": 5, "timestep": 8069, "ep_reward": 45.26123809814453, "reward": 0.8462085127830505, "action": -0.5025433897972107}
{"mode": "train", "epochs": 5, "timestep": 8070, "ep_reward": 46.127506256103516, "reward": 0.8662687540054321, "action": -1.5303442478179932}
{"mode": "train", "epochs": 5, "timestep": 8071, "ep_reward": 46.9886474609375, "reward": 0.8611425757408142, "action": -1.2657222747802734}
{"mode": "train", "epochs": 5, "timestep": 8072, "ep_reward": 47.82884216308594, "reward": 0.8401941061019897, "action": -0.013472020626068115}
{"mode": "train", "epochs": 5, "timestep": 8073, "ep_reward": 48.639015197753906, "reward": 0.8101745843887329, "action": -1.1938598155975342}
{"mode": "train", "epochs": 5, "timestep": 8074, "ep_reward": 49.382266998291016, "reward": 0.7432503700256348, "action": -1.3446952104568481}
{"mode": "train", "epochs": 5, "timestep": 8075, "ep_reward": 50.02324676513672, "reward": 0.6409788131713867, "action": -0.8217095136642456}
{"mode": "train", "epochs": 5, "timestep": 8076, "ep_reward": 50.5285530090332, "reward": 0.505304753780365, "action": -1.673311471939087}
{"mode": "train", "epochs": 5, "timestep": 8077, "ep_reward": 50.886207580566406, "reward": 0.3576549291610718, "action": -0.0014410614967346191}
{"mode": "train", "epochs": 5, "timestep": 8078, "ep_reward": 51.1353874206543, "reward": 0.24918055534362793, "action": -0.5278359651565552}
{"mode": "train", "epochs": 5, "timestep": 8079, "ep_reward": 51.25592041015625, "reward": 0.12053382396697998, "action": -1.8208057880401611}
{"mode": "train", "epochs": 5, "timestep": 8080, "ep_reward": 51.24979019165039, "reward": -0.006130337715148926, "action": -0.9009107351303101}
{"mode": "train", "epochs": 5, "timestep": 8081, "ep_reward": 51.389408111572266, "reward": 0.139617919921875, "action": 0.27312934398651123}
{"mode": "train", "epochs": 5, "timestep": 8082, "ep_reward": 51.68400955200195, "reward": 0.29460233449935913, "action": -0.7345834970474243}
{"mode": "train", "epochs": 5, "timestep": 8083, "ep_reward": 52.115753173828125, "reward": 0.4317438006401062, "action": -1.4141035079956055}
{"mode": "train", "epochs": 5, "timestep": 8084, "ep_reward": 52.6650505065918, "reward": 0.5492955446243286, "action": -1.7840063571929932}
{"mode": "train", "epochs": 5, "timestep": 8085, "ep_reward": 53.31123352050781, "reward": 0.6461836099624634, "action": -1.4545493125915527}
{"mode": "train", "epochs": 5, "timestep": 8086, "ep_reward": 54.0379638671875, "reward": 0.726731538772583, "action": -0.7437700033187866}
{"mode": "train", "epochs": 5, "timestep": 8087, "ep_reward": 54.83061218261719, "reward": 0.7926495671272278, "action": -1.065935730934143}
{"mode": "train", "epochs": 5, "timestep": 8088, "ep_reward": 55.66597366333008, "reward": 0.835360050201416, "action": -0.5275051593780518}
{"mode": "train", "epochs": 5, "timestep": 8089, "ep_reward": 56.530696868896484, "reward": 0.8647220134735107, "action": -1.6350536346435547}
{"mode": "train", "epochs": 5, "timestep": 8090, "ep_reward": 57.399688720703125, "reward": 0.8689934015274048, "action": -1.1498684883117676}
{"mode": "train", "epochs": 5, "timestep": 8091, "ep_reward": 58.26066970825195, "reward": 0.8609825968742371, "action": -1.3286559581756592}
{"mode": "train", "epochs": 5, "timestep": 8092, "ep_reward": 59.093482971191406, "reward": 0.8328115344047546, "action": -1.1058189868927002}
{"mode": "train", "epochs": 5, "timestep": 8093, "ep_reward": 59.87716293334961, "reward": 0.7836803197860718, "action": -1.1643128395080566}
{"mode": "train", "epochs": 5, "timestep": 8094, "ep_reward": 60.581947326660156, "reward": 0.7047836184501648, "action": -0.8086291551589966}
{"mode": "train", "epochs": 5, "timestep": 8095, "ep_reward": 61.176185607910156, "reward": 0.5942388772964478, "action": -0.8362780809402466}
{"mode": "train", "epochs": 5, "timestep": 8096, "ep_reward": 61.618896484375, "reward": 0.4427105188369751, "action": -0.9361771941184998}
{"mode": "train", "epochs": 5, "timestep": 8097, "ep_reward": 61.93827438354492, "reward": 0.3193790316581726, "action": -0.855052649974823}
{"mode": "train", "epochs": 5, "timestep": 8098, "ep_reward": 62.14171600341797, "reward": 0.20344191789627075, "action": -0.8412114977836609}
{"mode": "train", "epochs": 5, "timestep": 8099, "ep_reward": 62.20925521850586, "reward": 0.06754046678543091, "action": -0.3369750380516052}
{"mode": "train", "epochs": 5, "timestep": 8100, "ep_reward": 62.25995635986328, "reward": 0.05070137977600098, "action": -1.018703818321228}
{"mode": "train", "epochs": 5, "timestep": 8101, "ep_reward": 62.448848724365234, "reward": 0.18889284133911133, "action": -1.2275762557983398}
{"mode": "train", "epochs": 5, "timestep": 8102, "ep_reward": 62.77517318725586, "reward": 0.32632553577423096, "action": -0.6111266613006592}
{"mode": "train", "epochs": 5, "timestep": 8103, "ep_reward": 63.241146087646484, "reward": 0.46597200632095337, "action": -1.0486552715301514}
{"mode": "train", "epochs": 5, "timestep": 8104, "ep_reward": 63.82554244995117, "reward": 0.5843958854675293, "action": -0.8973612189292908}
{"mode": "train", "epochs": 5, "timestep": 8105, "ep_reward": 64.50885009765625, "reward": 0.6833044290542603, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 8106, "ep_reward": 65.25782775878906, "reward": 0.748975396156311, "action": -0.7720300555229187}
{"mode": "train", "epochs": 5, "timestep": 8107, "ep_reward": 66.06340789794922, "reward": 0.8055810928344727, "action": -0.9443482160568237}
{"mode": "train", "epochs": 5, "timestep": 8108, "ep_reward": 66.90364074707031, "reward": 0.8402338027954102, "action": -0.9680771827697754}
{"mode": "train", "epochs": 5, "timestep": 8109, "ep_reward": 67.76010131835938, "reward": 0.856464147567749, "action": -1.3570760488510132}
{"mode": "train", "epochs": 5, "timestep": 8110, "ep_reward": 68.61190032958984, "reward": 0.8517960906028748, "action": -0.4788668155670166}
{"mode": "train", "epochs": 5, "timestep": 8111, "ep_reward": 69.44800567626953, "reward": 0.8361067175865173, "action": -0.6878155469894409}
{"mode": "train", "epochs": 5, "timestep": 8112, "ep_reward": 70.24497985839844, "reward": 0.796973705291748, "action": -0.528498649597168}
{"mode": "train", "epochs": 5, "timestep": 8113, "ep_reward": 70.97822570800781, "reward": 0.7332483530044556, "action": -0.6910190582275391}
{"mode": "train", "epochs": 5, "timestep": 8114, "ep_reward": 71.61344146728516, "reward": 0.635215163230896, "action": -1.7881824970245361}
{"mode": "train", "epochs": 5, "timestep": 8115, "ep_reward": 72.09571075439453, "reward": 0.4822661876678467, "action": -0.5274373292922974}
{"mode": "train", "epochs": 5, "timestep": 8116, "ep_reward": 72.44276428222656, "reward": 0.3470548391342163, "action": -0.6970392465591431}
{"mode": "train", "epochs": 5, "timestep": 8117, "ep_reward": 72.67908477783203, "reward": 0.23632407188415527, "action": -1.696760892868042}
{"mode": "train", "epochs": 5, "timestep": 8118, "ep_reward": 72.78499603271484, "reward": 0.10591179132461548, "action": -0.42105942964553833}
{"mode": "train", "epochs": 5, "timestep": 8119, "ep_reward": 72.79524230957031, "reward": 0.010245442390441895, "action": -1.2590065002441406}
{"mode": "train", "epochs": 5, "timestep": 8120, "ep_reward": 72.94914245605469, "reward": 0.15389806032180786, "action": -0.624639630317688}
{"mode": "train", "epochs": 5, "timestep": 8121, "ep_reward": 73.24732208251953, "reward": 0.29818183183670044, "action": -0.7767316699028015}
{"mode": "train", "epochs": 5, "timestep": 8122, "ep_reward": 73.68376159667969, "reward": 0.4364423155784607, "action": -1.3316197395324707}
{"mode": "train", "epochs": 5, "timestep": 8123, "ep_reward": 74.23904418945312, "reward": 0.5552798509597778, "action": -1.3150792121887207}
{"mode": "train", "epochs": 5, "timestep": 8124, "ep_reward": 74.89491271972656, "reward": 0.6558704376220703, "action": -1.2957017421722412}
{"mode": "train", "epochs": 5, "timestep": 8125, "ep_reward": 75.62998962402344, "reward": 0.7350801229476929, "action": -1.1034860610961914}
{"mode": "train", "epochs": 5, "timestep": 8126, "ep_reward": 76.42450714111328, "reward": 0.7945142984390259, "action": -0.19728267192840576}
{"mode": "train", "epochs": 5, "timestep": 8127, "ep_reward": 77.2659912109375, "reward": 0.841480553150177, "action": -1.3393369913101196}
{"mode": "train", "epochs": 5, "timestep": 8128, "ep_reward": 78.12651824951172, "reward": 0.860527753829956, "action": -0.7759007215499878}
{"mode": "train", "epochs": 5, "timestep": 8129, "ep_reward": 78.99446868896484, "reward": 0.867949903011322, "action": -0.9964037537574768}
{"mode": "train", "epochs": 5, "timestep": 8130, "ep_reward": 79.8512954711914, "reward": 0.8568240404129028, "action": -0.2682550549507141}
{"mode": "train", "epochs": 5, "timestep": 8131, "ep_reward": 80.68479919433594, "reward": 0.833504319190979, "action": -1.7595328092575073}
{"mode": "train", "epochs": 5, "timestep": 8132, "ep_reward": 81.45767974853516, "reward": 0.7728778719902039, "action": -1.8685379028320312}
{"mode": "train", "epochs": 5, "timestep": 8133, "ep_reward": 82.13627624511719, "reward": 0.678598165512085, "action": -0.9226835370063782}
{"mode": "train", "epochs": 5, "timestep": 8134, "ep_reward": 82.69267272949219, "reward": 0.5563981533050537, "action": -1.5997562408447266}
{"mode": "train", "epochs": 5, "timestep": 8135, "ep_reward": 83.08570098876953, "reward": 0.39302557706832886, "action": -0.14772337675094604}
{"mode": "train", "epochs": 5, "timestep": 8136, "ep_reward": 83.3775634765625, "reward": 0.2918643355369568, "action": -1.6692801713943481}
{"mode": "train", "epochs": 5, "timestep": 8137, "ep_reward": 83.54853057861328, "reward": 0.17097079753875732, "action": -1.1264235973358154}
{"mode": "train", "epochs": 5, "timestep": 8138, "ep_reward": 83.57843017578125, "reward": 0.029897212982177734, "action": -1.6224520206451416}
{"mode": "train", "epochs": 5, "timestep": 8139, "ep_reward": 83.66592407226562, "reward": 0.08749431371688843, "action": -0.9709540009498596}
{"mode": "train", "epochs": 5, "timestep": 8140, "ep_reward": 83.89163208007812, "reward": 0.22570717334747314, "action": -1.2380681037902832}
{"mode": "train", "epochs": 5, "timestep": 8141, "ep_reward": 84.2537841796875, "reward": 0.36215299367904663, "action": -1.32679283618927}
{"mode": "train", "epochs": 5, "timestep": 8142, "ep_reward": 84.74384307861328, "reward": 0.4900556802749634, "action": -1.2724652290344238}
{"mode": "train", "epochs": 5, "timestep": 8143, "ep_reward": 85.34635925292969, "reward": 0.6025142669677734, "action": -0.7810130715370178}
{"mode": "train", "epochs": 5, "timestep": 8144, "ep_reward": 86.04460906982422, "reward": 0.6982519030570984, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 8145, "ep_reward": 86.8031234741211, "reward": 0.7585142254829407, "action": -1.8566839694976807}
{"mode": "train", "epochs": 5, "timestep": 8146, "ep_reward": 87.60255432128906, "reward": 0.799432635307312, "action": -1.4400663375854492}
{"mode": "train", "epochs": 5, "timestep": 8147, "ep_reward": 88.42646789550781, "reward": 0.8239151835441589, "action": -0.17923766374588013}
{"mode": "train", "epochs": 5, "timestep": 8148, "ep_reward": 89.26626586914062, "reward": 0.8397950530052185, "action": -1.3868733644485474}
{"mode": "train", "epochs": 5, "timestep": 8149, "ep_reward": 90.08991241455078, "reward": 0.8236501216888428, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 8150, "ep_reward": 90.86701965332031, "reward": 0.7771036624908447, "action": -1.179240107536316}
{"mode": "train", "epochs": 5, "timestep": 8151, "ep_reward": 91.57550048828125, "reward": 0.7084789276123047, "action": -1.2204985618591309}
{"mode": "train", "epochs": 5, "timestep": 8152, "ep_reward": 92.1774673461914, "reward": 0.6019702553749084, "action": -0.6637066602706909}
{"mode": "train", "epochs": 5, "timestep": 8153, "ep_reward": 92.6374282836914, "reward": 0.459958016872406, "action": -0.8900834321975708}
{"mode": "train", "epochs": 5, "timestep": 8154, "ep_reward": 92.99102020263672, "reward": 0.3535882830619812, "action": -0.743594229221344}
{"mode": "train", "epochs": 5, "timestep": 8155, "ep_reward": 93.23530578613281, "reward": 0.24428731203079224, "action": -0.9982605576515198}
{"mode": "train", "epochs": 5, "timestep": 8156, "ep_reward": 93.35018920898438, "reward": 0.11488491296768188, "action": -1.749404788017273}
{"mode": "train", "epochs": 5, "timestep": 8157, "ep_reward": 93.35030364990234, "reward": 0.00011199712753295898, "action": -1.5189359188079834}
{"mode": "train", "epochs": 5, "timestep": 8158, "ep_reward": 93.49540710449219, "reward": 0.1451045274734497, "action": -0.7835740447044373}
{"mode": "train", "epochs": 5, "timestep": 8159, "ep_reward": 93.78257751464844, "reward": 0.28716909885406494, "action": -1.3185439109802246}
{"mode": "train", "epochs": 5, "timestep": 8160, "ep_reward": 94.20244598388672, "reward": 0.4198654890060425, "action": -1.2415273189544678}
{"mode": "train", "epochs": 5, "timestep": 8161, "ep_reward": 94.74484252929688, "reward": 0.5424002408981323, "action": -0.4623144865036011}
{"mode": "train", "epochs": 5, "timestep": 8162, "ep_reward": 95.39908599853516, "reward": 0.65424644947052, "action": -1.352664589881897}
{"mode": "train", "epochs": 5, "timestep": 8163, "ep_reward": 96.1325912475586, "reward": 0.7335063815116882, "action": -0.4187365770339966}
{"mode": "train", "epochs": 5, "timestep": 8164, "ep_reward": 96.9323501586914, "reward": 0.7997622489929199, "action": -0.5989004373550415}
{"mode": "train", "epochs": 5, "timestep": 8165, "ep_reward": 97.77587890625, "reward": 0.8435291051864624, "action": -0.7323942184448242}
{"mode": "train", "epochs": 5, "timestep": 8166, "ep_reward": 98.64445495605469, "reward": 0.8685730695724487, "action": -0.8782538175582886}
{"mode": "train", "epochs": 5, "timestep": 8167, "ep_reward": 99.52122497558594, "reward": 0.8767719864845276, "action": -1.2790157794952393}
{"mode": "train", "epochs": 5, "timestep": 8168, "ep_reward": 100.38739776611328, "reward": 0.8661765456199646, "action": -0.6740713119506836}
{"mode": "train", "epochs": 5, "timestep": 8169, "ep_reward": 101.23056030273438, "reward": 0.8431620597839355, "action": -0.8212779760360718}
{"mode": "train", "epochs": 5, "timestep": 8170, "ep_reward": 102.02831268310547, "reward": 0.7977514266967773, "action": -1.32392156124115}
{"mode": "train", "epochs": 5, "timestep": 8171, "ep_reward": 102.74812316894531, "reward": 0.7198067307472229, "action": -1.0820828676223755}
{"mode": "train", "epochs": 5, "timestep": 8172, "ep_reward": 103.35753631591797, "reward": 0.6094094514846802, "action": -1.0634193420410156}
{"mode": "train", "epochs": 5, "timestep": 8173, "ep_reward": 103.8160171508789, "reward": 0.45848238468170166, "action": -1.2094151973724365}
{"mode": "train", "epochs": 5, "timestep": 8174, "ep_reward": 104.14078521728516, "reward": 0.3247643709182739, "action": -1.716097354888916}
{"mode": "train", "epochs": 5, "timestep": 8175, "ep_reward": 104.35083770751953, "reward": 0.21004873514175415, "action": -0.3687918782234192}
{"mode": "train", "epochs": 5, "timestep": 8176, "ep_reward": 104.42582702636719, "reward": 0.07498675584793091, "action": -1.692760944366455}
{"mode": "train", "epochs": 5, "timestep": 8177, "ep_reward": 104.46871185302734, "reward": 0.042887985706329346, "action": -1.173996925354004}
{"mode": "train", "epochs": 5, "timestep": 8178, "ep_reward": 104.65077209472656, "reward": 0.18206274509429932, "action": -1.6980745792388916}
{"mode": "train", "epochs": 5, "timestep": 8179, "ep_reward": 104.96414947509766, "reward": 0.31337791681289673, "action": -1.8063948154449463}
{"mode": "train", "epochs": 5, "timestep": 8180, "ep_reward": 105.40434265136719, "reward": 0.44019168615341187, "action": -1.5835330486297607}
{"mode": "train", "epochs": 5, "timestep": 8181, "ep_reward": 105.9613037109375, "reward": 0.5569605231285095, "action": -0.7045313119888306}
{"mode": "train", "epochs": 5, "timestep": 8182, "ep_reward": 106.62410736083984, "reward": 0.66280597448349, "action": 0.08165311813354492}
{"mode": "train", "epochs": 5, "timestep": 8183, "ep_reward": 107.37504577636719, "reward": 0.7509350180625916, "action": -1.2266615629196167}
{"mode": "train", "epochs": 5, "timestep": 8184, "ep_reward": 108.17662811279297, "reward": 0.8015832901000977, "action": -1.0127168893814087}
{"mode": "train", "epochs": 5, "timestep": 8185, "ep_reward": 109.01033782958984, "reward": 0.833712100982666, "action": -1.2343255281448364}
{"mode": "train", "epochs": 5, "timestep": 8186, "ep_reward": 109.85498046875, "reward": 0.8446430563926697, "action": -1.6631317138671875}
{"mode": "train", "epochs": 5, "timestep": 8187, "ep_reward": 110.68721771240234, "reward": 0.8322370648384094, "action": -1.602311372756958}
{"mode": "train", "epochs": 5, "timestep": 8188, "ep_reward": 111.4849624633789, "reward": 0.7977482676506042, "action": -1.417138934135437}
{"mode": "train", "epochs": 5, "timestep": 8189, "ep_reward": 112.22206115722656, "reward": 0.7370961904525757, "action": -1.2060720920562744}
{"mode": "train", "epochs": 5, "timestep": 8190, "ep_reward": 112.86605834960938, "reward": 0.6439962387084961, "action": -0.511186420917511}
{"mode": "train", "epochs": 5, "timestep": 8191, "ep_reward": 113.38546752929688, "reward": 0.5194089412689209, "action": -1.1911758184432983}
{"mode": "train", "epochs": 5, "timestep": 8192, "ep_reward": 113.77118682861328, "reward": 0.38571786880493164, "action": -0.8340851068496704}
{"mode": "train", "epochs": 5, "timestep": 8193, "ep_reward": 114.05412292480469, "reward": 0.282939076423645, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 8194, "ep_reward": 114.21472930908203, "reward": 0.16060566902160645, "action": -0.4186621904373169}
{"mode": "train", "epochs": 5, "timestep": 8195, "ep_reward": 114.23263549804688, "reward": 0.017905712127685547, "action": -1.4880050420761108}
{"mode": "train", "epochs": 5, "timestep": 8196, "ep_reward": 114.33121490478516, "reward": 0.09857714176177979, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 8197, "ep_reward": 114.56156158447266, "reward": 0.2303449511528015, "action": -1.056698203086853}
{"mode": "train", "epochs": 5, "timestep": 8198, "ep_reward": 114.93162536621094, "reward": 0.370063841342926, "action": -1.0830423831939697}
{"mode": "train", "epochs": 5, "timestep": 8199, "ep_reward": 115.43209838867188, "reward": 0.5004714727401733, "action": -1.1368623971939087}
{"mode": "train", "epochs": 5, "timestep": 8200, "ep_reward": 116.04478454589844, "reward": 0.6126871109008789, "action": -1.059802770614624}
{"mode": "train", "epochs": 5, "timestep": 8201, "ep_reward": 116.74829864501953, "reward": 0.7035171985626221, "action": -0.5337275266647339}
{"mode": "train", "epochs": 5, "timestep": 8202, "ep_reward": 117.52435302734375, "reward": 0.7760512828826904, "action": -0.5095571279525757}
{"mode": "train", "epochs": 5, "timestep": 8203, "ep_reward": 118.35050964355469, "reward": 0.8261590003967285, "action": -1.9069061279296875}
{"mode": "train", "epochs": 5, "timestep": 8204, "ep_reward": 119.19549560546875, "reward": 0.8449891805648804, "action": -1.622457504272461}
{"mode": "train", "epochs": 5, "timestep": 8205, "ep_reward": 120.04417419433594, "reward": 0.8486810326576233, "action": -1.1872433423995972}
{"mode": "train", "epochs": 5, "timestep": 8206, "ep_reward": 120.8814926147461, "reward": 0.8373169898986816, "action": -1.0947133302688599}
{"mode": "train", "epochs": 5, "timestep": 8207, "ep_reward": 121.6866683959961, "reward": 0.8051730394363403, "action": -1.3393926620483398}
{"mode": "train", "epochs": 5, "timestep": 8208, "ep_reward": 122.43045806884766, "reward": 0.7437905073165894, "action": -1.3147454261779785}
{"mode": "train", "epochs": 5, "timestep": 8209, "ep_reward": 123.07894897460938, "reward": 0.648490846157074, "action": -1.1931941509246826}
{"mode": "train", "epochs": 5, "timestep": 8210, "ep_reward": 123.59223937988281, "reward": 0.5132937431335449, "action": -1.0374820232391357}
{"mode": "train", "epochs": 5, "timestep": 8211, "ep_reward": 123.97200012207031, "reward": 0.37975966930389404, "action": -1.5493654012680054}
{"mode": "train", "epochs": 5, "timestep": 8212, "ep_reward": 124.24790954589844, "reward": 0.2759060859680176, "action": -1.6761726140975952}
{"mode": "train", "epochs": 5, "timestep": 8213, "ep_reward": 124.4001235961914, "reward": 0.15221315622329712, "action": -0.8032242059707642}
{"mode": "train", "epochs": 5, "timestep": 8214, "ep_reward": 124.4084701538086, "reward": 0.008348047733306885, "action": -1.1113039255142212}
{"mode": "train", "epochs": 5, "timestep": 8215, "ep_reward": 124.51606750488281, "reward": 0.1075943112373352, "action": -1.1534645557403564}
{"mode": "train", "epochs": 5, "timestep": 8216, "ep_reward": 124.76016998291016, "reward": 0.24410200119018555, "action": -1.3844102621078491}
{"mode": "train", "epochs": 5, "timestep": 8217, "ep_reward": 125.13858032226562, "reward": 0.378410279750824, "action": -1.8437860012054443}
{"mode": "train", "epochs": 5, "timestep": 8218, "ep_reward": 125.63758850097656, "reward": 0.4990077614784241, "action": -0.43769901990890503}
{"mode": "train", "epochs": 5, "timestep": 8219, "ep_reward": 126.25687408447266, "reward": 0.6192852258682251, "action": -0.4877218008041382}
{"mode": "train", "epochs": 5, "timestep": 8220, "ep_reward": 126.97123718261719, "reward": 0.7143599987030029, "action": -0.09346020221710205}
{"mode": "train", "epochs": 5, "timestep": 8221, "ep_reward": 127.7598648071289, "reward": 0.7886250019073486, "action": -0.554773211479187}
{"mode": "train", "epochs": 5, "timestep": 8222, "ep_reward": 128.59640502929688, "reward": 0.8365344405174255, "action": -0.6843439340591431}
{"mode": "train", "epochs": 5, "timestep": 8223, "ep_reward": 129.4613800048828, "reward": 0.8649702668190002, "action": -1.884049415588379}
{"mode": "train", "epochs": 5, "timestep": 8224, "ep_reward": 130.32925415039062, "reward": 0.8678709864616394, "action": -0.8896989822387695}
{"mode": "train", "epochs": 5, "timestep": 8225, "ep_reward": 131.19198608398438, "reward": 0.8627342581748962, "action": -1.3623933792114258}
{"mode": "train", "epochs": 5, "timestep": 8226, "ep_reward": 132.02723693847656, "reward": 0.8352454900741577, "action": -0.7547552585601807}
{"mode": "train", "epochs": 5, "timestep": 8227, "ep_reward": 132.81838989257812, "reward": 0.7911567687988281, "action": -0.7051745653152466}
{"mode": "train", "epochs": 5, "timestep": 8228, "ep_reward": 133.538818359375, "reward": 0.7204276323318481, "action": -0.6306355595588684}
{"mode": "train", "epochs": 5, "timestep": 8229, "ep_reward": 134.1560821533203, "reward": 0.6172641515731812, "action": -0.32532817125320435}
{"mode": "train", "epochs": 5, "timestep": 8230, "ep_reward": 134.6363983154297, "reward": 0.48031848669052124, "action": -1.1113312244415283}
{"mode": "train", "epochs": 5, "timestep": 8231, "ep_reward": 134.96852111816406, "reward": 0.33212536573410034, "action": -1.3121368885040283}
{"mode": "train", "epochs": 5, "timestep": 8232, "ep_reward": 135.187255859375, "reward": 0.21873724460601807, "action": -0.21409708261489868}
{"mode": "train", "epochs": 5, "timestep": 8233, "ep_reward": 135.27247619628906, "reward": 0.08522152900695801, "action": -0.638892650604248}
{"mode": "train", "epochs": 5, "timestep": 8234, "ep_reward": 135.30496215820312, "reward": 0.032489120960235596, "action": -0.025967657566070557}
{"mode": "train", "epochs": 5, "timestep": 8235, "ep_reward": 135.48565673828125, "reward": 0.1806960105895996, "action": -1.3009079694747925}
{"mode": "train", "epochs": 5, "timestep": 8236, "ep_reward": 135.80101013183594, "reward": 0.3153529763221741, "action": -1.5245089530944824}
{"mode": "train", "epochs": 5, "timestep": 8237, "ep_reward": 136.24497985839844, "reward": 0.4439741373062134, "action": -0.899804949760437}
{"mode": "train", "epochs": 5, "timestep": 8238, "ep_reward": 136.81234741210938, "reward": 0.56737220287323, "action": -0.08062100410461426}
{"mode": "train", "epochs": 5, "timestep": 8239, "ep_reward": 137.49066162109375, "reward": 0.6783163547515869, "action": -0.48676979541778564}
{"mode": "train", "epochs": 5, "timestep": 8240, "ep_reward": 138.25086975097656, "reward": 0.760212779045105, "action": -1.3957371711730957}
{"mode": "train", "epochs": 5, "timestep": 8241, "ep_reward": 139.06320190429688, "reward": 0.8123266696929932, "action": -0.6425657272338867}
{"mode": "train", "epochs": 5, "timestep": 8242, "ep_reward": 139.91566467285156, "reward": 0.8524625897407532, "action": -1.4047454595565796}
{"mode": "train", "epochs": 5, "timestep": 8243, "ep_reward": 140.7855987548828, "reward": 0.8699299097061157, "action": -0.6818607449531555}
{"mode": "train", "epochs": 5, "timestep": 8244, "ep_reward": 141.6636199951172, "reward": 0.8780272603034973, "action": -1.0835367441177368}
{"mode": "train", "epochs": 5, "timestep": 8245, "ep_reward": 142.531005859375, "reward": 0.8673823475837708, "action": -0.9077897071838379}
{"mode": "train", "epochs": 5, "timestep": 8246, "ep_reward": 143.37156677246094, "reward": 0.8405568599700928, "action": -1.1849870681762695}
{"mode": "train", "epochs": 5, "timestep": 8247, "ep_reward": 144.16078186035156, "reward": 0.7892082929611206, "action": -1.1207280158996582}
{"mode": "train", "epochs": 5, "timestep": 8248, "ep_reward": 144.87081909179688, "reward": 0.7100442051887512, "action": 0.10699975490570068}
{"mode": "train", "epochs": 5, "timestep": 8249, "ep_reward": 145.48287963867188, "reward": 0.6120648384094238, "action": -0.9253737926483154}
{"mode": "train", "epochs": 5, "timestep": 8250, "ep_reward": 145.94625854492188, "reward": 0.4633738398551941, "action": -0.9995248317718506}
{"mode": "train", "epochs": 5, "timestep": 8251, "ep_reward": 146.26513671875, "reward": 0.3188818693161011, "action": -0.7088383436203003}
{"mode": "train", "epochs": 5, "timestep": 8252, "ep_reward": 146.46783447265625, "reward": 0.20270520448684692, "action": -1.6608027219772339}
{"mode": "train", "epochs": 5, "timestep": 8253, "ep_reward": 146.53465270996094, "reward": 0.06681668758392334, "action": -0.6329345107078552}
{"mode": "train", "epochs": 5, "timestep": 8254, "ep_reward": 146.58599853515625, "reward": 0.051352858543395996, "action": -1.4443830251693726}
{"mode": "train", "epochs": 5, "timestep": 8255, "ep_reward": 146.7755584716797, "reward": 0.18956738710403442, "action": -0.802482008934021}
{"mode": "train", "epochs": 5, "timestep": 8256, "ep_reward": 147.1077880859375, "reward": 0.3322233557701111, "action": -0.9653753638267517}
{"mode": "train", "epochs": 5, "timestep": 8257, "ep_reward": 147.57423400878906, "reward": 0.46644043922424316, "action": -1.7750799655914307}
{"mode": "train", "epochs": 5, "timestep": 8258, "ep_reward": 148.15097045898438, "reward": 0.5767382383346558, "action": -0.6188613176345825}
{"mode": "train", "epochs": 5, "timestep": 8259, "ep_reward": 148.83096313476562, "reward": 0.6799895763397217, "action": -1.3952702283859253}
{"mode": "train", "epochs": 5, "timestep": 8260, "ep_reward": 149.5826873779297, "reward": 0.7517200112342834, "action": -1.0197395086288452}
{"mode": "train", "epochs": 5, "timestep": 8261, "ep_reward": 150.38812255859375, "reward": 0.8054291009902954, "action": -1.478833794593811}
{"mode": "train", "epochs": 5, "timestep": 8262, "ep_reward": 151.22323608398438, "reward": 0.8351128101348877, "action": -1.0713129043579102}
{"mode": "train", "epochs": 5, "timestep": 8263, "ep_reward": 152.0731658935547, "reward": 0.8499337434768677, "action": -1.7567927837371826}
{"mode": "train", "epochs": 5, "timestep": 8264, "ep_reward": 152.91322326660156, "reward": 0.840053141117096, "action": -1.656816840171814}
{"mode": "train", "epochs": 5, "timestep": 8265, "ep_reward": 153.7229766845703, "reward": 0.8097594380378723, "action": -0.16800469160079956}
{"mode": "train", "epochs": 5, "timestep": 8266, "ep_reward": 154.49253845214844, "reward": 0.7695648074150085, "action": -0.6607906818389893}
{"mode": "train", "epochs": 5, "timestep": 8267, "ep_reward": 155.18739318847656, "reward": 0.6948594450950623, "action": -1.418665885925293}
{"mode": "train", "epochs": 5, "timestep": 8268, "ep_reward": 155.76100158691406, "reward": 0.5736059546470642, "action": -0.7024431228637695}
{"mode": "train", "epochs": 5, "timestep": 8269, "ep_reward": 156.17994689941406, "reward": 0.41894930601119995, "action": -1.418439507484436}
{"mode": "train", "epochs": 5, "timestep": 8270, "ep_reward": 156.49485778808594, "reward": 0.31491464376449585, "action": -1.2084263563156128}
{"mode": "train", "epochs": 5, "timestep": 8271, "ep_reward": 156.6930694580078, "reward": 0.19821220636367798, "action": -0.6137248277664185}
{"mode": "train", "epochs": 5, "timestep": 8272, "ep_reward": 156.75445556640625, "reward": 0.061386704444885254, "action": -1.1227601766586304}
{"mode": "train", "epochs": 5, "timestep": 8273, "ep_reward": 156.8112030029297, "reward": 0.0567471981048584, "action": -1.6106669902801514}
{"mode": "train", "epochs": 5, "timestep": 8274, "ep_reward": 157.00537109375, "reward": 0.19416624307632446, "action": -1.4582353830337524}
{"mode": "train", "epochs": 5, "timestep": 8275, "ep_reward": 157.3340606689453, "reward": 0.32869696617126465, "action": -1.421849250793457}
{"mode": "train", "epochs": 5, "timestep": 8276, "ep_reward": 157.7930145263672, "reward": 0.4589599370956421, "action": -0.009870529174804688}
{"mode": "train", "epochs": 5, "timestep": 8277, "ep_reward": 158.3835906982422, "reward": 0.5905781984329224, "action": -0.5856051445007324}
{"mode": "train", "epochs": 5, "timestep": 8278, "ep_reward": 159.07504272460938, "reward": 0.6914457082748413, "action": -1.2650012969970703}
{"mode": "train", "epochs": 5, "timestep": 8279, "ep_reward": 159.8372039794922, "reward": 0.7621625661849976, "action": -1.239991545677185}
{"mode": "train", "epochs": 5, "timestep": 8280, "ep_reward": 160.6494903564453, "reward": 0.8122938871383667, "action": -0.6857786178588867}
{"mode": "train", "epochs": 5, "timestep": 8281, "ep_reward": 161.49765014648438, "reward": 0.8481603860855103, "action": -0.19154512882232666}
{"mode": "train", "epochs": 5, "timestep": 8282, "ep_reward": 162.3682098388672, "reward": 0.8705611228942871, "action": -0.9744195938110352}
{"mode": "train", "epochs": 5, "timestep": 8283, "ep_reward": 163.23863220214844, "reward": 0.8704173564910889, "action": 0.35521364212036133}
{"mode": "train", "epochs": 5, "timestep": 8284, "ep_reward": 164.10400390625, "reward": 0.8653713464736938, "action": -1.0471911430358887}
{"mode": "train", "epochs": 5, "timestep": 8285, "ep_reward": 164.93438720703125, "reward": 0.8303790092468262, "action": -0.7689323425292969}
{"mode": "train", "epochs": 5, "timestep": 8286, "ep_reward": 165.7093048095703, "reward": 0.7749131917953491, "action": -1.694798231124878}
{"mode": "train", "epochs": 5, "timestep": 8287, "ep_reward": 166.388671875, "reward": 0.6793598532676697, "action": -0.8006082773208618}
{"mode": "train", "epochs": 5, "timestep": 8288, "ep_reward": 166.94522094726562, "reward": 0.5565540790557861, "action": -1.0033648014068604}
{"mode": "train", "epochs": 5, "timestep": 8289, "ep_reward": 167.33547973632812, "reward": 0.3902565836906433, "action": -0.18679296970367432}
{"mode": "train", "epochs": 5, "timestep": 8290, "ep_reward": 167.6136016845703, "reward": 0.27812689542770386, "action": -0.7023128271102905}
{"mode": "train", "epochs": 5, "timestep": 8291, "ep_reward": 167.76824951171875, "reward": 0.15464723110198975, "action": -0.8736677169799805}
{"mode": "train", "epochs": 5, "timestep": 8292, "ep_reward": 167.77926635742188, "reward": 0.01101696491241455, "action": -1.8543281555175781}
{"mode": "train", "epochs": 5, "timestep": 8293, "ep_reward": 167.88430786132812, "reward": 0.10503768920898438, "action": -1.080056071281433}
{"mode": "train", "epochs": 5, "timestep": 8294, "ep_reward": 168.1266632080078, "reward": 0.24235671758651733, "action": -1.5491807460784912}
{"mode": "train", "epochs": 5, "timestep": 8295, "ep_reward": 168.50135803222656, "reward": 0.3746921420097351, "action": -1.155198335647583}
{"mode": "train", "epochs": 5, "timestep": 8296, "ep_reward": 169.00514221191406, "reward": 0.5037859082221985, "action": -1.2062724828720093}
{"mode": "train", "epochs": 5, "timestep": 8297, "ep_reward": 169.61965942382812, "reward": 0.6145206689834595, "action": -1.9351806640625}
{"mode": "train", "epochs": 5, "timestep": 8298, "ep_reward": 170.31532287597656, "reward": 0.6956658363342285, "action": -1.4557318687438965}
{"mode": "train", "epochs": 5, "timestep": 8299, "ep_reward": 171.07496643066406, "reward": 0.7596434950828552, "action": -0.7585586309432983}
{"mode": "train", "epochs": 5, "timestep": 8300, "ep_reward": 171.88262939453125, "reward": 0.8076604604721069, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 8301, "ep_reward": 172.70558166503906, "reward": 0.8229581117630005, "action": -0.943452000617981}
{"mode": "train", "epochs": 5, "timestep": 8302, "ep_reward": 173.53318786621094, "reward": 0.8276032209396362, "action": -1.0209959745407104}
{"mode": "train", "epochs": 5, "timestep": 8303, "ep_reward": 174.34274291992188, "reward": 0.80955970287323, "action": -0.15505552291870117}
{"mode": "train", "epochs": 5, "timestep": 8304, "ep_reward": 175.11865234375, "reward": 0.7759051322937012, "action": -0.7457342147827148}
{"mode": "train", "epochs": 5, "timestep": 8305, "ep_reward": 175.82582092285156, "reward": 0.7071709036827087, "action": -0.8438938856124878}
{"mode": "train", "epochs": 5, "timestep": 8306, "ep_reward": 176.4273681640625, "reward": 0.6015540361404419, "action": -0.37973135709762573}
{"mode": "train", "epochs": 5, "timestep": 8307, "ep_reward": 176.88894653320312, "reward": 0.4615809917449951, "action": -1.032711148262024}
{"mode": "train", "epochs": 5, "timestep": 8308, "ep_reward": 177.22930908203125, "reward": 0.3403676748275757, "action": -1.802391529083252}
{"mode": "train", "epochs": 5, "timestep": 8309, "ep_reward": 177.4579315185547, "reward": 0.22861939668655396, "action": -1.1484060287475586}
{"mode": "train", "epochs": 5, "timestep": 8310, "ep_reward": 177.55471801757812, "reward": 0.09678888320922852, "action": -0.839048445224762}
{"mode": "train", "epochs": 5, "timestep": 8311, "ep_reward": 177.57484436035156, "reward": 0.02012091875076294, "action": -1.0441068410873413}
{"mode": "train", "epochs": 5, "timestep": 8312, "ep_reward": 177.73724365234375, "reward": 0.16239994764328003, "action": -1.1325855255126953}
{"mode": "train", "epochs": 5, "timestep": 8313, "ep_reward": 178.0377960205078, "reward": 0.30055713653564453, "action": -0.9548752903938293}
{"mode": "train", "epochs": 5, "timestep": 8314, "ep_reward": 178.4752655029297, "reward": 0.4374762773513794, "action": -1.5871089696884155}
{"mode": "train", "epochs": 5, "timestep": 8315, "ep_reward": 179.0291290283203, "reward": 0.5538632869720459, "action": -0.9486292600631714}
{"mode": "train", "epochs": 5, "timestep": 8316, "ep_reward": 179.6875457763672, "reward": 0.6584174036979675, "action": -0.5804400444030762}
{"mode": "train", "epochs": 5, "timestep": 8317, "ep_reward": 180.43069458007812, "reward": 0.7431435585021973, "action": -1.0023114681243896}
{"mode": "train", "epochs": 5, "timestep": 8318, "ep_reward": 181.23135375976562, "reward": 0.8006560802459717, "action": -1.457718014717102}
{"mode": "train", "epochs": 5, "timestep": 8319, "ep_reward": 182.06561279296875, "reward": 0.8342516422271729, "action": -0.6083698272705078}
{"mode": "train", "epochs": 5, "timestep": 8320, "ep_reward": 182.9227752685547, "reward": 0.8571667075157166, "action": -0.8477298617362976}
{"mode": "train", "epochs": 5, "timestep": 8321, "ep_reward": 183.78338623046875, "reward": 0.8606176376342773, "action": -1.2041146755218506}
{"mode": "train", "epochs": 5, "timestep": 8322, "ep_reward": 184.6263885498047, "reward": 0.8430014848709106, "action": -0.9997743368148804}
{"mode": "train", "epochs": 5, "timestep": 8323, "ep_reward": 185.43255615234375, "reward": 0.8061693906784058, "action": -0.6380071640014648}
{"mode": "train", "epochs": 5, "timestep": 8324, "ep_reward": 186.179931640625, "reward": 0.747368335723877, "action": -0.6245688199996948}
{"mode": "train", "epochs": 5, "timestep": 8325, "ep_reward": 186.83743286132812, "reward": 0.6575077772140503, "action": -0.49385887384414673}
{"mode": "train", "epochs": 5, "timestep": 8326, "ep_reward": 187.36984252929688, "reward": 0.5324147939682007, "action": -0.8010302782058716}
{"mode": "train", "epochs": 5, "timestep": 8327, "ep_reward": 187.73928833007812, "reward": 0.3694450259208679, "action": -1.856384038925171}
{"mode": "train", "epochs": 5, "timestep": 8328, "ep_reward": 188.0029296875, "reward": 0.26364415884017944, "action": -0.6743069291114807}
{"mode": "train", "epochs": 5, "timestep": 8329, "ep_reward": 188.14036560058594, "reward": 0.13743460178375244, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 8330, "ep_reward": 188.13189697265625, "reward": -0.008461952209472656, "action": -1.5922942161560059}
{"mode": "train", "epochs": 5, "timestep": 8331, "ep_reward": 188.25457763671875, "reward": 0.12268280982971191, "action": -0.7227983474731445}
{"mode": "train", "epochs": 5, "timestep": 8332, "ep_reward": 188.51947021484375, "reward": 0.26488739252090454, "action": -1.6928715705871582}
{"mode": "train", "epochs": 5, "timestep": 8333, "ep_reward": 188.9134979248047, "reward": 0.39403218030929565, "action": -0.3373040556907654}
{"mode": "train", "epochs": 5, "timestep": 8334, "ep_reward": 189.4436798095703, "reward": 0.5301812887191772, "action": -1.1111198663711548}
{"mode": "train", "epochs": 5, "timestep": 8335, "ep_reward": 190.0812225341797, "reward": 0.6375369429588318, "action": -0.5252605676651001}
{"mode": "train", "epochs": 5, "timestep": 8336, "ep_reward": 190.80995178222656, "reward": 0.7287284135818481, "action": -0.6686322689056396}
{"mode": "train", "epochs": 5, "timestep": 8337, "ep_reward": 191.60533142089844, "reward": 0.7953783273696899, "action": -0.9100444316864014}
{"mode": "train", "epochs": 5, "timestep": 8338, "ep_reward": 192.44505310058594, "reward": 0.839723527431488, "action": -0.5393907427787781}
{"mode": "train", "epochs": 5, "timestep": 8339, "ep_reward": 193.31483459472656, "reward": 0.8697752952575684, "action": -0.4350258708000183}
{"mode": "train", "epochs": 5, "timestep": 8340, "ep_reward": 194.20001220703125, "reward": 0.8851802349090576, "action": -0.9657369256019592}
{"mode": "train", "epochs": 5, "timestep": 8341, "ep_reward": 195.0821075439453, "reward": 0.8820902705192566, "action": -1.0972955226898193}
{"mode": "train", "epochs": 5, "timestep": 8342, "ep_reward": 195.94454956054688, "reward": 0.8624425530433655, "action": -1.0862995386123657}
{"mode": "train", "epochs": 5, "timestep": 8343, "ep_reward": 196.76852416992188, "reward": 0.823971152305603, "action": -1.0054656267166138}
{"mode": "train", "epochs": 5, "timestep": 8344, "ep_reward": 197.5306854248047, "reward": 0.7621576189994812, "action": -0.6475538611412048}
{"mode": "train", "epochs": 5, "timestep": 8345, "ep_reward": 198.2046356201172, "reward": 0.6739442348480225, "action": -1.8289048671722412}
{"mode": "train", "epochs": 5, "timestep": 8346, "ep_reward": 198.73780822753906, "reward": 0.5331759452819824, "action": -0.697270929813385}
{"mode": "train", "epochs": 5, "timestep": 8347, "ep_reward": 199.10577392578125, "reward": 0.3679654002189636, "action": -1.5977047681808472}
{"mode": "train", "epochs": 5, "timestep": 8348, "ep_reward": 199.3675079345703, "reward": 0.2617390751838684, "action": -1.1215085983276367}
{"mode": "train", "epochs": 5, "timestep": 8349, "ep_reward": 199.5028839111328, "reward": 0.13537651300430298, "action": -1.4627968072891235}
{"mode": "train", "epochs": 5, "timestep": 8350, "ep_reward": 199.4920196533203, "reward": -0.010870695114135742, "action": -1.0841541290283203}
{"mode": "train", "epochs": 5, "timestep": 8351, "ep_reward": 199.61683654785156, "reward": 0.12481063604354858, "action": -1.3199193477630615}
{"mode": "train", "epochs": 5, "timestep": 8352, "ep_reward": 199.8766632080078, "reward": 0.2598262429237366, "action": -0.37985265254974365}
{"mode": "train", "epochs": 5, "timestep": 8353, "ep_reward": 200.28280639648438, "reward": 0.4061437249183655, "action": -1.3067278861999512}
{"mode": "train", "epochs": 5, "timestep": 8354, "ep_reward": 200.81198120117188, "reward": 0.5291711688041687, "action": -0.8547511100769043}
{"mode": "train", "epochs": 5, "timestep": 8355, "ep_reward": 201.451416015625, "reward": 0.6394421458244324, "action": 0.0631641149520874}
{"mode": "train", "epochs": 5, "timestep": 8356, "ep_reward": 202.18719482421875, "reward": 0.7357779145240784, "action": -1.125055193901062}
{"mode": "train", "epochs": 5, "timestep": 8357, "ep_reward": 202.9844970703125, "reward": 0.7972959280014038, "action": -0.5579118132591248}
{"mode": "train", "epochs": 5, "timestep": 8358, "ep_reward": 203.8288116455078, "reward": 0.8443132638931274, "action": -0.7595512270927429}
{"mode": "train", "epochs": 5, "timestep": 8359, "ep_reward": 204.7012176513672, "reward": 0.8724098801612854, "action": -1.041115403175354}
{"mode": "train", "epochs": 5, "timestep": 8360, "ep_reward": 205.58468627929688, "reward": 0.8834739327430725, "action": -0.7507688403129578}
{"mode": "train", "epochs": 5, "timestep": 8361, "ep_reward": 206.467041015625, "reward": 0.8823547959327698, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 8362, "ep_reward": 207.32228088378906, "reward": 0.855243444442749, "action": -1.4447345733642578}
{"mode": "train", "epochs": 5, "timestep": 8363, "ep_reward": 208.1344451904297, "reward": 0.8121581077575684, "action": -0.9635269641876221}
{"mode": "train", "epochs": 5, "timestep": 8364, "ep_reward": 208.8824005126953, "reward": 0.7479604482650757, "action": 0.08426368236541748}
{"mode": "train", "epochs": 5, "timestep": 8365, "ep_reward": 209.5474853515625, "reward": 0.6650888919830322, "action": -1.7835582494735718}
{"mode": "train", "epochs": 5, "timestep": 8366, "ep_reward": 210.06922912597656, "reward": 0.5217384099960327, "action": -1.4868652820587158}
{"mode": "train", "epochs": 5, "timestep": 8367, "ep_reward": 210.43138122558594, "reward": 0.3621576428413391, "action": -0.8557204604148865}
{"mode": "train", "epochs": 5, "timestep": 8368, "ep_reward": 210.6859588623047, "reward": 0.2545846700668335, "action": -1.1966893672943115}
{"mode": "train", "epochs": 5, "timestep": 8369, "ep_reward": 210.81292724609375, "reward": 0.1269681453704834, "action": -1.6811614036560059}
{"mode": "train", "epochs": 5, "timestep": 8370, "ep_reward": 210.79959106445312, "reward": -0.01333761215209961, "action": -0.4305630326271057}
{"mode": "train", "epochs": 5, "timestep": 8371, "ep_reward": 210.932861328125, "reward": 0.13327640295028687, "action": -0.6737969517707825}
{"mode": "train", "epochs": 5, "timestep": 8372, "ep_reward": 211.2093505859375, "reward": 0.27648454904556274, "action": -0.8476162552833557}
{"mode": "train", "epochs": 5, "timestep": 8373, "ep_reward": 211.62448120117188, "reward": 0.41513073444366455, "action": -1.0249664783477783}
{"mode": "train", "epochs": 5, "timestep": 8374, "ep_reward": 212.16453552246094, "reward": 0.5400599241256714, "action": -1.2640111446380615}
{"mode": "train", "epochs": 5, "timestep": 8375, "ep_reward": 212.80836486816406, "reward": 0.6438248157501221, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 8376, "ep_reward": 213.5276336669922, "reward": 0.7192612886428833, "action": -0.9731124043464661}
{"mode": "train", "epochs": 5, "timestep": 8377, "ep_reward": 214.31138610839844, "reward": 0.7837536931037903, "action": -1.2546186447143555}
{"mode": "train", "epochs": 5, "timestep": 8378, "ep_reward": 215.13616943359375, "reward": 0.8247783184051514, "action": -0.4876939654350281}
{"mode": "train", "epochs": 5, "timestep": 8379, "ep_reward": 215.98983764648438, "reward": 0.8536715507507324, "action": -0.9182518720626831}
{"mode": "train", "epochs": 5, "timestep": 8380, "ep_reward": 216.85101318359375, "reward": 0.8611700534820557, "action": -1.4623849391937256}
{"mode": "train", "epochs": 5, "timestep": 8381, "ep_reward": 217.69735717773438, "reward": 0.8463378548622131, "action": -0.23294419050216675}
{"mode": "train", "epochs": 5, "timestep": 8382, "ep_reward": 218.52011108398438, "reward": 0.8227605819702148, "action": -1.3224433660507202}
{"mode": "train", "epochs": 5, "timestep": 8383, "ep_reward": 219.28482055664062, "reward": 0.7647046446800232, "action": -0.8799006342887878}
{"mode": "train", "epochs": 5, "timestep": 8384, "ep_reward": 219.96517944335938, "reward": 0.6803611516952515, "action": -1.303986668586731}
{"mode": "train", "epochs": 5, "timestep": 8385, "ep_reward": 220.51792907714844, "reward": 0.5527499318122864, "action": -0.9319225549697876}
{"mode": "train", "epochs": 5, "timestep": 8386, "ep_reward": 220.90867614746094, "reward": 0.39075177907943726, "action": -1.2761824131011963}
{"mode": "train", "epochs": 5, "timestep": 8387, "ep_reward": 221.19798278808594, "reward": 0.28931188583374023, "action": -1.10391366481781}
{"mode": "train", "epochs": 5, "timestep": 8388, "ep_reward": 221.3657684326172, "reward": 0.16779214143753052, "action": -1.4443145990371704}
{"mode": "train", "epochs": 5, "timestep": 8389, "ep_reward": 221.39218139648438, "reward": 0.02641439437866211, "action": -0.8225843906402588}
{"mode": "train", "epochs": 5, "timestep": 8390, "ep_reward": 221.48312377929688, "reward": 0.0909387469291687, "action": -0.5993853807449341}
{"mode": "train", "epochs": 5, "timestep": 8391, "ep_reward": 221.7170867919922, "reward": 0.23396331071853638, "action": -0.12030243873596191}
{"mode": "train", "epochs": 5, "timestep": 8392, "ep_reward": 222.1000213623047, "reward": 0.38293343782424927, "action": -0.24349194765090942}
{"mode": "train", "epochs": 5, "timestep": 8393, "ep_reward": 222.61927795410156, "reward": 0.519256591796875, "action": -0.5342512130737305}
{"mode": "train", "epochs": 5, "timestep": 8394, "ep_reward": 223.25311279296875, "reward": 0.6338354349136353, "action": -0.6052650213241577}
{"mode": "train", "epochs": 5, "timestep": 8395, "ep_reward": 223.97926330566406, "reward": 0.7261431217193604, "action": -0.6227749586105347}
{"mode": "train", "epochs": 5, "timestep": 8396, "ep_reward": 224.776123046875, "reward": 0.7968608736991882, "action": -0.2731069326400757}
{"mode": "train", "epochs": 5, "timestep": 8397, "ep_reward": 225.6271514892578, "reward": 0.851032018661499, "action": -0.7824329137802124}
{"mode": "train", "epochs": 5, "timestep": 8398, "ep_reward": 226.5123291015625, "reward": 0.8851739168167114, "action": -0.9932335019111633}
{"mode": "train", "epochs": 5, "timestep": 8399, "ep_reward": 227.41746520996094, "reward": 0.9051404595375061, "action": -1.3288075923919678}
{"mode": "train", "epochs": 5, "timestep": 8400, "ep_reward": 228.3295135498047, "reward": 0.9120512008666992, "action": -0.6902502179145813}
{"mode": "train", "epochs": 5, "timestep": 8401, "ep_reward": 229.24205017089844, "reward": 0.9125440120697021, "action": -1.4752451181411743}
{"mode": "train", "epochs": 5, "timestep": 8402, "ep_reward": 230.13809204101562, "reward": 0.8960481882095337, "action": -0.49455004930496216}
{"mode": "train", "epochs": 5, "timestep": 8403, "ep_reward": 231.01071166992188, "reward": 0.8726129531860352, "action": -1.6706310510635376}
{"mode": "train", "epochs": 5, "timestep": 8404, "ep_reward": 231.83193969726562, "reward": 0.8212342858314514, "action": -1.2008124589920044}
{"mode": "train", "epochs": 5, "timestep": 8405, "ep_reward": 232.58029174804688, "reward": 0.7483524084091187, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 8406, "ep_reward": 233.21334838867188, "reward": 0.633049488067627, "action": -0.6141138076782227}
{"mode": "train", "epochs": 5, "timestep": 8407, "ep_reward": 233.7086944580078, "reward": 0.49534136056900024, "action": -0.966084361076355}
{"mode": "train", "epochs": 5, "timestep": 8408, "ep_reward": 234.03997802734375, "reward": 0.3312845826148987, "action": -1.5883629322052002}
{"mode": "train", "epochs": 5, "timestep": 8409, "ep_reward": 234.25775146484375, "reward": 0.217776358127594, "action": -0.5697820782661438}
{"mode": "train", "epochs": 5, "timestep": 8410, "ep_reward": 234.3418731689453, "reward": 0.08412104845046997, "action": -0.6912184953689575}
{"mode": "train", "epochs": 5, "timestep": 8411, "ep_reward": 234.37550354003906, "reward": 0.03363615274429321, "action": 0.21067094802856445}
{"mode": "train", "epochs": 5, "timestep": 8412, "ep_reward": 234.56040954589844, "reward": 0.18490737676620483, "action": 0.0695798397064209}
{"mode": "train", "epochs": 5, "timestep": 8413, "ep_reward": 234.8959503173828, "reward": 0.3355388045310974, "action": -1.1367168426513672}
{"mode": "train", "epochs": 5, "timestep": 8414, "ep_reward": 235.3606719970703, "reward": 0.4647212624549866, "action": -0.7302365303039551}
{"mode": "train", "epochs": 5, "timestep": 8415, "ep_reward": 235.94610595703125, "reward": 0.5854343175888062, "action": -1.2746676206588745}
{"mode": "train", "epochs": 5, "timestep": 8416, "ep_reward": 236.62701416015625, "reward": 0.6809130311012268, "action": -1.6925959587097168}
{"mode": "train", "epochs": 5, "timestep": 8417, "ep_reward": 237.37950134277344, "reward": 0.7524864673614502, "action": -0.520098090171814}
{"mode": "train", "epochs": 5, "timestep": 8418, "ep_reward": 238.19427490234375, "reward": 0.8147745132446289, "action": -1.773322343826294}
{"mode": "train", "epochs": 5, "timestep": 8419, "ep_reward": 239.04249572753906, "reward": 0.8482201099395752, "action": -0.29754841327667236}
{"mode": "train", "epochs": 5, "timestep": 8420, "ep_reward": 239.92019653320312, "reward": 0.8777081370353699, "action": -1.321520209312439}
{"mode": "train", "epochs": 5, "timestep": 8421, "ep_reward": 240.8046875, "reward": 0.8844921588897705, "action": -1.532673716545105}
{"mode": "train", "epochs": 5, "timestep": 8422, "ep_reward": 241.67991638183594, "reward": 0.8752343058586121, "action": -1.0283231735229492}
{"mode": "train", "epochs": 5, "timestep": 8423, "ep_reward": 242.53350830078125, "reward": 0.8535903096199036, "action": -0.5545973777770996}
{"mode": "train", "epochs": 5, "timestep": 8424, "ep_reward": 243.3500213623047, "reward": 0.816519558429718, "action": -1.5648648738861084}
{"mode": "train", "epochs": 5, "timestep": 8425, "ep_reward": 244.09439086914062, "reward": 0.7443692684173584, "action": -0.6868946552276611}
{"mode": "train", "epochs": 5, "timestep": 8426, "ep_reward": 244.74359130859375, "reward": 0.6491968631744385, "action": -0.6804013252258301}
{"mode": "train", "epochs": 5, "timestep": 8427, "ep_reward": 245.2605438232422, "reward": 0.5169585347175598, "action": -0.7700350284576416}
{"mode": "train", "epochs": 5, "timestep": 8428, "ep_reward": 245.61386108398438, "reward": 0.35332024097442627, "action": -1.8640553951263428}
{"mode": "train", "epochs": 5, "timestep": 8429, "ep_reward": 245.85800170898438, "reward": 0.244140625, "action": -1.3041839599609375}
{"mode": "train", "epochs": 5, "timestep": 8430, "ep_reward": 245.9728546142578, "reward": 0.11485487222671509, "action": -1.2741572856903076}
{"mode": "train", "epochs": 5, "timestep": 8431, "ep_reward": 245.97320556640625, "reward": 0.00034731626510620117, "action": -0.8209320306777954}
{"mode": "train", "epochs": 5, "timestep": 8432, "ep_reward": 246.11839294433594, "reward": 0.14519423246383667, "action": -1.0183825492858887}
{"mode": "train", "epochs": 5, "timestep": 8433, "ep_reward": 246.40280151367188, "reward": 0.28440427780151367, "action": -0.992172122001648}
{"mode": "train", "epochs": 5, "timestep": 8434, "ep_reward": 246.8243408203125, "reward": 0.42153406143188477, "action": -1.544607400894165}
{"mode": "train", "epochs": 5, "timestep": 8435, "ep_reward": 247.3646240234375, "reward": 0.5402868986129761, "action": -1.158299446105957}
{"mode": "train", "epochs": 5, "timestep": 8436, "ep_reward": 248.0098876953125, "reward": 0.6452628374099731, "action": -0.5173859596252441}
{"mode": "train", "epochs": 5, "timestep": 8437, "ep_reward": 248.7438201904297, "reward": 0.7339305877685547, "action": -0.69258713722229}
{"mode": "train", "epochs": 5, "timestep": 8438, "ep_reward": 249.54095458984375, "reward": 0.7971317768096924, "action": -1.6094017028808594}
{"mode": "train", "epochs": 5, "timestep": 8439, "ep_reward": 250.37286376953125, "reward": 0.831902027130127, "action": -0.4904520511627197}
{"mode": "train", "epochs": 5, "timestep": 8440, "ep_reward": 251.23121643066406, "reward": 0.8583580255508423, "action": -1.3714596033096313}
{"mode": "train", "epochs": 5, "timestep": 8441, "ep_reward": 252.09144592285156, "reward": 0.8602234721183777, "action": -0.3845375180244446}
{"mode": "train", "epochs": 5, "timestep": 8442, "ep_reward": 252.94464111328125, "reward": 0.8532027006149292, "action": -0.9266945123672485}
{"mode": "train", "epochs": 5, "timestep": 8443, "ep_reward": 253.76657104492188, "reward": 0.821923553943634, "action": -1.1851160526275635}
{"mode": "train", "epochs": 5, "timestep": 8444, "ep_reward": 254.53033447265625, "reward": 0.7637664079666138, "action": -1.1358293294906616}
{"mode": "train", "epochs": 5, "timestep": 8445, "ep_reward": 255.20513916015625, "reward": 0.6748120784759521, "action": -0.8070361614227295}
{"mode": "train", "epochs": 5, "timestep": 8446, "ep_reward": 255.75718688964844, "reward": 0.5520540475845337, "action": -1.4630532264709473}
{"mode": "train", "epochs": 5, "timestep": 8447, "ep_reward": 256.1435241699219, "reward": 0.3863508701324463, "action": -1.4576741456985474}
{"mode": "train", "epochs": 5, "timestep": 8448, "ep_reward": 256.4275817871094, "reward": 0.28405654430389404, "action": -0.4201255440711975}
{"mode": "train", "epochs": 5, "timestep": 8449, "ep_reward": 256.58905029296875, "reward": 0.16148364543914795, "action": -1.6383180618286133}
{"mode": "train", "epochs": 5, "timestep": 8450, "ep_reward": 256.608154296875, "reward": 0.019091367721557617, "action": -1.5309524536132812}
{"mode": "train", "epochs": 5, "timestep": 8451, "ep_reward": 256.705810546875, "reward": 0.09766697883605957, "action": -0.8798048496246338}
{"mode": "train", "epochs": 5, "timestep": 8452, "ep_reward": 256.9431457519531, "reward": 0.2373461127281189, "action": -1.0349786281585693}
{"mode": "train", "epochs": 5, "timestep": 8453, "ep_reward": 257.3189392089844, "reward": 0.3757890462875366, "action": -0.5578083992004395}
{"mode": "train", "epochs": 5, "timestep": 8454, "ep_reward": 257.8298034667969, "reward": 0.5108703374862671, "action": -1.1458370685577393}
{"mode": "train", "epochs": 5, "timestep": 8455, "ep_reward": 258.450927734375, "reward": 0.6211097836494446, "action": -0.44452357292175293}
{"mode": "train", "epochs": 5, "timestep": 8456, "ep_reward": 259.1679382324219, "reward": 0.7170181274414062, "action": -0.5157506465911865}
{"mode": "train", "epochs": 5, "timestep": 8457, "ep_reward": 259.95660400390625, "reward": 0.7886518239974976, "action": -1.6015422344207764}
{"mode": "train", "epochs": 5, "timestep": 8458, "ep_reward": 260.7872619628906, "reward": 0.8306708931922913, "action": -0.6874820590019226}
{"mode": "train", "epochs": 5, "timestep": 8459, "ep_reward": 261.6504821777344, "reward": 0.8632328510284424, "action": -1.0361820459365845}
{"mode": "train", "epochs": 5, "timestep": 8460, "ep_reward": 262.527587890625, "reward": 0.8771055936813354, "action": -1.4907485246658325}
{"mode": "train", "epochs": 5, "timestep": 8461, "ep_reward": 263.3999328613281, "reward": 0.8723564743995667, "action": -0.878999650478363}
{"mode": "train", "epochs": 5, "timestep": 8462, "ep_reward": 264.2561340332031, "reward": 0.8561971187591553, "action": -0.6658964157104492}
{"mode": "train", "epochs": 5, "timestep": 8463, "ep_reward": 265.0790100097656, "reward": 0.8228623867034912, "action": -0.6958212852478027}
{"mode": "train", "epochs": 5, "timestep": 8464, "ep_reward": 265.8448791503906, "reward": 0.7658557891845703, "action": -0.5682284832000732}
{"mode": "train", "epochs": 5, "timestep": 8465, "ep_reward": 266.5259094238281, "reward": 0.6810168027877808, "action": -0.8220899701118469}
{"mode": "train", "epochs": 5, "timestep": 8466, "ep_reward": 267.0834655761719, "reward": 0.5575594902038574, "action": -1.1628360748291016}
{"mode": "train", "epochs": 5, "timestep": 8467, "ep_reward": 267.47210693359375, "reward": 0.3886318802833557, "action": -1.5701243877410889}
{"mode": "train", "epochs": 5, "timestep": 8468, "ep_reward": 267.74591064453125, "reward": 0.2738063335418701, "action": 0.3295283317565918}
{"mode": "train", "epochs": 5, "timestep": 8469, "ep_reward": 267.8954162597656, "reward": 0.14949333667755127, "action": -1.2415435314178467}
{"mode": "train", "epochs": 5, "timestep": 8470, "ep_reward": 267.9007873535156, "reward": 0.005355954170227051, "action": -0.41684824228286743}
{"mode": "train", "epochs": 5, "timestep": 8471, "ep_reward": 268.010986328125, "reward": 0.11020737886428833, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 8472, "ep_reward": 268.25128173828125, "reward": 0.24028366804122925, "action": -1.3056237697601318}
{"mode": "train", "epochs": 5, "timestep": 8473, "ep_reward": 268.6282043457031, "reward": 0.37690985202789307, "action": -0.9022670984268188}
{"mode": "train", "epochs": 5, "timestep": 8474, "ep_reward": 269.1373596191406, "reward": 0.5091413259506226, "action": -1.0540269613265991}
{"mode": "train", "epochs": 5, "timestep": 8475, "ep_reward": 269.75811767578125, "reward": 0.6207629442214966, "action": -1.2213187217712402}
{"mode": "train", "epochs": 5, "timestep": 8476, "ep_reward": 270.466064453125, "reward": 0.7079553604125977, "action": -0.41467171907424927}
{"mode": "train", "epochs": 5, "timestep": 8477, "ep_reward": 271.24578857421875, "reward": 0.7797353863716125, "action": -0.7686357498168945}
{"mode": "train", "epochs": 5, "timestep": 8478, "ep_reward": 272.0714416503906, "reward": 0.8256475925445557, "action": -1.3515039682388306}
{"mode": "train", "epochs": 5, "timestep": 8479, "ep_reward": 272.9187927246094, "reward": 0.8473377823829651, "action": -0.6089942455291748}
{"mode": "train", "epochs": 5, "timestep": 8480, "ep_reward": 273.77642822265625, "reward": 0.8576306104660034, "action": -1.607143759727478}
{"mode": "train", "epochs": 5, "timestep": 8481, "ep_reward": 274.61737060546875, "reward": 0.8409454226493835, "action": -0.6272822618484497}
{"mode": "train", "epochs": 5, "timestep": 8482, "ep_reward": 275.4297180175781, "reward": 0.8123544454574585, "action": -0.837363600730896}
{"mode": "train", "epochs": 5, "timestep": 8483, "ep_reward": 276.1866149902344, "reward": 0.7568863034248352, "action": -0.240145742893219}
{"mode": "train", "epochs": 5, "timestep": 8484, "ep_reward": 276.8645324707031, "reward": 0.6779067516326904, "action": -0.9794408679008484}
{"mode": "train", "epochs": 5, "timestep": 8485, "ep_reward": 277.4180603027344, "reward": 0.5535142421722412, "action": -1.1383705139160156}
{"mode": "train", "epochs": 5, "timestep": 8486, "ep_reward": 277.8049011230469, "reward": 0.3868519067764282, "action": -1.5326181650161743}
{"mode": "train", "epochs": 5, "timestep": 8487, "ep_reward": 278.0895690917969, "reward": 0.28465890884399414, "action": -0.7740583419799805}
{"mode": "train", "epochs": 5, "timestep": 8488, "ep_reward": 278.251953125, "reward": 0.1623915433883667, "action": -0.21877163648605347}
{"mode": "train", "epochs": 5, "timestep": 8489, "ep_reward": 278.27191162109375, "reward": 0.019962072372436523, "action": -1.4492223262786865}
{"mode": "train", "epochs": 5, "timestep": 8490, "ep_reward": 278.3687744140625, "reward": 0.09686398506164551, "action": -0.9399400353431702}
{"mode": "train", "epochs": 5, "timestep": 8491, "ep_reward": 278.6044921875, "reward": 0.23570740222930908, "action": -1.4536765813827515}
{"mode": "train", "epochs": 5, "timestep": 8492, "ep_reward": 278.9736633300781, "reward": 0.36917150020599365, "action": -1.0441820621490479}
{"mode": "train", "epochs": 5, "timestep": 8493, "ep_reward": 279.4735412597656, "reward": 0.49986404180526733, "action": -1.3486900329589844}
{"mode": "train", "epochs": 5, "timestep": 8494, "ep_reward": 280.0833435058594, "reward": 0.609803318977356, "action": -1.2735040187835693}
{"mode": "train", "epochs": 5, "timestep": 8495, "ep_reward": 280.782470703125, "reward": 0.6991268396377563, "action": -0.801496148109436}
{"mode": "train", "epochs": 5, "timestep": 8496, "ep_reward": 281.5526123046875, "reward": 0.7701360583305359, "action": -0.5585620999336243}
{"mode": "train", "epochs": 5, "timestep": 8497, "ep_reward": 282.3736572265625, "reward": 0.8210498690605164, "action": -0.40276116132736206}
{"mode": "train", "epochs": 5, "timestep": 8498, "ep_reward": 283.22698974609375, "reward": 0.853334903717041, "action": -1.2112782001495361}
{"mode": "train", "epochs": 5, "timestep": 8499, "ep_reward": 284.0882263183594, "reward": 0.8612373471260071, "action": 0.10793745517730713}
{"mode": "train", "epochs": 5, "timestep": 8500, "ep_reward": 284.9517517089844, "reward": 0.8635162115097046, "action": -1.2325358390808105}
{"mode": "train", "epochs": 5, "timestep": 8501, "ep_reward": 285.787841796875, "reward": 0.8360859155654907, "action": -0.6510916948318481}
{"mode": "train", "epochs": 5, "timestep": 8502, "ep_reward": 286.5797424316406, "reward": 0.7918946743011475, "action": -1.8225812911987305}
{"mode": "train", "epochs": 5, "timestep": 8503, "ep_reward": 287.2867126464844, "reward": 0.7069761753082275, "action": -0.54962158203125}
{"mode": "train", "epochs": 5, "timestep": 8504, "ep_reward": 287.887451171875, "reward": 0.600750207901001, "action": -0.5072640180587769}
{"mode": "train", "epochs": 5, "timestep": 8505, "ep_reward": 288.3436584472656, "reward": 0.4562152028083801, "action": -0.946281373500824}
{"mode": "train", "epochs": 5, "timestep": 8506, "ep_reward": 288.6661682128906, "reward": 0.3225036859512329, "action": -1.456463098526001}
{"mode": "train", "epochs": 5, "timestep": 8507, "ep_reward": 288.87335205078125, "reward": 0.207197368144989, "action": -1.327277660369873}
{"mode": "train", "epochs": 5, "timestep": 8508, "ep_reward": 288.9451904296875, "reward": 0.07184994220733643, "action": -1.438662052154541}
{"mode": "train", "epochs": 5, "timestep": 8509, "ep_reward": 288.9913024902344, "reward": 0.04610627889633179, "action": -1.4864563941955566}
{"mode": "train", "epochs": 5, "timestep": 8510, "ep_reward": 289.17633056640625, "reward": 0.1850413680076599, "action": -0.6989032030105591}
{"mode": "train", "epochs": 5, "timestep": 8511, "ep_reward": 289.5052490234375, "reward": 0.3289296627044678, "action": -0.8324805498123169}
{"mode": "train", "epochs": 5, "timestep": 8512, "ep_reward": 289.9701843261719, "reward": 0.4649430513381958, "action": -0.2799389362335205}
{"mode": "train", "epochs": 5, "timestep": 8513, "ep_reward": 290.5618591308594, "reward": 0.5916703343391418, "action": -1.0359094142913818}
{"mode": "train", "epochs": 5, "timestep": 8514, "ep_reward": 291.2501525878906, "reward": 0.6882964372634888, "action": -0.4518619775772095}
{"mode": "train", "epochs": 5, "timestep": 8515, "ep_reward": 292.01849365234375, "reward": 0.7683413028717041, "action": -1.3856878280639648}
{"mode": "train", "epochs": 5, "timestep": 8516, "ep_reward": 292.8375244140625, "reward": 0.8190233111381531, "action": -0.21233850717544556}
{"mode": "train", "epochs": 5, "timestep": 8517, "ep_reward": 293.6990661621094, "reward": 0.8615312576293945, "action": -1.1047004461288452}
{"mode": "train", "epochs": 5, "timestep": 8518, "ep_reward": 294.580078125, "reward": 0.8810020685195923, "action": -0.03799372911453247}
{"mode": "train", "epochs": 5, "timestep": 8519, "ep_reward": 295.4747314453125, "reward": 0.8946425914764404, "action": -1.210507869720459}
{"mode": "train", "epochs": 5, "timestep": 8520, "ep_reward": 296.36065673828125, "reward": 0.8859198689460754, "action": -0.6329604983329773}
{"mode": "train", "epochs": 5, "timestep": 8521, "ep_reward": 297.2273864746094, "reward": 0.8667332530021667, "action": -1.0643224716186523}
{"mode": "train", "epochs": 5, "timestep": 8522, "ep_reward": 298.0530700683594, "reward": 0.8256956934928894, "action": -0.7013459205627441}
{"mode": "train", "epochs": 5, "timestep": 8523, "ep_reward": 298.8175048828125, "reward": 0.7644402980804443, "action": -1.6445906162261963}
{"mode": "train", "epochs": 5, "timestep": 8524, "ep_reward": 299.4796142578125, "reward": 0.6621211767196655, "action": -1.2718034982681274}
{"mode": "train", "epochs": 5, "timestep": 8525, "ep_reward": 300.0044860839844, "reward": 0.5248608589172363, "action": -0.787024974822998}
{"mode": "train", "epochs": 5, "timestep": 8526, "ep_reward": 300.3617248535156, "reward": 0.3572452664375305, "action": -1.2873339653015137}
{"mode": "train", "epochs": 5, "timestep": 8527, "ep_reward": 300.6104736328125, "reward": 0.24875646829605103, "action": -1.0950149297714233}
{"mode": "train", "epochs": 5, "timestep": 8528, "ep_reward": 300.7305603027344, "reward": 0.12007582187652588, "action": -1.9544174671173096}
{"mode": "train", "epochs": 5, "timestep": 8529, "ep_reward": 300.72491455078125, "reward": -0.005657076835632324, "action": -0.9349832534790039}
{"mode": "train", "epochs": 5, "timestep": 8530, "ep_reward": 300.8648986816406, "reward": 0.1399974822998047, "action": -0.7889988422393799}
{"mode": "train", "epochs": 5, "timestep": 8531, "ep_reward": 301.1468505859375, "reward": 0.28195977210998535, "action": -0.6417362689971924}
{"mode": "train", "epochs": 5, "timestep": 8532, "ep_reward": 301.5697937011719, "reward": 0.42294108867645264, "action": -1.5551605224609375}
{"mode": "train", "epochs": 5, "timestep": 8533, "ep_reward": 302.11065673828125, "reward": 0.5408766269683838, "action": -1.5622868537902832}
{"mode": "train", "epochs": 5, "timestep": 8534, "ep_reward": 302.752197265625, "reward": 0.6415257453918457, "action": -0.8758052587509155}
{"mode": "train", "epochs": 5, "timestep": 8535, "ep_reward": 303.48004150390625, "reward": 0.7278355360031128, "action": -0.8066816926002502}
{"mode": "train", "epochs": 5, "timestep": 8536, "ep_reward": 304.2718200683594, "reward": 0.7917882800102234, "action": -1.3255856037139893}
{"mode": "train", "epochs": 5, "timestep": 8537, "ep_reward": 305.1021423339844, "reward": 0.8303180932998657, "action": -1.931164026260376}
{"mode": "train", "epochs": 5, "timestep": 8538, "ep_reward": 305.94775390625, "reward": 0.8456003665924072, "action": -1.1512888669967651}
{"mode": "train", "epochs": 5, "timestep": 8539, "ep_reward": 306.79754638671875, "reward": 0.8497862219810486, "action": -1.465266227722168}
{"mode": "train", "epochs": 5, "timestep": 8540, "ep_reward": 307.6294860839844, "reward": 0.8319272994995117, "action": -0.8496338129043579}
{"mode": "train", "epochs": 5, "timestep": 8541, "ep_reward": 308.4268798828125, "reward": 0.7973824143409729, "action": -1.911547064781189}
{"mode": "train", "epochs": 5, "timestep": 8542, "ep_reward": 309.1502380371094, "reward": 0.7233554124832153, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 8543, "ep_reward": 309.7601013183594, "reward": 0.609849214553833, "action": -0.7394149303436279}
{"mode": "train", "epochs": 5, "timestep": 8544, "ep_reward": 310.2290344238281, "reward": 0.4689209461212158, "action": -1.120445728302002}
{"mode": "train", "epochs": 5, "timestep": 8545, "ep_reward": 310.5863342285156, "reward": 0.35728710889816284, "action": -0.6614112257957458}
{"mode": "train", "epochs": 5, "timestep": 8546, "ep_reward": 310.8350830078125, "reward": 0.24873435497283936, "action": -0.9439509510993958}
{"mode": "train", "epochs": 5, "timestep": 8547, "ep_reward": 310.95526123046875, "reward": 0.12016910314559937, "action": -1.2463972568511963}
{"mode": "train", "epochs": 5, "timestep": 8548, "ep_reward": 310.9495849609375, "reward": -0.005687117576599121, "action": -1.4916168451309204}
{"mode": "train", "epochs": 5, "timestep": 8549, "ep_reward": 311.0896301269531, "reward": 0.14004653692245483, "action": -0.7719376683235168}
{"mode": "train", "epochs": 5, "timestep": 8550, "ep_reward": 311.3717956542969, "reward": 0.2821803092956543, "action": -1.053005576133728}
{"mode": "train", "epochs": 5, "timestep": 8551, "ep_reward": 311.7899169921875, "reward": 0.4181171655654907, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 8552, "ep_reward": 312.3219299316406, "reward": 0.5320050716400146, "action": -0.459868848323822}
{"mode": "train", "epochs": 5, "timestep": 8553, "ep_reward": 312.9677734375, "reward": 0.6458352208137512, "action": -1.4327974319458008}
{"mode": "train", "epochs": 5, "timestep": 8554, "ep_reward": 313.6935729980469, "reward": 0.7257968187332153, "action": -0.6720656156539917}
{"mode": "train", "epochs": 5, "timestep": 8555, "ep_reward": 314.484619140625, "reward": 0.7910332679748535, "action": -0.16273730993270874}
{"mode": "train", "epochs": 5, "timestep": 8556, "ep_reward": 315.3240051269531, "reward": 0.8393814563751221, "action": 0.17572975158691406}
{"mode": "train", "epochs": 5, "timestep": 8557, "ep_reward": 316.19561767578125, "reward": 0.8716074824333191, "action": -0.8115690350532532}
{"mode": "train", "epochs": 5, "timestep": 8558, "ep_reward": 317.0754699707031, "reward": 0.8798656463623047, "action": -0.5691696405410767}
{"mode": "train", "epochs": 5, "timestep": 8559, "ep_reward": 317.9503479003906, "reward": 0.8748798370361328, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 8560, "ep_reward": 318.791015625, "reward": 0.8406713008880615, "action": -1.727964162826538}
{"mode": "train", "epochs": 5, "timestep": 8561, "ep_reward": 319.57647705078125, "reward": 0.7854711413383484, "action": -0.786896824836731}
{"mode": "train", "epochs": 5, "timestep": 8562, "ep_reward": 320.287353515625, "reward": 0.710870623588562, "action": -0.9865008592605591}
{"mode": "train", "epochs": 5, "timestep": 8563, "ep_reward": 320.8863830566406, "reward": 0.5990402698516846, "action": -0.5511611700057983}
{"mode": "train", "epochs": 5, "timestep": 8564, "ep_reward": 321.3393859863281, "reward": 0.4529898166656494, "action": -1.9639533758163452}
{"mode": "train", "epochs": 5, "timestep": 8565, "ep_reward": 321.6595458984375, "reward": 0.3201543092727661, "action": -1.1031465530395508}
{"mode": "train", "epochs": 5, "timestep": 8566, "ep_reward": 321.8637390136719, "reward": 0.20420676469802856, "action": -1.9558773040771484}
{"mode": "train", "epochs": 5, "timestep": 8567, "ep_reward": 321.93231201171875, "reward": 0.06858354806900024, "action": -1.119215965270996}
{"mode": "train", "epochs": 5, "timestep": 8568, "ep_reward": 321.9819030761719, "reward": 0.049584388732910156, "action": -0.8658007979393005}
{"mode": "train", "epochs": 5, "timestep": 8569, "ep_reward": 322.16986083984375, "reward": 0.1879425048828125, "action": -1.030489444732666}
{"mode": "train", "epochs": 5, "timestep": 8570, "ep_reward": 322.4976806640625, "reward": 0.3278173804283142, "action": -0.3007686138153076}
{"mode": "train", "epochs": 5, "timestep": 8571, "ep_reward": 322.96832275390625, "reward": 0.4706352949142456, "action": -1.2420521974563599}
{"mode": "train", "epochs": 5, "timestep": 8572, "ep_reward": 323.5543518066406, "reward": 0.5860269069671631, "action": -0.5344077348709106}
{"mode": "train", "epochs": 5, "timestep": 8573, "ep_reward": 324.2429504394531, "reward": 0.6886130571365356, "action": -0.483558714389801}
{"mode": "train", "epochs": 5, "timestep": 8574, "ep_reward": 325.0109558105469, "reward": 0.7680028676986694, "action": -1.1260401010513306}
{"mode": "train", "epochs": 5, "timestep": 8575, "ep_reward": 325.8311767578125, "reward": 0.8202230930328369, "action": -0.27983933687210083}
{"mode": "train", "epochs": 5, "timestep": 8576, "ep_reward": 326.6924133300781, "reward": 0.8612341284751892, "action": -0.7609648704528809}
{"mode": "train", "epochs": 5, "timestep": 8577, "ep_reward": 327.5746154785156, "reward": 0.882191002368927, "action": -1.1073113679885864}
{"mode": "train", "epochs": 5, "timestep": 8578, "ep_reward": 328.4610595703125, "reward": 0.8864551782608032, "action": -0.16211163997650146}
{"mode": "train", "epochs": 5, "timestep": 8579, "ep_reward": 329.3451232910156, "reward": 0.884077250957489, "action": -0.5507518649101257}
{"mode": "train", "epochs": 5, "timestep": 8580, "ep_reward": 330.2086486816406, "reward": 0.8635112643241882, "action": -1.084702491760254}
{"mode": "train", "epochs": 5, "timestep": 8581, "ep_reward": 331.0284118652344, "reward": 0.8197667002677917, "action": -0.29904866218566895}
{"mode": "train", "epochs": 5, "timestep": 8582, "ep_reward": 331.7882995605469, "reward": 0.7598746418952942, "action": -0.8957366347312927}
{"mode": "train", "epochs": 5, "timestep": 8583, "ep_reward": 332.4526062011719, "reward": 0.6642944812774658, "action": -0.9586703181266785}
{"mode": "train", "epochs": 5, "timestep": 8584, "ep_reward": 332.98394775390625, "reward": 0.5313268899917603, "action": -1.2298719882965088}
{"mode": "train", "epochs": 5, "timestep": 8585, "ep_reward": 333.33831787109375, "reward": 0.35435688495635986, "action": 0.012832283973693848}
{"mode": "train", "epochs": 5, "timestep": 8586, "ep_reward": 333.5807189941406, "reward": 0.24241530895233154, "action": -1.2155219316482544}
{"mode": "train", "epochs": 5, "timestep": 8587, "ep_reward": 333.693603515625, "reward": 0.11289602518081665, "action": -0.7193362712860107}
{"mode": "train", "epochs": 5, "timestep": 8588, "ep_reward": 333.6960754394531, "reward": 0.0024819374084472656, "action": -1.5739718675613403}
{"mode": "train", "epochs": 5, "timestep": 8589, "ep_reward": 333.8432922363281, "reward": 0.1472044587135315, "action": -0.37471723556518555}
{"mode": "train", "epochs": 5, "timestep": 8590, "ep_reward": 334.1377258300781, "reward": 0.2944207191467285, "action": -0.8136227130889893}
{"mode": "train", "epochs": 5, "timestep": 8591, "ep_reward": 334.5697326660156, "reward": 0.43199849128723145, "action": -1.0515919923782349}
{"mode": "train", "epochs": 5, "timestep": 8592, "ep_reward": 335.1240539550781, "reward": 0.554322361946106, "action": -1.1123923063278198}
{"mode": "train", "epochs": 5, "timestep": 8593, "ep_reward": 335.78125, "reward": 0.6571985483169556, "action": -1.478635549545288}
{"mode": "train", "epochs": 5, "timestep": 8594, "ep_reward": 336.51617431640625, "reward": 0.7349103689193726, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 8595, "ep_reward": 337.30352783203125, "reward": 0.787339448928833, "action": -1.5096921920776367}
{"mode": "train", "epochs": 5, "timestep": 8596, "ep_reward": 338.12872314453125, "reward": 0.8251891732215881, "action": -1.0244680643081665}
{"mode": "train", "epochs": 5, "timestep": 8597, "ep_reward": 338.9773864746094, "reward": 0.8486618995666504, "action": -1.751882553100586}
{"mode": "train", "epochs": 5, "timestep": 8598, "ep_reward": 339.82525634765625, "reward": 0.8478659391403198, "action": -0.7951449751853943}
{"mode": "train", "epochs": 5, "timestep": 8599, "ep_reward": 340.66162109375, "reward": 0.836353063583374, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 8600, "ep_reward": 341.4525451660156, "reward": 0.790935754776001, "action": -0.45897376537323}
{"mode": "train", "epochs": 5, "timestep": 8601, "ep_reward": 342.1860046386719, "reward": 0.7334468960762024, "action": -0.4014627933502197}
{"mode": "train", "epochs": 5, "timestep": 8602, "ep_reward": 342.8302917480469, "reward": 0.6443018913269043, "action": -1.457449197769165}
{"mode": "train", "epochs": 5, "timestep": 8603, "ep_reward": 343.331787109375, "reward": 0.5014930963516235, "action": -1.5681729316711426}
{"mode": "train", "epochs": 5, "timestep": 8604, "ep_reward": 343.6983337402344, "reward": 0.36653804779052734, "action": -1.8120489120483398}
{"mode": "train", "epochs": 5, "timestep": 8605, "ep_reward": 343.9583740234375, "reward": 0.2600513696670532, "action": -1.2672576904296875}
{"mode": "train", "epochs": 5, "timestep": 8606, "ep_reward": 344.09185791015625, "reward": 0.13347816467285156, "action": -1.149681568145752}
{"mode": "train", "epochs": 5, "timestep": 8607, "ep_reward": 344.0787658691406, "reward": -0.013099074363708496, "action": -1.0545592308044434}
{"mode": "train", "epochs": 5, "timestep": 8608, "ep_reward": 344.20562744140625, "reward": 0.1268754005432129, "action": -0.32078665494918823}
{"mode": "train", "epochs": 5, "timestep": 8609, "ep_reward": 344.4799499511719, "reward": 0.274310827255249, "action": -0.4146742820739746}
{"mode": "train", "epochs": 5, "timestep": 8610, "ep_reward": 344.8974609375, "reward": 0.4174969792366028, "action": -0.4511517286300659}
{"mode": "train", "epochs": 5, "timestep": 8611, "ep_reward": 345.4451904296875, "reward": 0.5477278828620911, "action": 0.2763702869415283}
{"mode": "train", "epochs": 5, "timestep": 8612, "ep_reward": 346.11077880859375, "reward": 0.6655775308609009, "action": -0.33783167600631714}
{"mode": "train", "epochs": 5, "timestep": 8613, "ep_reward": 346.8641357421875, "reward": 0.7533611059188843, "action": -1.0677787065505981}
{"mode": "train", "epochs": 5, "timestep": 8614, "ep_reward": 347.6783142089844, "reward": 0.8141714930534363, "action": -0.8606922030448914}
{"mode": "train", "epochs": 5, "timestep": 8615, "ep_reward": 348.53778076171875, "reward": 0.8594643473625183, "action": -1.3610399961471558}
{"mode": "train", "epochs": 5, "timestep": 8616, "ep_reward": 349.4245300292969, "reward": 0.8867602348327637, "action": -0.9770875573158264}
{"mode": "train", "epochs": 5, "timestep": 8617, "ep_reward": 350.32904052734375, "reward": 0.9045100212097168, "action": -1.598436951637268}
{"mode": "train", "epochs": 5, "timestep": 8618, "ep_reward": 351.23590087890625, "reward": 0.9068629145622253, "action": -1.4134907722473145}
{"mode": "train", "epochs": 5, "timestep": 8619, "ep_reward": 352.1346740722656, "reward": 0.8987799286842346, "action": -1.4305411577224731}
{"mode": "train", "epochs": 5, "timestep": 8620, "ep_reward": 353.011474609375, "reward": 0.8768115639686584, "action": -0.5659745931625366}
{"mode": "train", "epochs": 5, "timestep": 8621, "ep_reward": 353.8563232421875, "reward": 0.8448372483253479, "action": -1.7642278671264648}
{"mode": "train", "epochs": 5, "timestep": 8622, "ep_reward": 354.63641357421875, "reward": 0.7800784707069397, "action": -0.4848247170448303}
{"mode": "train", "epochs": 5, "timestep": 8623, "ep_reward": 355.33563232421875, "reward": 0.6992133259773254, "action": -1.5248134136199951}
{"mode": "train", "epochs": 5, "timestep": 8624, "ep_reward": 355.9065856933594, "reward": 0.5709519982337952, "action": -1.1044377088546753}
{"mode": "train", "epochs": 5, "timestep": 8625, "ep_reward": 356.3132019042969, "reward": 0.40661197900772095, "action": -1.8315752744674683}
{"mode": "train", "epochs": 5, "timestep": 8626, "ep_reward": 356.59320068359375, "reward": 0.2799991965293884, "action": -0.992365300655365}
{"mode": "train", "epochs": 5, "timestep": 8627, "ep_reward": 356.75006103515625, "reward": 0.15684646368026733, "action": -1.2004656791687012}
{"mode": "train", "epochs": 5, "timestep": 8628, "ep_reward": 356.7637939453125, "reward": 0.013736963272094727, "action": -1.1015247106552124}
{"mode": "train", "epochs": 5, "timestep": 8629, "ep_reward": 356.8664855957031, "reward": 0.10270482301712036, "action": -0.7097522020339966}
{"mode": "train", "epochs": 5, "timestep": 8630, "ep_reward": 357.11114501953125, "reward": 0.24466294050216675, "action": -0.8137107491493225}
{"mode": "train", "epochs": 5, "timestep": 8631, "ep_reward": 357.49627685546875, "reward": 0.3851439952850342, "action": -0.7190959453582764}
{"mode": "train", "epochs": 5, "timestep": 8632, "ep_reward": 358.01324462890625, "reward": 0.5169684886932373, "action": 0.3851780891418457}
{"mode": "train", "epochs": 5, "timestep": 8633, "ep_reward": 358.6552734375, "reward": 0.6420434713363647, "action": -0.41020727157592773}
{"mode": "train", "epochs": 5, "timestep": 8634, "ep_reward": 359.38946533203125, "reward": 0.7341834902763367, "action": -1.1876239776611328}
{"mode": "train", "epochs": 5, "timestep": 8635, "ep_reward": 360.1871643066406, "reward": 0.7976934909820557, "action": -1.4541385173797607}
{"mode": "train", "epochs": 5, "timestep": 8636, "ep_reward": 361.0282897949219, "reward": 0.8411120176315308, "action": -1.036122441291809}
{"mode": "train", "epochs": 5, "timestep": 8637, "ep_reward": 361.9002685546875, "reward": 0.8719872236251831, "action": -1.7651233673095703}
{"mode": "train", "epochs": 5, "timestep": 8638, "ep_reward": 362.7834777832031, "reward": 0.8832111954689026, "action": -1.6331205368041992}
{"mode": "train", "epochs": 5, "timestep": 8639, "ep_reward": 363.665283203125, "reward": 0.8818116188049316, "action": -0.3617980480194092}
{"mode": "train", "epochs": 5, "timestep": 8640, "ep_reward": 364.54107666015625, "reward": 0.8757847547531128, "action": -0.16821640729904175}
{"mode": "train", "epochs": 5, "timestep": 8641, "ep_reward": 365.3965148925781, "reward": 0.8554487824440002, "action": -0.9767321944236755}
{"mode": "train", "epochs": 5, "timestep": 8642, "ep_reward": 366.2051086425781, "reward": 0.8086066246032715, "action": -1.1971698999404907}
{"mode": "train", "epochs": 5, "timestep": 8643, "ep_reward": 366.93841552734375, "reward": 0.7333204746246338, "action": -1.7552406787872314}
{"mode": "train", "epochs": 5, "timestep": 8644, "ep_reward": 367.55535888671875, "reward": 0.6169503927230835, "action": -0.5538830757141113}
{"mode": "train", "epochs": 5, "timestep": 8645, "ep_reward": 368.0310363769531, "reward": 0.4756709933280945, "action": -1.7980202436447144}
{"mode": "train", "epochs": 5, "timestep": 8646, "ep_reward": 368.3572692871094, "reward": 0.3262273669242859, "action": -1.1373792886734009}
{"mode": "train", "epochs": 5, "timestep": 8647, "ep_reward": 368.5688781738281, "reward": 0.21159732341766357, "action": -1.143088936805725}
{"mode": "train", "epochs": 5, "timestep": 8648, "ep_reward": 368.6459045410156, "reward": 0.07702583074569702, "action": -0.625715434551239}
{"mode": "train", "epochs": 5, "timestep": 8649, "ep_reward": 368.6867370605469, "reward": 0.04082125425338745, "action": -1.811945915222168}
{"mode": "train", "epochs": 5, "timestep": 8650, "ep_reward": 368.86724853515625, "reward": 0.18051928281784058, "action": -0.7402888536453247}
{"mode": "train", "epochs": 5, "timestep": 8651, "ep_reward": 369.1910400390625, "reward": 0.32378941774368286, "action": -1.218369483947754}
{"mode": "train", "epochs": 5, "timestep": 8652, "ep_reward": 369.64666748046875, "reward": 0.45563745498657227, "action": -0.684149444103241}
{"mode": "train", "epochs": 5, "timestep": 8653, "ep_reward": 370.2262268066406, "reward": 0.579569935798645, "action": -1.1592695713043213}
{"mode": "train", "epochs": 5, "timestep": 8654, "ep_reward": 370.90313720703125, "reward": 0.676906406879425, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 8655, "ep_reward": 371.6473388671875, "reward": 0.7441988587379456, "action": -1.4733290672302246}
{"mode": "train", "epochs": 5, "timestep": 8656, "ep_reward": 372.44342041015625, "reward": 0.796087384223938, "action": -1.145566463470459}
{"mode": "train", "epochs": 5, "timestep": 8657, "ep_reward": 373.27435302734375, "reward": 0.8309308886528015, "action": -0.33987897634506226}
{"mode": "train", "epochs": 5, "timestep": 8658, "ep_reward": 374.1282043457031, "reward": 0.8538516163825989, "action": -1.4093002080917358}
{"mode": "train", "epochs": 5, "timestep": 8659, "ep_reward": 374.9773254394531, "reward": 0.849107027053833, "action": -1.6883668899536133}
{"mode": "train", "epochs": 5, "timestep": 8660, "ep_reward": 375.7991943359375, "reward": 0.8218560218811035, "action": -0.9249686002731323}
{"mode": "train", "epochs": 5, "timestep": 8661, "ep_reward": 376.5769958496094, "reward": 0.7777886390686035, "action": -1.284464716911316}
{"mode": "train", "epochs": 5, "timestep": 8662, "ep_reward": 377.27679443359375, "reward": 0.6997911334037781, "action": -1.985865592956543}
{"mode": "train", "epochs": 5, "timestep": 8663, "ep_reward": 377.8505859375, "reward": 0.5737859010696411, "action": -1.7856566905975342}
{"mode": "train", "epochs": 5, "timestep": 8664, "ep_reward": 378.2696228027344, "reward": 0.4190373420715332, "action": -1.2892954349517822}
{"mode": "train", "epochs": 5, "timestep": 8665, "ep_reward": 378.5936584472656, "reward": 0.32403749227523804, "action": -0.8975667357444763}
{"mode": "train", "epochs": 5, "timestep": 8666, "ep_reward": 378.802490234375, "reward": 0.20883607864379883, "action": -1.7843942642211914}
{"mode": "train", "epochs": 5, "timestep": 8667, "ep_reward": 378.87640380859375, "reward": 0.073921799659729, "action": -0.989172101020813}
{"mode": "train", "epochs": 5, "timestep": 8668, "ep_reward": 378.9205322265625, "reward": 0.04414069652557373, "action": -0.8753777742385864}
{"mode": "train", "epochs": 5, "timestep": 8669, "ep_reward": 379.1037292480469, "reward": 0.18320608139038086, "action": -1.1733615398406982}
{"mode": "train", "epochs": 5, "timestep": 8670, "ep_reward": 379.4249572753906, "reward": 0.3212188482284546, "action": -0.8102773427963257}
{"mode": "train", "epochs": 5, "timestep": 8671, "ep_reward": 379.8837585449219, "reward": 0.45880192518234253, "action": -0.6046006083488464}
{"mode": "train", "epochs": 5, "timestep": 8672, "ep_reward": 380.4670104980469, "reward": 0.583267092704773, "action": -0.3980465531349182}
{"mode": "train", "epochs": 5, "timestep": 8673, "ep_reward": 381.15478515625, "reward": 0.6877673864364624, "action": -0.723980188369751}
{"mode": "train", "epochs": 5, "timestep": 8674, "ep_reward": 381.92010498046875, "reward": 0.7653160095214844, "action": -0.7552512884140015}
{"mode": "train", "epochs": 5, "timestep": 8675, "ep_reward": 382.7413635253906, "reward": 0.8212471604347229, "action": -0.661456823348999}
{"mode": "train", "epochs": 5, "timestep": 8676, "ep_reward": 383.6007995605469, "reward": 0.8594216108322144, "action": -0.3697168827056885}
{"mode": "train", "epochs": 5, "timestep": 8677, "ep_reward": 384.4844970703125, "reward": 0.8837043642997742, "action": -1.7267231941223145}
{"mode": "train", "epochs": 5, "timestep": 8678, "ep_reward": 385.3680114746094, "reward": 0.883520781993866, "action": -0.79175865650177}
{"mode": "train", "epochs": 5, "timestep": 8679, "ep_reward": 386.2441101074219, "reward": 0.8760957717895508, "action": -0.850807785987854}
{"mode": "train", "epochs": 5, "timestep": 8680, "ep_reward": 387.09588623046875, "reward": 0.8517909049987793, "action": -1.1115169525146484}
{"mode": "train", "epochs": 5, "timestep": 8681, "ep_reward": 387.90069580078125, "reward": 0.8047952055931091, "action": -0.8796286582946777}
{"mode": "train", "epochs": 5, "timestep": 8682, "ep_reward": 388.634521484375, "reward": 0.7338117957115173, "action": -1.0393215417861938}
{"mode": "train", "epochs": 5, "timestep": 8683, "ep_reward": 389.2626037597656, "reward": 0.6280762553215027, "action": -0.6175740957260132}
{"mode": "train", "epochs": 5, "timestep": 8684, "ep_reward": 389.751953125, "reward": 0.4893420934677124, "action": -1.2254574298858643}
{"mode": "train", "epochs": 5, "timestep": 8685, "ep_reward": 390.08563232421875, "reward": 0.33367395401000977, "action": -1.3440501689910889}
{"mode": "train", "epochs": 5, "timestep": 8686, "ep_reward": 390.30609130859375, "reward": 0.22045689821243286, "action": -1.497488260269165}
{"mode": "train", "epochs": 5, "timestep": 8687, "ep_reward": 390.3933410644531, "reward": 0.08723509311676025, "action": -1.6623170375823975}
{"mode": "train", "epochs": 5, "timestep": 8688, "ep_reward": 390.42352294921875, "reward": 0.030192255973815918, "action": -0.5742641687393188}
{"mode": "train", "epochs": 5, "timestep": 8689, "ep_reward": 390.5950622558594, "reward": 0.17153948545455933, "action": -1.163925290107727}
{"mode": "train", "epochs": 5, "timestep": 8690, "ep_reward": 390.9044189453125, "reward": 0.3093467950820923, "action": -1.1812758445739746}
{"mode": "train", "epochs": 5, "timestep": 8691, "ep_reward": 391.3475341796875, "reward": 0.4431091547012329, "action": -1.2260445356369019}
{"mode": "train", "epochs": 5, "timestep": 8692, "ep_reward": 391.9104919433594, "reward": 0.5629608631134033, "action": -1.0707017183303833}
{"mode": "train", "epochs": 5, "timestep": 8693, "ep_reward": 392.574951171875, "reward": 0.6644489765167236, "action": -0.6721839308738708}
{"mode": "train", "epochs": 5, "timestep": 8694, "ep_reward": 393.3215637207031, "reward": 0.7465981245040894, "action": -1.63937509059906}
{"mode": "train", "epochs": 5, "timestep": 8695, "ep_reward": 394.11865234375, "reward": 0.7970944046974182, "action": 0.010959506034851074}
{"mode": "train", "epochs": 5, "timestep": 8696, "ep_reward": 394.9609375, "reward": 0.8422803282737732, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 8697, "ep_reward": 395.8124084472656, "reward": 0.8514829277992249, "action": -1.4188488721847534}
{"mode": "train", "epochs": 5, "timestep": 8698, "ep_reward": 396.660400390625, "reward": 0.8479924201965332, "action": -1.0975749492645264}
{"mode": "train", "epochs": 5, "timestep": 8699, "ep_reward": 397.48809814453125, "reward": 0.8276951313018799, "action": -1.2854914665222168}
{"mode": "train", "epochs": 5, "timestep": 8700, "ep_reward": 398.2701721191406, "reward": 0.7820702195167542, "action": -1.4904214143753052}
{"mode": "train", "epochs": 5, "timestep": 8701, "ep_reward": 398.97418212890625, "reward": 0.7040224671363831, "action": -1.8383922576904297}
{"mode": "train", "epochs": 5, "timestep": 8702, "ep_reward": 399.55682373046875, "reward": 0.5826468467712402, "action": -0.9590188264846802}
{"mode": "train", "epochs": 5, "timestep": 8703, "ep_reward": 399.98492431640625, "reward": 0.42808985710144043, "action": -0.42413127422332764}
{"mode": "train", "epochs": 5, "timestep": 8704, "ep_reward": 400.31597900390625, "reward": 0.33105671405792236, "action": -0.7387579679489136}
{"mode": "train", "epochs": 5, "timestep": 8705, "ep_reward": 400.5333251953125, "reward": 0.21733391284942627, "action": -0.8571339845657349}
{"mode": "train", "epochs": 5, "timestep": 8706, "ep_reward": 400.6168518066406, "reward": 0.08353948593139648, "action": -1.4417881965637207}
{"mode": "train", "epochs": 5, "timestep": 8707, "ep_reward": 400.65093994140625, "reward": 0.034072935581207275, "action": -1.0386639833450317}
{"mode": "train", "epochs": 5, "timestep": 8708, "ep_reward": 400.825439453125, "reward": 0.17450052499771118, "action": -1.1669690608978271}
{"mode": "train", "epochs": 5, "timestep": 8709, "ep_reward": 401.1378173828125, "reward": 0.31237584352493286, "action": -1.4187779426574707}
{"mode": "train", "epochs": 5, "timestep": 8710, "ep_reward": 401.5810241699219, "reward": 0.44321441650390625, "action": -0.9605653285980225}
{"mode": "train", "epochs": 5, "timestep": 8711, "ep_reward": 402.1471862792969, "reward": 0.5661479234695435, "action": -1.5089099407196045}
{"mode": "train", "epochs": 5, "timestep": 8712, "ep_reward": 402.8095703125, "reward": 0.662385106086731, "action": -0.3954676389694214}
{"mode": "train", "epochs": 5, "timestep": 8713, "ep_reward": 403.5568542480469, "reward": 0.7472718954086304, "action": -1.1459904909133911}
{"mode": "train", "epochs": 5, "timestep": 8714, "ep_reward": 404.3582458496094, "reward": 0.8013876080513, "action": -1.2846755981445312}
{"mode": "train", "epochs": 5, "timestep": 8715, "ep_reward": 405.1925048828125, "reward": 0.8342670202255249, "action": -0.6400119066238403}
{"mode": "train", "epochs": 5, "timestep": 8716, "ep_reward": 406.04669189453125, "reward": 0.8541891574859619, "action": -1.765907883644104}
{"mode": "train", "epochs": 5, "timestep": 8717, "ep_reward": 406.8929748535156, "reward": 0.846287727355957, "action": -0.5411399602890015}
{"mode": "train", "epochs": 5, "timestep": 8718, "ep_reward": 407.72259521484375, "reward": 0.8296356201171875, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 8719, "ep_reward": 408.4978332519531, "reward": 0.7752364277839661, "action": -1.0995486974716187}
{"mode": "train", "epochs": 5, "timestep": 8720, "ep_reward": 409.1971740722656, "reward": 0.6993287801742554, "action": -0.6130377054214478}
{"mode": "train", "epochs": 5, "timestep": 8721, "ep_reward": 409.79010009765625, "reward": 0.5929232835769653, "action": -1.122251272201538}
{"mode": "train", "epochs": 5, "timestep": 8722, "ep_reward": 410.2276611328125, "reward": 0.43756598234176636, "action": -1.6184591054916382}
{"mode": "train", "epochs": 5, "timestep": 8723, "ep_reward": 410.55633544921875, "reward": 0.32866424322128296, "action": -0.9024214744567871}
{"mode": "train", "epochs": 5, "timestep": 8724, "ep_reward": 410.7708740234375, "reward": 0.21454280614852905, "action": -0.2595447897911072}
{"mode": "train", "epochs": 5, "timestep": 8725, "ep_reward": 410.8511657714844, "reward": 0.08029013872146606, "action": -1.1955962181091309}
{"mode": "train", "epochs": 5, "timestep": 8726, "ep_reward": 410.8885803222656, "reward": 0.0374261736869812, "action": -1.536186933517456}
{"mode": "train", "epochs": 5, "timestep": 8727, "ep_reward": 411.0661315917969, "reward": 0.17754989862442017, "action": -0.4392551779747009}
{"mode": "train", "epochs": 5, "timestep": 8728, "ep_reward": 411.39068603515625, "reward": 0.32456356287002563, "action": -0.24855518341064453}
{"mode": "train", "epochs": 5, "timestep": 8729, "ep_reward": 411.8578796386719, "reward": 0.46719038486480713, "action": 0.007414102554321289}
{"mode": "train", "epochs": 5, "timestep": 8730, "ep_reward": 412.4537658691406, "reward": 0.5959008932113647, "action": -1.0798367261886597}
{"mode": "train", "epochs": 5, "timestep": 8731, "ep_reward": 413.1451721191406, "reward": 0.691409707069397, "action": -0.8751225471496582}
{"mode": "train", "epochs": 5, "timestep": 8732, "ep_reward": 413.9131774902344, "reward": 0.7679967880249023, "action": -1.0743176937103271}
{"mode": "train", "epochs": 5, "timestep": 8733, "ep_reward": 414.73602294921875, "reward": 0.8228574395179749, "action": -1.4982621669769287}
{"mode": "train", "epochs": 5, "timestep": 8734, "ep_reward": 415.5934143066406, "reward": 0.8573886156082153, "action": -0.4467132091522217}
{"mode": "train", "epochs": 5, "timestep": 8735, "ep_reward": 416.4783935546875, "reward": 0.8849652409553528, "action": -1.5849804878234863}
{"mode": "train", "epochs": 5, "timestep": 8736, "ep_reward": 417.368896484375, "reward": 0.8904945254325867, "action": -0.4639816880226135}
{"mode": "train", "epochs": 5, "timestep": 8737, "ep_reward": 418.2601318359375, "reward": 0.8912498950958252, "action": -0.6252782344818115}
{"mode": "train", "epochs": 5, "timestep": 8738, "ep_reward": 419.13690185546875, "reward": 0.8767760396003723, "action": -0.25954651832580566}
{"mode": "train", "epochs": 5, "timestep": 8739, "ep_reward": 419.9860534667969, "reward": 0.8491401076316833, "action": -1.5031863451004028}
{"mode": "train", "epochs": 5, "timestep": 8740, "ep_reward": 420.7754821777344, "reward": 0.7894366979598999, "action": -1.6634595394134521}
{"mode": "train", "epochs": 5, "timestep": 8741, "ep_reward": 421.4737243652344, "reward": 0.6982320547103882, "action": -1.3019449710845947}
{"mode": "train", "epochs": 5, "timestep": 8742, "ep_reward": 422.04754638671875, "reward": 0.573824405670166, "action": -0.6304945349693298}
{"mode": "train", "epochs": 5, "timestep": 8743, "ep_reward": 422.4658203125, "reward": 0.4182806611061096, "action": -0.6734882593154907}
{"mode": "train", "epochs": 5, "timestep": 8744, "ep_reward": 422.75372314453125, "reward": 0.28789234161376953, "action": -0.04225212335586548}
{"mode": "train", "epochs": 5, "timestep": 8745, "ep_reward": 422.91973876953125, "reward": 0.16603046655654907, "action": -1.4472966194152832}
{"mode": "train", "epochs": 5, "timestep": 8746, "ep_reward": 422.944091796875, "reward": 0.02436155080795288, "action": -1.052335262298584}
{"mode": "train", "epochs": 5, "timestep": 8747, "ep_reward": 423.0368957519531, "reward": 0.0928046703338623, "action": -0.970777153968811}
{"mode": "train", "epochs": 5, "timestep": 8748, "ep_reward": 423.2680969238281, "reward": 0.23118942975997925, "action": -1.1827831268310547}
{"mode": "train", "epochs": 5, "timestep": 8749, "ep_reward": 423.6363220214844, "reward": 0.36823761463165283, "action": -0.42572176456451416}
{"mode": "train", "epochs": 5, "timestep": 8750, "ep_reward": 424.1423034667969, "reward": 0.5059894323348999, "action": -0.8451452851295471}
{"mode": "train", "epochs": 5, "timestep": 8751, "ep_reward": 424.76239013671875, "reward": 0.6200742721557617, "action": -1.8225771188735962}
{"mode": "train", "epochs": 5, "timestep": 8752, "ep_reward": 425.4651184082031, "reward": 0.7027169466018677, "action": -0.8197991251945496}
{"mode": "train", "epochs": 5, "timestep": 8753, "ep_reward": 426.2392272949219, "reward": 0.7741043567657471, "action": -0.5080540180206299}
{"mode": "train", "epochs": 5, "timestep": 8754, "ep_reward": 427.06591796875, "reward": 0.8267030715942383, "action": -0.6551058292388916}
{"mode": "train", "epochs": 5, "timestep": 8755, "ep_reward": 427.9246826171875, "reward": 0.858757495880127, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 8756, "ep_reward": 428.7879638671875, "reward": 0.8632878065109253, "action": -1.7655613422393799}
{"mode": "train", "epochs": 5, "timestep": 8757, "ep_reward": 429.6408996582031, "reward": 0.8529407978057861, "action": -1.1442949771881104}
{"mode": "train", "epochs": 5, "timestep": 8758, "ep_reward": 430.469482421875, "reward": 0.8285874724388123, "action": -1.5082290172576904}
{"mode": "train", "epochs": 5, "timestep": 8759, "ep_reward": 431.2464599609375, "reward": 0.7769766449928284, "action": -0.9702699184417725}
{"mode": "train", "epochs": 5, "timestep": 8760, "ep_reward": 431.94744873046875, "reward": 0.7009892463684082, "action": -0.5477770566940308}
{"mode": "train", "epochs": 5, "timestep": 8761, "ep_reward": 432.5419006347656, "reward": 0.594454824924469, "action": -0.938857913017273}
{"mode": "train", "epochs": 5, "timestep": 8762, "ep_reward": 432.9836730957031, "reward": 0.44176506996154785, "action": -1.6836707592010498}
{"mode": "train", "epochs": 5, "timestep": 8763, "ep_reward": 433.3077392578125, "reward": 0.3240790367126465, "action": -0.8556968569755554}
{"mode": "train", "epochs": 5, "timestep": 8764, "ep_reward": 433.51678466796875, "reward": 0.20904862880706787, "action": -0.6979414820671082}
{"mode": "train", "epochs": 5, "timestep": 8765, "ep_reward": 433.5908203125, "reward": 0.0740233063697815, "action": -0.41295933723449707}
{"mode": "train", "epochs": 5, "timestep": 8766, "ep_reward": 433.6348571777344, "reward": 0.04402226209640503, "action": -1.349872350692749}
{"mode": "train", "epochs": 5, "timestep": 8767, "ep_reward": 433.8180847167969, "reward": 0.1832178831100464, "action": -0.6802626252174377}
{"mode": "train", "epochs": 5, "timestep": 8768, "ep_reward": 434.145263671875, "reward": 0.32718169689178467, "action": -1.672071933746338}
{"mode": "train", "epochs": 5, "timestep": 8769, "ep_reward": 434.5986328125, "reward": 0.45336616039276123, "action": -0.4612199068069458}
{"mode": "train", "epochs": 5, "timestep": 8770, "ep_reward": 435.1790466308594, "reward": 0.5804102420806885, "action": -0.7457770109176636}
{"mode": "train", "epochs": 5, "timestep": 8771, "ep_reward": 435.8609313964844, "reward": 0.6818898916244507, "action": -1.1139079332351685}
{"mode": "train", "epochs": 5, "timestep": 8772, "ep_reward": 436.6175842285156, "reward": 0.7566514611244202, "action": -1.0880151987075806}
{"mode": "train", "epochs": 5, "timestep": 8773, "ep_reward": 437.4278259277344, "reward": 0.8102480173110962, "action": -1.964448094367981}
{"mode": "train", "epochs": 5, "timestep": 8774, "ep_reward": 438.26519775390625, "reward": 0.8373656272888184, "action": -1.2512803077697754}
{"mode": "train", "epochs": 5, "timestep": 8775, "ep_reward": 439.118408203125, "reward": 0.8532091379165649, "action": -1.2787226438522339}
{"mode": "train", "epochs": 5, "timestep": 8776, "ep_reward": 439.96954345703125, "reward": 0.8511307239532471, "action": -0.826504111289978}
{"mode": "train", "epochs": 5, "timestep": 8777, "ep_reward": 440.8036193847656, "reward": 0.8340746164321899, "action": -0.26560914516448975}
{"mode": "train", "epochs": 5, "timestep": 8778, "ep_reward": 441.6044006347656, "reward": 0.800788938999176, "action": -1.5759069919586182}
{"mode": "train", "epochs": 5, "timestep": 8779, "ep_reward": 442.33160400390625, "reward": 0.727208137512207, "action": -0.6800251007080078}
{"mode": "train", "epochs": 5, "timestep": 8780, "ep_reward": 442.96087646484375, "reward": 0.6292660236358643, "action": -0.8911226391792297}
{"mode": "train", "epochs": 5, "timestep": 8781, "ep_reward": 443.4498291015625, "reward": 0.48896002769470215, "action": -1.371887445449829}
{"mode": "train", "epochs": 5, "timestep": 8782, "ep_reward": 443.8008728027344, "reward": 0.3510369062423706, "action": -0.7682105898857117}
{"mode": "train", "epochs": 5, "timestep": 8783, "ep_reward": 444.0421447753906, "reward": 0.24126160144805908, "action": -0.6817373037338257}
{"mode": "train", "epochs": 5, "timestep": 8784, "ep_reward": 444.1535949707031, "reward": 0.11143666505813599, "action": -1.0687252283096313}
{"mode": "train", "epochs": 5, "timestep": 8785, "ep_reward": 444.15777587890625, "reward": 0.004178643226623535, "action": -0.6804704666137695}
{"mode": "train", "epochs": 5, "timestep": 8786, "ep_reward": 444.3063049316406, "reward": 0.14851993322372437, "action": -0.9856741428375244}
{"mode": "train", "epochs": 5, "timestep": 8787, "ep_reward": 444.5945129394531, "reward": 0.2882084250450134, "action": -0.9905505180358887}
{"mode": "train", "epochs": 5, "timestep": 8788, "ep_reward": 445.0197448730469, "reward": 0.42523545026779175, "action": -0.47910594940185547}
{"mode": "train", "epochs": 5, "timestep": 8789, "ep_reward": 445.5751953125, "reward": 0.5554382801055908, "action": -1.5871069431304932}
{"mode": "train", "epochs": 5, "timestep": 8790, "ep_reward": 446.2283020019531, "reward": 0.6531165242195129, "action": -1.8042105436325073}
{"mode": "train", "epochs": 5, "timestep": 8791, "ep_reward": 446.9561462402344, "reward": 0.7278323173522949, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 8792, "ep_reward": 447.7361755371094, "reward": 0.7800288200378418, "action": -0.6353638172149658}
{"mode": "train", "epochs": 5, "timestep": 8793, "ep_reward": 448.5606689453125, "reward": 0.8244798183441162, "action": -1.354011058807373}
{"mode": "train", "epochs": 5, "timestep": 8794, "ep_reward": 449.4033508300781, "reward": 0.8426968455314636, "action": -0.9632985591888428}
{"mode": "train", "epochs": 5, "timestep": 8795, "ep_reward": 450.2489013671875, "reward": 0.8455655574798584, "action": -1.8839383125305176}
{"mode": "train", "epochs": 5, "timestep": 8796, "ep_reward": 451.068603515625, "reward": 0.8197147846221924, "action": -1.4405717849731445}
{"mode": "train", "epochs": 5, "timestep": 8797, "ep_reward": 451.8418273925781, "reward": 0.773213267326355, "action": -1.0968047380447388}
{"mode": "train", "epochs": 5, "timestep": 8798, "ep_reward": 452.5415344238281, "reward": 0.6996968984603882, "action": -1.2216448783874512}
{"mode": "train", "epochs": 5, "timestep": 8799, "ep_reward": 453.12823486328125, "reward": 0.5867063999176025, "action": -1.8020769357681274}
{"mode": "train", "epochs": 5, "timestep": 8800, "ep_reward": 453.5554504394531, "reward": 0.42721498012542725, "action": 0.07896864414215088}
{"mode": "train", "epochs": 5, "timestep": 8801, "ep_reward": 453.8894348144531, "reward": 0.3339836597442627, "action": -1.2560434341430664}
{"mode": "train", "epochs": 5, "timestep": 8802, "ep_reward": 454.11029052734375, "reward": 0.22086858749389648, "action": -1.1390572786331177}
{"mode": "train", "epochs": 5, "timestep": 8803, "ep_reward": 454.1980895996094, "reward": 0.087796151638031, "action": -0.5882222652435303}
{"mode": "train", "epochs": 5, "timestep": 8804, "ep_reward": 454.2276306152344, "reward": 0.02953052520751953, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 8805, "ep_reward": 454.39837646484375, "reward": 0.17076075077056885, "action": -0.8342118263244629}
{"mode": "train", "epochs": 5, "timestep": 8806, "ep_reward": 454.71112060546875, "reward": 0.31275731325149536, "action": -0.9454454183578491}
{"mode": "train", "epochs": 5, "timestep": 8807, "ep_reward": 455.1597900390625, "reward": 0.4486839771270752, "action": -0.45579808950424194}
{"mode": "train", "epochs": 5, "timestep": 8808, "ep_reward": 455.7357177734375, "reward": 0.5759258270263672, "action": -1.3515114784240723}
{"mode": "train", "epochs": 5, "timestep": 8809, "ep_reward": 456.40789794921875, "reward": 0.6721906661987305, "action": -1.877096176147461}
{"mode": "train", "epochs": 5, "timestep": 8810, "ep_reward": 457.15008544921875, "reward": 0.742180347442627, "action": -1.724501609802246}
{"mode": "train", "epochs": 5, "timestep": 8811, "ep_reward": 457.94354248046875, "reward": 0.793463945388794, "action": -0.7584365010261536}
{"mode": "train", "epochs": 5, "timestep": 8812, "ep_reward": 458.7771301269531, "reward": 0.8335961103439331, "action": -1.6577677726745605}
{"mode": "train", "epochs": 5, "timestep": 8813, "ep_reward": 459.6242980957031, "reward": 0.8471708297729492, "action": -0.4587295651435852}
{"mode": "train", "epochs": 5, "timestep": 8814, "ep_reward": 460.47760009765625, "reward": 0.8533011674880981, "action": -0.702183723449707}
{"mode": "train", "epochs": 5, "timestep": 8815, "ep_reward": 461.3160705566406, "reward": 0.838467001914978, "action": -1.243461012840271}
{"mode": "train", "epochs": 5, "timestep": 8816, "ep_reward": 462.1128845214844, "reward": 0.7968097925186157, "action": -0.7489364147186279}
{"mode": "train", "epochs": 5, "timestep": 8817, "ep_reward": 462.84600830078125, "reward": 0.733116626739502, "action": -0.3186493515968323}
{"mode": "train", "epochs": 5, "timestep": 8818, "ep_reward": 463.48822021484375, "reward": 0.6422207355499268, "action": -0.18944525718688965}
{"mode": "train", "epochs": 5, "timestep": 8819, "ep_reward": 464.0047912597656, "reward": 0.51658034324646, "action": -0.1363898515701294}
{"mode": "train", "epochs": 5, "timestep": 8820, "ep_reward": 464.3637390136719, "reward": 0.3589354157447815, "action": -0.9733811616897583}
{"mode": "train", "epochs": 5, "timestep": 8821, "ep_reward": 464.61444091796875, "reward": 0.2507065534591675, "action": -1.2975828647613525}
{"mode": "train", "epochs": 5, "timestep": 8822, "ep_reward": 464.7369384765625, "reward": 0.12250310182571411, "action": -1.423012137413025}
{"mode": "train", "epochs": 5, "timestep": 8823, "ep_reward": 464.7284851074219, "reward": -0.00845956802368164, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 8824, "ep_reward": 464.8662109375, "reward": 0.13772815465927124, "action": -0.7558149099349976}
{"mode": "train", "epochs": 5, "timestep": 8825, "ep_reward": 465.1462707519531, "reward": 0.280048668384552, "action": -0.6462479829788208}
{"mode": "train", "epochs": 5, "timestep": 8826, "ep_reward": 465.5673828125, "reward": 0.42112481594085693, "action": -0.6750094294548035}
{"mode": "train", "epochs": 5, "timestep": 8827, "ep_reward": 466.1164245605469, "reward": 0.5490437746047974, "action": -1.7252943515777588}
{"mode": "train", "epochs": 5, "timestep": 8828, "ep_reward": 466.76287841796875, "reward": 0.6464457511901855, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 8829, "ep_reward": 467.4842529296875, "reward": 0.7213640213012695, "action": -0.7577823996543884}
{"mode": "train", "epochs": 5, "timestep": 8830, "ep_reward": 468.2715759277344, "reward": 0.7873218655586243, "action": -1.3215184211730957}
{"mode": "train", "epochs": 5, "timestep": 8831, "ep_reward": 469.0987854003906, "reward": 0.8272234797477722, "action": -0.6687289476394653}
{"mode": "train", "epochs": 5, "timestep": 8832, "ep_reward": 469.9530944824219, "reward": 0.854316771030426, "action": -0.9314826726913452}
{"mode": "train", "epochs": 5, "timestep": 8833, "ep_reward": 470.8148193359375, "reward": 0.8617311716079712, "action": -1.1582168340682983}
{"mode": "train", "epochs": 5, "timestep": 8834, "ep_reward": 471.6645812988281, "reward": 0.8497538566589355, "action": -0.0387994647026062}
{"mode": "train", "epochs": 5, "timestep": 8835, "ep_reward": 472.4931335449219, "reward": 0.828563928604126, "action": -1.6826691627502441}
{"mode": "train", "epochs": 5, "timestep": 8836, "ep_reward": 473.26123046875, "reward": 0.7680839896202087, "action": -1.3961946964263916}
{"mode": "train", "epochs": 5, "timestep": 8837, "ep_reward": 473.9398193359375, "reward": 0.678602933883667, "action": -0.8055668473243713}
{"mode": "train", "epochs": 5, "timestep": 8838, "ep_reward": 474.498046875, "reward": 0.5582176446914673, "action": -0.18718403577804565}
{"mode": "train", "epochs": 5, "timestep": 8839, "ep_reward": 474.9045715332031, "reward": 0.4065396785736084, "action": -0.0051076412200927734}
{"mode": "train", "epochs": 5, "timestep": 8840, "ep_reward": 475.19805908203125, "reward": 0.2934723496437073, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 8841, "ep_reward": 475.37109375, "reward": 0.17302298545837402, "action": -0.5159271955490112}
{"mode": "train", "epochs": 5, "timestep": 8842, "ep_reward": 475.4034118652344, "reward": 0.032306015491485596, "action": -0.907286524772644}
{"mode": "train", "epochs": 5, "timestep": 8843, "ep_reward": 475.4887390136719, "reward": 0.0853123664855957, "action": -0.9579353332519531}
{"mode": "train", "epochs": 5, "timestep": 8844, "ep_reward": 475.7124328613281, "reward": 0.22369658946990967, "action": -0.586056113243103}
{"mode": "train", "epochs": 5, "timestep": 8845, "ep_reward": 476.0806884765625, "reward": 0.3682425618171692, "action": -0.0756525993347168}
{"mode": "train", "epochs": 5, "timestep": 8846, "ep_reward": 476.58966064453125, "reward": 0.5089625120162964, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 8847, "ep_reward": 477.19989013671875, "reward": 0.6102394461631775, "action": -0.5230523347854614}
{"mode": "train", "epochs": 5, "timestep": 8848, "ep_reward": 477.9076843261719, "reward": 0.7077942490577698, "action": -0.734716534614563}
{"mode": "train", "epochs": 5, "timestep": 8849, "ep_reward": 478.6877136230469, "reward": 0.7800284624099731, "action": -1.0377023220062256}
{"mode": "train", "epochs": 5, "timestep": 8850, "ep_reward": 479.5166931152344, "reward": 0.8289809226989746, "action": -1.1244380474090576}
{"mode": "train", "epochs": 5, "timestep": 8851, "ep_reward": 480.3762512207031, "reward": 0.8595689535140991, "action": -1.3445390462875366}
{"mode": "train", "epochs": 5, "timestep": 8852, "ep_reward": 481.2490234375, "reward": 0.8727742433547974, "action": -0.5428375005722046}
{"mode": "train", "epochs": 5, "timestep": 8853, "ep_reward": 482.126220703125, "reward": 0.8772094249725342, "action": -1.3549885749816895}
{"mode": "train", "epochs": 5, "timestep": 8854, "ep_reward": 482.9852294921875, "reward": 0.8589991331100464, "action": -0.965762197971344}
{"mode": "train", "epochs": 5, "timestep": 8855, "ep_reward": 483.81024169921875, "reward": 0.8250086307525635, "action": -1.011791706085205}
{"mode": "train", "epochs": 5, "timestep": 8856, "ep_reward": 484.5769348144531, "reward": 0.7667021751403809, "action": -1.2172836065292358}
{"mode": "train", "epochs": 5, "timestep": 8857, "ep_reward": 485.2523498535156, "reward": 0.6754289865493774, "action": 0.23636353015899658}
{"mode": "train", "epochs": 5, "timestep": 8858, "ep_reward": 485.8189697265625, "reward": 0.5666300058364868, "action": -1.4102232456207275}
{"mode": "train", "epochs": 5, "timestep": 8859, "ep_reward": 486.2153015136719, "reward": 0.3963433504104614, "action": -1.170184850692749}
{"mode": "train", "epochs": 5, "timestep": 8860, "ep_reward": 486.4958190917969, "reward": 0.28052812814712524, "action": -1.044268250465393}
{"mode": "train", "epochs": 5, "timestep": 8861, "ep_reward": 486.6532897949219, "reward": 0.15746963024139404, "action": -1.2454869747161865}
{"mode": "train", "epochs": 5, "timestep": 8862, "ep_reward": 486.667724609375, "reward": 0.014422893524169922, "action": -1.3544368743896484}
{"mode": "train", "epochs": 5, "timestep": 8863, "ep_reward": 486.7696228027344, "reward": 0.10189372301101685, "action": -1.6712524890899658}
{"mode": "train", "epochs": 5, "timestep": 8864, "ep_reward": 487.0028076171875, "reward": 0.2331811785697937, "action": -0.47058671712875366}
{"mode": "train", "epochs": 5, "timestep": 8865, "ep_reward": 487.3828430175781, "reward": 0.3800460696220398, "action": -1.348174810409546}
{"mode": "train", "epochs": 5, "timestep": 8866, "ep_reward": 487.888671875, "reward": 0.5058165788650513, "action": -0.25025635957717896}
{"mode": "train", "epochs": 5, "timestep": 8867, "ep_reward": 488.51531982421875, "reward": 0.6266509294509888, "action": -1.0949324369430542}
{"mode": "train", "epochs": 5, "timestep": 8868, "ep_reward": 489.230224609375, "reward": 0.7148997187614441, "action": -0.4495733976364136}
{"mode": "train", "epochs": 5, "timestep": 8869, "ep_reward": 490.01702880859375, "reward": 0.7867940664291382, "action": -1.2941131591796875}
{"mode": "train", "epochs": 5, "timestep": 8870, "ep_reward": 490.84722900390625, "reward": 0.8302092552185059, "action": -1.14031982421875}
{"mode": "train", "epochs": 5, "timestep": 8871, "ep_reward": 491.7045593261719, "reward": 0.8573256731033325, "action": -1.216088891029358}
{"mode": "train", "epochs": 5, "timestep": 8872, "ep_reward": 492.5721130371094, "reward": 0.8675554394721985, "action": -0.6974440813064575}
{"mode": "train", "epochs": 5, "timestep": 8873, "ep_reward": 493.43804931640625, "reward": 0.8659491539001465, "action": -0.5835424661636353}
{"mode": "train", "epochs": 5, "timestep": 8874, "ep_reward": 494.2860412597656, "reward": 0.848006010055542, "action": -1.3490421772003174}
{"mode": "train", "epochs": 5, "timestep": 8875, "ep_reward": 495.0883483886719, "reward": 0.8023083209991455, "action": -1.2017717361450195}
{"mode": "train", "epochs": 5, "timestep": 8876, "ep_reward": 495.8190612792969, "reward": 0.7307219505310059, "action": -1.1407830715179443}
{"mode": "train", "epochs": 5, "timestep": 8877, "ep_reward": 496.4444885253906, "reward": 0.6254286766052246, "action": -1.017923355102539}
{"mode": "train", "epochs": 5, "timestep": 8878, "ep_reward": 496.92572021484375, "reward": 0.48123419284820557, "action": -0.22502803802490234}
{"mode": "train", "epochs": 5, "timestep": 8879, "ep_reward": 497.2685546875, "reward": 0.34282416105270386, "action": 0.3334232568740845}
{"mode": "train", "epochs": 5, "timestep": 8880, "ep_reward": 497.4998779296875, "reward": 0.2313288450241089, "action": -1.1352214813232422}
{"mode": "train", "epochs": 5, "timestep": 8881, "ep_reward": 497.5997619628906, "reward": 0.09988051652908325, "action": -1.3126412630081177}
{"mode": "train", "epochs": 5, "timestep": 8882, "ep_reward": 497.61639404296875, "reward": 0.016634762287139893, "action": -1.5689539909362793}
{"mode": "train", "epochs": 5, "timestep": 8883, "ep_reward": 497.77587890625, "reward": 0.15947991609573364, "action": -0.8317936658859253}
{"mode": "train", "epochs": 5, "timestep": 8884, "ep_reward": 498.0772399902344, "reward": 0.30135709047317505, "action": -0.25428277254104614}
{"mode": "train", "epochs": 5, "timestep": 8885, "ep_reward": 498.5232849121094, "reward": 0.44603431224823, "action": -1.1482133865356445}
{"mode": "train", "epochs": 5, "timestep": 8886, "ep_reward": 499.0887451171875, "reward": 0.5654737949371338, "action": -1.2104917764663696}
{"mode": "train", "epochs": 5, "timestep": 8887, "ep_reward": 499.7540283203125, "reward": 0.6652820110321045, "action": -1.4097716808319092}
{"mode": "train", "epochs": 5, "timestep": 8888, "ep_reward": 500.4957580566406, "reward": 0.7417339086532593, "action": -1.3939332962036133}
{"mode": "train", "epochs": 5, "timestep": 8889, "ep_reward": 501.29327392578125, "reward": 0.7975062131881714, "action": -1.5527877807617188}
{"mode": "train", "epochs": 5, "timestep": 8890, "ep_reward": 502.1259765625, "reward": 0.8326991200447083, "action": -1.0607107877731323}
{"mode": "train", "epochs": 5, "timestep": 8891, "ep_reward": 502.9803771972656, "reward": 0.8544015884399414, "action": -0.26444172859191895}
{"mode": "train", "epochs": 5, "timestep": 8892, "ep_reward": 503.8460388183594, "reward": 0.8656507730484009, "action": -1.2946847677230835}
{"mode": "train", "epochs": 5, "timestep": 8893, "ep_reward": 504.69683837890625, "reward": 0.8508124351501465, "action": -0.678703248500824}
{"mode": "train", "epochs": 5, "timestep": 8894, "ep_reward": 505.5186767578125, "reward": 0.8218351006507874, "action": -0.18333399295806885}
{"mode": "train", "epochs": 5, "timestep": 8895, "ep_reward": 506.29345703125, "reward": 0.7747839689254761, "action": -0.8647125363349915}
{"mode": "train", "epochs": 5, "timestep": 8896, "ep_reward": 506.985595703125, "reward": 0.6921234130859375, "action": -0.7638145685195923}
{"mode": "train", "epochs": 5, "timestep": 8897, "ep_reward": 507.5606384277344, "reward": 0.57505202293396, "action": -0.15272903442382812}
{"mode": "train", "epochs": 5, "timestep": 8898, "ep_reward": 507.9885559082031, "reward": 0.42792588472366333, "action": 0.25340497493743896}
{"mode": "train", "epochs": 5, "timestep": 8899, "ep_reward": 508.2846374511719, "reward": 0.29608410596847534, "action": -1.1910943984985352}
{"mode": "train", "epochs": 5, "timestep": 8900, "ep_reward": 508.4605407714844, "reward": 0.17590445280075073, "action": -0.6841309070587158}
{"mode": "train", "epochs": 5, "timestep": 8901, "ep_reward": 508.4960021972656, "reward": 0.03547263145446777, "action": -1.8874722719192505}
{"mode": "train", "epochs": 5, "timestep": 8902, "ep_reward": 508.5779724121094, "reward": 0.08197659254074097, "action": -1.812695860862732}
{"mode": "train", "epochs": 5, "timestep": 8903, "ep_reward": 508.7940673828125, "reward": 0.21608489751815796, "action": -0.47968554496765137}
{"mode": "train", "epochs": 5, "timestep": 8904, "ep_reward": 509.15679931640625, "reward": 0.36273032426834106, "action": -1.935807466506958}
{"mode": "train", "epochs": 5, "timestep": 8905, "ep_reward": 509.6398620605469, "reward": 0.483071506023407, "action": -0.2674536108970642}
{"mode": "train", "epochs": 5, "timestep": 8906, "ep_reward": 510.24755859375, "reward": 0.6077091097831726, "action": -1.2697758674621582}
{"mode": "train", "epochs": 5, "timestep": 8907, "ep_reward": 510.9456787109375, "reward": 0.698113739490509, "action": -0.1957976222038269}
{"mode": "train", "epochs": 5, "timestep": 8908, "ep_reward": 511.721923828125, "reward": 0.7762329578399658, "action": -1.05915105342865}
{"mode": "train", "epochs": 5, "timestep": 8909, "ep_reward": 512.5460205078125, "reward": 0.8240939378738403, "action": -1.5962746143341064}
{"mode": "train", "epochs": 5, "timestep": 8910, "ep_reward": 513.3951416015625, "reward": 0.8491407632827759, "action": -1.2361621856689453}
{"mode": "train", "epochs": 5, "timestep": 8911, "ep_reward": 514.2554931640625, "reward": 0.8603404760360718, "action": -1.505359411239624}
{"mode": "train", "epochs": 5, "timestep": 8912, "ep_reward": 515.1074829101562, "reward": 0.8519702553749084, "action": -1.239410161972046}
{"mode": "train", "epochs": 5, "timestep": 8913, "ep_reward": 515.9338989257812, "reward": 0.8264238834381104, "action": -0.7742339372634888}
{"mode": "train", "epochs": 5, "timestep": 8914, "ep_reward": 516.7159423828125, "reward": 0.7820339798927307, "action": -1.254716396331787}
{"mode": "train", "epochs": 5, "timestep": 8915, "ep_reward": 517.4193725585938, "reward": 0.703411340713501, "action": -0.9716295003890991}
{"mode": "train", "epochs": 5, "timestep": 8916, "ep_reward": 518.0108642578125, "reward": 0.5915045142173767, "action": -0.5339205265045166}
{"mode": "train", "epochs": 5, "timestep": 8917, "ep_reward": 518.4555053710938, "reward": 0.4446318745613098, "action": -1.1986277103424072}
{"mode": "train", "epochs": 5, "timestep": 8918, "ep_reward": 518.7796020507812, "reward": 0.324115514755249, "action": -0.803481936454773}
{"mode": "train", "epochs": 5, "timestep": 8919, "ep_reward": 518.988525390625, "reward": 0.20889610052108765, "action": -1.87589430809021}
{"mode": "train", "epochs": 5, "timestep": 8920, "ep_reward": 519.0625610351562, "reward": 0.07405221462249756, "action": -0.6285618543624878}
{"mode": "train", "epochs": 5, "timestep": 8921, "ep_reward": 519.1065063476562, "reward": 0.04394209384918213, "action": -1.5495866537094116}
{"mode": "train", "epochs": 5, "timestep": 8922, "ep_reward": 519.2896728515625, "reward": 0.18314611911773682, "action": -0.9997460246086121}
{"mode": "train", "epochs": 5, "timestep": 8923, "ep_reward": 519.613037109375, "reward": 0.3233407139778137, "action": -0.291351854801178}
{"mode": "train", "epochs": 5, "timestep": 8924, "ep_reward": 520.0796508789062, "reward": 0.46660906076431274, "action": -0.2155730128288269}
{"mode": "train", "epochs": 5, "timestep": 8925, "ep_reward": 520.673095703125, "reward": 0.5934724807739258, "action": -1.779726266860962}
{"mode": "train", "epochs": 5, "timestep": 8926, "ep_reward": 521.3554077148438, "reward": 0.6823350787162781, "action": -1.4098519086837769}
{"mode": "train", "epochs": 5, "timestep": 8927, "ep_reward": 522.1101684570312, "reward": 0.754747211933136, "action": -1.0273163318634033}
{"mode": "train", "epochs": 5, "timestep": 8928, "ep_reward": 522.9202880859375, "reward": 0.8100959062576294, "action": -0.805392324924469}
{"mode": "train", "epochs": 5, "timestep": 8929, "ep_reward": 523.7682495117188, "reward": 0.8479762077331543, "action": -1.940006971359253}
{"mode": "train", "epochs": 5, "timestep": 8930, "ep_reward": 524.6278076171875, "reward": 0.8595564961433411, "action": -0.9654431343078613}
{"mode": "train", "epochs": 5, "timestep": 8931, "ep_reward": 525.4906005859375, "reward": 0.862823486328125, "action": -1.4221688508987427}
{"mode": "train", "epochs": 5, "timestep": 8932, "ep_reward": 526.3349609375, "reward": 0.844342827796936, "action": -1.5617856979370117}
{"mode": "train", "epochs": 5, "timestep": 8933, "ep_reward": 527.1380004882812, "reward": 0.8030397295951843, "action": -0.8866016864776611}
{"mode": "train", "epochs": 5, "timestep": 8934, "ep_reward": 527.879638671875, "reward": 0.7416679263114929, "action": -0.9134129285812378}
{"mode": "train", "epochs": 5, "timestep": 8935, "ep_reward": 528.52685546875, "reward": 0.647215723991394, "action": -0.8314694166183472}
{"mode": "train", "epochs": 5, "timestep": 8936, "ep_reward": 529.04150390625, "reward": 0.5146346092224121, "action": -0.9480535984039307}
{"mode": "train", "epochs": 5, "timestep": 8937, "ep_reward": 529.4092407226562, "reward": 0.367728054523468, "action": -0.47272735834121704}
{"mode": "train", "epochs": 5, "timestep": 8938, "ep_reward": 529.6705932617188, "reward": 0.2613254189491272, "action": -0.7165689468383789}
{"mode": "train", "epochs": 5, "timestep": 8939, "ep_reward": 529.8055419921875, "reward": 0.13497185707092285, "action": -0.16762202978134155}
{"mode": "train", "epochs": 5, "timestep": 8940, "ep_reward": 529.7940673828125, "reward": -0.011453747749328613, "action": -0.8390932083129883}
{"mode": "train", "epochs": 5, "timestep": 8941, "ep_reward": 529.9193115234375, "reward": 0.12527436017990112, "action": -1.7084591388702393}
{"mode": "train", "epochs": 5, "timestep": 8942, "ep_reward": 530.1746215820312, "reward": 0.2553054094314575, "action": -1.5559093952178955}
{"mode": "train", "epochs": 5, "timestep": 8943, "ep_reward": 530.56298828125, "reward": 0.38833916187286377, "action": -0.33489811420440674}
{"mode": "train", "epochs": 5, "timestep": 8944, "ep_reward": 531.0890502929688, "reward": 0.5260788202285767, "action": -1.5911579132080078}
{"mode": "train", "epochs": 5, "timestep": 8945, "ep_reward": 531.7178955078125, "reward": 0.6288626790046692, "action": -1.3655354976654053}
{"mode": "train", "epochs": 5, "timestep": 8946, "ep_reward": 532.4302978515625, "reward": 0.7123812437057495, "action": -1.1329103708267212}
{"mode": "train", "epochs": 5, "timestep": 8947, "ep_reward": 533.20556640625, "reward": 0.7752934694290161, "action": -0.06371915340423584}
{"mode": "train", "epochs": 5, "timestep": 8948, "ep_reward": 534.031494140625, "reward": 0.8259330987930298, "action": -1.3407093286514282}
{"mode": "train", "epochs": 5, "timestep": 8949, "ep_reward": 534.8761596679688, "reward": 0.8446676731109619, "action": -1.951232671737671}
{"mode": "train", "epochs": 5, "timestep": 8950, "ep_reward": 535.7156982421875, "reward": 0.8395160436630249, "action": -0.46791040897369385}
{"mode": "train", "epochs": 5, "timestep": 8951, "ep_reward": 536.5435791015625, "reward": 0.8278773427009583, "action": -0.8979446887969971}
{"mode": "train", "epochs": 5, "timestep": 8952, "ep_reward": 537.3329467773438, "reward": 0.7893588542938232, "action": -1.2837753295898438}
{"mode": "train", "epochs": 5, "timestep": 8953, "ep_reward": 538.0512084960938, "reward": 0.7182812690734863, "action": -1.1259512901306152}
{"mode": "train", "epochs": 5, "timestep": 8954, "ep_reward": 538.6641235351562, "reward": 0.6128896474838257, "action": -1.3855042457580566}
{"mode": "train", "epochs": 5, "timestep": 8955, "ep_reward": 539.1249389648438, "reward": 0.46079200506210327, "action": -1.617917537689209}
{"mode": "train", "epochs": 5, "timestep": 8956, "ep_reward": 539.472900390625, "reward": 0.3479558825492859, "action": -0.9309751987457275}
{"mode": "train", "epochs": 5, "timestep": 8957, "ep_reward": 539.7105102539062, "reward": 0.2375849485397339, "action": -0.6908187866210938}
{"mode": "train", "epochs": 5, "timestep": 8958, "ep_reward": 539.8176879882812, "reward": 0.10715216398239136, "action": -1.0419561862945557}
{"mode": "train", "epochs": 5, "timestep": 8959, "ep_reward": 539.8264770507812, "reward": 0.008783280849456787, "action": -1.4980100393295288}
{"mode": "train", "epochs": 5, "timestep": 8960, "ep_reward": 539.9791259765625, "reward": 0.152646005153656, "action": -0.7844043970108032}
{"mode": "train", "epochs": 5, "timestep": 8961, "ep_reward": 540.2740478515625, "reward": 0.2949259281158447, "action": -0.823060929775238}
{"mode": "train", "epochs": 5, "timestep": 8962, "ep_reward": 540.7072143554688, "reward": 0.43317675590515137, "action": -0.9128054976463318}
{"mode": "train", "epochs": 5, "timestep": 8963, "ep_reward": 541.2645263671875, "reward": 0.5572905540466309, "action": -1.064549207687378}
{"mode": "train", "epochs": 5, "timestep": 8964, "ep_reward": 541.9246215820312, "reward": 0.660099983215332, "action": -1.425475835800171}
{"mode": "train", "epochs": 5, "timestep": 8965, "ep_reward": 542.6622314453125, "reward": 0.7375851273536682, "action": 0.06872272491455078}
{"mode": "train", "epochs": 5, "timestep": 8966, "ep_reward": 543.4696044921875, "reward": 0.8073485493659973, "action": -0.6435641050338745}
{"mode": "train", "epochs": 5, "timestep": 8967, "ep_reward": 544.3194580078125, "reward": 0.8498327732086182, "action": -1.2978841066360474}
{"mode": "train", "epochs": 5, "timestep": 8968, "ep_reward": 545.1898803710938, "reward": 0.870424211025238, "action": -0.4647989273071289}
{"mode": "train", "epochs": 5, "timestep": 8969, "ep_reward": 546.0725708007812, "reward": 0.8826919794082642, "action": -0.6158391833305359}
{"mode": "train", "epochs": 5, "timestep": 8970, "ep_reward": 546.9515991210938, "reward": 0.8790519833564758, "action": -1.0127476453781128}
{"mode": "train", "epochs": 5, "timestep": 8971, "ep_reward": 547.807861328125, "reward": 0.8562452793121338, "action": -0.709013819694519}
{"mode": "train", "epochs": 5, "timestep": 8972, "ep_reward": 548.6245727539062, "reward": 0.816711962223053, "action": -0.7843341827392578}
{"mode": "train", "epochs": 5, "timestep": 8973, "ep_reward": 549.3766479492188, "reward": 0.7520522475242615, "action": -1.584814190864563}
{"mode": "train", "epochs": 5, "timestep": 8974, "ep_reward": 550.0230712890625, "reward": 0.6464096307754517, "action": -0.7724325656890869}
{"mode": "train", "epochs": 5, "timestep": 8975, "ep_reward": 550.5347900390625, "reward": 0.5117065906524658, "action": -0.5776275992393494}
{"mode": "train", "epochs": 5, "timestep": 8976, "ep_reward": 550.884765625, "reward": 0.349986732006073, "action": -0.5902242660522461}
{"mode": "train", "epochs": 5, "timestep": 8977, "ep_reward": 551.1246337890625, "reward": 0.23986369371414185, "action": -1.540731430053711}
{"mode": "train", "epochs": 5, "timestep": 8978, "ep_reward": 551.2344970703125, "reward": 0.10987037420272827, "action": -1.5274771451950073}
{"mode": "train", "epochs": 5, "timestep": 8979, "ep_reward": 551.2401733398438, "reward": 0.005653560161590576, "action": -1.7849065065383911}
{"mode": "train", "epochs": 5, "timestep": 8980, "ep_reward": 551.3899536132812, "reward": 0.1497969627380371, "action": -1.8574790954589844}
{"mode": "train", "epochs": 5, "timestep": 8981, "ep_reward": 551.6685180664062, "reward": 0.2785656452178955, "action": -1.577732801437378}
{"mode": "train", "epochs": 5, "timestep": 8982, "ep_reward": 552.0789794921875, "reward": 0.4104808568954468, "action": -1.0090093612670898}
{"mode": "train", "epochs": 5, "timestep": 8983, "ep_reward": 552.6166381835938, "reward": 0.5376741290092468, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 8984, "ep_reward": 553.2503051757812, "reward": 0.6336373090744019, "action": -0.5023566484451294}
{"mode": "train", "epochs": 5, "timestep": 8985, "ep_reward": 553.9735107421875, "reward": 0.7232018709182739, "action": -0.8962293863296509}
{"mode": "train", "epochs": 5, "timestep": 8986, "ep_reward": 554.7570190429688, "reward": 0.7835378646850586, "action": -1.0640333890914917}
{"mode": "train", "epochs": 5, "timestep": 8987, "ep_reward": 555.5770263671875, "reward": 0.8200185894966125, "action": -1.006658673286438}
{"mode": "train", "epochs": 5, "timestep": 8988, "ep_reward": 556.4136962890625, "reward": 0.8366777896881104, "action": -0.9937498569488525}
{"mode": "train", "epochs": 5, "timestep": 8989, "ep_reward": 557.2471313476562, "reward": 0.8334486484527588, "action": -1.0538139343261719}
{"mode": "train", "epochs": 5, "timestep": 8990, "ep_reward": 558.05517578125, "reward": 0.8080337047576904, "action": 0.09837937355041504}
{"mode": "train", "epochs": 5, "timestep": 8991, "ep_reward": 558.8250122070312, "reward": 0.7698169350624084, "action": -1.2944481372833252}
{"mode": "train", "epochs": 5, "timestep": 8992, "ep_reward": 559.5116577148438, "reward": 0.6866684556007385, "action": -0.7242410182952881}
{"mode": "train", "epochs": 5, "timestep": 8993, "ep_reward": 560.0844116210938, "reward": 0.5727462768554688, "action": -1.162142038345337}
{"mode": "train", "epochs": 5, "timestep": 8994, "ep_reward": 560.4944458007812, "reward": 0.41005706787109375, "action": -1.1536530256271362}
{"mode": "train", "epochs": 5, "timestep": 8995, "ep_reward": 560.805419921875, "reward": 0.3109636902809143, "action": -1.0622248649597168}
{"mode": "train", "epochs": 5, "timestep": 8996, "ep_reward": 560.9989013671875, "reward": 0.1934959888458252, "action": -0.6819735765457153}
{"mode": "train", "epochs": 5, "timestep": 8997, "ep_reward": 561.0548706054688, "reward": 0.05597484111785889, "action": -0.8169466257095337}
{"mode": "train", "epochs": 5, "timestep": 8998, "ep_reward": 561.1171875, "reward": 0.06230425834655762, "action": -0.8648226261138916}
{"mode": "train", "epochs": 5, "timestep": 8999, "ep_reward": 561.3181762695312, "reward": 0.20099425315856934, "action": -1.5764708518981934}
{"mode": "train", "epochs": 5, "timestep": 9000, "ep_reward": 561.6519165039062, "reward": 0.3337153196334839, "action": -1.29012131690979}
{"mode": "train", "epochs": 5, "timestep": 9001, "ep_reward": 562.116943359375, "reward": 0.46502649784088135, "action": -1.2704007625579834}
{"mode": "train", "epochs": 5, "timestep": 9002, "ep_reward": 562.6984252929688, "reward": 0.5814814567565918, "action": -1.009721040725708}
{"mode": "train", "epochs": 5, "timestep": 9003, "ep_reward": 563.3778686523438, "reward": 0.6794416904449463, "action": -0.7348009347915649}
{"mode": "train", "epochs": 5, "timestep": 9004, "ep_reward": 564.1340942382812, "reward": 0.7562161684036255, "action": -1.0035974979400635}
{"mode": "train", "epochs": 5, "timestep": 9005, "ep_reward": 564.9415893554688, "reward": 0.8075151443481445, "action": -0.5785448551177979}
{"mode": "train", "epochs": 5, "timestep": 9006, "ep_reward": 565.7838745117188, "reward": 0.8422917723655701, "action": -0.8664351105690002}
{"mode": "train", "epochs": 5, "timestep": 9007, "ep_reward": 566.639892578125, "reward": 0.8560259938240051, "action": -0.6476190090179443}
{"mode": "train", "epochs": 5, "timestep": 9008, "ep_reward": 567.4938354492188, "reward": 0.8539441823959351, "action": -0.7682371735572815}
{"mode": "train", "epochs": 5, "timestep": 9009, "ep_reward": 568.3256225585938, "reward": 0.8317826986312866, "action": -1.4129287004470825}
{"mode": "train", "epochs": 5, "timestep": 9010, "ep_reward": 569.1060180664062, "reward": 0.7803815603256226, "action": -1.250894546508789}
{"mode": "train", "epochs": 5, "timestep": 9011, "ep_reward": 569.8065795898438, "reward": 0.7005767822265625, "action": -1.1675701141357422}
{"mode": "train", "epochs": 5, "timestep": 9012, "ep_reward": 570.3910522460938, "reward": 0.5844826698303223, "action": -0.9231752753257751}
{"mode": "train", "epochs": 5, "timestep": 9013, "ep_reward": 570.8202514648438, "reward": 0.4292052984237671, "action": -1.0520527362823486}
{"mode": "train", "epochs": 5, "timestep": 9014, "ep_reward": 571.138671875, "reward": 0.31840401887893677, "action": -1.6147270202636719}
{"mode": "train", "epochs": 5, "timestep": 9015, "ep_reward": 571.341064453125, "reward": 0.20238083600997925, "action": -1.183815836906433}
{"mode": "train", "epochs": 5, "timestep": 9016, "ep_reward": 571.4072875976562, "reward": 0.06624126434326172, "action": -1.4371565580368042}
{"mode": "train", "epochs": 5, "timestep": 9017, "ep_reward": 571.459228515625, "reward": 0.05194061994552612, "action": -0.5320684313774109}
{"mode": "train", "epochs": 5, "timestep": 9018, "ep_reward": 571.6536865234375, "reward": 0.19448214769363403, "action": -1.3407753705978394}
{"mode": "train", "epochs": 5, "timestep": 9019, "ep_reward": 571.9832763671875, "reward": 0.3295603394508362, "action": -1.2028446197509766}
{"mode": "train", "epochs": 5, "timestep": 9020, "ep_reward": 572.44482421875, "reward": 0.4615742564201355, "action": -0.9812331199645996}
{"mode": "train", "epochs": 5, "timestep": 9021, "ep_reward": 573.0264282226562, "reward": 0.5815895795822144, "action": -0.5066061019897461}
{"mode": "train", "epochs": 5, "timestep": 9022, "ep_reward": 573.7116088867188, "reward": 0.6851670742034912, "action": -0.878254234790802}
{"mode": "train", "epochs": 5, "timestep": 9023, "ep_reward": 574.4725952148438, "reward": 0.760958731174469, "action": -1.7360886335372925}
{"mode": "train", "epochs": 5, "timestep": 9024, "ep_reward": 575.2800903320312, "reward": 0.807490348815918, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9025, "ep_reward": 576.1132202148438, "reward": 0.8331301808357239, "action": -1.850993037223816}
{"mode": "train", "epochs": 5, "timestep": 9026, "ep_reward": 576.9552001953125, "reward": 0.8419892191886902, "action": -1.459904670715332}
{"mode": "train", "epochs": 5, "timestep": 9027, "ep_reward": 577.7904663085938, "reward": 0.8352609872817993, "action": -0.27637046575546265}
{"mode": "train", "epochs": 5, "timestep": 9028, "ep_reward": 578.6092529296875, "reward": 0.8187636137008667, "action": -1.070452332496643}
{"mode": "train", "epochs": 5, "timestep": 9029, "ep_reward": 579.379638671875, "reward": 0.7703773975372314, "action": -0.7108217477798462}
{"mode": "train", "epochs": 5, "timestep": 9030, "ep_reward": 580.0755615234375, "reward": 0.695915937423706, "action": -0.9845203161239624}
{"mode": "train", "epochs": 5, "timestep": 9031, "ep_reward": 580.6570434570312, "reward": 0.5814775228500366, "action": -1.6193503141403198}
{"mode": "train", "epochs": 5, "timestep": 9032, "ep_reward": 581.0712890625, "reward": 0.4142299294471741, "action": -0.553636372089386}
{"mode": "train", "epochs": 5, "timestep": 9033, "ep_reward": 581.3885498046875, "reward": 0.3172755241394043, "action": -1.236492395401001}
{"mode": "train", "epochs": 5, "timestep": 9034, "ep_reward": 581.5895385742188, "reward": 0.20097053050994873, "action": -1.1082249879837036}
{"mode": "train", "epochs": 5, "timestep": 9035, "ep_reward": 581.6541748046875, "reward": 0.0646662712097168, "action": -0.9618901014328003}
{"mode": "train", "epochs": 5, "timestep": 9036, "ep_reward": 581.7075805664062, "reward": 0.053388774394989014, "action": -1.9406360387802124}
{"mode": "train", "epochs": 5, "timestep": 9037, "ep_reward": 581.8989868164062, "reward": 0.1914212703704834, "action": -0.7525023221969604}
{"mode": "train", "epochs": 5, "timestep": 9038, "ep_reward": 582.2337036132812, "reward": 0.3347068428993225, "action": -1.0423256158828735}
{"mode": "train", "epochs": 5, "timestep": 9039, "ep_reward": 582.7015380859375, "reward": 0.4678621292114258, "action": -1.2778351306915283}
{"mode": "train", "epochs": 5, "timestep": 9040, "ep_reward": 583.2849731445312, "reward": 0.5834201574325562, "action": -1.2053908109664917}
{"mode": "train", "epochs": 5, "timestep": 9041, "ep_reward": 583.9644165039062, "reward": 0.6794734001159668, "action": -1.1449897289276123}
{"mode": "train", "epochs": 5, "timestep": 9042, "ep_reward": 584.7180786132812, "reward": 0.7536658048629761, "action": -0.5952099561691284}
{"mode": "train", "epochs": 5, "timestep": 9043, "ep_reward": 585.5288696289062, "reward": 0.8107970356941223, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9044, "ep_reward": 586.3646240234375, "reward": 0.8357439041137695, "action": -1.175203800201416}
{"mode": "train", "epochs": 5, "timestep": 9045, "ep_reward": 587.2145385742188, "reward": 0.849938690662384, "action": -1.8068946599960327}
{"mode": "train", "epochs": 5, "timestep": 9046, "ep_reward": 588.0546264648438, "reward": 0.8401136994361877, "action": -0.650741457939148}
{"mode": "train", "epochs": 5, "timestep": 9047, "ep_reward": 588.875, "reward": 0.8203983902931213, "action": -0.5355168581008911}
{"mode": "train", "epochs": 5, "timestep": 9048, "ep_reward": 589.6533813476562, "reward": 0.7783886790275574, "action": -1.0732817649841309}
{"mode": "train", "epochs": 5, "timestep": 9049, "ep_reward": 590.3549194335938, "reward": 0.7015193700790405, "action": -1.3311688899993896}
{"mode": "train", "epochs": 5, "timestep": 9050, "ep_reward": 590.9391479492188, "reward": 0.5842150449752808, "action": -0.8416138887405396}
{"mode": "train", "epochs": 5, "timestep": 9051, "ep_reward": 591.3696899414062, "reward": 0.43056201934814453, "action": -1.3322457075119019}
{"mode": "train", "epochs": 5, "timestep": 9052, "ep_reward": 591.6917724609375, "reward": 0.32208746671676636, "action": -0.9199062585830688}
{"mode": "train", "epochs": 5, "timestep": 9053, "ep_reward": 591.8984985351562, "reward": 0.20670783519744873, "action": -0.390328586101532}
{"mode": "train", "epochs": 5, "timestep": 9054, "ep_reward": 591.9697875976562, "reward": 0.07126647233963013, "action": -0.6772807240486145}
{"mode": "train", "epochs": 5, "timestep": 9055, "ep_reward": 592.0167236328125, "reward": 0.04693073034286499, "action": -0.4715917110443115}
{"mode": "train", "epochs": 5, "timestep": 9056, "ep_reward": 592.2067260742188, "reward": 0.18999123573303223, "action": -1.7418971061706543}
{"mode": "train", "epochs": 5, "timestep": 9057, "ep_reward": 592.52685546875, "reward": 0.3201313614845276, "action": -0.804681658744812}
{"mode": "train", "epochs": 5, "timestep": 9058, "ep_reward": 592.9850463867188, "reward": 0.458213746547699, "action": -0.6141369342803955}
{"mode": "train", "epochs": 5, "timestep": 9059, "ep_reward": 593.567626953125, "reward": 0.5825567245483398, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9060, "ep_reward": 594.23828125, "reward": 0.6706556081771851, "action": -1.437743067741394}
{"mode": "train", "epochs": 5, "timestep": 9061, "ep_reward": 594.9818115234375, "reward": 0.7435105443000793, "action": -1.3089524507522583}
{"mode": "train", "epochs": 5, "timestep": 9062, "ep_reward": 595.7774047851562, "reward": 0.795586109161377, "action": -1.4614109992980957}
{"mode": "train", "epochs": 5, "timestep": 9063, "ep_reward": 596.6030883789062, "reward": 0.82566237449646, "action": -1.0941435098648071}
{"mode": "train", "epochs": 5, "timestep": 9064, "ep_reward": 597.4425048828125, "reward": 0.8394410610198975, "action": -1.6849894523620605}
{"mode": "train", "epochs": 5, "timestep": 9065, "ep_reward": 598.2703857421875, "reward": 0.8278848528862, "action": -0.5172088742256165}
{"mode": "train", "epochs": 5, "timestep": 9066, "ep_reward": 599.07568359375, "reward": 0.8052956461906433, "action": -1.4154809713363647}
{"mode": "train", "epochs": 5, "timestep": 9067, "ep_reward": 599.8229370117188, "reward": 0.7472587823867798, "action": -0.5801056623458862}
{"mode": "train", "epochs": 5, "timestep": 9068, "ep_reward": 600.4889526367188, "reward": 0.6659917831420898, "action": -0.7043628096580505}
{"mode": "train", "epochs": 5, "timestep": 9069, "ep_reward": 601.033935546875, "reward": 0.5450054407119751, "action": -1.4834020137786865}
{"mode": "train", "epochs": 5, "timestep": 9070, "ep_reward": 601.4292602539062, "reward": 0.39530158042907715, "action": -0.3203818202018738}
{"mode": "train", "epochs": 5, "timestep": 9071, "ep_reward": 601.7239379882812, "reward": 0.294705331325531, "action": -1.377429723739624}
{"mode": "train", "epochs": 5, "timestep": 9072, "ep_reward": 601.8982543945312, "reward": 0.17431730031967163, "action": -0.6071428656578064}
{"mode": "train", "epochs": 5, "timestep": 9073, "ep_reward": 601.9320678710938, "reward": 0.03384363651275635, "action": -0.4705941677093506}
{"mode": "train", "epochs": 5, "timestep": 9074, "ep_reward": 602.0159912109375, "reward": 0.08392912149429321, "action": 0.40901243686676025}
{"mode": "train", "epochs": 5, "timestep": 9075, "ep_reward": 602.255126953125, "reward": 0.2391221523284912, "action": -0.8128982186317444}
{"mode": "train", "epochs": 5, "timestep": 9076, "ep_reward": 602.6324462890625, "reward": 0.3773428201675415, "action": -0.7800924181938171}
{"mode": "train", "epochs": 5, "timestep": 9077, "ep_reward": 603.1400756835938, "reward": 0.5076099634170532, "action": -1.726772427558899}
{"mode": "train", "epochs": 5, "timestep": 9078, "ep_reward": 603.7518310546875, "reward": 0.6117595434188843, "action": -1.1414393186569214}
{"mode": "train", "epochs": 5, "timestep": 9079, "ep_reward": 604.455078125, "reward": 0.7032535076141357, "action": -0.9042672514915466}
{"mode": "train", "epochs": 5, "timestep": 9080, "ep_reward": 605.2304077148438, "reward": 0.7753547430038452, "action": -1.8843879699707031}
{"mode": "train", "epochs": 5, "timestep": 9081, "ep_reward": 606.0492553710938, "reward": 0.8188765048980713, "action": -1.5071035623550415}
{"mode": "train", "epochs": 5, "timestep": 9082, "ep_reward": 606.897705078125, "reward": 0.8484542965888977, "action": -0.6348419189453125}
{"mode": "train", "epochs": 5, "timestep": 9083, "ep_reward": 607.7664184570312, "reward": 0.8686923980712891, "action": -0.9020318388938904}
{"mode": "train", "epochs": 5, "timestep": 9084, "ep_reward": 608.6370849609375, "reward": 0.8706902265548706, "action": -1.1120243072509766}
{"mode": "train", "epochs": 5, "timestep": 9085, "ep_reward": 609.4913940429688, "reward": 0.8542797565460205, "action": -0.6922076940536499}
{"mode": "train", "epochs": 5, "timestep": 9086, "ep_reward": 610.3135986328125, "reward": 0.8221907019615173, "action": -1.1397380828857422}
{"mode": "train", "epochs": 5, "timestep": 9087, "ep_reward": 611.0753173828125, "reward": 0.7616924047470093, "action": -0.785839319229126}
{"mode": "train", "epochs": 5, "timestep": 9088, "ep_reward": 611.7494506835938, "reward": 0.6741371154785156, "action": -1.6750521659851074}
{"mode": "train", "epochs": 5, "timestep": 9089, "ep_reward": 612.286376953125, "reward": 0.5369232892990112, "action": -1.7350101470947266}
{"mode": "train", "epochs": 5, "timestep": 9090, "ep_reward": 612.663330078125, "reward": 0.37698155641555786, "action": -0.14055466651916504}
{"mode": "train", "epochs": 5, "timestep": 9091, "ep_reward": 612.9357299804688, "reward": 0.27240222692489624, "action": -1.4586994647979736}
{"mode": "train", "epochs": 5, "timestep": 9092, "ep_reward": 613.0838012695312, "reward": 0.14804834127426147, "action": -0.7976229190826416}
{"mode": "train", "epochs": 5, "timestep": 9093, "ep_reward": 613.0874633789062, "reward": 0.0036406517028808594, "action": 0.12924957275390625}
{"mode": "train", "epochs": 5, "timestep": 9094, "ep_reward": 613.1993408203125, "reward": 0.11187779903411865, "action": -1.509178876876831}
{"mode": "train", "epochs": 5, "timestep": 9095, "ep_reward": 613.443359375, "reward": 0.24404650926589966, "action": -1.5173931121826172}
{"mode": "train", "epochs": 5, "timestep": 9096, "ep_reward": 613.8209838867188, "reward": 0.3776305317878723, "action": -0.16026020050048828}
{"mode": "train", "epochs": 5, "timestep": 9097, "ep_reward": 614.33935546875, "reward": 0.5183824300765991, "action": -1.6810672283172607}
{"mode": "train", "epochs": 5, "timestep": 9098, "ep_reward": 614.9609985351562, "reward": 0.62166827917099, "action": -0.7023781538009644}
{"mode": "train", "epochs": 5, "timestep": 9099, "ep_reward": 615.6749267578125, "reward": 0.7139391899108887, "action": -1.2582660913467407}
{"mode": "train", "epochs": 5, "timestep": 9100, "ep_reward": 616.4521484375, "reward": 0.7772255539894104, "action": -0.2585211992263794}
{"mode": "train", "epochs": 5, "timestep": 9101, "ep_reward": 617.2803955078125, "reward": 0.8282381296157837, "action": -1.7534384727478027}
{"mode": "train", "epochs": 5, "timestep": 9102, "ep_reward": 618.1270751953125, "reward": 0.8466733694076538, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9103, "ep_reward": 618.972412109375, "reward": 0.8453338742256165, "action": -0.616320013999939}
{"mode": "train", "epochs": 5, "timestep": 9104, "ep_reward": 619.8096313476562, "reward": 0.8372316360473633, "action": -1.167787790298462}
{"mode": "train", "epochs": 5, "timestep": 9105, "ep_reward": 620.6118774414062, "reward": 0.8022735714912415, "action": -1.3063522577285767}
{"mode": "train", "epochs": 5, "timestep": 9106, "ep_reward": 621.3506469726562, "reward": 0.7387496829032898, "action": -1.1451208591461182}
{"mode": "train", "epochs": 5, "timestep": 9107, "ep_reward": 621.9933471679688, "reward": 0.6426945924758911, "action": -1.504270315170288}
{"mode": "train", "epochs": 5, "timestep": 9108, "ep_reward": 622.493408203125, "reward": 0.5000419616699219, "action": 0.20632171630859375}
{"mode": "train", "epochs": 5, "timestep": 9109, "ep_reward": 622.8656616210938, "reward": 0.3722265958786011, "action": -0.33799445629119873}
{"mode": "train", "epochs": 5, "timestep": 9110, "ep_reward": 623.13232421875, "reward": 0.2666650414466858, "action": -1.3900550603866577}
{"mode": "train", "epochs": 5, "timestep": 9111, "ep_reward": 623.2736206054688, "reward": 0.14128071069717407, "action": -0.9614178538322449}
{"mode": "train", "epochs": 5, "timestep": 9112, "ep_reward": 623.2694091796875, "reward": -0.0042351484298706055, "action": -1.4245693683624268}
{"mode": "train", "epochs": 5, "timestep": 9113, "ep_reward": 623.3883056640625, "reward": 0.11889064311981201, "action": -1.2157636880874634}
{"mode": "train", "epochs": 5, "timestep": 9114, "ep_reward": 623.643310546875, "reward": 0.2549784779548645, "action": -1.141879677772522}
{"mode": "train", "epochs": 5, "timestep": 9115, "ep_reward": 624.0353393554688, "reward": 0.3920060396194458, "action": -1.6040220260620117}
{"mode": "train", "epochs": 5, "timestep": 9116, "ep_reward": 624.5491333007812, "reward": 0.5138136148452759, "action": -0.38328248262405396}
{"mode": "train", "epochs": 5, "timestep": 9117, "ep_reward": 625.1810913085938, "reward": 0.6319494247436523, "action": -0.7216799259185791}
{"mode": "train", "epochs": 5, "timestep": 9118, "ep_reward": 625.9031982421875, "reward": 0.7221177816390991, "action": -0.3851383328437805}
{"mode": "train", "epochs": 5, "timestep": 9119, "ep_reward": 626.695068359375, "reward": 0.7918746471405029, "action": -1.4556262493133545}
{"mode": "train", "epochs": 5, "timestep": 9120, "ep_reward": 627.5262451171875, "reward": 0.831198513507843, "action": -0.2959268093109131}
{"mode": "train", "epochs": 5, "timestep": 9121, "ep_reward": 628.3888549804688, "reward": 0.8625836372375488, "action": -0.8420889973640442}
{"mode": "train", "epochs": 5, "timestep": 9122, "ep_reward": 629.2616577148438, "reward": 0.8727985620498657, "action": -1.344313383102417}
{"mode": "train", "epochs": 5, "timestep": 9123, "ep_reward": 630.1245727539062, "reward": 0.8629211187362671, "action": -0.5369181632995605}
{"mode": "train", "epochs": 5, "timestep": 9124, "ep_reward": 630.9666748046875, "reward": 0.8421159386634827, "action": -1.2712193727493286}
{"mode": "train", "epochs": 5, "timestep": 9125, "ep_reward": 631.759765625, "reward": 0.7930727005004883, "action": -0.5692430138587952}
{"mode": "train", "epochs": 5, "timestep": 9126, "ep_reward": 632.4837036132812, "reward": 0.7239216566085815, "action": -0.31746983528137207}
{"mode": "train", "epochs": 5, "timestep": 9127, "ep_reward": 633.1092529296875, "reward": 0.6255518198013306, "action": -0.8445073962211609}
{"mode": "train", "epochs": 5, "timestep": 9128, "ep_reward": 633.5919799804688, "reward": 0.4827422499656677, "action": -0.7975417375564575}
{"mode": "train", "epochs": 5, "timestep": 9129, "ep_reward": 633.9247436523438, "reward": 0.33274132013320923, "action": -0.9961432218551636}
{"mode": "train", "epochs": 5, "timestep": 9130, "ep_reward": 634.14404296875, "reward": 0.21929866075515747, "action": -1.4116299152374268}
{"mode": "train", "epochs": 5, "timestep": 9131, "ep_reward": 634.2298583984375, "reward": 0.08579361438751221, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9132, "ep_reward": 634.261474609375, "reward": 0.031605541706085205, "action": -0.8373394012451172}
{"mode": "train", "epochs": 5, "timestep": 9133, "ep_reward": 634.4337768554688, "reward": 0.17232495546340942, "action": -1.267555832862854}
{"mode": "train", "epochs": 5, "timestep": 9134, "ep_reward": 634.74267578125, "reward": 0.308904230594635, "action": -1.5115032196044922}
{"mode": "train", "epochs": 5, "timestep": 9135, "ep_reward": 635.1817016601562, "reward": 0.43903350830078125, "action": -0.5853862762451172}
{"mode": "train", "epochs": 5, "timestep": 9136, "ep_reward": 635.7487182617188, "reward": 0.5670163631439209, "action": -0.8190926909446716}
{"mode": "train", "epochs": 5, "timestep": 9137, "ep_reward": 636.4190673828125, "reward": 0.6703364849090576, "action": -0.8915389776229858}
{"mode": "train", "epochs": 5, "timestep": 9138, "ep_reward": 637.1685180664062, "reward": 0.7494211792945862, "action": -0.8658148646354675}
{"mode": "train", "epochs": 5, "timestep": 9139, "ep_reward": 637.9749755859375, "reward": 0.8064852356910706, "action": 0.03493964672088623}
{"mode": "train", "epochs": 5, "timestep": 9140, "ep_reward": 638.826171875, "reward": 0.8512118458747864, "action": -0.6887146234512329}
{"mode": "train", "epochs": 5, "timestep": 9141, "ep_reward": 639.6981811523438, "reward": 0.8720104694366455, "action": -1.2411103248596191}
{"mode": "train", "epochs": 5, "timestep": 9142, "ep_reward": 640.571044921875, "reward": 0.8728812336921692, "action": -0.2694437503814697}
{"mode": "train", "epochs": 5, "timestep": 9143, "ep_reward": 641.4368896484375, "reward": 0.8658627271652222, "action": -1.1506094932556152}
{"mode": "train", "epochs": 5, "timestep": 9144, "ep_reward": 642.2702026367188, "reward": 0.8333331346511841, "action": -1.039347529411316}
{"mode": "train", "epochs": 5, "timestep": 9145, "ep_reward": 643.049072265625, "reward": 0.7788453102111816, "action": -1.1264963150024414}
{"mode": "train", "epochs": 5, "timestep": 9146, "ep_reward": 643.7431030273438, "reward": 0.6940328478813171, "action": -0.5976195335388184}
{"mode": "train", "epochs": 5, "timestep": 9147, "ep_reward": 644.322998046875, "reward": 0.5798825025558472, "action": -0.9178617000579834}
{"mode": "train", "epochs": 5, "timestep": 9148, "ep_reward": 644.7447509765625, "reward": 0.4217263460159302, "action": -0.8099702000617981}
{"mode": "train", "epochs": 5, "timestep": 9149, "ep_reward": 645.0415649414062, "reward": 0.2968067526817322, "action": -0.6427371501922607}
{"mode": "train", "epochs": 5, "timestep": 9150, "ep_reward": 645.21826171875, "reward": 0.176672101020813, "action": -0.8110808730125427}
{"mode": "train", "epochs": 5, "timestep": 9151, "ep_reward": 645.2547607421875, "reward": 0.03650933504104614, "action": -1.167490839958191}
{"mode": "train", "epochs": 5, "timestep": 9152, "ep_reward": 645.3359375, "reward": 0.08120507001876831, "action": -1.354843020439148}
{"mode": "train", "epochs": 5, "timestep": 9153, "ep_reward": 645.5512084960938, "reward": 0.21525061130523682, "action": -1.3036668300628662}
{"mode": "train", "epochs": 5, "timestep": 9154, "ep_reward": 645.9031372070312, "reward": 0.3519405722618103, "action": -0.7755858302116394}
{"mode": "train", "epochs": 5, "timestep": 9155, "ep_reward": 646.3910522460938, "reward": 0.48789530992507935, "action": -0.659930944442749}
{"mode": "train", "epochs": 5, "timestep": 9156, "ep_reward": 646.998291015625, "reward": 0.6072471141815186, "action": -1.74399995803833}
{"mode": "train", "epochs": 5, "timestep": 9157, "ep_reward": 647.6909790039062, "reward": 0.6927109956741333, "action": -1.7118892669677734}
{"mode": "train", "epochs": 5, "timestep": 9158, "ep_reward": 648.4481201171875, "reward": 0.7571597099304199, "action": -0.7500133514404297}
{"mode": "train", "epochs": 5, "timestep": 9159, "ep_reward": 649.2572631835938, "reward": 0.8091210126876831, "action": -1.8452963829040527}
{"mode": "train", "epochs": 5, "timestep": 9160, "ep_reward": 650.0879516601562, "reward": 0.8306844234466553, "action": -1.0850818157196045}
{"mode": "train", "epochs": 5, "timestep": 9161, "ep_reward": 650.9278564453125, "reward": 0.8399288654327393, "action": -1.3228919506072998}
{"mode": "train", "epochs": 5, "timestep": 9162, "ep_reward": 651.754638671875, "reward": 0.8267741203308105, "action": -1.418833613395691}
{"mode": "train", "epochs": 5, "timestep": 9163, "ep_reward": 652.5440063476562, "reward": 0.7893928289413452, "action": -1.1158584356307983}
{"mode": "train", "epochs": 5, "timestep": 9164, "ep_reward": 653.2706298828125, "reward": 0.7265998721122742, "action": -0.5359311103820801}
{"mode": "train", "epochs": 5, "timestep": 9165, "ep_reward": 653.906982421875, "reward": 0.636350154876709, "action": -0.7987180948257446}
{"mode": "train", "epochs": 5, "timestep": 9166, "ep_reward": 654.4097900390625, "reward": 0.5027916431427002, "action": -0.9784423112869263}
{"mode": "train", "epochs": 5, "timestep": 9167, "ep_reward": 654.7813110351562, "reward": 0.37149572372436523, "action": -1.7259938716888428}
{"mode": "train", "epochs": 5, "timestep": 9168, "ep_reward": 655.04736328125, "reward": 0.26605671644210815, "action": -0.9936738014221191}
{"mode": "train", "epochs": 5, "timestep": 9169, "ep_reward": 655.1878662109375, "reward": 0.1405237913131714, "action": -0.7123404741287231}
{"mode": "train", "epochs": 5, "timestep": 9170, "ep_reward": 655.1827392578125, "reward": -0.00510561466217041, "action": -1.2571653127670288}
{"mode": "train", "epochs": 5, "timestep": 9171, "ep_reward": 655.302490234375, "reward": 0.11977744102478027, "action": -0.3278815746307373}
{"mode": "train", "epochs": 5, "timestep": 9172, "ep_reward": 655.5692749023438, "reward": 0.26679927110671997, "action": -1.605546474456787}
{"mode": "train", "epochs": 5, "timestep": 9173, "ep_reward": 655.9653930664062, "reward": 0.3960953950881958, "action": -1.2126551866531372}
{"mode": "train", "epochs": 5, "timestep": 9174, "ep_reward": 656.4867553710938, "reward": 0.5213620662689209, "action": -1.7562570571899414}
{"mode": "train", "epochs": 5, "timestep": 9175, "ep_reward": 657.10986328125, "reward": 0.6231191754341125, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9176, "ep_reward": 657.8118896484375, "reward": 0.7020379304885864, "action": -0.6833683252334595}
{"mode": "train", "epochs": 5, "timestep": 9177, "ep_reward": 658.583984375, "reward": 0.7720773816108704, "action": -1.0096702575683594}
{"mode": "train", "epochs": 5, "timestep": 9178, "ep_reward": 659.4002685546875, "reward": 0.8162969946861267, "action": -1.1762144565582275}
{"mode": "train", "epochs": 5, "timestep": 9179, "ep_reward": 660.2391357421875, "reward": 0.8388426899909973, "action": -1.7811455726623535}
{"mode": "train", "epochs": 5, "timestep": 9180, "ep_reward": 661.0759887695312, "reward": 0.8368281722068787, "action": -0.917243480682373}
{"mode": "train", "epochs": 5, "timestep": 9181, "ep_reward": 661.8982543945312, "reward": 0.8222454786300659, "action": -0.5374921560287476}
{"mode": "train", "epochs": 5, "timestep": 9182, "ep_reward": 662.6864624023438, "reward": 0.7882348299026489, "action": -1.1363266706466675}
{"mode": "train", "epochs": 5, "timestep": 9183, "ep_reward": 663.4063110351562, "reward": 0.7198548316955566, "action": -0.03330951929092407}
{"mode": "train", "epochs": 5, "timestep": 9184, "ep_reward": 664.0370483398438, "reward": 0.6307426691055298, "action": -0.9675201177597046}
{"mode": "train", "epochs": 5, "timestep": 9185, "ep_reward": 664.527587890625, "reward": 0.4905524253845215, "action": -0.9816606640815735}
{"mode": "train", "epochs": 5, "timestep": 9186, "ep_reward": 664.884033203125, "reward": 0.35643237829208374, "action": -0.8615004420280457}
{"mode": "train", "epochs": 5, "timestep": 9187, "ep_reward": 665.1317749023438, "reward": 0.2477576732635498, "action": -0.6596873998641968}
{"mode": "train", "epochs": 5, "timestep": 9188, "ep_reward": 665.2507934570312, "reward": 0.11902540922164917, "action": -1.0283074378967285}
{"mode": "train", "epochs": 5, "timestep": 9189, "ep_reward": 665.2463989257812, "reward": -0.004422307014465332, "action": -1.7543467283248901}
{"mode": "train", "epochs": 5, "timestep": 9190, "ep_reward": 665.387451171875, "reward": 0.14105552434921265, "action": -1.6828062534332275}
{"mode": "train", "epochs": 5, "timestep": 9191, "ep_reward": 665.6593627929688, "reward": 0.27192407846450806, "action": -0.7825797200202942}
{"mode": "train", "epochs": 5, "timestep": 9192, "ep_reward": 666.0728759765625, "reward": 0.41352492570877075, "action": -1.3569424152374268}
{"mode": "train", "epochs": 5, "timestep": 9193, "ep_reward": 666.6085815429688, "reward": 0.5357297658920288, "action": -1.271158218383789}
{"mode": "train", "epochs": 5, "timestep": 9194, "ep_reward": 667.248779296875, "reward": 0.6401770114898682, "action": -1.3852896690368652}
{"mode": "train", "epochs": 5, "timestep": 9195, "ep_reward": 667.9697265625, "reward": 0.7209224700927734, "action": -1.1385502815246582}
{"mode": "train", "epochs": 5, "timestep": 9196, "ep_reward": 668.7510986328125, "reward": 0.7813519835472107, "action": -1.176597237586975}
{"mode": "train", "epochs": 5, "timestep": 9197, "ep_reward": 669.5709838867188, "reward": 0.819911777973175, "action": -0.30632686614990234}
{"mode": "train", "epochs": 5, "timestep": 9198, "ep_reward": 670.4173583984375, "reward": 0.8464047908782959, "action": -1.0531500577926636}
{"mode": "train", "epochs": 5, "timestep": 9199, "ep_reward": 671.2645263671875, "reward": 0.8471817970275879, "action": -1.5542263984680176}
{"mode": "train", "epochs": 5, "timestep": 9200, "ep_reward": 672.087890625, "reward": 0.8233703970909119, "action": -1.542323350906372}
{"mode": "train", "epochs": 5, "timestep": 9201, "ep_reward": 672.8630981445312, "reward": 0.7752191424369812, "action": -0.6616663932800293}
{"mode": "train", "epochs": 5, "timestep": 9202, "ep_reward": 673.5697021484375, "reward": 0.7066274881362915, "action": -1.077396035194397}
{"mode": "train", "epochs": 5, "timestep": 9203, "ep_reward": 674.166748046875, "reward": 0.5970296859741211, "action": -0.33596497774124146}
{"mode": "train", "epochs": 5, "timestep": 9204, "ep_reward": 674.6231079101562, "reward": 0.45634007453918457, "action": -0.8033347129821777}
{"mode": "train", "epochs": 5, "timestep": 9205, "ep_reward": 674.96044921875, "reward": 0.33735620975494385, "action": -0.9347698092460632}
{"mode": "train", "epochs": 5, "timestep": 9206, "ep_reward": 675.1851806640625, "reward": 0.22475790977478027, "action": -1.6387865543365479}
{"mode": "train", "epochs": 5, "timestep": 9207, "ep_reward": 675.2775268554688, "reward": 0.0923762321472168, "action": -1.0207152366638184}
{"mode": "train", "epochs": 5, "timestep": 9208, "ep_reward": 675.3024291992188, "reward": 0.02488023042678833, "action": -0.052111923694610596}
{"mode": "train", "epochs": 5, "timestep": 9209, "ep_reward": 675.4749755859375, "reward": 0.17255938053131104, "action": -1.02734375}
{"mode": "train", "epochs": 5, "timestep": 9210, "ep_reward": 675.78564453125, "reward": 0.31066298484802246, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9211, "ep_reward": 676.21923828125, "reward": 0.4336065649986267, "action": -1.1755802631378174}
{"mode": "train", "epochs": 5, "timestep": 9212, "ep_reward": 676.7747192382812, "reward": 0.5554722547531128, "action": -0.5299754738807678}
{"mode": "train", "epochs": 5, "timestep": 9213, "ep_reward": 677.4387817382812, "reward": 0.6640480160713196, "action": -1.0613738298416138}
{"mode": "train", "epochs": 5, "timestep": 9214, "ep_reward": 678.181884765625, "reward": 0.7431209087371826, "action": -0.5802134871482849}
{"mode": "train", "epochs": 5, "timestep": 9215, "ep_reward": 678.9862670898438, "reward": 0.8043857216835022, "action": -0.6026998162269592}
{"mode": "train", "epochs": 5, "timestep": 9216, "ep_reward": 679.8311157226562, "reward": 0.8448680639266968, "action": -0.8728541135787964}
{"mode": "train", "epochs": 5, "timestep": 9217, "ep_reward": 680.696533203125, "reward": 0.8654105067253113, "action": -0.4729442000389099}
{"mode": "train", "epochs": 5, "timestep": 9218, "ep_reward": 681.5697021484375, "reward": 0.8731687664985657, "action": -0.5134624242782593}
{"mode": "train", "epochs": 5, "timestep": 9219, "ep_reward": 682.4342041015625, "reward": 0.8644914627075195, "action": -1.290541648864746}
{"mode": "train", "epochs": 5, "timestep": 9220, "ep_reward": 683.2650756835938, "reward": 0.8308531641960144, "action": -0.9415091276168823}
{"mode": "train", "epochs": 5, "timestep": 9221, "ep_reward": 684.042236328125, "reward": 0.7771866917610168, "action": -1.2682533264160156}
{"mode": "train", "epochs": 5, "timestep": 9222, "ep_reward": 684.7326049804688, "reward": 0.6903424859046936, "action": -0.8639963269233704}
{"mode": "train", "epochs": 5, "timestep": 9223, "ep_reward": 685.3041381835938, "reward": 0.5715112686157227, "action": -0.9297844171524048}
{"mode": "train", "epochs": 5, "timestep": 9224, "ep_reward": 685.7149658203125, "reward": 0.41081172227859497, "action": -1.575018048286438}
{"mode": "train", "epochs": 5, "timestep": 9225, "ep_reward": 686.0090942382812, "reward": 0.2941036820411682, "action": -1.674056053161621}
{"mode": "train", "epochs": 5, "timestep": 9226, "ep_reward": 686.1826782226562, "reward": 0.17358189821243286, "action": -1.3557934761047363}
{"mode": "train", "epochs": 5, "timestep": 9227, "ep_reward": 686.2156982421875, "reward": 0.03300565481185913, "action": -1.3244279623031616}
{"mode": "train", "epochs": 5, "timestep": 9228, "ep_reward": 686.3002319335938, "reward": 0.08453953266143799, "action": -1.3151271343231201}
{"mode": "train", "epochs": 5, "timestep": 9229, "ep_reward": 686.5186157226562, "reward": 0.218400239944458, "action": -1.0456687211990356}
{"mode": "train", "epochs": 5, "timestep": 9230, "ep_reward": 686.8767700195312, "reward": 0.3581386208534241, "action": -1.479746699333191}
{"mode": "train", "epochs": 5, "timestep": 9231, "ep_reward": 687.3616943359375, "reward": 0.48492002487182617, "action": -0.035618722438812256}
{"mode": "train", "epochs": 5, "timestep": 9232, "ep_reward": 687.9735717773438, "reward": 0.6118727922439575, "action": -1.0304700136184692}
{"mode": "train", "epochs": 5, "timestep": 9233, "ep_reward": 688.6773681640625, "reward": 0.7037862539291382, "action": -0.777646541595459}
{"mode": "train", "epochs": 5, "timestep": 9234, "ep_reward": 689.45263671875, "reward": 0.7752929925918579, "action": -1.5550211668014526}
{"mode": "train", "epochs": 5, "timestep": 9235, "ep_reward": 690.2713623046875, "reward": 0.8187008500099182, "action": -0.9158861041069031}
{"mode": "train", "epochs": 5, "timestep": 9236, "ep_reward": 691.1206665039062, "reward": 0.8493081331253052, "action": 0.11088097095489502}
{"mode": "train", "epochs": 5, "timestep": 9237, "ep_reward": 691.9918212890625, "reward": 0.8711663484573364, "action": -0.7654121518135071}
{"mode": "train", "epochs": 5, "timestep": 9238, "ep_reward": 692.8612670898438, "reward": 0.8694173097610474, "action": -0.7688064575195312}
{"mode": "train", "epochs": 5, "timestep": 9239, "ep_reward": 693.7119140625, "reward": 0.8506531715393066, "action": -1.460629940032959}
{"mode": "train", "epochs": 5, "timestep": 9240, "ep_reward": 694.5169677734375, "reward": 0.8050593733787537, "action": -0.7747749090194702}
{"mode": "train", "epochs": 5, "timestep": 9241, "ep_reward": 695.2567749023438, "reward": 0.7398312091827393, "action": -0.8075924515724182}
{"mode": "train", "epochs": 5, "timestep": 9242, "ep_reward": 695.8986206054688, "reward": 0.6418410539627075, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9243, "ep_reward": 696.3861083984375, "reward": 0.48745864629745483, "action": -1.8823237419128418}
{"mode": "train", "epochs": 5, "timestep": 9244, "ep_reward": 696.735107421875, "reward": 0.34901154041290283, "action": -1.4610618352890015}
{"mode": "train", "epochs": 5, "timestep": 9245, "ep_reward": 696.9739990234375, "reward": 0.2389134168624878, "action": -0.9998431205749512}
{"mode": "train", "epochs": 5, "timestep": 9246, "ep_reward": 697.082763671875, "reward": 0.10873633623123169, "action": -1.0669020414352417}
{"mode": "train", "epochs": 5, "timestep": 9247, "ep_reward": 697.08984375, "reward": 0.007080495357513428, "action": -1.275156021118164}
{"mode": "train", "epochs": 5, "timestep": 9248, "ep_reward": 697.2407836914062, "reward": 0.1509670615196228, "action": -1.799424648284912}
{"mode": "train", "epochs": 5, "timestep": 9249, "ep_reward": 697.5213623046875, "reward": 0.28056514263153076, "action": -1.1278846263885498}
{"mode": "train", "epochs": 5, "timestep": 9250, "ep_reward": 697.9390869140625, "reward": 0.4177529811859131, "action": -1.2724592685699463}
{"mode": "train", "epochs": 5, "timestep": 9251, "ep_reward": 698.4797973632812, "reward": 0.5407333374023438, "action": -1.383177399635315}
{"mode": "train", "epochs": 5, "timestep": 9252, "ep_reward": 699.1227416992188, "reward": 0.6429203748703003, "action": -1.2383005619049072}
{"mode": "train", "epochs": 5, "timestep": 9253, "ep_reward": 699.8465576171875, "reward": 0.7238140106201172, "action": -0.4499107003211975}
{"mode": "train", "epochs": 5, "timestep": 9254, "ep_reward": 700.6354370117188, "reward": 0.7889046669006348, "action": -0.5155530571937561}
{"mode": "train", "epochs": 5, "timestep": 9255, "ep_reward": 701.4662475585938, "reward": 0.8308409452438354, "action": -1.0169848203659058}
{"mode": "train", "epochs": 5, "timestep": 9256, "ep_reward": 702.3150024414062, "reward": 0.8487765789031982, "action": -0.9135944843292236}
{"mode": "train", "epochs": 5, "timestep": 9257, "ep_reward": 703.1641845703125, "reward": 0.8491990566253662, "action": -1.630914330482483}
{"mode": "train", "epochs": 5, "timestep": 9258, "ep_reward": 703.9874877929688, "reward": 0.8233013153076172, "action": -0.9486128091812134}
{"mode": "train", "epochs": 5, "timestep": 9259, "ep_reward": 704.767578125, "reward": 0.7800607085227966, "action": -0.9061141610145569}
{"mode": "train", "epochs": 5, "timestep": 9260, "ep_reward": 705.4757690429688, "reward": 0.7081945538520813, "action": -1.0248420238494873}
{"mode": "train", "epochs": 5, "timestep": 9261, "ep_reward": 706.07470703125, "reward": 0.5989080667495728, "action": -0.35780084133148193}
{"mode": "train", "epochs": 5, "timestep": 9262, "ep_reward": 706.5326538085938, "reward": 0.45792603492736816, "action": -0.7455434799194336}
{"mode": "train", "epochs": 5, "timestep": 9263, "ep_reward": 706.8675537109375, "reward": 0.334877073764801, "action": -1.8939588069915771}
{"mode": "train", "epochs": 5, "timestep": 9264, "ep_reward": 707.0896606445312, "reward": 0.2221289873123169, "action": -0.7736606001853943}
{"mode": "train", "epochs": 5, "timestep": 9265, "ep_reward": 707.1787719726562, "reward": 0.08911991119384766, "action": -1.340954065322876}
{"mode": "train", "epochs": 5, "timestep": 9266, "ep_reward": 707.2069702148438, "reward": 0.028193295001983643, "action": -1.217786431312561}
{"mode": "train", "epochs": 5, "timestep": 9267, "ep_reward": 707.37646484375, "reward": 0.16948843002319336, "action": -0.5527411103248596}
{"mode": "train", "epochs": 5, "timestep": 9268, "ep_reward": 707.69140625, "reward": 0.3149667978286743, "action": -0.612949550151825}
{"mode": "train", "epochs": 5, "timestep": 9269, "ep_reward": 708.1454467773438, "reward": 0.4540669322013855, "action": -1.3121368885040283}
{"mode": "train", "epochs": 5, "timestep": 9270, "ep_reward": 708.7161865234375, "reward": 0.5707442164421082, "action": -1.1455738544464111}
{"mode": "train", "epochs": 5, "timestep": 9271, "ep_reward": 709.3864135742188, "reward": 0.6702409982681274, "action": -0.8585823774337769}
{"mode": "train", "epochs": 5, "timestep": 9272, "ep_reward": 710.1369018554688, "reward": 0.7505061030387878, "action": -1.1027348041534424}
{"mode": "train", "epochs": 5, "timestep": 9273, "ep_reward": 710.9437255859375, "reward": 0.8068382740020752, "action": -1.141090989112854}
{"mode": "train", "epochs": 5, "timestep": 9274, "ep_reward": 711.7874755859375, "reward": 0.8437637090682983, "action": -1.2414531707763672}
{"mode": "train", "epochs": 5, "timestep": 9275, "ep_reward": 712.6502075195312, "reward": 0.8627156019210815, "action": -1.7548874616622925}
{"mode": "train", "epochs": 5, "timestep": 9276, "ep_reward": 713.5114135742188, "reward": 0.861203134059906, "action": -0.8401376008987427}
{"mode": "train", "epochs": 5, "timestep": 9277, "ep_reward": 714.3613891601562, "reward": 0.8499752283096313, "action": -1.3194019794464111}
{"mode": "train", "epochs": 5, "timestep": 9278, "ep_reward": 715.1755981445312, "reward": 0.8142277598381042, "action": -0.528035044670105}
{"mode": "train", "epochs": 5, "timestep": 9279, "ep_reward": 715.9371337890625, "reward": 0.7615275382995605, "action": -0.8186975717544556}
{"mode": "train", "epochs": 5, "timestep": 9280, "ep_reward": 716.6124877929688, "reward": 0.6753358840942383, "action": -1.901104211807251}
{"mode": "train", "epochs": 5, "timestep": 9281, "ep_reward": 717.14892578125, "reward": 0.5364675521850586, "action": 0.21442484855651855}
{"mode": "train", "epochs": 5, "timestep": 9282, "ep_reward": 717.5345458984375, "reward": 0.3855985403060913, "action": -0.3677036762237549}
{"mode": "train", "epochs": 5, "timestep": 9283, "ep_reward": 717.8145141601562, "reward": 0.27998673915863037, "action": -1.110051155090332}
{"mode": "train", "epochs": 5, "timestep": 9284, "ep_reward": 717.97119140625, "reward": 0.15669000148773193, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9285, "ep_reward": 717.9849853515625, "reward": 0.013799130916595459, "action": -0.5320985317230225}
{"mode": "train", "epochs": 5, "timestep": 9286, "ep_reward": 718.0875854492188, "reward": 0.10259336233139038, "action": -1.4926612377166748}
{"mode": "train", "epochs": 5, "timestep": 9287, "ep_reward": 718.3223876953125, "reward": 0.2347731590270996, "action": -1.023415207862854}
{"mode": "train", "epochs": 5, "timestep": 9288, "ep_reward": 718.6970825195312, "reward": 0.37471234798431396, "action": -0.7628607749938965}
{"mode": "train", "epochs": 5, "timestep": 9289, "ep_reward": 719.2053833007812, "reward": 0.508326530456543, "action": -0.8043095469474792}
{"mode": "train", "epochs": 5, "timestep": 9290, "ep_reward": 719.8281860351562, "reward": 0.6227883100509644, "action": -0.8576847910881042}
{"mode": "train", "epochs": 5, "timestep": 9291, "ep_reward": 720.5421142578125, "reward": 0.7139319181442261, "action": -0.4538736343383789}
{"mode": "train", "epochs": 5, "timestep": 9292, "ep_reward": 721.3277587890625, "reward": 0.7856506705284119, "action": -1.5239988565444946}
{"mode": "train", "epochs": 5, "timestep": 9293, "ep_reward": 722.154541015625, "reward": 0.8267573118209839, "action": -1.075286865234375}
{"mode": "train", "epochs": 5, "timestep": 9294, "ep_reward": 723.0084838867188, "reward": 0.8539316654205322, "action": -0.9513195157051086}
{"mode": "train", "epochs": 5, "timestep": 9295, "ep_reward": 723.8738403320312, "reward": 0.8653290271759033, "action": -0.6861140727996826}
{"mode": "train", "epochs": 5, "timestep": 9296, "ep_reward": 724.7362060546875, "reward": 0.862383246421814, "action": -0.47979336977005005}
{"mode": "train", "epochs": 5, "timestep": 9297, "ep_reward": 725.5797729492188, "reward": 0.8435802459716797, "action": -0.4176589250564575}
{"mode": "train", "epochs": 5, "timestep": 9298, "ep_reward": 726.384765625, "reward": 0.8050054311752319, "action": -0.8866029381752014}
{"mode": "train", "epochs": 5, "timestep": 9299, "ep_reward": 727.1207885742188, "reward": 0.7360324263572693, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9300, "ep_reward": 727.7404174804688, "reward": 0.6196272969245911, "action": -1.23212730884552}
{"mode": "train", "epochs": 5, "timestep": 9301, "ep_reward": 728.2105102539062, "reward": 0.47007572650909424, "action": -0.0915607213973999}
{"mode": "train", "epochs": 5, "timestep": 9302, "ep_reward": 728.5476684570312, "reward": 0.3371638059616089, "action": -1.647865653038025}
{"mode": "train", "epochs": 5, "timestep": 9303, "ep_reward": 728.7725219726562, "reward": 0.2248329520225525, "action": -0.08120459318161011}
{"mode": "train", "epochs": 5, "timestep": 9304, "ep_reward": 728.8646850585938, "reward": 0.09218573570251465, "action": -1.5392024517059326}
{"mode": "train", "epochs": 5, "timestep": 9305, "ep_reward": 728.8895874023438, "reward": 0.024906635284423828, "action": -1.187957763671875}
{"mode": "train", "epochs": 5, "timestep": 9306, "ep_reward": 729.05615234375, "reward": 0.16657286882400513, "action": -1.117955207824707}
{"mode": "train", "epochs": 5, "timestep": 9307, "ep_reward": 729.3611450195312, "reward": 0.305017352104187, "action": -0.7063180208206177}
{"mode": "train", "epochs": 5, "timestep": 9308, "ep_reward": 729.8057250976562, "reward": 0.44457149505615234, "action": -1.792639136314392}
{"mode": "train", "epochs": 5, "timestep": 9309, "ep_reward": 730.3633422851562, "reward": 0.5576121807098389, "action": -0.6471544504165649}
{"mode": "train", "epochs": 5, "timestep": 9310, "ep_reward": 731.0278930664062, "reward": 0.6645665168762207, "action": -0.9903572797775269}
{"mode": "train", "epochs": 5, "timestep": 9311, "ep_reward": 731.7720336914062, "reward": 0.7441437244415283, "action": -1.154926061630249}
{"mode": "train", "epochs": 5, "timestep": 9312, "ep_reward": 732.5721435546875, "reward": 0.8000795841217041, "action": 0.1531529426574707}
{"mode": "train", "epochs": 5, "timestep": 9313, "ep_reward": 733.4194946289062, "reward": 0.8473331332206726, "action": -0.6379884481430054}
{"mode": "train", "epochs": 5, "timestep": 9314, "ep_reward": 734.288818359375, "reward": 0.8693451881408691, "action": -1.7269065380096436}
{"mode": "train", "epochs": 5, "timestep": 9315, "ep_reward": 735.1554565429688, "reward": 0.866631805896759, "action": -0.7861936092376709}
{"mode": "train", "epochs": 5, "timestep": 9316, "ep_reward": 736.0103149414062, "reward": 0.8548865914344788, "action": -1.2687439918518066}
{"mode": "train", "epochs": 5, "timestep": 9317, "ep_reward": 736.82958984375, "reward": 0.8192813992500305, "action": -0.7357131242752075}
{"mode": "train", "epochs": 5, "timestep": 9318, "ep_reward": 737.5941162109375, "reward": 0.7645002603530884, "action": 0.058055877685546875}
{"mode": "train", "epochs": 5, "timestep": 9319, "ep_reward": 738.283935546875, "reward": 0.6898101568222046, "action": -0.5700057148933411}
{"mode": "train", "epochs": 5, "timestep": 9320, "ep_reward": 738.8578491210938, "reward": 0.5739061832427979, "action": -0.865827202796936}
{"mode": "train", "epochs": 5, "timestep": 9321, "ep_reward": 739.2725219726562, "reward": 0.4146735668182373, "action": -0.7677555084228516}
{"mode": "train", "epochs": 5, "timestep": 9322, "ep_reward": 739.561767578125, "reward": 0.28926050662994385, "action": -0.5837100148200989}
{"mode": "train", "epochs": 5, "timestep": 9323, "ep_reward": 739.7293090820312, "reward": 0.16754961013793945, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9324, "ep_reward": 739.7554321289062, "reward": 0.02611595392227173, "action": -1.7977346181869507}
{"mode": "train", "epochs": 5, "timestep": 9325, "ep_reward": 739.846435546875, "reward": 0.09102040529251099, "action": -1.0487349033355713}
{"mode": "train", "epochs": 5, "timestep": 9326, "ep_reward": 740.0748291015625, "reward": 0.22838890552520752, "action": -1.137821078300476}
{"mode": "train", "epochs": 5, "timestep": 9327, "ep_reward": 740.4410400390625, "reward": 0.36622267961502075, "action": -0.714203953742981}
{"mode": "train", "epochs": 5, "timestep": 9328, "ep_reward": 740.9417724609375, "reward": 0.5007424354553223, "action": -1.7791997194290161}
{"mode": "train", "epochs": 5, "timestep": 9329, "ep_reward": 741.5476684570312, "reward": 0.6058740615844727, "action": -0.39042937755584717}
{"mode": "train", "epochs": 5, "timestep": 9330, "ep_reward": 742.2528076171875, "reward": 0.7051452398300171, "action": -0.7927505970001221}
{"mode": "train", "epochs": 5, "timestep": 9331, "ep_reward": 743.0289306640625, "reward": 0.7761044502258301, "action": -0.8058959245681763}
{"mode": "train", "epochs": 5, "timestep": 9332, "ep_reward": 743.8543090820312, "reward": 0.8253536224365234, "action": -1.7653748989105225}
{"mode": "train", "epochs": 5, "timestep": 9333, "ep_reward": 744.7022094726562, "reward": 0.8479061126708984, "action": -0.8714730739593506}
{"mode": "train", "epochs": 5, "timestep": 9334, "ep_reward": 745.5633544921875, "reward": 0.8611392974853516, "action": -0.3312681317329407}
{"mode": "train", "epochs": 5, "timestep": 9335, "ep_reward": 746.42529296875, "reward": 0.8619364500045776, "action": -1.1525592803955078}
{"mode": "train", "epochs": 5, "timestep": 9336, "ep_reward": 747.2627563476562, "reward": 0.8374447822570801, "action": -0.8607420921325684}
{"mode": "train", "epochs": 5, "timestep": 9337, "ep_reward": 748.0565185546875, "reward": 0.7937325835227966, "action": -0.677141547203064}
{"mode": "train", "epochs": 5, "timestep": 9338, "ep_reward": 748.7814331054688, "reward": 0.7249095439910889, "action": -1.0945948362350464}
{"mode": "train", "epochs": 5, "timestep": 9339, "ep_reward": 749.3988647460938, "reward": 0.6174049377441406, "action": -0.8521238565444946}
{"mode": "train", "epochs": 5, "timestep": 9340, "ep_reward": 749.8716430664062, "reward": 0.4728032350540161, "action": -1.093717098236084}
{"mode": "train", "epochs": 5, "timestep": 9341, "ep_reward": 750.2067260742188, "reward": 0.33507204055786133, "action": -0.9642324447631836}
{"mode": "train", "epochs": 5, "timestep": 9342, "ep_reward": 750.4286499023438, "reward": 0.22195106744766235, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9343, "ep_reward": 750.517822265625, "reward": 0.08920079469680786, "action": -1.071213722229004}
{"mode": "train", "epochs": 5, "timestep": 9344, "ep_reward": 750.5460205078125, "reward": 0.028217792510986328, "action": -0.6401408910751343}
{"mode": "train", "epochs": 5, "timestep": 9345, "ep_reward": 750.7153930664062, "reward": 0.16940051317214966, "action": -1.058756709098816}
{"mode": "train", "epochs": 5, "timestep": 9346, "ep_reward": 751.0239868164062, "reward": 0.30856871604919434, "action": -1.1868311166763306}
{"mode": "train", "epochs": 5, "timestep": 9347, "ep_reward": 751.4662475585938, "reward": 0.4422447681427002, "action": -0.7689563035964966}
{"mode": "train", "epochs": 5, "timestep": 9348, "ep_reward": 752.0336303710938, "reward": 0.5673535466194153, "action": -0.5930362939834595}
{"mode": "train", "epochs": 5, "timestep": 9349, "ep_reward": 752.7067260742188, "reward": 0.6730654835700989, "action": -0.6648638248443604}
{"mode": "train", "epochs": 5, "timestep": 9350, "ep_reward": 753.4610595703125, "reward": 0.7543134093284607, "action": -0.9726085662841797}
{"mode": "train", "epochs": 5, "timestep": 9351, "ep_reward": 754.2716674804688, "reward": 0.8106244802474976, "action": -1.5026092529296875}
{"mode": "train", "epochs": 5, "timestep": 9352, "ep_reward": 755.1152954101562, "reward": 0.8436199426651001, "action": -0.015812575817108154}
{"mode": "train", "epochs": 5, "timestep": 9353, "ep_reward": 755.9873046875, "reward": 0.8720014691352844, "action": -1.3663270473480225}
{"mode": "train", "epochs": 5, "timestep": 9354, "ep_reward": 756.86083984375, "reward": 0.8735435605049133, "action": -1.226049780845642}
{"mode": "train", "epochs": 5, "timestep": 9355, "ep_reward": 757.7210083007812, "reward": 0.8601689338684082, "action": -0.34457582235336304}
{"mode": "train", "epochs": 5, "timestep": 9356, "ep_reward": 758.5572509765625, "reward": 0.8362665176391602, "action": -0.7892811894416809}
{"mode": "train", "epochs": 5, "timestep": 9357, "ep_reward": 759.3438720703125, "reward": 0.7866147756576538, "action": -0.37187713384628296}
{"mode": "train", "epochs": 5, "timestep": 9358, "ep_reward": 760.0580444335938, "reward": 0.7141571044921875, "action": -1.4303922653198242}
{"mode": "train", "epochs": 5, "timestep": 9359, "ep_reward": 760.6530151367188, "reward": 0.5949850082397461, "action": -1.3250807523727417}
{"mode": "train", "epochs": 5, "timestep": 9360, "ep_reward": 761.0879516601562, "reward": 0.4349108338356018, "action": -1.2936491966247559}
{"mode": "train", "epochs": 5, "timestep": 9361, "ep_reward": 761.3963012695312, "reward": 0.3083440065383911, "action": -1.787192463874817}
{"mode": "train", "epochs": 5, "timestep": 9362, "ep_reward": 761.5867919921875, "reward": 0.1904774308204651, "action": -1.2312089204788208}
{"mode": "train", "epochs": 5, "timestep": 9363, "ep_reward": 761.63916015625, "reward": 0.052365779876708984, "action": -1.9412636756896973}
{"mode": "train", "epochs": 5, "timestep": 9364, "ep_reward": 761.704833984375, "reward": 0.06569159030914307, "action": -0.8387097120285034}
{"mode": "train", "epochs": 5, "timestep": 9365, "ep_reward": 761.9097290039062, "reward": 0.20491957664489746, "action": -0.9428001046180725}
{"mode": "train", "epochs": 5, "timestep": 9366, "ep_reward": 762.2549438476562, "reward": 0.3452288508415222, "action": -1.663337230682373}
{"mode": "train", "epochs": 5, "timestep": 9367, "ep_reward": 762.7251586914062, "reward": 0.4701922535896301, "action": -1.652968406677246}
{"mode": "train", "epochs": 5, "timestep": 9368, "ep_reward": 763.3064575195312, "reward": 0.5812884569168091, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9369, "ep_reward": 763.9752197265625, "reward": 0.668752908706665, "action": -1.1373449563980103}
{"mode": "train", "epochs": 5, "timestep": 9370, "ep_reward": 764.7181396484375, "reward": 0.7428951263427734, "action": -0.8836982250213623}
{"mode": "train", "epochs": 5, "timestep": 9371, "ep_reward": 765.5140380859375, "reward": 0.7959063649177551, "action": -1.1362138986587524}
{"mode": "train", "epochs": 5, "timestep": 9372, "ep_reward": 766.3387451171875, "reward": 0.8246917128562927, "action": -0.9307780265808105}
{"mode": "train", "epochs": 5, "timestep": 9373, "ep_reward": 767.1736450195312, "reward": 0.8349294066429138, "action": -1.51871919631958}
{"mode": "train", "epochs": 5, "timestep": 9374, "ep_reward": 767.9922485351562, "reward": 0.8185943961143494, "action": -1.6698774099349976}
{"mode": "train", "epochs": 5, "timestep": 9375, "ep_reward": 768.7682495117188, "reward": 0.7759950757026672, "action": -1.3966476917266846}
{"mode": "train", "epochs": 5, "timestep": 9376, "ep_reward": 769.4736328125, "reward": 0.7054089307785034, "action": -0.8508721590042114}
{"mode": "train", "epochs": 5, "timestep": 9377, "ep_reward": 770.0776977539062, "reward": 0.6040763854980469, "action": 0.37047576904296875}
{"mode": "train", "epochs": 5, "timestep": 9378, "ep_reward": 770.5571899414062, "reward": 0.47946327924728394, "action": -0.5572270154953003}
{"mode": "train", "epochs": 5, "timestep": 9379, "ep_reward": 770.9149169921875, "reward": 0.357738733291626, "action": -1.0777994394302368}
{"mode": "train", "epochs": 5, "timestep": 9380, "ep_reward": 771.1642456054688, "reward": 0.24935060739517212, "action": -0.7718990445137024}
{"mode": "train", "epochs": 5, "timestep": 9381, "ep_reward": 771.2849731445312, "reward": 0.12073761224746704, "action": -1.9069583415985107}
{"mode": "train", "epochs": 5, "timestep": 9382, "ep_reward": 771.2785034179688, "reward": -0.006465435028076172, "action": -1.4514641761779785}
{"mode": "train", "epochs": 5, "timestep": 9383, "ep_reward": 771.4179077148438, "reward": 0.13939648866653442, "action": 0.20487916469573975}
{"mode": "train", "epochs": 5, "timestep": 9384, "ep_reward": 771.7114868164062, "reward": 0.2935766577720642, "action": -0.15452873706817627}
{"mode": "train", "epochs": 5, "timestep": 9385, "ep_reward": 772.1490478515625, "reward": 0.4375811815261841, "action": -1.589773416519165}
{"mode": "train", "epochs": 5, "timestep": 9386, "ep_reward": 772.7012939453125, "reward": 0.5522582530975342, "action": -0.597942590713501}
{"mode": "train", "epochs": 5, "timestep": 9387, "ep_reward": 773.362060546875, "reward": 0.6607469320297241, "action": -0.2975388169288635}
{"mode": "train", "epochs": 5, "timestep": 9388, "ep_reward": 774.1115112304688, "reward": 0.7494726181030273, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9389, "ep_reward": 774.9136962890625, "reward": 0.8022152185440063, "action": -1.634239912033081}
{"mode": "train", "epochs": 5, "timestep": 9390, "ep_reward": 775.755126953125, "reward": 0.8414157629013062, "action": -0.2315482497215271}
{"mode": "train", "epochs": 5, "timestep": 9391, "ep_reward": 776.630859375, "reward": 0.875759482383728, "action": -0.19092237949371338}
{"mode": "train", "epochs": 5, "timestep": 9392, "ep_reward": 777.5262451171875, "reward": 0.8954156637191772, "action": -0.7563319802284241}
{"mode": "train", "epochs": 5, "timestep": 9393, "ep_reward": 778.4241333007812, "reward": 0.8979184031486511, "action": -0.3468875288963318}
{"mode": "train", "epochs": 5, "timestep": 9394, "ep_reward": 779.3147583007812, "reward": 0.8906008005142212, "action": -0.7357016801834106}
{"mode": "train", "epochs": 5, "timestep": 9395, "ep_reward": 780.1805419921875, "reward": 0.8657922148704529, "action": -0.8958243727684021}
{"mode": "train", "epochs": 5, "timestep": 9396, "ep_reward": 781.0017700195312, "reward": 0.8212218284606934, "action": -0.9745023846626282}
{"mode": "train", "epochs": 5, "timestep": 9397, "ep_reward": 781.7533569335938, "reward": 0.7515729665756226, "action": -1.5289149284362793}
{"mode": "train", "epochs": 5, "timestep": 9398, "ep_reward": 782.3971557617188, "reward": 0.6437776684761047, "action": -0.6417657136917114}
{"mode": "train", "epochs": 5, "timestep": 9399, "ep_reward": 782.906005859375, "reward": 0.5088326930999756, "action": -0.8527002334594727}
{"mode": "train", "epochs": 5, "timestep": 9400, "ep_reward": 783.2431640625, "reward": 0.33713358640670776, "action": -0.4572686553001404}
{"mode": "train", "epochs": 5, "timestep": 9401, "ep_reward": 783.4676513671875, "reward": 0.22448468208312988, "action": -1.4161025285720825}
{"mode": "train", "epochs": 5, "timestep": 9402, "ep_reward": 783.5596923828125, "reward": 0.0920446515083313, "action": -0.6857020854949951}
{"mode": "train", "epochs": 5, "timestep": 9403, "ep_reward": 783.5848999023438, "reward": 0.025189518928527832, "action": -1.142867088317871}
{"mode": "train", "epochs": 5, "timestep": 9404, "ep_reward": 783.7517700195312, "reward": 0.16686642169952393, "action": -0.627082884311676}
{"mode": "train", "epochs": 5, "timestep": 9405, "ep_reward": 784.0631103515625, "reward": 0.3113629221916199, "action": -0.792770266532898}
{"mode": "train", "epochs": 5, "timestep": 9406, "ep_reward": 784.5116577148438, "reward": 0.44856125116348267, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9407, "ep_reward": 785.0701293945312, "reward": 0.5584810376167297, "action": -1.1517117023468018}
{"mode": "train", "epochs": 5, "timestep": 9408, "ep_reward": 785.7301025390625, "reward": 0.6599650382995605, "action": -1.4955676794052124}
{"mode": "train", "epochs": 5, "timestep": 9409, "ep_reward": 786.4656372070312, "reward": 0.7355241775512695, "action": -0.952980637550354}
{"mode": "train", "epochs": 5, "timestep": 9410, "ep_reward": 787.2599487304688, "reward": 0.7943178415298462, "action": -1.3691859245300293}
{"mode": "train", "epochs": 5, "timestep": 9411, "ep_reward": 788.0885009765625, "reward": 0.8285435438156128, "action": -1.1850494146347046}
{"mode": "train", "epochs": 5, "timestep": 9412, "ep_reward": 788.93408203125, "reward": 0.845611035823822, "action": -0.502167820930481}
{"mode": "train", "epochs": 5, "timestep": 9413, "ep_reward": 789.7843017578125, "reward": 0.8502437472343445, "action": -1.0087472200393677}
{"mode": "train", "epochs": 5, "timestep": 9414, "ep_reward": 790.6152954101562, "reward": 0.8309832811355591, "action": -0.7169785499572754}
{"mode": "train", "epochs": 5, "timestep": 9415, "ep_reward": 791.4074096679688, "reward": 0.7921149134635925, "action": -1.0581860542297363}
{"mode": "train", "epochs": 5, "timestep": 9416, "ep_reward": 792.1295166015625, "reward": 0.7220960855484009, "action": 0.412406325340271}
{"mode": "train", "epochs": 5, "timestep": 9417, "ep_reward": 792.7665405273438, "reward": 0.637026309967041, "action": -0.4535512924194336}
{"mode": "train", "epochs": 5, "timestep": 9418, "ep_reward": 793.2716064453125, "reward": 0.5050360560417175, "action": -0.9564821124076843}
{"mode": "train", "epochs": 5, "timestep": 9419, "ep_reward": 793.6224365234375, "reward": 0.3508434295654297, "action": -1.3600184917449951}
{"mode": "train", "epochs": 5, "timestep": 9420, "ep_reward": 793.863525390625, "reward": 0.24108296632766724, "action": -1.0571941137313843}
{"mode": "train", "epochs": 5, "timestep": 9421, "ep_reward": 793.9747314453125, "reward": 0.1111915111541748, "action": -1.578442096710205}
{"mode": "train", "epochs": 5, "timestep": 9422, "ep_reward": 793.9788818359375, "reward": 0.0041637420654296875, "action": -1.8820102214813232}
{"mode": "train", "epochs": 5, "timestep": 9423, "ep_reward": 794.1275634765625, "reward": 0.14866691827774048, "action": -1.0459250211715698}
{"mode": "train", "epochs": 5, "timestep": 9424, "ep_reward": 794.4151611328125, "reward": 0.2876136898994446, "action": -1.0042157173156738}
{"mode": "train", "epochs": 5, "timestep": 9425, "ep_reward": 794.8395385742188, "reward": 0.4244067668914795, "action": -1.9360806941986084}
{"mode": "train", "epochs": 5, "timestep": 9426, "ep_reward": 795.3779907226562, "reward": 0.5384422540664673, "action": -0.5749202370643616}
{"mode": "train", "epochs": 5, "timestep": 9427, "ep_reward": 796.02783203125, "reward": 0.6498222351074219, "action": -1.314558744430542}
{"mode": "train", "epochs": 5, "timestep": 9428, "ep_reward": 796.7573852539062, "reward": 0.7295485138893127, "action": -1.3198567628860474}
{"mode": "train", "epochs": 5, "timestep": 9429, "ep_reward": 797.5444946289062, "reward": 0.7871242761611938, "action": -0.705741286277771}
{"mode": "train", "epochs": 5, "timestep": 9430, "ep_reward": 798.3740234375, "reward": 0.8295112252235413, "action": -0.7912771105766296}
{"mode": "train", "epochs": 5, "timestep": 9431, "ep_reward": 799.225830078125, "reward": 0.8518152236938477, "action": -1.0895198583602905}
{"mode": "train", "epochs": 5, "timestep": 9432, "ep_reward": 800.0794677734375, "reward": 0.8536490201950073, "action": -0.5625852346420288}
{"mode": "train", "epochs": 5, "timestep": 9433, "ep_reward": 800.9212036132812, "reward": 0.8417270183563232, "action": -0.23355180025100708}
{"mode": "train", "epochs": 5, "timestep": 9434, "ep_reward": 801.7337646484375, "reward": 0.812545657157898, "action": -0.8211158514022827}
{"mode": "train", "epochs": 5, "timestep": 9435, "ep_reward": 802.48681640625, "reward": 0.7530524730682373, "action": -0.7700740098953247}
{"mode": "train", "epochs": 5, "timestep": 9436, "ep_reward": 803.1497192382812, "reward": 0.6629077196121216, "action": -1.2560982704162598}
{"mode": "train", "epochs": 5, "timestep": 9437, "ep_reward": 803.677978515625, "reward": 0.528268039226532, "action": -0.4413033127784729}
{"mode": "train", "epochs": 5, "timestep": 9438, "ep_reward": 804.0491943359375, "reward": 0.3711972236633301, "action": -1.5031821727752686}
{"mode": "train", "epochs": 5, "timestep": 9439, "ep_reward": 804.3147583007812, "reward": 0.26553958654403687, "action": -1.6174501180648804}
{"mode": "train", "epochs": 5, "timestep": 9440, "ep_reward": 804.4547729492188, "reward": 0.14000672101974487, "action": -0.9926484823226929}
{"mode": "train", "epochs": 5, "timestep": 9441, "ep_reward": 804.4491577148438, "reward": -0.005637764930725098, "action": -1.0724601745605469}
{"mode": "train", "epochs": 5, "timestep": 9442, "ep_reward": 804.5693359375, "reward": 0.1201818585395813, "action": -1.266066312789917}
{"mode": "train", "epochs": 5, "timestep": 9443, "ep_reward": 804.8250122070312, "reward": 0.2557021975517273, "action": -0.9531556963920593}
{"mode": "train", "epochs": 5, "timestep": 9444, "ep_reward": 805.2201538085938, "reward": 0.3951653838157654, "action": -1.2055182456970215}
{"mode": "train", "epochs": 5, "timestep": 9445, "ep_reward": 805.7412109375, "reward": 0.521082878112793, "action": -0.8001282811164856}
{"mode": "train", "epochs": 5, "timestep": 9446, "ep_reward": 806.3746337890625, "reward": 0.6334124803543091, "action": -0.00617527961730957}
{"mode": "train", "epochs": 5, "timestep": 9447, "ep_reward": 807.1048583984375, "reward": 0.7302238345146179, "action": -1.47573721408844}
{"mode": "train", "epochs": 5, "timestep": 9448, "ep_reward": 807.89404296875, "reward": 0.7891769409179688, "action": -1.7351480722427368}
{"mode": "train", "epochs": 5, "timestep": 9449, "ep_reward": 808.7208251953125, "reward": 0.8267711400985718, "action": -0.573508620262146}
{"mode": "train", "epochs": 5, "timestep": 9450, "ep_reward": 809.5773315429688, "reward": 0.8565264344215393, "action": -0.655502438545227}
{"mode": "train", "epochs": 5, "timestep": 9451, "ep_reward": 810.44580078125, "reward": 0.8684809803962708, "action": -1.0488390922546387}
{"mode": "train", "epochs": 5, "timestep": 9452, "ep_reward": 811.3064575195312, "reward": 0.860627293586731, "action": -0.8355461955070496}
{"mode": "train", "epochs": 5, "timestep": 9453, "ep_reward": 812.1427612304688, "reward": 0.8363329172134399, "action": -0.9992596507072449}
{"mode": "train", "epochs": 5, "timestep": 9454, "ep_reward": 812.9310913085938, "reward": 0.7883458137512207, "action": -1.1378206014633179}
{"mode": "train", "epochs": 5, "timestep": 9455, "ep_reward": 813.6416015625, "reward": 0.7105024456977844, "action": -0.6821151375770569}
{"mode": "train", "epochs": 5, "timestep": 9456, "ep_reward": 814.24462890625, "reward": 0.6030149459838867, "action": -1.0183273553848267}
{"mode": "train", "epochs": 5, "timestep": 9457, "ep_reward": 814.6956176757812, "reward": 0.45096707344055176, "action": -0.6030948162078857}
{"mode": "train", "epochs": 5, "timestep": 9458, "ep_reward": 815.01708984375, "reward": 0.3215000033378601, "action": -0.9092692732810974}
{"mode": "train", "epochs": 5, "timestep": 9459, "ep_reward": 815.2230834960938, "reward": 0.20597755908966064, "action": -0.7963467836380005}
{"mode": "train", "epochs": 5, "timestep": 9460, "ep_reward": 815.2935180664062, "reward": 0.07040560245513916, "action": -1.1153435707092285}
{"mode": "train", "epochs": 5, "timestep": 9461, "ep_reward": 815.3412475585938, "reward": 0.04772591590881348, "action": -0.8788161873817444}
{"mode": "train", "epochs": 5, "timestep": 9462, "ep_reward": 815.527587890625, "reward": 0.1863120198249817, "action": -1.1595724821090698}
{"mode": "train", "epochs": 5, "timestep": 9463, "ep_reward": 815.8521118164062, "reward": 0.32451897859573364, "action": -0.9768340587615967}
{"mode": "train", "epochs": 5, "timestep": 9464, "ep_reward": 816.31201171875, "reward": 0.4598849415779114, "action": -0.6054757833480835}
{"mode": "train", "epochs": 5, "timestep": 9465, "ep_reward": 816.8963012695312, "reward": 0.5842806696891785, "action": -0.5514972805976868}
{"mode": "train", "epochs": 5, "timestep": 9466, "ep_reward": 817.5831298828125, "reward": 0.6868020296096802, "action": -1.8522800207138062}
{"mode": "train", "epochs": 5, "timestep": 9467, "ep_reward": 818.3367919921875, "reward": 0.7536429762840271, "action": -1.1653012037277222}
{"mode": "train", "epochs": 5, "timestep": 9468, "ep_reward": 819.1435546875, "reward": 0.8067602515220642, "action": -0.16162675619125366}
{"mode": "train", "epochs": 5, "timestep": 9469, "ep_reward": 819.992431640625, "reward": 0.848875105381012, "action": -1.2194461822509766}
{"mode": "train", "epochs": 5, "timestep": 9470, "ep_reward": 820.856689453125, "reward": 0.8642439842224121, "action": -1.0381590127944946}
{"mode": "train", "epochs": 5, "timestep": 9471, "ep_reward": 821.7214965820312, "reward": 0.8648371696472168, "action": -0.7989948987960815}
{"mode": "train", "epochs": 5, "timestep": 9472, "ep_reward": 822.5716552734375, "reward": 0.8501845598220825, "action": -1.0238558053970337}
{"mode": "train", "epochs": 5, "timestep": 9473, "ep_reward": 823.3851318359375, "reward": 0.8134644627571106, "action": -0.01590418815612793}
{"mode": "train", "epochs": 5, "timestep": 9474, "ep_reward": 824.14794921875, "reward": 0.762793779373169, "action": 0.22632253170013428}
{"mode": "train", "epochs": 5, "timestep": 9475, "ep_reward": 824.8353881835938, "reward": 0.6874418258666992, "action": -0.595090389251709}
{"mode": "train", "epochs": 5, "timestep": 9476, "ep_reward": 825.4044799804688, "reward": 0.5690954923629761, "action": -0.8114268183708191}
{"mode": "train", "epochs": 5, "timestep": 9477, "ep_reward": 825.8135986328125, "reward": 0.40910983085632324, "action": -0.9489667415618896}
{"mode": "train", "epochs": 5, "timestep": 9478, "ep_reward": 826.0928955078125, "reward": 0.27932506799697876, "action": -0.9663758277893066}
{"mode": "train", "epochs": 5, "timestep": 9479, "ep_reward": 826.2489013671875, "reward": 0.15600472688674927, "action": -1.4683029651641846}
{"mode": "train", "epochs": 5, "timestep": 9480, "ep_reward": 826.2617797851562, "reward": 0.012880265712738037, "action": -0.5027371644973755}
{"mode": "train", "epochs": 5, "timestep": 9481, "ep_reward": 826.3652954101562, "reward": 0.1035231351852417, "action": -0.9532747864723206}
{"mode": "train", "epochs": 5, "timestep": 9482, "ep_reward": 826.6077880859375, "reward": 0.2424924373626709, "action": -0.7255319356918335}
{"mode": "train", "epochs": 5, "timestep": 9483, "ep_reward": 826.9923706054688, "reward": 0.38456225395202637, "action": -1.3260376453399658}
{"mode": "train", "epochs": 5, "timestep": 9484, "ep_reward": 827.5020751953125, "reward": 0.5096933841705322, "action": -0.6030666828155518}
{"mode": "train", "epochs": 5, "timestep": 9485, "ep_reward": 828.1281127929688, "reward": 0.626030683517456, "action": -0.45826393365859985}
{"mode": "train", "epochs": 5, "timestep": 9486, "ep_reward": 828.8486938476562, "reward": 0.7206027507781982, "action": -1.2730563879013062}
{"mode": "train", "epochs": 5, "timestep": 9487, "ep_reward": 829.63330078125, "reward": 0.7845908999443054, "action": -0.9633066654205322}
{"mode": "train", "epochs": 5, "timestep": 9488, "ep_reward": 830.46484375, "reward": 0.8315514922142029, "action": -1.3906877040863037}
{"mode": "train", "epochs": 5, "timestep": 9489, "ep_reward": 831.3220825195312, "reward": 0.8572640419006348, "action": -1.0140461921691895}
{"mode": "train", "epochs": 5, "timestep": 9490, "ep_reward": 832.192138671875, "reward": 0.8700670599937439, "action": -0.5060396790504456}
{"mode": "train", "epochs": 5, "timestep": 9491, "ep_reward": 833.0634155273438, "reward": 0.8712717294692993, "action": 0.018000006675720215}
{"mode": "train", "epochs": 5, "timestep": 9492, "ep_reward": 833.9238891601562, "reward": 0.8604803085327148, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9493, "ep_reward": 834.7364501953125, "reward": 0.8125537633895874, "action": -1.1362450122833252}
{"mode": "train", "epochs": 5, "timestep": 9494, "ep_reward": 835.4827270507812, "reward": 0.7462908029556274, "action": -0.6732980608940125}
{"mode": "train", "epochs": 5, "timestep": 9495, "ep_reward": 836.1358642578125, "reward": 0.6531553864479065, "action": -1.2799785137176514}
{"mode": "train", "epochs": 5, "timestep": 9496, "ep_reward": 836.6497192382812, "reward": 0.5138851404190063, "action": -0.33214640617370605}
{"mode": "train", "epochs": 5, "timestep": 9497, "ep_reward": 837.0087280273438, "reward": 0.3589886426925659, "action": -1.2747877836227417}
{"mode": "train", "epochs": 5, "timestep": 9498, "ep_reward": 837.2595825195312, "reward": 0.250829815864563, "action": -1.2464377880096436}
{"mode": "train", "epochs": 5, "timestep": 9499, "ep_reward": 837.38232421875, "reward": 0.12272435426712036, "action": -0.7988545894622803}
{"mode": "train", "epochs": 5, "timestep": 9500, "ep_reward": 837.3739624023438, "reward": -0.00836324691772461, "action": -0.1607847809791565}
{"mode": "train", "epochs": 5, "timestep": 9501, "ep_reward": 837.511474609375, "reward": 0.13753175735473633, "action": -1.262860894203186}
{"mode": "train", "epochs": 5, "timestep": 9502, "ep_reward": 837.7850952148438, "reward": 0.27359241247177124, "action": 0.11794841289520264}
{"mode": "train", "epochs": 5, "timestep": 9503, "ep_reward": 838.210205078125, "reward": 0.42508119344711304, "action": -1.2907450199127197}
{"mode": "train", "epochs": 5, "timestep": 9504, "ep_reward": 838.7557983398438, "reward": 0.5456207990646362, "action": -0.6349010467529297}
{"mode": "train", "epochs": 5, "timestep": 9505, "ep_reward": 839.4109497070312, "reward": 0.6551320552825928, "action": -0.3640223741531372}
{"mode": "train", "epochs": 5, "timestep": 9506, "ep_reward": 840.1551513671875, "reward": 0.7442264556884766, "action": -0.7771166563034058}
{"mode": "train", "epochs": 5, "timestep": 9507, "ep_reward": 840.962158203125, "reward": 0.8070150017738342, "action": -1.314645528793335}
{"mode": "train", "epochs": 5, "timestep": 9508, "ep_reward": 841.8087768554688, "reward": 0.8466023206710815, "action": -0.6210995316505432}
{"mode": "train", "epochs": 5, "timestep": 9509, "ep_reward": 842.6842651367188, "reward": 0.8754912614822388, "action": -1.8140621185302734}
{"mode": "train", "epochs": 5, "timestep": 9510, "ep_reward": 843.5650024414062, "reward": 0.880715012550354, "action": -0.9736761450767517}
{"mode": "train", "epochs": 5, "timestep": 9511, "ep_reward": 844.443115234375, "reward": 0.8780961632728577, "action": -0.5887258052825928}
{"mode": "train", "epochs": 5, "timestep": 9512, "ep_reward": 845.3060302734375, "reward": 0.8629021048545837, "action": -1.2045542001724243}
{"mode": "train", "epochs": 5, "timestep": 9513, "ep_reward": 846.1297607421875, "reward": 0.8237501382827759, "action": -0.7142062783241272}
{"mode": "train", "epochs": 5, "timestep": 9514, "ep_reward": 846.8951416015625, "reward": 0.7653644680976868, "action": -1.1264314651489258}
{"mode": "train", "epochs": 5, "timestep": 9515, "ep_reward": 847.5675048828125, "reward": 0.672365128993988, "action": -0.9651607275009155}
{"mode": "train", "epochs": 5, "timestep": 9516, "ep_reward": 848.1114501953125, "reward": 0.5439337491989136, "action": -0.4372243285179138}
{"mode": "train", "epochs": 5, "timestep": 9517, "ep_reward": 848.4948120117188, "reward": 0.3833896517753601, "action": 0.4401155710220337}
{"mode": "train", "epochs": 5, "timestep": 9518, "ep_reward": 848.7611083984375, "reward": 0.2662942409515381, "action": -1.1038405895233154}
{"mode": "train", "epochs": 5, "timestep": 9519, "ep_reward": 848.90185546875, "reward": 0.14077377319335938, "action": -1.112410068511963}
{"mode": "train", "epochs": 5, "timestep": 9520, "ep_reward": 848.8970947265625, "reward": -0.0047789812088012695, "action": -1.3355329036712646}
{"mode": "train", "epochs": 5, "timestep": 9521, "ep_reward": 849.0165405273438, "reward": 0.11943459510803223, "action": -0.8692045211791992}
{"mode": "train", "epochs": 5, "timestep": 9522, "ep_reward": 849.2764282226562, "reward": 0.2598961591720581, "action": -0.6460013389587402}
{"mode": "train", "epochs": 5, "timestep": 9523, "ep_reward": 849.678466796875, "reward": 0.40201514959335327, "action": -1.4998784065246582}
{"mode": "train", "epochs": 5, "timestep": 9524, "ep_reward": 850.2015991210938, "reward": 0.5231378078460693, "action": -0.6069983243942261}
{"mode": "train", "epochs": 5, "timestep": 9525, "ep_reward": 850.8386840820312, "reward": 0.6370812654495239, "action": -0.4953402280807495}
{"mode": "train", "epochs": 5, "timestep": 9526, "ep_reward": 851.5675659179688, "reward": 0.728863000869751, "action": -0.3345767855644226}
{"mode": "train", "epochs": 5, "timestep": 9527, "ep_reward": 852.366455078125, "reward": 0.7989004850387573, "action": -0.3157828450202942}
{"mode": "train", "epochs": 5, "timestep": 9528, "ep_reward": 853.2147827148438, "reward": 0.8483242392539978, "action": -1.0480339527130127}
{"mode": "train", "epochs": 5, "timestep": 9529, "ep_reward": 854.0897216796875, "reward": 0.8749268054962158, "action": -1.3039870262145996}
{"mode": "train", "epochs": 5, "timestep": 9530, "ep_reward": 854.9751586914062, "reward": 0.8854169845581055, "action": -0.8295795321464539}
{"mode": "train", "epochs": 5, "timestep": 9531, "ep_reward": 855.8609008789062, "reward": 0.8857548236846924, "action": -0.5730698108673096}
{"mode": "train", "epochs": 5, "timestep": 9532, "ep_reward": 856.7344360351562, "reward": 0.8735120892524719, "action": -0.9393731355667114}
{"mode": "train", "epochs": 5, "timestep": 9533, "ep_reward": 857.57568359375, "reward": 0.841254472732544, "action": -0.8508388996124268}
{"mode": "train", "epochs": 5, "timestep": 9534, "ep_reward": 858.3638916015625, "reward": 0.7882012724876404, "action": -0.5561071634292603}
{"mode": "train", "epochs": 5, "timestep": 9535, "ep_reward": 859.0748291015625, "reward": 0.7109525203704834, "action": -1.545353889465332}
{"mode": "train", "epochs": 5, "timestep": 9536, "ep_reward": 859.6622924804688, "reward": 0.5874555110931396, "action": -1.2096065282821655}
{"mode": "train", "epochs": 5, "timestep": 9537, "ep_reward": 860.0888061523438, "reward": 0.4265146851539612, "action": -1.234375}
{"mode": "train", "epochs": 5, "timestep": 9538, "ep_reward": 860.385009765625, "reward": 0.29617494344711304, "action": -1.3054760694503784}
{"mode": "train", "epochs": 5, "timestep": 9539, "ep_reward": 860.56103515625, "reward": 0.17605584859848022, "action": -0.3171681761741638}
{"mode": "train", "epochs": 5, "timestep": 9540, "ep_reward": 860.5968627929688, "reward": 0.03580892086029053, "action": -0.7423843145370483}
{"mode": "train", "epochs": 5, "timestep": 9541, "ep_reward": 860.6787719726562, "reward": 0.08188754320144653, "action": -1.5623302459716797}
{"mode": "train", "epochs": 5, "timestep": 9542, "ep_reward": 860.8947143554688, "reward": 0.21596169471740723, "action": -0.49587202072143555}
{"mode": "train", "epochs": 5, "timestep": 9543, "ep_reward": 861.25732421875, "reward": 0.3626272678375244, "action": -0.45536166429519653}
{"mode": "train", "epochs": 5, "timestep": 9544, "ep_reward": 861.7573852539062, "reward": 0.5000712871551514, "action": -1.507713794708252}
{"mode": "train", "epochs": 5, "timestep": 9545, "ep_reward": 862.3655395507812, "reward": 0.6081364154815674, "action": -0.40753448009490967}
{"mode": "train", "epochs": 5, "timestep": 9546, "ep_reward": 863.0726928710938, "reward": 0.7071292400360107, "action": -1.2871991395950317}
{"mode": "train", "epochs": 5, "timestep": 9547, "ep_reward": 863.8471069335938, "reward": 0.7744376063346863, "action": -0.22702360153198242}
{"mode": "train", "epochs": 5, "timestep": 9548, "ep_reward": 864.6777954101562, "reward": 0.8306640386581421, "action": -1.1417148113250732}
{"mode": "train", "epochs": 5, "timestep": 9549, "ep_reward": 865.538330078125, "reward": 0.8605566620826721, "action": -1.1094553470611572}
{"mode": "train", "epochs": 5, "timestep": 9550, "ep_reward": 866.4134521484375, "reward": 0.8751254081726074, "action": -0.7376972436904907}
{"mode": "train", "epochs": 5, "timestep": 9551, "ep_reward": 867.2910766601562, "reward": 0.8775988817214966, "action": -1.2248197793960571}
{"mode": "train", "epochs": 5, "timestep": 9552, "ep_reward": 868.1511840820312, "reward": 0.8601295948028564, "action": -1.4403185844421387}
{"mode": "train", "epochs": 5, "timestep": 9553, "ep_reward": 868.9724731445312, "reward": 0.8213016390800476, "action": -1.4459576606750488}
{"mode": "train", "epochs": 5, "timestep": 9554, "ep_reward": 869.7295532226562, "reward": 0.7570831775665283, "action": -0.551609992980957}
{"mode": "train", "epochs": 5, "timestep": 9555, "ep_reward": 870.4008178710938, "reward": 0.6712771654129028, "action": -1.3336236476898193}
{"mode": "train", "epochs": 5, "timestep": 9556, "ep_reward": 870.9388427734375, "reward": 0.5380250811576843, "action": -1.8925721645355225}
{"mode": "train", "epochs": 5, "timestep": 9557, "ep_reward": 871.314453125, "reward": 0.37564003467559814, "action": -1.3683099746704102}
{"mode": "train", "epochs": 5, "timestep": 9558, "ep_reward": 871.5853271484375, "reward": 0.27085012197494507, "action": -1.78916597366333}
{"mode": "train", "epochs": 5, "timestep": 9559, "ep_reward": 871.7316284179688, "reward": 0.14631891250610352, "action": -0.6332015991210938}
{"mode": "train", "epochs": 5, "timestep": 9560, "ep_reward": 871.7332153320312, "reward": 0.0016053318977355957, "action": -0.7259111404418945}
{"mode": "train", "epochs": 5, "timestep": 9561, "ep_reward": 871.846923828125, "reward": 0.11371797323226929, "action": -1.333841323852539}
{"mode": "train", "epochs": 5, "timestep": 9562, "ep_reward": 872.0951538085938, "reward": 0.24820226430892944, "action": -1.0662777423858643}
{"mode": "train", "epochs": 5, "timestep": 9563, "ep_reward": 872.48193359375, "reward": 0.38679271936416626, "action": -0.6350871324539185}
{"mode": "train", "epochs": 5, "timestep": 9564, "ep_reward": 873.0022583007812, "reward": 0.5203408002853394, "action": -1.3383994102478027}
{"mode": "train", "epochs": 5, "timestep": 9565, "ep_reward": 873.6292114257812, "reward": 0.626955509185791, "action": -1.0198523998260498}
{"mode": "train", "epochs": 5, "timestep": 9566, "ep_reward": 874.3446044921875, "reward": 0.7153644561767578, "action": -0.4117843508720398}
{"mode": "train", "epochs": 5, "timestep": 9567, "ep_reward": 875.131103515625, "reward": 0.7864882946014404, "action": -1.3039946556091309}
{"mode": "train", "epochs": 5, "timestep": 9568, "ep_reward": 875.9592895507812, "reward": 0.8281818628311157, "action": -0.8926051259040833}
{"mode": "train", "epochs": 5, "timestep": 9569, "ep_reward": 876.8146362304688, "reward": 0.8553435206413269, "action": -0.20851069688796997}
{"mode": "train", "epochs": 5, "timestep": 9570, "ep_reward": 877.6859741210938, "reward": 0.8713146448135376, "action": -0.6803289651870728}
{"mode": "train", "epochs": 5, "timestep": 9571, "ep_reward": 878.5530395507812, "reward": 0.8670682907104492, "action": -1.3493115901947021}
{"mode": "train", "epochs": 5, "timestep": 9572, "ep_reward": 879.3924560546875, "reward": 0.8394007086753845, "action": -0.7929991483688354}
{"mode": "train", "epochs": 5, "timestep": 9573, "ep_reward": 880.1875, "reward": 0.7950153350830078, "action": -0.8925127387046814}
{"mode": "train", "epochs": 5, "timestep": 9574, "ep_reward": 880.9099731445312, "reward": 0.7224426865577698, "action": -1.6362732648849487}
{"mode": "train", "epochs": 5, "timestep": 9575, "ep_reward": 881.515869140625, "reward": 0.6058907508850098, "action": -0.9543014764785767}
{"mode": "train", "epochs": 5, "timestep": 9576, "ep_reward": 881.9719848632812, "reward": 0.4561198353767395, "action": -0.9663729667663574}
{"mode": "train", "epochs": 5, "timestep": 9577, "ep_reward": 882.2992553710938, "reward": 0.32729679346084595, "action": -1.1994966268539429}
{"mode": "train", "epochs": 5, "timestep": 9578, "ep_reward": 882.5121459960938, "reward": 0.21288776397705078, "action": -1.1038315296173096}
{"mode": "train", "epochs": 5, "timestep": 9579, "ep_reward": 882.5904541015625, "reward": 0.07829165458679199, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9580, "ep_reward": 882.6298828125, "reward": 0.03942251205444336, "action": -0.9796279072761536}
{"mode": "train", "epochs": 5, "timestep": 9581, "ep_reward": 882.8090209960938, "reward": 0.17912447452545166, "action": -1.2095019817352295}
{"mode": "train", "epochs": 5, "timestep": 9582, "ep_reward": 883.1255493164062, "reward": 0.3165404200553894, "action": -1.4314427375793457}
{"mode": "train", "epochs": 5, "timestep": 9583, "ep_reward": 883.5725708007812, "reward": 0.4469919800758362, "action": -1.2897944450378418}
{"mode": "train", "epochs": 5, "timestep": 9584, "ep_reward": 884.1383056640625, "reward": 0.5657531023025513, "action": -1.2620269060134888}
{"mode": "train", "epochs": 5, "timestep": 9585, "ep_reward": 884.802734375, "reward": 0.6644175052642822, "action": -1.0593148469924927}
{"mode": "train", "epochs": 5, "timestep": 9586, "ep_reward": 885.5447387695312, "reward": 0.7420214414596558, "action": -0.7449084520339966}
{"mode": "train", "epochs": 5, "timestep": 9587, "ep_reward": 886.34423828125, "reward": 0.7995226383209229, "action": -1.303189992904663}
{"mode": "train", "epochs": 5, "timestep": 9588, "ep_reward": 887.1749877929688, "reward": 0.8307753205299377, "action": -1.6151719093322754}
{"mode": "train", "epochs": 5, "timestep": 9589, "ep_reward": 888.0150756835938, "reward": 0.8400984406471252, "action": -1.7612507343292236}
{"mode": "train", "epochs": 5, "timestep": 9590, "ep_reward": 888.843505859375, "reward": 0.8284054398536682, "action": -0.5918282270431519}
{"mode": "train", "epochs": 5, "timestep": 9591, "ep_reward": 889.649169921875, "reward": 0.8056647777557373, "action": -1.5569770336151123}
{"mode": "train", "epochs": 5, "timestep": 9592, "ep_reward": 890.3958129882812, "reward": 0.7466381788253784, "action": -0.6948524713516235}
{"mode": "train", "epochs": 5, "timestep": 9593, "ep_reward": 891.0599975585938, "reward": 0.6641656160354614, "action": -1.2049013376235962}
{"mode": "train", "epochs": 5, "timestep": 9594, "ep_reward": 891.5955810546875, "reward": 0.535584568977356, "action": -1.3953218460083008}
{"mode": "train", "epochs": 5, "timestep": 9595, "ep_reward": 891.9908447265625, "reward": 0.3952460289001465, "action": -0.6945469379425049}
{"mode": "train", "epochs": 5, "timestep": 9596, "ep_reward": 892.2855224609375, "reward": 0.2946486473083496, "action": -1.4771373271942139}
{"mode": "train", "epochs": 5, "timestep": 9597, "ep_reward": 892.4595947265625, "reward": 0.17409390211105347, "action": -1.7915294170379639}
{"mode": "train", "epochs": 5, "timestep": 9598, "ep_reward": 892.4933471679688, "reward": 0.03372621536254883, "action": -1.1192294359207153}
{"mode": "train", "epochs": 5, "timestep": 9599, "ep_reward": 892.5772705078125, "reward": 0.08395016193389893, "action": -0.7990641593933105}
{"mode": "train", "epochs": 5, "timestep": 9600, "ep_reward": 892.801513671875, "reward": 0.2242436408996582, "action": -0.880007266998291}
{"mode": "train", "epochs": 5, "timestep": 9601, "ep_reward": 893.166259765625, "reward": 0.3647649884223938, "action": -1.1716965436935425}
{"mode": "train", "epochs": 5, "timestep": 9602, "ep_reward": 893.659912109375, "reward": 0.49363040924072266, "action": -1.0179184675216675}
{"mode": "train", "epochs": 5, "timestep": 9603, "ep_reward": 894.2679443359375, "reward": 0.6080242991447449, "action": -1.494399070739746}
{"mode": "train", "epochs": 5, "timestep": 9604, "ep_reward": 894.9641723632812, "reward": 0.6962038278579712, "action": -0.764555811882019}
{"mode": "train", "epochs": 5, "timestep": 9605, "ep_reward": 895.733642578125, "reward": 0.7694888114929199, "action": -1.5791571140289307}
{"mode": "train", "epochs": 5, "timestep": 9606, "ep_reward": 896.5475463867188, "reward": 0.813874363899231, "action": -0.1874447464942932}
{"mode": "train", "epochs": 5, "timestep": 9607, "ep_reward": 897.3989868164062, "reward": 0.8514634370803833, "action": -1.1952807903289795}
{"mode": "train", "epochs": 5, "timestep": 9608, "ep_reward": 898.2617797851562, "reward": 0.8627737760543823, "action": -0.07354569435119629}
{"mode": "train", "epochs": 5, "timestep": 9609, "ep_reward": 899.1287841796875, "reward": 0.8669812679290771, "action": -1.036347508430481}
{"mode": "train", "epochs": 5, "timestep": 9610, "ep_reward": 899.9741821289062, "reward": 0.8454058766365051, "action": -1.7430325746536255}
{"mode": "train", "epochs": 5, "timestep": 9611, "ep_reward": 900.7698364257812, "reward": 0.7956682443618774, "action": -0.22126269340515137}
{"mode": "train", "epochs": 5, "timestep": 9612, "ep_reward": 901.504150390625, "reward": 0.7343403100967407, "action": -1.1110889911651611}
{"mode": "train", "epochs": 5, "timestep": 9613, "ep_reward": 902.1346435546875, "reward": 0.6304935216903687, "action": 0.019995808601379395}
{"mode": "train", "epochs": 5, "timestep": 9614, "ep_reward": 902.6381225585938, "reward": 0.5034637451171875, "action": -1.4895687103271484}
{"mode": "train", "epochs": 5, "timestep": 9615, "ep_reward": 902.9847412109375, "reward": 0.34664762020111084, "action": -0.6988126039505005}
{"mode": "train", "epochs": 5, "timestep": 9616, "ep_reward": 903.2205810546875, "reward": 0.2358403205871582, "action": -1.6852149963378906}
{"mode": "train", "epochs": 5, "timestep": 9617, "ep_reward": 903.3258666992188, "reward": 0.10529673099517822, "action": -0.9910833239555359}
{"mode": "train", "epochs": 5, "timestep": 9618, "ep_reward": 903.336669921875, "reward": 0.01081174612045288, "action": -1.5344377756118774}
{"mode": "train", "epochs": 5, "timestep": 9619, "ep_reward": 903.4910888671875, "reward": 0.15442413091659546, "action": -0.7020295858383179}
{"mode": "train", "epochs": 5, "timestep": 9620, "ep_reward": 903.7887573242188, "reward": 0.29768311977386475, "action": -1.3681093454360962}
{"mode": "train", "epochs": 5, "timestep": 9621, "ep_reward": 904.2178344726562, "reward": 0.42909854650497437, "action": -1.3521690368652344}
{"mode": "train", "epochs": 5, "timestep": 9622, "ep_reward": 904.7670288085938, "reward": 0.5492235422134399, "action": -0.420498788356781}
{"mode": "train", "epochs": 5, "timestep": 9623, "ep_reward": 905.4273071289062, "reward": 0.6602604389190674, "action": -0.773844838142395}
{"mode": "train", "epochs": 5, "timestep": 9624, "ep_reward": 906.1708984375, "reward": 0.743564248085022, "action": -0.43485552072525024}
{"mode": "train", "epochs": 5, "timestep": 9625, "ep_reward": 906.9783935546875, "reward": 0.8074823021888733, "action": -0.19022399187088013}
{"mode": "train", "epochs": 5, "timestep": 9626, "ep_reward": 907.8314819335938, "reward": 0.8530754446983337, "action": -0.8105061054229736}
{"mode": "train", "epochs": 5, "timestep": 9627, "ep_reward": 908.7081298828125, "reward": 0.8766356706619263, "action": -0.22552186250686646}
{"mode": "train", "epochs": 5, "timestep": 9628, "ep_reward": 909.5982055664062, "reward": 0.8900634050369263, "action": -1.4175493717193604}
{"mode": "train", "epochs": 5, "timestep": 9629, "ep_reward": 910.478515625, "reward": 0.8802942037582397, "action": -0.7258754372596741}
{"mode": "train", "epochs": 5, "timestep": 9630, "ep_reward": 911.3388671875, "reward": 0.860340416431427, "action": -0.532772421836853}
{"mode": "train", "epochs": 5, "timestep": 9631, "ep_reward": 912.162353515625, "reward": 0.8234925866127014, "action": -1.2434792518615723}
{"mode": "train", "epochs": 5, "timestep": 9632, "ep_reward": 912.9182739257812, "reward": 0.7559013366699219, "action": -1.0624146461486816}
{"mode": "train", "epochs": 5, "timestep": 9633, "ep_reward": 913.5767822265625, "reward": 0.6585280299186707, "action": -1.1920835971832275}
{"mode": "train", "epochs": 5, "timestep": 9634, "ep_reward": 914.0978393554688, "reward": 0.5210500955581665, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9635, "ep_reward": 914.4529418945312, "reward": 0.35508066415786743, "action": -1.6707271337509155}
{"mode": "train", "epochs": 5, "timestep": 9636, "ep_reward": 914.6991577148438, "reward": 0.24623793363571167, "action": -1.0999630689620972}
{"mode": "train", "epochs": 5, "timestep": 9637, "ep_reward": 914.8165283203125, "reward": 0.11737090349197388, "action": -0.16714608669281006}
{"mode": "train", "epochs": 5, "timestep": 9638, "ep_reward": 914.814208984375, "reward": -0.0023251771926879883, "action": -0.5484936833381653}
{"mode": "train", "epochs": 5, "timestep": 9639, "ep_reward": 914.9570922851562, "reward": 0.14290469884872437, "action": -0.4735351800918579}
{"mode": "train", "epochs": 5, "timestep": 9640, "ep_reward": 915.2459106445312, "reward": 0.28880995512008667, "action": -0.893446147441864}
{"mode": "train", "epochs": 5, "timestep": 9641, "ep_reward": 915.671875, "reward": 0.42596858739852905, "action": -0.5997031927108765}
{"mode": "train", "epochs": 5, "timestep": 9642, "ep_reward": 916.22607421875, "reward": 0.5542072057723999, "action": -1.0277575254440308}
{"mode": "train", "epochs": 5, "timestep": 9643, "ep_reward": 916.8839111328125, "reward": 0.657846212387085, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9644, "ep_reward": 917.6149291992188, "reward": 0.7309930920600891, "action": -0.6764098405838013}
{"mode": "train", "epochs": 5, "timestep": 9645, "ep_reward": 918.4113159179688, "reward": 0.7963728904724121, "action": -1.0809636116027832}
{"mode": "train", "epochs": 5, "timestep": 9646, "ep_reward": 919.2493286132812, "reward": 0.8379936218261719, "action": 0.04164564609527588}
{"mode": "train", "epochs": 5, "timestep": 9647, "ep_reward": 920.1206665039062, "reward": 0.8713492155075073, "action": -0.367264986038208}
{"mode": "train", "epochs": 5, "timestep": 9648, "ep_reward": 921.0061645507812, "reward": 0.8855082392692566, "action": -0.9318406581878662}
{"mode": "train", "epochs": 5, "timestep": 9649, "ep_reward": 921.8870239257812, "reward": 0.8808724284172058, "action": -0.7432903051376343}
{"mode": "train", "epochs": 5, "timestep": 9650, "ep_reward": 922.749267578125, "reward": 0.8622656464576721, "action": -0.5252586603164673}
{"mode": "train", "epochs": 5, "timestep": 9651, "ep_reward": 923.5764770507812, "reward": 0.8272141218185425, "action": -1.4384760856628418}
{"mode": "train", "epochs": 5, "timestep": 9652, "ep_reward": 924.3363037109375, "reward": 0.7598009705543518, "action": -0.4966050386428833}
{"mode": "train", "epochs": 5, "timestep": 9653, "ep_reward": 925.0081176757812, "reward": 0.6718335747718811, "action": -0.9884260892868042}
{"mode": "train", "epochs": 5, "timestep": 9654, "ep_reward": 925.5501098632812, "reward": 0.5419719219207764, "action": -0.6896785497665405}
{"mode": "train", "epochs": 5, "timestep": 9655, "ep_reward": 925.9267578125, "reward": 0.376645028591156, "action": -0.5560637712478638}
{"mode": "train", "epochs": 5, "timestep": 9656, "ep_reward": 926.1856079101562, "reward": 0.2588256001472473, "action": -0.1766391396522522}
{"mode": "train", "epochs": 5, "timestep": 9657, "ep_reward": 926.3174438476562, "reward": 0.13186073303222656, "action": -1.4886915683746338}
{"mode": "train", "epochs": 5, "timestep": 9658, "ep_reward": 926.3025512695312, "reward": -0.014897584915161133, "action": -1.0278685092926025}
{"mode": "train", "epochs": 5, "timestep": 9659, "ep_reward": 926.4308471679688, "reward": 0.12831121683120728, "action": -1.6080445051193237}
{"mode": "train", "epochs": 5, "timestep": 9660, "ep_reward": 926.6906127929688, "reward": 0.25976043939590454, "action": -1.1015599966049194}
{"mode": "train", "epochs": 5, "timestep": 9661, "ep_reward": 927.088623046875, "reward": 0.3980017900466919, "action": -0.48776817321777344}
{"mode": "train", "epochs": 5, "timestep": 9662, "ep_reward": 927.620849609375, "reward": 0.5322211980819702, "action": -1.5965278148651123}
{"mode": "train", "epochs": 5, "timestep": 9663, "ep_reward": 928.2548828125, "reward": 0.6340280771255493, "action": -0.5588480234146118}
{"mode": "train", "epochs": 5, "timestep": 9664, "ep_reward": 928.9797973632812, "reward": 0.7249065041542053, "action": -1.0296146869659424}
{"mode": "train", "epochs": 5, "timestep": 9665, "ep_reward": 929.7672729492188, "reward": 0.7874581813812256, "action": -1.5143284797668457}
{"mode": "train", "epochs": 5, "timestep": 9666, "ep_reward": 930.5924072265625, "reward": 0.8251488208770752, "action": -0.5160447359085083}
{"mode": "train", "epochs": 5, "timestep": 9667, "ep_reward": 931.4453735351562, "reward": 0.8529890775680542, "action": -1.0358693599700928}
{"mode": "train", "epochs": 5, "timestep": 9668, "ep_reward": 932.3040161132812, "reward": 0.8586590886116028, "action": -0.23789018392562866}
{"mode": "train", "epochs": 5, "timestep": 9669, "ep_reward": 933.15771484375, "reward": 0.8537111282348633, "action": -1.0539114475250244}
{"mode": "train", "epochs": 5, "timestep": 9670, "ep_reward": 933.9796752929688, "reward": 0.8219649195671082, "action": -1.7227230072021484}
{"mode": "train", "epochs": 5, "timestep": 9671, "ep_reward": 934.7383422851562, "reward": 0.7586543560028076, "action": -0.46894949674606323}
{"mode": "train", "epochs": 5, "timestep": 9672, "ep_reward": 935.4159545898438, "reward": 0.6775833368301392, "action": 0.035541653633117676}
{"mode": "train", "epochs": 5, "timestep": 9673, "ep_reward": 935.9840087890625, "reward": 0.5680465698242188, "action": -1.287719488143921}
{"mode": "train", "epochs": 5, "timestep": 9674, "ep_reward": 936.384521484375, "reward": 0.4005321264266968, "action": -0.7857809066772461}
{"mode": "train", "epochs": 5, "timestep": 9675, "ep_reward": 936.6739501953125, "reward": 0.2894529104232788, "action": -1.402864933013916}
{"mode": "train", "epochs": 5, "timestep": 9676, "ep_reward": 936.842041015625, "reward": 0.16809707880020142, "action": -0.7938293218612671}
{"mode": "train", "epochs": 5, "timestep": 9677, "ep_reward": 936.8685302734375, "reward": 0.026467740535736084, "action": -1.90537691116333}
{"mode": "train", "epochs": 5, "timestep": 9678, "ep_reward": 936.9591674804688, "reward": 0.09060871601104736, "action": -1.477162480354309}
{"mode": "train", "epochs": 5, "timestep": 9679, "ep_reward": 937.1825561523438, "reward": 0.2233595848083496, "action": -1.3694522380828857}
{"mode": "train", "epochs": 5, "timestep": 9680, "ep_reward": 937.5418090820312, "reward": 0.35926926136016846, "action": -0.6036745309829712}
{"mode": "train", "epochs": 5, "timestep": 9681, "ep_reward": 938.03857421875, "reward": 0.4967383146286011, "action": -0.49371474981307983}
{"mode": "train", "epochs": 5, "timestep": 9682, "ep_reward": 938.6551513671875, "reward": 0.6165528893470764, "action": -1.032486081123352}
{"mode": "train", "epochs": 5, "timestep": 9683, "ep_reward": 939.362548828125, "reward": 0.7073832750320435, "action": -1.1767321825027466}
{"mode": "train", "epochs": 5, "timestep": 9684, "ep_reward": 940.1369018554688, "reward": 0.774340033531189, "action": -0.893471896648407}
{"mode": "train", "epochs": 5, "timestep": 9685, "ep_reward": 940.9598388671875, "reward": 0.8229663968086243, "action": -1.2514252662658691}
{"mode": "train", "epochs": 5, "timestep": 9686, "ep_reward": 941.8095092773438, "reward": 0.8496676683425903, "action": -0.9367259740829468}
{"mode": "train", "epochs": 5, "timestep": 9687, "ep_reward": 942.6714477539062, "reward": 0.8619385957717896, "action": -0.037083327770233154}
{"mode": "train", "epochs": 5, "timestep": 9688, "ep_reward": 943.5364990234375, "reward": 0.8650335669517517, "action": -1.0276228189468384}
{"mode": "train", "epochs": 5, "timestep": 9689, "ep_reward": 944.37841796875, "reward": 0.8419325351715088, "action": -0.316646933555603}
{"mode": "train", "epochs": 5, "timestep": 9690, "ep_reward": 945.1830444335938, "reward": 0.8046232461929321, "action": -1.0534043312072754}
{"mode": "train", "epochs": 5, "timestep": 9691, "ep_reward": 945.9171752929688, "reward": 0.7341560125350952, "action": -1.3298100233078003}
{"mode": "train", "epochs": 5, "timestep": 9692, "ep_reward": 946.5435180664062, "reward": 0.6263654828071594, "action": -1.736839771270752}
{"mode": "train", "epochs": 5, "timestep": 9693, "ep_reward": 947.014404296875, "reward": 0.47088390588760376, "action": -1.1707870960235596}
{"mode": "train", "epochs": 5, "timestep": 9694, "ep_reward": 947.353271484375, "reward": 0.3388966917991638, "action": -1.9742642641067505}
{"mode": "train", "epochs": 5, "timestep": 9695, "ep_reward": 947.5802001953125, "reward": 0.22693896293640137, "action": -0.8487170338630676}
{"mode": "train", "epochs": 5, "timestep": 9696, "ep_reward": 947.6748046875, "reward": 0.09463220834732056, "action": -1.7574632167816162}
{"mode": "train", "epochs": 5, "timestep": 9697, "ep_reward": 947.6971435546875, "reward": 0.022347629070281982, "action": 0.12578368186950684}
{"mode": "train", "epochs": 5, "timestep": 9698, "ep_reward": 947.8693237304688, "reward": 0.17216283082962036, "action": -0.9521665573120117}
{"mode": "train", "epochs": 5, "timestep": 9699, "ep_reward": 948.1802978515625, "reward": 0.31096404790878296, "action": -0.9662003517150879}
{"mode": "train", "epochs": 5, "timestep": 9700, "ep_reward": 948.6260375976562, "reward": 0.4457685947418213, "action": -1.0308607816696167}
{"mode": "train", "epochs": 5, "timestep": 9701, "ep_reward": 949.1928100585938, "reward": 0.5667624473571777, "action": -0.4107053875923157}
{"mode": "train", "epochs": 5, "timestep": 9702, "ep_reward": 949.8673706054688, "reward": 0.6745325326919556, "action": -0.37582457065582275}
{"mode": "train", "epochs": 5, "timestep": 9703, "ep_reward": 950.6263427734375, "reward": 0.7589666843414307, "action": -1.128476619720459}
{"mode": "train", "epochs": 5, "timestep": 9704, "ep_reward": 951.4412841796875, "reward": 0.8149515986442566, "action": -1.7411421537399292}
{"mode": "train", "epochs": 5, "timestep": 9705, "ep_reward": 952.2896728515625, "reward": 0.8483815789222717, "action": -0.6740316152572632}
{"mode": "train", "epochs": 5, "timestep": 9706, "ep_reward": 953.1643676757812, "reward": 0.8747173547744751, "action": -0.7805564403533936}
{"mode": "train", "epochs": 5, "timestep": 9707, "ep_reward": 954.0496215820312, "reward": 0.8852440118789673, "action": -1.783428430557251}
{"mode": "train", "epochs": 5, "timestep": 9708, "ep_reward": 954.9230346679688, "reward": 0.8734185099601746, "action": -1.1864488124847412}
{"mode": "train", "epochs": 5, "timestep": 9709, "ep_reward": 955.7725219726562, "reward": 0.8495122194290161, "action": -0.561064600944519}
{"mode": "train", "epochs": 5, "timestep": 9710, "ep_reward": 956.5835571289062, "reward": 0.8110132813453674, "action": -1.193692922592163}
{"mode": "train", "epochs": 5, "timestep": 9711, "ep_reward": 957.3244018554688, "reward": 0.7408452033996582, "action": -1.157297968864441}
{"mode": "train", "epochs": 5, "timestep": 9712, "ep_reward": 957.9620971679688, "reward": 0.6377227306365967, "action": -1.1634032726287842}
{"mode": "train", "epochs": 5, "timestep": 9713, "ep_reward": 958.4567260742188, "reward": 0.49461114406585693, "action": -0.8137757778167725}
{"mode": "train", "epochs": 5, "timestep": 9714, "ep_reward": 958.802490234375, "reward": 0.3457605838775635, "action": -1.8054319620132446}
{"mode": "train", "epochs": 5, "timestep": 9715, "ep_reward": 959.03759765625, "reward": 0.23511964082717896, "action": -0.7301070690155029}
{"mode": "train", "epochs": 5, "timestep": 9716, "ep_reward": 959.1419067382812, "reward": 0.1043136715888977, "action": -0.6395192742347717}
{"mode": "train", "epochs": 5, "timestep": 9717, "ep_reward": 959.1539306640625, "reward": 0.01203697919845581, "action": -0.842746376991272}
{"mode": "train", "epochs": 5, "timestep": 9718, "ep_reward": 959.3093872070312, "reward": 0.15543490648269653, "action": 0.31841111183166504}
{"mode": "train", "epochs": 5, "timestep": 9719, "ep_reward": 959.6207275390625, "reward": 0.31131511926651, "action": -0.5975456237792969}
{"mode": "train", "epochs": 5, "timestep": 9720, "ep_reward": 960.06982421875, "reward": 0.44912272691726685, "action": -1.1763814687728882}
{"mode": "train", "epochs": 5, "timestep": 9721, "ep_reward": 960.636962890625, "reward": 0.5671492218971252, "action": -1.1711382865905762}
{"mode": "train", "epochs": 5, "timestep": 9722, "ep_reward": 961.303955078125, "reward": 0.667011022567749, "action": -1.8177034854888916}
{"mode": "train", "epochs": 5, "timestep": 9723, "ep_reward": 962.0441284179688, "reward": 0.7401860952377319, "action": -1.2121727466583252}
{"mode": "train", "epochs": 5, "timestep": 9724, "ep_reward": 962.8434448242188, "reward": 0.7993120551109314, "action": -1.080723762512207}
{"mode": "train", "epochs": 5, "timestep": 9725, "ep_reward": 963.6839599609375, "reward": 0.8405030965805054, "action": -1.0621150732040405}
{"mode": "train", "epochs": 5, "timestep": 9726, "ep_reward": 964.5487060546875, "reward": 0.864717423915863, "action": -1.267128586769104}
{"mode": "train", "epochs": 5, "timestep": 9727, "ep_reward": 965.4202270507812, "reward": 0.87151700258255, "action": -1.238523006439209}
{"mode": "train", "epochs": 5, "timestep": 9728, "ep_reward": 966.2827758789062, "reward": 0.8625237941741943, "action": -0.8805409073829651}
{"mode": "train", "epochs": 5, "timestep": 9729, "ep_reward": 967.1212768554688, "reward": 0.8384706377983093, "action": -1.2586239576339722}
{"mode": "train", "epochs": 5, "timestep": 9730, "ep_reward": 967.9100341796875, "reward": 0.7887718081474304, "action": 0.4347625970840454}
{"mode": "train", "epochs": 5, "timestep": 9731, "ep_reward": 968.6404418945312, "reward": 0.7304040789604187, "action": -0.4014255404472351}
{"mode": "train", "epochs": 5, "timestep": 9732, "ep_reward": 969.2727661132812, "reward": 0.6323463320732117, "action": -0.6461342573165894}
{"mode": "train", "epochs": 5, "timestep": 9733, "ep_reward": 969.7671508789062, "reward": 0.4944117069244385, "action": -0.29319530725479126}
{"mode": "train", "epochs": 5, "timestep": 9734, "ep_reward": 970.1021118164062, "reward": 0.33494287729263306, "action": -0.6425336003303528}
{"mode": "train", "epochs": 5, "timestep": 9735, "ep_reward": 970.3240966796875, "reward": 0.2219552993774414, "action": -0.8341626524925232}
{"mode": "train", "epochs": 5, "timestep": 9736, "ep_reward": 970.4131469726562, "reward": 0.08902645111083984, "action": -0.005116522312164307}
{"mode": "train", "epochs": 5, "timestep": 9737, "ep_reward": 970.4415893554688, "reward": 0.028437912464141846, "action": -1.1122949123382568}
{"mode": "train", "epochs": 5, "timestep": 9738, "ep_reward": 970.6112060546875, "reward": 0.16961991786956787, "action": -1.2430771589279175}
{"mode": "train", "epochs": 5, "timestep": 9739, "ep_reward": 970.9175415039062, "reward": 0.3063427209854126, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9740, "ep_reward": 971.3482055664062, "reward": 0.4306797385215759, "action": -0.4039701819419861}
{"mode": "train", "epochs": 5, "timestep": 9741, "ep_reward": 971.9103393554688, "reward": 0.562122106552124, "action": -1.4760016202926636}
{"mode": "train", "epochs": 5, "timestep": 9742, "ep_reward": 972.5697021484375, "reward": 0.6593853235244751, "action": -1.0744389295578003}
{"mode": "train", "epochs": 5, "timestep": 9743, "ep_reward": 973.3079833984375, "reward": 0.7382898926734924, "action": -0.7541624903678894}
{"mode": "train", "epochs": 5, "timestep": 9744, "ep_reward": 974.1050415039062, "reward": 0.797076404094696, "action": -1.724315881729126}
{"mode": "train", "epochs": 5, "timestep": 9745, "ep_reward": 974.9309692382812, "reward": 0.8259375095367432, "action": -1.5358376502990723}
{"mode": "train", "epochs": 5, "timestep": 9746, "ep_reward": 975.7684326171875, "reward": 0.8374418616294861, "action": -0.6721853613853455}
{"mode": "train", "epochs": 5, "timestep": 9747, "ep_reward": 976.605712890625, "reward": 0.8372676968574524, "action": -0.8339629173278809}
{"mode": "train", "epochs": 5, "timestep": 9748, "ep_reward": 977.4200439453125, "reward": 0.814354658126831, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9749, "ep_reward": 978.1737670898438, "reward": 0.7537423372268677, "action": -1.581266164779663}
{"mode": "train", "epochs": 5, "timestep": 9750, "ep_reward": 978.8370361328125, "reward": 0.663277268409729, "action": -0.8283249139785767}
{"mode": "train", "epochs": 5, "timestep": 9751, "ep_reward": 979.378662109375, "reward": 0.5416454076766968, "action": -1.2821272611618042}
{"mode": "train", "epochs": 5, "timestep": 9752, "ep_reward": 979.780029296875, "reward": 0.4013707637786865, "action": -0.8048771619796753}
{"mode": "train", "epochs": 5, "timestep": 9753, "ep_reward": 980.0822143554688, "reward": 0.3022022247314453, "action": -1.1010910272598267}
{"mode": "train", "epochs": 5, "timestep": 9754, "ep_reward": 980.2653198242188, "reward": 0.18313068151474, "action": -0.4312477707862854}
{"mode": "train", "epochs": 5, "timestep": 9755, "ep_reward": 980.3092041015625, "reward": 0.043868303298950195, "action": -1.4738160371780396}
{"mode": "train", "epochs": 5, "timestep": 9756, "ep_reward": 980.38330078125, "reward": 0.07409250736236572, "action": -1.1378551721572876}
{"mode": "train", "epochs": 5, "timestep": 9757, "ep_reward": 980.593017578125, "reward": 0.209722638130188, "action": -1.7410218715667725}
{"mode": "train", "epochs": 5, "timestep": 9758, "ep_reward": 980.933837890625, "reward": 0.340823769569397, "action": -0.7084656953811646}
{"mode": "train", "epochs": 5, "timestep": 9759, "ep_reward": 981.4127197265625, "reward": 0.47889089584350586, "action": -1.6382153034210205}
{"mode": "train", "epochs": 5, "timestep": 9760, "ep_reward": 982.0017700195312, "reward": 0.5890719890594482, "action": -0.7905716896057129}
{"mode": "train", "epochs": 5, "timestep": 9761, "ep_reward": 982.6891479492188, "reward": 0.6873856782913208, "action": -1.8325859308242798}
{"mode": "train", "epochs": 5, "timestep": 9762, "ep_reward": 983.4404296875, "reward": 0.7512772083282471, "action": -1.2010467052459717}
{"mode": "train", "epochs": 5, "timestep": 9763, "ep_reward": 984.2400512695312, "reward": 0.7995988130569458, "action": -0.9056321382522583}
{"mode": "train", "epochs": 5, "timestep": 9764, "ep_reward": 985.069580078125, "reward": 0.829511284828186, "action": -0.9671938419342041}
{"mode": "train", "epochs": 5, "timestep": 9765, "ep_reward": 985.908447265625, "reward": 0.8388519287109375, "action": -0.6440954208374023}
{"mode": "train", "epochs": 5, "timestep": 9766, "ep_reward": 986.7394409179688, "reward": 0.8310061097145081, "action": -1.5161876678466797}
{"mode": "train", "epochs": 5, "timestep": 9767, "ep_reward": 987.5315551757812, "reward": 0.7920893430709839, "action": -1.0801410675048828}
{"mode": "train", "epochs": 5, "timestep": 9768, "ep_reward": 988.2609252929688, "reward": 0.7293577790260315, "action": -0.890207827091217}
{"mode": "train", "epochs": 5, "timestep": 9769, "ep_reward": 988.8950805664062, "reward": 0.6341845989227295, "action": -1.7457205057144165}
{"mode": "train", "epochs": 5, "timestep": 9770, "ep_reward": 989.3801879882812, "reward": 0.48511815071105957, "action": -0.37364304065704346}
{"mode": "train", "epochs": 5, "timestep": 9771, "ep_reward": 989.7479248046875, "reward": 0.36774539947509766, "action": -1.7039408683776855}
{"mode": "train", "epochs": 5, "timestep": 9772, "ep_reward": 990.0094604492188, "reward": 0.26153409481048584, "action": -0.7767850160598755}
{"mode": "train", "epochs": 5, "timestep": 9773, "ep_reward": 990.1446533203125, "reward": 0.13519108295440674, "action": -0.6096827983856201}
{"mode": "train", "epochs": 5, "timestep": 9774, "ep_reward": 990.1332397460938, "reward": -0.011395573616027832, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9775, "ep_reward": 990.2583618164062, "reward": 0.1250976324081421, "action": -1.480006456375122}
{"mode": "train", "epochs": 5, "timestep": 9776, "ep_reward": 990.5164794921875, "reward": 0.258117139339447, "action": -0.3989447355270386}
{"mode": "train", "epochs": 5, "timestep": 9777, "ep_reward": 990.921142578125, "reward": 0.4046545624732971, "action": -1.0751380920410156}
{"mode": "train", "epochs": 5, "timestep": 9778, "ep_reward": 991.4518432617188, "reward": 0.5306708216667175, "action": -0.7301965355873108}
{"mode": "train", "epochs": 5, "timestep": 9779, "ep_reward": 992.0936889648438, "reward": 0.641822338104248, "action": -1.6018638610839844}
{"mode": "train", "epochs": 5, "timestep": 9780, "ep_reward": 992.8153686523438, "reward": 0.7217010259628296, "action": -0.4395720362663269}
{"mode": "train", "epochs": 5, "timestep": 9781, "ep_reward": 993.6064453125, "reward": 0.7910881042480469, "action": -1.2316051721572876}
{"mode": "train", "epochs": 5, "timestep": 9782, "ep_reward": 994.438720703125, "reward": 0.8323029279708862, "action": -1.318289041519165}
{"mode": "train", "epochs": 5, "timestep": 9783, "ep_reward": 995.2936401367188, "reward": 0.8548904657363892, "action": -1.9478404521942139}
{"mode": "train", "epochs": 5, "timestep": 9784, "ep_reward": 996.1490478515625, "reward": 0.8553990125656128, "action": -1.0268865823745728}
{"mode": "train", "epochs": 5, "timestep": 9785, "ep_reward": 996.9949951171875, "reward": 0.8459258079528809, "action": -0.7237622737884521}
{"mode": "train", "epochs": 5, "timestep": 9786, "ep_reward": 997.8140869140625, "reward": 0.8190747499465942, "action": -1.0656569004058838}
{"mode": "train", "epochs": 5, "timestep": 9787, "ep_reward": 998.57861328125, "reward": 0.7645485997200012, "action": -0.7838713526725769}
{"mode": "train", "epochs": 5, "timestep": 9788, "ep_reward": 999.2611694335938, "reward": 0.6825478076934814, "action": -0.45502161979675293}
{"mode": "train", "epochs": 5, "timestep": 9789, "ep_reward": 999.8297119140625, "reward": 0.5685603618621826, "action": -0.38411521911621094}
{"mode": "train", "epochs": 5, "timestep": 9790, "ep_reward": 1000.2459106445312, "reward": 0.41619443893432617, "action": -1.752603530883789}
{"mode": "train", "epochs": 5, "timestep": 9791, "ep_reward": 1000.5440673828125, "reward": 0.29815393686294556, "action": -0.7746031284332275}
{"mode": "train", "epochs": 5, "timestep": 9792, "ep_reward": 1000.7223510742188, "reward": 0.17826509475708008, "action": -0.8411522507667542}
{"mode": "train", "epochs": 5, "timestep": 9793, "ep_reward": 1000.7607421875, "reward": 0.0383872389793396, "action": -0.7745029330253601}
{"mode": "train", "epochs": 5, "timestep": 9794, "ep_reward": 1000.8402709960938, "reward": 0.07949984073638916, "action": -1.0742098093032837}
{"mode": "train", "epochs": 5, "timestep": 9795, "ep_reward": 1001.0565185546875, "reward": 0.21626335382461548, "action": -0.47668009996414185}
{"mode": "train", "epochs": 5, "timestep": 9796, "ep_reward": 1001.4189453125, "reward": 0.36240726709365845, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9797, "ep_reward": 1001.900634765625, "reward": 0.48169922828674316, "action": -1.1252233982086182}
{"mode": "train", "epochs": 5, "timestep": 9798, "ep_reward": 1002.497802734375, "reward": 0.5971437692642212, "action": -0.6303293704986572}
{"mode": "train", "epochs": 5, "timestep": 9799, "ep_reward": 1003.1936645507812, "reward": 0.6958593130111694, "action": -1.140482783317566}
{"mode": "train", "epochs": 5, "timestep": 9800, "ep_reward": 1003.959228515625, "reward": 0.7655932903289795, "action": -1.2597562074661255}
{"mode": "train", "epochs": 5, "timestep": 9801, "ep_reward": 1004.7720947265625, "reward": 0.812889575958252, "action": -0.804904043674469}
{"mode": "train", "epochs": 5, "timestep": 9802, "ep_reward": 1005.6168212890625, "reward": 0.8446987867355347, "action": -1.4776564836502075}
{"mode": "train", "epochs": 5, "timestep": 9803, "ep_reward": 1006.4693603515625, "reward": 0.8525397777557373, "action": -1.5195058584213257}
{"mode": "train", "epochs": 5, "timestep": 9804, "ep_reward": 1007.3109741210938, "reward": 0.8415860533714294, "action": -1.6571621894836426}
{"mode": "train", "epochs": 5, "timestep": 9805, "ep_reward": 1008.1190185546875, "reward": 0.8080166578292847, "action": 0.392414927482605}
{"mode": "train", "epochs": 5, "timestep": 9806, "ep_reward": 1008.8895263671875, "reward": 0.7705221176147461, "action": -1.4334553480148315}
{"mode": "train", "epochs": 5, "timestep": 9807, "ep_reward": 1009.5732421875, "reward": 0.6837007403373718, "action": -0.6316416263580322}
{"mode": "train", "epochs": 5, "timestep": 9808, "ep_reward": 1010.1421508789062, "reward": 0.5689249038696289, "action": -0.7186784744262695}
{"mode": "train", "epochs": 5, "timestep": 9809, "ep_reward": 1010.5540771484375, "reward": 0.4119459390640259, "action": -0.31117868423461914}
{"mode": "train", "epochs": 5, "timestep": 9810, "ep_reward": 1010.8583374023438, "reward": 0.30427229404449463, "action": -0.9167503118515015}
{"mode": "train", "epochs": 5, "timestep": 9811, "ep_reward": 1011.0438842773438, "reward": 0.18553441762924194, "action": -0.6981330513954163}
{"mode": "train", "epochs": 5, "timestep": 9812, "ep_reward": 1011.090576171875, "reward": 0.046684861183166504, "action": -1.3721001148223877}
{"mode": "train", "epochs": 5, "timestep": 9813, "ep_reward": 1011.1620483398438, "reward": 0.0714450478553772, "action": 0.03309428691864014}
{"mode": "train", "epochs": 5, "timestep": 9814, "ep_reward": 1011.3836059570312, "reward": 0.22154128551483154, "action": -1.5571017265319824}
{"mode": "train", "epochs": 5, "timestep": 9815, "ep_reward": 1011.73583984375, "reward": 0.352213978767395, "action": -0.32390254735946655}
{"mode": "train", "epochs": 5, "timestep": 9816, "ep_reward": 1012.2277221679688, "reward": 0.4918738603591919, "action": -0.6743125915527344}
{"mode": "train", "epochs": 5, "timestep": 9817, "ep_reward": 1012.8375244140625, "reward": 0.6098265647888184, "action": -1.2620041370391846}
{"mode": "train", "epochs": 5, "timestep": 9818, "ep_reward": 1013.5379638671875, "reward": 0.7004643082618713, "action": -1.79264497756958}
{"mode": "train", "epochs": 5, "timestep": 9819, "ep_reward": 1014.3034057617188, "reward": 0.7654457092285156, "action": -1.2048799991607666}
{"mode": "train", "epochs": 5, "timestep": 9820, "ep_reward": 1015.1197509765625, "reward": 0.8163411617279053, "action": -1.1562350988388062}
{"mode": "train", "epochs": 5, "timestep": 9821, "ep_reward": 1015.968994140625, "reward": 0.8492464423179626, "action": -0.7746429443359375}
{"mode": "train", "epochs": 5, "timestep": 9822, "ep_reward": 1016.8375854492188, "reward": 0.868580162525177, "action": -0.28877097368240356}
{"mode": "train", "epochs": 5, "timestep": 9823, "ep_reward": 1017.7135009765625, "reward": 0.8759412169456482, "action": -1.4888660907745361}
{"mode": "train", "epochs": 5, "timestep": 9824, "ep_reward": 1018.5707397460938, "reward": 0.8572497367858887, "action": 0.3594188690185547}
{"mode": "train", "epochs": 5, "timestep": 9825, "ep_reward": 1019.4071655273438, "reward": 0.8363966941833496, "action": -1.8452677726745605}
{"mode": "train", "epochs": 5, "timestep": 9826, "ep_reward": 1020.1797485351562, "reward": 0.7725680470466614, "action": -0.11654061079025269}
{"mode": "train", "epochs": 5, "timestep": 9827, "ep_reward": 1020.8770751953125, "reward": 0.6973544359207153, "action": -1.544752836227417}
{"mode": "train", "epochs": 5, "timestep": 9828, "ep_reward": 1021.4469604492188, "reward": 0.5698874592781067, "action": -0.8613760471343994}
{"mode": "train", "epochs": 5, "timestep": 9829, "ep_reward": 1021.856689453125, "reward": 0.4097168445587158, "action": -1.0071572065353394}
{"mode": "train", "epochs": 5, "timestep": 9830, "ep_reward": 1022.1463623046875, "reward": 0.2896885275840759, "action": -1.386332631111145}
{"mode": "train", "epochs": 5, "timestep": 9831, "ep_reward": 1022.3147583007812, "reward": 0.16837060451507568, "action": -0.8039107322692871}
{"mode": "train", "epochs": 5, "timestep": 9832, "ep_reward": 1022.3417358398438, "reward": 0.026981592178344727, "action": -0.6852664351463318}
{"mode": "train", "epochs": 5, "timestep": 9833, "ep_reward": 1022.4321899414062, "reward": 0.09043598175048828, "action": -0.4185248017311096}
{"mode": "train", "epochs": 5, "timestep": 9834, "ep_reward": 1022.6677856445312, "reward": 0.23562604188919067, "action": -1.0512938499450684}
{"mode": "train", "epochs": 5, "timestep": 9835, "ep_reward": 1023.0406494140625, "reward": 0.3728782534599304, "action": -1.2013671398162842}
{"mode": "train", "epochs": 5, "timestep": 9836, "ep_reward": 1023.5408325195312, "reward": 0.5001751184463501, "action": -1.9052435159683228}
{"mode": "train", "epochs": 5, "timestep": 9837, "ep_reward": 1024.144775390625, "reward": 0.6039991974830627, "action": -0.32299143075942993}
{"mode": "train", "epochs": 5, "timestep": 9838, "ep_reward": 1024.8492431640625, "reward": 0.7044944763183594, "action": -0.5788329839706421}
{"mode": "train", "epochs": 5, "timestep": 9839, "ep_reward": 1025.627197265625, "reward": 0.7779526114463806, "action": -0.9837825298309326}
{"mode": "train", "epochs": 5, "timestep": 9840, "ep_reward": 1026.4534912109375, "reward": 0.8263131380081177, "action": -1.0515638589859009}
{"mode": "train", "epochs": 5, "timestep": 9841, "ep_reward": 1027.309326171875, "reward": 0.8558824062347412, "action": -0.8618072271347046}
{"mode": "train", "epochs": 5, "timestep": 9842, "ep_reward": 1028.179931640625, "reward": 0.8705692291259766, "action": -1.0948028564453125}
{"mode": "train", "epochs": 5, "timestep": 9843, "ep_reward": 1029.0472412109375, "reward": 0.8673118352890015, "action": -1.645999789237976}
{"mode": "train", "epochs": 5, "timestep": 9844, "ep_reward": 1029.888916015625, "reward": 0.8417226672172546, "action": -0.8840256929397583}
{"mode": "train", "epochs": 5, "timestep": 9845, "ep_reward": 1030.6903076171875, "reward": 0.8014152646064758, "action": -1.319353461265564}
{"mode": "train", "epochs": 5, "timestep": 9846, "ep_reward": 1031.419921875, "reward": 0.7296619415283203, "action": -0.30562520027160645}
{"mode": "train", "epochs": 5, "timestep": 9847, "ep_reward": 1032.05615234375, "reward": 0.6362539529800415, "action": -1.430001974105835}
{"mode": "train", "epochs": 5, "timestep": 9848, "ep_reward": 1032.5452880859375, "reward": 0.4891730546951294, "action": -0.6191648244857788}
{"mode": "train", "epochs": 5, "timestep": 9849, "ep_reward": 1032.893798828125, "reward": 0.34847724437713623, "action": -1.727762222290039}
{"mode": "train", "epochs": 5, "timestep": 9850, "ep_reward": 1033.1322021484375, "reward": 0.2383805513381958, "action": -0.38131457567214966}
{"mode": "train", "epochs": 5, "timestep": 9851, "ep_reward": 1033.240234375, "reward": 0.10806483030319214, "action": -0.8774704337120056}
{"mode": "train", "epochs": 5, "timestep": 9852, "ep_reward": 1033.2479248046875, "reward": 0.007731616497039795, "action": -1.8964416980743408}
{"mode": "train", "epochs": 5, "timestep": 9853, "ep_reward": 1033.399658203125, "reward": 0.1517753005027771, "action": -1.1173951625823975}
{"mode": "train", "epochs": 5, "timestep": 9854, "ep_reward": 1033.689453125, "reward": 0.28985345363616943, "action": -1.3284517526626587}
{"mode": "train", "epochs": 5, "timestep": 9855, "ep_reward": 1034.1124267578125, "reward": 0.42298567295074463, "action": -0.32995402812957764}
{"mode": "train", "epochs": 5, "timestep": 9856, "ep_reward": 1034.6680908203125, "reward": 0.5556818246841431, "action": -1.1011630296707153}
{"mode": "train", "epochs": 5, "timestep": 9857, "ep_reward": 1035.3265380859375, "reward": 0.6584689617156982, "action": -0.7166670560836792}
{"mode": "train", "epochs": 5, "timestep": 9858, "ep_reward": 1036.069091796875, "reward": 0.7425646781921387, "action": -1.7565315961837769}
{"mode": "train", "epochs": 5, "timestep": 9859, "ep_reward": 1036.8638916015625, "reward": 0.7948417663574219, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9860, "ep_reward": 1037.690185546875, "reward": 0.8262481689453125, "action": -0.5031548738479614}
{"mode": "train", "epochs": 5, "timestep": 9861, "ep_reward": 1038.5428466796875, "reward": 0.8526573777198792, "action": -0.4723894000053406}
{"mode": "train", "epochs": 5, "timestep": 9862, "ep_reward": 1039.404296875, "reward": 0.861420750617981, "action": -1.238031268119812}
{"mode": "train", "epochs": 5, "timestep": 9863, "ep_reward": 1040.2501220703125, "reward": 0.8457748293876648, "action": -0.3002883791923523}
{"mode": "train", "epochs": 5, "timestep": 9864, "ep_reward": 1041.0687255859375, "reward": 0.8186311721801758, "action": -1.0554289817810059}
{"mode": "train", "epochs": 5, "timestep": 9865, "ep_reward": 1041.8287353515625, "reward": 0.7600148916244507, "action": -0.3247112035751343}
{"mode": "train", "epochs": 5, "timestep": 9866, "ep_reward": 1042.5079345703125, "reward": 0.6791700720787048, "action": -1.6381351947784424}
{"mode": "train", "epochs": 5, "timestep": 9867, "ep_reward": 1043.052734375, "reward": 0.5448106527328491, "action": -0.6854058504104614}
{"mode": "train", "epochs": 5, "timestep": 9868, "ep_reward": 1043.434814453125, "reward": 0.3821409344673157, "action": -1.3862831592559814}
{"mode": "train", "epochs": 5, "timestep": 9869, "ep_reward": 1043.7137451171875, "reward": 0.2789217233657837, "action": -0.34337103366851807}
{"mode": "train", "epochs": 5, "timestep": 9870, "ep_reward": 1043.8692626953125, "reward": 0.15552616119384766, "action": -1.0479799509048462}
{"mode": "train", "epochs": 5, "timestep": 9871, "ep_reward": 1043.8814697265625, "reward": 0.01219087839126587, "action": -1.0356717109680176}
{"mode": "train", "epochs": 5, "timestep": 9872, "ep_reward": 1043.985595703125, "reward": 0.10414350032806396, "action": -0.7334320545196533}
{"mode": "train", "epochs": 5, "timestep": 9873, "ep_reward": 1044.2314453125, "reward": 0.2458782196044922, "action": -0.6037018895149231}
{"mode": "train", "epochs": 5, "timestep": 9874, "ep_reward": 1044.6202392578125, "reward": 0.3887398838996887, "action": -1.6952366828918457}
{"mode": "train", "epochs": 5, "timestep": 9875, "ep_reward": 1045.12890625, "reward": 0.5087192058563232, "action": -1.5354719161987305}
{"mode": "train", "epochs": 5, "timestep": 9876, "ep_reward": 1045.7440185546875, "reward": 0.6151702404022217, "action": -0.8938664197921753}
{"mode": "train", "epochs": 5, "timestep": 9877, "ep_reward": 1046.451416015625, "reward": 0.7073395252227783, "action": -1.3099827766418457}
{"mode": "train", "epochs": 5, "timestep": 9878, "ep_reward": 1047.223876953125, "reward": 0.7724779844284058, "action": -0.4862949848175049}
{"mode": "train", "epochs": 5, "timestep": 9879, "ep_reward": 1048.0478515625, "reward": 0.8239731788635254, "action": -1.1848382949829102}
{"mode": "train", "epochs": 5, "timestep": 9880, "ep_reward": 1048.897705078125, "reward": 0.8497998118400574, "action": -1.6825273036956787}
{"mode": "train", "epochs": 5, "timestep": 9881, "ep_reward": 1049.7518310546875, "reward": 0.8541113138198853, "action": -0.46479541063308716}
{"mode": "train", "epochs": 5, "timestep": 9882, "ep_reward": 1050.60302734375, "reward": 0.8512533903121948, "action": -0.6783943772315979}
{"mode": "train", "epochs": 5, "timestep": 9883, "ep_reward": 1051.43017578125, "reward": 0.8271133303642273, "action": -1.3942241668701172}
{"mode": "train", "epochs": 5, "timestep": 9884, "ep_reward": 1052.202392578125, "reward": 0.7722376585006714, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9885, "ep_reward": 1052.8809814453125, "reward": 0.6785316467285156, "action": -1.5095397233963013}
{"mode": "train", "epochs": 5, "timestep": 9886, "ep_reward": 1053.4306640625, "reward": 0.5496248602867126, "action": -0.3463895916938782}
{"mode": "train", "epochs": 5, "timestep": 9887, "ep_reward": 1053.8299560546875, "reward": 0.3992742896080017, "action": -0.6072777509689331}
{"mode": "train", "epochs": 5, "timestep": 9888, "ep_reward": 1054.12939453125, "reward": 0.29944097995758057, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9889, "ep_reward": 1054.3094482421875, "reward": 0.18005162477493286, "action": -0.6991696357727051}
{"mode": "train", "epochs": 5, "timestep": 9890, "ep_reward": 1054.349609375, "reward": 0.04022097587585449, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9891, "ep_reward": 1054.4271240234375, "reward": 0.0775499939918518, "action": -0.8803619742393494}
{"mode": "train", "epochs": 5, "timestep": 9892, "ep_reward": 1054.6436767578125, "reward": 0.21656745672225952, "action": -1.311378836631775}
{"mode": "train", "epochs": 5, "timestep": 9893, "ep_reward": 1054.9959716796875, "reward": 0.35225164890289307, "action": -0.9242627024650574}
{"mode": "train", "epochs": 5, "timestep": 9894, "ep_reward": 1055.481689453125, "reward": 0.48575133085250854, "action": -1.6970233917236328}
{"mode": "train", "epochs": 5, "timestep": 9895, "ep_reward": 1056.07568359375, "reward": 0.5940133333206177, "action": -1.5973865985870361}
{"mode": "train", "epochs": 5, "timestep": 9896, "ep_reward": 1056.759033203125, "reward": 0.6833608150482178, "action": -0.9655370712280273}
{"mode": "train", "epochs": 5, "timestep": 9897, "ep_reward": 1057.515380859375, "reward": 0.7563316822052002, "action": -1.9239050149917603}
{"mode": "train", "epochs": 5, "timestep": 9898, "ep_reward": 1058.313232421875, "reward": 0.7978079319000244, "action": -0.4630948305130005}
{"mode": "train", "epochs": 5, "timestep": 9899, "ep_reward": 1059.1456298828125, "reward": 0.8324037194252014, "action": -1.1480728387832642}
{"mode": "train", "epochs": 5, "timestep": 9900, "ep_reward": 1059.9862060546875, "reward": 0.8405975699424744, "action": -1.7181222438812256}
{"mode": "train", "epochs": 5, "timestep": 9901, "ep_reward": 1060.8095703125, "reward": 0.8233585953712463, "action": -0.41307348012924194}
{"mode": "train", "epochs": 5, "timestep": 9902, "ep_reward": 1061.6053466796875, "reward": 0.795760989189148, "action": -1.5728169679641724}
{"mode": "train", "epochs": 5, "timestep": 9903, "ep_reward": 1062.33349609375, "reward": 0.7282066345214844, "action": -1.932534098625183}
{"mode": "train", "epochs": 5, "timestep": 9904, "ep_reward": 1062.95263671875, "reward": 0.6191763281822205, "action": -0.34032952785491943}
{"mode": "train", "epochs": 5, "timestep": 9905, "ep_reward": 1063.441162109375, "reward": 0.48848944902420044, "action": 0.12049782276153564}
{"mode": "train", "epochs": 5, "timestep": 9906, "ep_reward": 1063.8089599609375, "reward": 0.36778533458709717, "action": -0.9202405214309692}
{"mode": "train", "epochs": 5, "timestep": 9907, "ep_reward": 1064.0703125, "reward": 0.26135045289993286, "action": -1.352826476097107}
{"mode": "train", "epochs": 5, "timestep": 9908, "ep_reward": 1064.205322265625, "reward": 0.13506174087524414, "action": -0.6610129475593567}
{"mode": "train", "epochs": 5, "timestep": 9909, "ep_reward": 1064.1937255859375, "reward": -0.011539340019226074, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9910, "ep_reward": 1064.3189697265625, "reward": 0.125266432762146, "action": -1.2313729524612427}
{"mode": "train", "epochs": 5, "timestep": 9911, "ep_reward": 1064.580322265625, "reward": 0.2614104747772217, "action": -0.22264760732650757}
{"mode": "train", "epochs": 5, "timestep": 9912, "ep_reward": 1064.98974609375, "reward": 0.4093695878982544, "action": -1.2578470706939697}
{"mode": "train", "epochs": 5, "timestep": 9913, "ep_reward": 1065.5220947265625, "reward": 0.5323952436447144, "action": 0.08337652683258057}
{"mode": "train", "epochs": 5, "timestep": 9914, "ep_reward": 1066.173828125, "reward": 0.6517652273178101, "action": -0.6957795023918152}
{"mode": "train", "epochs": 5, "timestep": 9915, "ep_reward": 1066.91259765625, "reward": 0.7387868165969849, "action": -0.8643336296081543}
{"mode": "train", "epochs": 5, "timestep": 9916, "ep_reward": 1067.7149658203125, "reward": 0.8023651838302612, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9917, "ep_reward": 1068.552978515625, "reward": 0.8379524946212769, "action": -1.1644138097763062}
{"mode": "train", "epochs": 5, "timestep": 9918, "ep_reward": 1069.41748046875, "reward": 0.8644556999206543, "action": -0.7362033128738403}
{"mode": "train", "epochs": 5, "timestep": 9919, "ep_reward": 1070.29638671875, "reward": 0.8789334893226624, "action": -1.1364450454711914}
{"mode": "train", "epochs": 5, "timestep": 9920, "ep_reward": 1071.171630859375, "reward": 0.8752449750900269, "action": -1.0563607215881348}
{"mode": "train", "epochs": 5, "timestep": 9921, "ep_reward": 1072.027587890625, "reward": 0.8559212684631348, "action": -0.7657784223556519}
{"mode": "train", "epochs": 5, "timestep": 9922, "ep_reward": 1072.847412109375, "reward": 0.8198326826095581, "action": -0.3776055574417114}
{"mode": "train", "epochs": 5, "timestep": 9923, "ep_reward": 1073.611328125, "reward": 0.7638651728630066, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9924, "ep_reward": 1074.2703857421875, "reward": 0.6590880155563354, "action": -0.6594926118850708}
{"mode": "train", "epochs": 5, "timestep": 9925, "ep_reward": 1074.8017578125, "reward": 0.5313241481781006, "action": -0.1283971071243286}
{"mode": "train", "epochs": 5, "timestep": 9926, "ep_reward": 1075.1744384765625, "reward": 0.3726493716239929, "action": -0.8943296670913696}
{"mode": "train", "epochs": 5, "timestep": 9927, "ep_reward": 1075.4344482421875, "reward": 0.2600547671318054, "action": -0.931128978729248}
{"mode": "train", "epochs": 5, "timestep": 9928, "ep_reward": 1075.56787109375, "reward": 0.1333904266357422, "action": -1.325562834739685}
{"mode": "train", "epochs": 5, "timestep": 9929, "ep_reward": 1075.5546875, "reward": -0.013158917427062988, "action": -0.8770645260810852}
{"mode": "train", "epochs": 5, "timestep": 9930, "ep_reward": 1075.6815185546875, "reward": 0.12688755989074707, "action": -1.1044719219207764}
{"mode": "train", "epochs": 5, "timestep": 9931, "ep_reward": 1075.946044921875, "reward": 0.2644956707954407, "action": -1.5255248546600342}
{"mode": "train", "epochs": 5, "timestep": 9932, "ep_reward": 1076.3424072265625, "reward": 0.39633363485336304, "action": -1.0995814800262451}
{"mode": "train", "epochs": 5, "timestep": 9933, "ep_reward": 1076.8662109375, "reward": 0.5237624645233154, "action": -0.15196168422698975}
{"mode": "train", "epochs": 5, "timestep": 9934, "ep_reward": 1077.5086669921875, "reward": 0.642456591129303, "action": -1.17388117313385}
{"mode": "train", "epochs": 5, "timestep": 9935, "ep_reward": 1078.2347412109375, "reward": 0.7260969281196594, "action": -0.5887826681137085}
{"mode": "train", "epochs": 5, "timestep": 9936, "ep_reward": 1079.02783203125, "reward": 0.7930328845977783, "action": -0.8979373574256897}
{"mode": "train", "epochs": 5, "timestep": 9937, "ep_reward": 1079.8641357421875, "reward": 0.8363115191459656, "action": -1.1884386539459229}
{"mode": "train", "epochs": 5, "timestep": 9938, "ep_reward": 1080.723388671875, "reward": 0.8592678308486938, "action": -1.5297701358795166}
{"mode": "train", "epochs": 5, "timestep": 9939, "ep_reward": 1081.58642578125, "reward": 0.8630567193031311, "action": -0.7503267526626587}
{"mode": "train", "epochs": 5, "timestep": 9940, "ep_reward": 1082.4427490234375, "reward": 0.8562984466552734, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9941, "ep_reward": 1083.2615966796875, "reward": 0.8187959790229797, "action": -0.48411500453948975}
{"mode": "train", "epochs": 5, "timestep": 9942, "ep_reward": 1084.032958984375, "reward": 0.771336019039154, "action": -1.293103575706482}
{"mode": "train", "epochs": 5, "timestep": 9943, "ep_reward": 1084.7181396484375, "reward": 0.6851910352706909, "action": -0.7824491262435913}
{"mode": "train", "epochs": 5, "timestep": 9944, "ep_reward": 1085.285888671875, "reward": 0.5677211284637451, "action": -1.002657413482666}
{"mode": "train", "epochs": 5, "timestep": 9945, "ep_reward": 1085.6912841796875, "reward": 0.40535658597946167, "action": -1.3914825916290283}
{"mode": "train", "epochs": 5, "timestep": 9946, "ep_reward": 1085.990966796875, "reward": 0.2996656894683838, "action": -1.4303622245788574}
{"mode": "train", "epochs": 5, "timestep": 9947, "ep_reward": 1086.171142578125, "reward": 0.18016737699508667, "action": -0.7593684196472168}
{"mode": "train", "epochs": 5, "timestep": 9948, "ep_reward": 1086.211669921875, "reward": 0.04058516025543213, "action": -0.641795814037323}
{"mode": "train", "epochs": 5, "timestep": 9949, "ep_reward": 1086.2890625, "reward": 0.07739537954330444, "action": -1.041420340538025}
{"mode": "train", "epochs": 5, "timestep": 9950, "ep_reward": 1086.5035400390625, "reward": 0.21446442604064941, "action": -0.8382089138031006}
{"mode": "train", "epochs": 5, "timestep": 9951, "ep_reward": 1086.85986328125, "reward": 0.3563655614852905, "action": -0.8385936617851257}
{"mode": "train", "epochs": 5, "timestep": 9952, "ep_reward": 1087.3499755859375, "reward": 0.4901670217514038, "action": -1.1181257963180542}
{"mode": "train", "epochs": 5, "timestep": 9953, "ep_reward": 1087.9541015625, "reward": 0.6040880680084229, "action": -0.8947986364364624}
{"mode": "train", "epochs": 5, "timestep": 9954, "ep_reward": 1088.6531982421875, "reward": 0.6990903615951538, "action": -1.1234419345855713}
{"mode": "train", "epochs": 5, "timestep": 9955, "ep_reward": 1089.42236328125, "reward": 0.7691324353218079, "action": -1.012020230293274}
{"mode": "train", "epochs": 5, "timestep": 9956, "ep_reward": 1090.2415771484375, "reward": 0.8192564249038696, "action": -1.0594844818115234}
{"mode": "train", "epochs": 5, "timestep": 9957, "ep_reward": 1091.0916748046875, "reward": 0.8500537872314453, "action": -1.5946640968322754}
{"mode": "train", "epochs": 5, "timestep": 9958, "ep_reward": 1091.951171875, "reward": 0.8594403266906738, "action": 0.04439115524291992}
{"mode": "train", "epochs": 5, "timestep": 9959, "ep_reward": 1092.8172607421875, "reward": 0.8660393953323364, "action": -0.9180219769477844}
{"mode": "train", "epochs": 5, "timestep": 9960, "ep_reward": 1093.6639404296875, "reward": 0.8467288613319397, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9961, "ep_reward": 1094.4598388671875, "reward": 0.795912504196167, "action": 0.06785809993743896}
{"mode": "train", "epochs": 5, "timestep": 9962, "ep_reward": 1095.1990966796875, "reward": 0.7393009662628174, "action": -0.5126111507415771}
{"mode": "train", "epochs": 5, "timestep": 9963, "ep_reward": 1095.8446044921875, "reward": 0.6455128192901611, "action": -1.1844282150268555}
{"mode": "train", "epochs": 5, "timestep": 9964, "ep_reward": 1096.3492431640625, "reward": 0.504654049873352, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9965, "ep_reward": 1096.7017822265625, "reward": 0.35256844758987427, "action": -1.1078795194625854}
{"mode": "train", "epochs": 5, "timestep": 9966, "ep_reward": 1096.94482421875, "reward": 0.24306422472000122, "action": -1.2908836603164673}
{"mode": "train", "epochs": 5, "timestep": 9967, "ep_reward": 1097.0584716796875, "reward": 0.11367201805114746, "action": -0.5223361849784851}
{"mode": "train", "epochs": 5, "timestep": 9968, "ep_reward": 1097.0601806640625, "reward": 0.0016720890998840332, "action": -1.4611629247665405}
{"mode": "train", "epochs": 5, "timestep": 9969, "ep_reward": 1097.2064208984375, "reward": 0.1462498903274536, "action": -2.0}
{"mode": "train", "epochs": 5, "timestep": 9970, "ep_reward": 1097.4796142578125, "reward": 0.27324944734573364, "action": -0.9196186661720276}
{"mode": "train", "epochs": 5, "timestep": 9971, "ep_reward": 1097.8934326171875, "reward": 0.4138072729110718, "action": -0.6777198314666748}
{"mode": "train", "epochs": 5, "timestep": 9972, "ep_reward": 1098.4376220703125, "reward": 0.5442323088645935, "action": -0.6256300210952759}
{"mode": "train", "epochs": 5, "timestep": 9973, "ep_reward": 1099.091552734375, "reward": 0.6539442539215088, "action": -1.5861198902130127}
{"mode": "train", "epochs": 5, "timestep": 9974, "ep_reward": 1099.8218994140625, "reward": 0.7303545475006104, "action": -0.9277783632278442}
{"mode": "train", "epochs": 5, "timestep": 9975, "ep_reward": 1100.61328125, "reward": 0.791344404220581, "action": -1.0681072473526}
{"mode": "train", "epochs": 5, "timestep": 9976, "ep_reward": 1101.4434814453125, "reward": 0.8301711678504944, "action": -0.2630784511566162}
{"mode": "train", "epochs": 5, "timestep": 9977, "ep_reward": 1102.3006591796875, "reward": 0.8571544885635376, "action": -1.1346904039382935}
{"mode": "train", "epochs": 5, "timestep": 9978, "ep_reward": 1103.15966796875, "reward": 0.8590003252029419, "action": -1.469227910041809}
{"mode": "train", "epochs": 5, "timestep": 9979, "ep_reward": 1103.9993896484375, "reward": 0.8396983742713928, "action": -0.9580603837966919}
{"mode": "train", "epochs": 5, "timestep": 9980, "ep_reward": 1104.8028564453125, "reward": 0.8034802079200745, "action": -1.39315927028656}
{"mode": "train", "epochs": 5, "timestep": 9981, "ep_reward": 1105.538818359375, "reward": 0.7359145879745483, "action": -0.5195430517196655}
{"mode": "train", "epochs": 5, "timestep": 9982, "ep_reward": 1106.1837158203125, "reward": 0.6449111700057983, "action": -1.068737506866455}
{"mode": "train", "epochs": 5, "timestep": 9983, "ep_reward": 1106.6915283203125, "reward": 0.5078346133232117, "action": -0.5542842149734497}
{"mode": "train", "epochs": 5, "timestep": 9984, "ep_reward": 1107.056396484375, "reward": 0.3648872971534729, "action": -0.8285821080207825}
{"mode": "train", "epochs": 5, "timestep": 9985, "ep_reward": 1107.314208984375, "reward": 0.25780707597732544, "action": -1.5388100147247314}
{"mode": "train", "epochs": 5, "timestep": 9986, "ep_reward": 1107.4451904296875, "reward": 0.1309717893600464, "action": -0.30312567949295044}
{"mode": "train", "epochs": 5, "timestep": 9987, "ep_reward": 1107.4290771484375, "reward": -0.016081809997558594, "action": -1.1264424324035645}
{"mode": "train", "epochs": 5, "timestep": 9988, "ep_reward": 1107.5584716796875, "reward": 0.12943905591964722, "action": -0.965169370174408}
{"mode": "train", "epochs": 5, "timestep": 9989, "ep_reward": 1107.827392578125, "reward": 0.2689439058303833, "action": -0.8764855265617371}
{"mode": "train", "epochs": 5, "timestep": 9990, "ep_reward": 1108.2354736328125, "reward": 0.40811312198638916, "action": -1.4207584857940674}
{"mode": "train", "epochs": 5, "timestep": 9991, "ep_reward": 1108.76513671875, "reward": 0.5296880602836609, "action": -1.265243411064148}
{"mode": "train", "epochs": 5, "timestep": 9992, "ep_reward": 1109.400634765625, "reward": 0.6354804039001465, "action": -0.729586124420166}
{"mode": "train", "epochs": 5, "timestep": 9993, "ep_reward": 1110.1253662109375, "reward": 0.724683940410614, "action": -0.16172891855239868}
{"mode": "train", "epochs": 5, "timestep": 9994, "ep_reward": 1110.9210205078125, "reward": 0.7956428527832031, "action": -1.0044890642166138}
{"mode": "train", "epochs": 5, "timestep": 9995, "ep_reward": 1111.7587890625, "reward": 0.8378063440322876, "action": -0.5271521210670471}
{"mode": "train", "epochs": 5, "timestep": 9996, "ep_reward": 1112.6251220703125, "reward": 0.8663399815559387, "action": -0.5556554794311523}
{"mode": "train", "epochs": 5, "timestep": 9997, "ep_reward": 1113.5037841796875, "reward": 0.8787013292312622, "action": -0.34455257654190063}
{"mode": "train", "epochs": 5, "timestep": 9998, "ep_reward": 1114.3814697265625, "reward": 0.8777104616165161, "action": -0.6546026468276978}
{"mode": "train", "epochs": 5, "timestep": 9999, "ep_reward": 1115.2396240234375, "reward": 0.8582099676132202, "action": -1.5530554056167603}
{"mode": "train", "epochs": 5, "timestep": 10000, "ep_reward": 1116.0506591796875, "reward": 0.8110790252685547, "action": -0.8150373697280884}
{"mode": "train", "epochs": 6, "timestep": 10001, "ep_reward": 0.6272229552268982, "reward": 0.6272229552268982, "action": 0.5751456618309021}
{"mode": "train", "epochs": 6, "timestep": 10002, "ep_reward": 1.2550805807113647, "reward": 0.6278576254844666, "action": 1.948157548904419}
{"mode": "train", "epochs": 6, "timestep": 10003, "ep_reward": 1.8660669326782227, "reward": 0.6109863519668579, "action": 0.9521842002868652}
{"mode": "train", "epochs": 6, "timestep": 10004, "ep_reward": 2.446014881134033, "reward": 0.5799480676651001, "action": 0.5641156435012817}
{"mode": "train", "epochs": 6, "timestep": 10005, "ep_reward": 2.9839701652526855, "reward": 0.5379553437232971, "action": 0.4567723274230957}
{"mode": "train", "epochs": 6, "timestep": 10006, "ep_reward": 3.4706833362579346, "reward": 0.4867132306098938, "action": 0.10732966661453247}
{"mode": "train", "epochs": 6, "timestep": 10007, "ep_reward": 3.901308536529541, "reward": 0.43062514066696167, "action": 1.3185638189315796}
{"mode": "train", "epochs": 6, "timestep": 10008, "ep_reward": 4.262353897094727, "reward": 0.36104512214660645, "action": 0.7704885601997375}
{"mode": "train", "epochs": 6, "timestep": 10009, "ep_reward": 4.608113765716553, "reward": 0.34575986862182617, "action": 1.0019015073776245}
{"mode": "train", "epochs": 6, "timestep": 10010, "ep_reward": 5.011664867401123, "reward": 0.403550922870636, "action": 1.0430574417114258}
{"mode": "train", "epochs": 6, "timestep": 10011, "ep_reward": 5.474030017852783, "reward": 0.46236521005630493, "action": 1.0213195085525513}
{"mode": "train", "epochs": 6, "timestep": 10012, "ep_reward": 5.994359016418457, "reward": 0.5203288793563843, "action": 1.4013644456863403}
{"mode": "train", "epochs": 6, "timestep": 10013, "ep_reward": 6.56836462020874, "reward": 0.5740057229995728, "action": 1.1220908164978027}
{"mode": "train", "epochs": 6, "timestep": 10014, "ep_reward": 7.192716121673584, "reward": 0.6243513226509094, "action": 1.1684399843215942}
{"mode": "train", "epochs": 6, "timestep": 10015, "ep_reward": 7.860565185546875, "reward": 0.667849063873291, "action": 1.3973660469055176}
{"mode": "train", "epochs": 6, "timestep": 10016, "ep_reward": 8.56385326385498, "reward": 0.7032877206802368, "action": 0.19393956661224365}
{"mode": "train", "epochs": 6, "timestep": 10017, "ep_reward": 9.29523754119873, "reward": 0.7313845753669739, "action": 0.3915271759033203}
{"mode": "train", "epochs": 6, "timestep": 10018, "ep_reward": 10.041705131530762, "reward": 0.7464674711227417, "action": 1.2158818244934082}
{"mode": "train", "epochs": 6, "timestep": 10019, "ep_reward": 10.792308807373047, "reward": 0.7506040930747986, "action": -0.6426168084144592}
{"mode": "train", "epochs": 6, "timestep": 10020, "ep_reward": 11.532242774963379, "reward": 0.7399338483810425, "action": -1.233406662940979}
{"mode": "train", "epochs": 6, "timestep": 10021, "ep_reward": 12.241291046142578, "reward": 0.7090479135513306, "action": -1.004987359046936}
{"mode": "train", "epochs": 6, "timestep": 10022, "ep_reward": 12.900384902954102, "reward": 0.6590934991836548, "action": -0.7079120874404907}
{"mode": "train", "epochs": 6, "timestep": 10023, "ep_reward": 13.493036270141602, "reward": 0.5926511287689209, "action": -1.183802843093872}
{"mode": "train", "epochs": 6, "timestep": 10024, "ep_reward": 13.999349594116211, "reward": 0.5063134431838989, "action": -0.9674148559570312}
{"mode": "train", "epochs": 6, "timestep": 10025, "ep_reward": 14.406834602355957, "reward": 0.4074854254722595, "action": -0.9038372039794922}
{"mode": "train", "epochs": 6, "timestep": 10026, "ep_reward": 14.707125663757324, "reward": 0.3002914786338806, "action": -1.3615009784698486}
{"mode": "train", "epochs": 6, "timestep": 10027, "ep_reward": 14.977209091186523, "reward": 0.2700836658477783, "action": -0.26521700620651245}
{"mode": "train", "epochs": 6, "timestep": 10028, "ep_reward": 15.339656829833984, "reward": 0.3624478578567505, "action": -0.9984504580497742}
{"mode": "train", "epochs": 6, "timestep": 10029, "ep_reward": 15.78916072845459, "reward": 0.44950413703918457, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 10030, "ep_reward": 16.317485809326172, "reward": 0.5283247232437134, "action": -1.1124423742294312}
{"mode": "train", "epochs": 6, "timestep": 10031, "ep_reward": 16.927133560180664, "reward": 0.6096472144126892, "action": -0.8817207217216492}
{"mode": "train", "epochs": 6, "timestep": 10032, "ep_reward": 17.610565185546875, "reward": 0.6834322214126587, "action": 0.23308193683624268}
{"mode": "train", "epochs": 6, "timestep": 10033, "ep_reward": 18.360719680786133, "reward": 0.7501550912857056, "action": -1.0108774900436401}
{"mode": "train", "epochs": 6, "timestep": 10034, "ep_reward": 19.157188415527344, "reward": 0.7964680194854736, "action": -1.0904139280319214}
{"mode": "train", "epochs": 6, "timestep": 10035, "ep_reward": 19.988039016723633, "reward": 0.830851137638092, "action": -1.9298467636108398}
{"mode": "train", "epochs": 6, "timestep": 10036, "ep_reward": 20.841903686523438, "reward": 0.8538647294044495, "action": -1.0353002548217773}
{"mode": "train", "epochs": 6, "timestep": 10037, "ep_reward": 21.711631774902344, "reward": 0.869727611541748, "action": -0.9631502032279968}
{"mode": "train", "epochs": 6, "timestep": 10038, "ep_reward": 22.5875244140625, "reward": 0.8758929967880249, "action": -0.13663628697395325}
{"mode": "train", "epochs": 6, "timestep": 10039, "ep_reward": 23.458040237426758, "reward": 0.8705164194107056, "action": 0.5158155560493469}
{"mode": "train", "epochs": 6, "timestep": 10040, "ep_reward": 24.307525634765625, "reward": 0.8494844436645508, "action": -0.3421614170074463}
{"mode": "train", "epochs": 6, "timestep": 10041, "ep_reward": 25.123340606689453, "reward": 0.8158154487609863, "action": -0.2851080596446991}
{"mode": "train", "epochs": 6, "timestep": 10042, "ep_reward": 25.890235900878906, "reward": 0.7668957710266113, "action": -0.5263757705688477}
{"mode": "train", "epochs": 6, "timestep": 10043, "ep_reward": 26.593843460083008, "reward": 0.7036070823669434, "action": 0.4256601333618164}
{"mode": "train", "epochs": 6, "timestep": 10044, "ep_reward": 27.20929718017578, "reward": 0.6154542565345764, "action": 0.7711316347122192}
{"mode": "train", "epochs": 6, "timestep": 10045, "ep_reward": 27.71354103088379, "reward": 0.5042435526847839, "action": -0.0706339031457901}
{"mode": "train", "epochs": 6, "timestep": 10046, "ep_reward": 28.09978485107422, "reward": 0.3862442970275879, "action": 0.5315496921539307}
{"mode": "train", "epochs": 6, "timestep": 10047, "ep_reward": 28.352474212646484, "reward": 0.25269031524658203, "action": -0.25124943256378174}
{"mode": "train", "epochs": 6, "timestep": 10048, "ep_reward": 28.539464950561523, "reward": 0.18698984384536743, "action": -0.7966578006744385}
{"mode": "train", "epochs": 6, "timestep": 10049, "ep_reward": 28.845829010009766, "reward": 0.30636316537857056, "action": -0.9353323578834534}
{"mode": "train", "epochs": 6, "timestep": 10050, "ep_reward": 29.270389556884766, "reward": 0.42456090450286865, "action": -0.4053337872028351}
{"mode": "train", "epochs": 6, "timestep": 10051, "ep_reward": 29.800796508789062, "reward": 0.5304077863693237, "action": 0.43185290694236755}
{"mode": "train", "epochs": 6, "timestep": 10052, "ep_reward": 30.420188903808594, "reward": 0.6193920373916626, "action": 0.5562881827354431}
{"mode": "train", "epochs": 6, "timestep": 10053, "ep_reward": 31.115707397460938, "reward": 0.6955188512802124, "action": 1.9601609706878662}
{"mode": "train", "epochs": 6, "timestep": 10054, "ep_reward": 31.86783790588379, "reward": 0.7521306872367859, "action": 1.4848145246505737}
{"mode": "train", "epochs": 6, "timestep": 10055, "ep_reward": 32.669246673583984, "reward": 0.8014070391654968, "action": 0.37158507108688354}
{"mode": "train", "epochs": 6, "timestep": 10056, "ep_reward": 33.51252365112305, "reward": 0.8432774543762207, "action": 0.33362746238708496}
{"mode": "train", "epochs": 6, "timestep": 10057, "ep_reward": 34.38438034057617, "reward": 0.8718550205230713, "action": -0.21495729684829712}
{"mode": "train", "epochs": 6, "timestep": 10058, "ep_reward": 35.27238464355469, "reward": 0.8880059719085693, "action": 1.8822683095932007}
{"mode": "train", "epochs": 6, "timestep": 10059, "ep_reward": 36.16547393798828, "reward": 0.8930908441543579, "action": 0.6484255790710449}
{"mode": "train", "epochs": 6, "timestep": 10060, "ep_reward": 37.05522537231445, "reward": 0.8897523283958435, "action": 0.7732118964195251}
{"mode": "train", "epochs": 6, "timestep": 10061, "ep_reward": 37.93165969848633, "reward": 0.8764350414276123, "action": -1.1906695365905762}
{"mode": "train", "epochs": 6, "timestep": 10062, "ep_reward": 38.77490234375, "reward": 0.8432439565658569, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 10063, "ep_reward": 39.55849075317383, "reward": 0.7835870981216431, "action": -1.9172307252883911}
{"mode": "train", "epochs": 6, "timestep": 10064, "ep_reward": 40.2551155090332, "reward": 0.6966243982315063, "action": -0.7338758111000061}
{"mode": "train", "epochs": 6, "timestep": 10065, "ep_reward": 40.847537994384766, "reward": 0.5924211740493774, "action": -1.9605982303619385}
{"mode": "train", "epochs": 6, "timestep": 10066, "ep_reward": 41.297706604003906, "reward": 0.4501689076423645, "action": -0.1177862286567688}
{"mode": "train", "epochs": 6, "timestep": 10067, "ep_reward": 41.60696029663086, "reward": 0.309253454208374, "action": -1.5806884765625}
{"mode": "train", "epochs": 6, "timestep": 10068, "ep_reward": 41.745628356933594, "reward": 0.13866698741912842, "action": -0.392846941947937}
{"mode": "train", "epochs": 6, "timestep": 10069, "ep_reward": 41.89683151245117, "reward": 0.15120184421539307, "action": -0.9130668640136719}
{"mode": "train", "epochs": 6, "timestep": 10070, "ep_reward": 42.17115783691406, "reward": 0.2743273377418518, "action": -1.5400314331054688}
{"mode": "train", "epochs": 6, "timestep": 10071, "ep_reward": 42.563838958740234, "reward": 0.39268070459365845, "action": -1.0798792839050293}
{"mode": "train", "epochs": 6, "timestep": 10072, "ep_reward": 43.07590103149414, "reward": 0.5120635032653809, "action": -0.38013678789138794}
{"mode": "train", "epochs": 6, "timestep": 10073, "ep_reward": 43.70164489746094, "reward": 0.6257438659667969, "action": -1.2410383224487305}
{"mode": "train", "epochs": 6, "timestep": 10074, "ep_reward": 44.41490936279297, "reward": 0.7132646441459656, "action": -1.4626480340957642}
{"mode": "train", "epochs": 6, "timestep": 10075, "ep_reward": 45.1967658996582, "reward": 0.7818548679351807, "action": -1.3130218982696533}
{"mode": "train", "epochs": 6, "timestep": 10076, "ep_reward": 46.032352447509766, "reward": 0.8355876803398132, "action": -1.4451799392700195}
{"mode": "train", "epochs": 6, "timestep": 10077, "ep_reward": 46.906707763671875, "reward": 0.8743534684181213, "action": -0.596800684928894}
{"mode": "train", "epochs": 6, "timestep": 10078, "ep_reward": 47.813079833984375, "reward": 0.9063721895217896, "action": -1.160459280014038}
{"mode": "train", "epochs": 6, "timestep": 10079, "ep_reward": 48.73784255981445, "reward": 0.9247632622718811, "action": 0.08694422245025635}
{"mode": "train", "epochs": 6, "timestep": 10080, "ep_reward": 49.67934799194336, "reward": 0.94150710105896, "action": -1.803731918334961}
{"mode": "train", "epochs": 6, "timestep": 10081, "ep_reward": 50.62006759643555, "reward": 0.9407209157943726, "action": -1.822070837020874}
{"mode": "train", "epochs": 6, "timestep": 10082, "ep_reward": 51.55235290527344, "reward": 0.9322871565818787, "action": -0.4582133889198303}
{"mode": "train", "epochs": 6, "timestep": 10083, "ep_reward": 52.475399017333984, "reward": 0.923045814037323, "action": -0.19278055429458618}
{"mode": "train", "epochs": 6, "timestep": 10084, "ep_reward": 53.38068771362305, "reward": 0.9052895307540894, "action": -1.705954909324646}
{"mode": "train", "epochs": 6, "timestep": 10085, "ep_reward": 54.243648529052734, "reward": 0.8629621267318726, "action": -0.873940646648407}
{"mode": "train", "epochs": 6, "timestep": 10086, "ep_reward": 55.05057907104492, "reward": 0.806929349899292, "action": -1.6532106399536133}
{"mode": "train", "epochs": 6, "timestep": 10087, "ep_reward": 55.7673454284668, "reward": 0.7167671918869019, "action": -1.3979370594024658}
{"mode": "train", "epochs": 6, "timestep": 10088, "ep_reward": 56.36143493652344, "reward": 0.5940894484519958, "action": -1.4243084192276}
{"mode": "train", "epochs": 6, "timestep": 10089, "ep_reward": 56.79256057739258, "reward": 0.43112385272979736, "action": -1.7246224880218506}
{"mode": "train", "epochs": 6, "timestep": 10090, "ep_reward": 57.07030487060547, "reward": 0.277743399143219, "action": -1.421586036682129}
{"mode": "train", "epochs": 6, "timestep": 10091, "ep_reward": 57.22466278076172, "reward": 0.1543560028076172, "action": 0.0996391773223877}
{"mode": "train", "epochs": 6, "timestep": 10092, "ep_reward": 57.23540496826172, "reward": 0.010742008686065674, "action": -1.274413824081421}
{"mode": "train", "epochs": 6, "timestep": 10093, "ep_reward": 57.34083938598633, "reward": 0.10543471574783325, "action": -0.7089388370513916}
{"mode": "train", "epochs": 6, "timestep": 10094, "ep_reward": 57.58835220336914, "reward": 0.24751293659210205, "action": -0.37575745582580566}
{"mode": "train", "epochs": 6, "timestep": 10095, "ep_reward": 57.98146438598633, "reward": 0.39311110973358154, "action": -0.9706488847732544}
{"mode": "train", "epochs": 6, "timestep": 10096, "ep_reward": 58.50214385986328, "reward": 0.5206801295280457, "action": -0.90559321641922}
{"mode": "train", "epochs": 6, "timestep": 10097, "ep_reward": 59.13378143310547, "reward": 0.6316385269165039, "action": -0.995753288269043}
{"mode": "train", "epochs": 6, "timestep": 10098, "ep_reward": 59.85404586791992, "reward": 0.7202627658843994, "action": -0.5447533130645752}
{"mode": "train", "epochs": 6, "timestep": 10099, "ep_reward": 60.64524459838867, "reward": 0.7911987900733948, "action": -1.022492527961731}
{"mode": "train", "epochs": 6, "timestep": 10100, "ep_reward": 61.483028411865234, "reward": 0.837782621383667, "action": -1.015988826751709}
{"mode": "train", "epochs": 6, "timestep": 10101, "ep_reward": 62.35063171386719, "reward": 0.8676015138626099, "action": -0.3830074667930603}
{"mode": "train", "epochs": 6, "timestep": 10102, "ep_reward": 63.237998962402344, "reward": 0.8873653411865234, "action": -0.2112608551979065}
{"mode": "train", "epochs": 6, "timestep": 10103, "ep_reward": 64.13250732421875, "reward": 0.8945108652114868, "action": -1.38158118724823}
{"mode": "train", "epochs": 6, "timestep": 10104, "ep_reward": 65.01152038574219, "reward": 0.879010796546936, "action": -0.5925712585449219}
{"mode": "train", "epochs": 6, "timestep": 10105, "ep_reward": 65.86505889892578, "reward": 0.8535374999046326, "action": -1.7157397270202637}
{"mode": "train", "epochs": 6, "timestep": 10106, "ep_reward": 66.66250610351562, "reward": 0.7974485158920288, "action": -0.15203189849853516}
{"mode": "train", "epochs": 6, "timestep": 10107, "ep_reward": 67.39274597167969, "reward": 0.7302360534667969, "action": -1.0501923561096191}
{"mode": "train", "epochs": 6, "timestep": 10108, "ep_reward": 68.0136947631836, "reward": 0.6209520101547241, "action": -1.9999406337738037}
{"mode": "train", "epochs": 6, "timestep": 10109, "ep_reward": 68.4718246459961, "reward": 0.45812612771987915, "action": -0.4696463942527771}
{"mode": "train", "epochs": 6, "timestep": 10110, "ep_reward": 68.79017639160156, "reward": 0.3183513879776001, "action": -1.074321985244751}
{"mode": "train", "epochs": 6, "timestep": 10111, "ep_reward": 68.99242401123047, "reward": 0.20225131511688232, "action": -0.8465180397033691}
{"mode": "train", "epochs": 6, "timestep": 10112, "ep_reward": 69.05854034423828, "reward": 0.06611406803131104, "action": -0.9348950386047363}
{"mode": "train", "epochs": 6, "timestep": 10113, "ep_reward": 69.11048889160156, "reward": 0.05195116996765137, "action": -1.8492352962493896}
{"mode": "train", "epochs": 6, "timestep": 10114, "ep_reward": 69.30054473876953, "reward": 0.19005578756332397, "action": -1.500409483909607}
{"mode": "train", "epochs": 6, "timestep": 10115, "ep_reward": 69.62461853027344, "reward": 0.32407617568969727, "action": -1.023379921913147}
{"mode": "train", "epochs": 6, "timestep": 10116, "ep_reward": 70.0841064453125, "reward": 0.4594886898994446, "action": -0.39351266622543335}
{"mode": "train", "epochs": 6, "timestep": 10117, "ep_reward": 70.6706314086914, "reward": 0.5865281820297241, "action": -0.7178537845611572}
{"mode": "train", "epochs": 6, "timestep": 10118, "ep_reward": 71.35755920410156, "reward": 0.6869258880615234, "action": -1.272458791732788}
{"mode": "train", "epochs": 6, "timestep": 10119, "ep_reward": 72.11626434326172, "reward": 0.7587047815322876, "action": -0.5184040069580078}
{"mode": "train", "epochs": 6, "timestep": 10120, "ep_reward": 72.93238830566406, "reward": 0.8161216974258423, "action": -0.4458107352256775}
{"mode": "train", "epochs": 6, "timestep": 10121, "ep_reward": 73.78657531738281, "reward": 0.8541871905326843, "action": -1.4518818855285645}
{"mode": "train", "epochs": 6, "timestep": 10122, "ep_reward": 74.65359497070312, "reward": 0.8670158982276917, "action": -1.427051067352295}
{"mode": "train", "epochs": 6, "timestep": 10123, "ep_reward": 75.51773071289062, "reward": 0.8641335964202881, "action": -0.36403316259384155}
{"mode": "train", "epochs": 6, "timestep": 10124, "ep_reward": 76.37088012695312, "reward": 0.8531497120857239, "action": -1.1538058519363403}
{"mode": "train", "epochs": 6, "timestep": 10125, "ep_reward": 77.18631744384766, "reward": 0.8154377937316895, "action": -0.6553775072097778}
{"mode": "train", "epochs": 6, "timestep": 10126, "ep_reward": 77.94416809082031, "reward": 0.7578533291816711, "action": -1.2861621379852295}
{"mode": "train", "epochs": 6, "timestep": 10127, "ep_reward": 78.60623168945312, "reward": 0.6620604991912842, "action": -0.9134459495544434}
{"mode": "train", "epochs": 6, "timestep": 10128, "ep_reward": 79.1382827758789, "reward": 0.5320498943328857, "action": -1.535308599472046}
{"mode": "train", "epochs": 6, "timestep": 10129, "ep_reward": 79.5095443725586, "reward": 0.3712637424468994, "action": -0.2757454514503479}
{"mode": "train", "epochs": 6, "timestep": 10130, "ep_reward": 79.77508544921875, "reward": 0.26554250717163086, "action": -1.0907649993896484}
{"mode": "train", "epochs": 6, "timestep": 10131, "ep_reward": 79.91500091552734, "reward": 0.13991189002990723, "action": -0.9243907928466797}
{"mode": "train", "epochs": 6, "timestep": 10132, "ep_reward": 79.90921020507812, "reward": -0.0057909488677978516, "action": -1.2940187454223633}
{"mode": "train", "epochs": 6, "timestep": 10133, "ep_reward": 80.029541015625, "reward": 0.12032902240753174, "action": -0.9969086647033691}
{"mode": "train", "epochs": 6, "timestep": 10134, "ep_reward": 80.28876495361328, "reward": 0.2592255473136902, "action": -0.6645563840866089}
{"mode": "train", "epochs": 6, "timestep": 10135, "ep_reward": 80.69020080566406, "reward": 0.40143388509750366, "action": -1.4345881938934326}
{"mode": "train", "epochs": 6, "timestep": 10136, "ep_reward": 81.21370697021484, "reward": 0.523507833480835, "action": -0.5626976490020752}
{"mode": "train", "epochs": 6, "timestep": 10137, "ep_reward": 81.85152435302734, "reward": 0.6378142833709717, "action": -1.0488728284835815}
{"mode": "train", "epochs": 6, "timestep": 10138, "ep_reward": 82.57551574707031, "reward": 0.7239951491355896, "action": -0.9428386688232422}
{"mode": "train", "epochs": 6, "timestep": 10139, "ep_reward": 83.36467742919922, "reward": 0.7891640067100525, "action": -0.4170088768005371}
{"mode": "train", "epochs": 6, "timestep": 10140, "ep_reward": 84.2031478881836, "reward": 0.8384718298912048, "action": -0.543858528137207}
{"mode": "train", "epochs": 6, "timestep": 10141, "ep_reward": 85.07158660888672, "reward": 0.8684383630752563, "action": -1.4152417182922363}
{"mode": "train", "epochs": 6, "timestep": 10142, "ep_reward": 85.94758605957031, "reward": 0.8760014772415161, "action": -0.23987191915512085}
{"mode": "train", "epochs": 6, "timestep": 10143, "ep_reward": 86.8255844116211, "reward": 0.8779969215393066, "action": -1.0354748964309692}
{"mode": "train", "epochs": 6, "timestep": 10144, "ep_reward": 87.68312072753906, "reward": 0.8575371503829956, "action": 0.17815661430358887}
{"mode": "train", "epochs": 6, "timestep": 10145, "ep_reward": 88.5125732421875, "reward": 0.8294533491134644, "action": -0.665786862373352}
{"mode": "train", "epochs": 6, "timestep": 10146, "ep_reward": 89.28407287597656, "reward": 0.7715007066726685, "action": -1.3226375579833984}
{"mode": "train", "epochs": 6, "timestep": 10147, "ep_reward": 89.96102142333984, "reward": 0.6769468188285828, "action": 0.25243937969207764}
{"mode": "train", "epochs": 6, "timestep": 10148, "ep_reward": 90.52783203125, "reward": 0.5668132305145264, "action": -0.687448263168335}
{"mode": "train", "epochs": 6, "timestep": 10149, "ep_reward": 90.9359130859375, "reward": 0.40808016061782837, "action": -0.6733831167221069}
{"mode": "train", "epochs": 6, "timestep": 10150, "ep_reward": 91.20650482177734, "reward": 0.27059006690979004, "action": -1.5472331047058105}
{"mode": "train", "epochs": 6, "timestep": 10151, "ep_reward": 91.3524169921875, "reward": 0.14591515064239502, "action": -0.9977909922599792}
{"mode": "train", "epochs": 6, "timestep": 10152, "ep_reward": 91.35357666015625, "reward": 0.001162707805633545, "action": -0.9168740510940552}
{"mode": "train", "epochs": 6, "timestep": 10153, "ep_reward": 91.4676513671875, "reward": 0.11407220363616943, "action": -1.4983208179473877}
{"mode": "train", "epochs": 6, "timestep": 10154, "ep_reward": 91.71412658691406, "reward": 0.24647259712219238, "action": -1.305929183959961}
{"mode": "train", "epochs": 6, "timestep": 10155, "ep_reward": 92.09651947021484, "reward": 0.382390558719635, "action": -1.5925204753875732}
{"mode": "train", "epochs": 6, "timestep": 10156, "ep_reward": 92.60223388671875, "reward": 0.5057114362716675, "action": -1.0951358079910278}
{"mode": "train", "epochs": 6, "timestep": 10157, "ep_reward": 93.21976470947266, "reward": 0.6175286173820496, "action": -0.7309212684631348}
{"mode": "train", "epochs": 6, "timestep": 10158, "ep_reward": 93.92967987060547, "reward": 0.7099149227142334, "action": -0.9130445122718811}
{"mode": "train", "epochs": 6, "timestep": 10159, "ep_reward": 94.70575714111328, "reward": 0.7760796546936035, "action": -1.2799118757247925}
{"mode": "train", "epochs": 6, "timestep": 10160, "ep_reward": 95.52265167236328, "reward": 0.8168926239013672, "action": -1.0713276863098145}
{"mode": "train", "epochs": 6, "timestep": 10161, "ep_reward": 96.362548828125, "reward": 0.8398979306221008, "action": -0.5658396482467651}
{"mode": "train", "epochs": 6, "timestep": 10162, "ep_reward": 97.21102905273438, "reward": 0.8484821319580078, "action": -0.8790920376777649}
{"mode": "train", "epochs": 6, "timestep": 10163, "ep_reward": 98.04595184326172, "reward": 0.8349262475967407, "action": -1.0652741193771362}
{"mode": "train", "epochs": 6, "timestep": 10164, "ep_reward": 98.84358215332031, "reward": 0.7976325154304504, "action": -0.646336555480957}
{"mode": "train", "epochs": 6, "timestep": 10165, "ep_reward": 99.58145141601562, "reward": 0.737872838973999, "action": -1.2900677919387817}
{"mode": "train", "epochs": 6, "timestep": 10166, "ep_reward": 100.21865844726562, "reward": 0.6372052431106567, "action": -1.1044187545776367}
{"mode": "train", "epochs": 6, "timestep": 10167, "ep_reward": 100.71621704101562, "reward": 0.4975581765174866, "action": -1.2852962017059326}
{"mode": "train", "epochs": 6, "timestep": 10168, "ep_reward": 101.07958984375, "reward": 0.36337602138519287, "action": -1.2133742570877075}
{"mode": "train", "epochs": 6, "timestep": 10169, "ep_reward": 101.3357162475586, "reward": 0.2561227083206177, "action": -1.105646014213562}
{"mode": "train", "epochs": 6, "timestep": 10170, "ep_reward": 101.46452331542969, "reward": 0.1288069486618042, "action": -1.4041762351989746}
{"mode": "train", "epochs": 6, "timestep": 10171, "ep_reward": 101.44912719726562, "reward": -0.015395402908325195, "action": -0.7128576040267944}
{"mode": "train", "epochs": 6, "timestep": 10172, "ep_reward": 101.58042907714844, "reward": 0.13130301237106323, "action": -1.8908928632736206}
{"mode": "train", "epochs": 6, "timestep": 10173, "ep_reward": 101.8397445678711, "reward": 0.25931859016418457, "action": -0.8054007887840271}
{"mode": "train", "epochs": 6, "timestep": 10174, "ep_reward": 102.24128723144531, "reward": 0.4015437364578247, "action": -1.9221279621124268}
{"mode": "train", "epochs": 6, "timestep": 10175, "ep_reward": 102.76012420654297, "reward": 0.5188355445861816, "action": -0.7088773250579834}
{"mode": "train", "epochs": 6, "timestep": 10176, "ep_reward": 103.39249420166016, "reward": 0.6323682069778442, "action": -1.5863205194473267}
{"mode": "train", "epochs": 6, "timestep": 10177, "ep_reward": 104.10492706298828, "reward": 0.7124300003051758, "action": -1.8522648811340332}
{"mode": "train", "epochs": 6, "timestep": 10178, "ep_reward": 104.87226867675781, "reward": 0.7673411965370178, "action": -0.5978280305862427}
{"mode": "train", "epochs": 6, "timestep": 10179, "ep_reward": 105.6846694946289, "reward": 0.8124001026153564, "action": -0.8094996213912964}
{"mode": "train", "epochs": 6, "timestep": 10180, "ep_reward": 106.51864624023438, "reward": 0.8339783549308777, "action": -1.0341160297393799}
{"mode": "train", "epochs": 6, "timestep": 10181, "ep_reward": 107.35192108154297, "reward": 0.8332741260528564, "action": -0.4386700987815857}
{"mode": "train", "epochs": 6, "timestep": 10182, "ep_reward": 108.16905212402344, "reward": 0.8171321153640747, "action": -0.35013478994369507}
{"mode": "train", "epochs": 6, "timestep": 10183, "ep_reward": 108.94742584228516, "reward": 0.7783768177032471, "action": -0.6976609230041504}
{"mode": "train", "epochs": 6, "timestep": 10184, "ep_reward": 109.65496063232422, "reward": 0.7075313329696655, "action": -1.008701205253601}
{"mode": "train", "epochs": 6, "timestep": 10185, "ep_reward": 110.25225067138672, "reward": 0.5972907543182373, "action": -1.287031888961792}
{"mode": "train", "epochs": 6, "timestep": 10186, "ep_reward": 110.69275665283203, "reward": 0.4405069351196289, "action": -1.1556971073150635}
{"mode": "train", "epochs": 6, "timestep": 10187, "ep_reward": 111.02208709716797, "reward": 0.329326868057251, "action": -1.2119117975234985}
{"mode": "train", "epochs": 6, "timestep": 10188, "ep_reward": 111.23725891113281, "reward": 0.2151743769645691, "action": -1.8282212018966675}
{"mode": "train", "epochs": 6, "timestep": 10189, "ep_reward": 111.31848907470703, "reward": 0.08122694492340088, "action": -1.3905545473098755}
{"mode": "train", "epochs": 6, "timestep": 10190, "ep_reward": 111.35501098632812, "reward": 0.03652191162109375, "action": -0.8615543842315674}
{"mode": "train", "epochs": 6, "timestep": 10191, "ep_reward": 111.53162384033203, "reward": 0.1766124963760376, "action": -1.1347829103469849}
{"mode": "train", "epochs": 6, "timestep": 10192, "ep_reward": 111.84663391113281, "reward": 0.3150113821029663, "action": -0.734559178352356}
{"mode": "train", "epochs": 6, "timestep": 10193, "ep_reward": 112.30046081542969, "reward": 0.4538278579711914, "action": -0.5841857194900513}
{"mode": "train", "epochs": 6, "timestep": 10194, "ep_reward": 112.8794174194336, "reward": 0.5789566040039062, "action": -1.7277977466583252}
{"mode": "train", "epochs": 6, "timestep": 10195, "ep_reward": 113.55030059814453, "reward": 0.6708806753158569, "action": -0.7920499444007874}
{"mode": "train", "epochs": 6, "timestep": 10196, "ep_reward": 114.30115509033203, "reward": 0.7508516907691956, "action": -1.4555723667144775}
{"mode": "train", "epochs": 6, "timestep": 10197, "ep_reward": 115.10383605957031, "reward": 0.8026840090751648, "action": -0.2796558141708374}
{"mode": "train", "epochs": 6, "timestep": 10198, "ep_reward": 115.94905090332031, "reward": 0.845217227935791, "action": -1.7949788570404053}
{"mode": "train", "epochs": 6, "timestep": 10199, "ep_reward": 116.80598449707031, "reward": 0.8569307327270508, "action": -1.513833999633789}
{"mode": "train", "epochs": 6, "timestep": 10200, "ep_reward": 117.65998077392578, "reward": 0.8539955615997314, "action": -1.2243173122406006}
{"mode": "train", "epochs": 6, "timestep": 10201, "ep_reward": 118.4947280883789, "reward": 0.8347490429878235, "action": -0.8531632423400879}
{"mode": "train", "epochs": 6, "timestep": 10202, "ep_reward": 119.29170227050781, "reward": 0.7969765067100525, "action": -0.047733426094055176}
{"mode": "train", "epochs": 6, "timestep": 10203, "ep_reward": 120.0333251953125, "reward": 0.7416245937347412, "action": -1.6052882671356201}
{"mode": "train", "epochs": 6, "timestep": 10204, "ep_reward": 120.66920471191406, "reward": 0.6358791589736938, "action": -1.3244048357009888}
{"mode": "train", "epochs": 6, "timestep": 10205, "ep_reward": 121.16075897216797, "reward": 0.49155545234680176, "action": -0.607366681098938}
{"mode": "train", "epochs": 6, "timestep": 10206, "ep_reward": 121.51750946044922, "reward": 0.356751024723053, "action": -1.5278420448303223}
{"mode": "train", "epochs": 6, "timestep": 10207, "ep_reward": 121.76563262939453, "reward": 0.2481251358985901, "action": -1.601883053779602}
{"mode": "train", "epochs": 6, "timestep": 10208, "ep_reward": 121.8851318359375, "reward": 0.11949962377548218, "action": -1.6700749397277832}
{"mode": "train", "epochs": 6, "timestep": 10209, "ep_reward": 121.88011169433594, "reward": -0.00502169132232666, "action": -1.5045268535614014}
{"mode": "train", "epochs": 6, "timestep": 10210, "ep_reward": 122.02068328857422, "reward": 0.1405714750289917, "action": -1.2452659606933594}
{"mode": "train", "epochs": 6, "timestep": 10211, "ep_reward": 122.29753875732422, "reward": 0.27685457468032837, "action": -1.019018292427063}
{"mode": "train", "epochs": 6, "timestep": 10212, "ep_reward": 122.71206665039062, "reward": 0.41452866792678833, "action": -1.1795234680175781}
{"mode": "train", "epochs": 6, "timestep": 10213, "ep_reward": 123.25059509277344, "reward": 0.5385269522666931, "action": -0.8698415160179138}
{"mode": "train", "epochs": 6, "timestep": 10214, "ep_reward": 123.89746856689453, "reward": 0.6468754410743713, "action": -0.8873408436775208}
{"mode": "train", "epochs": 6, "timestep": 10215, "ep_reward": 124.62933349609375, "reward": 0.7318666577339172, "action": -0.94600909948349}
{"mode": "train", "epochs": 6, "timestep": 10216, "ep_reward": 125.42295837402344, "reward": 0.7936217784881592, "action": -0.6900873780250549}
{"mode": "train", "epochs": 6, "timestep": 10217, "ep_reward": 126.26009368896484, "reward": 0.8371380567550659, "action": -0.6794813871383667}
{"mode": "train", "epochs": 6, "timestep": 10218, "ep_reward": 127.12245178222656, "reward": 0.8623567223548889, "action": -1.6229476928710938}
{"mode": "train", "epochs": 6, "timestep": 10219, "ep_reward": 127.98573303222656, "reward": 0.8632846474647522, "action": -0.7624093294143677}
{"mode": "train", "epochs": 6, "timestep": 10220, "ep_reward": 128.84007263183594, "reward": 0.854340672492981, "action": -1.5331525802612305}
{"mode": "train", "epochs": 6, "timestep": 10221, "ep_reward": 129.6588134765625, "reward": 0.8187484741210938, "action": -1.2321805953979492}
{"mode": "train", "epochs": 6, "timestep": 10222, "ep_reward": 130.4196014404297, "reward": 0.7607936859130859, "action": -0.8716817498207092}
{"mode": "train", "epochs": 6, "timestep": 10223, "ep_reward": 131.0950927734375, "reward": 0.6754963994026184, "action": -0.5120776891708374}
{"mode": "train", "epochs": 6, "timestep": 10224, "ep_reward": 131.65292358398438, "reward": 0.5578298568725586, "action": -1.3340880870819092}
{"mode": "train", "epochs": 6, "timestep": 10225, "ep_reward": 132.0427703857422, "reward": 0.38985246419906616, "action": -0.8411043882369995}
{"mode": "train", "epochs": 6, "timestep": 10226, "ep_reward": 132.33084106445312, "reward": 0.28806746006011963, "action": -1.5734572410583496}
{"mode": "train", "epochs": 6, "timestep": 10227, "ep_reward": 132.4973602294922, "reward": 0.16652387380599976, "action": -0.6155622005462646}
{"mode": "train", "epochs": 6, "timestep": 10228, "ep_reward": 132.52220153808594, "reward": 0.024844229221343994, "action": -0.675772488117218}
{"mode": "train", "epochs": 6, "timestep": 10229, "ep_reward": 132.61448669433594, "reward": 0.09228575229644775, "action": -1.6270174980163574}
{"mode": "train", "epochs": 6, "timestep": 10230, "ep_reward": 132.83932495117188, "reward": 0.22484159469604492, "action": -1.2328593730926514}
{"mode": "train", "epochs": 6, "timestep": 10231, "ep_reward": 133.2017059326172, "reward": 0.3623860478401184, "action": -1.130448341369629}
{"mode": "train", "epochs": 6, "timestep": 10232, "ep_reward": 133.69482421875, "reward": 0.4931216239929199, "action": -1.200808048248291}
{"mode": "train", "epochs": 6, "timestep": 10233, "ep_reward": 134.30075073242188, "reward": 0.6059225797653198, "action": -0.6351319551467896}
{"mode": "train", "epochs": 6, "timestep": 10234, "ep_reward": 135.00318908691406, "reward": 0.7024319171905518, "action": -0.6881082653999329}
{"mode": "train", "epochs": 6, "timestep": 10235, "ep_reward": 135.77723693847656, "reward": 0.7740443348884583, "action": -0.8666086196899414}
{"mode": "train", "epochs": 6, "timestep": 10236, "ep_reward": 136.59922790527344, "reward": 0.8219847083091736, "action": -0.3446435332298279}
{"mode": "train", "epochs": 6, "timestep": 10237, "ep_reward": 137.45436096191406, "reward": 0.8551262021064758, "action": -0.5732592344284058}
{"mode": "train", "epochs": 6, "timestep": 10238, "ep_reward": 138.3232879638672, "reward": 0.8689322471618652, "action": -0.8130990266799927}
{"mode": "train", "epochs": 6, "timestep": 10239, "ep_reward": 139.1875762939453, "reward": 0.8642836809158325, "action": -1.455381155014038}
{"mode": "train", "epochs": 6, "timestep": 10240, "ep_reward": 140.02357482910156, "reward": 0.8359968662261963, "action": -0.6064492464065552}
{"mode": "train", "epochs": 6, "timestep": 10241, "ep_reward": 140.81712341308594, "reward": 0.7935505509376526, "action": -0.49192994832992554}
{"mode": "train", "epochs": 6, "timestep": 10242, "ep_reward": 141.5429229736328, "reward": 0.7257938385009766, "action": -1.3981457948684692}
{"mode": "train", "epochs": 6, "timestep": 10243, "ep_reward": 142.15658569335938, "reward": 0.6136672496795654, "action": -0.8729920387268066}
{"mode": "train", "epochs": 6, "timestep": 10244, "ep_reward": 142.6240234375, "reward": 0.46743613481521606, "action": -0.6544078588485718}
{"mode": "train", "epochs": 6, "timestep": 10245, "ep_reward": 142.95506286621094, "reward": 0.3310454487800598, "action": -0.9029662013053894}
{"mode": "train", "epochs": 6, "timestep": 10246, "ep_reward": 143.1722412109375, "reward": 0.21717286109924316, "action": -1.8383941650390625}
{"mode": "train", "epochs": 6, "timestep": 10247, "ep_reward": 143.2559051513672, "reward": 0.08367115259170532, "action": -0.09030348062515259}
{"mode": "train", "epochs": 6, "timestep": 10248, "ep_reward": 143.28990173339844, "reward": 0.034002602100372314, "action": -1.4879108667373657}
{"mode": "train", "epochs": 6, "timestep": 10249, "ep_reward": 143.46434020996094, "reward": 0.1744368076324463, "action": -1.5583384037017822}
{"mode": "train", "epochs": 6, "timestep": 10250, "ep_reward": 143.77182006835938, "reward": 0.3074796199798584, "action": -1.2489268779754639}
{"mode": "train", "epochs": 6, "timestep": 10251, "ep_reward": 144.2130889892578, "reward": 0.44126230478286743, "action": -1.2362558841705322}
{"mode": "train", "epochs": 6, "timestep": 10252, "ep_reward": 144.77464294433594, "reward": 0.5615565180778503, "action": -0.9558080434799194}
{"mode": "train", "epochs": 6, "timestep": 10253, "ep_reward": 145.4388427734375, "reward": 0.6641987562179565, "action": -1.489687442779541}
{"mode": "train", "epochs": 6, "timestep": 10254, "ep_reward": 146.17666625976562, "reward": 0.7378274202346802, "action": -0.8797025084495544}
{"mode": "train", "epochs": 6, "timestep": 10255, "ep_reward": 146.97166442871094, "reward": 0.7950039505958557, "action": -0.3855145573616028}
{"mode": "train", "epochs": 6, "timestep": 10256, "ep_reward": 147.8068389892578, "reward": 0.8351714611053467, "action": -1.0709446668624878}
{"mode": "train", "epochs": 6, "timestep": 10257, "ep_reward": 148.6566925048828, "reward": 0.8498581647872925, "action": -1.0628398656845093}
{"mode": "train", "epochs": 6, "timestep": 10258, "ep_reward": 149.50279235839844, "reward": 0.8461024761199951, "action": -1.7381621599197388}
{"mode": "train", "epochs": 6, "timestep": 10259, "ep_reward": 150.3184814453125, "reward": 0.8156888484954834, "action": -0.6861853003501892}
{"mode": "train", "epochs": 6, "timestep": 10260, "ep_reward": 151.08934020996094, "reward": 0.7708609104156494, "action": -0.7222026586532593}
{"mode": "train", "epochs": 6, "timestep": 10261, "ep_reward": 151.78550720214844, "reward": 0.696172833442688, "action": -0.3447328209877014}
{"mode": "train", "epochs": 6, "timestep": 10262, "ep_reward": 152.37623596191406, "reward": 0.5907238721847534, "action": -1.6586356163024902}
{"mode": "train", "epochs": 6, "timestep": 10263, "ep_reward": 152.8014373779297, "reward": 0.42520272731781006, "action": -1.537919044494629}
{"mode": "train", "epochs": 6, "timestep": 10264, "ep_reward": 153.12059020996094, "reward": 0.31914710998535156, "action": -1.3775177001953125}
{"mode": "train", "epochs": 6, "timestep": 10265, "ep_reward": 153.32386779785156, "reward": 0.20327293872833252, "action": -0.6146253943443298}
{"mode": "train", "epochs": 6, "timestep": 10266, "ep_reward": 153.39111328125, "reward": 0.06724995374679565, "action": -1.1114999055862427}
{"mode": "train", "epochs": 6, "timestep": 10267, "ep_reward": 153.4420166015625, "reward": 0.05089592933654785, "action": -1.2312403917312622}
{"mode": "train", "epochs": 6, "timestep": 10268, "ep_reward": 153.63119506835938, "reward": 0.18917816877365112, "action": -0.2326483130455017}
{"mode": "train", "epochs": 6, "timestep": 10269, "ep_reward": 153.9700164794922, "reward": 0.3388156294822693, "action": -0.9976367950439453}
{"mode": "train", "epochs": 6, "timestep": 10270, "ep_reward": 154.44143676757812, "reward": 0.47142529487609863, "action": -0.7299947142601013}
{"mode": "train", "epochs": 6, "timestep": 10271, "ep_reward": 155.0336151123047, "reward": 0.5921801328659058, "action": -0.5787994861602783}
{"mode": "train", "epochs": 6, "timestep": 10272, "ep_reward": 155.7267608642578, "reward": 0.6931391358375549, "action": -1.0030657052993774}
{"mode": "train", "epochs": 6, "timestep": 10273, "ep_reward": 156.49412536621094, "reward": 0.7673603296279907, "action": -0.5877424478530884}
{"mode": "train", "epochs": 6, "timestep": 10274, "ep_reward": 157.31874084472656, "reward": 0.8246157169342041, "action": -1.0673117637634277}
{"mode": "train", "epochs": 6, "timestep": 10275, "ep_reward": 158.17840576171875, "reward": 0.859669029712677, "action": -1.0358723402023315}
{"mode": "train", "epochs": 6, "timestep": 10276, "ep_reward": 159.05809020996094, "reward": 0.8796858787536621, "action": -0.13595223426818848}
{"mode": "train", "epochs": 6, "timestep": 10277, "ep_reward": 159.95059204101562, "reward": 0.8925024271011353, "action": -0.6657463312149048}
{"mode": "train", "epochs": 6, "timestep": 10278, "ep_reward": 160.8380584716797, "reward": 0.8874607086181641, "action": -1.868420124053955}
{"mode": "train", "epochs": 6, "timestep": 10279, "ep_reward": 161.69554138183594, "reward": 0.8574754595756531, "action": -1.0029295682907104}
{"mode": "train", "epochs": 6, "timestep": 10280, "ep_reward": 162.51019287109375, "reward": 0.8146538734436035, "action": -1.1670730113983154}
{"mode": "train", "epochs": 6, "timestep": 10281, "ep_reward": 163.2549591064453, "reward": 0.7447594404220581, "action": -1.27488374710083}
{"mode": "train", "epochs": 6, "timestep": 10282, "ep_reward": 163.8955535888672, "reward": 0.6405891180038452, "action": -1.270090937614441}
{"mode": "train", "epochs": 6, "timestep": 10283, "ep_reward": 164.3920135498047, "reward": 0.49646735191345215, "action": -0.16910123825073242}
{"mode": "train", "epochs": 6, "timestep": 10284, "ep_reward": 164.7365264892578, "reward": 0.34451591968536377, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 10285, "ep_reward": 164.97023010253906, "reward": 0.23369795083999634, "action": -0.6457163095474243}
{"mode": "train", "epochs": 6, "timestep": 10286, "ep_reward": 165.0728759765625, "reward": 0.10264778137207031, "action": -0.7398611903190613}
{"mode": "train", "epochs": 6, "timestep": 10287, "ep_reward": 165.08673095703125, "reward": 0.01386028528213501, "action": -0.47989052534103394}
{"mode": "train", "epochs": 6, "timestep": 10288, "ep_reward": 165.2436981201172, "reward": 0.1569693684577942, "action": 0.6124426126480103}
{"mode": "train", "epochs": 6, "timestep": 10289, "ep_reward": 165.56011962890625, "reward": 0.31642162799835205, "action": -0.8171494007110596}
{"mode": "train", "epochs": 6, "timestep": 10290, "ep_reward": 166.01097106933594, "reward": 0.45085084438323975, "action": -1.2496671676635742}
{"mode": "train", "epochs": 6, "timestep": 10291, "ep_reward": 166.57875061035156, "reward": 0.5677805542945862, "action": -1.2974432706832886}
{"mode": "train", "epochs": 6, "timestep": 10292, "ep_reward": 167.24517822265625, "reward": 0.6664284467697144, "action": -0.7915708422660828}
{"mode": "train", "epochs": 6, "timestep": 10293, "ep_reward": 167.99440002441406, "reward": 0.7492160797119141, "action": -0.7179160118103027}
{"mode": "train", "epochs": 6, "timestep": 10294, "ep_reward": 168.8056182861328, "reward": 0.8112173080444336, "action": -1.6538864374160767}
{"mode": "train", "epochs": 6, "timestep": 10295, "ep_reward": 169.65274047851562, "reward": 0.8471238613128662, "action": -0.8445303440093994}
{"mode": "train", "epochs": 6, "timestep": 10296, "ep_reward": 170.52659606933594, "reward": 0.8738620281219482, "action": -0.8596079349517822}
{"mode": "train", "epochs": 6, "timestep": 10297, "ep_reward": 171.4123992919922, "reward": 0.8857961893081665, "action": -1.0900700092315674}
{"mode": "train", "epochs": 6, "timestep": 10298, "ep_reward": 172.2942657470703, "reward": 0.881862223148346, "action": -0.6393988132476807}
{"mode": "train", "epochs": 6, "timestep": 10299, "ep_reward": 173.16058349609375, "reward": 0.8663113713264465, "action": -0.5904521942138672}
{"mode": "train", "epochs": 6, "timestep": 10300, "ep_reward": 173.99411010742188, "reward": 0.8335227370262146, "action": -0.5099474191665649}
{"mode": "train", "epochs": 6, "timestep": 10301, "ep_reward": 174.77378845214844, "reward": 0.7796737551689148, "action": -0.7559762597084045}
{"mode": "train", "epochs": 6, "timestep": 10302, "ep_reward": 175.46925354003906, "reward": 0.6954652070999146, "action": -1.3658878803253174}
{"mode": "train", "epochs": 6, "timestep": 10303, "ep_reward": 176.0376434326172, "reward": 0.5683902502059937, "action": -0.5553451776504517}
{"mode": "train", "epochs": 6, "timestep": 10304, "ep_reward": 176.4499969482422, "reward": 0.41234731674194336, "action": -0.9890387058258057}
{"mode": "train", "epochs": 6, "timestep": 10305, "ep_reward": 176.7299346923828, "reward": 0.2799404263496399, "action": -0.6544487476348877}
{"mode": "train", "epochs": 6, "timestep": 10306, "ep_reward": 176.8867645263672, "reward": 0.15682262182235718, "action": 0.1359410285949707}
{"mode": "train", "epochs": 6, "timestep": 10307, "ep_reward": 176.9004364013672, "reward": 0.013672351837158203, "action": -0.3554333448410034}
{"mode": "train", "epochs": 6, "timestep": 10308, "ep_reward": 177.0032501220703, "reward": 0.10281318426132202, "action": -0.8753405809402466}
{"mode": "train", "epochs": 6, "timestep": 10309, "ep_reward": 177.2459716796875, "reward": 0.24272549152374268, "action": -0.7645703554153442}
{"mode": "train", "epochs": 6, "timestep": 10310, "ep_reward": 177.6302032470703, "reward": 0.3842260241508484, "action": -0.7367196083068848}
{"mode": "train", "epochs": 6, "timestep": 10311, "ep_reward": 178.1462860107422, "reward": 0.516083836555481, "action": -0.603114128112793}
{"mode": "train", "epochs": 6, "timestep": 10312, "ep_reward": 178.77735900878906, "reward": 0.6310732960700989, "action": -1.1247944831848145}
{"mode": "train", "epochs": 6, "timestep": 10313, "ep_reward": 179.495849609375, "reward": 0.7184860110282898, "action": -1.0104446411132812}
{"mode": "train", "epochs": 6, "timestep": 10314, "ep_reward": 180.28138732910156, "reward": 0.7855335474014282, "action": -0.7684842348098755}
{"mode": "train", "epochs": 6, "timestep": 10315, "ep_reward": 181.1160125732422, "reward": 0.8346221446990967, "action": -1.0816800594329834}
{"mode": "train", "epochs": 6, "timestep": 10316, "ep_reward": 181.97958374023438, "reward": 0.8635679483413696, "action": -0.37488341331481934}
{"mode": "train", "epochs": 6, "timestep": 10317, "ep_reward": 182.8622589111328, "reward": 0.8826779127120972, "action": -0.32815617322921753}
{"mode": "train", "epochs": 6, "timestep": 10318, "ep_reward": 183.7498779296875, "reward": 0.8876174688339233, "action": -1.2770509719848633}
{"mode": "train", "epochs": 6, "timestep": 10319, "ep_reward": 184.6202392578125, "reward": 0.8703650236129761, "action": -1.320392370223999}
{"mode": "train", "epochs": 6, "timestep": 10320, "ep_reward": 185.45492553710938, "reward": 0.8346806764602661, "action": -1.2707562446594238}
{"mode": "train", "epochs": 6, "timestep": 10321, "ep_reward": 186.2308349609375, "reward": 0.7759112119674683, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 10322, "ep_reward": 186.90875244140625, "reward": 0.6779248714447021, "action": -0.7353664636611938}
{"mode": "train", "epochs": 6, "timestep": 10323, "ep_reward": 187.46517944335938, "reward": 0.5564227104187012, "action": -0.954851508140564}
{"mode": "train", "epochs": 6, "timestep": 10324, "ep_reward": 187.85617065429688, "reward": 0.3909849524497986, "action": -1.045867681503296}
{"mode": "train", "epochs": 6, "timestep": 10325, "ep_reward": 188.13821411132812, "reward": 0.2820475101470947, "action": -0.7449706792831421}
{"mode": "train", "epochs": 6, "timestep": 10326, "ep_reward": 188.2974853515625, "reward": 0.15927499532699585, "action": -0.7831825613975525}
{"mode": "train", "epochs": 6, "timestep": 10327, "ep_reward": 188.31398010253906, "reward": 0.01648956537246704, "action": -0.9349112510681152}
{"mode": "train", "epochs": 6, "timestep": 10328, "ep_reward": 188.4141845703125, "reward": 0.10019701719284058, "action": -0.566677451133728}
{"mode": "train", "epochs": 6, "timestep": 10329, "ep_reward": 188.6580047607422, "reward": 0.24381625652313232, "action": -1.1389120817184448}
{"mode": "train", "epochs": 6, "timestep": 10330, "ep_reward": 189.0380401611328, "reward": 0.3800387978553772, "action": -1.2578164339065552}
{"mode": "train", "epochs": 6, "timestep": 10331, "ep_reward": 189.54437255859375, "reward": 0.5063295364379883, "action": -1.4443671703338623}
{"mode": "train", "epochs": 6, "timestep": 10332, "ep_reward": 190.15846252441406, "reward": 0.6140915155410767, "action": -1.359708309173584}
{"mode": "train", "epochs": 6, "timestep": 10333, "ep_reward": 190.8602752685547, "reward": 0.7018073797225952, "action": -1.8170464038848877}
{"mode": "train", "epochs": 6, "timestep": 10334, "ep_reward": 191.62326049804688, "reward": 0.7629870176315308, "action": -1.47512686252594}
{"mode": "train", "epochs": 6, "timestep": 10335, "ep_reward": 192.42979431152344, "reward": 0.8065286874771118, "action": -1.4326670169830322}
{"mode": "train", "epochs": 6, "timestep": 10336, "ep_reward": 193.26004028320312, "reward": 0.8302422761917114, "action": -1.68001127243042}
{"mode": "train", "epochs": 6, "timestep": 10337, "ep_reward": 194.0919647216797, "reward": 0.8319185376167297, "action": -1.3809456825256348}
{"mode": "train", "epochs": 6, "timestep": 10338, "ep_reward": 194.90711975097656, "reward": 0.8151574730873108, "action": -0.6573917865753174}
{"mode": "train", "epochs": 6, "timestep": 10339, "ep_reward": 195.68833923339844, "reward": 0.7812157869338989, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 10340, "ep_reward": 196.39089965820312, "reward": 0.7025566101074219, "action": -0.9796804785728455}
{"mode": "train", "epochs": 6, "timestep": 10341, "ep_reward": 196.98829650878906, "reward": 0.5973898768424988, "action": -1.2867830991744995}
{"mode": "train", "epochs": 6, "timestep": 10342, "ep_reward": 197.43190002441406, "reward": 0.4436107873916626, "action": -1.553191900253296}
{"mode": "train", "epochs": 6, "timestep": 10343, "ep_reward": 197.78076171875, "reward": 0.34886014461517334, "action": -1.2734004259109497}
{"mode": "train", "epochs": 6, "timestep": 10344, "ep_reward": 198.0194091796875, "reward": 0.23864924907684326, "action": -1.291689157485962}
{"mode": "train", "epochs": 6, "timestep": 10345, "ep_reward": 198.12786865234375, "reward": 0.10846149921417236, "action": -1.1586334705352783}
{"mode": "train", "epochs": 6, "timestep": 10346, "ep_reward": 198.13522338867188, "reward": 0.007348179817199707, "action": -1.412512183189392}
{"mode": "train", "epochs": 6, "timestep": 10347, "ep_reward": 198.2864990234375, "reward": 0.1512824296951294, "action": -1.5105128288269043}
{"mode": "train", "epochs": 6, "timestep": 10348, "ep_reward": 198.57106018066406, "reward": 0.2845607399940491, "action": -0.4227645993232727}
{"mode": "train", "epochs": 6, "timestep": 10349, "ep_reward": 199.00067138671875, "reward": 0.42961055040359497, "action": -0.4458502531051636}
{"mode": "train", "epochs": 6, "timestep": 10350, "ep_reward": 199.56039428710938, "reward": 0.5597296357154846, "action": -0.6726873517036438}
{"mode": "train", "epochs": 6, "timestep": 10351, "ep_reward": 200.22657775878906, "reward": 0.6661853194236755, "action": -0.7032340168952942}
{"mode": "train", "epochs": 6, "timestep": 10352, "ep_reward": 200.9759063720703, "reward": 0.7493218779563904, "action": -1.4195752143859863}
{"mode": "train", "epochs": 6, "timestep": 10353, "ep_reward": 201.7804412841797, "reward": 0.8045293092727661, "action": -1.163263201713562}
{"mode": "train", "epochs": 6, "timestep": 10354, "ep_reward": 202.62396240234375, "reward": 0.8435238599777222, "action": -1.1967812776565552}
{"mode": "train", "epochs": 6, "timestep": 10355, "ep_reward": 203.48953247070312, "reward": 0.8655643463134766, "action": -0.2122785449028015}
{"mode": "train", "epochs": 6, "timestep": 10356, "ep_reward": 204.36953735351562, "reward": 0.8800085186958313, "action": -0.5517945289611816}
{"mode": "train", "epochs": 6, "timestep": 10357, "ep_reward": 205.24609375, "reward": 0.8765604496002197, "action": -1.162662386894226}
{"mode": "train", "epochs": 6, "timestep": 10358, "ep_reward": 206.09771728515625, "reward": 0.8516241312026978, "action": -1.4628506898880005}
{"mode": "train", "epochs": 6, "timestep": 10359, "ep_reward": 206.90072631835938, "reward": 0.8030085563659668, "action": -1.4325810670852661}
{"mode": "train", "epochs": 6, "timestep": 10360, "ep_reward": 207.62759399414062, "reward": 0.7268692255020142, "action": -1.1771318912506104}
{"mode": "train", "epochs": 6, "timestep": 10361, "ep_reward": 208.24612426757812, "reward": 0.6185240745544434, "action": -1.1808457374572754}
{"mode": "train", "epochs": 6, "timestep": 10362, "ep_reward": 208.7152099609375, "reward": 0.4690793752670288, "action": -0.6933531761169434}
{"mode": "train", "epochs": 6, "timestep": 10363, "ep_reward": 209.0491943359375, "reward": 0.3339882493019104, "action": -1.8544116020202637}
{"mode": "train", "epochs": 6, "timestep": 10364, "ep_reward": 209.270263671875, "reward": 0.22107207775115967, "action": -0.5610975027084351}
{"mode": "train", "epochs": 6, "timestep": 10365, "ep_reward": 209.35812377929688, "reward": 0.0878591537475586, "action": -1.3912571668624878}
{"mode": "train", "epochs": 6, "timestep": 10366, "ep_reward": 209.3875274658203, "reward": 0.029411256313323975, "action": -1.7919502258300781}
{"mode": "train", "epochs": 6, "timestep": 10367, "ep_reward": 209.55816650390625, "reward": 0.17064183950424194, "action": -0.5460061430931091}
{"mode": "train", "epochs": 6, "timestep": 10368, "ep_reward": 209.87432861328125, "reward": 0.31616711616516113, "action": -1.0937281847000122}
{"mode": "train", "epochs": 6, "timestep": 10369, "ep_reward": 210.32379150390625, "reward": 0.44946563243865967, "action": -1.6976523399353027}
{"mode": "train", "epochs": 6, "timestep": 10370, "ep_reward": 210.88656616210938, "reward": 0.5627790689468384, "action": -1.0902268886566162}
{"mode": "train", "epochs": 6, "timestep": 10371, "ep_reward": 211.55078125, "reward": 0.6642197370529175, "action": -0.061754703521728516}
{"mode": "train", "epochs": 6, "timestep": 10372, "ep_reward": 212.30343627929688, "reward": 0.7526564598083496, "action": -1.2014305591583252}
{"mode": "train", "epochs": 6, "timestep": 10373, "ep_reward": 213.1105499267578, "reward": 0.8071116805076599, "action": -0.5892360806465149}
{"mode": "train", "epochs": 6, "timestep": 10374, "ep_reward": 213.95816040039062, "reward": 0.8476114273071289, "action": -1.1062965393066406}
{"mode": "train", "epochs": 6, "timestep": 10375, "ep_reward": 214.82470703125, "reward": 0.866540789604187, "action": 0.4148041009902954}
{"mode": "train", "epochs": 6, "timestep": 10376, "ep_reward": 215.70680236816406, "reward": 0.8820933699607849, "action": -1.473036766052246}
{"mode": "train", "epochs": 6, "timestep": 10377, "ep_reward": 216.57374572753906, "reward": 0.8669378161430359, "action": -0.7994301319122314}
{"mode": "train", "epochs": 6, "timestep": 10378, "ep_reward": 217.41323852539062, "reward": 0.8395000696182251, "action": -1.7754738330841064}
{"mode": "train", "epochs": 6, "timestep": 10379, "ep_reward": 218.193359375, "reward": 0.7801159620285034, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 10380, "ep_reward": 218.8797607421875, "reward": 0.6863958835601807, "action": -1.4117964506149292}
{"mode": "train", "epochs": 6, "timestep": 10381, "ep_reward": 219.43948364257812, "reward": 0.5597224235534668, "action": -0.7474020719528198}
{"mode": "train", "epochs": 6, "timestep": 10382, "ep_reward": 219.83888244628906, "reward": 0.39940357208251953, "action": -0.6600978374481201}
{"mode": "train", "epochs": 6, "timestep": 10383, "ep_reward": 220.13487243652344, "reward": 0.29598766565322876, "action": -0.4406818747520447}
{"mode": "train", "epochs": 6, "timestep": 10384, "ep_reward": 220.3103485107422, "reward": 0.17547690868377686, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 10385, "ep_reward": 220.34573364257812, "reward": 0.0353885293006897, "action": -1.0221151113510132}
{"mode": "train", "epochs": 6, "timestep": 10386, "ep_reward": 220.42808532714844, "reward": 0.08234447240829468, "action": -1.0694537162780762}
{"mode": "train", "epochs": 6, "timestep": 10387, "ep_reward": 220.64727783203125, "reward": 0.2191895842552185, "action": -1.1232712268829346}
{"mode": "train", "epochs": 6, "timestep": 10388, "ep_reward": 221.00479125976562, "reward": 0.3575083613395691, "action": -0.9288103580474854}
{"mode": "train", "epochs": 6, "timestep": 10389, "ep_reward": 221.4954071044922, "reward": 0.4906100630760193, "action": -0.4706730842590332}
{"mode": "train", "epochs": 6, "timestep": 10390, "ep_reward": 222.10699462890625, "reward": 0.6115853786468506, "action": -1.0834027528762817}
{"mode": "train", "epochs": 6, "timestep": 10391, "ep_reward": 222.81027221679688, "reward": 0.7032732963562012, "action": 0.19055664539337158}
{"mode": "train", "epochs": 6, "timestep": 10392, "ep_reward": 223.59457397460938, "reward": 0.7843084931373596, "action": -0.11380523443222046}
{"mode": "train", "epochs": 6, "timestep": 10393, "ep_reward": 224.43429565429688, "reward": 0.8397181034088135, "action": -1.1829545497894287}
{"mode": "train", "epochs": 6, "timestep": 10394, "ep_reward": 225.302978515625, "reward": 0.8686822056770325, "action": -0.3963618278503418}
{"mode": "train", "epochs": 6, "timestep": 10395, "ep_reward": 226.19180297851562, "reward": 0.8888201713562012, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 10396, "ep_reward": 227.07498168945312, "reward": 0.8831728100776672, "action": -0.8029893636703491}
{"mode": "train", "epochs": 6, "timestep": 10397, "ep_reward": 227.94686889648438, "reward": 0.8718944787979126, "action": -1.5336612462997437}
{"mode": "train", "epochs": 6, "timestep": 10398, "ep_reward": 228.78372192382812, "reward": 0.8368558883666992, "action": -1.112988829612732}
{"mode": "train", "epochs": 6, "timestep": 10399, "ep_reward": 229.56639099121094, "reward": 0.7826672196388245, "action": -1.1834341287612915}
{"mode": "train", "epochs": 6, "timestep": 10400, "ep_reward": 230.2648468017578, "reward": 0.6984615921974182, "action": -1.3486299514770508}
{"mode": "train", "epochs": 6, "timestep": 10401, "ep_reward": 230.84011840820312, "reward": 0.5752649307250977, "action": -1.0675013065338135}
{"mode": "train", "epochs": 6, "timestep": 10402, "ep_reward": 231.25369262695312, "reward": 0.413576602935791, "action": -1.0992999076843262}
{"mode": "train", "epochs": 6, "timestep": 10403, "ep_reward": 231.5512237548828, "reward": 0.29752761125564575, "action": -1.009743332862854}
{"mode": "train", "epochs": 6, "timestep": 10404, "ep_reward": 231.72869873046875, "reward": 0.17748093605041504, "action": -1.422757863998413}
{"mode": "train", "epochs": 6, "timestep": 10405, "ep_reward": 231.76629638671875, "reward": 0.03759819269180298, "action": -0.6354732513427734}
{"mode": "train", "epochs": 6, "timestep": 10406, "ep_reward": 231.8465576171875, "reward": 0.08025437593460083, "action": -1.1315159797668457}
{"mode": "train", "epochs": 6, "timestep": 10407, "ep_reward": 232.06280517578125, "reward": 0.21624869108200073, "action": -1.212958812713623}
{"mode": "train", "epochs": 6, "timestep": 10408, "ep_reward": 232.41648864746094, "reward": 0.35369008779525757, "action": -0.8614494800567627}
{"mode": "train", "epochs": 6, "timestep": 10409, "ep_reward": 232.9046630859375, "reward": 0.488166868686676, "action": -0.009367763996124268}
{"mode": "train", "epochs": 6, "timestep": 10410, "ep_reward": 233.51925659179688, "reward": 0.6145964860916138, "action": -0.8365313410758972}
{"mode": "train", "epochs": 6, "timestep": 10411, "ep_reward": 234.227294921875, "reward": 0.7080403566360474, "action": -1.8131225109100342}
{"mode": "train", "epochs": 6, "timestep": 10412, "ep_reward": 234.99755859375, "reward": 0.7702622413635254, "action": -1.1601589918136597}
{"mode": "train", "epochs": 6, "timestep": 10413, "ep_reward": 235.81622314453125, "reward": 0.818664014339447, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 10414, "ep_reward": 236.65757751464844, "reward": 0.8413504362106323, "action": -1.3991388082504272}
{"mode": "train", "epochs": 6, "timestep": 10415, "ep_reward": 237.5093231201172, "reward": 0.8517487645149231, "action": -1.5456699132919312}
{"mode": "train", "epochs": 6, "timestep": 10416, "ep_reward": 238.35183715820312, "reward": 0.8425081968307495, "action": -1.4931120872497559}
{"mode": "train", "epochs": 6, "timestep": 10417, "ep_reward": 239.16448974609375, "reward": 0.8126556873321533, "action": -1.5527911186218262}
{"mode": "train", "epochs": 6, "timestep": 10418, "ep_reward": 239.92050170898438, "reward": 0.7560182809829712, "action": -1.2653204202651978}
{"mode": "train", "epochs": 6, "timestep": 10419, "ep_reward": 240.58999633789062, "reward": 0.669501543045044, "action": -0.6169589757919312}
{"mode": "train", "epochs": 6, "timestep": 10420, "ep_reward": 241.14215087890625, "reward": 0.5521613359451294, "action": -0.904212236404419}
{"mode": "train", "epochs": 6, "timestep": 10421, "ep_reward": 241.5437469482422, "reward": 0.40160298347473145, "action": -0.6609597206115723}
{"mode": "train", "epochs": 6, "timestep": 10422, "ep_reward": 241.84622192382812, "reward": 0.30247753858566284, "action": -1.0942528247833252}
{"mode": "train", "epochs": 6, "timestep": 10423, "ep_reward": 242.0296630859375, "reward": 0.18344277143478394, "action": -0.7116423845291138}
{"mode": "train", "epochs": 6, "timestep": 10424, "ep_reward": 242.07400512695312, "reward": 0.04434174299240112, "action": -0.9342089891433716}
{"mode": "train", "epochs": 6, "timestep": 10425, "ep_reward": 242.147705078125, "reward": 0.07370501756668091, "action": -1.122542381286621}
{"mode": "train", "epochs": 6, "timestep": 10426, "ep_reward": 242.35739135742188, "reward": 0.20969337224960327, "action": -0.24543136358261108}
{"mode": "train", "epochs": 6, "timestep": 10427, "ep_reward": 242.71661376953125, "reward": 0.35921788215637207, "action": -0.1942017674446106}
{"mode": "train", "epochs": 6, "timestep": 10428, "ep_reward": 243.2161407470703, "reward": 0.49952149391174316, "action": -0.35922133922576904}
{"mode": "train", "epochs": 6, "timestep": 10429, "ep_reward": 243.83547973632812, "reward": 0.6193438172340393, "action": -1.627342939376831}
{"mode": "train", "epochs": 6, "timestep": 10430, "ep_reward": 244.54039001464844, "reward": 0.7049039006233215, "action": -0.7552909851074219}
{"mode": "train", "epochs": 6, "timestep": 10431, "ep_reward": 245.31881713867188, "reward": 0.7784234881401062, "action": -1.2645113468170166}
{"mode": "train", "epochs": 6, "timestep": 10432, "ep_reward": 246.1461639404297, "reward": 0.8273396492004395, "action": -1.455418586730957}
{"mode": "train", "epochs": 6, "timestep": 10433, "ep_reward": 247.00384521484375, "reward": 0.85767662525177, "action": -1.3959325551986694}
{"mode": "train", "epochs": 6, "timestep": 10434, "ep_reward": 247.87701416015625, "reward": 0.873167097568512, "action": -1.211548089981079}
{"mode": "train", "epochs": 6, "timestep": 10435, "ep_reward": 248.75216674804688, "reward": 0.8751547336578369, "action": -1.1055971384048462}
{"mode": "train", "epochs": 6, "timestep": 10436, "ep_reward": 249.61422729492188, "reward": 0.862059473991394, "action": -1.1613937616348267}
{"mode": "train", "epochs": 6, "timestep": 10437, "ep_reward": 250.4440460205078, "reward": 0.8298211097717285, "action": -1.0213395357131958}
{"mode": "train", "epochs": 6, "timestep": 10438, "ep_reward": 251.219482421875, "reward": 0.7754340171813965, "action": -1.6179354190826416}
{"mode": "train", "epochs": 6, "timestep": 10439, "ep_reward": 251.9036102294922, "reward": 0.6841297149658203, "action": -0.11869025230407715}
{"mode": "train", "epochs": 6, "timestep": 10440, "ep_reward": 252.47804260253906, "reward": 0.5744256377220154, "action": -1.3384606838226318}
{"mode": "train", "epochs": 6, "timestep": 10441, "ep_reward": 252.88597106933594, "reward": 0.4079325199127197, "action": -1.253753423690796}
{"mode": "train", "epochs": 6, "timestep": 10442, "ep_reward": 253.18019104003906, "reward": 0.2942204475402832, "action": -0.8580381870269775}
{"mode": "train", "epochs": 6, "timestep": 10443, "ep_reward": 253.35385131835938, "reward": 0.17366009950637817, "action": -0.5590754747390747}
{"mode": "train", "epochs": 6, "timestep": 10444, "ep_reward": 253.3868865966797, "reward": 0.03303581476211548, "action": -0.9533489346504211}
{"mode": "train", "epochs": 6, "timestep": 10445, "ep_reward": 253.47152709960938, "reward": 0.08464306592941284, "action": -0.6803624629974365}
{"mode": "train", "epochs": 6, "timestep": 10446, "ep_reward": 253.697998046875, "reward": 0.22646361589431763, "action": -0.4754256010055542}
{"mode": "train", "epochs": 6, "timestep": 10447, "ep_reward": 254.06959533691406, "reward": 0.37159037590026855, "action": -0.7516471147537231}
{"mode": "train", "epochs": 6, "timestep": 10448, "ep_reward": 254.57359313964844, "reward": 0.503997266292572, "action": -0.06059861183166504}
{"mode": "train", "epochs": 6, "timestep": 10449, "ep_reward": 255.20010375976562, "reward": 0.626508355140686, "action": -0.5316921472549438}
{"mode": "train", "epochs": 6, "timestep": 10450, "ep_reward": 255.92105102539062, "reward": 0.7209527492523193, "action": -0.6486471891403198}
{"mode": "train", "epochs": 6, "timestep": 10451, "ep_reward": 256.7132873535156, "reward": 0.7922337055206299, "action": -1.2411754131317139}
{"mode": "train", "epochs": 6, "timestep": 10452, "ep_reward": 257.5525207519531, "reward": 0.8392333388328552, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 10453, "ep_reward": 258.4173583984375, "reward": 0.8648339509963989, "action": -1.3295559883117676}
{"mode": "train", "epochs": 6, "timestep": 10454, "ep_reward": 259.29901123046875, "reward": 0.8816550970077515, "action": -0.796798586845398}
{"mode": "train", "epochs": 6, "timestep": 10455, "ep_reward": 260.1877136230469, "reward": 0.8886913061141968, "action": -1.3454952239990234}
{"mode": "train", "epochs": 6, "timestep": 10456, "ep_reward": 261.0649719238281, "reward": 0.8772590160369873, "action": -1.3502678871154785}
{"mode": "train", "epochs": 6, "timestep": 10457, "ep_reward": 261.9140319824219, "reward": 0.8490528464317322, "action": -0.8238207101821899}
{"mode": "train", "epochs": 6, "timestep": 10458, "ep_reward": 262.7186279296875, "reward": 0.8046048879623413, "action": -1.923953890800476}
{"mode": "train", "epochs": 6, "timestep": 10459, "ep_reward": 263.44012451171875, "reward": 0.721494197845459, "action": -1.853243350982666}
{"mode": "train", "epochs": 6, "timestep": 10460, "ep_reward": 264.0415344238281, "reward": 0.6013967394828796, "action": -0.6550451517105103}
{"mode": "train", "epochs": 6, "timestep": 10461, "ep_reward": 264.4964599609375, "reward": 0.4549254775047302, "action": -1.3845863342285156}
{"mode": "train", "epochs": 6, "timestep": 10462, "ep_reward": 264.8215637207031, "reward": 0.32510268688201904, "action": -0.854610800743103}
{"mode": "train", "epochs": 6, "timestep": 10463, "ep_reward": 265.0318603515625, "reward": 0.21028554439544678, "action": -0.3944082260131836}
{"mode": "train", "epochs": 6, "timestep": 10464, "ep_reward": 265.1072998046875, "reward": 0.07543659210205078, "action": -0.29694437980651855}
{"mode": "train", "epochs": 6, "timestep": 10465, "ep_reward": 265.1499938964844, "reward": 0.04268890619277954, "action": -0.10450637340545654}
{"mode": "train", "epochs": 6, "timestep": 10466, "ep_reward": 265.34014892578125, "reward": 0.19016671180725098, "action": -1.7227668762207031}
{"mode": "train", "epochs": 6, "timestep": 10467, "ep_reward": 265.6598815917969, "reward": 0.3197377920150757, "action": -0.9995570778846741}
{"mode": "train", "epochs": 6, "timestep": 10468, "ep_reward": 266.11480712890625, "reward": 0.4549291133880615, "action": -0.9789459109306335}
{"mode": "train", "epochs": 6, "timestep": 10469, "ep_reward": 266.6905822753906, "reward": 0.5757836103439331, "action": -1.0317728519439697}
{"mode": "train", "epochs": 6, "timestep": 10470, "ep_reward": 267.3658752441406, "reward": 0.6752970218658447, "action": -0.03238403797149658}
{"mode": "train", "epochs": 6, "timestep": 10471, "ep_reward": 268.1272888183594, "reward": 0.7614048719406128, "action": -0.8825333714485168}
{"mode": "train", "epochs": 6, "timestep": 10472, "ep_reward": 268.94384765625, "reward": 0.8165644407272339, "action": -0.3543207049369812}
{"mode": "train", "epochs": 6, "timestep": 10473, "ep_reward": 269.801025390625, "reward": 0.8571876287460327, "action": -0.5829762816429138}
{"mode": "train", "epochs": 6, "timestep": 10474, "ep_reward": 270.6802978515625, "reward": 0.879277229309082, "action": -0.9982969164848328}
{"mode": "train", "epochs": 6, "timestep": 10475, "ep_reward": 271.5637512207031, "reward": 0.8834510445594788, "action": -1.3996264934539795}
{"mode": "train", "epochs": 6, "timestep": 10476, "ep_reward": 272.4332275390625, "reward": 0.8694620132446289, "action": -1.2847795486450195}
{"mode": "train", "epochs": 6, "timestep": 10477, "ep_reward": 273.27166748046875, "reward": 0.8384504914283752, "action": -1.713292121887207}
{"mode": "train", "epochs": 6, "timestep": 10478, "ep_reward": 274.0519714355469, "reward": 0.780302882194519, "action": -0.6419832706451416}
{"mode": "train", "epochs": 6, "timestep": 10479, "ep_reward": 274.75592041015625, "reward": 0.7039405107498169, "action": 0.2080124020576477}
{"mode": "train", "epochs": 6, "timestep": 10480, "ep_reward": 275.36090087890625, "reward": 0.6049667596817017, "action": -1.5012785196304321}
{"mode": "train", "epochs": 6, "timestep": 10481, "ep_reward": 275.8058776855469, "reward": 0.4449694752693176, "action": -1.030147671699524}
{"mode": "train", "epochs": 6, "timestep": 10482, "ep_reward": 276.11712646484375, "reward": 0.3112626075744629, "action": -1.271841049194336}
{"mode": "train", "epochs": 6, "timestep": 10483, "ep_reward": 276.3109130859375, "reward": 0.19380134344100952, "action": -1.3395004272460938}
{"mode": "train", "epochs": 6, "timestep": 10484, "ep_reward": 276.3673095703125, "reward": 0.05638629198074341, "action": -1.128297209739685}
{"mode": "train", "epochs": 6, "timestep": 10485, "ep_reward": 276.4291687011719, "reward": 0.06186866760253906, "action": -0.7528778314590454}
{"mode": "train", "epochs": 6, "timestep": 10486, "ep_reward": 276.6312561035156, "reward": 0.2020866870880127, "action": -0.3425416350364685}
{"mode": "train", "epochs": 6, "timestep": 10487, "ep_reward": 276.98095703125, "reward": 0.3497017025947571, "action": -1.0933548212051392}
{"mode": "train", "epochs": 6, "timestep": 10488, "ep_reward": 277.4610290527344, "reward": 0.48008179664611816, "action": -1.493593692779541}
{"mode": "train", "epochs": 6, "timestep": 10489, "ep_reward": 278.0523376464844, "reward": 0.5913140773773193, "action": -0.27704715728759766}
{"mode": "train", "epochs": 6, "timestep": 10490, "ep_reward": 278.7476501464844, "reward": 0.6952999830245972, "action": -0.9055203199386597}
{"mode": "train", "epochs": 6, "timestep": 10491, "ep_reward": 279.51690673828125, "reward": 0.7692661285400391, "action": -1.124069094657898}
{"mode": "train", "epochs": 6, "timestep": 10492, "ep_reward": 280.33740234375, "reward": 0.8205102682113647, "action": -1.4695857763290405}
{"mode": "train", "epochs": 6, "timestep": 10493, "ep_reward": 281.1882019042969, "reward": 0.850791335105896, "action": -1.7392594814300537}
{"mode": "train", "epochs": 6, "timestep": 10494, "ep_reward": 282.0509338378906, "reward": 0.8627445697784424, "action": -0.9617687463760376}
{"mode": "train", "epochs": 6, "timestep": 10495, "ep_reward": 282.91595458984375, "reward": 0.8650239109992981, "action": -0.07426130771636963}
{"mode": "train", "epochs": 6, "timestep": 10496, "ep_reward": 283.77398681640625, "reward": 0.8580422401428223, "action": -0.8810972571372986}
{"mode": "train", "epochs": 6, "timestep": 10497, "ep_reward": 284.5992126464844, "reward": 0.8252314925193787, "action": -0.8047600984573364}
{"mode": "train", "epochs": 6, "timestep": 10498, "ep_reward": 285.36895751953125, "reward": 0.7697306275367737, "action": -0.5878376960754395}
{"mode": "train", "epochs": 6, "timestep": 10499, "ep_reward": 286.0564270019531, "reward": 0.6874788999557495, "action": -0.34150511026382446}
{"mode": "train", "epochs": 6, "timestep": 10500, "ep_reward": 286.6302795410156, "reward": 0.5738378763198853, "action": -0.9428174495697021}
{"mode": "train", "epochs": 6, "timestep": 10501, "ep_reward": 287.0434875488281, "reward": 0.41320061683654785, "action": -1.1504013538360596}
{"mode": "train", "epochs": 6, "timestep": 10502, "ep_reward": 287.3303527832031, "reward": 0.28687918186187744, "action": -0.43265604972839355}
{"mode": "train", "epochs": 6, "timestep": 10503, "ep_reward": 287.4952697753906, "reward": 0.1649300456047058, "action": -0.8986986875534058}
{"mode": "train", "epochs": 6, "timestep": 10504, "ep_reward": 287.51824951171875, "reward": 0.022984564304351807, "action": -1.1756088733673096}
{"mode": "train", "epochs": 6, "timestep": 10505, "ep_reward": 287.6121826171875, "reward": 0.09394770860671997, "action": -1.747103214263916}
{"mode": "train", "epochs": 6, "timestep": 10506, "ep_reward": 287.8385009765625, "reward": 0.22632986307144165, "action": -0.9350184202194214}
{"mode": "train", "epochs": 6, "timestep": 10507, "ep_reward": 288.2060546875, "reward": 0.3675641417503357, "action": -1.0011318922042847}
{"mode": "train", "epochs": 6, "timestep": 10508, "ep_reward": 288.7051086425781, "reward": 0.499056339263916, "action": -0.37796658277511597}
{"mode": "train", "epochs": 6, "timestep": 10509, "ep_reward": 289.32476806640625, "reward": 0.619665265083313, "action": -1.3509025573730469}
{"mode": "train", "epochs": 6, "timestep": 10510, "ep_reward": 290.0314025878906, "reward": 0.7066448926925659, "action": -1.6577643156051636}
{"mode": "train", "epochs": 6, "timestep": 10511, "ep_reward": 290.80047607421875, "reward": 0.7690685987472534, "action": -0.7506265640258789}
{"mode": "train", "epochs": 6, "timestep": 10512, "ep_reward": 291.6195983886719, "reward": 0.8191120028495789, "action": -1.655695915222168}
{"mode": "train", "epochs": 6, "timestep": 10513, "ep_reward": 292.4613952636719, "reward": 0.8417918086051941, "action": -0.6907405257225037}
{"mode": "train", "epochs": 6, "timestep": 10514, "ep_reward": 293.31634521484375, "reward": 0.8549346923828125, "action": -1.3880374431610107}
{"mode": "train", "epochs": 6, "timestep": 10515, "ep_reward": 294.159912109375, "reward": 0.8435607552528381, "action": -1.5509074926376343}
{"mode": "train", "epochs": 6, "timestep": 10516, "ep_reward": 294.969482421875, "reward": 0.8095638155937195, "action": -0.9024286866188049}
{"mode": "train", "epochs": 6, "timestep": 10517, "ep_reward": 295.7256164550781, "reward": 0.7561370134353638, "action": -1.0908147096633911}
{"mode": "train", "epochs": 6, "timestep": 10518, "ep_reward": 296.39434814453125, "reward": 0.6687450408935547, "action": -0.8924022912979126}
{"mode": "train", "epochs": 6, "timestep": 10519, "ep_reward": 296.9393310546875, "reward": 0.5449894666671753, "action": -0.6348022222518921}
{"mode": "train", "epochs": 6, "timestep": 10520, "ep_reward": 297.3317565917969, "reward": 0.3924386501312256, "action": -0.06357502937316895}
{"mode": "train", "epochs": 6, "timestep": 10521, "ep_reward": 297.6229248046875, "reward": 0.2911568284034729, "action": -1.6297569274902344}
{"mode": "train", "epochs": 6, "timestep": 10522, "ep_reward": 297.7930908203125, "reward": 0.1701553463935852, "action": -0.9122524261474609}
{"mode": "train", "epochs": 6, "timestep": 10523, "ep_reward": 297.8221435546875, "reward": 0.02905791997909546, "action": -0.7443673014640808}
{"mode": "train", "epochs": 6, "timestep": 10524, "ep_reward": 297.91058349609375, "reward": 0.0884365439414978, "action": -0.724778950214386}
{"mode": "train", "epochs": 6, "timestep": 10525, "ep_reward": 298.1404113769531, "reward": 0.22983115911483765, "action": -0.23360604047775269}
{"mode": "train", "epochs": 6, "timestep": 10526, "ep_reward": 298.5182800292969, "reward": 0.37788301706314087, "action": -0.31387418508529663}
{"mode": "train", "epochs": 6, "timestep": 10527, "ep_reward": 299.032470703125, "reward": 0.5141905546188354, "action": -1.4018309116363525}
{"mode": "train", "epochs": 6, "timestep": 10528, "ep_reward": 299.6531982421875, "reward": 0.6207146644592285, "action": -1.4873601198196411}
{"mode": "train", "epochs": 6, "timestep": 10529, "ep_reward": 300.36004638671875, "reward": 0.7068629264831543, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 10530, "ep_reward": 301.1281433105469, "reward": 0.7680957317352295, "action": -0.798940896987915}
{"mode": "train", "epochs": 6, "timestep": 10531, "ep_reward": 301.94891357421875, "reward": 0.8207566142082214, "action": -1.2517949342727661}
{"mode": "train", "epochs": 6, "timestep": 10532, "ep_reward": 302.7994689941406, "reward": 0.8505696058273315, "action": -1.9635632038116455}
{"mode": "train", "epochs": 6, "timestep": 10533, "ep_reward": 303.6573791503906, "reward": 0.8578980565071106, "action": -0.246673583984375}
{"mode": "train", "epochs": 6, "timestep": 10534, "ep_reward": 304.5203857421875, "reward": 0.8630066514015198, "action": -1.0569370985031128}
{"mode": "train", "epochs": 6, "timestep": 10535, "ep_reward": 305.3636474609375, "reward": 0.8432513475418091, "action": -1.0744922161102295}
{"mode": "train", "epochs": 6, "timestep": 10536, "ep_reward": 306.1656799316406, "reward": 0.8020327687263489, "action": -1.2572046518325806}
{"mode": "train", "epochs": 6, "timestep": 10537, "ep_reward": 306.8975524902344, "reward": 0.7318575382232666, "action": -0.8577824831008911}
{"mode": "train", "epochs": 6, "timestep": 10538, "ep_reward": 307.5298156738281, "reward": 0.6322669982910156, "action": -0.8968008756637573}
{"mode": "train", "epochs": 6, "timestep": 10539, "ep_reward": 308.0223693847656, "reward": 0.4925440549850464, "action": -1.2407373189926147}
{"mode": "train", "epochs": 6, "timestep": 10540, "ep_reward": 308.3732604980469, "reward": 0.35088545083999634, "action": -0.8431342840194702}
{"mode": "train", "epochs": 6, "timestep": 10541, "ep_reward": 308.6143493652344, "reward": 0.2410876750946045, "action": -0.6946175694465637}
{"mode": "train", "epochs": 6, "timestep": 10542, "ep_reward": 308.7255554199219, "reward": 0.11121124029159546, "action": -1.2341269254684448}
{"mode": "train", "epochs": 6, "timestep": 10543, "ep_reward": 308.7297668457031, "reward": 0.004196882247924805, "action": -1.9321337938308716}
{"mode": "train", "epochs": 6, "timestep": 10544, "ep_reward": 308.8785095214844, "reward": 0.14874732494354248, "action": -0.6591570377349854}
{"mode": "train", "epochs": 6, "timestep": 10545, "ep_reward": 309.1710205078125, "reward": 0.29250437021255493, "action": -0.7001797556877136}
{"mode": "train", "epochs": 6, "timestep": 10546, "ep_reward": 309.6031494140625, "reward": 0.4321368932723999, "action": -0.4073482155799866}
{"mode": "train", "epochs": 6, "timestep": 10547, "ep_reward": 310.16485595703125, "reward": 0.561708927154541, "action": -1.1400245428085327}
{"mode": "train", "epochs": 6, "timestep": 10548, "ep_reward": 310.8278503417969, "reward": 0.6629876494407654, "action": -1.2759603261947632}
{"mode": "train", "epochs": 6, "timestep": 10549, "ep_reward": 311.5697326660156, "reward": 0.7418796420097351, "action": -0.620054304599762}
{"mode": "train", "epochs": 6, "timestep": 10550, "ep_reward": 312.3755798339844, "reward": 0.8058525919914246, "action": -0.5488711595535278}
{"mode": "train", "epochs": 6, "timestep": 10551, "ep_reward": 313.2262878417969, "reward": 0.8507121205329895, "action": -0.6424024701118469}
{"mode": "train", "epochs": 6, "timestep": 10552, "ep_reward": 314.1043395996094, "reward": 0.8780426383018494, "action": -1.2811411619186401}
{"mode": "train", "epochs": 6, "timestep": 10553, "ep_reward": 314.9905090332031, "reward": 0.8861624598503113, "action": -0.956887423992157}
{"mode": "train", "epochs": 6, "timestep": 10554, "ep_reward": 315.8733215332031, "reward": 0.8828174471855164, "action": -1.006827473640442}
{"mode": "train", "epochs": 6, "timestep": 10555, "ep_reward": 316.7370300292969, "reward": 0.8637105226516724, "action": -0.9699083566665649}
{"mode": "train", "epochs": 6, "timestep": 10556, "ep_reward": 317.5633544921875, "reward": 0.8263206481933594, "action": -0.9711326360702515}
{"mode": "train", "epochs": 6, "timestep": 10557, "ep_reward": 318.3285827636719, "reward": 0.7652273178100586, "action": -0.9511838555335999}
{"mode": "train", "epochs": 6, "timestep": 10558, "ep_reward": 319.002685546875, "reward": 0.6741040945053101, "action": -0.7884173393249512}
{"mode": "train", "epochs": 6, "timestep": 10559, "ep_reward": 319.55096435546875, "reward": 0.5482864379882812, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 10560, "ep_reward": 319.9210510253906, "reward": 0.37008988857269287, "action": -0.970896303653717}
{"mode": "train", "epochs": 6, "timestep": 10561, "ep_reward": 320.1852722167969, "reward": 0.26421254873275757, "action": -0.9155373573303223}
{"mode": "train", "epochs": 6, "timestep": 10562, "ep_reward": 320.3236083984375, "reward": 0.13833880424499512, "action": -0.8284521102905273}
{"mode": "train", "epochs": 6, "timestep": 10563, "ep_reward": 320.3160400390625, "reward": -0.007574558258056641, "action": -1.0859625339508057}
{"mode": "train", "epochs": 6, "timestep": 10564, "ep_reward": 320.4380187988281, "reward": 0.12198066711425781, "action": -0.5745360851287842}
{"mode": "train", "epochs": 6, "timestep": 10565, "ep_reward": 320.7040710449219, "reward": 0.2660493850708008, "action": -1.4244204759597778}
{"mode": "train", "epochs": 6, "timestep": 10566, "ep_reward": 321.1019592285156, "reward": 0.39787691831588745, "action": -1.9391191005706787}
{"mode": "train", "epochs": 6, "timestep": 10567, "ep_reward": 321.6167907714844, "reward": 0.5148299932479858, "action": -0.4988555312156677}
{"mode": "train", "epochs": 6, "timestep": 10568, "ep_reward": 322.2481994628906, "reward": 0.631419837474823, "action": -1.490193486213684}
{"mode": "train", "epochs": 6, "timestep": 10569, "ep_reward": 322.9620666503906, "reward": 0.7138727903366089, "action": -1.6553285121917725}
{"mode": "train", "epochs": 6, "timestep": 10570, "ep_reward": 323.7349548339844, "reward": 0.7729009985923767, "action": -0.9158164262771606}
{"mode": "train", "epochs": 6, "timestep": 10571, "ep_reward": 324.5528259277344, "reward": 0.8178622722625732, "action": -0.9540356993675232}
{"mode": "train", "epochs": 6, "timestep": 10572, "ep_reward": 325.395263671875, "reward": 0.8424268364906311, "action": -1.266424536705017}
{"mode": "train", "epochs": 6, "timestep": 10573, "ep_reward": 326.2406005859375, "reward": 0.8453304767608643, "action": -1.7220048904418945}
{"mode": "train", "epochs": 6, "timestep": 10574, "ep_reward": 327.06475830078125, "reward": 0.8241603374481201, "action": -0.6871640086174011}
{"mode": "train", "epochs": 6, "timestep": 10575, "ep_reward": 327.8544616699219, "reward": 0.7897005081176758, "action": -0.857319176197052}
{"mode": "train", "epochs": 6, "timestep": 10576, "ep_reward": 328.58013916015625, "reward": 0.7256914973258972, "action": -1.5785887241363525}
{"mode": "train", "epochs": 6, "timestep": 10577, "ep_reward": 329.1977844238281, "reward": 0.6176483631134033, "action": -0.12075763940811157}
{"mode": "train", "epochs": 6, "timestep": 10578, "ep_reward": 329.6856384277344, "reward": 0.487842857837677, "action": -1.0376535654067993}
{"mode": "train", "epochs": 6, "timestep": 10579, "ep_reward": 330.04315185546875, "reward": 0.35751211643218994, "action": -0.5693345069885254}
{"mode": "train", "epochs": 6, "timestep": 10580, "ep_reward": 330.2921142578125, "reward": 0.24895519018173218, "action": -1.2454843521118164}
{"mode": "train", "epochs": 6, "timestep": 10581, "ep_reward": 330.41265869140625, "reward": 0.12054461240768433, "action": -0.6690984964370728}
{"mode": "train", "epochs": 6, "timestep": 10582, "ep_reward": 330.4067077636719, "reward": -0.005936384201049805, "action": -0.8375023603439331}
{"mode": "train", "epochs": 6, "timestep": 10583, "ep_reward": 330.54644775390625, "reward": 0.13974231481552124, "action": -0.8130204081535339}
{"mode": "train", "epochs": 6, "timestep": 10584, "ep_reward": 330.8277893066406, "reward": 0.28132951259613037, "action": -1.2665808200836182}
{"mode": "train", "epochs": 6, "timestep": 10585, "ep_reward": 331.2428283691406, "reward": 0.4150530695915222, "action": -0.6297106742858887}
{"mode": "train", "epochs": 6, "timestep": 10586, "ep_reward": 331.78790283203125, "reward": 0.5450729131698608, "action": -0.4968692660331726}
{"mode": "train", "epochs": 6, "timestep": 10587, "ep_reward": 332.4439697265625, "reward": 0.6560665965080261, "action": -1.1049959659576416}
{"mode": "train", "epochs": 6, "timestep": 10588, "ep_reward": 333.1817626953125, "reward": 0.7377927303314209, "action": -1.1367818117141724}
{"mode": "train", "epochs": 6, "timestep": 10589, "ep_reward": 333.9796447753906, "reward": 0.7978706955909729, "action": -1.4211032390594482}
{"mode": "train", "epochs": 6, "timestep": 10590, "ep_reward": 334.81597900390625, "reward": 0.8363444209098816, "action": -0.3610149621963501}
{"mode": "train", "epochs": 6, "timestep": 10591, "ep_reward": 335.68212890625, "reward": 0.8661645650863647, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 10592, "ep_reward": 336.54876708984375, "reward": 0.8666344881057739, "action": -0.8213003277778625}
{"mode": "train", "epochs": 6, "timestep": 10593, "ep_reward": 337.4091796875, "reward": 0.8604210019111633, "action": -1.209252953529358}
{"mode": "train", "epochs": 6, "timestep": 10594, "ep_reward": 338.2413330078125, "reward": 0.8321578502655029, "action": -1.6320081949234009}
{"mode": "train", "epochs": 6, "timestep": 10595, "ep_reward": 339.0173645019531, "reward": 0.776017963886261, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 10596, "ep_reward": 339.701171875, "reward": 0.6838039755821228, "action": -1.0732053518295288}
{"mode": "train", "epochs": 6, "timestep": 10597, "ep_reward": 340.2641906738281, "reward": 0.5630238652229309, "action": -0.9813107252120972}
{"mode": "train", "epochs": 6, "timestep": 10598, "ep_reward": 340.6670837402344, "reward": 0.4028838276863098, "action": -0.8586037158966064}
{"mode": "train", "epochs": 6, "timestep": 10599, "ep_reward": 340.97113037109375, "reward": 0.3040618300437927, "action": -1.1634867191314697}
{"mode": "train", "epochs": 6, "timestep": 10600, "ep_reward": 341.1563720703125, "reward": 0.18523132801055908, "action": -1.4543870687484741}
{"mode": "train", "epochs": 6, "timestep": 10601, "ep_reward": 341.20294189453125, "reward": 0.046557605266571045, "action": -0.6155892610549927}
{"mode": "train", "epochs": 6, "timestep": 10602, "ep_reward": 341.2744140625, "reward": 0.07147389650344849, "action": -1.6799315214157104}
{"mode": "train", "epochs": 6, "timestep": 10603, "ep_reward": 341.48138427734375, "reward": 0.20696920156478882, "action": -0.9340020418167114}
{"mode": "train", "epochs": 6, "timestep": 10604, "ep_reward": 341.8294982910156, "reward": 0.34810054302215576, "action": -1.403961181640625}
{"mode": "train", "epochs": 6, "timestep": 10605, "ep_reward": 342.30572509765625, "reward": 0.47621703147888184, "action": -1.8167821168899536}
{"mode": "train", "epochs": 6, "timestep": 10606, "ep_reward": 342.8904113769531, "reward": 0.5846925377845764, "action": -1.4574013948440552}
{"mode": "train", "epochs": 6, "timestep": 10607, "ep_reward": 343.5674743652344, "reward": 0.6770758628845215, "action": -0.8571674227714539}
{"mode": "train", "epochs": 6, "timestep": 10608, "ep_reward": 344.31964111328125, "reward": 0.7521786093711853, "action": -1.3914637565612793}
{"mode": "train", "epochs": 6, "timestep": 10609, "ep_reward": 345.1185607910156, "reward": 0.7989232540130615, "action": -0.48905879259109497}
{"mode": "train", "epochs": 6, "timestep": 10610, "ep_reward": 345.951416015625, "reward": 0.8328654766082764, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 10611, "ep_reward": 346.7845153808594, "reward": 0.833104133605957, "action": -0.775006890296936}
{"mode": "train", "epochs": 6, "timestep": 10612, "ep_reward": 347.6086730957031, "reward": 0.8241702318191528, "action": -0.10148108005523682}
{"mode": "train", "epochs": 6, "timestep": 10613, "ep_reward": 348.40814208984375, "reward": 0.7994703054428101, "action": -0.9533624649047852}
{"mode": "train", "epochs": 6, "timestep": 10614, "ep_reward": 349.1479187011719, "reward": 0.7397811412811279, "action": -0.06657552719116211}
{"mode": "train", "epochs": 6, "timestep": 10615, "ep_reward": 349.8063659667969, "reward": 0.6584484577178955, "action": -1.0840153694152832}
{"mode": "train", "epochs": 6, "timestep": 10616, "ep_reward": 350.332763671875, "reward": 0.5263833999633789, "action": -1.4779372215270996}
{"mode": "train", "epochs": 6, "timestep": 10617, "ep_reward": 350.71026611328125, "reward": 0.3775068521499634, "action": -0.6131649017333984}
{"mode": "train", "epochs": 6, "timestep": 10618, "ep_reward": 350.98333740234375, "reward": 0.27308589220046997, "action": -1.3436710834503174}
{"mode": "train", "epochs": 6, "timestep": 10619, "ep_reward": 351.132080078125, "reward": 0.14874917268753052, "action": -1.3771018981933594}
{"mode": "train", "epochs": 6, "timestep": 10620, "ep_reward": 351.136474609375, "reward": 0.004386603832244873, "action": -1.5528862476348877}
{"mode": "train", "epochs": 6, "timestep": 10621, "ep_reward": 351.2476501464844, "reward": 0.11118167638778687, "action": -0.66595458984375}
{"mode": "train", "epochs": 6, "timestep": 10622, "ep_reward": 351.50140380859375, "reward": 0.25375455617904663, "action": -1.8051679134368896}
{"mode": "train", "epochs": 6, "timestep": 10623, "ep_reward": 351.8832092285156, "reward": 0.38179248571395874, "action": -0.9741556644439697}
{"mode": "train", "epochs": 6, "timestep": 10624, "ep_reward": 352.39532470703125, "reward": 0.5121129155158997, "action": -0.6221143007278442}
{"mode": "train", "epochs": 6, "timestep": 10625, "ep_reward": 353.0232238769531, "reward": 0.627887487411499, "action": -0.9285308122634888}
{"mode": "train", "epochs": 6, "timestep": 10626, "ep_reward": 353.7403869628906, "reward": 0.7171715497970581, "action": -0.8462469577789307}
{"mode": "train", "epochs": 6, "timestep": 10627, "ep_reward": 354.5247802734375, "reward": 0.7843978404998779, "action": -1.3993557691574097}
{"mode": "train", "epochs": 6, "timestep": 10628, "ep_reward": 355.350830078125, "reward": 0.826036810874939, "action": -0.7754502296447754}
{"mode": "train", "epochs": 6, "timestep": 10629, "ep_reward": 356.2056884765625, "reward": 0.8548682928085327, "action": -0.8637940883636475}
{"mode": "train", "epochs": 6, "timestep": 10630, "ep_reward": 357.07159423828125, "reward": 0.8659008145332336, "action": -0.8904102444648743}
{"mode": "train", "epochs": 6, "timestep": 10631, "ep_reward": 357.931640625, "reward": 0.8600600361824036, "action": -0.3523423671722412}
{"mode": "train", "epochs": 6, "timestep": 10632, "ep_reward": 358.7725524902344, "reward": 0.8409268260002136, "action": -1.1893484592437744}
{"mode": "train", "epochs": 6, "timestep": 10633, "ep_reward": 359.56512451171875, "reward": 0.7925742864608765, "action": -0.996080756187439}
{"mode": "train", "epochs": 6, "timestep": 10634, "ep_reward": 360.2831726074219, "reward": 0.7180570960044861, "action": -1.9057929515838623}
{"mode": "train", "epochs": 6, "timestep": 10635, "ep_reward": 360.879638671875, "reward": 0.5964683294296265, "action": -0.38870495557785034}
{"mode": "train", "epochs": 6, "timestep": 10636, "ep_reward": 361.33270263671875, "reward": 0.45305949449539185, "action": -1.107606291770935}
{"mode": "train", "epochs": 6, "timestep": 10637, "ep_reward": 361.657470703125, "reward": 0.3247653841972351, "action": -0.6348934769630432}
{"mode": "train", "epochs": 6, "timestep": 10638, "ep_reward": 361.8673095703125, "reward": 0.2098519206047058, "action": -0.5629549026489258}
{"mode": "train", "epochs": 6, "timestep": 10639, "ep_reward": 361.9422302246094, "reward": 0.0749313235282898, "action": -0.594441294670105}
{"mode": "train", "epochs": 6, "timestep": 10640, "ep_reward": 361.98541259765625, "reward": 0.043167948722839355, "action": -0.5955140590667725}
{"mode": "train", "epochs": 6, "timestep": 10641, "ep_reward": 362.16998291015625, "reward": 0.1845611333847046, "action": -1.75392484664917}
{"mode": "train", "epochs": 6, "timestep": 10642, "ep_reward": 362.4848327636719, "reward": 0.3148581385612488, "action": -1.2401671409606934}
{"mode": "train", "epochs": 6, "timestep": 10643, "ep_reward": 362.9332275390625, "reward": 0.448380708694458, "action": -0.5351304411888123}
{"mode": "train", "epochs": 6, "timestep": 10644, "ep_reward": 363.5087585449219, "reward": 0.5755199193954468, "action": -1.571081280708313}
{"mode": "train", "epochs": 6, "timestep": 10645, "ep_reward": 364.1780090332031, "reward": 0.6692531108856201, "action": -0.8791503310203552}
{"mode": "train", "epochs": 6, "timestep": 10646, "ep_reward": 364.92559814453125, "reward": 0.7475920915603638, "action": -1.694288969039917}
{"mode": "train", "epochs": 6, "timestep": 10647, "ep_reward": 365.72113037109375, "reward": 0.7955309152603149, "action": -1.5556066036224365}
{"mode": "train", "epochs": 6, "timestep": 10648, "ep_reward": 366.5458679199219, "reward": 0.8247469067573547, "action": -0.28302544355392456}
{"mode": "train", "epochs": 6, "timestep": 10649, "ep_reward": 367.3918762207031, "reward": 0.8460212349891663, "action": -0.7631960511207581}
{"mode": "train", "epochs": 6, "timestep": 10650, "ep_reward": 368.2354736328125, "reward": 0.8436064720153809, "action": -1.617499828338623}
{"mode": "train", "epochs": 6, "timestep": 10651, "ep_reward": 369.04791259765625, "reward": 0.8124386668205261, "action": -1.3462294340133667}
{"mode": "train", "epochs": 6, "timestep": 10652, "ep_reward": 369.8058166503906, "reward": 0.757888913154602, "action": -1.356858253479004}
{"mode": "train", "epochs": 6, "timestep": 10653, "ep_reward": 370.4762878417969, "reward": 0.6704712510108948, "action": -0.6395281553268433}
{"mode": "train", "epochs": 6, "timestep": 10654, "ep_reward": 371.0292663574219, "reward": 0.5529924035072327, "action": -0.7262495756149292}
{"mode": "train", "epochs": 6, "timestep": 10655, "ep_reward": 371.43072509765625, "reward": 0.4014638066291809, "action": -1.4675297737121582}
{"mode": "train", "epochs": 6, "timestep": 10656, "ep_reward": 371.733154296875, "reward": 0.30242645740509033, "action": -1.1937824487686157}
{"mode": "train", "epochs": 6, "timestep": 10657, "ep_reward": 371.91650390625, "reward": 0.1833629608154297, "action": -1.0599631071090698}
{"mode": "train", "epochs": 6, "timestep": 10658, "ep_reward": 371.96075439453125, "reward": 0.04426044225692749, "action": -1.2067523002624512}
{"mode": "train", "epochs": 6, "timestep": 10659, "ep_reward": 372.0345458984375, "reward": 0.07380509376525879, "action": -0.5576606392860413}
{"mode": "train", "epochs": 6, "timestep": 10660, "ep_reward": 372.25128173828125, "reward": 0.21673977375030518, "action": -1.2023626565933228}
{"mode": "train", "epochs": 6, "timestep": 10661, "ep_reward": 372.6043395996094, "reward": 0.35304582118988037, "action": -1.049281358718872}
{"mode": "train", "epochs": 6, "timestep": 10662, "ep_reward": 373.0889587402344, "reward": 0.48461639881134033, "action": -0.3843993544578552}
{"mode": "train", "epochs": 6, "timestep": 10663, "ep_reward": 373.6963806152344, "reward": 0.6074070930480957, "action": -0.5572619438171387}
{"mode": "train", "epochs": 6, "timestep": 10664, "ep_reward": 374.40155029296875, "reward": 0.7051820755004883, "action": -1.7358675003051758}
{"mode": "train", "epochs": 6, "timestep": 10665, "ep_reward": 375.1708984375, "reward": 0.7693517208099365, "action": -0.9771143794059753}
{"mode": "train", "epochs": 6, "timestep": 10666, "ep_reward": 375.9915466308594, "reward": 0.8206367492675781, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 10667, "ep_reward": 376.8365478515625, "reward": 0.8450164198875427, "action": -1.2424023151397705}
{"mode": "train", "epochs": 6, "timestep": 10668, "ep_reward": 377.6954650878906, "reward": 0.8589116334915161, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 10669, "ep_reward": 378.5445861816406, "reward": 0.8491281867027283, "action": -0.18494194746017456}
{"mode": "train", "epochs": 6, "timestep": 10670, "ep_reward": 379.3809509277344, "reward": 0.8363620042800903, "action": -1.7956271171569824}
{"mode": "train", "epochs": 6, "timestep": 10671, "ep_reward": 380.16680908203125, "reward": 0.7858693599700928, "action": -1.2817716598510742}
{"mode": "train", "epochs": 6, "timestep": 10672, "ep_reward": 380.87744140625, "reward": 0.710637092590332, "action": -1.9221007823944092}
{"mode": "train", "epochs": 6, "timestep": 10673, "ep_reward": 381.4670104980469, "reward": 0.5895583629608154, "action": -1.1318044662475586}
{"mode": "train", "epochs": 6, "timestep": 10674, "ep_reward": 381.9007873535156, "reward": 0.43377530574798584, "action": -1.5883078575134277}
{"mode": "train", "epochs": 6, "timestep": 10675, "ep_reward": 382.2329406738281, "reward": 0.33216243982315063, "action": -0.8080485463142395}
{"mode": "train", "epochs": 6, "timestep": 10676, "ep_reward": 382.4515380859375, "reward": 0.21860337257385254, "action": -1.2874921560287476}
{"mode": "train", "epochs": 6, "timestep": 10677, "ep_reward": 382.5365295410156, "reward": 0.08498948812484741, "action": -1.883811354637146}
{"mode": "train", "epochs": 6, "timestep": 10678, "ep_reward": 382.5689392089844, "reward": 0.03241372108459473, "action": -1.3277256488800049}
{"mode": "train", "epochs": 6, "timestep": 10679, "ep_reward": 382.7420654296875, "reward": 0.1731242537498474, "action": -0.9767547249794006}
{"mode": "train", "epochs": 6, "timestep": 10680, "ep_reward": 383.0553894042969, "reward": 0.3133236765861511, "action": -1.464133620262146}
{"mode": "train", "epochs": 6, "timestep": 10681, "ep_reward": 383.49847412109375, "reward": 0.44309866428375244, "action": -1.834216594696045}
{"mode": "train", "epochs": 6, "timestep": 10682, "ep_reward": 384.0546569824219, "reward": 0.5561887621879578, "action": -0.08115404844284058}
{"mode": "train", "epochs": 6, "timestep": 10683, "ep_reward": 384.7239074707031, "reward": 0.6692556142807007, "action": -0.29377299547195435}
{"mode": "train", "epochs": 6, "timestep": 10684, "ep_reward": 385.47796630859375, "reward": 0.7540605068206787, "action": -1.1296509504318237}
{"mode": "train", "epochs": 6, "timestep": 10685, "ep_reward": 386.28594970703125, "reward": 0.8079978823661804, "action": -0.6711823344230652}
{"mode": "train", "epochs": 6, "timestep": 10686, "ep_reward": 387.13238525390625, "reward": 0.846428632736206, "action": -1.4237382411956787}
{"mode": "train", "epochs": 6, "timestep": 10687, "ep_reward": 387.9934997558594, "reward": 0.8611092567443848, "action": -0.8627031445503235}
{"mode": "train", "epochs": 6, "timestep": 10688, "ep_reward": 388.857421875, "reward": 0.8639183044433594, "action": -1.4500675201416016}
{"mode": "train", "epochs": 6, "timestep": 10689, "ep_reward": 389.7013244628906, "reward": 0.8439095616340637, "action": -1.5071159601211548}
{"mode": "train", "epochs": 6, "timestep": 10690, "ep_reward": 390.5030822753906, "reward": 0.8017538189888, "action": -0.5857250690460205}
{"mode": "train", "epochs": 6, "timestep": 10691, "ep_reward": 391.2453308105469, "reward": 0.7422629594802856, "action": -1.4772473573684692}
{"mode": "train", "epochs": 6, "timestep": 10692, "ep_reward": 391.884765625, "reward": 0.639430582523346, "action": -1.1677926778793335}
{"mode": "train", "epochs": 6, "timestep": 10693, "ep_reward": 392.38385009765625, "reward": 0.49907851219177246, "action": -0.7093728184700012}
{"mode": "train", "epochs": 6, "timestep": 10694, "ep_reward": 392.7454528808594, "reward": 0.36160653829574585, "action": -1.3806463479995728}
{"mode": "train", "epochs": 6, "timestep": 10695, "ep_reward": 392.9995422363281, "reward": 0.2541007995605469, "action": 0.012040376663208008}
{"mode": "train", "epochs": 6, "timestep": 10696, "ep_reward": 393.1260070800781, "reward": 0.12647360563278198, "action": -0.2153090238571167}
{"mode": "train", "epochs": 6, "timestep": 10697, "ep_reward": 393.1133728027344, "reward": -0.012627601623535156, "action": -0.9740513563156128}
{"mode": "train", "epochs": 6, "timestep": 10698, "ep_reward": 393.2471618652344, "reward": 0.13379120826721191, "action": -1.6582598686218262}
{"mode": "train", "epochs": 6, "timestep": 10699, "ep_reward": 393.511962890625, "reward": 0.2647859454154968, "action": -0.7937847375869751}
{"mode": "train", "epochs": 6, "timestep": 10700, "ep_reward": 393.9185485839844, "reward": 0.40657734870910645, "action": -1.1835064888000488}
{"mode": "train", "epochs": 6, "timestep": 10701, "ep_reward": 394.4502258300781, "reward": 0.5316832065582275, "action": -0.49401038885116577}
{"mode": "train", "epochs": 6, "timestep": 10702, "ep_reward": 395.09552001953125, "reward": 0.6453070640563965, "action": -0.7433667182922363}
{"mode": "train", "epochs": 6, "timestep": 10703, "ep_reward": 395.8277587890625, "reward": 0.732252836227417, "action": -0.45537835359573364}
{"mode": "train", "epochs": 6, "timestep": 10704, "ep_reward": 396.62646484375, "reward": 0.7986953854560852, "action": -1.597025990486145}
{"mode": "train", "epochs": 6, "timestep": 10705, "ep_reward": 397.4612121582031, "reward": 0.8347573280334473, "action": -1.0137602090835571}
{"mode": "train", "epochs": 6, "timestep": 10706, "ep_reward": 398.3197326660156, "reward": 0.8585109114646912, "action": -0.3440505862236023}
{"mode": "train", "epochs": 6, "timestep": 10707, "ep_reward": 399.1909484863281, "reward": 0.8712207674980164, "action": -1.116919755935669}
{"mode": "train", "epochs": 6, "timestep": 10708, "ep_reward": 400.05206298828125, "reward": 0.8611204028129578, "action": -0.6838133335113525}
{"mode": "train", "epochs": 6, "timestep": 10709, "ep_reward": 400.8886413574219, "reward": 0.836590588092804, "action": -0.6630239486694336}
{"mode": "train", "epochs": 6, "timestep": 10710, "ep_reward": 401.6792297363281, "reward": 0.7905793190002441, "action": -1.1333914995193481}
{"mode": "train", "epochs": 6, "timestep": 10711, "ep_reward": 402.39111328125, "reward": 0.7118778824806213, "action": -1.5887701511383057}
{"mode": "train", "epochs": 6, "timestep": 10712, "ep_reward": 402.98248291015625, "reward": 0.5913686752319336, "action": -0.30082112550735474}
{"mode": "train", "epochs": 6, "timestep": 10713, "ep_reward": 403.4296875, "reward": 0.4471997618675232, "action": -1.247117042541504}
{"mode": "train", "epochs": 6, "timestep": 10714, "ep_reward": 403.7453918457031, "reward": 0.3156989812850952, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 10715, "ep_reward": 403.9447021484375, "reward": 0.19931954145431519, "action": -0.7843118906021118}
{"mode": "train", "epochs": 6, "timestep": 10716, "ep_reward": 404.00738525390625, "reward": 0.06268393993377686, "action": -1.1572327613830566}
{"mode": "train", "epochs": 6, "timestep": 10717, "ep_reward": 404.06298828125, "reward": 0.055595219135284424, "action": -0.17837220430374146}
{"mode": "train", "epochs": 6, "timestep": 10718, "ep_reward": 404.26568603515625, "reward": 0.20269489288330078, "action": -0.9395890831947327}
{"mode": "train", "epochs": 6, "timestep": 10719, "ep_reward": 404.60736083984375, "reward": 0.3416803479194641, "action": -1.275269865989685}
{"mode": "train", "epochs": 6, "timestep": 10720, "ep_reward": 405.07806396484375, "reward": 0.47071772813796997, "action": -1.2238045930862427}
{"mode": "train", "epochs": 6, "timestep": 10721, "ep_reward": 405.66436767578125, "reward": 0.5863003730773926, "action": -1.0186271667480469}
{"mode": "train", "epochs": 6, "timestep": 10722, "ep_reward": 406.3482360839844, "reward": 0.6838656663894653, "action": -1.0920391082763672}
{"mode": "train", "epochs": 6, "timestep": 10723, "ep_reward": 407.10650634765625, "reward": 0.7582687139511108, "action": -0.8144161701202393}
{"mode": "train", "epochs": 6, "timestep": 10724, "ep_reward": 407.92022705078125, "reward": 0.8137274384498596, "action": -1.5642375946044922}
{"mode": "train", "epochs": 6, "timestep": 10725, "ep_reward": 408.7638854980469, "reward": 0.8436630964279175, "action": -0.2647349238395691}
{"mode": "train", "epochs": 6, "timestep": 10726, "ep_reward": 409.6313171386719, "reward": 0.8674324750900269, "action": -1.2218546867370605}
{"mode": "train", "epochs": 6, "timestep": 10727, "ep_reward": 410.4981994628906, "reward": 0.8668745756149292, "action": -0.570672869682312}
{"mode": "train", "epochs": 6, "timestep": 10728, "ep_reward": 411.3531799316406, "reward": 0.8549708127975464, "action": -0.7627335786819458}
{"mode": "train", "epochs": 6, "timestep": 10729, "ep_reward": 412.1753234863281, "reward": 0.8221516609191895, "action": -1.3720769882202148}
{"mode": "train", "epochs": 6, "timestep": 10730, "ep_reward": 412.9342956542969, "reward": 0.7589644193649292, "action": -0.9685621857643127}
{"mode": "train", "epochs": 6, "timestep": 10731, "ep_reward": 413.6026916503906, "reward": 0.668390154838562, "action": -1.2189767360687256}
{"mode": "train", "epochs": 6, "timestep": 10732, "ep_reward": 414.138916015625, "reward": 0.5362366437911987, "action": -1.1706137657165527}
{"mode": "train", "epochs": 6, "timestep": 10733, "ep_reward": 414.5145263671875, "reward": 0.37559646368026733, "action": -0.49908894300460815}
{"mode": "train", "epochs": 6, "timestep": 10734, "ep_reward": 414.7853088378906, "reward": 0.27078282833099365, "action": -1.211897850036621}
{"mode": "train", "epochs": 6, "timestep": 10735, "ep_reward": 414.9314270019531, "reward": 0.14611107110977173, "action": -0.6529895663261414}
{"mode": "train", "epochs": 6, "timestep": 10736, "ep_reward": 414.93267822265625, "reward": 0.0012587308883666992, "action": -1.5116366147994995}
{"mode": "train", "epochs": 6, "timestep": 10737, "ep_reward": 415.046630859375, "reward": 0.11395233869552612, "action": -1.2020084857940674}
{"mode": "train", "epochs": 6, "timestep": 10738, "ep_reward": 415.2967529296875, "reward": 0.2501358389854431, "action": -0.512891411781311}
{"mode": "train", "epochs": 6, "timestep": 10739, "ep_reward": 415.6916198730469, "reward": 0.3948752284049988, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 10740, "ep_reward": 416.2027893066406, "reward": 0.5111832022666931, "action": -0.9388414621353149}
{"mode": "train", "epochs": 6, "timestep": 10741, "ep_reward": 416.8265380859375, "reward": 0.6237344741821289, "action": -0.9102505445480347}
{"mode": "train", "epochs": 6, "timestep": 10742, "ep_reward": 417.54022216796875, "reward": 0.7136791944503784, "action": -1.1328766345977783}
{"mode": "train", "epochs": 6, "timestep": 10743, "ep_reward": 418.3185729980469, "reward": 0.7783649563789368, "action": -0.5613007545471191}
{"mode": "train", "epochs": 6, "timestep": 10744, "ep_reward": 419.1454772949219, "reward": 0.8269147872924805, "action": -1.58993661403656}
{"mode": "train", "epochs": 6, "timestep": 10745, "ep_reward": 419.992919921875, "reward": 0.8474535942077637, "action": -0.2281970977783203}
{"mode": "train", "epochs": 6, "timestep": 10746, "ep_reward": 420.855224609375, "reward": 0.8623179197311401, "action": -0.649535596370697}
{"mode": "train", "epochs": 6, "timestep": 10747, "ep_reward": 421.7113952636719, "reward": 0.8561762571334839, "action": -0.5968968868255615}
{"mode": "train", "epochs": 6, "timestep": 10748, "ep_reward": 422.54327392578125, "reward": 0.8318833112716675, "action": -0.07792717218399048}
{"mode": "train", "epochs": 6, "timestep": 10749, "ep_reward": 423.3343200683594, "reward": 0.7910515666007996, "action": -0.4994773864746094}
{"mode": "train", "epochs": 6, "timestep": 10750, "ep_reward": 424.0541687011719, "reward": 0.719839870929718, "action": -0.807931661605835}
{"mode": "train", "epochs": 6, "timestep": 10751, "ep_reward": 424.6661376953125, "reward": 0.6119785308837891, "action": -1.2541987895965576}
{"mode": "train", "epochs": 6, "timestep": 10752, "ep_reward": 425.1244812011719, "reward": 0.4583290219306946, "action": -0.7950775623321533}
{"mode": "train", "epochs": 6, "timestep": 10753, "ep_reward": 425.444580078125, "reward": 0.32008469104766846, "action": -0.3467855453491211}
{"mode": "train", "epochs": 6, "timestep": 10754, "ep_reward": 425.64886474609375, "reward": 0.20428109169006348, "action": 0.07255017757415771}
{"mode": "train", "epochs": 6, "timestep": 10755, "ep_reward": 425.71722412109375, "reward": 0.06837213039398193, "action": -1.2598191499710083}
{"mode": "train", "epochs": 6, "timestep": 10756, "ep_reward": 425.7669677734375, "reward": 0.049756765365600586, "action": -1.0452207326889038}
{"mode": "train", "epochs": 6, "timestep": 10757, "ep_reward": 425.95489501953125, "reward": 0.1879206895828247, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 10758, "ep_reward": 426.27044677734375, "reward": 0.3155640959739685, "action": -1.7356386184692383}
{"mode": "train", "epochs": 6, "timestep": 10759, "ep_reward": 426.7140808105469, "reward": 0.4436337947845459, "action": -1.0000951290130615}
{"mode": "train", "epochs": 6, "timestep": 10760, "ep_reward": 427.2808837890625, "reward": 0.5667896270751953, "action": -0.20985853672027588}
{"mode": "train", "epochs": 6, "timestep": 10761, "ep_reward": 427.956787109375, "reward": 0.6759041547775269, "action": -0.9743890762329102}
{"mode": "train", "epochs": 6, "timestep": 10762, "ep_reward": 428.7080383300781, "reward": 0.7512627243995667, "action": 0.045018553733825684}
{"mode": "train", "epochs": 6, "timestep": 10763, "ep_reward": 429.5211181640625, "reward": 0.8130781054496765, "action": -0.6752539277076721}
{"mode": "train", "epochs": 6, "timestep": 10764, "ep_reward": 430.3682556152344, "reward": 0.8471466898918152, "action": -0.5543431043624878}
{"mode": "train", "epochs": 6, "timestep": 10765, "ep_reward": 431.232666015625, "reward": 0.8644042015075684, "action": -0.858452320098877}
{"mode": "train", "epochs": 6, "timestep": 10766, "ep_reward": 432.0948791503906, "reward": 0.8622273206710815, "action": -1.2969725131988525}
{"mode": "train", "epochs": 6, "timestep": 10767, "ep_reward": 432.9330139160156, "reward": 0.8381271362304688, "action": -0.8089330792427063}
{"mode": "train", "epochs": 6, "timestep": 10768, "ep_reward": 433.72967529296875, "reward": 0.7966758608818054, "action": -1.21549654006958}
{"mode": "train", "epochs": 6, "timestep": 10769, "ep_reward": 434.4533386230469, "reward": 0.7236602902412415, "action": -0.850090742111206}
{"mode": "train", "epochs": 6, "timestep": 10770, "ep_reward": 435.0736389160156, "reward": 0.620290994644165, "action": -1.0608296394348145}
{"mode": "train", "epochs": 6, "timestep": 10771, "ep_reward": 435.54742431640625, "reward": 0.4737943410873413, "action": -1.0017313957214355}
{"mode": "train", "epochs": 6, "timestep": 10772, "ep_reward": 435.8872985839844, "reward": 0.3398604393005371, "action": -0.9894073009490967}
{"mode": "train", "epochs": 6, "timestep": 10773, "ep_reward": 436.1151428222656, "reward": 0.2278391718864441, "action": -1.1899641752243042}
{"mode": "train", "epochs": 6, "timestep": 10774, "ep_reward": 436.2110290527344, "reward": 0.09587883949279785, "action": -0.9427570104598999}
{"mode": "train", "epochs": 6, "timestep": 10775, "ep_reward": 436.232177734375, "reward": 0.021149039268493652, "action": -0.10619872808456421}
{"mode": "train", "epochs": 6, "timestep": 10776, "ep_reward": 436.400146484375, "reward": 0.16796976327896118, "action": -1.4756035804748535}
{"mode": "train", "epochs": 6, "timestep": 10777, "ep_reward": 436.7010803222656, "reward": 0.30093997716903687, "action": -1.04727303981781}
{"mode": "train", "epochs": 6, "timestep": 10778, "ep_reward": 437.1378173828125, "reward": 0.4367450475692749, "action": -1.0656949281692505}
{"mode": "train", "epochs": 6, "timestep": 10779, "ep_reward": 437.69683837890625, "reward": 0.5590240359306335, "action": -1.6696414947509766}
{"mode": "train", "epochs": 6, "timestep": 10780, "ep_reward": 438.3517761230469, "reward": 0.654943585395813, "action": -1.8097847700119019}
{"mode": "train", "epochs": 6, "timestep": 10781, "ep_reward": 439.0799560546875, "reward": 0.7281930446624756, "action": -0.8209249973297119}
{"mode": "train", "epochs": 6, "timestep": 10782, "ep_reward": 439.869140625, "reward": 0.7891710996627808, "action": -0.4075579047203064}
{"mode": "train", "epochs": 6, "timestep": 10783, "ep_reward": 440.70111083984375, "reward": 0.8319693803787231, "action": -1.6699812412261963}
{"mode": "train", "epochs": 6, "timestep": 10784, "ep_reward": 441.5452880859375, "reward": 0.8441810607910156, "action": -0.5378917455673218}
{"mode": "train", "epochs": 6, "timestep": 10785, "ep_reward": 442.3931579589844, "reward": 0.8478671312332153, "action": -1.614323616027832}
{"mode": "train", "epochs": 6, "timestep": 10786, "ep_reward": 443.2148132324219, "reward": 0.8216583132743835, "action": -1.4554507732391357}
{"mode": "train", "epochs": 6, "timestep": 10787, "ep_reward": 443.9870300292969, "reward": 0.7722041606903076, "action": -1.241155743598938}
{"mode": "train", "epochs": 6, "timestep": 10788, "ep_reward": 444.68096923828125, "reward": 0.6939429044723511, "action": -1.2864370346069336}
{"mode": "train", "epochs": 6, "timestep": 10789, "ep_reward": 445.2575988769531, "reward": 0.5766414403915405, "action": -0.7531435489654541}
{"mode": "train", "epochs": 6, "timestep": 10790, "ep_reward": 445.6807556152344, "reward": 0.4231525659561157, "action": -0.43597936630249023}
{"mode": "train", "epochs": 6, "timestep": 10791, "ep_reward": 446.005126953125, "reward": 0.3243669867515564, "action": -1.4878900051116943}
{"mode": "train", "epochs": 6, "timestep": 10792, "ep_reward": 446.21466064453125, "reward": 0.20952165126800537, "action": -0.4092825651168823}
{"mode": "train", "epochs": 6, "timestep": 10793, "ep_reward": 446.2892150878906, "reward": 0.074554443359375, "action": -0.2826163172721863}
{"mode": "train", "epochs": 6, "timestep": 10794, "ep_reward": 446.3327941894531, "reward": 0.04356801509857178, "action": -0.6653358340263367}
{"mode": "train", "epochs": 6, "timestep": 10795, "ep_reward": 446.5169982910156, "reward": 0.18419039249420166, "action": -1.3159466981887817}
{"mode": "train", "epochs": 6, "timestep": 10796, "ep_reward": 446.837158203125, "reward": 0.3201615810394287, "action": -0.4191390872001648}
{"mode": "train", "epochs": 6, "timestep": 10797, "ep_reward": 447.2995910644531, "reward": 0.4624212384223938, "action": -1.1535120010375977}
{"mode": "train", "epochs": 6, "timestep": 10798, "ep_reward": 447.87957763671875, "reward": 0.5799843072891235, "action": -1.417757272720337}
{"mode": "train", "epochs": 6, "timestep": 10799, "ep_reward": 448.5542297363281, "reward": 0.6746576428413391, "action": -1.4533841609954834}
{"mode": "train", "epochs": 6, "timestep": 10800, "ep_reward": 449.3016052246094, "reward": 0.74737948179245, "action": -0.3498326539993286}
{"mode": "train", "epochs": 6, "timestep": 10801, "ep_reward": 450.1103210449219, "reward": 0.8087170720100403, "action": -1.0958131551742554}
{"mode": "train", "epochs": 6, "timestep": 10802, "ep_reward": 450.9531555175781, "reward": 0.8428478837013245, "action": -1.303816795349121}
{"mode": "train", "epochs": 6, "timestep": 10803, "ep_reward": 451.810791015625, "reward": 0.8576461672782898, "action": -1.2116820812225342}
{"mode": "train", "epochs": 6, "timestep": 10804, "ep_reward": 452.6669006347656, "reward": 0.8561018109321594, "action": -0.8808313608169556}
{"mode": "train", "epochs": 6, "timestep": 10805, "ep_reward": 453.50592041015625, "reward": 0.8390238881111145, "action": -0.6401134729385376}
{"mode": "train", "epochs": 6, "timestep": 10806, "ep_reward": 454.3087463378906, "reward": 0.8028292655944824, "action": -1.8104852437973022}
{"mode": "train", "epochs": 6, "timestep": 10807, "ep_reward": 455.0361022949219, "reward": 0.7273449897766113, "action": -1.312652826309204}
{"mode": "train", "epochs": 6, "timestep": 10808, "ep_reward": 455.65740966796875, "reward": 0.6212964057922363, "action": -0.34334713220596313}
{"mode": "train", "epochs": 6, "timestep": 10809, "ep_reward": 456.1451110839844, "reward": 0.48770707845687866, "action": -0.958621084690094}
{"mode": "train", "epochs": 6, "timestep": 10810, "ep_reward": 456.4963684082031, "reward": 0.3512486219406128, "action": -1.1324546337127686}
{"mode": "train", "epochs": 6, "timestep": 10811, "ep_reward": 456.7379455566406, "reward": 0.2415810227394104, "action": -0.5008382797241211}
{"mode": "train", "epochs": 6, "timestep": 10812, "ep_reward": 456.84979248046875, "reward": 0.11184030771255493, "action": -0.6323426961898804}
{"mode": "train", "epochs": 6, "timestep": 10813, "ep_reward": 456.8534240722656, "reward": 0.0036287307739257812, "action": -1.7167026996612549}
{"mode": "train", "epochs": 6, "timestep": 10814, "ep_reward": 457.00164794921875, "reward": 0.14821350574493408, "action": -0.6162557601928711}
{"mode": "train", "epochs": 6, "timestep": 10815, "ep_reward": 457.2941589355469, "reward": 0.29251110553741455, "action": -0.39837783575057983}
{"mode": "train", "epochs": 6, "timestep": 10816, "ep_reward": 457.7296142578125, "reward": 0.4354444742202759, "action": -1.699875831604004}
{"mode": "train", "epochs": 6, "timestep": 10817, "ep_reward": 458.2796936035156, "reward": 0.5500853657722473, "action": -0.6962169408798218}
{"mode": "train", "epochs": 6, "timestep": 10818, "ep_reward": 458.9378356933594, "reward": 0.6581506729125977, "action": -0.3774747848510742}
{"mode": "train", "epochs": 6, "timestep": 10819, "ep_reward": 459.6840515136719, "reward": 0.7462087869644165, "action": -0.053404033184051514}
{"mode": "train", "epochs": 6, "timestep": 10820, "ep_reward": 460.4979553222656, "reward": 0.8138980865478516, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 10821, "ep_reward": 461.34417724609375, "reward": 0.8462122082710266, "action": -1.1633208990097046}
{"mode": "train", "epochs": 6, "timestep": 10822, "ep_reward": 462.2138977050781, "reward": 0.8697159290313721, "action": -1.7650346755981445}
{"mode": "train", "epochs": 6, "timestep": 10823, "ep_reward": 463.0873718261719, "reward": 0.8734626770019531, "action": -1.3606102466583252}
{"mode": "train", "epochs": 6, "timestep": 10824, "ep_reward": 463.9521484375, "reward": 0.8647688031196594, "action": -1.2447242736816406}
{"mode": "train", "epochs": 6, "timestep": 10825, "ep_reward": 464.7911682128906, "reward": 0.8390234708786011, "action": -1.0256867408752441}
{"mode": "train", "epochs": 6, "timestep": 10826, "ep_reward": 465.5844421386719, "reward": 0.7932817339897156, "action": -0.7606890201568604}
{"mode": "train", "epochs": 6, "timestep": 10827, "ep_reward": 466.30731201171875, "reward": 0.7228761911392212, "action": -1.2866299152374268}
{"mode": "train", "epochs": 6, "timestep": 10828, "ep_reward": 466.91912841796875, "reward": 0.6118215322494507, "action": -1.1579675674438477}
{"mode": "train", "epochs": 6, "timestep": 10829, "ep_reward": 467.37982177734375, "reward": 0.4606972336769104, "action": -1.3567134141921997}
{"mode": "train", "epochs": 6, "timestep": 10830, "ep_reward": 467.7110290527344, "reward": 0.33120518922805786, "action": -1.4074636697769165}
{"mode": "train", "epochs": 6, "timestep": 10831, "ep_reward": 467.9284362792969, "reward": 0.21741396188735962, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 10832, "ep_reward": 468.0124206542969, "reward": 0.08399105072021484, "action": -0.36765390634536743}
{"mode": "train", "epochs": 6, "timestep": 10833, "ep_reward": 468.0460510253906, "reward": 0.03362482786178589, "action": -1.648262619972229}
{"mode": "train", "epochs": 6, "timestep": 10834, "ep_reward": 468.2203369140625, "reward": 0.1742849349975586, "action": -0.1290941834449768}
{"mode": "train", "epochs": 6, "timestep": 10835, "ep_reward": 468.5453186035156, "reward": 0.32497721910476685, "action": -1.0885082483291626}
{"mode": "train", "epochs": 6, "timestep": 10836, "ep_reward": 469.0024719238281, "reward": 0.4571577310562134, "action": -1.2825984954833984}
{"mode": "train", "epochs": 6, "timestep": 10837, "ep_reward": 469.5763244628906, "reward": 0.5738527178764343, "action": -0.3677406907081604}
{"mode": "train", "epochs": 6, "timestep": 10838, "ep_reward": 470.25689697265625, "reward": 0.6805580854415894, "action": -1.1961612701416016}
{"mode": "train", "epochs": 6, "timestep": 10839, "ep_reward": 471.0126647949219, "reward": 0.7557559013366699, "action": -1.5983622074127197}
{"mode": "train", "epochs": 6, "timestep": 10840, "ep_reward": 471.8197326660156, "reward": 0.8070583343505859, "action": -1.0897142887115479}
{"mode": "train", "epochs": 6, "timestep": 10841, "ep_reward": 472.66412353515625, "reward": 0.8443912863731384, "action": -1.4608354568481445}
{"mode": "train", "epochs": 6, "timestep": 10842, "ep_reward": 473.5257263183594, "reward": 0.8616060614585876, "action": -1.6120280027389526}
{"mode": "train", "epochs": 6, "timestep": 10843, "ep_reward": 474.3871154785156, "reward": 0.8613758087158203, "action": -0.21593141555786133}
{"mode": "train", "epochs": 6, "timestep": 10844, "ep_reward": 475.2430725097656, "reward": 0.8559572696685791, "action": -0.8798469305038452}
{"mode": "train", "epochs": 6, "timestep": 10845, "ep_reward": 476.0687561035156, "reward": 0.8256747126579285, "action": -1.0456656217575073}
{"mode": "train", "epochs": 6, "timestep": 10846, "ep_reward": 476.8388671875, "reward": 0.7701013088226318, "action": -1.21073317527771}
{"mode": "train", "epochs": 6, "timestep": 10847, "ep_reward": 477.52099609375, "reward": 0.6821233034133911, "action": -1.3035722970962524}
{"mode": "train", "epochs": 6, "timestep": 10848, "ep_reward": 478.07562255859375, "reward": 0.5546362400054932, "action": -0.5181825160980225}
{"mode": "train", "epochs": 6, "timestep": 10849, "ep_reward": 478.47198486328125, "reward": 0.3963490128517151, "action": -0.3400411009788513}
{"mode": "train", "epochs": 6, "timestep": 10850, "ep_reward": 478.7604064941406, "reward": 0.2884247899055481, "action": -1.2905693054199219}
{"mode": "train", "epochs": 6, "timestep": 10851, "ep_reward": 478.9272155761719, "reward": 0.16682308912277222, "action": -1.1906013488769531}
{"mode": "train", "epochs": 6, "timestep": 10852, "ep_reward": 478.952392578125, "reward": 0.025173425674438477, "action": -1.3953359127044678}
{"mode": "train", "epochs": 6, "timestep": 10853, "ep_reward": 479.04443359375, "reward": 0.09204083681106567, "action": -0.41583073139190674}
{"mode": "train", "epochs": 6, "timestep": 10854, "ep_reward": 479.28179931640625, "reward": 0.2373577356338501, "action": -0.41921377182006836}
{"mode": "train", "epochs": 6, "timestep": 10855, "ep_reward": 479.6639099121094, "reward": 0.3820984363555908, "action": -1.358696699142456}
{"mode": "train", "epochs": 6, "timestep": 10856, "ep_reward": 480.1700744628906, "reward": 0.5061607360839844, "action": -0.2438792586326599}
{"mode": "train", "epochs": 6, "timestep": 10857, "ep_reward": 480.796630859375, "reward": 0.6265530586242676, "action": -0.25832056999206543}
{"mode": "train", "epochs": 6, "timestep": 10858, "ep_reward": 481.52001953125, "reward": 0.7234015464782715, "action": -1.1086230278015137}
{"mode": "train", "epochs": 6, "timestep": 10859, "ep_reward": 482.3099365234375, "reward": 0.7899102568626404, "action": -1.4831688404083252}
{"mode": "train", "epochs": 6, "timestep": 10860, "ep_reward": 483.1446228027344, "reward": 0.8346753716468811, "action": -1.4044067859649658}
{"mode": "train", "epochs": 6, "timestep": 10861, "ep_reward": 484.0086975097656, "reward": 0.8640652298927307, "action": -0.046926021575927734}
{"mode": "train", "epochs": 6, "timestep": 10862, "ep_reward": 484.89776611328125, "reward": 0.889076828956604, "action": -0.8763314485549927}
{"mode": "train", "epochs": 6, "timestep": 10863, "ep_reward": 485.7917785644531, "reward": 0.8940023183822632, "action": -1.293242335319519}
{"mode": "train", "epochs": 6, "timestep": 10864, "ep_reward": 486.6739501953125, "reward": 0.8821797370910645, "action": -1.3065783977508545}
{"mode": "train", "epochs": 6, "timestep": 10865, "ep_reward": 487.5280456542969, "reward": 0.8541048169136047, "action": -0.9916701316833496}
{"mode": "train", "epochs": 6, "timestep": 10866, "ep_reward": 488.33648681640625, "reward": 0.8084472417831421, "action": -1.010542869567871}
{"mode": "train", "epochs": 6, "timestep": 10867, "ep_reward": 489.0730895996094, "reward": 0.7366077899932861, "action": -1.532211184501648}
{"mode": "train", "epochs": 6, "timestep": 10868, "ep_reward": 489.6980285644531, "reward": 0.6249356865882874, "action": -1.655606985092163}
{"mode": "train", "epochs": 6, "timestep": 10869, "ep_reward": 490.16748046875, "reward": 0.4694565534591675, "action": -1.0481034517288208}
{"mode": "train", "epochs": 6, "timestep": 10870, "ep_reward": 490.4985046386719, "reward": 0.33100950717926025, "action": -1.4981591701507568}
{"mode": "train", "epochs": 6, "timestep": 10871, "ep_reward": 490.7158203125, "reward": 0.21732330322265625, "action": -1.4244608879089355}
{"mode": "train", "epochs": 6, "timestep": 10872, "ep_reward": 490.799560546875, "reward": 0.08374768495559692, "action": -0.2323148250579834}
{"mode": "train", "epochs": 6, "timestep": 10873, "ep_reward": 490.8335266113281, "reward": 0.03396439552307129, "action": -1.2022507190704346}
{"mode": "train", "epochs": 6, "timestep": 10874, "ep_reward": 491.0080261230469, "reward": 0.17448753118515015, "action": -0.6186307668685913}
{"mode": "train", "epochs": 6, "timestep": 10875, "ep_reward": 491.3271789550781, "reward": 0.31914955377578735, "action": -1.3040366172790527}
{"mode": "train", "epochs": 6, "timestep": 10876, "ep_reward": 491.7771911621094, "reward": 0.44999921321868896, "action": -1.2549371719360352}
{"mode": "train", "epochs": 6, "timestep": 10877, "ep_reward": 492.34552001953125, "reward": 0.5683343410491943, "action": -1.2396290302276611}
{"mode": "train", "epochs": 6, "timestep": 10878, "ep_reward": 493.0126037597656, "reward": 0.6670845746994019, "action": -1.0882624387741089}
{"mode": "train", "epochs": 6, "timestep": 10879, "ep_reward": 493.757568359375, "reward": 0.7449660301208496, "action": -0.7891536951065063}
{"mode": "train", "epochs": 6, "timestep": 10880, "ep_reward": 494.56085205078125, "reward": 0.8032740354537964, "action": -1.7210891246795654}
{"mode": "train", "epochs": 6, "timestep": 10881, "ep_reward": 495.39410400390625, "reward": 0.8332410454750061, "action": -0.9535799622535706}
{"mode": "train", "epochs": 6, "timestep": 10882, "ep_reward": 496.2459716796875, "reward": 0.851865291595459, "action": -1.006585717201233}
{"mode": "train", "epochs": 6, "timestep": 10883, "ep_reward": 497.0979919433594, "reward": 0.8520088195800781, "action": -1.3582707643508911}
{"mode": "train", "epochs": 6, "timestep": 10884, "ep_reward": 497.927734375, "reward": 0.8297505974769592, "action": -0.7374941110610962}
{"mode": "train", "epochs": 6, "timestep": 10885, "ep_reward": 498.7184143066406, "reward": 0.790681004524231, "action": -1.0460283756256104}
{"mode": "train", "epochs": 6, "timestep": 10886, "ep_reward": 499.43902587890625, "reward": 0.7206031084060669, "action": -0.6145281791687012}
{"mode": "train", "epochs": 6, "timestep": 10887, "ep_reward": 500.060302734375, "reward": 0.6212868094444275, "action": -0.3209155797958374}
{"mode": "train", "epochs": 6, "timestep": 10888, "ep_reward": 500.5476379394531, "reward": 0.48733043670654297, "action": -0.7705295085906982}
{"mode": "train", "epochs": 6, "timestep": 10889, "ep_reward": 500.8943786621094, "reward": 0.3467440605163574, "action": -1.3099844455718994}
{"mode": "train", "epochs": 6, "timestep": 10890, "ep_reward": 501.13055419921875, "reward": 0.23618626594543457, "action": -0.7909162044525146}
{"mode": "train", "epochs": 6, "timestep": 10891, "ep_reward": 501.2361145019531, "reward": 0.10556906461715698, "action": -0.7042497992515564}
{"mode": "train", "epochs": 6, "timestep": 10892, "ep_reward": 501.2467346191406, "reward": 0.010606229305267334, "action": -1.1906468868255615}
{"mode": "train", "epochs": 6, "timestep": 10893, "ep_reward": 501.4009094238281, "reward": 0.15417742729187012, "action": -0.8747327327728271}
{"mode": "train", "epochs": 6, "timestep": 10894, "ep_reward": 501.6962585449219, "reward": 0.29534435272216797, "action": -1.1228653192520142}
{"mode": "train", "epochs": 6, "timestep": 10895, "ep_reward": 502.1264953613281, "reward": 0.4302281141281128, "action": -0.1890120506286621}
{"mode": "train", "epochs": 6, "timestep": 10896, "ep_reward": 502.6894226074219, "reward": 0.5629388093948364, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 10897, "ep_reward": 503.34466552734375, "reward": 0.6552320718765259, "action": 0.03554034233093262}
{"mode": "train", "epochs": 6, "timestep": 10898, "ep_reward": 504.0917663574219, "reward": 0.7470886707305908, "action": -1.8293118476867676}
{"mode": "train", "epochs": 6, "timestep": 10899, "ep_reward": 504.8903503417969, "reward": 0.7985873222351074, "action": -0.5478295087814331}
{"mode": "train", "epochs": 6, "timestep": 10900, "ep_reward": 505.73272705078125, "reward": 0.842389702796936, "action": -1.922046422958374}
{"mode": "train", "epochs": 6, "timestep": 10901, "ep_reward": 506.5899353027344, "reward": 0.8572164177894592, "action": -0.6107561588287354}
{"mode": "train", "epochs": 6, "timestep": 10902, "ep_reward": 507.45654296875, "reward": 0.8666166067123413, "action": -1.3374714851379395}
{"mode": "train", "epochs": 6, "timestep": 10903, "ep_reward": 508.309326171875, "reward": 0.8527778387069702, "action": -1.188543677330017}
{"mode": "train", "epochs": 6, "timestep": 10904, "ep_reward": 509.1297912597656, "reward": 0.8204526901245117, "action": -0.48480725288391113}
{"mode": "train", "epochs": 6, "timestep": 10905, "ep_reward": 509.90087890625, "reward": 0.7711000442504883, "action": -1.3283613920211792}
{"mode": "train", "epochs": 6, "timestep": 10906, "ep_reward": 510.58355712890625, "reward": 0.6826723217964172, "action": -1.1944692134857178}
{"mode": "train", "epochs": 6, "timestep": 10907, "ep_reward": 511.14093017578125, "reward": 0.5573769807815552, "action": -1.1098332405090332}
{"mode": "train", "epochs": 6, "timestep": 10908, "ep_reward": 511.5330810546875, "reward": 0.3921552300453186, "action": -0.6438348293304443}
{"mode": "train", "epochs": 6, "timestep": 10909, "ep_reward": 511.8240966796875, "reward": 0.2910084128379822, "action": -0.038724541664123535}
{"mode": "train", "epochs": 6, "timestep": 10910, "ep_reward": 511.993896484375, "reward": 0.1698061227798462, "action": -0.6971092224121094}
{"mode": "train", "epochs": 6, "timestep": 10911, "ep_reward": 512.0224609375, "reward": 0.0285605788230896, "action": -1.2938437461853027}
{"mode": "train", "epochs": 6, "timestep": 10912, "ep_reward": 512.111328125, "reward": 0.08885228633880615, "action": -0.585677981376648}
{"mode": "train", "epochs": 6, "timestep": 10913, "ep_reward": 512.34326171875, "reward": 0.2319352626800537, "action": -0.8838883638381958}
{"mode": "train", "epochs": 6, "timestep": 10914, "ep_reward": 512.7150268554688, "reward": 0.37174755334854126, "action": -0.6969257593154907}
{"mode": "train", "epochs": 6, "timestep": 10915, "ep_reward": 513.2201538085938, "reward": 0.5051535367965698, "action": -0.37422269582748413}
{"mode": "train", "epochs": 6, "timestep": 10916, "ep_reward": 513.844482421875, "reward": 0.6243358850479126, "action": -0.7407236099243164}
{"mode": "train", "epochs": 6, "timestep": 10917, "ep_reward": 514.5615844726562, "reward": 0.7171194553375244, "action": 0.67978835105896}
{"mode": "train", "epochs": 6, "timestep": 10918, "ep_reward": 515.361572265625, "reward": 0.7999586462974548, "action": -1.2718265056610107}
{"mode": "train", "epochs": 6, "timestep": 10919, "ep_reward": 516.2067260742188, "reward": 0.8451387286186218, "action": -1.1477134227752686}
{"mode": "train", "epochs": 6, "timestep": 10920, "ep_reward": 517.082763671875, "reward": 0.8760132193565369, "action": -0.35702580213546753}
{"mode": "train", "epochs": 6, "timestep": 10921, "ep_reward": 517.9817504882812, "reward": 0.8989971280097961, "action": -0.8637559413909912}
{"mode": "train", "epochs": 6, "timestep": 10922, "ep_reward": 518.887939453125, "reward": 0.9061833620071411, "action": 0.03543740510940552}
{"mode": "train", "epochs": 6, "timestep": 10923, "ep_reward": 519.7962036132812, "reward": 0.9082523584365845, "action": -0.3015281558036804}
{"mode": "train", "epochs": 6, "timestep": 10924, "ep_reward": 520.6923828125, "reward": 0.8961571455001831, "action": -0.5988532304763794}
{"mode": "train", "epochs": 6, "timestep": 10925, "ep_reward": 521.5603637695312, "reward": 0.8679873943328857, "action": -1.1003717184066772}
{"mode": "train", "epochs": 6, "timestep": 10926, "ep_reward": 522.377685546875, "reward": 0.817308783531189, "action": 0.3258335590362549}
{"mode": "train", "epochs": 6, "timestep": 10927, "ep_reward": 523.1348266601562, "reward": 0.7571444511413574, "action": -1.2281432151794434}
{"mode": "train", "epochs": 6, "timestep": 10928, "ep_reward": 523.7870483398438, "reward": 0.6522114276885986, "action": -1.0776208639144897}
{"mode": "train", "epochs": 6, "timestep": 10929, "ep_reward": 524.2992553710938, "reward": 0.5121864676475525, "action": -0.7540467977523804}
{"mode": "train", "epochs": 6, "timestep": 10930, "ep_reward": 524.6382446289062, "reward": 0.3389660716056824, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 10931, "ep_reward": 524.8504638671875, "reward": 0.2122461199760437, "action": -1.7355716228485107}
{"mode": "train", "epochs": 6, "timestep": 10932, "ep_reward": 524.9282836914062, "reward": 0.07780319452285767, "action": -1.4072506427764893}
{"mode": "train", "epochs": 6, "timestep": 10933, "ep_reward": 524.9683837890625, "reward": 0.04009002447128296, "action": -0.6845682859420776}
{"mode": "train", "epochs": 6, "timestep": 10934, "ep_reward": 525.1488037109375, "reward": 0.18042081594467163, "action": -0.9253446459770203}
{"mode": "train", "epochs": 6, "timestep": 10935, "ep_reward": 525.4700927734375, "reward": 0.3213140368461609, "action": -0.7680816054344177}
{"mode": "train", "epochs": 6, "timestep": 10936, "ep_reward": 525.928955078125, "reward": 0.45887869596481323, "action": -0.13388586044311523}
{"mode": "train", "epochs": 6, "timestep": 10937, "ep_reward": 526.5169067382812, "reward": 0.5879613161087036, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 10938, "ep_reward": 527.1925659179688, "reward": 0.6756543517112732, "action": -0.8795679807662964}
{"mode": "train", "epochs": 6, "timestep": 10939, "ep_reward": 527.9467163085938, "reward": 0.7541670203208923, "action": -1.0707060098648071}
{"mode": "train", "epochs": 6, "timestep": 10940, "ep_reward": 528.7560424804688, "reward": 0.8093005418777466, "action": -0.1429646611213684}
{"mode": "train", "epochs": 6, "timestep": 10941, "ep_reward": 529.6090087890625, "reward": 0.8529698252677917, "action": -1.0556901693344116}
{"mode": "train", "epochs": 6, "timestep": 10942, "ep_reward": 530.48095703125, "reward": 0.8719301223754883, "action": -0.6323748826980591}
{"mode": "train", "epochs": 6, "timestep": 10943, "ep_reward": 531.360107421875, "reward": 0.8791326284408569, "action": -0.4242877960205078}
{"mode": "train", "epochs": 6, "timestep": 10944, "ep_reward": 532.2327880859375, "reward": 0.8727036714553833, "action": -1.6960644721984863}
{"mode": "train", "epochs": 6, "timestep": 10945, "ep_reward": 533.0709838867188, "reward": 0.8381974697113037, "action": -1.0610915422439575}
{"mode": "train", "epochs": 6, "timestep": 10946, "ep_reward": 533.857666015625, "reward": 0.78668612241745, "action": -1.0058538913726807}
{"mode": "train", "epochs": 6, "timestep": 10947, "ep_reward": 534.56494140625, "reward": 0.7072575092315674, "action": -1.2546602487564087}
{"mode": "train", "epochs": 6, "timestep": 10948, "ep_reward": 535.1539916992188, "reward": 0.5890301465988159, "action": -0.8311975598335266}
{"mode": "train", "epochs": 6, "timestep": 10949, "ep_reward": 535.58935546875, "reward": 0.43538832664489746, "action": -0.40582454204559326}
{"mode": "train", "epochs": 6, "timestep": 10950, "ep_reward": 535.8981323242188, "reward": 0.30877685546875, "action": -1.2023978233337402}
{"mode": "train", "epochs": 6, "timestep": 10951, "ep_reward": 536.0888671875, "reward": 0.1907406449317932, "action": -1.855277419090271}
{"mode": "train", "epochs": 6, "timestep": 10952, "ep_reward": 536.1419067382812, "reward": 0.05303025245666504, "action": -0.4841530919075012}
{"mode": "train", "epochs": 6, "timestep": 10953, "ep_reward": 536.2071533203125, "reward": 0.06525349617004395, "action": -0.8352863788604736}
{"mode": "train", "epochs": 6, "timestep": 10954, "ep_reward": 536.41162109375, "reward": 0.2044689655303955, "action": -1.205406904220581}
{"mode": "train", "epochs": 6, "timestep": 10955, "ep_reward": 536.7532958984375, "reward": 0.34169673919677734, "action": -0.7762771248817444}
{"mode": "train", "epochs": 6, "timestep": 10956, "ep_reward": 537.2311401367188, "reward": 0.47783929109573364, "action": -1.2149372100830078}
{"mode": "train", "epochs": 6, "timestep": 10957, "ep_reward": 537.8237915039062, "reward": 0.5926685333251953, "action": -0.8367182612419128}
{"mode": "train", "epochs": 6, "timestep": 10958, "ep_reward": 538.514404296875, "reward": 0.6906321048736572, "action": -0.416533887386322}
{"mode": "train", "epochs": 6, "timestep": 10959, "ep_reward": 539.2835693359375, "reward": 0.7691794633865356, "action": -1.0607273578643799}
{"mode": "train", "epochs": 6, "timestep": 10960, "ep_reward": 540.1033935546875, "reward": 0.819807767868042, "action": -0.77269047498703}
{"mode": "train", "epochs": 6, "timestep": 10961, "ep_reward": 540.9576416015625, "reward": 0.8542431592941284, "action": -1.1962013244628906}
{"mode": "train", "epochs": 6, "timestep": 10962, "ep_reward": 541.826171875, "reward": 0.8685563802719116, "action": -0.8699328899383545}
{"mode": "train", "epochs": 6, "timestep": 10963, "ep_reward": 542.6958618164062, "reward": 0.8696638345718384, "action": -1.3602659702301025}
{"mode": "train", "epochs": 6, "timestep": 10964, "ep_reward": 543.5455322265625, "reward": 0.8496572375297546, "action": -0.8021277189254761}
{"mode": "train", "epochs": 6, "timestep": 10965, "ep_reward": 544.3599853515625, "reward": 0.8144687414169312, "action": -0.14041966199874878}
{"mode": "train", "epochs": 6, "timestep": 10966, "ep_reward": 545.1220092773438, "reward": 0.7620400190353394, "action": -0.488545298576355}
{"mode": "train", "epochs": 6, "timestep": 10967, "ep_reward": 545.799072265625, "reward": 0.6770407557487488, "action": -1.2818522453308105}
{"mode": "train", "epochs": 6, "timestep": 10968, "ep_reward": 546.3448486328125, "reward": 0.5457751154899597, "action": -0.12419623136520386}
{"mode": "train", "epochs": 6, "timestep": 10969, "ep_reward": 546.7357177734375, "reward": 0.39089536666870117, "action": -1.0779858827590942}
{"mode": "train", "epochs": 6, "timestep": 10970, "ep_reward": 547.0067138671875, "reward": 0.2710195779800415, "action": 0.003234386444091797}
{"mode": "train", "epochs": 6, "timestep": 10971, "ep_reward": 547.1530151367188, "reward": 0.1462884545326233, "action": -0.5583878755569458}
{"mode": "train", "epochs": 6, "timestep": 10972, "ep_reward": 547.1546020507812, "reward": 0.0015723109245300293, "action": -0.6288182139396667}
{"mode": "train", "epochs": 6, "timestep": 10973, "ep_reward": 547.2683715820312, "reward": 0.11375844478607178, "action": -1.314382791519165}
{"mode": "train", "epochs": 6, "timestep": 10974, "ep_reward": 547.5166625976562, "reward": 0.24830645322799683, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 10975, "ep_reward": 547.8919677734375, "reward": 0.3753301501274109, "action": -1.1045136451721191}
{"mode": "train", "epochs": 6, "timestep": 10976, "ep_reward": 548.397705078125, "reward": 0.5057103633880615, "action": -0.5966660976409912}
{"mode": "train", "epochs": 6, "timestep": 10977, "ep_reward": 549.0206298828125, "reward": 0.6229445934295654, "action": -1.349888563156128}
{"mode": "train", "epochs": 6, "timestep": 10978, "ep_reward": 549.728759765625, "reward": 0.7081320285797119, "action": -1.1161274909973145}
{"mode": "train", "epochs": 6, "timestep": 10979, "ep_reward": 550.50146484375, "reward": 0.772689163684845, "action": -0.7994349002838135}
{"mode": "train", "epochs": 6, "timestep": 10980, "ep_reward": 551.319580078125, "reward": 0.818092942237854, "action": -1.3991230726242065}
{"mode": "train", "epochs": 6, "timestep": 10981, "ep_reward": 552.1575927734375, "reward": 0.8379834890365601, "action": -0.588977575302124}
{"mode": "train", "epochs": 6, "timestep": 10982, "ep_reward": 553.0037841796875, "reward": 0.8461645245552063, "action": -0.9734225273132324}
{"mode": "train", "epochs": 6, "timestep": 10983, "ep_reward": 553.8349609375, "reward": 0.8311932682991028, "action": -1.0301916599273682}
{"mode": "train", "epochs": 6, "timestep": 10984, "ep_reward": 554.6281127929688, "reward": 0.7931416034698486, "action": -1.2248384952545166}
{"mode": "train", "epochs": 6, "timestep": 10985, "ep_reward": 555.3530883789062, "reward": 0.7249575257301331, "action": -1.2686164379119873}
{"mode": "train", "epochs": 6, "timestep": 10986, "ep_reward": 555.9736938476562, "reward": 0.6205811500549316, "action": -0.9618620872497559}
{"mode": "train", "epochs": 6, "timestep": 10987, "ep_reward": 556.4517211914062, "reward": 0.47804689407348633, "action": -1.4934087991714478}
{"mode": "train", "epochs": 6, "timestep": 10988, "ep_reward": 556.8072509765625, "reward": 0.35555654764175415, "action": -0.7996031641960144}
{"mode": "train", "epochs": 6, "timestep": 10989, "ep_reward": 557.053955078125, "reward": 0.2467058300971985, "action": -0.5378947854042053}
{"mode": "train", "epochs": 6, "timestep": 10990, "ep_reward": 557.1717529296875, "reward": 0.11778903007507324, "action": -1.0035587549209595}
{"mode": "train", "epochs": 6, "timestep": 10991, "ep_reward": 557.1688232421875, "reward": -0.0029081106185913086, "action": -1.0265812873840332}
{"mode": "train", "epochs": 6, "timestep": 10992, "ep_reward": 557.3111572265625, "reward": 0.1423080563545227, "action": -1.461482048034668}
{"mode": "train", "epochs": 6, "timestep": 10993, "ep_reward": 557.5870971679688, "reward": 0.2759379744529724, "action": -1.0771236419677734}
{"mode": "train", "epochs": 6, "timestep": 10994, "ep_reward": 558.0005493164062, "reward": 0.4134269952774048, "action": -0.671880304813385}
{"mode": "train", "epochs": 6, "timestep": 10995, "ep_reward": 558.544189453125, "reward": 0.5436255931854248, "action": -0.5744494199752808}
{"mode": "train", "epochs": 6, "timestep": 10996, "ep_reward": 559.1983642578125, "reward": 0.6541775465011597, "action": 0.20969617366790771}
{"mode": "train", "epochs": 6, "timestep": 10997, "ep_reward": 559.9467163085938, "reward": 0.7483251094818115, "action": -0.47979533672332764}
{"mode": "train", "epochs": 6, "timestep": 10998, "ep_reward": 560.7586059570312, "reward": 0.8119117021560669, "action": -1.0958396196365356}
{"mode": "train", "epochs": 6, "timestep": 10999, "ep_reward": 561.609619140625, "reward": 0.8510304093360901, "action": -1.5817145109176636}
{"mode": "train", "epochs": 6, "timestep": 11000, "ep_reward": 562.480224609375, "reward": 0.870576024055481, "action": 0.5212279558181763}
{"mode": "train", "epochs": 6, "timestep": 11001, "ep_reward": 563.3721923828125, "reward": 0.8919884562492371, "action": -0.7691113948822021}
{"mode": "train", "epochs": 6, "timestep": 11002, "ep_reward": 564.2617797851562, "reward": 0.8895570635795593, "action": 0.3545573353767395}
{"mode": "train", "epochs": 6, "timestep": 11003, "ep_reward": 565.1439208984375, "reward": 0.8821461796760559, "action": -0.4537232518196106}
{"mode": "train", "epochs": 6, "timestep": 11004, "ep_reward": 565.996826171875, "reward": 0.8529238700866699, "action": -1.2853697538375854}
{"mode": "train", "epochs": 6, "timestep": 11005, "ep_reward": 566.7928466796875, "reward": 0.7960425615310669, "action": -1.209754467010498}
{"mode": "train", "epochs": 6, "timestep": 11006, "ep_reward": 567.5047607421875, "reward": 0.7119218111038208, "action": -1.2165168523788452}
{"mode": "train", "epochs": 6, "timestep": 11007, "ep_reward": 568.0973510742188, "reward": 0.5926091074943542, "action": -1.1150633096694946}
{"mode": "train", "epochs": 6, "timestep": 11008, "ep_reward": 568.5318603515625, "reward": 0.43450701236724854, "action": -0.4784896969795227}
{"mode": "train", "epochs": 6, "timestep": 11009, "ep_reward": 568.8260498046875, "reward": 0.2941780686378479, "action": -1.779537320137024}
{"mode": "train", "epochs": 6, "timestep": 11010, "ep_reward": 568.9998168945312, "reward": 0.1737905740737915, "action": -0.5783805251121521}
{"mode": "train", "epochs": 6, "timestep": 11011, "ep_reward": 569.0328979492188, "reward": 0.03310137987136841, "action": -1.5293748378753662}
{"mode": "train", "epochs": 6, "timestep": 11012, "ep_reward": 569.1172485351562, "reward": 0.08436417579650879, "action": -1.5865986347198486}
{"mode": "train", "epochs": 6, "timestep": 11013, "ep_reward": 569.3353271484375, "reward": 0.2181043028831482, "action": -0.3797574043273926}
{"mode": "train", "epochs": 6, "timestep": 11014, "ep_reward": 569.7014770507812, "reward": 0.36612004041671753, "action": -1.2020779848098755}
{"mode": "train", "epochs": 6, "timestep": 11015, "ep_reward": 570.196044921875, "reward": 0.49458813667297363, "action": -0.8416173458099365}
{"mode": "train", "epochs": 6, "timestep": 11016, "ep_reward": 570.8067016601562, "reward": 0.6106430292129517, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 11017, "ep_reward": 571.4996948242188, "reward": 0.6930134296417236, "action": -1.9783973693847656}
{"mode": "train", "epochs": 6, "timestep": 11018, "ep_reward": 572.2547607421875, "reward": 0.7550716996192932, "action": -0.7137102484703064}
{"mode": "train", "epochs": 6, "timestep": 11019, "ep_reward": 573.0628662109375, "reward": 0.8080791234970093, "action": -0.11555284261703491}
{"mode": "train", "epochs": 6, "timestep": 11020, "ep_reward": 573.9083862304688, "reward": 0.8455371260643005, "action": -0.003592371940612793}
{"mode": "train", "epochs": 6, "timestep": 11021, "ep_reward": 574.7733764648438, "reward": 0.8649899959564209, "action": -1.8577922582626343}
{"mode": "train", "epochs": 6, "timestep": 11022, "ep_reward": 575.6246948242188, "reward": 0.8512899875640869, "action": -1.0178667306900024}
{"mode": "train", "epochs": 6, "timestep": 11023, "ep_reward": 576.4500732421875, "reward": 0.8253570199012756, "action": -0.18112969398498535}
{"mode": "train", "epochs": 6, "timestep": 11024, "ep_reward": 577.2349243164062, "reward": 0.7848377823829651, "action": -1.0820508003234863}
{"mode": "train", "epochs": 6, "timestep": 11025, "ep_reward": 577.94189453125, "reward": 0.706968367099762, "action": -1.0756915807724}
{"mode": "train", "epochs": 6, "timestep": 11026, "ep_reward": 578.5350341796875, "reward": 0.593167781829834, "action": -0.5134172439575195}
{"mode": "train", "epochs": 6, "timestep": 11027, "ep_reward": 578.9813842773438, "reward": 0.4463679790496826, "action": -1.6457905769348145}
{"mode": "train", "epochs": 6, "timestep": 11028, "ep_reward": 579.30078125, "reward": 0.3194255232810974, "action": -1.104580283164978}
{"mode": "train", "epochs": 6, "timestep": 11029, "ep_reward": 579.5043334960938, "reward": 0.2035311460494995, "action": -0.8800655007362366}
{"mode": "train", "epochs": 6, "timestep": 11030, "ep_reward": 579.5719604492188, "reward": 0.06760233640670776, "action": -0.9434170722961426}
{"mode": "train", "epochs": 6, "timestep": 11031, "ep_reward": 579.6226196289062, "reward": 0.050642967224121094, "action": -0.38044220209121704}
{"mode": "train", "epochs": 6, "timestep": 11032, "ep_reward": 579.8177490234375, "reward": 0.19510138034820557, "action": -0.7628490924835205}
{"mode": "train", "epochs": 6, "timestep": 11033, "ep_reward": 580.1547241210938, "reward": 0.33697235584259033, "action": -0.4843941926956177}
{"mode": "train", "epochs": 6, "timestep": 11034, "ep_reward": 580.6303100585938, "reward": 0.475583553314209, "action": -1.5291528701782227}
{"mode": "train", "epochs": 6, "timestep": 11035, "ep_reward": 581.2169799804688, "reward": 0.5866813063621521, "action": -1.6522363424301147}
{"mode": "train", "epochs": 6, "timestep": 11036, "ep_reward": 581.8949584960938, "reward": 0.6780015230178833, "action": -0.17449462413787842}
{"mode": "train", "epochs": 6, "timestep": 11037, "ep_reward": 582.6572875976562, "reward": 0.7623590230941772, "action": -0.9277840852737427}
{"mode": "train", "epochs": 6, "timestep": 11038, "ep_reward": 583.4744873046875, "reward": 0.8171749114990234, "action": -0.5200977325439453}
{"mode": "train", "epochs": 6, "timestep": 11039, "ep_reward": 584.3310546875, "reward": 0.8565682172775269, "action": -1.3690850734710693}
{"mode": "train", "epochs": 6, "timestep": 11040, "ep_reward": 585.2037353515625, "reward": 0.8726528882980347, "action": -1.873220443725586}
{"mode": "train", "epochs": 6, "timestep": 11041, "ep_reward": 586.073486328125, "reward": 0.8697338104248047, "action": 0.17676669359207153}
{"mode": "train", "epochs": 6, "timestep": 11042, "ep_reward": 586.9413452148438, "reward": 0.8678656816482544, "action": -0.7312139868736267}
{"mode": "train", "epochs": 6, "timestep": 11043, "ep_reward": 587.7823486328125, "reward": 0.8410089015960693, "action": -0.18257850408554077}
{"mode": "train", "epochs": 6, "timestep": 11044, "ep_reward": 588.5809326171875, "reward": 0.7985758185386658, "action": -0.9518406391143799}
{"mode": "train", "epochs": 6, "timestep": 11045, "ep_reward": 589.3034057617188, "reward": 0.7224608659744263, "action": -1.0273290872573853}
{"mode": "train", "epochs": 6, "timestep": 11046, "ep_reward": 589.9150390625, "reward": 0.6116287708282471, "action": -0.9212760329246521}
{"mode": "train", "epochs": 6, "timestep": 11047, "ep_reward": 590.3778076171875, "reward": 0.4627837538719177, "action": -0.8880833983421326}
{"mode": "train", "epochs": 6, "timestep": 11048, "ep_reward": 590.6950073242188, "reward": 0.31719595193862915, "action": -1.877673625946045}
{"mode": "train", "epochs": 6, "timestep": 11049, "ep_reward": 590.8960571289062, "reward": 0.2010311484336853, "action": -1.057694911956787}
{"mode": "train", "epochs": 6, "timestep": 11050, "ep_reward": 590.9608154296875, "reward": 0.06474876403808594, "action": -0.7760941386222839}
{"mode": "train", "epochs": 6, "timestep": 11051, "ep_reward": 591.0143432617188, "reward": 0.05352514982223511, "action": -0.75983065366745}
{"mode": "train", "epochs": 6, "timestep": 11052, "ep_reward": 591.2077026367188, "reward": 0.19334471225738525, "action": -0.9262681007385254}
{"mode": "train", "epochs": 6, "timestep": 11053, "ep_reward": 591.5418090820312, "reward": 0.33408254384994507, "action": -1.0146504640579224}
{"mode": "train", "epochs": 6, "timestep": 11054, "ep_reward": 592.009521484375, "reward": 0.46768462657928467, "action": -0.8641288876533508}
{"mode": "train", "epochs": 6, "timestep": 11055, "ep_reward": 592.5973510742188, "reward": 0.587851881980896, "action": -0.8759207129478455}
{"mode": "train", "epochs": 6, "timestep": 11056, "ep_reward": 593.2838745117188, "reward": 0.6865408420562744, "action": -1.0108174085617065}
{"mode": "train", "epochs": 6, "timestep": 11057, "ep_reward": 594.0450439453125, "reward": 0.7611538767814636, "action": -0.6872855424880981}
{"mode": "train", "epochs": 6, "timestep": 11058, "ep_reward": 594.8623657226562, "reward": 0.8173369765281677, "action": -0.42384928464889526}
{"mode": "train", "epochs": 6, "timestep": 11059, "ep_reward": 595.7188110351562, "reward": 0.8564281463623047, "action": -0.14163494110107422}
{"mode": "train", "epochs": 6, "timestep": 11060, "ep_reward": 596.5996704101562, "reward": 0.8808408975601196, "action": -1.5494251251220703}
{"mode": "train", "epochs": 6, "timestep": 11061, "ep_reward": 597.4790649414062, "reward": 0.8794099688529968, "action": -1.344289779663086}
{"mode": "train", "epochs": 6, "timestep": 11062, "ep_reward": 598.3430786132812, "reward": 0.8640187382698059, "action": -1.314293384552002}
{"mode": "train", "epochs": 6, "timestep": 11063, "ep_reward": 599.17333984375, "reward": 0.8302703499794006, "action": 0.01795196533203125}
{"mode": "train", "epochs": 6, "timestep": 11064, "ep_reward": 599.9602661132812, "reward": 0.7869521379470825, "action": -0.9614205360412598}
{"mode": "train", "epochs": 6, "timestep": 11065, "ep_reward": 600.6668090820312, "reward": 0.706548273563385, "action": -0.7615911960601807}
{"mode": "train", "epochs": 6, "timestep": 11066, "ep_reward": 601.2606811523438, "reward": 0.5938523411750793, "action": -1.0299676656723022}
{"mode": "train", "epochs": 6, "timestep": 11067, "ep_reward": 601.698486328125, "reward": 0.437785804271698, "action": -1.6110886335372925}
{"mode": "train", "epochs": 6, "timestep": 11068, "ep_reward": 602.0028686523438, "reward": 0.30436182022094727, "action": -0.6972174644470215}
{"mode": "train", "epochs": 6, "timestep": 11069, "ep_reward": 602.1885375976562, "reward": 0.1856398582458496, "action": -0.48421138525009155}
{"mode": "train", "epochs": 6, "timestep": 11070, "ep_reward": 602.2352905273438, "reward": 0.046780288219451904, "action": -1.4813743829727173}
{"mode": "train", "epochs": 6, "timestep": 11071, "ep_reward": 602.3065185546875, "reward": 0.0712202787399292, "action": -1.2731895446777344}
{"mode": "train", "epochs": 6, "timestep": 11072, "ep_reward": 602.51318359375, "reward": 0.2066764235496521, "action": -1.0105786323547363}
{"mode": "train", "epochs": 6, "timestep": 11073, "ep_reward": 602.8601684570312, "reward": 0.3469560742378235, "action": -0.6239838600158691}
{"mode": "train", "epochs": 6, "timestep": 11074, "ep_reward": 603.3447875976562, "reward": 0.4846476912498474, "action": -0.3694562315940857}
{"mode": "train", "epochs": 6, "timestep": 11075, "ep_reward": 603.9523315429688, "reward": 0.6075615882873535, "action": -1.0545183420181274}
{"mode": "train", "epochs": 6, "timestep": 11076, "ep_reward": 604.6527709960938, "reward": 0.7004542350769043, "action": -1.502028226852417}
{"mode": "train", "epochs": 6, "timestep": 11077, "ep_reward": 605.4201049804688, "reward": 0.7673077583312988, "action": -1.0433043241500854}
{"mode": "train", "epochs": 6, "timestep": 11078, "ep_reward": 606.23828125, "reward": 0.8181843757629395, "action": -0.8354838490486145}
{"mode": "train", "epochs": 6, "timestep": 11079, "ep_reward": 607.0902709960938, "reward": 0.8519805073738098, "action": -1.2662510871887207}
{"mode": "train", "epochs": 6, "timestep": 11080, "ep_reward": 607.95556640625, "reward": 0.865311861038208, "action": -1.0524262189865112}
{"mode": "train", "epochs": 6, "timestep": 11081, "ep_reward": 608.8196411132812, "reward": 0.8640735149383545, "action": -1.4331889152526855}
{"mode": "train", "epochs": 6, "timestep": 11082, "ep_reward": 609.6614379882812, "reward": 0.841783344745636, "action": -0.391682505607605}
{"mode": "train", "epochs": 6, "timestep": 11083, "ep_reward": 610.4696044921875, "reward": 0.808160126209259, "action": -0.9485175609588623}
{"mode": "train", "epochs": 6, "timestep": 11084, "ep_reward": 611.2132568359375, "reward": 0.743641197681427, "action": -1.2331823110580444}
{"mode": "train", "epochs": 6, "timestep": 11085, "ep_reward": 611.8561401367188, "reward": 0.6428815126419067, "action": -1.1000254154205322}
{"mode": "train", "epochs": 6, "timestep": 11086, "ep_reward": 612.3596801757812, "reward": 0.5035383701324463, "action": -1.3933135271072388}
{"mode": "train", "epochs": 6, "timestep": 11087, "ep_reward": 612.7171020507812, "reward": 0.35744595527648926, "action": -1.6433885097503662}
{"mode": "train", "epochs": 6, "timestep": 11088, "ep_reward": 612.9661254882812, "reward": 0.24900782108306885, "action": -1.5154519081115723}
{"mode": "train", "epochs": 6, "timestep": 11089, "ep_reward": 613.0867919921875, "reward": 0.12063783407211304, "action": -0.9001219272613525}
{"mode": "train", "epochs": 6, "timestep": 11090, "ep_reward": 613.0807495117188, "reward": -0.006022810935974121, "action": -0.00023853778839111328}
{"mode": "train", "epochs": 6, "timestep": 11091, "ep_reward": 613.22216796875, "reward": 0.1413888931274414, "action": -0.13052117824554443}
{"mode": "train", "epochs": 6, "timestep": 11092, "ep_reward": 613.51318359375, "reward": 0.29101139307022095, "action": -1.1406480073928833}
{"mode": "train", "epochs": 6, "timestep": 11093, "ep_reward": 613.937255859375, "reward": 0.4241003394126892, "action": -1.4805762767791748}
{"mode": "train", "epochs": 6, "timestep": 11094, "ep_reward": 614.4797973632812, "reward": 0.5425307750701904, "action": -1.1327317953109741}
{"mode": "train", "epochs": 6, "timestep": 11095, "ep_reward": 615.1272583007812, "reward": 0.6474608778953552, "action": -0.47134929895401}
{"mode": "train", "epochs": 6, "timestep": 11096, "ep_reward": 615.8642578125, "reward": 0.7369867563247681, "action": -0.6109136343002319}
{"mode": "train", "epochs": 6, "timestep": 11097, "ep_reward": 616.66650390625, "reward": 0.8022160530090332, "action": -1.0762050151824951}
{"mode": "train", "epochs": 6, "timestep": 11098, "ep_reward": 617.51025390625, "reward": 0.8437359929084778, "action": -0.9063670039176941}
{"mode": "train", "epochs": 6, "timestep": 11099, "ep_reward": 618.3801879882812, "reward": 0.8699582815170288, "action": -0.952332615852356}
{"mode": "train", "epochs": 6, "timestep": 11100, "ep_reward": 619.2606811523438, "reward": 0.8805105090141296, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 11101, "ep_reward": 620.1283569335938, "reward": 0.8676738739013672, "action": -1.3791635036468506}
{"mode": "train", "epochs": 6, "timestep": 11102, "ep_reward": 620.9705200195312, "reward": 0.8421817421913147, "action": -0.5443806648254395}
{"mode": "train", "epochs": 6, "timestep": 11103, "ep_reward": 621.7737426757812, "reward": 0.8032293319702148, "action": -0.4256221652030945}
{"mode": "train", "epochs": 6, "timestep": 11104, "ep_reward": 622.5140380859375, "reward": 0.7403174638748169, "action": -0.5404564142227173}
{"mode": "train", "epochs": 6, "timestep": 11105, "ep_reward": 623.1591796875, "reward": 0.6451275944709778, "action": -0.9045047163963318}
{"mode": "train", "epochs": 6, "timestep": 11106, "ep_reward": 623.6669921875, "reward": 0.5078369975090027, "action": -1.3607975244522095}
{"mode": "train", "epochs": 6, "timestep": 11107, "ep_reward": 624.0150146484375, "reward": 0.34803998470306396, "action": -1.4273453950881958}
{"mode": "train", "epochs": 6, "timestep": 11108, "ep_reward": 624.2528076171875, "reward": 0.2378029227256775, "action": -0.07692611217498779}
{"mode": "train", "epochs": 6, "timestep": 11109, "ep_reward": 624.3602294921875, "reward": 0.1074339747428894, "action": -0.30705153942108154}
{"mode": "train", "epochs": 6, "timestep": 11110, "ep_reward": 624.368896484375, "reward": 0.00864642858505249, "action": -0.7607985734939575}
{"mode": "train", "epochs": 6, "timestep": 11111, "ep_reward": 624.5213623046875, "reward": 0.15245956182479858, "action": -0.4953485131263733}
{"mode": "train", "epochs": 6, "timestep": 11112, "ep_reward": 624.8197021484375, "reward": 0.2983231544494629, "action": -0.5609432458877563}
{"mode": "train", "epochs": 6, "timestep": 11113, "ep_reward": 625.2586669921875, "reward": 0.4389445185661316, "action": -0.7072016596794128}
{"mode": "train", "epochs": 6, "timestep": 11114, "ep_reward": 625.82275390625, "reward": 0.5640904903411865, "action": -0.9734434485435486}
{"mode": "train", "epochs": 6, "timestep": 11115, "ep_reward": 626.4894409179688, "reward": 0.6666734218597412, "action": -0.7327988147735596}
{"mode": "train", "epochs": 6, "timestep": 11116, "ep_reward": 627.2393188476562, "reward": 0.7498671412467957, "action": -0.6893638372421265}
{"mode": "train", "epochs": 6, "timestep": 11117, "ep_reward": 628.0513305664062, "reward": 0.8119838237762451, "action": -0.45270752906799316}
{"mode": "train", "epochs": 6, "timestep": 11118, "ep_reward": 628.9083251953125, "reward": 0.8570113182067871, "action": -0.9998433589935303}
{"mode": "train", "epochs": 6, "timestep": 11119, "ep_reward": 629.7901611328125, "reward": 0.8818652629852295, "action": -0.5506744980812073}
{"mode": "train", "epochs": 6, "timestep": 11120, "ep_reward": 630.6866455078125, "reward": 0.8964651823043823, "action": -0.9535144567489624}
{"mode": "train", "epochs": 6, "timestep": 11121, "ep_reward": 631.5819702148438, "reward": 0.8953312635421753, "action": -0.42813920974731445}
{"mode": "train", "epochs": 6, "timestep": 11122, "ep_reward": 632.4668579101562, "reward": 0.884863018989563, "action": -0.38071805238723755}
{"mode": "train", "epochs": 6, "timestep": 11123, "ep_reward": 633.3265380859375, "reward": 0.8596915602684021, "action": -1.309272050857544}
{"mode": "train", "epochs": 6, "timestep": 11124, "ep_reward": 634.1336669921875, "reward": 0.8071492314338684, "action": -0.6000171899795532}
{"mode": "train", "epochs": 6, "timestep": 11125, "ep_reward": 634.869384765625, "reward": 0.7357059717178345, "action": -0.9743890762329102}
{"mode": "train", "epochs": 6, "timestep": 11126, "ep_reward": 635.4976806640625, "reward": 0.6282938718795776, "action": -1.8629508018493652}
{"mode": "train", "epochs": 6, "timestep": 11127, "ep_reward": 635.9671020507812, "reward": 0.4694451093673706, "action": -1.5573590993881226}
{"mode": "train", "epochs": 6, "timestep": 11128, "ep_reward": 636.2849731445312, "reward": 0.3178730010986328, "action": -0.21823978424072266}
{"mode": "train", "epochs": 6, "timestep": 11129, "ep_reward": 636.486572265625, "reward": 0.20157206058502197, "action": -1.096265196800232}
{"mode": "train", "epochs": 6, "timestep": 11130, "ep_reward": 636.5519409179688, "reward": 0.06539487838745117, "action": -0.6207678318023682}
{"mode": "train", "epochs": 6, "timestep": 11131, "ep_reward": 636.604736328125, "reward": 0.05277293920516968, "action": -1.5425735712051392}
{"mode": "train", "epochs": 6, "timestep": 11132, "ep_reward": 636.7955322265625, "reward": 0.19079816341400146, "action": -0.903256893157959}
{"mode": "train", "epochs": 6, "timestep": 11133, "ep_reward": 637.1277465820312, "reward": 0.3322429656982422, "action": -0.8469076752662659}
{"mode": "train", "epochs": 6, "timestep": 11134, "ep_reward": 637.5957641601562, "reward": 0.46801501512527466, "action": -1.8079798221588135}
{"mode": "train", "epochs": 6, "timestep": 11135, "ep_reward": 638.1734619140625, "reward": 0.5777247548103333, "action": -0.6221187114715576}
{"mode": "train", "epochs": 6, "timestep": 11136, "ep_reward": 638.8541870117188, "reward": 0.6807506084442139, "action": -1.2399283647537231}
{"mode": "train", "epochs": 6, "timestep": 11137, "ep_reward": 639.6079711914062, "reward": 0.7537657618522644, "action": -0.6546444296836853}
{"mode": "train", "epochs": 6, "timestep": 11138, "ep_reward": 640.41845703125, "reward": 0.810499906539917, "action": 0.06364631652832031}
{"mode": "train", "epochs": 6, "timestep": 11139, "ep_reward": 641.2715454101562, "reward": 0.8531188368797302, "action": 0.07433116436004639}
{"mode": "train", "epochs": 6, "timestep": 11140, "ep_reward": 642.1494140625, "reward": 0.8778638243675232, "action": -0.501020610332489}
{"mode": "train", "epochs": 6, "timestep": 11141, "ep_reward": 643.0321044921875, "reward": 0.8826616406440735, "action": -0.7799426913261414}
{"mode": "train", "epochs": 6, "timestep": 11142, "ep_reward": 643.9022827148438, "reward": 0.8701932430267334, "action": -0.8982120752334595}
{"mode": "train", "epochs": 6, "timestep": 11143, "ep_reward": 644.7415161132812, "reward": 0.8392208814620972, "action": -1.692186713218689}
{"mode": "train", "epochs": 6, "timestep": 11144, "ep_reward": 645.5196533203125, "reward": 0.7781099081039429, "action": -0.6102800965309143}
{"mode": "train", "epochs": 6, "timestep": 11145, "ep_reward": 646.2182006835938, "reward": 0.6985512971878052, "action": -1.873223066329956}
{"mode": "train", "epochs": 6, "timestep": 11146, "ep_reward": 646.785400390625, "reward": 0.5672276020050049, "action": -0.46974611282348633}
{"mode": "train", "epochs": 6, "timestep": 11147, "ep_reward": 647.1981811523438, "reward": 0.41281116008758545, "action": -1.4150493144989014}
{"mode": "train", "epochs": 6, "timestep": 11148, "ep_reward": 647.4902954101562, "reward": 0.2921353578567505, "action": -1.3819180727005005}
{"mode": "train", "epochs": 6, "timestep": 11149, "ep_reward": 647.6615600585938, "reward": 0.1712825894355774, "action": -0.6262582540512085}
{"mode": "train", "epochs": 6, "timestep": 11150, "ep_reward": 647.69189453125, "reward": 0.030334293842315674, "action": -0.6425247192382812}
{"mode": "train", "epochs": 6, "timestep": 11151, "ep_reward": 647.7791748046875, "reward": 0.08725959062576294, "action": -0.36946427822113037}
{"mode": "train", "epochs": 6, "timestep": 11152, "ep_reward": 648.0121459960938, "reward": 0.23296374082565308, "action": -0.9278244972229004}
{"mode": "train", "epochs": 6, "timestep": 11153, "ep_reward": 648.3837890625, "reward": 0.3716423511505127, "action": -1.4510736465454102}
{"mode": "train", "epochs": 6, "timestep": 11154, "ep_reward": 648.8799438476562, "reward": 0.4961656332015991, "action": -0.8755359649658203}
{"mode": "train", "epochs": 6, "timestep": 11155, "ep_reward": 649.4915771484375, "reward": 0.611648440361023, "action": -1.425856113433838}
{"mode": "train", "epochs": 6, "timestep": 11156, "ep_reward": 650.1915283203125, "reward": 0.6999250650405884, "action": -0.8770748376846313}
{"mode": "train", "epochs": 6, "timestep": 11157, "ep_reward": 650.9633178710938, "reward": 0.7717875242233276, "action": -1.0060185194015503}
{"mode": "train", "epochs": 6, "timestep": 11158, "ep_reward": 651.7844848632812, "reward": 0.8211899995803833, "action": -1.0312364101409912}
{"mode": "train", "epochs": 6, "timestep": 11159, "ep_reward": 652.6361083984375, "reward": 0.8516260385513306, "action": -1.3112177848815918}
{"mode": "train", "epochs": 6, "timestep": 11160, "ep_reward": 653.4989013671875, "reward": 0.8628137111663818, "action": -1.100081443786621}
{"mode": "train", "epochs": 6, "timestep": 11161, "ep_reward": 654.35791015625, "reward": 0.8590176105499268, "action": -1.166614294052124}
{"mode": "train", "epochs": 6, "timestep": 11162, "ep_reward": 655.194091796875, "reward": 0.8361671566963196, "action": -0.9597384333610535}
{"mode": "train", "epochs": 6, "timestep": 11163, "ep_reward": 655.9871215820312, "reward": 0.7930441498756409, "action": -1.2473602294921875}
{"mode": "train", "epochs": 6, "timestep": 11164, "ep_reward": 656.7059326171875, "reward": 0.7187901735305786, "action": -1.6029685735702515}
{"mode": "train", "epochs": 6, "timestep": 11165, "ep_reward": 657.3097534179688, "reward": 0.6038457751274109, "action": 0.024632811546325684}
{"mode": "train", "epochs": 6, "timestep": 11166, "ep_reward": 657.7798461914062, "reward": 0.47006797790527344, "action": -0.8420457243919373}
{"mode": "train", "epochs": 6, "timestep": 11167, "ep_reward": 658.1165771484375, "reward": 0.33670079708099365, "action": -1.122270941734314}
{"mode": "train", "epochs": 6, "timestep": 11168, "ep_reward": 658.3407592773438, "reward": 0.2241523265838623, "action": -0.5523570775985718}
{"mode": "train", "epochs": 6, "timestep": 11169, "ep_reward": 658.4322509765625, "reward": 0.09146589040756226, "action": -1.2518846988677979}
{"mode": "train", "epochs": 6, "timestep": 11170, "ep_reward": 658.4579467773438, "reward": 0.025685608386993408, "action": -1.4316407442092896}
{"mode": "train", "epochs": 6, "timestep": 11171, "ep_reward": 658.6251220703125, "reward": 0.16715633869171143, "action": -1.8132327795028687}
{"mode": "train", "epochs": 6, "timestep": 11172, "ep_reward": 658.9220581054688, "reward": 0.2969229221343994, "action": -1.0235319137573242}
{"mode": "train", "epochs": 6, "timestep": 11173, "ep_reward": 659.3565673828125, "reward": 0.43449831008911133, "action": -1.268160343170166}
{"mode": "train", "epochs": 6, "timestep": 11174, "ep_reward": 659.9118041992188, "reward": 0.5552517175674438, "action": -1.6547889709472656}
{"mode": "train", "epochs": 6, "timestep": 11175, "ep_reward": 660.5635986328125, "reward": 0.6517841815948486, "action": -0.4532492160797119}
{"mode": "train", "epochs": 6, "timestep": 11176, "ep_reward": 661.3014526367188, "reward": 0.7378336191177368, "action": -1.7806200981140137}
{"mode": "train", "epochs": 6, "timestep": 11177, "ep_reward": 662.0884399414062, "reward": 0.786998450756073, "action": -0.4463440775871277}
{"mode": "train", "epochs": 6, "timestep": 11178, "ep_reward": 662.9159545898438, "reward": 0.8275381326675415, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 11179, "ep_reward": 663.7498168945312, "reward": 0.8338412046432495, "action": -0.9339461922645569}
{"mode": "train", "epochs": 6, "timestep": 11180, "ep_reward": 664.5797729492188, "reward": 0.8299501538276672, "action": 0.22261810302734375}
{"mode": "train", "epochs": 6, "timestep": 11181, "ep_reward": 665.3956298828125, "reward": 0.8158793449401855, "action": -1.2790818214416504}
{"mode": "train", "epochs": 6, "timestep": 11182, "ep_reward": 666.1578979492188, "reward": 0.7622594833374023, "action": -1.358457326889038}
{"mode": "train", "epochs": 6, "timestep": 11183, "ep_reward": 666.83349609375, "reward": 0.6755722761154175, "action": -1.009102463722229}
{"mode": "train", "epochs": 6, "timestep": 11184, "ep_reward": 667.3873291015625, "reward": 0.5538263916969299, "action": -1.1397151947021484}
{"mode": "train", "epochs": 6, "timestep": 11185, "ep_reward": 667.7892456054688, "reward": 0.4019305109977722, "action": -1.1181635856628418}
{"mode": "train", "epochs": 6, "timestep": 11186, "ep_reward": 668.0921630859375, "reward": 0.30293720960617065, "action": -1.1360697746276855}
{"mode": "train", "epochs": 6, "timestep": 11187, "ep_reward": 668.2759399414062, "reward": 0.18377768993377686, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 11188, "ep_reward": 668.3207397460938, "reward": 0.04479551315307617, "action": -1.9702205657958984}
{"mode": "train", "epochs": 6, "timestep": 11189, "ep_reward": 668.393798828125, "reward": 0.073028564453125, "action": -1.4271435737609863}
{"mode": "train", "epochs": 6, "timestep": 11190, "ep_reward": 668.60205078125, "reward": 0.20826256275177002, "action": -0.9757897257804871}
{"mode": "train", "epochs": 6, "timestep": 11191, "ep_reward": 668.950927734375, "reward": 0.3488895893096924, "action": -1.3873331546783447}
{"mode": "train", "epochs": 6, "timestep": 11192, "ep_reward": 669.4283447265625, "reward": 0.47738975286483765, "action": -0.5839781761169434}
{"mode": "train", "epochs": 6, "timestep": 11193, "ep_reward": 670.0277709960938, "reward": 0.5994310975074768, "action": -1.3014687299728394}
{"mode": "train", "epochs": 6, "timestep": 11194, "ep_reward": 670.71875, "reward": 0.6910014152526855, "action": -1.6382089853286743}
{"mode": "train", "epochs": 6, "timestep": 11195, "ep_reward": 671.4758911132812, "reward": 0.7571471929550171, "action": -0.24730134010314941}
{"mode": "train", "epochs": 6, "timestep": 11196, "ep_reward": 672.290771484375, "reward": 0.8148645162582397, "action": -0.8657076954841614}
{"mode": "train", "epochs": 6, "timestep": 11197, "ep_reward": 673.1371459960938, "reward": 0.8464031219482422, "action": -0.9811864495277405}
{"mode": "train", "epochs": 6, "timestep": 11198, "ep_reward": 673.9962768554688, "reward": 0.8591251373291016, "action": -1.2567723989486694}
{"mode": "train", "epochs": 6, "timestep": 11199, "ep_reward": 674.8483276367188, "reward": 0.8520234823226929, "action": -0.8661872744560242}
{"mode": "train", "epochs": 6, "timestep": 11200, "ep_reward": 675.677490234375, "reward": 0.8291349411010742, "action": -0.7554375529289246}
{"mode": "train", "epochs": 6, "timestep": 11201, "ep_reward": 676.4620361328125, "reward": 0.7845463752746582, "action": -1.276623249053955}
{"mode": "train", "epochs": 6, "timestep": 11202, "ep_reward": 677.1676025390625, "reward": 0.7055398225784302, "action": -1.5223872661590576}
{"mode": "train", "epochs": 6, "timestep": 11203, "ep_reward": 677.7535400390625, "reward": 0.5859326720237732, "action": -1.479825735092163}
{"mode": "train", "epochs": 6, "timestep": 11204, "ep_reward": 678.1756591796875, "reward": 0.4221457839012146, "action": -1.3791868686676025}
{"mode": "train", "epochs": 6, "timestep": 11205, "ep_reward": 678.4949951171875, "reward": 0.31934940814971924, "action": -1.3760700225830078}
{"mode": "train", "epochs": 6, "timestep": 11206, "ep_reward": 678.698486328125, "reward": 0.20349228382110596, "action": -0.8657633662223816}
{"mode": "train", "epochs": 6, "timestep": 11207, "ep_reward": 678.7660522460938, "reward": 0.06754946708679199, "action": -0.9930223822593689}
{"mode": "train", "epochs": 6, "timestep": 11208, "ep_reward": 678.8167114257812, "reward": 0.05066978931427002, "action": -0.6903848648071289}
{"mode": "train", "epochs": 6, "timestep": 11209, "ep_reward": 679.0079345703125, "reward": 0.19123363494873047, "action": -1.1313791275024414}
{"mode": "train", "epochs": 6, "timestep": 11210, "ep_reward": 679.3373413085938, "reward": 0.3293788433074951, "action": -0.6385773420333862}
{"mode": "train", "epochs": 6, "timestep": 11211, "ep_reward": 679.8052978515625, "reward": 0.4679662585258484, "action": -1.2293016910552979}
{"mode": "train", "epochs": 6, "timestep": 11212, "ep_reward": 680.3892211914062, "reward": 0.5838966369628906, "action": -1.4228835105895996}
{"mode": "train", "epochs": 6, "timestep": 11213, "ep_reward": 681.0670166015625, "reward": 0.6778193712234497, "action": -0.5207209587097168}
{"mode": "train", "epochs": 6, "timestep": 11214, "ep_reward": 681.8255004882812, "reward": 0.758497953414917, "action": -0.8439137935638428}
{"mode": "train", "epochs": 6, "timestep": 11215, "ep_reward": 682.6390991210938, "reward": 0.813581109046936, "action": -0.8548002243041992}
{"mode": "train", "epochs": 6, "timestep": 11216, "ep_reward": 683.4883422851562, "reward": 0.8492131233215332, "action": -0.7334779500961304}
{"mode": "train", "epochs": 6, "timestep": 11217, "ep_reward": 684.3571166992188, "reward": 0.8687814474105835, "action": -0.4031681418418884}
{"mode": "train", "epochs": 6, "timestep": 11218, "ep_reward": 685.2322998046875, "reward": 0.8751989006996155, "action": -0.6117291450500488}
{"mode": "train", "epochs": 6, "timestep": 11219, "ep_reward": 686.0962524414062, "reward": 0.8639708757400513, "action": -1.038286805152893}
{"mode": "train", "epochs": 6, "timestep": 11220, "ep_reward": 686.9271240234375, "reward": 0.8308882713317871, "action": 0.28898775577545166}
{"mode": "train", "epochs": 6, "timestep": 11221, "ep_reward": 687.7159423828125, "reward": 0.7888123393058777, "action": -0.803329348564148}
{"mode": "train", "epochs": 6, "timestep": 11222, "ep_reward": 688.4253540039062, "reward": 0.7094289064407349, "action": -0.6764687895774841}
{"mode": "train", "epochs": 6, "timestep": 11223, "ep_reward": 689.0230102539062, "reward": 0.5976443290710449, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 11224, "ep_reward": 689.4501953125, "reward": 0.4272065758705139, "action": -0.8089838027954102}
{"mode": "train", "epochs": 6, "timestep": 11225, "ep_reward": 689.7496337890625, "reward": 0.2994532585144043, "action": -0.8371361494064331}
{"mode": "train", "epochs": 6, "timestep": 11226, "ep_reward": 689.929443359375, "reward": 0.17979764938354492, "action": -1.0206224918365479}
{"mode": "train", "epochs": 6, "timestep": 11227, "ep_reward": 689.9696044921875, "reward": 0.0401463508605957, "action": -1.1504292488098145}
{"mode": "train", "epochs": 6, "timestep": 11228, "ep_reward": 690.0473022460938, "reward": 0.07770055532455444, "action": -1.3891446590423584}
{"mode": "train", "epochs": 6, "timestep": 11229, "ep_reward": 690.2594604492188, "reward": 0.21213799715042114, "action": -1.8115887641906738}
{"mode": "train", "epochs": 6, "timestep": 11230, "ep_reward": 690.6019897460938, "reward": 0.34251248836517334, "action": -0.7716617584228516}
{"mode": "train", "epochs": 6, "timestep": 11231, "ep_reward": 691.0819091796875, "reward": 0.47989195585250854, "action": -1.615712285041809}
{"mode": "train", "epochs": 6, "timestep": 11232, "ep_reward": 691.6720581054688, "reward": 0.5901550650596619, "action": -1.136285662651062}
{"mode": "train", "epochs": 6, "timestep": 11233, "ep_reward": 692.3564453125, "reward": 0.6843924522399902, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 11234, "ep_reward": 693.1028442382812, "reward": 0.7463968992233276, "action": -0.4791274666786194}
{"mode": "train", "epochs": 6, "timestep": 11235, "ep_reward": 693.9038696289062, "reward": 0.8010525703430176, "action": -0.3907656669616699}
{"mode": "train", "epochs": 6, "timestep": 11236, "ep_reward": 694.738037109375, "reward": 0.8341940641403198, "action": -1.152855396270752}
{"mode": "train", "epochs": 6, "timestep": 11237, "ep_reward": 695.5784301757812, "reward": 0.8404013514518738, "action": -0.503866970539093}
{"mode": "train", "epochs": 6, "timestep": 11238, "ep_reward": 696.4111328125, "reward": 0.8327008485794067, "action": -1.1866159439086914}
{"mode": "train", "epochs": 6, "timestep": 11239, "ep_reward": 697.2073974609375, "reward": 0.7962433099746704, "action": -1.1614370346069336}
{"mode": "train", "epochs": 6, "timestep": 11240, "ep_reward": 697.9398193359375, "reward": 0.7323983311653137, "action": -0.19545364379882812}
{"mode": "train", "epochs": 6, "timestep": 11241, "ep_reward": 698.5865478515625, "reward": 0.6467268466949463, "action": -1.0210211277008057}
{"mode": "train", "epochs": 6, "timestep": 11242, "ep_reward": 699.0983276367188, "reward": 0.5117895007133484, "action": -1.1159460544586182}
{"mode": "train", "epochs": 6, "timestep": 11243, "ep_reward": 699.4689331054688, "reward": 0.37060344219207764, "action": -1.6249053478240967}
{"mode": "train", "epochs": 6, "timestep": 11244, "ep_reward": 699.73388671875, "reward": 0.2649783492088318, "action": -0.755130410194397}
{"mode": "train", "epochs": 6, "timestep": 11245, "ep_reward": 699.8731079101562, "reward": 0.13921064138412476, "action": -0.8898287415504456}
{"mode": "train", "epochs": 6, "timestep": 11246, "ep_reward": 699.8665161132812, "reward": -0.006580352783203125, "action": -1.180747389793396}
{"mode": "train", "epochs": 6, "timestep": 11247, "ep_reward": 699.987548828125, "reward": 0.12100547552108765, "action": -1.2720407247543335}
{"mode": "train", "epochs": 6, "timestep": 11248, "ep_reward": 700.2440185546875, "reward": 0.2564418315887451, "action": -1.1433848142623901}
{"mode": "train", "epochs": 6, "timestep": 11249, "ep_reward": 700.6376953125, "reward": 0.3936612606048584, "action": -0.29170143604278564}
{"mode": "train", "epochs": 6, "timestep": 11250, "ep_reward": 701.1680297851562, "reward": 0.5303072929382324, "action": -1.6436100006103516}
{"mode": "train", "epochs": 6, "timestep": 11251, "ep_reward": 701.7998046875, "reward": 0.6317718029022217, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 11252, "ep_reward": 702.5090942382812, "reward": 0.7092952132225037, "action": -0.6976215839385986}
{"mode": "train", "epochs": 6, "timestep": 11253, "ep_reward": 703.2869873046875, "reward": 0.777897834777832, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 11254, "ep_reward": 704.0997314453125, "reward": 0.8127394914627075, "action": -1.0697438716888428}
{"mode": "train", "epochs": 6, "timestep": 11255, "ep_reward": 704.9364013671875, "reward": 0.8366971611976624, "action": -1.0245447158813477}
{"mode": "train", "epochs": 6, "timestep": 11256, "ep_reward": 705.7781372070312, "reward": 0.8417115807533264, "action": -0.9063599705696106}
{"mode": "train", "epochs": 6, "timestep": 11257, "ep_reward": 706.60595703125, "reward": 0.8278217911720276, "action": -0.13668519258499146}
{"mode": "train", "epochs": 6, "timestep": 11258, "ep_reward": 707.4052734375, "reward": 0.7993098497390747, "action": -1.1117879152297974}
{"mode": "train", "epochs": 6, "timestep": 11259, "ep_reward": 708.1395874023438, "reward": 0.7343153953552246, "action": -0.947773277759552}
{"mode": "train", "epochs": 6, "timestep": 11260, "ep_reward": 708.77685546875, "reward": 0.6372464895248413, "action": -1.029097557067871}
{"mode": "train", "epochs": 6, "timestep": 11261, "ep_reward": 709.2755126953125, "reward": 0.49865567684173584, "action": -1.1710103750228882}
{"mode": "train", "epochs": 6, "timestep": 11262, "ep_reward": 709.6383666992188, "reward": 0.36287689208984375, "action": -0.807741641998291}
{"mode": "train", "epochs": 6, "timestep": 11263, "ep_reward": 709.893798828125, "reward": 0.2554139494895935, "action": -1.4048256874084473}
{"mode": "train", "epochs": 6, "timestep": 11264, "ep_reward": 710.0218505859375, "reward": 0.12806951999664307, "action": -1.1863945722579956}
{"mode": "train", "epochs": 6, "timestep": 11265, "ep_reward": 710.00732421875, "reward": -0.01449596881866455, "action": -0.44800007343292236}
{"mode": "train", "epochs": 6, "timestep": 11266, "ep_reward": 710.1395874023438, "reward": 0.13228988647460938, "action": -0.20199233293533325}
{"mode": "train", "epochs": 6, "timestep": 11267, "ep_reward": 710.4208984375, "reward": 0.2812836170196533, "action": -0.8133904337882996}
{"mode": "train", "epochs": 6, "timestep": 11268, "ep_reward": 710.8399047851562, "reward": 0.4190177321434021, "action": -1.814603567123413}
{"mode": "train", "epochs": 6, "timestep": 11269, "ep_reward": 711.3740844726562, "reward": 0.5341815948486328, "action": -1.203106164932251}
{"mode": "train", "epochs": 6, "timestep": 11270, "ep_reward": 712.0139770507812, "reward": 0.6398658752441406, "action": -0.4718659520149231}
{"mode": "train", "epochs": 6, "timestep": 11271, "ep_reward": 712.7449340820312, "reward": 0.7309388518333435, "action": -1.0997880697250366}
{"mode": "train", "epochs": 6, "timestep": 11272, "ep_reward": 713.5379638671875, "reward": 0.7930442094802856, "action": -1.4211812019348145}
{"mode": "train", "epochs": 6, "timestep": 11273, "ep_reward": 714.3707885742188, "reward": 0.8328181505203247, "action": -0.7679249048233032}
{"mode": "train", "epochs": 6, "timestep": 11274, "ep_reward": 715.2313232421875, "reward": 0.8605455160140991, "action": -1.271411418914795}
{"mode": "train", "epochs": 6, "timestep": 11275, "ep_reward": 716.0989379882812, "reward": 0.8676450252532959, "action": -1.443459391593933}
{"mode": "train", "epochs": 6, "timestep": 11276, "ep_reward": 716.9556884765625, "reward": 0.8567301630973816, "action": -0.9311447739601135}
{"mode": "train", "epochs": 6, "timestep": 11277, "ep_reward": 717.7870483398438, "reward": 0.8313388228416443, "action": -1.2255451679229736}
{"mode": "train", "epochs": 6, "timestep": 11278, "ep_reward": 718.567138671875, "reward": 0.7801107168197632, "action": -0.5101300477981567}
{"mode": "train", "epochs": 6, "timestep": 11279, "ep_reward": 719.2747802734375, "reward": 0.70766282081604, "action": -1.6314691305160522}
{"mode": "train", "epochs": 6, "timestep": 11280, "ep_reward": 719.8606567382812, "reward": 0.5858708620071411, "action": -0.970167875289917}
{"mode": "train", "epochs": 6, "timestep": 11281, "ep_reward": 720.2904052734375, "reward": 0.42977750301361084, "action": -1.1454875469207764}
{"mode": "train", "epochs": 6, "timestep": 11282, "ep_reward": 720.60546875, "reward": 0.3150774836540222, "action": -0.3259091377258301}
{"mode": "train", "epochs": 6, "timestep": 11283, "ep_reward": 720.8037109375, "reward": 0.19822371006011963, "action": -1.3101637363433838}
{"mode": "train", "epochs": 6, "timestep": 11284, "ep_reward": 720.865234375, "reward": 0.06152164936065674, "action": -0.9540292620658875}
{"mode": "train", "epochs": 6, "timestep": 11285, "ep_reward": 720.9219970703125, "reward": 0.05677604675292969, "action": -0.5200884342193604}
{"mode": "train", "epochs": 6, "timestep": 11286, "ep_reward": 721.1216430664062, "reward": 0.19963663816452026, "action": -1.2847096920013428}
{"mode": "train", "epochs": 6, "timestep": 11287, "ep_reward": 721.4569702148438, "reward": 0.3353550434112549, "action": -0.15227770805358887}
{"mode": "train", "epochs": 6, "timestep": 11288, "ep_reward": 721.93603515625, "reward": 0.47905367612838745, "action": -1.054619312286377}
{"mode": "train", "epochs": 6, "timestep": 11289, "ep_reward": 722.5310668945312, "reward": 0.5950310230255127, "action": -1.1319308280944824}
{"mode": "train", "epochs": 6, "timestep": 11290, "ep_reward": 723.220947265625, "reward": 0.6898764371871948, "action": -1.144132137298584}
{"mode": "train", "epochs": 6, "timestep": 11291, "ep_reward": 723.98388671875, "reward": 0.7629159092903137, "action": -0.44062095880508423}
{"mode": "train", "epochs": 6, "timestep": 11292, "ep_reward": 724.8050537109375, "reward": 0.8211496472358704, "action": -1.6727824211120605}
{"mode": "train", "epochs": 6, "timestep": 11293, "ep_reward": 725.6553344726562, "reward": 0.850276529788971, "action": -0.6288825273513794}
{"mode": "train", "epochs": 6, "timestep": 11294, "ep_reward": 726.5270385742188, "reward": 0.8717237114906311, "action": -1.7002949714660645}
{"mode": "train", "epochs": 6, "timestep": 11295, "ep_reward": 727.3958740234375, "reward": 0.8688298463821411, "action": -1.4472705125808716}
{"mode": "train", "epochs": 6, "timestep": 11296, "ep_reward": 728.2470092773438, "reward": 0.8511085510253906, "action": -0.07457202672958374}
{"mode": "train", "epochs": 6, "timestep": 11297, "ep_reward": 729.0734252929688, "reward": 0.8264318704605103, "action": -0.45795589685440063}
{"mode": "train", "epochs": 6, "timestep": 11298, "ep_reward": 729.8491821289062, "reward": 0.7757399082183838, "action": -1.429422378540039}
{"mode": "train", "epochs": 6, "timestep": 11299, "ep_reward": 730.534423828125, "reward": 0.6852413415908813, "action": -1.3559173345565796}
{"mode": "train", "epochs": 6, "timestep": 11300, "ep_reward": 731.091552734375, "reward": 0.5571529865264893, "action": -0.7401731014251709}
{"mode": "train", "epochs": 6, "timestep": 11301, "ep_reward": 731.4869384765625, "reward": 0.39540624618530273, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 11302, "ep_reward": 731.7723999023438, "reward": 0.28544706106185913, "action": -1.2921794652938843}
{"mode": "train", "epochs": 6, "timestep": 11303, "ep_reward": 731.9357299804688, "reward": 0.1633284091949463, "action": -1.0858123302459717}
{"mode": "train", "epochs": 6, "timestep": 11304, "ep_reward": 731.9569091796875, "reward": 0.02115577459335327, "action": -1.2488350868225098}
{"mode": "train", "epochs": 6, "timestep": 11305, "ep_reward": 732.052734375, "reward": 0.09580445289611816, "action": -0.7293422818183899}
{"mode": "train", "epochs": 6, "timestep": 11306, "ep_reward": 732.2899780273438, "reward": 0.23725521564483643, "action": -1.338810682296753}
{"mode": "train", "epochs": 6, "timestep": 11307, "ep_reward": 732.66162109375, "reward": 0.3716403841972351, "action": -1.0764960050582886}
{"mode": "train", "epochs": 6, "timestep": 11308, "ep_reward": 733.1630249023438, "reward": 0.5014163851737976, "action": -0.5720236301422119}
{"mode": "train", "epochs": 6, "timestep": 11309, "ep_reward": 733.7825317382812, "reward": 0.6194809675216675, "action": -1.1192916631698608}
{"mode": "train", "epochs": 6, "timestep": 11310, "ep_reward": 734.4915771484375, "reward": 0.7090543508529663, "action": -0.35480475425720215}
{"mode": "train", "epochs": 6, "timestep": 11311, "ep_reward": 735.27490234375, "reward": 0.7833508253097534, "action": -1.2231732606887817}
{"mode": "train", "epochs": 6, "timestep": 11312, "ep_reward": 736.1034545898438, "reward": 0.8285725712776184, "action": -0.832557737827301}
{"mode": "train", "epochs": 6, "timestep": 11313, "ep_reward": 736.9627075195312, "reward": 0.8592749834060669, "action": -1.0352482795715332}
{"mode": "train", "epochs": 6, "timestep": 11314, "ep_reward": 737.8347778320312, "reward": 0.8720818758010864, "action": -0.969188392162323}
{"mode": "train", "epochs": 6, "timestep": 11315, "ep_reward": 738.70458984375, "reward": 0.8698040246963501, "action": -0.6293691396713257}
{"mode": "train", "epochs": 6, "timestep": 11316, "ep_reward": 739.5581665039062, "reward": 0.8535855412483215, "action": -1.3890939950942993}
{"mode": "train", "epochs": 6, "timestep": 11317, "ep_reward": 740.3687133789062, "reward": 0.8105679750442505, "action": -0.6147400736808777}
{"mode": "train", "epochs": 6, "timestep": 11318, "ep_reward": 741.118408203125, "reward": 0.7497050762176514, "action": -0.6419269442558289}
{"mode": "train", "epochs": 6, "timestep": 11319, "ep_reward": 741.7760009765625, "reward": 0.6576024293899536, "action": -1.9498838186264038}
{"mode": "train", "epochs": 6, "timestep": 11320, "ep_reward": 742.2855224609375, "reward": 0.5095418691635132, "action": -1.0752609968185425}
{"mode": "train", "epochs": 6, "timestep": 11321, "ep_reward": 742.6446533203125, "reward": 0.35911548137664795, "action": -0.7733892798423767}
{"mode": "train", "epochs": 6, "timestep": 11322, "ep_reward": 742.8956298828125, "reward": 0.2509579658508301, "action": -0.8421288728713989}
{"mode": "train", "epochs": 6, "timestep": 11323, "ep_reward": 743.0183715820312, "reward": 0.12275606393814087, "action": -1.241217851638794}
{"mode": "train", "epochs": 6, "timestep": 11324, "ep_reward": 743.0097045898438, "reward": -0.008692264556884766, "action": -1.923640489578247}
{"mode": "train", "epochs": 6, "timestep": 11325, "ep_reward": 743.147216796875, "reward": 0.13753032684326172, "action": -0.47930145263671875}
{"mode": "train", "epochs": 6, "timestep": 11326, "ep_reward": 743.430419921875, "reward": 0.28322285413742065, "action": -0.9708630442619324}
{"mode": "train", "epochs": 6, "timestep": 11327, "ep_reward": 743.8499755859375, "reward": 0.41953420639038086, "action": -1.9309687614440918}
{"mode": "train", "epochs": 6, "timestep": 11328, "ep_reward": 744.3836669921875, "reward": 0.5336734056472778, "action": -1.2793796062469482}
{"mode": "train", "epochs": 6, "timestep": 11329, "ep_reward": 745.0221557617188, "reward": 0.6384994387626648, "action": -1.4074275493621826}
{"mode": "train", "epochs": 6, "timestep": 11330, "ep_reward": 745.7423095703125, "reward": 0.7201720476150513, "action": -0.20354348421096802}
{"mode": "train", "epochs": 6, "timestep": 11331, "ep_reward": 746.5331420898438, "reward": 0.7908080816268921, "action": -1.2961080074310303}
{"mode": "train", "epochs": 6, "timestep": 11332, "ep_reward": 747.3629150390625, "reward": 0.8297618627548218, "action": -0.6550793051719666}
{"mode": "train", "epochs": 6, "timestep": 11333, "ep_reward": 748.2188720703125, "reward": 0.8559606075286865, "action": -0.6064977645874023}
{"mode": "train", "epochs": 6, "timestep": 11334, "ep_reward": 749.0841674804688, "reward": 0.8652967214584351, "action": -0.9848020076751709}
{"mode": "train", "epochs": 6, "timestep": 11335, "ep_reward": 749.9384155273438, "reward": 0.854268491268158, "action": -1.2740200757980347}
{"mode": "train", "epochs": 6, "timestep": 11336, "ep_reward": 750.7594604492188, "reward": 0.8210551738739014, "action": -0.884117066860199}
{"mode": "train", "epochs": 6, "timestep": 11337, "ep_reward": 751.5267333984375, "reward": 0.7672938108444214, "action": -0.9117302298545837}
{"mode": "train", "epochs": 6, "timestep": 11338, "ep_reward": 752.2097778320312, "reward": 0.68301922082901, "action": -1.0631024837493896}
{"mode": "train", "epochs": 6, "timestep": 11339, "ep_reward": 752.7693481445312, "reward": 0.5595887899398804, "action": -0.5423334836959839}
{"mode": "train", "epochs": 6, "timestep": 11340, "ep_reward": 753.171630859375, "reward": 0.4022707939147949, "action": -0.5167781114578247}
{"mode": "train", "epochs": 6, "timestep": 11341, "ep_reward": 753.4633178710938, "reward": 0.2916697859764099, "action": -0.5557473301887512}
{"mode": "train", "epochs": 6, "timestep": 11342, "ep_reward": 753.6338500976562, "reward": 0.17052316665649414, "action": -1.3651118278503418}
{"mode": "train", "epochs": 6, "timestep": 11343, "ep_reward": 753.6632080078125, "reward": 0.029340744018554688, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 11344, "ep_reward": 753.7509765625, "reward": 0.08775156736373901, "action": -1.983938217163086}
{"mode": "train", "epochs": 6, "timestep": 11345, "ep_reward": 753.9720458984375, "reward": 0.22108060121536255, "action": -0.6166183948516846}
{"mode": "train", "epochs": 6, "timestep": 11346, "ep_reward": 754.338134765625, "reward": 0.36611461639404297, "action": -1.6876368522644043}
{"mode": "train", "epochs": 6, "timestep": 11347, "ep_reward": 754.8273315429688, "reward": 0.4892001152038574, "action": -1.130071997642517}
{"mode": "train", "epochs": 6, "timestep": 11348, "ep_reward": 755.4307250976562, "reward": 0.6033788323402405, "action": -0.9421238303184509}
{"mode": "train", "epochs": 6, "timestep": 11349, "ep_reward": 756.1282348632812, "reward": 0.6975058317184448, "action": -0.4058275818824768}
{"mode": "train", "epochs": 6, "timestep": 11350, "ep_reward": 756.9013061523438, "reward": 0.7730974555015564, "action": -0.762931764125824}
{"mode": "train", "epochs": 6, "timestep": 11351, "ep_reward": 757.7239379882812, "reward": 0.8226083517074585, "action": -1.8973160982131958}
{"mode": "train", "epochs": 6, "timestep": 11352, "ep_reward": 758.5672607421875, "reward": 0.8433516025543213, "action": -1.0284892320632935}
{"mode": "train", "epochs": 6, "timestep": 11353, "ep_reward": 759.4213256835938, "reward": 0.8540886640548706, "action": -0.8933002948760986}
{"mode": "train", "epochs": 6, "timestep": 11354, "ep_reward": 760.269287109375, "reward": 0.8479674458503723, "action": -0.23739093542099}
{"mode": "train", "epochs": 6, "timestep": 11355, "ep_reward": 761.09765625, "reward": 0.828357994556427, "action": -1.315078854560852}
{"mode": "train", "epochs": 6, "timestep": 11356, "ep_reward": 761.8729858398438, "reward": 0.7753033638000488, "action": 0.08407986164093018}
{"mode": "train", "epochs": 6, "timestep": 11357, "ep_reward": 762.5818481445312, "reward": 0.7088844776153564, "action": -0.11038261651992798}
{"mode": "train", "epochs": 6, "timestep": 11358, "ep_reward": 763.1900024414062, "reward": 0.6081392765045166, "action": -1.3386591672897339}
{"mode": "train", "epochs": 6, "timestep": 11359, "ep_reward": 763.6421508789062, "reward": 0.45217764377593994, "action": -0.1448548436164856}
{"mode": "train", "epochs": 6, "timestep": 11360, "ep_reward": 763.9613647460938, "reward": 0.31921952962875366, "action": -0.8872758150100708}
{"mode": "train", "epochs": 6, "timestep": 11361, "ep_reward": 764.1646728515625, "reward": 0.20328611135482788, "action": -0.5118863582611084}
{"mode": "train", "epochs": 6, "timestep": 11362, "ep_reward": 764.2318725585938, "reward": 0.06717145442962646, "action": -1.627206802368164}
{"mode": "train", "epochs": 6, "timestep": 11363, "ep_reward": 764.28271484375, "reward": 0.0508694052696228, "action": -1.3178150653839111}
{"mode": "train", "epochs": 6, "timestep": 11364, "ep_reward": 764.4718017578125, "reward": 0.18907928466796875, "action": -1.1922403573989868}
{"mode": "train", "epochs": 6, "timestep": 11365, "ep_reward": 764.7987670898438, "reward": 0.32696932554244995, "action": -0.30988746881484985}
{"mode": "train", "epochs": 6, "timestep": 11366, "ep_reward": 765.268798828125, "reward": 0.47005558013916016, "action": -1.073494791984558}
{"mode": "train", "epochs": 6, "timestep": 11367, "ep_reward": 765.8562622070312, "reward": 0.587470531463623, "action": -0.5343575477600098}
{"mode": "train", "epochs": 6, "timestep": 11368, "ep_reward": 766.5459594726562, "reward": 0.6897022724151611, "action": -0.9896237850189209}
{"mode": "train", "epochs": 6, "timestep": 11369, "ep_reward": 767.3101196289062, "reward": 0.7641859650611877, "action": -0.6621636748313904}
{"mode": "train", "epochs": 6, "timestep": 11370, "ep_reward": 768.1306762695312, "reward": 0.8205578923225403, "action": -0.35823124647140503}
{"mode": "train", "epochs": 6, "timestep": 11371, "ep_reward": 768.9910278320312, "reward": 0.8603666424751282, "action": -1.367755651473999}
{"mode": "train", "epochs": 6, "timestep": 11372, "ep_reward": 769.8670654296875, "reward": 0.8760499954223633, "action": -0.9443681240081787}
{"mode": "train", "epochs": 6, "timestep": 11373, "ep_reward": 770.74755859375, "reward": 0.8805121779441833, "action": -0.7188050150871277}
{"mode": "train", "epochs": 6, "timestep": 11374, "ep_reward": 771.6192626953125, "reward": 0.8716758489608765, "action": -1.1746394634246826}
{"mode": "train", "epochs": 6, "timestep": 11375, "ep_reward": 772.4610595703125, "reward": 0.8417723178863525, "action": -0.9389304518699646}
{"mode": "train", "epochs": 6, "timestep": 11376, "ep_reward": 773.2532348632812, "reward": 0.7921908497810364, "action": -1.4152326583862305}
{"mode": "train", "epochs": 6, "timestep": 11377, "ep_reward": 773.9627075195312, "reward": 0.709473729133606, "action": 0.039061546325683594}
{"mode": "train", "epochs": 6, "timestep": 11378, "ep_reward": 774.572509765625, "reward": 0.6098058223724365, "action": -1.6758346557617188}
{"mode": "train", "epochs": 6, "timestep": 11379, "ep_reward": 775.0211791992188, "reward": 0.4486619234085083, "action": -0.34270286560058594}
{"mode": "train", "epochs": 6, "timestep": 11380, "ep_reward": 775.3356323242188, "reward": 0.3144437074661255, "action": -1.234863519668579}
{"mode": "train", "epochs": 6, "timestep": 11381, "ep_reward": 775.533203125, "reward": 0.1975824236869812, "action": -1.2736563682556152}
{"mode": "train", "epochs": 6, "timestep": 11382, "ep_reward": 775.5939331054688, "reward": 0.060734450817108154, "action": -1.2317824363708496}
{"mode": "train", "epochs": 6, "timestep": 11383, "ep_reward": 775.6514282226562, "reward": 0.057479918003082275, "action": -1.0200221538543701}
{"mode": "train", "epochs": 6, "timestep": 11384, "ep_reward": 775.84619140625, "reward": 0.19475841522216797, "action": -1.1849009990692139}
{"mode": "train", "epochs": 6, "timestep": 11385, "ep_reward": 776.1788940429688, "reward": 0.3327181339263916, "action": -1.2116879224777222}
{"mode": "train", "epochs": 6, "timestep": 11386, "ep_reward": 776.6436157226562, "reward": 0.4647248387336731, "action": -1.0921272039413452}
{"mode": "train", "epochs": 6, "timestep": 11387, "ep_reward": 777.2267456054688, "reward": 0.5831530094146729, "action": -0.5827969312667847}
{"mode": "train", "epochs": 6, "timestep": 11388, "ep_reward": 777.9122314453125, "reward": 0.6854571104049683, "action": -0.9231840372085571}
{"mode": "train", "epochs": 6, "timestep": 11389, "ep_reward": 778.6724853515625, "reward": 0.7602809071540833, "action": -0.3484613299369812}
{"mode": "train", "epochs": 6, "timestep": 11390, "ep_reward": 779.49072265625, "reward": 0.8182430863380432, "action": -0.6247346997261047}
{"mode": "train", "epochs": 6, "timestep": 11391, "ep_reward": 780.344482421875, "reward": 0.8537404537200928, "action": -1.449874758720398}
{"mode": "train", "epochs": 6, "timestep": 11392, "ep_reward": 781.2100219726562, "reward": 0.8655596971511841, "action": -1.0385513305664062}
{"mode": "train", "epochs": 6, "timestep": 11393, "ep_reward": 782.0745849609375, "reward": 0.864567756652832, "action": -1.3135979175567627}
{"mode": "train", "epochs": 6, "timestep": 11394, "ep_reward": 782.9180297851562, "reward": 0.8434734344482422, "action": -1.3375297784805298}
{"mode": "train", "epochs": 6, "timestep": 11395, "ep_reward": 783.7185668945312, "reward": 0.800517201423645, "action": -1.2198047637939453}
{"mode": "train", "epochs": 6, "timestep": 11396, "ep_reward": 784.4497680664062, "reward": 0.7312058210372925, "action": -1.1555566787719727}
{"mode": "train", "epochs": 6, "timestep": 11397, "ep_reward": 785.0777587890625, "reward": 0.6279603242874146, "action": -1.3197436332702637}
{"mode": "train", "epochs": 6, "timestep": 11398, "ep_reward": 785.5587158203125, "reward": 0.48095351457595825, "action": 0.020618319511413574}
{"mode": "train", "epochs": 6, "timestep": 11399, "ep_reward": 785.90966796875, "reward": 0.3509429097175598, "action": -0.4743913412094116}
{"mode": "train", "epochs": 6, "timestep": 11400, "ep_reward": 786.150634765625, "reward": 0.24099433422088623, "action": -1.5801844596862793}
{"mode": "train", "epochs": 6, "timestep": 11401, "ep_reward": 786.261962890625, "reward": 0.11132925748825073, "action": -0.4924129843711853}
{"mode": "train", "epochs": 6, "timestep": 11402, "ep_reward": 786.266357421875, "reward": 0.004387319087982178, "action": -0.11846405267715454}
{"mode": "train", "epochs": 6, "timestep": 11403, "ep_reward": 786.4169311523438, "reward": 0.1505548357963562, "action": -1.2938294410705566}
{"mode": "train", "epochs": 6, "timestep": 11404, "ep_reward": 786.7030029296875, "reward": 0.28608083724975586, "action": -0.6239844560623169}
{"mode": "train", "epochs": 6, "timestep": 11405, "ep_reward": 787.1306762695312, "reward": 0.42766666412353516, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 11406, "ep_reward": 787.6710205078125, "reward": 0.540326714515686, "action": -1.266034483909607}
{"mode": "train", "epochs": 6, "timestep": 11407, "ep_reward": 788.3150634765625, "reward": 0.6440150737762451, "action": -1.2820649147033691}
{"mode": "train", "epochs": 6, "timestep": 11408, "ep_reward": 789.0400390625, "reward": 0.7249937057495117, "action": -1.306803822517395}
{"mode": "train", "epochs": 6, "timestep": 11409, "ep_reward": 789.8232421875, "reward": 0.7831823825836182, "action": -0.3201492428779602}
{"mode": "train", "epochs": 6, "timestep": 11410, "ep_reward": 790.65234375, "reward": 0.8290996551513672, "action": -1.080505132675171}
{"mode": "train", "epochs": 6, "timestep": 11411, "ep_reward": 791.5008544921875, "reward": 0.8484923243522644, "action": -0.33139151334762573}
{"mode": "train", "epochs": 6, "timestep": 11412, "ep_reward": 792.357177734375, "reward": 0.8563179969787598, "action": -1.4120662212371826}
{"mode": "train", "epochs": 6, "timestep": 11413, "ep_reward": 793.1929931640625, "reward": 0.8358415365219116, "action": -1.1366920471191406}
{"mode": "train", "epochs": 6, "timestep": 11414, "ep_reward": 793.9886474609375, "reward": 0.7956376075744629, "action": -0.946594774723053}
{"mode": "train", "epochs": 6, "timestep": 11415, "ep_reward": 794.7185668945312, "reward": 0.7299107313156128, "action": -1.0043666362762451}
{"mode": "train", "epochs": 6, "timestep": 11416, "ep_reward": 795.3478393554688, "reward": 0.6293021440505981, "action": -1.4643604755401611}
{"mode": "train", "epochs": 6, "timestep": 11417, "ep_reward": 795.8287353515625, "reward": 0.4809179902076721, "action": -0.1533188819885254}
{"mode": "train", "epochs": 6, "timestep": 11418, "ep_reward": 796.182861328125, "reward": 0.3541044592857361, "action": -1.243344783782959}
{"mode": "train", "epochs": 6, "timestep": 11419, "ep_reward": 796.4277954101562, "reward": 0.24496370553970337, "action": -1.1521937847137451}
{"mode": "train", "epochs": 6, "timestep": 11420, "ep_reward": 796.5436401367188, "reward": 0.11586576700210571, "action": -0.6590735912322998}
{"mode": "train", "epochs": 6, "timestep": 11421, "ep_reward": 796.54296875, "reward": -0.0006579160690307617, "action": -0.1847197413444519}
{"mode": "train", "epochs": 6, "timestep": 11422, "ep_reward": 796.6875610351562, "reward": 0.14460331201553345, "action": -0.7444643974304199}
{"mode": "train", "epochs": 6, "timestep": 11423, "ep_reward": 796.974609375, "reward": 0.2870340347290039, "action": -1.5635013580322266}
{"mode": "train", "epochs": 6, "timestep": 11424, "ep_reward": 797.3912963867188, "reward": 0.41670024394989014, "action": -1.1412004232406616}
{"mode": "train", "epochs": 6, "timestep": 11425, "ep_reward": 797.93212890625, "reward": 0.5408327579498291, "action": -1.2072337865829468}
{"mode": "train", "epochs": 6, "timestep": 11426, "ep_reward": 798.5772705078125, "reward": 0.6451196670532227, "action": -1.300786018371582}
{"mode": "train", "epochs": 6, "timestep": 11427, "ep_reward": 799.303466796875, "reward": 0.7261903882026672, "action": -0.6190511584281921}
{"mode": "train", "epochs": 6, "timestep": 11428, "ep_reward": 800.0947875976562, "reward": 0.7913178205490112, "action": -0.5251250267028809}
{"mode": "train", "epochs": 6, "timestep": 11429, "ep_reward": 800.9306030273438, "reward": 0.8357883095741272, "action": -0.2868924140930176}
{"mode": "train", "epochs": 6, "timestep": 11430, "ep_reward": 801.7940063476562, "reward": 0.8634040951728821, "action": -1.451586127281189}
{"mode": "train", "epochs": 6, "timestep": 11431, "ep_reward": 802.65869140625, "reward": 0.8646652698516846, "action": -0.2862650752067566}
{"mode": "train", "epochs": 6, "timestep": 11432, "ep_reward": 803.517578125, "reward": 0.8589147925376892, "action": -1.6097049713134766}
{"mode": "train", "epochs": 6, "timestep": 11433, "ep_reward": 804.3399658203125, "reward": 0.8224083185195923, "action": -0.5778100490570068}
{"mode": "train", "epochs": 6, "timestep": 11434, "ep_reward": 805.1117553710938, "reward": 0.771772027015686, "action": -0.677200436592102}
{"mode": "train", "epochs": 6, "timestep": 11435, "ep_reward": 805.8029174804688, "reward": 0.6911607980728149, "action": -1.0460200309753418}
{"mode": "train", "epochs": 6, "timestep": 11436, "ep_reward": 806.3729858398438, "reward": 0.5700628757476807, "action": -0.5105027556419373}
{"mode": "train", "epochs": 6, "timestep": 11437, "ep_reward": 806.788818359375, "reward": 0.41581058502197266, "action": -1.6358109712600708}
{"mode": "train", "epochs": 6, "timestep": 11438, "ep_reward": 807.083740234375, "reward": 0.2949070930480957, "action": -1.9875696897506714}
{"mode": "train", "epochs": 6, "timestep": 11439, "ep_reward": 807.2583618164062, "reward": 0.17464399337768555, "action": -1.1750695705413818}
{"mode": "train", "epochs": 6, "timestep": 11440, "ep_reward": 807.2926025390625, "reward": 0.03426647186279297, "action": -0.8065734505653381}
{"mode": "train", "epochs": 6, "timestep": 11441, "ep_reward": 807.3760375976562, "reward": 0.08343243598937988, "action": -1.1142549514770508}
{"mode": "train", "epochs": 6, "timestep": 11442, "ep_reward": 807.5958251953125, "reward": 0.21980774402618408, "action": -0.6391452550888062}
{"mode": "train", "epochs": 6, "timestep": 11443, "ep_reward": 807.9599609375, "reward": 0.3641347289085388, "action": -0.9062801003456116}
{"mode": "train", "epochs": 6, "timestep": 11444, "ep_reward": 808.4561157226562, "reward": 0.4961734414100647, "action": -1.4573731422424316}
{"mode": "train", "epochs": 6, "timestep": 11445, "ep_reward": 809.0615844726562, "reward": 0.6054468154907227, "action": -0.8810537457466125}
{"mode": "train", "epochs": 6, "timestep": 11446, "ep_reward": 809.76171875, "reward": 0.7001405954360962, "action": -1.2713990211486816}
{"mode": "train", "epochs": 6, "timestep": 11447, "ep_reward": 810.5298461914062, "reward": 0.7681335210800171, "action": -1.3305118083953857}
{"mode": "train", "epochs": 6, "timestep": 11448, "ep_reward": 811.3446655273438, "reward": 0.8148323893547058, "action": -0.8258388638496399}
{"mode": "train", "epochs": 6, "timestep": 11449, "ep_reward": 812.1915893554688, "reward": 0.8469203114509583, "action": -0.7777562141418457}
{"mode": "train", "epochs": 6, "timestep": 11450, "ep_reward": 813.0532836914062, "reward": 0.8617143034934998, "action": -0.2903137803077698}
{"mode": "train", "epochs": 6, "timestep": 11451, "ep_reward": 813.9168701171875, "reward": 0.86357182264328, "action": -1.769197702407837}
{"mode": "train", "epochs": 6, "timestep": 11452, "ep_reward": 814.7512817382812, "reward": 0.8343914747238159, "action": -0.4475780129432678}
{"mode": "train", "epochs": 6, "timestep": 11453, "ep_reward": 815.546630859375, "reward": 0.7953323721885681, "action": -0.7153850793838501}
{"mode": "train", "epochs": 6, "timestep": 11454, "ep_reward": 816.2737426757812, "reward": 0.7271149754524231, "action": -0.5058854222297668}
{"mode": "train", "epochs": 6, "timestep": 11455, "ep_reward": 816.9024047851562, "reward": 0.6286361813545227, "action": -1.0288232564926147}
{"mode": "train", "epochs": 6, "timestep": 11456, "ep_reward": 817.386962890625, "reward": 0.4845882058143616, "action": -1.2609766721725464}
{"mode": "train", "epochs": 6, "timestep": 11457, "ep_reward": 817.7269897460938, "reward": 0.3400111198425293, "action": -1.9405152797698975}
{"mode": "train", "epochs": 6, "timestep": 11458, "ep_reward": 817.9552612304688, "reward": 0.22826772928237915, "action": -0.8817011117935181}
{"mode": "train", "epochs": 6, "timestep": 11459, "ep_reward": 818.051513671875, "reward": 0.09622514247894287, "action": -1.608227014541626}
{"mode": "train", "epochs": 6, "timestep": 11460, "ep_reward": 818.0721435546875, "reward": 0.02065497636795044, "action": -0.39477890729904175}
{"mode": "train", "epochs": 6, "timestep": 11461, "ep_reward": 818.2361450195312, "reward": 0.16398173570632935, "action": -0.7130177021026611}
{"mode": "train", "epochs": 6, "timestep": 11462, "ep_reward": 818.543212890625, "reward": 0.3070910573005676, "action": -0.9884783625602722}
{"mode": "train", "epochs": 6, "timestep": 11463, "ep_reward": 818.985595703125, "reward": 0.44240325689315796, "action": -1.0717219114303589}
{"mode": "train", "epochs": 6, "timestep": 11464, "ep_reward": 819.5491943359375, "reward": 0.563611626625061, "action": -0.7541738748550415}
{"mode": "train", "epochs": 6, "timestep": 11465, "ep_reward": 820.2177124023438, "reward": 0.6684969663619995, "action": -0.2738857865333557}
{"mode": "train", "epochs": 6, "timestep": 11466, "ep_reward": 820.972412109375, "reward": 0.7547109127044678, "action": -1.6036837100982666}
{"mode": "train", "epochs": 6, "timestep": 11467, "ep_reward": 821.7792358398438, "reward": 0.8067996501922607, "action": -0.874168872833252}
{"mode": "train", "epochs": 6, "timestep": 11468, "ep_reward": 822.6261596679688, "reward": 0.8469374179840088, "action": -0.8240255117416382}
{"mode": "train", "epochs": 6, "timestep": 11469, "ep_reward": 823.4967651367188, "reward": 0.8706000447273254, "action": -0.6515157222747803}
{"mode": "train", "epochs": 6, "timestep": 11470, "ep_reward": 824.3771362304688, "reward": 0.8803473711013794, "action": -0.45971572399139404}
{"mode": "train", "epochs": 6, "timestep": 11471, "ep_reward": 825.253662109375, "reward": 0.876517653465271, "action": -1.932557463645935}
{"mode": "train", "epochs": 6, "timestep": 11472, "ep_reward": 826.0972290039062, "reward": 0.8435713648796082, "action": -1.2636001110076904}
{"mode": "train", "epochs": 6, "timestep": 11473, "ep_reward": 826.8914794921875, "reward": 0.7942546010017395, "action": -0.5849992036819458}
{"mode": "train", "epochs": 6, "timestep": 11474, "ep_reward": 827.6160888671875, "reward": 0.7245848178863525, "action": -1.3270678520202637}
{"mode": "train", "epochs": 6, "timestep": 11475, "ep_reward": 828.2283935546875, "reward": 0.6123263835906982, "action": -1.4657220840454102}
{"mode": "train", "epochs": 6, "timestep": 11476, "ep_reward": 828.6845092773438, "reward": 0.4561208486557007, "action": -0.6253546476364136}
{"mode": "train", "epochs": 6, "timestep": 11477, "ep_reward": 829.010986328125, "reward": 0.3264511227607727, "action": -1.3074965476989746}
{"mode": "train", "epochs": 6, "timestep": 11478, "ep_reward": 829.2229614257812, "reward": 0.2119762897491455, "action": -0.06177443265914917}
{"mode": "train", "epochs": 6, "timestep": 11479, "ep_reward": 829.3002319335938, "reward": 0.07727783918380737, "action": -1.373104453086853}
{"mode": "train", "epochs": 6, "timestep": 11480, "ep_reward": 829.3408203125, "reward": 0.04060721397399902, "action": -0.9970903396606445}
{"mode": "train", "epochs": 6, "timestep": 11481, "ep_reward": 829.5210571289062, "reward": 0.1802341341972351, "action": -0.4015728235244751}
{"mode": "train", "epochs": 6, "timestep": 11482, "ep_reward": 829.8487548828125, "reward": 0.3276855945587158, "action": -1.0714020729064941}
{"mode": "train", "epochs": 6, "timestep": 11483, "ep_reward": 830.3091430664062, "reward": 0.4603927731513977, "action": -1.1409497261047363}
{"mode": "train", "epochs": 6, "timestep": 11484, "ep_reward": 830.887451171875, "reward": 0.5783113837242126, "action": -1.1326501369476318}
{"mode": "train", "epochs": 6, "timestep": 11485, "ep_reward": 831.5639038085938, "reward": 0.6764345169067383, "action": -0.4421609044075012}
{"mode": "train", "epochs": 6, "timestep": 11486, "ep_reward": 832.3226928710938, "reward": 0.7587920427322388, "action": -1.2992734909057617}
{"mode": "train", "epochs": 6, "timestep": 11487, "ep_reward": 833.1338500976562, "reward": 0.8111571073532104, "action": -1.476148009300232}
{"mode": "train", "epochs": 6, "timestep": 11488, "ep_reward": 833.9774780273438, "reward": 0.843617856502533, "action": -0.8933867812156677}
{"mode": "train", "epochs": 6, "timestep": 11489, "ep_reward": 834.8414916992188, "reward": 0.864001989364624, "action": -1.2974669933319092}
{"mode": "train", "epochs": 6, "timestep": 11490, "ep_reward": 835.7061157226562, "reward": 0.8646485209465027, "action": -1.145405650138855}
{"mode": "train", "epochs": 6, "timestep": 11491, "ep_reward": 836.5553588867188, "reward": 0.8492521047592163, "action": -0.9886637926101685}
{"mode": "train", "epochs": 6, "timestep": 11492, "ep_reward": 837.3703002929688, "reward": 0.8149515986442566, "action": -1.5470845699310303}
{"mode": "train", "epochs": 6, "timestep": 11493, "ep_reward": 838.1196899414062, "reward": 0.7493873834609985, "action": -0.7358905076980591}
{"mode": "train", "epochs": 6, "timestep": 11494, "ep_reward": 838.77978515625, "reward": 0.6600958108901978, "action": -1.4871530532836914}
{"mode": "train", "epochs": 6, "timestep": 11495, "ep_reward": 839.3017578125, "reward": 0.5219774842262268, "action": -0.19595301151275635}
{"mode": "train", "epochs": 6, "timestep": 11496, "ep_reward": 839.6759033203125, "reward": 0.37413614988327026, "action": -0.6644412875175476}
{"mode": "train", "epochs": 6, "timestep": 11497, "ep_reward": 839.9450073242188, "reward": 0.2691015601158142, "action": -0.5586991310119629}
{"mode": "train", "epochs": 6, "timestep": 11498, "ep_reward": 840.0889892578125, "reward": 0.14399707317352295, "action": -1.1446675062179565}
{"mode": "train", "epochs": 6, "timestep": 11499, "ep_reward": 840.087890625, "reward": -0.0010864734649658203, "action": -1.40829598903656}
{"mode": "train", "epochs": 6, "timestep": 11500, "ep_reward": 840.2040405273438, "reward": 0.11615705490112305, "action": -0.42211389541625977}
{"mode": "train", "epochs": 6, "timestep": 11501, "ep_reward": 840.4661254882812, "reward": 0.2620566487312317, "action": -0.6571925282478333}
{"mode": "train", "epochs": 6, "timestep": 11502, "ep_reward": 840.8692016601562, "reward": 0.4030511975288391, "action": -1.19331955909729}
{"mode": "train", "epochs": 6, "timestep": 11503, "ep_reward": 841.3961791992188, "reward": 0.5269991755485535, "action": -1.1714274883270264}
{"mode": "train", "epochs": 6, "timestep": 11504, "ep_reward": 842.0302734375, "reward": 0.6340994834899902, "action": -1.429372787475586}
{"mode": "train", "epochs": 6, "timestep": 11505, "ep_reward": 842.7479248046875, "reward": 0.7176770567893982, "action": -0.8889977931976318}
{"mode": "train", "epochs": 6, "timestep": 11506, "ep_reward": 843.532958984375, "reward": 0.7850340008735657, "action": -1.137416124343872}
{"mode": "train", "epochs": 6, "timestep": 11507, "ep_reward": 844.3627319335938, "reward": 0.8297879695892334, "action": -0.3049299716949463}
{"mode": "train", "epochs": 6, "timestep": 11508, "ep_reward": 845.2261962890625, "reward": 0.8634671568870544, "action": -0.9876722097396851}
{"mode": "train", "epochs": 6, "timestep": 11509, "ep_reward": 846.1013793945312, "reward": 0.8751952648162842, "action": -1.4384909868240356}
{"mode": "train", "epochs": 6, "timestep": 11510, "ep_reward": 846.9691772460938, "reward": 0.8678210973739624, "action": -0.8229821920394897}
{"mode": "train", "epochs": 6, "timestep": 11511, "ep_reward": 847.8175659179688, "reward": 0.8484184741973877, "action": -0.7822458744049072}
{"mode": "train", "epochs": 6, "timestep": 11512, "ep_reward": 848.6266479492188, "reward": 0.8090814352035522, "action": -1.2599986791610718}
{"mode": "train", "epochs": 6, "timestep": 11513, "ep_reward": 849.3656005859375, "reward": 0.738980770111084, "action": -1.2924777269363403}
{"mode": "train", "epochs": 6, "timestep": 11514, "ep_reward": 850.0001220703125, "reward": 0.6345231533050537, "action": -0.9943872094154358}
{"mode": "train", "epochs": 6, "timestep": 11515, "ep_reward": 850.4937133789062, "reward": 0.49358123540878296, "action": -0.8235378861427307}
{"mode": "train", "epochs": 6, "timestep": 11516, "ep_reward": 850.8424682617188, "reward": 0.3487781882286072, "action": -0.49928969144821167}
{"mode": "train", "epochs": 6, "timestep": 11517, "ep_reward": 851.080810546875, "reward": 0.23833584785461426, "action": -1.8707062005996704}
{"mode": "train", "epochs": 6, "timestep": 11518, "ep_reward": 851.1890869140625, "reward": 0.10827898979187012, "action": -0.7708157300949097}
{"mode": "train", "epochs": 6, "timestep": 11519, "ep_reward": 851.1967163085938, "reward": 0.007626533508300781, "action": -1.2346490621566772}
{"mode": "train", "epochs": 6, "timestep": 11520, "ep_reward": 851.3482666015625, "reward": 0.15156161785125732, "action": -1.1120870113372803}
{"mode": "train", "epochs": 6, "timestep": 11521, "ep_reward": 851.6380615234375, "reward": 0.2897758483886719, "action": -0.713642954826355}
{"mode": "train", "epochs": 6, "timestep": 11522, "ep_reward": 852.0682983398438, "reward": 0.4302142262458801, "action": -1.1095366477966309}
{"mode": "train", "epochs": 6, "timestep": 11523, "ep_reward": 852.6210327148438, "reward": 0.5527515411376953, "action": -0.4608456492424011}
{"mode": "train", "epochs": 6, "timestep": 11524, "ep_reward": 853.28369140625, "reward": 0.6626827716827393, "action": -0.9968816041946411}
{"mode": "train", "epochs": 6, "timestep": 11525, "ep_reward": 854.0274047851562, "reward": 0.7437365055084229, "action": 0.1246950626373291}
{"mode": "train", "epochs": 6, "timestep": 11526, "ep_reward": 854.84033203125, "reward": 0.8129444122314453, "action": -0.3857063055038452}
{"mode": "train", "epochs": 6, "timestep": 11527, "ep_reward": 855.6973266601562, "reward": 0.8569959998130798, "action": -1.4438024759292603}
{"mode": "train", "epochs": 6, "timestep": 11528, "ep_reward": 856.5740356445312, "reward": 0.8766857981681824, "action": -1.0567846298217773}
{"mode": "train", "epochs": 6, "timestep": 11529, "ep_reward": 857.459228515625, "reward": 0.8851805329322815, "action": -1.7471628189086914}
{"mode": "train", "epochs": 6, "timestep": 11530, "ep_reward": 858.3330688476562, "reward": 0.8738464713096619, "action": -1.1819299459457397}
{"mode": "train", "epochs": 6, "timestep": 11531, "ep_reward": 859.1831665039062, "reward": 0.850125789642334, "action": -1.5421562194824219}
{"mode": "train", "epochs": 6, "timestep": 11532, "ep_reward": 859.9852294921875, "reward": 0.8020901679992676, "action": -0.3505726456642151}
{"mode": "train", "epochs": 6, "timestep": 11533, "ep_reward": 860.7249755859375, "reward": 0.7397336363792419, "action": -0.5268275737762451}
{"mode": "train", "epochs": 6, "timestep": 11534, "ep_reward": 861.3695068359375, "reward": 0.6445320844650269, "action": -0.47161978483200073}
{"mode": "train", "epochs": 6, "timestep": 11535, "ep_reward": 861.8829956054688, "reward": 0.513500452041626, "action": -1.440190076828003}
{"mode": "train", "epochs": 6, "timestep": 11536, "ep_reward": 862.2314453125, "reward": 0.3484206795692444, "action": -0.15003818273544312}
{"mode": "train", "epochs": 6, "timestep": 11537, "ep_reward": 862.469482421875, "reward": 0.23804545402526855, "action": -1.007497787475586}
{"mode": "train", "epochs": 6, "timestep": 11538, "ep_reward": 862.5772705078125, "reward": 0.10779619216918945, "action": -0.0031130313873291016}
{"mode": "train", "epochs": 6, "timestep": 11539, "ep_reward": 862.5853881835938, "reward": 0.00809323787689209, "action": -1.783539056777954}
{"mode": "train", "epochs": 6, "timestep": 11540, "ep_reward": 862.7373657226562, "reward": 0.15198057889938354, "action": -1.572500467300415}
{"mode": "train", "epochs": 6, "timestep": 11541, "ep_reward": 863.0216674804688, "reward": 0.2843259572982788, "action": -1.7366960048675537}
{"mode": "train", "epochs": 6, "timestep": 11542, "ep_reward": 863.4351196289062, "reward": 0.41345179080963135, "action": -1.4480984210968018}
{"mode": "train", "epochs": 6, "timestep": 11543, "ep_reward": 863.9703979492188, "reward": 0.5352805256843567, "action": -0.5197376012802124}
{"mode": "train", "epochs": 6, "timestep": 11544, "ep_reward": 864.6182250976562, "reward": 0.6478103399276733, "action": 0.05507159233093262}
{"mode": "train", "epochs": 6, "timestep": 11545, "ep_reward": 865.3587646484375, "reward": 0.7405680418014526, "action": -1.3446052074432373}
{"mode": "train", "epochs": 6, "timestep": 11546, "ep_reward": 866.154052734375, "reward": 0.7953126430511475, "action": 0.2839937210083008}
{"mode": "train", "epochs": 6, "timestep": 11547, "ep_reward": 866.9981689453125, "reward": 0.8441242575645447, "action": -1.3986653089523315}
{"mode": "train", "epochs": 6, "timestep": 11548, "ep_reward": 867.8579711914062, "reward": 0.8598243594169617, "action": -0.6118412613868713}
{"mode": "train", "epochs": 6, "timestep": 11549, "ep_reward": 868.7235717773438, "reward": 0.8655793070793152, "action": -0.8580782413482666}
{"mode": "train", "epochs": 6, "timestep": 11550, "ep_reward": 869.5756225585938, "reward": 0.8520461916923523, "action": -1.0215152502059937}
{"mode": "train", "epochs": 6, "timestep": 11551, "ep_reward": 870.3927612304688, "reward": 0.8171331882476807, "action": -1.5771710872650146}
{"mode": "train", "epochs": 6, "timestep": 11552, "ep_reward": 871.1439819335938, "reward": 0.7511979341506958, "action": -0.8026145100593567}
{"mode": "train", "epochs": 6, "timestep": 11553, "ep_reward": 871.80517578125, "reward": 0.6611802577972412, "action": -1.1736054420471191}
{"mode": "train", "epochs": 6, "timestep": 11554, "ep_reward": 872.3330078125, "reward": 0.5278509259223938, "action": -0.4499768614768982}
{"mode": "train", "epochs": 6, "timestep": 11555, "ep_reward": 872.70703125, "reward": 0.3740151524543762, "action": -0.9490242004394531}
{"mode": "train", "epochs": 6, "timestep": 11556, "ep_reward": 872.9760131835938, "reward": 0.2689880132675171, "action": -0.5832529067993164}
{"mode": "train", "epochs": 6, "timestep": 11557, "ep_reward": 873.119873046875, "reward": 0.14387845993041992, "action": -1.0526376962661743}
{"mode": "train", "epochs": 6, "timestep": 11558, "ep_reward": 873.1187744140625, "reward": -0.001114487648010254, "action": -0.1417614221572876}
{"mode": "train", "epochs": 6, "timestep": 11559, "ep_reward": 873.2350463867188, "reward": 0.11629575490951538, "action": -0.3477351665496826}
{"mode": "train", "epochs": 6, "timestep": 11560, "ep_reward": 873.4981689453125, "reward": 0.26310473680496216, "action": -0.750744104385376}
{"mode": "train", "epochs": 6, "timestep": 11561, "ep_reward": 873.9008178710938, "reward": 0.40264731645584106, "action": -1.9308412075042725}
{"mode": "train", "epochs": 6, "timestep": 11562, "ep_reward": 874.419189453125, "reward": 0.5183756351470947, "action": -0.8507483005523682}
{"mode": "train", "epochs": 6, "timestep": 11563, "ep_reward": 875.0497436523438, "reward": 0.6305388808250427, "action": -0.8675251603126526}
{"mode": "train", "epochs": 6, "timestep": 11564, "ep_reward": 875.7698364257812, "reward": 0.7200900316238403, "action": -0.3373623490333557}
{"mode": "train", "epochs": 6, "timestep": 11565, "ep_reward": 876.5616455078125, "reward": 0.7917867302894592, "action": -0.7840007543563843}
{"mode": "train", "epochs": 6, "timestep": 11566, "ep_reward": 877.4000854492188, "reward": 0.8384221792221069, "action": -1.1243377923965454}
{"mode": "train", "epochs": 6, "timestep": 11567, "ep_reward": 878.2649536132812, "reward": 0.8648693561553955, "action": -1.042771339416504}
{"mode": "train", "epochs": 6, "timestep": 11568, "ep_reward": 879.1414184570312, "reward": 0.8764855861663818, "action": -1.437201976776123}
{"mode": "train", "epochs": 6, "timestep": 11569, "ep_reward": 880.0110473632812, "reward": 0.8696279525756836, "action": -1.2920985221862793}
{"mode": "train", "epochs": 6, "timestep": 11570, "ep_reward": 880.857666015625, "reward": 0.8465955853462219, "action": -1.624386191368103}
{"mode": "train", "epochs": 6, "timestep": 11571, "ep_reward": 881.6566162109375, "reward": 0.7989211082458496, "action": -0.8728582262992859}
{"mode": "train", "epochs": 6, "timestep": 11572, "ep_reward": 882.3878784179688, "reward": 0.731271505355835, "action": -1.1660619974136353}
{"mode": "train", "epochs": 6, "timestep": 11573, "ep_reward": 883.0142211914062, "reward": 0.6263731718063354, "action": -0.761643648147583}
{"mode": "train", "epochs": 6, "timestep": 11574, "ep_reward": 883.5009155273438, "reward": 0.4866737723350525, "action": -0.6169451475143433}
{"mode": "train", "epochs": 6, "timestep": 11575, "ep_reward": 883.8465576171875, "reward": 0.34563690423965454, "action": -1.3927438259124756}
{"mode": "train", "epochs": 6, "timestep": 11576, "ep_reward": 884.0812377929688, "reward": 0.23466521501541138, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 11577, "ep_reward": 884.185302734375, "reward": 0.10405737161636353, "action": -0.49665433168411255}
{"mode": "train", "epochs": 6, "timestep": 11578, "ep_reward": 884.1976318359375, "reward": 0.012318313121795654, "action": -0.8141509294509888}
{"mode": "train", "epochs": 6, "timestep": 11579, "ep_reward": 884.3531494140625, "reward": 0.15553951263427734, "action": -1.4622507095336914}
{"mode": "train", "epochs": 6, "timestep": 11580, "ep_reward": 884.642578125, "reward": 0.2894224524497986, "action": -1.252568006515503}
{"mode": "train", "epochs": 6, "timestep": 11581, "ep_reward": 885.0667114257812, "reward": 0.4241247773170471, "action": 0.008680105209350586}
{"mode": "train", "epochs": 6, "timestep": 11582, "ep_reward": 885.6275024414062, "reward": 0.5607643723487854, "action": -1.0161820650100708}
{"mode": "train", "epochs": 6, "timestep": 11583, "ep_reward": 886.2909545898438, "reward": 0.6634609699249268, "action": -0.7849628329277039}
{"mode": "train", "epochs": 6, "timestep": 11584, "ep_reward": 887.036865234375, "reward": 0.7459161281585693, "action": -0.9046966433525085}
{"mode": "train", "epochs": 6, "timestep": 11585, "ep_reward": 887.8419799804688, "reward": 0.8051048517227173, "action": -0.8183015584945679}
{"mode": "train", "epochs": 6, "timestep": 11586, "ep_reward": 888.6874389648438, "reward": 0.8454685211181641, "action": -0.8287112712860107}
{"mode": "train", "epochs": 6, "timestep": 11587, "ep_reward": 889.5559692382812, "reward": 0.8685510158538818, "action": -0.8750287890434265}
{"mode": "train", "epochs": 6, "timestep": 11588, "ep_reward": 890.431640625, "reward": 0.8756697177886963, "action": -0.43485093116760254}
{"mode": "train", "epochs": 6, "timestep": 11589, "ep_reward": 891.3023681640625, "reward": 0.8707319498062134, "action": -1.8176288604736328}
{"mode": "train", "epochs": 6, "timestep": 11590, "ep_reward": 892.1387329101562, "reward": 0.8363481760025024, "action": -1.6091575622558594}
{"mode": "train", "epochs": 6, "timestep": 11591, "ep_reward": 892.9188232421875, "reward": 0.7800780534744263, "action": -1.1384471654891968}
{"mode": "train", "epochs": 6, "timestep": 11592, "ep_reward": 893.617431640625, "reward": 0.6986006498336792, "action": -0.36336076259613037}
{"mode": "train", "epochs": 6, "timestep": 11593, "ep_reward": 894.2086181640625, "reward": 0.5911968946456909, "action": -0.1296406388282776}
{"mode": "train", "epochs": 6, "timestep": 11594, "ep_reward": 894.6578369140625, "reward": 0.44924396276474, "action": -1.760718584060669}
{"mode": "train", "epochs": 6, "timestep": 11595, "ep_reward": 894.9703979492188, "reward": 0.31256234645843506, "action": -0.4690024256706238}
{"mode": "train", "epochs": 6, "timestep": 11596, "ep_reward": 895.165771484375, "reward": 0.19534385204315186, "action": -0.40699100494384766}
{"mode": "train", "epochs": 6, "timestep": 11597, "ep_reward": 895.2238159179688, "reward": 0.05804431438446045, "action": -1.1904674768447876}
{"mode": "train", "epochs": 6, "timestep": 11598, "ep_reward": 895.2840576171875, "reward": 0.06023532152175903, "action": -0.3484278917312622}
{"mode": "train", "epochs": 6, "timestep": 11599, "ep_reward": 895.4893798828125, "reward": 0.20534855127334595, "action": -1.1536519527435303}
{"mode": "train", "epochs": 6, "timestep": 11600, "ep_reward": 895.83154296875, "reward": 0.3421333432197571, "action": -0.5698754787445068}
{"mode": "train", "epochs": 6, "timestep": 11601, "ep_reward": 896.3114624023438, "reward": 0.4799293875694275, "action": -0.6051912307739258}
{"mode": "train", "epochs": 6, "timestep": 11602, "ep_reward": 896.9120483398438, "reward": 0.6005901098251343, "action": -1.433397889137268}
{"mode": "train", "epochs": 6, "timestep": 11603, "ep_reward": 897.603515625, "reward": 0.6914792060852051, "action": -0.9046313166618347}
{"mode": "train", "epochs": 6, "timestep": 11604, "ep_reward": 898.3698120117188, "reward": 0.7663019299507141, "action": -1.4722297191619873}
{"mode": "train", "epochs": 6, "timestep": 11605, "ep_reward": 899.1852416992188, "reward": 0.8154301047325134, "action": -0.6079529523849487}
{"mode": "train", "epochs": 6, "timestep": 11606, "ep_reward": 900.038818359375, "reward": 0.8535752892494202, "action": -1.7293834686279297}
{"mode": "train", "epochs": 6, "timestep": 11607, "ep_reward": 900.90478515625, "reward": 0.86598801612854, "action": -0.9620057344436646}
{"mode": "train", "epochs": 6, "timestep": 11608, "ep_reward": 901.7738037109375, "reward": 0.8690026998519897, "action": 0.025764942169189453}
{"mode": "train", "epochs": 6, "timestep": 11609, "ep_reward": 902.6378784179688, "reward": 0.8640693426132202, "action": -0.7112914323806763}
{"mode": "train", "epochs": 6, "timestep": 11610, "ep_reward": 903.4727783203125, "reward": 0.8348863124847412, "action": -1.523538589477539}
{"mode": "train", "epochs": 6, "timestep": 11611, "ep_reward": 904.2476806640625, "reward": 0.7749225497245789, "action": -1.9649560451507568}
{"mode": "train", "epochs": 6, "timestep": 11612, "ep_reward": 904.9259033203125, "reward": 0.6782186031341553, "action": -1.2033758163452148}
{"mode": "train", "epochs": 6, "timestep": 11613, "ep_reward": 905.4766235351562, "reward": 0.5507311224937439, "action": -1.3410484790802002}
{"mode": "train", "epochs": 6, "timestep": 11614, "ep_reward": 905.8637084960938, "reward": 0.3871006965637207, "action": -1.3483757972717285}
{"mode": "train", "epochs": 6, "timestep": 11615, "ep_reward": 906.1484985351562, "reward": 0.28481125831604004, "action": -1.5357778072357178}
{"mode": "train", "epochs": 6, "timestep": 11616, "ep_reward": 906.3110961914062, "reward": 0.162617027759552, "action": -1.1767523288726807}
{"mode": "train", "epochs": 6, "timestep": 11617, "ep_reward": 906.3314819335938, "reward": 0.02039623260498047, "action": -0.9203191995620728}
{"mode": "train", "epochs": 6, "timestep": 11618, "ep_reward": 906.4280395507812, "reward": 0.09658759832382202, "action": -0.04942852258682251}
{"mode": "train", "epochs": 6, "timestep": 11619, "ep_reward": 906.6743774414062, "reward": 0.24636250734329224, "action": -1.7924575805664062}
{"mode": "train", "epochs": 6, "timestep": 11620, "ep_reward": 907.0480346679688, "reward": 0.37367504835128784, "action": -0.2821088433265686}
{"mode": "train", "epochs": 6, "timestep": 11621, "ep_reward": 907.56005859375, "reward": 0.5120360851287842, "action": -0.8404490947723389}
{"mode": "train", "epochs": 6, "timestep": 11622, "ep_reward": 908.1851196289062, "reward": 0.6250908970832825, "action": -1.3699901103973389}
{"mode": "train", "epochs": 6, "timestep": 11623, "ep_reward": 908.8964233398438, "reward": 0.7112761735916138, "action": -1.9520946741104126}
{"mode": "train", "epochs": 6, "timestep": 11624, "ep_reward": 909.6677856445312, "reward": 0.7713822722434998, "action": -1.0515780448913574}
{"mode": "train", "epochs": 6, "timestep": 11625, "ep_reward": 910.4879760742188, "reward": 0.8202109336853027, "action": -1.143204927444458}
{"mode": "train", "epochs": 6, "timestep": 11626, "ep_reward": 911.3374633789062, "reward": 0.8494863510131836, "action": -1.096278429031372}
{"mode": "train", "epochs": 6, "timestep": 11627, "ep_reward": 912.1995239257812, "reward": 0.8620648384094238, "action": -0.8497307896614075}
{"mode": "train", "epochs": 6, "timestep": 11628, "ep_reward": 913.0593872070312, "reward": 0.8598602414131165, "action": -0.9166232347488403}
{"mode": "train", "epochs": 6, "timestep": 11629, "ep_reward": 913.8983154296875, "reward": 0.8389054536819458, "action": -0.4119318127632141}
{"mode": "train", "epochs": 6, "timestep": 11630, "ep_reward": 914.6998291015625, "reward": 0.8015155792236328, "action": -1.1031054258346558}
{"mode": "train", "epochs": 6, "timestep": 11631, "ep_reward": 915.4306640625, "reward": 0.7308275699615479, "action": -1.1560322046279907}
{"mode": "train", "epochs": 6, "timestep": 11632, "ep_reward": 916.0558471679688, "reward": 0.625207781791687, "action": -1.5216286182403564}
{"mode": "train", "epochs": 6, "timestep": 11633, "ep_reward": 916.5289306640625, "reward": 0.4730597138404846, "action": -0.947067379951477}
{"mode": "train", "epochs": 6, "timestep": 11634, "ep_reward": 916.8704833984375, "reward": 0.34157222509384155, "action": -0.11367005109786987}
{"mode": "train", "epochs": 6, "timestep": 11635, "ep_reward": 917.1002197265625, "reward": 0.22973382472991943, "action": -1.6474530696868896}
{"mode": "train", "epochs": 6, "timestep": 11636, "ep_reward": 917.1983642578125, "reward": 0.09811621904373169, "action": -1.3757723569869995}
{"mode": "train", "epochs": 6, "timestep": 11637, "ep_reward": 917.217041015625, "reward": 0.018668413162231445, "action": -0.41927653551101685}
{"mode": "train", "epochs": 6, "timestep": 11638, "ep_reward": 917.3785400390625, "reward": 0.16147226095199585, "action": -1.7521494626998901}
{"mode": "train", "epochs": 6, "timestep": 11639, "ep_reward": 917.6703491210938, "reward": 0.2918015122413635, "action": -0.9523287415504456}
{"mode": "train", "epochs": 6, "timestep": 11640, "ep_reward": 918.1007080078125, "reward": 0.43036431074142456, "action": -1.2268580198287964}
{"mode": "train", "epochs": 6, "timestep": 11641, "ep_reward": 918.6528930664062, "reward": 0.5521945953369141, "action": -0.2973913550376892}
{"mode": "train", "epochs": 6, "timestep": 11642, "ep_reward": 919.316650390625, "reward": 0.6637696027755737, "action": -1.4344398975372314}
{"mode": "train", "epochs": 6, "timestep": 11643, "ep_reward": 920.0558471679688, "reward": 0.7391810417175293, "action": -1.3705756664276123}
{"mode": "train", "epochs": 6, "timestep": 11644, "ep_reward": 920.8495483398438, "reward": 0.7936968207359314, "action": -0.2341715693473816}
{"mode": "train", "epochs": 6, "timestep": 11645, "ep_reward": 921.6875610351562, "reward": 0.8380240201950073, "action": -0.5925162434577942}
{"mode": "train", "epochs": 6, "timestep": 11646, "ep_reward": 922.5476684570312, "reward": 0.8601056337356567, "action": -1.3029755353927612}
{"mode": "train", "epochs": 6, "timestep": 11647, "ep_reward": 923.40673828125, "reward": 0.8590856790542603, "action": -0.5273275971412659}
{"mode": "train", "epochs": 6, "timestep": 11648, "ep_reward": 924.2537231445312, "reward": 0.8469942212104797, "action": -0.8960497975349426}
{"mode": "train", "epochs": 6, "timestep": 11649, "ep_reward": 925.0648803710938, "reward": 0.8111607432365417, "action": -1.5909807682037354}
{"mode": "train", "epochs": 6, "timestep": 11650, "ep_reward": 925.8070678710938, "reward": 0.7422162294387817, "action": 0.09500539302825928}
{"mode": "train", "epochs": 6, "timestep": 11651, "ep_reward": 926.4674682617188, "reward": 0.660419225692749, "action": 0.14957934617996216}
{"mode": "train", "epochs": 6, "timestep": 11652, "ep_reward": 927.0128784179688, "reward": 0.5453989505767822, "action": -0.4859389066696167}
{"mode": "train", "epochs": 6, "timestep": 11653, "ep_reward": 927.397216796875, "reward": 0.384350061416626, "action": -1.1378538608551025}
{"mode": "train", "epochs": 6, "timestep": 11654, "ep_reward": 927.6636962890625, "reward": 0.26649314165115356, "action": -1.5107450485229492}
{"mode": "train", "epochs": 6, "timestep": 11655, "ep_reward": 927.8047485351562, "reward": 0.14107298851013184, "action": -1.1958571672439575}
{"mode": "train", "epochs": 6, "timestep": 11656, "ep_reward": 927.8002319335938, "reward": -0.004522919654846191, "action": -1.8445732593536377}
{"mode": "train", "epochs": 6, "timestep": 11657, "ep_reward": 927.9193725585938, "reward": 0.1191328763961792, "action": -0.6975947618484497}
{"mode": "train", "epochs": 6, "timestep": 11658, "ep_reward": 928.1810913085938, "reward": 0.2617074251174927, "action": -0.7051291465759277}
{"mode": "train", "epochs": 6, "timestep": 11659, "ep_reward": 928.5839233398438, "reward": 0.40280991792678833, "action": -0.49104058742523193}
{"mode": "train", "epochs": 6, "timestep": 11660, "ep_reward": 929.118896484375, "reward": 0.5349972248077393, "action": -1.3490530252456665}
{"mode": "train", "epochs": 6, "timestep": 11661, "ep_reward": 929.7577514648438, "reward": 0.6388817429542542, "action": -1.1425330638885498}
{"mode": "train", "epochs": 6, "timestep": 11662, "ep_reward": 930.4820556640625, "reward": 0.7243257761001587, "action": -0.6720982789993286}
{"mode": "train", "epochs": 6, "timestep": 11663, "ep_reward": 931.2744750976562, "reward": 0.7924216985702515, "action": -1.434370756149292}
{"mode": "train", "epochs": 6, "timestep": 11664, "ep_reward": 932.1083984375, "reward": 0.8339439034461975, "action": -0.6535047292709351}
{"mode": "train", "epochs": 6, "timestep": 11665, "ep_reward": 932.9732055664062, "reward": 0.8648107051849365, "action": -0.9663252830505371}
{"mode": "train", "epochs": 6, "timestep": 11666, "ep_reward": 933.8505249023438, "reward": 0.8773385286331177, "action": -1.0840733051300049}
{"mode": "train", "epochs": 6, "timestep": 11667, "ep_reward": 934.724365234375, "reward": 0.8738605976104736, "action": -0.8065038919448853}
{"mode": "train", "epochs": 6, "timestep": 11668, "ep_reward": 935.58056640625, "reward": 0.8562315702438354, "action": -1.5784858465194702}
{"mode": "train", "epochs": 6, "timestep": 11669, "ep_reward": 936.392333984375, "reward": 0.8117480874061584, "action": -1.2391154766082764}
{"mode": "train", "epochs": 6, "timestep": 11670, "ep_reward": 937.136474609375, "reward": 0.7441141605377197, "action": -0.6439707279205322}
{"mode": "train", "epochs": 6, "timestep": 11671, "ep_reward": 937.787353515625, "reward": 0.6508703231811523, "action": 0.19837504625320435}
{"mode": "train", "epochs": 6, "timestep": 11672, "ep_reward": 938.3201904296875, "reward": 0.5328637361526489, "action": -1.190779685974121}
{"mode": "train", "epochs": 6, "timestep": 11673, "ep_reward": 938.6807861328125, "reward": 0.3605955243110657, "action": -1.5705645084381104}
{"mode": "train", "epochs": 6, "timestep": 11674, "ep_reward": 938.9337158203125, "reward": 0.252906858921051, "action": -0.5396378040313721}
{"mode": "train", "epochs": 6, "timestep": 11675, "ep_reward": 939.0587158203125, "reward": 0.12500327825546265, "action": -1.250165581703186}
{"mode": "train", "epochs": 6, "timestep": 11676, "ep_reward": 939.047607421875, "reward": -0.011129975318908691, "action": -1.4085108041763306}
{"mode": "train", "epochs": 6, "timestep": 11677, "ep_reward": 939.1829223632812, "reward": 0.13528954982757568, "action": -0.8626759052276611}
{"mode": "train", "epochs": 6, "timestep": 11678, "ep_reward": 939.4589233398438, "reward": 0.2760184407234192, "action": -1.9666235446929932}
{"mode": "train", "epochs": 6, "timestep": 11679, "ep_reward": 939.8604736328125, "reward": 0.4015687108039856, "action": -1.096511960029602}
{"mode": "train", "epochs": 6, "timestep": 11680, "ep_reward": 940.3890380859375, "reward": 0.528545618057251, "action": -0.8796690106391907}
{"mode": "train", "epochs": 6, "timestep": 11681, "ep_reward": 941.027587890625, "reward": 0.6385753154754639, "action": -1.1347236633300781}
{"mode": "train", "epochs": 6, "timestep": 11682, "ep_reward": 941.7501831054688, "reward": 0.7225886583328247, "action": -0.8498232960700989}
{"mode": "train", "epochs": 6, "timestep": 11683, "ep_reward": 942.5364379882812, "reward": 0.786275327205658, "action": -1.7919063568115234}
{"mode": "train", "epochs": 6, "timestep": 11684, "ep_reward": 943.356689453125, "reward": 0.8202565312385559, "action": -0.9760516285896301}
{"mode": "train", "epochs": 6, "timestep": 11685, "ep_reward": 944.1991577148438, "reward": 0.8424593210220337, "action": -1.5412700176239014}
{"mode": "train", "epochs": 6, "timestep": 11686, "ep_reward": 945.0397338867188, "reward": 0.8405569791793823, "action": -1.5861456394195557}
{"mode": "train", "epochs": 6, "timestep": 11687, "ep_reward": 945.8572387695312, "reward": 0.8175039887428284, "action": -1.168610692024231}
{"mode": "train", "epochs": 6, "timestep": 11688, "ep_reward": 946.6309814453125, "reward": 0.7737516164779663, "action": -1.4104843139648438}
{"mode": "train", "epochs": 6, "timestep": 11689, "ep_reward": 947.3275756835938, "reward": 0.696566104888916, "action": -0.7419545650482178}
{"mode": "train", "epochs": 6, "timestep": 11690, "ep_reward": 947.9174194335938, "reward": 0.5898290872573853, "action": -1.1175990104675293}
{"mode": "train", "epochs": 6, "timestep": 11691, "ep_reward": 948.3523559570312, "reward": 0.43491482734680176, "action": 0.4956566095352173}
{"mode": "train", "epochs": 6, "timestep": 11692, "ep_reward": 948.6874389648438, "reward": 0.33510786294937134, "action": -1.1532163619995117}
{"mode": "train", "epochs": 6, "timestep": 11693, "ep_reward": 948.90966796875, "reward": 0.2222321629524231, "action": -0.7175041437149048}
{"mode": "train", "epochs": 6, "timestep": 11694, "ep_reward": 948.9989624023438, "reward": 0.08931058645248413, "action": -0.627849280834198}
{"mode": "train", "epochs": 6, "timestep": 11695, "ep_reward": 949.0271606445312, "reward": 0.02818167209625244, "action": -0.33320969343185425}
{"mode": "train", "epochs": 6, "timestep": 11696, "ep_reward": 949.19970703125, "reward": 0.1725415587425232, "action": -0.4022573232650757}
{"mode": "train", "epochs": 6, "timestep": 11697, "ep_reward": 949.5188598632812, "reward": 0.31918203830718994, "action": -0.6779906749725342}
{"mode": "train", "epochs": 6, "timestep": 11698, "ep_reward": 949.9754638671875, "reward": 0.4566164016723633, "action": -0.4296834468841553}
{"mode": "train", "epochs": 6, "timestep": 11699, "ep_reward": 950.5576782226562, "reward": 0.5822362899780273, "action": -1.1382958889007568}
{"mode": "train", "epochs": 6, "timestep": 11700, "ep_reward": 951.2374267578125, "reward": 0.6797419786453247, "action": -1.093827724456787}
{"mode": "train", "epochs": 6, "timestep": 11701, "ep_reward": 951.9942016601562, "reward": 0.7567960023880005, "action": -0.1029776930809021}
{"mode": "train", "epochs": 6, "timestep": 11702, "ep_reward": 952.8160400390625, "reward": 0.8218167424201965, "action": -0.06786471605300903}
{"mode": "train", "epochs": 6, "timestep": 11703, "ep_reward": 953.6835327148438, "reward": 0.8674886226654053, "action": -1.147949457168579}
{"mode": "train", "epochs": 6, "timestep": 11704, "ep_reward": 954.5733032226562, "reward": 0.8897914290428162, "action": -0.8286367654800415}
{"mode": "train", "epochs": 6, "timestep": 11705, "ep_reward": 955.4750366210938, "reward": 0.901759922504425, "action": -1.499527931213379}
{"mode": "train", "epochs": 6, "timestep": 11706, "ep_reward": 956.3718872070312, "reward": 0.8968328833580017, "action": -0.9841437339782715}
{"mode": "train", "epochs": 6, "timestep": 11707, "ep_reward": 957.2542114257812, "reward": 0.882307767868042, "action": -0.31481730937957764}
{"mode": "train", "epochs": 6, "timestep": 11708, "ep_reward": 958.11181640625, "reward": 0.8575848340988159, "action": -1.245500087738037}
{"mode": "train", "epochs": 6, "timestep": 11709, "ep_reward": 958.9170532226562, "reward": 0.8052341938018799, "action": -0.9984776377677917}
{"mode": "train", "epochs": 6, "timestep": 11710, "ep_reward": 959.6456909179688, "reward": 0.7286627292633057, "action": -1.4163155555725098}
{"mode": "train", "epochs": 6, "timestep": 11711, "ep_reward": 960.2590942382812, "reward": 0.6134263277053833, "action": -1.2165828943252563}
{"mode": "train", "epochs": 6, "timestep": 11712, "ep_reward": 960.7191772460938, "reward": 0.46009111404418945, "action": -1.6589913368225098}
{"mode": "train", "epochs": 6, "timestep": 11713, "ep_reward": 961.0326538085938, "reward": 0.3134564757347107, "action": -0.9445855617523193}
{"mode": "train", "epochs": 6, "timestep": 11714, "ep_reward": 961.2290649414062, "reward": 0.19638091325759888, "action": -1.0916800498962402}
{"mode": "train", "epochs": 6, "timestep": 11715, "ep_reward": 961.2883911132812, "reward": 0.059319376945495605, "action": -1.1083338260650635}
{"mode": "train", "epochs": 6, "timestep": 11716, "ep_reward": 961.3472900390625, "reward": 0.05892103910446167, "action": -1.0640426874160767}
{"mode": "train", "epochs": 6, "timestep": 11717, "ep_reward": 961.5432739257812, "reward": 0.19598114490509033, "action": -1.4137072563171387}
{"mode": "train", "epochs": 6, "timestep": 11718, "ep_reward": 961.8743286132812, "reward": 0.33106088638305664, "action": -1.5820600986480713}
{"mode": "train", "epochs": 6, "timestep": 11719, "ep_reward": 962.3334350585938, "reward": 0.4590930938720703, "action": -1.1377257108688354}
{"mode": "train", "epochs": 6, "timestep": 11720, "ep_reward": 962.9114379882812, "reward": 0.5780328512191772, "action": -1.0646753311157227}
{"mode": "train", "epochs": 6, "timestep": 11721, "ep_reward": 963.58740234375, "reward": 0.6759905815124512, "action": -1.156427264213562}
{"mode": "train", "epochs": 6, "timestep": 11722, "ep_reward": 964.336669921875, "reward": 0.7492414712905884, "action": -0.6402537822723389}
{"mode": "train", "epochs": 6, "timestep": 11723, "ep_reward": 965.14111328125, "reward": 0.804431676864624, "action": -1.6159276962280273}
{"mode": "train", "epochs": 6, "timestep": 11724, "ep_reward": 965.9707641601562, "reward": 0.8296545743942261, "action": -1.3394004106521606}
{"mode": "train", "epochs": 6, "timestep": 11725, "ep_reward": 966.8088989257812, "reward": 0.8381582498550415, "action": -0.34791070222854614}
{"mode": "train", "epochs": 6, "timestep": 11726, "ep_reward": 967.6448974609375, "reward": 0.8359948992729187, "action": -1.0880459547042847}
{"mode": "train", "epochs": 6, "timestep": 11727, "ep_reward": 968.4501342773438, "reward": 0.8052642345428467, "action": -0.9697861671447754}
{"mode": "train", "epochs": 6, "timestep": 11728, "ep_reward": 969.1997680664062, "reward": 0.749613344669342, "action": -0.2896055579185486}
{"mode": "train", "epochs": 6, "timestep": 11729, "ep_reward": 969.8700561523438, "reward": 0.6702866554260254, "action": -1.2888792753219604}
{"mode": "train", "epochs": 6, "timestep": 11730, "ep_reward": 970.410400390625, "reward": 0.540366530418396, "action": -1.1799272298812866}
{"mode": "train", "epochs": 6, "timestep": 11731, "ep_reward": 970.7997436523438, "reward": 0.3893583416938782, "action": -0.49097973108291626}
{"mode": "train", "epochs": 6, "timestep": 11732, "ep_reward": 971.0872192382812, "reward": 0.2874997854232788, "action": -1.1218979358673096}
{"mode": "train", "epochs": 6, "timestep": 11733, "ep_reward": 971.2528076171875, "reward": 0.1656186580657959, "action": -1.612199306488037}
{"mode": "train", "epochs": 6, "timestep": 11734, "ep_reward": 971.2767944335938, "reward": 0.02396368980407715, "action": -0.529364824295044}
{"mode": "train", "epochs": 6, "timestep": 11735, "ep_reward": 971.3699951171875, "reward": 0.0932234525680542, "action": -1.0795142650604248}
{"mode": "train", "epochs": 6, "timestep": 11736, "ep_reward": 971.6002197265625, "reward": 0.23022282123565674, "action": -1.4440233707427979}
{"mode": "train", "epochs": 6, "timestep": 11737, "ep_reward": 971.9645385742188, "reward": 0.3643031120300293, "action": -0.7651081681251526}
{"mode": "train", "epochs": 6, "timestep": 11738, "ep_reward": 972.4635620117188, "reward": 0.4990137815475464, "action": -0.6052972078323364}
{"mode": "train", "epochs": 6, "timestep": 11739, "ep_reward": 973.0807495117188, "reward": 0.617182731628418, "action": -1.1111059188842773}
{"mode": "train", "epochs": 6, "timestep": 11740, "ep_reward": 973.787841796875, "reward": 0.7070643901824951, "action": -1.4667609930038452}
{"mode": "train", "epochs": 6, "timestep": 11741, "ep_reward": 974.5592041015625, "reward": 0.771346390247345, "action": -0.8634390830993652}
{"mode": "train", "epochs": 6, "timestep": 11742, "ep_reward": 975.3796997070312, "reward": 0.82051682472229, "action": -0.8322486281394958}
{"mode": "train", "epochs": 6, "timestep": 11743, "ep_reward": 976.2303466796875, "reward": 0.8506759405136108, "action": -0.8735991716384888}
{"mode": "train", "epochs": 6, "timestep": 11744, "ep_reward": 977.0933837890625, "reward": 0.8630505800247192, "action": -1.1026619672775269}
{"mode": "train", "epochs": 6, "timestep": 11745, "ep_reward": 977.9496459960938, "reward": 0.8562500476837158, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 11746, "ep_reward": 978.7716064453125, "reward": 0.8219675421714783, "action": -0.43933266401290894}
{"mode": "train", "epochs": 6, "timestep": 11747, "ep_reward": 979.55029296875, "reward": 0.7786770462989807, "action": -1.1905205249786377}
{"mode": "train", "epochs": 6, "timestep": 11748, "ep_reward": 980.2487182617188, "reward": 0.6984044313430786, "action": -0.05300551652908325}
{"mode": "train", "epochs": 6, "timestep": 11749, "ep_reward": 980.8455200195312, "reward": 0.5967923402786255, "action": -0.9706019759178162}
{"mode": "train", "epochs": 6, "timestep": 11750, "ep_reward": 981.2892456054688, "reward": 0.443714439868927, "action": -0.7822970151901245}
{"mode": "train", "epochs": 6, "timestep": 11751, "ep_reward": 981.6080932617188, "reward": 0.3188651204109192, "action": -0.5518476963043213}
{"mode": "train", "epochs": 6, "timestep": 11752, "ep_reward": 981.8109130859375, "reward": 0.20282793045043945, "action": 0.35156846046447754}
{"mode": "train", "epochs": 6, "timestep": 11753, "ep_reward": 981.8776245117188, "reward": 0.06671810150146484, "action": -1.033606767654419}
{"mode": "train", "epochs": 6, "timestep": 11754, "ep_reward": 981.9290771484375, "reward": 0.0514378547668457, "action": -1.3368042707443237}
{"mode": "train", "epochs": 6, "timestep": 11755, "ep_reward": 982.1187133789062, "reward": 0.18964070081710815, "action": -0.7102551460266113}
{"mode": "train", "epochs": 6, "timestep": 11756, "ep_reward": 982.4522094726562, "reward": 0.3334827423095703, "action": -0.5148440599441528}
{"mode": "train", "epochs": 6, "timestep": 11757, "ep_reward": 982.925048828125, "reward": 0.4728107452392578, "action": -1.364437460899353}
{"mode": "train", "epochs": 6, "timestep": 11758, "ep_reward": 983.5114135742188, "reward": 0.5863525867462158, "action": -1.6215500831604004}
{"mode": "train", "epochs": 6, "timestep": 11759, "ep_reward": 984.1892700195312, "reward": 0.677864134311676, "action": -0.4720723032951355}
{"mode": "train", "epochs": 6, "timestep": 11760, "ep_reward": 984.9483642578125, "reward": 0.7590847611427307, "action": -0.7728333473205566}
{"mode": "train", "epochs": 6, "timestep": 11761, "ep_reward": 985.7632446289062, "reward": 0.8148508071899414, "action": -0.9781026840209961}
{"mode": "train", "epochs": 6, "timestep": 11762, "ep_reward": 986.6128540039062, "reward": 0.8495827913284302, "action": -0.8378820419311523}
{"mode": "train", "epochs": 6, "timestep": 11763, "ep_reward": 987.4814453125, "reward": 0.8686032295227051, "action": -0.7474088668823242}
{"mode": "train", "epochs": 6, "timestep": 11764, "ep_reward": 988.35400390625, "reward": 0.8725422620773315, "action": -0.37861573696136475}
{"mode": "train", "epochs": 6, "timestep": 11765, "ep_reward": 989.2174682617188, "reward": 0.8634800910949707, "action": -0.8924720287322998}
{"mode": "train", "epochs": 6, "timestep": 11766, "ep_reward": 990.04931640625, "reward": 0.8318641185760498, "action": -1.1093934774398804}
{"mode": "train", "epochs": 6, "timestep": 11767, "ep_reward": 990.824462890625, "reward": 0.7751666307449341, "action": -0.9922934770584106}
{"mode": "train", "epochs": 6, "timestep": 11768, "ep_reward": 991.514404296875, "reward": 0.689936637878418, "action": -1.4913634061813354}
{"mode": "train", "epochs": 6, "timestep": 11769, "ep_reward": 992.075439453125, "reward": 0.5610338449478149, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 11770, "ep_reward": 992.4631958007812, "reward": 0.38776975870132446, "action": -1.228272795677185}
{"mode": "train", "epochs": 6, "timestep": 11771, "ep_reward": 992.7489013671875, "reward": 0.2857072353363037, "action": -0.7322856187820435}
{"mode": "train", "epochs": 6, "timestep": 11772, "ep_reward": 992.9124755859375, "reward": 0.16355067491531372, "action": -1.0144857168197632}
{"mode": "train", "epochs": 6, "timestep": 11773, "ep_reward": 992.9337158203125, "reward": 0.021267294883728027, "action": -1.8743754625320435}
{"mode": "train", "epochs": 6, "timestep": 11774, "ep_reward": 993.0292358398438, "reward": 0.09555011987686157, "action": -1.1340422630310059}
{"mode": "train", "epochs": 6, "timestep": 11775, "ep_reward": 993.26123046875, "reward": 0.23202329874038696, "action": -0.8880146741867065}
{"mode": "train", "epochs": 6, "timestep": 11776, "ep_reward": 993.6340942382812, "reward": 0.3728805184364319, "action": -1.3836138248443604}
{"mode": "train", "epochs": 6, "timestep": 11777, "ep_reward": 994.1329345703125, "reward": 0.4988316297531128, "action": -1.3788782358169556}
{"mode": "train", "epochs": 6, "timestep": 11778, "ep_reward": 994.7416381835938, "reward": 0.6086863279342651, "action": -0.5288962125778198}
{"mode": "train", "epochs": 6, "timestep": 11779, "ep_reward": 995.4474487304688, "reward": 0.7058084011077881, "action": -1.1506367921829224}
{"mode": "train", "epochs": 6, "timestep": 11780, "ep_reward": 996.22021484375, "reward": 0.7727919816970825, "action": -1.188821792602539}
{"mode": "train", "epochs": 6, "timestep": 11781, "ep_reward": 997.0385131835938, "reward": 0.8182742595672607, "action": -1.3901574611663818}
{"mode": "train", "epochs": 6, "timestep": 11782, "ep_reward": 997.8814697265625, "reward": 0.8429260849952698, "action": -1.0094045400619507}
{"mode": "train", "epochs": 6, "timestep": 11783, "ep_reward": 998.7344360351562, "reward": 0.8529559969902039, "action": -0.3174856901168823}
{"mode": "train", "epochs": 6, "timestep": 11784, "ep_reward": 999.5853881835938, "reward": 0.8509417772293091, "action": -1.2974555492401123}
{"mode": "train", "epochs": 6, "timestep": 11785, "ep_reward": 1000.4055786132812, "reward": 0.8202112913131714, "action": -1.4110572338104248}
{"mode": "train", "epochs": 6, "timestep": 11786, "ep_reward": 1001.1689453125, "reward": 0.7633562684059143, "action": -0.860650897026062}
{"mode": "train", "epochs": 6, "timestep": 11787, "ep_reward": 1001.85009765625, "reward": 0.6811525821685791, "action": -1.0821311473846436}
{"mode": "train", "epochs": 6, "timestep": 11788, "ep_reward": 1002.4085083007812, "reward": 0.5584084987640381, "action": -0.815402090549469}
{"mode": "train", "epochs": 6, "timestep": 11789, "ep_reward": 1002.8060302734375, "reward": 0.3975241780281067, "action": -1.0926562547683716}
{"mode": "train", "epochs": 6, "timestep": 11790, "ep_reward": 1003.1036376953125, "reward": 0.2976100444793701, "action": -0.2542364001274109}
{"mode": "train", "epochs": 6, "timestep": 11791, "ep_reward": 1003.2811889648438, "reward": 0.1775813102722168, "action": -0.8537081480026245}
{"mode": "train", "epochs": 6, "timestep": 11792, "ep_reward": 1003.3187255859375, "reward": 0.037532925605773926, "action": -1.2918720245361328}
{"mode": "train", "epochs": 6, "timestep": 11793, "ep_reward": 1003.39892578125, "reward": 0.08021044731140137, "action": -1.3802623748779297}
{"mode": "train", "epochs": 6, "timestep": 11794, "ep_reward": 1003.61328125, "reward": 0.2143721580505371, "action": -1.5033490657806396}
{"mode": "train", "epochs": 6, "timestep": 11795, "ep_reward": 1003.9618530273438, "reward": 0.3485472798347473, "action": -1.1649101972579956}
{"mode": "train", "epochs": 6, "timestep": 11796, "ep_reward": 1004.4423217773438, "reward": 0.4804624319076538, "action": -0.4587600827217102}
{"mode": "train", "epochs": 6, "timestep": 11797, "ep_reward": 1005.0459594726562, "reward": 0.6036399602890015, "action": -0.10517293214797974}
{"mode": "train", "epochs": 6, "timestep": 11798, "ep_reward": 1005.7522583007812, "reward": 0.7062757015228271, "action": -1.2399884462356567}
{"mode": "train", "epochs": 6, "timestep": 11799, "ep_reward": 1006.525634765625, "reward": 0.773366391658783, "action": -0.46449679136276245}
{"mode": "train", "epochs": 6, "timestep": 11800, "ep_reward": 1007.3522338867188, "reward": 0.8266046047210693, "action": -0.9713211059570312}
{"mode": "train", "epochs": 6, "timestep": 11801, "ep_reward": 1008.2085571289062, "reward": 0.8563510179519653, "action": -1.7982323169708252}
{"mode": "train", "epochs": 6, "timestep": 11802, "ep_reward": 1009.0714111328125, "reward": 0.8628783822059631, "action": -1.0575069189071655}
{"mode": "train", "epochs": 6, "timestep": 11803, "ep_reward": 1009.9303588867188, "reward": 0.8589456677436829, "action": -1.2429251670837402}
{"mode": "train", "epochs": 6, "timestep": 11804, "ep_reward": 1010.7651977539062, "reward": 0.8348430395126343, "action": -0.8960027694702148}
{"mode": "train", "epochs": 6, "timestep": 11805, "ep_reward": 1011.556884765625, "reward": 0.791698694229126, "action": -0.6442419290542603}
{"mode": "train", "epochs": 6, "timestep": 11806, "ep_reward": 1012.28076171875, "reward": 0.7238560318946838, "action": -1.45704984664917}
{"mode": "train", "epochs": 6, "timestep": 11807, "ep_reward": 1012.8926391601562, "reward": 0.6118618845939636, "action": -0.8960423469543457}
{"mode": "train", "epochs": 6, "timestep": 11808, "ep_reward": 1013.358154296875, "reward": 0.46551209688186646, "action": -0.6673980355262756}
{"mode": "train", "epochs": 6, "timestep": 11809, "ep_reward": 1013.6943359375, "reward": 0.3361656665802002, "action": -1.4292442798614502}
{"mode": "train", "epochs": 6, "timestep": 11810, "ep_reward": 1013.9179077148438, "reward": 0.22357535362243652, "action": -0.302845299243927}
{"mode": "train", "epochs": 6, "timestep": 11811, "ep_reward": 1014.0086669921875, "reward": 0.09076130390167236, "action": -1.2968453168869019}
{"mode": "train", "epochs": 6, "timestep": 11812, "ep_reward": 1014.03515625, "reward": 0.026489973068237305, "action": -1.1023675203323364}
{"mode": "train", "epochs": 6, "timestep": 11813, "ep_reward": 1014.203125, "reward": 0.16794246435165405, "action": -1.1474891901016235}
{"mode": "train", "epochs": 6, "timestep": 11814, "ep_reward": 1014.509033203125, "reward": 0.30593550205230713, "action": -1.469287633895874}
{"mode": "train", "epochs": 6, "timestep": 11815, "ep_reward": 1014.945556640625, "reward": 0.43651461601257324, "action": -0.8751488327980042}
{"mode": "train", "epochs": 6, "timestep": 11816, "ep_reward": 1015.5070190429688, "reward": 0.5614801645278931, "action": -0.2494913935661316}
{"mode": "train", "epochs": 6, "timestep": 11817, "ep_reward": 1016.1787109375, "reward": 0.6716942191123962, "action": -1.6207165718078613}
{"mode": "train", "epochs": 6, "timestep": 11818, "ep_reward": 1016.9227294921875, "reward": 0.7440324425697327, "action": -0.4432520270347595}
{"mode": "train", "epochs": 6, "timestep": 11819, "ep_reward": 1017.7288818359375, "reward": 0.8061729073524475, "action": -0.5478531122207642}
{"mode": "train", "epochs": 6, "timestep": 11820, "ep_reward": 1018.5755004882812, "reward": 0.8466387987136841, "action": -1.1969096660614014}
{"mode": "train", "epochs": 6, "timestep": 11821, "ep_reward": 1019.439697265625, "reward": 0.8641669750213623, "action": -0.8924139738082886}
{"mode": "train", "epochs": 6, "timestep": 11822, "ep_reward": 1020.3077392578125, "reward": 0.8680622577667236, "action": -0.991881251335144}
{"mode": "train", "epochs": 6, "timestep": 11823, "ep_reward": 1021.1620483398438, "reward": 0.8543134331703186, "action": -0.32413995265960693}
{"mode": "train", "epochs": 6, "timestep": 11824, "ep_reward": 1021.9896850585938, "reward": 0.8276224136352539, "action": -0.23801755905151367}
{"mode": "train", "epochs": 6, "timestep": 11825, "ep_reward": 1022.7694091796875, "reward": 0.7797094583511353, "action": -1.2025316953659058}
{"mode": "train", "epochs": 6, "timestep": 11826, "ep_reward": 1023.462646484375, "reward": 0.6932539939880371, "action": -1.239390254020691}
{"mode": "train", "epochs": 6, "timestep": 11827, "ep_reward": 1024.0318603515625, "reward": 0.5692638158798218, "action": -0.8693944811820984}
{"mode": "train", "epochs": 6, "timestep": 11828, "ep_reward": 1024.4407958984375, "reward": 0.4089263081550598, "action": -0.442161500453949}
{"mode": "train", "epochs": 6, "timestep": 11829, "ep_reward": 1024.731689453125, "reward": 0.2908366918563843, "action": -0.9088683128356934}
{"mode": "train", "epochs": 6, "timestep": 11830, "ep_reward": 1024.9013671875, "reward": 0.16963058710098267, "action": -0.9306387901306152}
{"mode": "train", "epochs": 6, "timestep": 11831, "ep_reward": 1024.9296875, "reward": 0.02833378314971924, "action": -1.5222406387329102}
{"mode": "train", "epochs": 6, "timestep": 11832, "ep_reward": 1025.0186767578125, "reward": 0.08900970220565796, "action": -0.9059825539588928}
{"mode": "train", "epochs": 6, "timestep": 11833, "ep_reward": 1025.2467041015625, "reward": 0.22808337211608887, "action": -1.2413349151611328}
{"mode": "train", "epochs": 6, "timestep": 11834, "ep_reward": 1025.611083984375, "reward": 0.3643205165863037, "action": -0.9943607449531555}
{"mode": "train", "epochs": 6, "timestep": 11835, "ep_reward": 1026.10693359375, "reward": 0.49588221311569214, "action": -0.7305119037628174}
{"mode": "train", "epochs": 6, "timestep": 11836, "ep_reward": 1026.7200927734375, "reward": 0.6131582260131836, "action": -1.2095896005630493}
{"mode": "train", "epochs": 6, "timestep": 11837, "ep_reward": 1027.423095703125, "reward": 0.7030547857284546, "action": -0.8633688688278198}
{"mode": "train", "epochs": 6, "timestep": 11838, "ep_reward": 1028.197021484375, "reward": 0.7739131450653076, "action": -1.3943767547607422}
{"mode": "train", "epochs": 6, "timestep": 11839, "ep_reward": 1029.015869140625, "reward": 0.8188597559928894, "action": -0.6855355501174927}
{"mode": "train", "epochs": 6, "timestep": 11840, "ep_reward": 1029.8671875, "reward": 0.8512693643569946, "action": -1.203432559967041}
{"mode": "train", "epochs": 6, "timestep": 11841, "ep_reward": 1030.7291259765625, "reward": 0.861973226070404, "action": -0.49500060081481934}
{"mode": "train", "epochs": 6, "timestep": 11842, "ep_reward": 1031.5908203125, "reward": 0.8617390394210815, "action": -1.7416199445724487}
{"mode": "train", "epochs": 6, "timestep": 11843, "ep_reward": 1032.4229736328125, "reward": 0.8320940136909485, "action": -1.227707862854004}
{"mode": "train", "epochs": 6, "timestep": 11844, "ep_reward": 1033.206787109375, "reward": 0.7837628126144409, "action": -1.323641300201416}
{"mode": "train", "epochs": 6, "timestep": 11845, "ep_reward": 1033.91162109375, "reward": 0.7048748731613159, "action": -0.6749736070632935}
{"mode": "train", "epochs": 6, "timestep": 11846, "ep_reward": 1034.50927734375, "reward": 0.597618579864502, "action": -0.9144014716148376}
{"mode": "train", "epochs": 6, "timestep": 11847, "ep_reward": 1034.9556884765625, "reward": 0.4463922381401062, "action": -0.7668009996414185}
{"mode": "train", "epochs": 6, "timestep": 11848, "ep_reward": 1035.281494140625, "reward": 0.32583290338516235, "action": -0.6009488105773926}
{"mode": "train", "epochs": 6, "timestep": 11849, "ep_reward": 1035.492431640625, "reward": 0.2109474539756775, "action": -1.7102816104888916}
{"mode": "train", "epochs": 6, "timestep": 11850, "ep_reward": 1035.5687255859375, "reward": 0.07629519701004028, "action": -1.3105418682098389}
{"mode": "train", "epochs": 6, "timestep": 11851, "ep_reward": 1035.6103515625, "reward": 0.04168063402175903, "action": -0.6512188911437988}
{"mode": "train", "epochs": 6, "timestep": 11852, "ep_reward": 1035.7928466796875, "reward": 0.18252605199813843, "action": -0.050417304039001465}
{"mode": "train", "epochs": 6, "timestep": 11853, "ep_reward": 1036.126708984375, "reward": 0.33392053842544556, "action": -1.3800766468048096}
{"mode": "train", "epochs": 6, "timestep": 11854, "ep_reward": 1036.588623046875, "reward": 0.4618760943412781, "action": -1.051626205444336}
{"mode": "train", "epochs": 6, "timestep": 11855, "ep_reward": 1037.169189453125, "reward": 0.5805295705795288, "action": -0.44014930725097656}
{"mode": "train", "epochs": 6, "timestep": 11856, "ep_reward": 1037.8543701171875, "reward": 0.6852211952209473, "action": -0.8127247095108032}
{"mode": "train", "epochs": 6, "timestep": 11857, "ep_reward": 1038.6173095703125, "reward": 0.7629449963569641, "action": -0.4261045455932617}
{"mode": "train", "epochs": 6, "timestep": 11858, "ep_reward": 1039.4400634765625, "reward": 0.8227084279060364, "action": -1.5846946239471436}
{"mode": "train", "epochs": 6, "timestep": 11859, "ep_reward": 1040.294677734375, "reward": 0.8546419143676758, "action": -0.1974552869796753}
{"mode": "train", "epochs": 6, "timestep": 11860, "ep_reward": 1041.1767578125, "reward": 0.8820754885673523, "action": -0.9552570581436157}
{"mode": "train", "epochs": 6, "timestep": 11861, "ep_reward": 1042.0660400390625, "reward": 0.8893311619758606, "action": -0.18728071451187134}
{"mode": "train", "epochs": 6, "timestep": 11862, "ep_reward": 1042.954833984375, "reward": 0.8888257145881653, "action": -1.0833714008331299}
{"mode": "train", "epochs": 6, "timestep": 11863, "ep_reward": 1043.8214111328125, "reward": 0.866538941860199, "action": -1.2341779470443726}
{"mode": "train", "epochs": 6, "timestep": 11864, "ep_reward": 1044.6456298828125, "reward": 0.8241637945175171, "action": -1.6170463562011719}
{"mode": "train", "epochs": 6, "timestep": 11865, "ep_reward": 1045.398681640625, "reward": 0.7529924511909485, "action": -0.01133573055267334}
{"mode": "train", "epochs": 6, "timestep": 11866, "ep_reward": 1046.0672607421875, "reward": 0.6685681939125061, "action": -0.9467520713806152}
{"mode": "train", "epochs": 6, "timestep": 11867, "ep_reward": 1046.6048583984375, "reward": 0.5376293659210205, "action": -1.8150579929351807}
{"mode": "train", "epochs": 6, "timestep": 11868, "ep_reward": 1046.9639892578125, "reward": 0.359164834022522, "action": -0.7896372675895691}
{"mode": "train", "epochs": 6, "timestep": 11869, "ep_reward": 1047.21484375, "reward": 0.2508884072303772, "action": -1.630799412727356}
{"mode": "train", "epochs": 6, "timestep": 11870, "ep_reward": 1047.337646484375, "reward": 0.12285745143890381, "action": -0.854069709777832}
{"mode": "train", "epochs": 6, "timestep": 11871, "ep_reward": 1047.3291015625, "reward": -0.00857388973236084, "action": -1.0394692420959473}
{"mode": "train", "epochs": 6, "timestep": 11872, "ep_reward": 1047.466552734375, "reward": 0.13743817806243896, "action": -1.1127649545669556}
{"mode": "train", "epochs": 6, "timestep": 11873, "ep_reward": 1047.741943359375, "reward": 0.27534204721450806, "action": -0.5106421113014221}
{"mode": "train", "epochs": 6, "timestep": 11874, "ep_reward": 1048.160888671875, "reward": 0.4189763069152832, "action": -0.884656548500061}
{"mode": "train", "epochs": 6, "timestep": 11875, "ep_reward": 1048.7060546875, "reward": 0.5451984405517578, "action": -0.8359564542770386}
{"mode": "train", "epochs": 6, "timestep": 11876, "ep_reward": 1049.3587646484375, "reward": 0.6526966094970703, "action": 0.7875651121139526}
{"mode": "train", "epochs": 6, "timestep": 11877, "ep_reward": 1050.1114501953125, "reward": 0.7527066469192505, "action": -1.7505508661270142}
{"mode": "train", "epochs": 6, "timestep": 11878, "ep_reward": 1050.91748046875, "reward": 0.806015133857727, "action": -1.2039752006530762}
{"mode": "train", "epochs": 6, "timestep": 11879, "ep_reward": 1051.7640380859375, "reward": 0.8466157913208008, "action": -1.0266095399856567}
{"mode": "train", "epochs": 6, "timestep": 11880, "ep_reward": 1052.636474609375, "reward": 0.8724924921989441, "action": -1.4321876764297485}
{"mode": "train", "epochs": 6, "timestep": 11881, "ep_reward": 1053.51708984375, "reward": 0.880630373954773, "action": -1.0462068319320679}
{"mode": "train", "epochs": 6, "timestep": 11882, "ep_reward": 1054.3944091796875, "reward": 0.8772873878479004, "action": -0.49175846576690674}
{"mode": "train", "epochs": 6, "timestep": 11883, "ep_reward": 1055.2572021484375, "reward": 0.8627439737319946, "action": -0.8910341858863831}
{"mode": "train", "epochs": 6, "timestep": 11884, "ep_reward": 1056.0836181640625, "reward": 0.8263772130012512, "action": -1.1034868955612183}
{"mode": "train", "epochs": 6, "timestep": 11885, "ep_reward": 1056.847900390625, "reward": 0.7642665505409241, "action": -0.3117642402648926}
{"mode": "train", "epochs": 6, "timestep": 11886, "ep_reward": 1057.5289306640625, "reward": 0.6810897588729858, "action": -1.5850586891174316}
{"mode": "train", "epochs": 6, "timestep": 11887, "ep_reward": 1058.0750732421875, "reward": 0.5461146831512451, "action": -0.887012779712677}
{"mode": "train", "epochs": 6, "timestep": 11888, "ep_reward": 1058.4537353515625, "reward": 0.3787150979042053, "action": -0.5152552723884583}
{"mode": "train", "epochs": 6, "timestep": 11889, "ep_reward": 1058.7205810546875, "reward": 0.2668975591659546, "action": -1.2642982006072998}
{"mode": "train", "epochs": 6, "timestep": 11890, "ep_reward": 1058.8621826171875, "reward": 0.14157629013061523, "action": 0.039907097816467285}
{"mode": "train", "epochs": 6, "timestep": 11891, "ep_reward": 1058.858154296875, "reward": -0.0040007829666137695, "action": -1.568511724472046}
{"mode": "train", "epochs": 6, "timestep": 11892, "ep_reward": 1058.9769287109375, "reward": 0.11875230073928833, "action": -0.36137425899505615}
{"mode": "train", "epochs": 6, "timestep": 11893, "ep_reward": 1059.242431640625, "reward": 0.26549291610717773, "action": -0.3411163091659546}
{"mode": "train", "epochs": 6, "timestep": 11894, "ep_reward": 1059.65234375, "reward": 0.40993618965148926, "action": -1.298084020614624}
{"mode": "train", "epochs": 6, "timestep": 11895, "ep_reward": 1060.1839599609375, "reward": 0.5316544771194458, "action": -0.06215280294418335}
{"mode": "train", "epochs": 6, "timestep": 11896, "ep_reward": 1060.833251953125, "reward": 0.6492680311203003, "action": -1.5377860069274902}
{"mode": "train", "epochs": 6, "timestep": 11897, "ep_reward": 1061.5626220703125, "reward": 0.7294032573699951, "action": -0.866350531578064}
{"mode": "train", "epochs": 6, "timestep": 11898, "ep_reward": 1062.3582763671875, "reward": 0.7956360578536987, "action": -1.1559033393859863}
{"mode": "train", "epochs": 6, "timestep": 11899, "ep_reward": 1063.198486328125, "reward": 0.840155303478241, "action": -1.281280755996704}
{"mode": "train", "epochs": 6, "timestep": 11900, "ep_reward": 1064.0657958984375, "reward": 0.8672850728034973, "action": -1.0193970203399658}
{"mode": "train", "epochs": 6, "timestep": 11901, "ep_reward": 1064.947509765625, "reward": 0.8816639184951782, "action": -1.1035523414611816}
{"mode": "train", "epochs": 6, "timestep": 11902, "ep_reward": 1065.82861328125, "reward": 0.8810909986495972, "action": -0.46271812915802}
{"mode": "train", "epochs": 6, "timestep": 11903, "ep_reward": 1066.6990966796875, "reward": 0.870438814163208, "action": -1.7446155548095703}
{"mode": "train", "epochs": 6, "timestep": 11904, "ep_reward": 1067.5301513671875, "reward": 0.8310266733169556, "action": -0.8610366582870483}
{"mode": "train", "epochs": 6, "timestep": 11905, "ep_reward": 1068.306396484375, "reward": 0.7762007713317871, "action": -0.6705432534217834}
{"mode": "train", "epochs": 6, "timestep": 11906, "ep_reward": 1069.001220703125, "reward": 0.6947906017303467, "action": 0.2176276445388794}
{"mode": "train", "epochs": 6, "timestep": 11907, "ep_reward": 1069.59228515625, "reward": 0.5911223888397217, "action": -1.296523094177246}
{"mode": "train", "epochs": 6, "timestep": 11908, "ep_reward": 1070.02197265625, "reward": 0.42965471744537354, "action": -1.3916559219360352}
{"mode": "train", "epochs": 6, "timestep": 11909, "ep_reward": 1070.3157958984375, "reward": 0.2938358783721924, "action": -1.000793695449829}
{"mode": "train", "epochs": 6, "timestep": 11910, "ep_reward": 1070.4888916015625, "reward": 0.1730479598045349, "action": -1.7416539192199707}
{"mode": "train", "epochs": 6, "timestep": 11911, "ep_reward": 1070.521240234375, "reward": 0.032394468784332275, "action": -1.6961162090301514}
{"mode": "train", "epochs": 6, "timestep": 11912, "ep_reward": 1070.6064453125, "reward": 0.08516132831573486, "action": -0.45412153005599976}
{"mode": "train", "epochs": 6, "timestep": 11913, "ep_reward": 1070.836181640625, "reward": 0.22973787784576416, "action": -1.1665937900543213}
{"mode": "train", "epochs": 6, "timestep": 11914, "ep_reward": 1071.201904296875, "reward": 0.3657330870628357, "action": -1.8639503717422485}
{"mode": "train", "epochs": 6, "timestep": 11915, "ep_reward": 1071.6883544921875, "reward": 0.4864423871040344, "action": 0.11382901668548584}
{"mode": "train", "epochs": 6, "timestep": 11916, "ep_reward": 1072.302978515625, "reward": 0.6146203875541687, "action": -0.4334883689880371}
{"mode": "train", "epochs": 6, "timestep": 11917, "ep_reward": 1073.0150146484375, "reward": 0.7120622396469116, "action": -1.2469358444213867}
{"mode": "train", "epochs": 6, "timestep": 11918, "ep_reward": 1073.7938232421875, "reward": 0.7787902355194092, "action": -1.1387066841125488}
{"mode": "train", "epochs": 6, "timestep": 11919, "ep_reward": 1074.62060546875, "reward": 0.8267261981964111, "action": -0.9586626887321472}
{"mode": "train", "epochs": 6, "timestep": 11920, "ep_reward": 1075.47900390625, "reward": 0.8583988547325134, "action": -0.27577751874923706}
{"mode": "train", "epochs": 6, "timestep": 11921, "ep_reward": 1076.3585205078125, "reward": 0.8794809579849243, "action": -0.3747557997703552}
{"mode": "train", "epochs": 6, "timestep": 11922, "ep_reward": 1077.243408203125, "reward": 0.8849003911018372, "action": -0.4416085481643677}
{"mode": "train", "epochs": 6, "timestep": 11923, "ep_reward": 1078.11865234375, "reward": 0.87519371509552, "action": -0.38779813051223755}
{"mode": "train", "epochs": 6, "timestep": 11924, "ep_reward": 1078.96826171875, "reward": 0.8495680689811707, "action": -1.7647862434387207}
{"mode": "train", "epochs": 6, "timestep": 11925, "ep_reward": 1079.7586669921875, "reward": 0.7903780937194824, "action": -1.4347037076950073}
{"mode": "train", "epochs": 6, "timestep": 11926, "ep_reward": 1080.46337890625, "reward": 0.7047288417816162, "action": -1.196743130683899}
{"mode": "train", "epochs": 6, "timestep": 11927, "ep_reward": 1081.0487060546875, "reward": 0.5852676033973694, "action": -1.2205893993377686}
{"mode": "train", "epochs": 6, "timestep": 11928, "ep_reward": 1081.4725341796875, "reward": 0.423850953578949, "action": -0.9147218465805054}
{"mode": "train", "epochs": 6, "timestep": 11929, "ep_reward": 1081.7728271484375, "reward": 0.3002631664276123, "action": -0.45438623428344727}
{"mode": "train", "epochs": 6, "timestep": 11930, "ep_reward": 1081.9534912109375, "reward": 0.18071025609970093, "action": -1.0099339485168457}
{"mode": "train", "epochs": 6, "timestep": 11931, "ep_reward": 1081.9947509765625, "reward": 0.04121530055999756, "action": -0.9316592216491699}
{"mode": "train", "epochs": 6, "timestep": 11932, "ep_reward": 1082.071533203125, "reward": 0.07680243253707886, "action": -0.6166041493415833}
{"mode": "train", "epochs": 6, "timestep": 11933, "ep_reward": 1082.2906494140625, "reward": 0.21911507844924927, "action": -1.055179238319397}
{"mode": "train", "epochs": 6, "timestep": 11934, "ep_reward": 1082.64794921875, "reward": 0.35729336738586426, "action": -0.8584189414978027}
{"mode": "train", "epochs": 6, "timestep": 11935, "ep_reward": 1083.138427734375, "reward": 0.4905261993408203, "action": -0.8475890159606934}
{"mode": "train", "epochs": 6, "timestep": 11936, "ep_reward": 1083.74560546875, "reward": 0.6072002053260803, "action": -1.1443963050842285}
{"mode": "train", "epochs": 6, "timestep": 11937, "ep_reward": 1084.44482421875, "reward": 0.6992174386978149, "action": -1.5331413745880127}
{"mode": "train", "epochs": 6, "timestep": 11938, "ep_reward": 1085.210693359375, "reward": 0.7658637762069702, "action": -0.42544394731521606}
{"mode": "train", "epochs": 6, "timestep": 11939, "ep_reward": 1086.03271484375, "reward": 0.8220617175102234, "action": -0.3919031023979187}
{"mode": "train", "epochs": 6, "timestep": 11940, "ep_reward": 1086.8917236328125, "reward": 0.8589578866958618, "action": -0.8892218470573425}
{"mode": "train", "epochs": 6, "timestep": 11941, "ep_reward": 1087.7669677734375, "reward": 0.8752778172492981, "action": -0.40208005905151367}
{"mode": "train", "epochs": 6, "timestep": 11942, "ep_reward": 1088.6474609375, "reward": 0.8804352283477783, "action": -0.8349906206130981}
{"mode": "train", "epochs": 6, "timestep": 11943, "ep_reward": 1089.51416015625, "reward": 0.8666443228721619, "action": -1.3811644315719604}
{"mode": "train", "epochs": 6, "timestep": 11944, "ep_reward": 1090.343994140625, "reward": 0.8298566341400146, "action": -1.2046781778335571}
{"mode": "train", "epochs": 6, "timestep": 11945, "ep_reward": 1091.11474609375, "reward": 0.7707504034042358, "action": -1.3708930015563965}
{"mode": "train", "epochs": 6, "timestep": 11946, "ep_reward": 1091.793701171875, "reward": 0.6789137721061707, "action": -1.115004539489746}
{"mode": "train", "epochs": 6, "timestep": 11947, "ep_reward": 1092.345703125, "reward": 0.5519566535949707, "action": -0.4807208776473999}
{"mode": "train", "epochs": 6, "timestep": 11948, "ep_reward": 1092.73876953125, "reward": 0.39312565326690674, "action": -0.9458948969841003}
{"mode": "train", "epochs": 6, "timestep": 11949, "ep_reward": 1093.0191650390625, "reward": 0.28045427799224854, "action": -0.17996227741241455}
{"mode": "train", "epochs": 6, "timestep": 11950, "ep_reward": 1093.176513671875, "reward": 0.1573917269706726, "action": -0.03038167953491211}
{"mode": "train", "epochs": 6, "timestep": 11951, "ep_reward": 1093.190673828125, "reward": 0.014207899570465088, "action": -1.3683414459228516}
{"mode": "train", "epochs": 6, "timestep": 11952, "ep_reward": 1093.29296875, "reward": 0.10224181413650513, "action": -0.7308029532432556}
{"mode": "train", "epochs": 6, "timestep": 11953, "ep_reward": 1093.536865234375, "reward": 0.24383586645126343, "action": -1.4242480993270874}
{"mode": "train", "epochs": 6, "timestep": 11954, "ep_reward": 1093.9139404296875, "reward": 0.37703144550323486, "action": 0.08793878555297852}
{"mode": "train", "epochs": 6, "timestep": 11955, "ep_reward": 1094.43359375, "reward": 0.5197086334228516, "action": -0.7111384868621826}
{"mode": "train", "epochs": 6, "timestep": 11956, "ep_reward": 1095.06640625, "reward": 0.6327947378158569, "action": -1.5307245254516602}
{"mode": "train", "epochs": 6, "timestep": 11957, "ep_reward": 1095.7823486328125, "reward": 0.7159491181373596, "action": -1.5590262413024902}
{"mode": "train", "epochs": 6, "timestep": 11958, "ep_reward": 1096.560791015625, "reward": 0.7784706354141235, "action": -0.8998221158981323}
{"mode": "train", "epochs": 6, "timestep": 11959, "ep_reward": 1097.387939453125, "reward": 0.8271927237510681, "action": -1.1210832595825195}
{"mode": "train", "epochs": 6, "timestep": 11960, "ep_reward": 1098.24365234375, "reward": 0.8557676076889038, "action": -0.9354181289672852}
{"mode": "train", "epochs": 6, "timestep": 11961, "ep_reward": 1099.1131591796875, "reward": 0.8694524765014648, "action": -1.0826021432876587}
{"mode": "train", "epochs": 6, "timestep": 11962, "ep_reward": 1099.97900390625, "reward": 0.86590176820755, "action": -0.5657301545143127}
{"mode": "train", "epochs": 6, "timestep": 11963, "ep_reward": 1100.82861328125, "reward": 0.8495557308197021, "action": -0.840739369392395}
{"mode": "train", "epochs": 6, "timestep": 11964, "ep_reward": 1101.6392822265625, "reward": 0.8106875419616699, "action": -1.0903844833374023}
{"mode": "train", "epochs": 6, "timestep": 11965, "ep_reward": 1102.383056640625, "reward": 0.7437843084335327, "action": -0.6389539241790771}
{"mode": "train", "epochs": 6, "timestep": 11966, "ep_reward": 1103.03271484375, "reward": 0.6496908664703369, "action": -1.9853434562683105}
{"mode": "train", "epochs": 6, "timestep": 11967, "ep_reward": 1103.5311279296875, "reward": 0.49839967489242554, "action": -1.02460777759552}
{"mode": "train", "epochs": 6, "timestep": 11968, "ep_reward": 1103.8853759765625, "reward": 0.3542611598968506, "action": -0.6844059228897095}
{"mode": "train", "epochs": 6, "timestep": 11969, "ep_reward": 1104.1304931640625, "reward": 0.24514341354370117, "action": -0.15765869617462158}
{"mode": "train", "epochs": 6, "timestep": 11970, "ep_reward": 1104.2464599609375, "reward": 0.11591857671737671, "action": -1.1208629608154297}
{"mode": "train", "epochs": 6, "timestep": 11971, "ep_reward": 1104.2454833984375, "reward": -0.001000523567199707, "action": -1.9620323181152344}
{"mode": "train", "epochs": 6, "timestep": 11972, "ep_reward": 1104.3896484375, "reward": 0.1442144513130188, "action": -0.905724823474884}
{"mode": "train", "epochs": 6, "timestep": 11973, "ep_reward": 1104.6744384765625, "reward": 0.2847669720649719, "action": -1.157274603843689}
{"mode": "train", "epochs": 6, "timestep": 11974, "ep_reward": 1105.09423828125, "reward": 0.41979533433914185, "action": -0.7356701493263245}
{"mode": "train", "epochs": 6, "timestep": 11975, "ep_reward": 1105.6422119140625, "reward": 0.5480072498321533, "action": -0.679929256439209}
{"mode": "train", "epochs": 6, "timestep": 11976, "ep_reward": 1106.298828125, "reward": 0.6566437482833862, "action": -0.04510003328323364}
{"mode": "train", "epochs": 6, "timestep": 11977, "ep_reward": 1107.046875, "reward": 0.7479920387268066, "action": -1.1273469924926758}
{"mode": "train", "epochs": 6, "timestep": 11978, "ep_reward": 1107.8531494140625, "reward": 0.8062553405761719, "action": -1.915531873703003}
{"mode": "train", "epochs": 6, "timestep": 11979, "ep_reward": 1108.69287109375, "reward": 0.8396981954574585, "action": -0.8473738431930542}
{"mode": "train", "epochs": 6, "timestep": 11980, "ep_reward": 1109.558349609375, "reward": 0.8654329776763916, "action": -2.0}
{"mode": "train", "epochs": 6, "timestep": 11981, "ep_reward": 1110.4244384765625, "reward": 0.8661006093025208, "action": -0.5626335144042969}
{"mode": "train", "epochs": 6, "timestep": 11982, "ep_reward": 1111.2867431640625, "reward": 0.8623590469360352, "action": -0.8764573335647583}
{"mode": "train", "epochs": 6, "timestep": 11983, "ep_reward": 1112.1246337890625, "reward": 0.8378311991691589, "action": -1.2537723779678345}
{"mode": "train", "epochs": 6, "timestep": 11984, "ep_reward": 1112.9122314453125, "reward": 0.7875602841377258, "action": -0.6008020043373108}
{"mode": "train", "epochs": 6, "timestep": 11985, "ep_reward": 1113.628173828125, "reward": 0.7159632444381714, "action": -1.5658299922943115}
{"mode": "train", "epochs": 6, "timestep": 11986, "ep_reward": 1114.225830078125, "reward": 0.5977159738540649, "action": -1.5040569305419922}
{"mode": "train", "epochs": 6, "timestep": 11987, "ep_reward": 1114.6624755859375, "reward": 0.4365953803062439, "action": -0.5788534283638}
{"mode": "train", "epochs": 6, "timestep": 11988, "ep_reward": 1114.9822998046875, "reward": 0.3198276162147522, "action": -1.6989727020263672}
{"mode": "train", "epochs": 6, "timestep": 11989, "ep_reward": 1115.1865234375, "reward": 0.20416826009750366, "action": -0.2378634810447693}
{"mode": "train", "epochs": 6, "timestep": 11990, "ep_reward": 1115.2547607421875, "reward": 0.0681990385055542, "action": -1.4648293256759644}
{"mode": "train", "epochs": 6, "timestep": 11991, "ep_reward": 1115.3046875, "reward": 0.049869418144226074, "action": -1.3117159605026245}
{"mode": "train", "epochs": 6, "timestep": 11992, "ep_reward": 1115.492919921875, "reward": 0.18825501203536987, "action": -0.9540644884109497}
{"mode": "train", "epochs": 6, "timestep": 11993, "ep_reward": 1115.8218994140625, "reward": 0.3290230631828308, "action": -1.0440897941589355}
{"mode": "train", "epochs": 6, "timestep": 11994, "ep_reward": 1116.2847900390625, "reward": 0.4629064202308655, "action": -1.0567376613616943}
{"mode": "train", "epochs": 6, "timestep": 11995, "ep_reward": 1116.866455078125, "reward": 0.581682562828064, "action": -1.4434140920639038}
{"mode": "train", "epochs": 6, "timestep": 11996, "ep_reward": 1117.5421142578125, "reward": 0.6756861209869385, "action": -0.750765323638916}
{"mode": "train", "epochs": 6, "timestep": 11997, "ep_reward": 1118.29638671875, "reward": 0.7542630434036255, "action": -1.4328299760818481}
{"mode": "train", "epochs": 6, "timestep": 11998, "ep_reward": 1119.1004638671875, "reward": 0.8040988445281982, "action": -1.3845093250274658}
{"mode": "train", "epochs": 6, "timestep": 11999, "ep_reward": 1119.935302734375, "reward": 0.8348677158355713, "action": -1.308326244354248}
{"mode": "train", "epochs": 6, "timestep": 12000, "ep_reward": 1120.7833251953125, "reward": 0.8479855060577393, "action": 0.0037691593170166016}
{"mode": "train", "epochs": 7, "timestep": 12001, "ep_reward": 0.45071297883987427, "reward": 0.45071297883987427, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 12002, "ep_reward": 0.9199780225753784, "reward": 0.46926504373550415, "action": -1.9533495903015137}
{"mode": "train", "epochs": 7, "timestep": 12003, "ep_reward": 1.4099161624908447, "reward": 0.4899381399154663, "action": -1.0269399881362915}
{"mode": "train", "epochs": 7, "timestep": 12004, "ep_reward": 1.9213066101074219, "reward": 0.5113903880119324, "action": -0.8485693335533142}
{"mode": "train", "epochs": 7, "timestep": 12005, "ep_reward": 2.4520318508148193, "reward": 0.5307252407073975, "action": -1.2320024967193604}
{"mode": "train", "epochs": 7, "timestep": 12006, "ep_reward": 2.999361753463745, "reward": 0.5473299026489258, "action": 0.5417559742927551}
{"mode": "train", "epochs": 7, "timestep": 12007, "ep_reward": 3.558194637298584, "reward": 0.5588330030441284, "action": 0.6145991683006287}
{"mode": "train", "epochs": 7, "timestep": 12008, "ep_reward": 4.118983268737793, "reward": 0.5607888102531433, "action": -0.24106407165527344}
{"mode": "train", "epochs": 7, "timestep": 12009, "ep_reward": 4.6745195388793945, "reward": 0.5555365085601807, "action": 0.3467945456504822}
{"mode": "train", "epochs": 7, "timestep": 12010, "ep_reward": 5.216231346130371, "reward": 0.5417119860649109, "action": 0.44322669506073}
{"mode": "train", "epochs": 7, "timestep": 12011, "ep_reward": 5.735414028167725, "reward": 0.5191826820373535, "action": 1.1755406856536865}
{"mode": "train", "epochs": 7, "timestep": 12012, "ep_reward": 6.220487594604492, "reward": 0.4850737452507019, "action": 0.6559371948242188}
{"mode": "train", "epochs": 7, "timestep": 12013, "ep_reward": 6.665183067321777, "reward": 0.44469523429870605, "action": 0.7330411672592163}
{"mode": "train", "epochs": 7, "timestep": 12014, "ep_reward": 7.063356876373291, "reward": 0.39817363023757935, "action": 1.223741054534912}
{"mode": "train", "epochs": 7, "timestep": 12015, "ep_reward": 7.4132466316223145, "reward": 0.34988975524902344, "action": 0.9791857004165649}
{"mode": "train", "epochs": 7, "timestep": 12016, "ep_reward": 7.807582378387451, "reward": 0.39433592557907104, "action": 0.5999279022216797}
{"mode": "train", "epochs": 7, "timestep": 12017, "ep_reward": 8.248822212219238, "reward": 0.44123953580856323, "action": 0.5925308465957642}
{"mode": "train", "epochs": 7, "timestep": 12018, "ep_reward": 8.73594856262207, "reward": 0.48712676763534546, "action": 1.5196566581726074}
{"mode": "train", "epochs": 7, "timestep": 12019, "ep_reward": 9.264636993408203, "reward": 0.528688907623291, "action": 1.8443968296051025}
{"mode": "train", "epochs": 7, "timestep": 12020, "ep_reward": 9.832864761352539, "reward": 0.5682274103164673, "action": 1.3143244981765747}
{"mode": "train", "epochs": 7, "timestep": 12021, "ep_reward": 10.43919563293457, "reward": 0.6063312888145447, "action": 1.8191033601760864}
{"mode": "train", "epochs": 7, "timestep": 12022, "ep_reward": 11.078288078308105, "reward": 0.6390928030014038, "action": 1.1173077821731567}
{"mode": "train", "epochs": 7, "timestep": 12023, "ep_reward": 11.746000289916992, "reward": 0.6677126884460449, "action": 1.4211312532424927}
{"mode": "train", "epochs": 7, "timestep": 12024, "ep_reward": 12.434858322143555, "reward": 0.6888575553894043, "action": 1.0497304201126099}
{"mode": "train", "epochs": 7, "timestep": 12025, "ep_reward": 13.137356758117676, "reward": 0.7024985551834106, "action": 1.3930079936981201}
{"mode": "train", "epochs": 7, "timestep": 12026, "ep_reward": 13.845427513122559, "reward": 0.7080705165863037, "action": 0.33865028619766235}
{"mode": "train", "epochs": 7, "timestep": 12027, "ep_reward": 14.548376083374023, "reward": 0.702949047088623, "action": -1.835269808769226}
{"mode": "train", "epochs": 7, "timestep": 12028, "ep_reward": 15.225866317749023, "reward": 0.6774907112121582, "action": -0.20366069674491882}
{"mode": "train", "epochs": 7, "timestep": 12029, "ep_reward": 15.864998817443848, "reward": 0.6391324996948242, "action": -1.019860029220581}
{"mode": "train", "epochs": 7, "timestep": 12030, "ep_reward": 16.44697380065918, "reward": 0.5819750428199768, "action": -0.5394512414932251}
{"mode": "train", "epochs": 7, "timestep": 12031, "ep_reward": 16.960205078125, "reward": 0.5132313966751099, "action": -1.1520898342132568}
{"mode": "train", "epochs": 7, "timestep": 12032, "ep_reward": 17.388545989990234, "reward": 0.428341805934906, "action": -0.6007848978042603}
{"mode": "train", "epochs": 7, "timestep": 12033, "ep_reward": 17.72811508178711, "reward": 0.33956992626190186, "action": -0.6747909784317017}
{"mode": "train", "epochs": 7, "timestep": 12034, "ep_reward": 18.025371551513672, "reward": 0.2972572445869446, "action": -1.2595977783203125}
{"mode": "train", "epochs": 7, "timestep": 12035, "ep_reward": 18.39579200744629, "reward": 0.3704211115837097, "action": -0.9938602447509766}
{"mode": "train", "epochs": 7, "timestep": 12036, "ep_reward": 18.843116760253906, "reward": 0.4473256468772888, "action": -1.4583942890167236}
{"mode": "train", "epochs": 7, "timestep": 12037, "ep_reward": 19.363725662231445, "reward": 0.5206081867218018, "action": -1.0471665859222412}
{"mode": "train", "epochs": 7, "timestep": 12038, "ep_reward": 19.956668853759766, "reward": 0.5929425358772278, "action": -0.8651366233825684}
{"mode": "train", "epochs": 7, "timestep": 12039, "ep_reward": 20.615564346313477, "reward": 0.6588959693908691, "action": -1.0637052059173584}
{"mode": "train", "epochs": 7, "timestep": 12040, "ep_reward": 21.32971954345703, "reward": 0.714155912399292, "action": -1.6429146528244019}
{"mode": "train", "epochs": 7, "timestep": 12041, "ep_reward": 22.08735466003418, "reward": 0.7576346397399902, "action": -0.8012273907661438}
{"mode": "train", "epochs": 7, "timestep": 12042, "ep_reward": 22.880916595458984, "reward": 0.7935619354248047, "action": -1.7199532985687256}
{"mode": "train", "epochs": 7, "timestep": 12043, "ep_reward": 23.698030471801758, "reward": 0.8171137571334839, "action": -1.4369367361068726}
{"mode": "train", "epochs": 7, "timestep": 12044, "ep_reward": 24.530418395996094, "reward": 0.8323887586593628, "action": -0.8502062559127808}
{"mode": "train", "epochs": 7, "timestep": 12045, "ep_reward": 25.368366241455078, "reward": 0.8379485607147217, "action": -0.002837434411048889}
{"mode": "train", "epochs": 7, "timestep": 12046, "ep_reward": 26.198524475097656, "reward": 0.8301576972007751, "action": 1.058563470840454}
{"mode": "train", "epochs": 7, "timestep": 12047, "ep_reward": 27.00155258178711, "reward": 0.8030271530151367, "action": 0.4382959008216858}
{"mode": "train", "epochs": 7, "timestep": 12048, "ep_reward": 27.760141372680664, "reward": 0.7585886716842651, "action": 0.9394232034683228}
{"mode": "train", "epochs": 7, "timestep": 12049, "ep_reward": 28.451677322387695, "reward": 0.6915352940559387, "action": 0.05082058906555176}
{"mode": "train", "epochs": 7, "timestep": 12050, "ep_reward": 29.062679290771484, "reward": 0.6110018491744995, "action": 0.6491884589195251}
{"mode": "train", "epochs": 7, "timestep": 12051, "ep_reward": 29.570775985717773, "reward": 0.5080959796905518, "action": 0.43914464116096497}
{"mode": "train", "epochs": 7, "timestep": 12052, "ep_reward": 29.96297264099121, "reward": 0.39219754934310913, "action": 1.0769561529159546}
{"mode": "train", "epochs": 7, "timestep": 12053, "ep_reward": 30.222185134887695, "reward": 0.25921279191970825, "action": -0.592738687992096}
{"mode": "train", "epochs": 7, "timestep": 12054, "ep_reward": 30.436138153076172, "reward": 0.21395307779312134, "action": 1.0636664628982544}
{"mode": "train", "epochs": 7, "timestep": 12055, "ep_reward": 30.74875259399414, "reward": 0.3126142621040344, "action": 0.46711480617523193}
{"mode": "train", "epochs": 7, "timestep": 12056, "ep_reward": 31.16756820678711, "reward": 0.4188149571418762, "action": -1.539879322052002}
{"mode": "train", "epochs": 7, "timestep": 12057, "ep_reward": 31.70401382446289, "reward": 0.536446213722229, "action": -0.11255179345607758}
{"mode": "train", "epochs": 7, "timestep": 12058, "ep_reward": 32.33245086669922, "reward": 0.6284366846084595, "action": 0.3780139684677124}
{"mode": "train", "epochs": 7, "timestep": 12059, "ep_reward": 33.03601837158203, "reward": 0.7035689353942871, "action": 0.8497209548950195}
{"mode": "train", "epochs": 7, "timestep": 12060, "ep_reward": 33.79871368408203, "reward": 0.7626953721046448, "action": 0.7727144956588745}
{"mode": "train", "epochs": 7, "timestep": 12061, "ep_reward": 34.60806655883789, "reward": 0.8093531131744385, "action": 0.9305396676063538}
{"mode": "train", "epochs": 7, "timestep": 12062, "ep_reward": 35.45124435424805, "reward": 0.8431780338287354, "action": 1.2206135988235474}
{"mode": "train", "epochs": 7, "timestep": 12063, "ep_reward": 36.31696701049805, "reward": 0.8657229542732239, "action": 0.8554681539535522}
{"mode": "train", "epochs": 7, "timestep": 12064, "ep_reward": 37.19597625732422, "reward": 0.879007875919342, "action": 0.02943211793899536}
{"mode": "train", "epochs": 7, "timestep": 12065, "ep_reward": 38.07710647583008, "reward": 0.881130039691925, "action": 1.0918424129486084}
{"mode": "train", "epochs": 7, "timestep": 12066, "ep_reward": 38.9502067565918, "reward": 0.8730989694595337, "action": 0.8425514698028564}
{"mode": "train", "epochs": 7, "timestep": 12067, "ep_reward": 39.8048210144043, "reward": 0.8546134233474731, "action": 0.47024184465408325}
{"mode": "train", "epochs": 7, "timestep": 12068, "ep_reward": 40.627681732177734, "reward": 0.822861909866333, "action": 0.6169170141220093}
{"mode": "train", "epochs": 7, "timestep": 12069, "ep_reward": 41.4056396484375, "reward": 0.7779591083526611, "action": 0.021207988262176514}
{"mode": "train", "epochs": 7, "timestep": 12070, "ep_reward": 42.11919403076172, "reward": 0.7135528326034546, "action": -0.640601634979248}
{"mode": "train", "epochs": 7, "timestep": 12071, "ep_reward": 42.7438850402832, "reward": 0.6246911287307739, "action": -0.25838059186935425}
{"mode": "train", "epochs": 7, "timestep": 12072, "ep_reward": 43.263160705566406, "reward": 0.5192767381668091, "action": -1.1316313743591309}
{"mode": "train", "epochs": 7, "timestep": 12073, "ep_reward": 43.65039825439453, "reward": 0.38723665475845337, "action": -0.5098998546600342}
{"mode": "train", "epochs": 7, "timestep": 12074, "ep_reward": 43.90038299560547, "reward": 0.24998486042022705, "action": -0.9567185044288635}
{"mode": "train", "epochs": 7, "timestep": 12075, "ep_reward": 44.057735443115234, "reward": 0.1573517918586731, "action": -1.4284878969192505}
{"mode": "train", "epochs": 7, "timestep": 12076, "ep_reward": 44.32063674926758, "reward": 0.26290011405944824, "action": -0.556178867816925}
{"mode": "train", "epochs": 7, "timestep": 12077, "ep_reward": 44.70211410522461, "reward": 0.3814757466316223, "action": -0.6593030095100403}
{"mode": "train", "epochs": 7, "timestep": 12078, "ep_reward": 45.197914123535156, "reward": 0.49579840898513794, "action": -0.9132595658302307}
{"mode": "train", "epochs": 7, "timestep": 12079, "ep_reward": 45.79674530029297, "reward": 0.5988308191299438, "action": -0.9232938885688782}
{"mode": "train", "epochs": 7, "timestep": 12080, "ep_reward": 46.485565185546875, "reward": 0.6888209581375122, "action": -0.9145916700363159}
{"mode": "train", "epochs": 7, "timestep": 12081, "ep_reward": 47.249237060546875, "reward": 0.7636732459068298, "action": -0.7635654211044312}
{"mode": "train", "epochs": 7, "timestep": 12082, "ep_reward": 48.07321548461914, "reward": 0.8239794969558716, "action": -1.6329615116119385}
{"mode": "train", "epochs": 7, "timestep": 12083, "ep_reward": 48.93948745727539, "reward": 0.8662737607955933, "action": -0.14258992671966553}
{"mode": "train", "epochs": 7, "timestep": 12084, "ep_reward": 49.844120025634766, "reward": 0.9046323299407959, "action": -0.18252742290496826}
{"mode": "train", "epochs": 7, "timestep": 12085, "ep_reward": 50.77555847167969, "reward": 0.9314390420913696, "action": -1.5133814811706543}
{"mode": "train", "epochs": 7, "timestep": 12086, "ep_reward": 51.722530364990234, "reward": 0.946970522403717, "action": -1.117820143699646}
{"mode": "train", "epochs": 7, "timestep": 12087, "ep_reward": 52.68153381347656, "reward": 0.9590029120445251, "action": -0.7610752582550049}
{"mode": "train", "epochs": 7, "timestep": 12088, "ep_reward": 53.64912796020508, "reward": 0.9675956964492798, "action": -0.9668591022491455}
{"mode": "train", "epochs": 7, "timestep": 12089, "ep_reward": 54.621795654296875, "reward": 0.9726690649986267, "action": -0.2567417025566101}
{"mode": "train", "epochs": 7, "timestep": 12090, "ep_reward": 55.59669876098633, "reward": 0.9749012589454651, "action": -0.9098947644233704}
{"mode": "train", "epochs": 7, "timestep": 12091, "ep_reward": 56.570892333984375, "reward": 0.9741934537887573, "action": -0.5624988079071045}
{"mode": "train", "epochs": 7, "timestep": 12092, "ep_reward": 57.54129409790039, "reward": 0.970401406288147, "action": 0.7405155897140503}
{"mode": "train", "epochs": 7, "timestep": 12093, "ep_reward": 58.50099182128906, "reward": 0.9596966505050659, "action": 0.6694340109825134}
{"mode": "train", "epochs": 7, "timestep": 12094, "ep_reward": 59.44208526611328, "reward": 0.9410938024520874, "action": -0.12060065567493439}
{"mode": "train", "epochs": 7, "timestep": 12095, "ep_reward": 60.358238220214844, "reward": 0.9161539673805237, "action": -0.8412667512893677}
{"mode": "train", "epochs": 7, "timestep": 12096, "ep_reward": 61.243309020996094, "reward": 0.8850688934326172, "action": -0.6158550381660461}
{"mode": "train", "epochs": 7, "timestep": 12097, "ep_reward": 62.08442306518555, "reward": 0.8411158323287964, "action": -0.688860297203064}
{"mode": "train", "epochs": 7, "timestep": 12098, "ep_reward": 62.86711883544922, "reward": 0.782695472240448, "action": -1.2401188611984253}
{"mode": "train", "epochs": 7, "timestep": 12099, "ep_reward": 63.579097747802734, "reward": 0.7119784355163574, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 12100, "ep_reward": 64.21197509765625, "reward": 0.6328771114349365, "action": -1.4280492067337036}
{"mode": "train", "epochs": 7, "timestep": 12101, "ep_reward": 64.74563598632812, "reward": 0.5336607098579407, "action": -0.22070443630218506}
{"mode": "train", "epochs": 7, "timestep": 12102, "ep_reward": 65.15164184570312, "reward": 0.40600478649139404, "action": 0.11604851484298706}
{"mode": "train", "epochs": 7, "timestep": 12103, "ep_reward": 65.41353607177734, "reward": 0.2618957757949829, "action": -1.1747697591781616}
{"mode": "train", "epochs": 7, "timestep": 12104, "ep_reward": 65.54695129394531, "reward": 0.13341772556304932, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 12105, "ep_reward": 65.78125762939453, "reward": 0.2343042492866516, "action": -0.6060764789581299}
{"mode": "train", "epochs": 7, "timestep": 12106, "ep_reward": 66.14016723632812, "reward": 0.3589111566543579, "action": -0.5309158563613892}
{"mode": "train", "epochs": 7, "timestep": 12107, "ep_reward": 66.6180648803711, "reward": 0.4778974652290344, "action": -1.2705371379852295}
{"mode": "train", "epochs": 7, "timestep": 12108, "ep_reward": 67.20960998535156, "reward": 0.5915448665618896, "action": -0.36768969893455505}
{"mode": "train", "epochs": 7, "timestep": 12109, "ep_reward": 67.890625, "reward": 0.6810137033462524, "action": 0.0061855316162109375}
{"mode": "train", "epochs": 7, "timestep": 12110, "ep_reward": 68.6419448852539, "reward": 0.7513175010681152, "action": 1.3801774978637695}
{"mode": "train", "epochs": 7, "timestep": 12111, "ep_reward": 69.44244384765625, "reward": 0.8005023002624512, "action": 1.1890159845352173}
{"mode": "train", "epochs": 7, "timestep": 12112, "ep_reward": 70.28192901611328, "reward": 0.8394837975502014, "action": 0.8868099451065063}
{"mode": "train", "epochs": 7, "timestep": 12113, "ep_reward": 71.15027618408203, "reward": 0.8683503270149231, "action": 1.6089811325073242}
{"mode": "train", "epochs": 7, "timestep": 12114, "ep_reward": 72.03668212890625, "reward": 0.886406421661377, "action": 0.8447012901306152}
{"mode": "train", "epochs": 7, "timestep": 12115, "ep_reward": 72.93365478515625, "reward": 0.8969755172729492, "action": 1.1770074367523193}
{"mode": "train", "epochs": 7, "timestep": 12116, "ep_reward": 73.83257293701172, "reward": 0.8989143967628479, "action": 0.0676916241645813}
{"mode": "train", "epochs": 7, "timestep": 12117, "ep_reward": 74.72268676757812, "reward": 0.8901157975196838, "action": 0.5343919992446899}
{"mode": "train", "epochs": 7, "timestep": 12118, "ep_reward": 75.59319305419922, "reward": 0.8705079555511475, "action": 1.0105541944503784}
{"mode": "train", "epochs": 7, "timestep": 12119, "ep_reward": 76.4345474243164, "reward": 0.8413577079772949, "action": 0.9352180361747742}
{"mode": "train", "epochs": 7, "timestep": 12120, "ep_reward": 77.23464965820312, "reward": 0.8001013398170471, "action": 0.7132539749145508}
{"mode": "train", "epochs": 7, "timestep": 12121, "ep_reward": 77.97842407226562, "reward": 0.7437721490859985, "action": -0.7083024382591248}
{"mode": "train", "epochs": 7, "timestep": 12122, "ep_reward": 78.63736724853516, "reward": 0.6589415073394775, "action": -1.5962107181549072}
{"mode": "train", "epochs": 7, "timestep": 12123, "ep_reward": 79.17948150634766, "reward": 0.5421124696731567, "action": -0.7289160490036011}
{"mode": "train", "epochs": 7, "timestep": 12124, "ep_reward": 79.5908203125, "reward": 0.4113391637802124, "action": -1.85483980178833}
{"mode": "train", "epochs": 7, "timestep": 12125, "ep_reward": 79.84082794189453, "reward": 0.2500039339065552, "action": -1.5052244663238525}
{"mode": "train", "epochs": 7, "timestep": 12126, "ep_reward": 79.93329620361328, "reward": 0.09246838092803955, "action": -0.9016551971435547}
{"mode": "train", "epochs": 7, "timestep": 12127, "ep_reward": 80.14404296875, "reward": 0.21074867248535156, "action": -1.2644009590148926}
{"mode": "train", "epochs": 7, "timestep": 12128, "ep_reward": 80.4742660522461, "reward": 0.3302253484725952, "action": -0.8158751726150513}
{"mode": "train", "epochs": 7, "timestep": 12129, "ep_reward": 80.92821502685547, "reward": 0.4539501667022705, "action": -1.5527138710021973}
{"mode": "train", "epochs": 7, "timestep": 12130, "ep_reward": 81.48986053466797, "reward": 0.5616482496261597, "action": -1.7095245122909546}
{"mode": "train", "epochs": 7, "timestep": 12131, "ep_reward": 82.14537811279297, "reward": 0.6555203199386597, "action": -0.9810670614242554}
{"mode": "train", "epochs": 7, "timestep": 12132, "ep_reward": 82.88525390625, "reward": 0.7398726940155029, "action": -1.1210551261901855}
{"mode": "train", "epochs": 7, "timestep": 12133, "ep_reward": 83.69036102294922, "reward": 0.8051050305366516, "action": -0.8982040286064148}
{"mode": "train", "epochs": 7, "timestep": 12134, "ep_reward": 84.54613494873047, "reward": 0.8557769060134888, "action": -0.7738629579544067}
{"mode": "train", "epochs": 7, "timestep": 12135, "ep_reward": 85.43940734863281, "reward": 0.8932695388793945, "action": -0.5572715401649475}
{"mode": "train", "epochs": 7, "timestep": 12136, "ep_reward": 86.3599853515625, "reward": 0.9205756187438965, "action": -0.7378271818161011}
{"mode": "train", "epochs": 7, "timestep": 12137, "ep_reward": 87.2976303100586, "reward": 0.9376468658447266, "action": -1.7689266204833984}
{"mode": "train", "epochs": 7, "timestep": 12138, "ep_reward": 88.24011993408203, "reward": 0.9424907565116882, "action": -0.7708970308303833}
{"mode": "train", "epochs": 7, "timestep": 12139, "ep_reward": 89.18603515625, "reward": 0.9459152817726135, "action": -1.344160556793213}
{"mode": "train", "epochs": 7, "timestep": 12140, "ep_reward": 90.12539672851562, "reward": 0.9393602609634399, "action": -0.919163703918457}
{"mode": "train", "epochs": 7, "timestep": 12141, "ep_reward": 91.05213165283203, "reward": 0.9267347455024719, "action": -1.9572118520736694}
{"mode": "train", "epochs": 7, "timestep": 12142, "ep_reward": 91.94853210449219, "reward": 0.8964038491249084, "action": -0.7818605899810791}
{"mode": "train", "epochs": 7, "timestep": 12143, "ep_reward": 92.80730438232422, "reward": 0.8587709665298462, "action": -0.8208514451980591}
{"mode": "train", "epochs": 7, "timestep": 12144, "ep_reward": 93.60847473144531, "reward": 0.801166832447052, "action": -1.6150469779968262}
{"mode": "train", "epochs": 7, "timestep": 12145, "ep_reward": 94.3172836303711, "reward": 0.7088066339492798, "action": -1.3743566274642944}
{"mode": "train", "epochs": 7, "timestep": 12146, "ep_reward": 94.90083312988281, "reward": 0.5835496783256531, "action": -0.9097779393196106}
{"mode": "train", "epochs": 7, "timestep": 12147, "ep_reward": 95.3266372680664, "reward": 0.4258044958114624, "action": -0.985133945941925}
{"mode": "train", "epochs": 7, "timestep": 12148, "ep_reward": 95.59602355957031, "reward": 0.2693854570388794, "action": -1.2213281393051147}
{"mode": "train", "epochs": 7, "timestep": 12149, "ep_reward": 95.74031066894531, "reward": 0.1442851424217224, "action": -1.8397245407104492}
{"mode": "train", "epochs": 7, "timestep": 12150, "ep_reward": 95.73982238769531, "reward": -0.00048530101776123047, "action": -0.028641462326049805}
{"mode": "train", "epochs": 7, "timestep": 12151, "ep_reward": 95.85552215576172, "reward": 0.11570000648498535, "action": -0.8203129768371582}
{"mode": "train", "epochs": 7, "timestep": 12152, "ep_reward": 96.11200714111328, "reward": 0.25648796558380127, "action": -1.7990972995758057}
{"mode": "train", "epochs": 7, "timestep": 12153, "ep_reward": 96.496826171875, "reward": 0.38482218980789185, "action": -0.6808438301086426}
{"mode": "train", "epochs": 7, "timestep": 12154, "ep_reward": 97.01510620117188, "reward": 0.5182784199714661, "action": -1.3654046058654785}
{"mode": "train", "epochs": 7, "timestep": 12155, "ep_reward": 97.64009094238281, "reward": 0.6249828338623047, "action": -0.8066214323043823}
{"mode": "train", "epochs": 7, "timestep": 12156, "ep_reward": 98.3558120727539, "reward": 0.7157210111618042, "action": -0.5113157033920288}
{"mode": "train", "epochs": 7, "timestep": 12157, "ep_reward": 99.14154815673828, "reward": 0.7857351303100586, "action": -0.2974117398262024}
{"mode": "train", "epochs": 7, "timestep": 12158, "ep_reward": 99.97735595703125, "reward": 0.8358098268508911, "action": -0.7520602345466614}
{"mode": "train", "epochs": 7, "timestep": 12159, "ep_reward": 100.84066772460938, "reward": 0.8633115291595459, "action": -1.1884551048278809}
{"mode": "train", "epochs": 7, "timestep": 12160, "ep_reward": 101.71176147460938, "reward": 0.8710914850234985, "action": -1.44010591506958}
{"mode": "train", "epochs": 7, "timestep": 12161, "ep_reward": 102.57238006591797, "reward": 0.8606206774711609, "action": -1.186238408088684}
{"mode": "train", "epochs": 7, "timestep": 12162, "ep_reward": 103.40616607666016, "reward": 0.8337889909744263, "action": 0.06578850746154785}
{"mode": "train", "epochs": 7, "timestep": 12163, "ep_reward": 104.20347595214844, "reward": 0.797308087348938, "action": -0.7564946413040161}
{"mode": "train", "epochs": 7, "timestep": 12164, "ep_reward": 104.93016815185547, "reward": 0.7266954183578491, "action": -1.1733981370925903}
{"mode": "train", "epochs": 7, "timestep": 12165, "ep_reward": 105.54771423339844, "reward": 0.6175443530082703, "action": -0.49128639698028564}
{"mode": "train", "epochs": 7, "timestep": 12166, "ep_reward": 106.02569580078125, "reward": 0.47798532247543335, "action": -1.5322802066802979}
{"mode": "train", "epochs": 7, "timestep": 12167, "ep_reward": 106.35713195800781, "reward": 0.33143800497055054, "action": -1.3869315385818481}
{"mode": "train", "epochs": 7, "timestep": 12168, "ep_reward": 106.57481384277344, "reward": 0.21768558025360107, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 12169, "ep_reward": 106.65909576416016, "reward": 0.08428442478179932, "action": -0.676239013671875}
{"mode": "train", "epochs": 7, "timestep": 12170, "ep_reward": 106.69254302978516, "reward": 0.03344905376434326, "action": -0.5562340021133423}
{"mode": "train", "epochs": 7, "timestep": 12171, "ep_reward": 106.86772155761719, "reward": 0.17517638206481934, "action": -0.7471973896026611}
{"mode": "train", "epochs": 7, "timestep": 12172, "ep_reward": 107.185791015625, "reward": 0.3180668354034424, "action": -0.7430384159088135}
{"mode": "train", "epochs": 7, "timestep": 12173, "ep_reward": 107.64147186279297, "reward": 0.45567822456359863, "action": -0.9967257976531982}
{"mode": "train", "epochs": 7, "timestep": 12174, "ep_reward": 108.21717834472656, "reward": 0.5757079124450684, "action": -1.4931106567382812}
{"mode": "train", "epochs": 7, "timestep": 12175, "ep_reward": 108.8879165649414, "reward": 0.6707411408424377, "action": -0.45575231313705444}
{"mode": "train", "epochs": 7, "timestep": 12176, "ep_reward": 109.6423568725586, "reward": 0.7544411420822144, "action": -0.5130554437637329}
{"mode": "train", "epochs": 7, "timestep": 12177, "ep_reward": 110.45706176757812, "reward": 0.8147047758102417, "action": -1.8273124694824219}
{"mode": "train", "epochs": 7, "timestep": 12178, "ep_reward": 111.30193328857422, "reward": 0.8448742032051086, "action": -0.667041540145874}
{"mode": "train", "epochs": 7, "timestep": 12179, "ep_reward": 112.17024230957031, "reward": 0.8683106899261475, "action": -0.7153657674789429}
{"mode": "train", "epochs": 7, "timestep": 12180, "ep_reward": 113.04576110839844, "reward": 0.8755195140838623, "action": -0.8905725479125977}
{"mode": "train", "epochs": 7, "timestep": 12181, "ep_reward": 113.91124725341797, "reward": 0.8654897212982178, "action": -1.167305827140808}
{"mode": "train", "epochs": 7, "timestep": 12182, "ep_reward": 114.74624633789062, "reward": 0.8349999785423279, "action": -1.1019169092178345}
{"mode": "train", "epochs": 7, "timestep": 12183, "ep_reward": 115.52859497070312, "reward": 0.7823466062545776, "action": -0.8075734972953796}
{"mode": "train", "epochs": 7, "timestep": 12184, "ep_reward": 116.232666015625, "reward": 0.7040707468986511, "action": -1.2092788219451904}
{"mode": "train", "epochs": 7, "timestep": 12185, "ep_reward": 116.81805419921875, "reward": 0.5853849649429321, "action": -0.590571939945221}
{"mode": "train", "epochs": 7, "timestep": 12186, "ep_reward": 117.25247192382812, "reward": 0.43441712856292725, "action": -1.298339605331421}
{"mode": "train", "epochs": 7, "timestep": 12187, "ep_reward": 117.55921936035156, "reward": 0.3067508339881897, "action": -0.8884060382843018}
{"mode": "train", "epochs": 7, "timestep": 12188, "ep_reward": 117.74761199951172, "reward": 0.18839097023010254, "action": -1.3473607301712036}
{"mode": "train", "epochs": 7, "timestep": 12189, "ep_reward": 117.79762268066406, "reward": 0.05000799894332886, "action": -1.791844367980957}
{"mode": "train", "epochs": 7, "timestep": 12190, "ep_reward": 117.86556243896484, "reward": 0.06794136762619019, "action": -1.5738868713378906}
{"mode": "train", "epochs": 7, "timestep": 12191, "ep_reward": 118.06946563720703, "reward": 0.20390045642852783, "action": -0.9721791744232178}
{"mode": "train", "epochs": 7, "timestep": 12192, "ep_reward": 118.41387939453125, "reward": 0.3444111943244934, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 12193, "ep_reward": 118.87985229492188, "reward": 0.4659738540649414, "action": -0.12366282939910889}
{"mode": "train", "epochs": 7, "timestep": 12194, "ep_reward": 119.47509765625, "reward": 0.5952479839324951, "action": -0.9676402807235718}
{"mode": "train", "epochs": 7, "timestep": 12195, "ep_reward": 120.1661376953125, "reward": 0.6910429000854492, "action": -1.5965867042541504}
{"mode": "train", "epochs": 7, "timestep": 12196, "ep_reward": 120.92394256591797, "reward": 0.757807195186615, "action": -0.7538753151893616}
{"mode": "train", "epochs": 7, "timestep": 12197, "ep_reward": 121.73516845703125, "reward": 0.8112260699272156, "action": -1.00568687915802}
{"mode": "train", "epochs": 7, "timestep": 12198, "ep_reward": 122.57734680175781, "reward": 0.8421762585639954, "action": -1.2113088369369507}
{"mode": "train", "epochs": 7, "timestep": 12199, "ep_reward": 123.43052673339844, "reward": 0.8531800508499146, "action": -1.1904233694076538}
{"mode": "train", "epochs": 7, "timestep": 12200, "ep_reward": 124.27667999267578, "reward": 0.8461565375328064, "action": -1.5312738418579102}
{"mode": "train", "epochs": 7, "timestep": 12201, "ep_reward": 125.09207153320312, "reward": 0.8153881430625916, "action": -1.5399198532104492}
{"mode": "train", "epochs": 7, "timestep": 12202, "ep_reward": 125.8507308959961, "reward": 0.7586557865142822, "action": -1.0913724899291992}
{"mode": "train", "epochs": 7, "timestep": 12203, "ep_reward": 126.52510833740234, "reward": 0.674376904964447, "action": -1.1172864437103271}
{"mode": "train", "epochs": 7, "timestep": 12204, "ep_reward": 127.07569885253906, "reward": 0.5505927801132202, "action": -0.5552803874015808}
{"mode": "train", "epochs": 7, "timestep": 12205, "ep_reward": 127.47645568847656, "reward": 0.400753378868103, "action": -0.5192018747329712}
{"mode": "train", "epochs": 7, "timestep": 12206, "ep_reward": 127.77783966064453, "reward": 0.3013826608657837, "action": -1.3708124160766602}
{"mode": "train", "epochs": 7, "timestep": 12207, "ep_reward": 127.96002960205078, "reward": 0.18219006061553955, "action": -0.7979283928871155}
{"mode": "train", "epochs": 7, "timestep": 12208, "ep_reward": 128.0029296875, "reward": 0.04290425777435303, "action": -0.9416360855102539}
{"mode": "train", "epochs": 7, "timestep": 12209, "ep_reward": 128.07801818847656, "reward": 0.07508140802383423, "action": -1.2511581182479858}
{"mode": "train", "epochs": 7, "timestep": 12210, "ep_reward": 128.2880096435547, "reward": 0.2099871039390564, "action": -1.1382935047149658}
{"mode": "train", "epochs": 7, "timestep": 12211, "ep_reward": 128.63662719726562, "reward": 0.3486195206642151, "action": -1.3739356994628906}
{"mode": "train", "epochs": 7, "timestep": 12212, "ep_reward": 129.1141357421875, "reward": 0.4775117039680481, "action": -0.7393914461135864}
{"mode": "train", "epochs": 7, "timestep": 12213, "ep_reward": 129.71209716796875, "reward": 0.597954273223877, "action": -0.7371680736541748}
{"mode": "train", "epochs": 7, "timestep": 12214, "ep_reward": 130.40762329101562, "reward": 0.695518970489502, "action": -0.8015746474266052}
{"mode": "train", "epochs": 7, "timestep": 12215, "ep_reward": 131.1762237548828, "reward": 0.7686066627502441, "action": -1.1497102975845337}
{"mode": "train", "epochs": 7, "timestep": 12216, "ep_reward": 131.99295043945312, "reward": 0.8167283535003662, "action": -1.2077734470367432}
{"mode": "train", "epochs": 7, "timestep": 12217, "ep_reward": 132.8381805419922, "reward": 0.8452312350273132, "action": -1.5963068008422852}
{"mode": "train", "epochs": 7, "timestep": 12218, "ep_reward": 133.6910400390625, "reward": 0.8528528213500977, "action": -0.3421168923377991}
{"mode": "train", "epochs": 7, "timestep": 12219, "ep_reward": 134.544677734375, "reward": 0.8536306619644165, "action": -1.1505917310714722}
{"mode": "train", "epochs": 7, "timestep": 12220, "ep_reward": 135.3726806640625, "reward": 0.827997088432312, "action": -0.29382771253585815}
{"mode": "train", "epochs": 7, "timestep": 12221, "ep_reward": 136.16075134277344, "reward": 0.7880755662918091, "action": -0.8378956913948059}
{"mode": "train", "epochs": 7, "timestep": 12222, "ep_reward": 136.87586975097656, "reward": 0.7151235938072205, "action": -1.4187546968460083}
{"mode": "train", "epochs": 7, "timestep": 12223, "ep_reward": 137.4756317138672, "reward": 0.5997679233551025, "action": -0.225547194480896}
{"mode": "train", "epochs": 7, "timestep": 12224, "ep_reward": 137.9355010986328, "reward": 0.4598769545555115, "action": -1.2356197834014893}
{"mode": "train", "epochs": 7, "timestep": 12225, "ep_reward": 138.262451171875, "reward": 0.3269440531730652, "action": -1.108545184135437}
{"mode": "train", "epochs": 7, "timestep": 12226, "ep_reward": 138.4749755859375, "reward": 0.21251976490020752, "action": -0.3211061954498291}
{"mode": "train", "epochs": 7, "timestep": 12227, "ep_reward": 138.55300903320312, "reward": 0.07802873849868774, "action": -0.2167567014694214}
{"mode": "train", "epochs": 7, "timestep": 12228, "ep_reward": 138.59292602539062, "reward": 0.039912402629852295, "action": -1.2698066234588623}
{"mode": "train", "epochs": 7, "timestep": 12229, "ep_reward": 138.77252197265625, "reward": 0.17960339784622192, "action": -1.0896239280700684}
{"mode": "train", "epochs": 7, "timestep": 12230, "ep_reward": 139.09112548828125, "reward": 0.31860941648483276, "action": -0.7093968391418457}
{"mode": "train", "epochs": 7, "timestep": 12231, "ep_reward": 139.5484619140625, "reward": 0.45732980966567993, "action": -1.296692967414856}
{"mode": "train", "epochs": 7, "timestep": 12232, "ep_reward": 140.12261962890625, "reward": 0.5741527676582336, "action": -1.186416745185852}
{"mode": "train", "epochs": 7, "timestep": 12233, "ep_reward": 140.79498291015625, "reward": 0.6723557710647583, "action": -0.6699522733688354}
{"mode": "train", "epochs": 7, "timestep": 12234, "ep_reward": 141.54795837402344, "reward": 0.7529703378677368, "action": -1.1320313215255737}
{"mode": "train", "epochs": 7, "timestep": 12235, "ep_reward": 142.3547821044922, "reward": 0.8068195581436157, "action": -1.2153360843658447}
{"mode": "train", "epochs": 7, "timestep": 12236, "ep_reward": 143.1953125, "reward": 0.8405305743217468, "action": -0.9860590100288391}
{"mode": "train", "epochs": 7, "timestep": 12237, "ep_reward": 144.05386352539062, "reward": 0.8585568070411682, "action": -0.5824781656265259}
{"mode": "train", "epochs": 7, "timestep": 12238, "ep_reward": 144.91688537597656, "reward": 0.8630279302597046, "action": -0.48912155628204346}
{"mode": "train", "epochs": 7, "timestep": 12239, "ep_reward": 145.76776123046875, "reward": 0.8508737087249756, "action": -1.2245309352874756}
{"mode": "train", "epochs": 7, "timestep": 12240, "ep_reward": 146.57972717285156, "reward": 0.8119680881500244, "action": -1.2377972602844238}
{"mode": "train", "epochs": 7, "timestep": 12241, "ep_reward": 147.32664489746094, "reward": 0.7469227313995361, "action": -0.9116517305374146}
{"mode": "train", "epochs": 7, "timestep": 12242, "ep_reward": 147.97930908203125, "reward": 0.6526587009429932, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 12243, "ep_reward": 148.4827880859375, "reward": 0.5034846067428589, "action": -0.8284255862236023}
{"mode": "train", "epochs": 7, "timestep": 12244, "ep_reward": 148.84727478027344, "reward": 0.3644863963127136, "action": -1.3101787567138672}
{"mode": "train", "epochs": 7, "timestep": 12245, "ep_reward": 149.10482788085938, "reward": 0.25755053758621216, "action": -0.2906416058540344}
{"mode": "train", "epochs": 7, "timestep": 12246, "ep_reward": 149.23529052734375, "reward": 0.13046550750732422, "action": -0.9155739545822144}
{"mode": "train", "epochs": 7, "timestep": 12247, "ep_reward": 149.21873474121094, "reward": -0.016557812690734863, "action": -0.7752072811126709}
{"mode": "train", "epochs": 7, "timestep": 12248, "ep_reward": 149.3486785888672, "reward": 0.12994170188903809, "action": -1.2576580047607422e-05}
{"mode": "train", "epochs": 7, "timestep": 12249, "ep_reward": 149.6300506591797, "reward": 0.28137654066085815, "action": -0.6025115251541138}
{"mode": "train", "epochs": 7, "timestep": 12250, "ep_reward": 150.0513153076172, "reward": 0.4212721586227417, "action": -1.240721583366394}
{"mode": "train", "epochs": 7, "timestep": 12251, "ep_reward": 150.59339904785156, "reward": 0.5420815944671631, "action": -1.685971736907959}
{"mode": "train", "epochs": 7, "timestep": 12252, "ep_reward": 151.2346649169922, "reward": 0.641261100769043, "action": -1.1912314891815186}
{"mode": "train", "epochs": 7, "timestep": 12253, "ep_reward": 151.9602508544922, "reward": 0.7255934476852417, "action": -0.17530596256256104}
{"mode": "train", "epochs": 7, "timestep": 12254, "ep_reward": 152.7577362060547, "reward": 0.7974837422370911, "action": -0.6100790500640869}
{"mode": "train", "epochs": 7, "timestep": 12255, "ep_reward": 153.60223388671875, "reward": 0.8445051908493042, "action": -1.2194697856903076}
{"mode": "train", "epochs": 7, "timestep": 12256, "ep_reward": 154.47181701660156, "reward": 0.8695876598358154, "action": -1.580545425415039}
{"mode": "train", "epochs": 7, "timestep": 12257, "ep_reward": 155.3488311767578, "reward": 0.8770119547843933, "action": -1.6514065265655518}
{"mode": "train", "epochs": 7, "timestep": 12258, "ep_reward": 156.21759033203125, "reward": 0.8687625527381897, "action": -1.019015908241272}
{"mode": "train", "epochs": 7, "timestep": 12259, "ep_reward": 157.06600952148438, "reward": 0.8484212160110474, "action": -1.8409626483917236}
{"mode": "train", "epochs": 7, "timestep": 12260, "ep_reward": 157.86526489257812, "reward": 0.7992510199546814, "action": -0.7408227920532227}
{"mode": "train", "epochs": 7, "timestep": 12261, "ep_reward": 158.59877014160156, "reward": 0.7335028648376465, "action": -1.697500228881836}
{"mode": "train", "epochs": 7, "timestep": 12262, "ep_reward": 159.2211151123047, "reward": 0.6223405599594116, "action": -0.8756129741668701}
{"mode": "train", "epochs": 7, "timestep": 12263, "ep_reward": 159.70114135742188, "reward": 0.4800271987915039, "action": -0.42977994680404663}
{"mode": "train", "epochs": 7, "timestep": 12264, "ep_reward": 160.046875, "reward": 0.3457355499267578, "action": -1.0021761655807495}
{"mode": "train", "epochs": 7, "timestep": 12265, "ep_reward": 160.2816925048828, "reward": 0.23481708765029907, "action": -1.5175540447235107}
{"mode": "train", "epochs": 7, "timestep": 12266, "ep_reward": 160.38575744628906, "reward": 0.10406452417373657, "action": -0.9719536304473877}
{"mode": "train", "epochs": 7, "timestep": 12267, "ep_reward": 160.39805603027344, "reward": 0.012304484844207764, "action": -0.22141945362091064}
{"mode": "train", "epochs": 7, "timestep": 12268, "ep_reward": 160.55557250976562, "reward": 0.15752285718917847, "action": -0.6744695901870728}
{"mode": "train", "epochs": 7, "timestep": 12269, "ep_reward": 160.85638427734375, "reward": 0.30080950260162354, "action": -0.8849929571151733}
{"mode": "train", "epochs": 7, "timestep": 12270, "ep_reward": 161.2939453125, "reward": 0.4375637173652649, "action": -0.04720628261566162}
{"mode": "train", "epochs": 7, "timestep": 12271, "ep_reward": 161.86436462402344, "reward": 0.5704236626625061, "action": -1.1048853397369385}
{"mode": "train", "epochs": 7, "timestep": 12272, "ep_reward": 162.53466796875, "reward": 0.6702962517738342, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 12273, "ep_reward": 163.275634765625, "reward": 0.7409676313400269, "action": -1.1936758756637573}
{"mode": "train", "epochs": 7, "timestep": 12274, "ep_reward": 164.07513427734375, "reward": 0.7995035648345947, "action": -1.8329517841339111}
{"mode": "train", "epochs": 7, "timestep": 12275, "ep_reward": 164.90872192382812, "reward": 0.8335898518562317, "action": -1.0838544368743896}
{"mode": "train", "epochs": 7, "timestep": 12276, "ep_reward": 165.76553344726562, "reward": 0.8568055629730225, "action": -1.40481436252594}
{"mode": "train", "epochs": 7, "timestep": 12277, "ep_reward": 166.6260223388672, "reward": 0.860491156578064, "action": -1.1292487382888794}
{"mode": "train", "epochs": 7, "timestep": 12278, "ep_reward": 167.47499084472656, "reward": 0.8489728569984436, "action": -1.0800096988677979}
{"mode": "train", "epochs": 7, "timestep": 12279, "ep_reward": 168.29278564453125, "reward": 0.8178008198738098, "action": -0.6112639904022217}
{"mode": "train", "epochs": 7, "timestep": 12280, "ep_reward": 169.0597381591797, "reward": 0.7669550180435181, "action": -1.4051977396011353}
{"mode": "train", "epochs": 7, "timestep": 12281, "ep_reward": 169.73643493652344, "reward": 0.6766940355300903, "action": -1.3606609106063843}
{"mode": "train", "epochs": 7, "timestep": 12282, "ep_reward": 170.2838134765625, "reward": 0.5473740100860596, "action": -1.2531187534332275}
{"mode": "train", "epochs": 7, "timestep": 12283, "ep_reward": 170.6743621826172, "reward": 0.3905501961708069, "action": -0.5009266138076782}
{"mode": "train", "epochs": 7, "timestep": 12284, "ep_reward": 170.96322631835938, "reward": 0.2888637185096741, "action": -1.667270302772522}
{"mode": "train", "epochs": 7, "timestep": 12285, "ep_reward": 171.13063049316406, "reward": 0.16740518808364868, "action": -1.2884654998779297}
{"mode": "train", "epochs": 7, "timestep": 12286, "ep_reward": 171.15646362304688, "reward": 0.025831162929534912, "action": -1.5444550514221191}
{"mode": "train", "epochs": 7, "timestep": 12287, "ep_reward": 171.24786376953125, "reward": 0.09139519929885864, "action": -0.4830227494239807}
{"mode": "train", "epochs": 7, "timestep": 12288, "ep_reward": 171.4837188720703, "reward": 0.2358596920967102, "action": -0.4932768940925598}
{"mode": "train", "epochs": 7, "timestep": 12289, "ep_reward": 171.86373901367188, "reward": 0.38002127408981323, "action": -0.49224358797073364}
{"mode": "train", "epochs": 7, "timestep": 12290, "ep_reward": 172.37796020507812, "reward": 0.5142245888710022, "action": -0.5329373478889465}
{"mode": "train", "epochs": 7, "timestep": 12291, "ep_reward": 173.00790405273438, "reward": 0.6299362182617188, "action": -0.01372992992401123}
{"mode": "train", "epochs": 7, "timestep": 12292, "ep_reward": 173.73626708984375, "reward": 0.728369951248169, "action": -1.2435073852539062}
{"mode": "train", "epochs": 7, "timestep": 12293, "ep_reward": 174.52957153320312, "reward": 0.7933074235916138, "action": -0.7274307608604431}
{"mode": "train", "epochs": 7, "timestep": 12294, "ep_reward": 175.37371826171875, "reward": 0.8441487550735474, "action": -1.5263190269470215}
{"mode": "train", "epochs": 7, "timestep": 12295, "ep_reward": 176.24667358398438, "reward": 0.8729568719863892, "action": -1.0063354969024658}
{"mode": "train", "epochs": 7, "timestep": 12296, "ep_reward": 177.13885498046875, "reward": 0.8921855688095093, "action": -0.8540077805519104}
{"mode": "train", "epochs": 7, "timestep": 12297, "ep_reward": 178.03875732421875, "reward": 0.8998989462852478, "action": -0.8266016244888306}
{"mode": "train", "epochs": 7, "timestep": 12298, "ep_reward": 178.9339599609375, "reward": 0.8952025771141052, "action": -1.671018123626709}
{"mode": "train", "epochs": 7, "timestep": 12299, "ep_reward": 179.8036346435547, "reward": 0.8696718215942383, "action": -1.822029948234558}
{"mode": "train", "epochs": 7, "timestep": 12300, "ep_reward": 180.62713623046875, "reward": 0.8235069513320923, "action": -1.280737042427063}
{"mode": "train", "epochs": 7, "timestep": 12301, "ep_reward": 181.38400268554688, "reward": 0.7568730711936951, "action": -1.2596276998519897}
{"mode": "train", "epochs": 7, "timestep": 12302, "ep_reward": 182.042236328125, "reward": 0.6582277417182922, "action": -1.6636040210723877}
{"mode": "train", "epochs": 7, "timestep": 12303, "ep_reward": 182.5565643310547, "reward": 0.5143285989761353, "action": -1.726309061050415}
{"mode": "train", "epochs": 7, "timestep": 12304, "ep_reward": 182.9151153564453, "reward": 0.3585541844367981, "action": -0.9449729323387146}
{"mode": "train", "epochs": 7, "timestep": 12305, "ep_reward": 183.16539001464844, "reward": 0.2502775192260742, "action": -1.0513256788253784}
{"mode": "train", "epochs": 7, "timestep": 12306, "ep_reward": 183.2874298095703, "reward": 0.12203919887542725, "action": -0.8379637002944946}
{"mode": "train", "epochs": 7, "timestep": 12307, "ep_reward": 183.27978515625, "reward": -0.007650852203369141, "action": -0.9860547184944153}
{"mode": "train", "epochs": 7, "timestep": 12308, "ep_reward": 183.41796875, "reward": 0.13818800449371338, "action": -1.3776384592056274}
{"mode": "train", "epochs": 7, "timestep": 12309, "ep_reward": 183.6907501220703, "reward": 0.2727816700935364, "action": -0.9008192420005798}
{"mode": "train", "epochs": 7, "timestep": 12310, "ep_reward": 184.10308837890625, "reward": 0.41234368085861206, "action": -1.1407337188720703}
{"mode": "train", "epochs": 7, "timestep": 12311, "ep_reward": 184.6401824951172, "reward": 0.5370886921882629, "action": -0.5899568796157837}
{"mode": "train", "epochs": 7, "timestep": 12312, "ep_reward": 185.28868103027344, "reward": 0.6484992504119873, "action": -1.8577975034713745}
{"mode": "train", "epochs": 7, "timestep": 12313, "ep_reward": 186.0126190185547, "reward": 0.7239314317703247, "action": -0.320065975189209}
{"mode": "train", "epochs": 7, "timestep": 12314, "ep_reward": 186.80532836914062, "reward": 0.792710542678833, "action": -0.2464424967765808}
{"mode": "train", "epochs": 7, "timestep": 12315, "ep_reward": 187.64544677734375, "reward": 0.8401222229003906, "action": -1.2001817226409912}
{"mode": "train", "epochs": 7, "timestep": 12316, "ep_reward": 188.50657653808594, "reward": 0.8611282706260681, "action": -0.8138610124588013}
{"mode": "train", "epochs": 7, "timestep": 12317, "ep_reward": 189.3756561279297, "reward": 0.8690760135650635, "action": -0.9930945038795471}
{"mode": "train", "epochs": 7, "timestep": 12318, "ep_reward": 190.23448181152344, "reward": 0.8588268160820007, "action": -1.846177339553833}
{"mode": "train", "epochs": 7, "timestep": 12319, "ep_reward": 191.05618286132812, "reward": 0.821696400642395, "action": -0.475588858127594}
{"mode": "train", "epochs": 7, "timestep": 12320, "ep_reward": 191.8297882080078, "reward": 0.7736027836799622, "action": -0.7419375777244568}
{"mode": "train", "epochs": 7, "timestep": 12321, "ep_reward": 192.52369689941406, "reward": 0.6939159631729126, "action": -0.8231163024902344}
{"mode": "train", "epochs": 7, "timestep": 12322, "ep_reward": 193.10125732421875, "reward": 0.5775635242462158, "action": -0.9342191815376282}
{"mode": "train", "epochs": 7, "timestep": 12323, "ep_reward": 193.52005004882812, "reward": 0.4188002347946167, "action": -1.2664425373077393}
{"mode": "train", "epochs": 7, "timestep": 12324, "ep_reward": 193.8209228515625, "reward": 0.3008667230606079, "action": -1.767529010772705}
{"mode": "train", "epochs": 7, "timestep": 12325, "ep_reward": 194.0026092529297, "reward": 0.18168669939041138, "action": -0.6227646470069885}
{"mode": "train", "epochs": 7, "timestep": 12326, "ep_reward": 194.04481506347656, "reward": 0.04221159219741821, "action": -1.5407922267913818}
{"mode": "train", "epochs": 7, "timestep": 12327, "ep_reward": 194.1205291748047, "reward": 0.07571709156036377, "action": -0.8455712795257568}
{"mode": "train", "epochs": 7, "timestep": 12328, "ep_reward": 194.33575439453125, "reward": 0.21521925926208496, "action": -0.32963794469833374}
{"mode": "train", "epochs": 7, "timestep": 12329, "ep_reward": 194.69850158691406, "reward": 0.3627434968948364, "action": -1.5486979484558105}
{"mode": "train", "epochs": 7, "timestep": 12330, "ep_reward": 195.185302734375, "reward": 0.48680782318115234, "action": -1.2722734212875366}
{"mode": "train", "epochs": 7, "timestep": 12331, "ep_reward": 195.78489685058594, "reward": 0.5995899438858032, "action": -0.6127318739891052}
{"mode": "train", "epochs": 7, "timestep": 12332, "ep_reward": 196.4832305908203, "reward": 0.6983327269554138, "action": -1.0935604572296143}
{"mode": "train", "epochs": 7, "timestep": 12333, "ep_reward": 197.2521514892578, "reward": 0.768919050693512, "action": -1.760028600692749}
{"mode": "train", "epochs": 7, "timestep": 12334, "ep_reward": 198.06503295898438, "reward": 0.8128889203071594, "action": -1.4453754425048828}
{"mode": "train", "epochs": 7, "timestep": 12335, "ep_reward": 198.9063262939453, "reward": 0.841286838054657, "action": -1.065381407737732}
{"mode": "train", "epochs": 7, "timestep": 12336, "ep_reward": 199.7615966796875, "reward": 0.8552722930908203, "action": -0.7330583333969116}
{"mode": "train", "epochs": 7, "timestep": 12337, "ep_reward": 200.61610412597656, "reward": 0.8545016050338745, "action": -0.8091779947280884}
{"mode": "train", "epochs": 7, "timestep": 12338, "ep_reward": 201.45040893554688, "reward": 0.8342980742454529, "action": -0.29919207096099854}
{"mode": "train", "epochs": 7, "timestep": 12339, "ep_reward": 202.24781799316406, "reward": 0.7974100112915039, "action": -0.9104008674621582}
{"mode": "train", "epochs": 7, "timestep": 12340, "ep_reward": 202.97552490234375, "reward": 0.7277015447616577, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 12341, "ep_reward": 203.58517456054688, "reward": 0.6096563935279846, "action": -0.6500102877616882}
{"mode": "train", "epochs": 7, "timestep": 12342, "ep_reward": 204.05181884765625, "reward": 0.46664220094680786, "action": -1.6989717483520508}
{"mode": "train", "epochs": 7, "timestep": 12343, "ep_reward": 204.38937377929688, "reward": 0.3375564217567444, "action": -0.7870887517929077}
{"mode": "train", "epochs": 7, "timestep": 12344, "ep_reward": 204.61436462402344, "reward": 0.22499698400497437, "action": -1.5326590538024902}
{"mode": "train", "epochs": 7, "timestep": 12345, "ep_reward": 204.7069549560547, "reward": 0.09258967638015747, "action": -1.2811096906661987}
{"mode": "train", "epochs": 7, "timestep": 12346, "ep_reward": 204.73153686523438, "reward": 0.02458930015563965, "action": -0.6564344167709351}
{"mode": "train", "epochs": 7, "timestep": 12347, "ep_reward": 204.89781188964844, "reward": 0.16627168655395508, "action": -0.922250509262085}
{"mode": "train", "epochs": 7, "timestep": 12348, "ep_reward": 205.20494079589844, "reward": 0.30713146924972534, "action": -0.6709470748901367}
{"mode": "train", "epochs": 7, "timestep": 12349, "ep_reward": 205.65171813964844, "reward": 0.44677287340164185, "action": -0.811913251876831}
{"mode": "train", "epochs": 7, "timestep": 12350, "ep_reward": 206.22198486328125, "reward": 0.5702674388885498, "action": -0.8747106194496155}
{"mode": "train", "epochs": 7, "timestep": 12351, "ep_reward": 206.8945770263672, "reward": 0.6725980043411255, "action": -1.031040906906128}
{"mode": "train", "epochs": 7, "timestep": 12352, "ep_reward": 207.64559936523438, "reward": 0.7510274648666382, "action": -0.3581932783126831}
{"mode": "train", "epochs": 7, "timestep": 12353, "ep_reward": 208.4595184326172, "reward": 0.813918948173523, "action": -1.4097845554351807}
{"mode": "train", "epochs": 7, "timestep": 12354, "ep_reward": 209.30801391601562, "reward": 0.8485016226768494, "action": -1.3078782558441162}
{"mode": "train", "epochs": 7, "timestep": 12355, "ep_reward": 210.17579650878906, "reward": 0.8677765727043152, "action": -1.446063756942749}
{"mode": "train", "epochs": 7, "timestep": 12356, "ep_reward": 211.04637145996094, "reward": 0.8705694079399109, "action": -0.08792734146118164}
{"mode": "train", "epochs": 7, "timestep": 12357, "ep_reward": 211.9150848388672, "reward": 0.8687161803245544, "action": -0.9761554002761841}
{"mode": "train", "epochs": 7, "timestep": 12358, "ep_reward": 212.75709533691406, "reward": 0.8420043587684631, "action": -0.8429896235466003}
{"mode": "train", "epochs": 7, "timestep": 12359, "ep_reward": 213.55223083496094, "reward": 0.7951412796974182, "action": -0.6146689653396606}
{"mode": "train", "epochs": 7, "timestep": 12360, "ep_reward": 214.2762451171875, "reward": 0.7240116596221924, "action": -0.6255917549133301}
{"mode": "train", "epochs": 7, "timestep": 12361, "ep_reward": 214.89645385742188, "reward": 0.6202045679092407, "action": -0.9344463348388672}
{"mode": "train", "epochs": 7, "timestep": 12362, "ep_reward": 215.3704833984375, "reward": 0.4740321636199951, "action": -0.37778979539871216}
{"mode": "train", "epochs": 7, "timestep": 12363, "ep_reward": 215.69595336914062, "reward": 0.32547593116760254, "action": -1.1399123668670654}
{"mode": "train", "epochs": 7, "timestep": 12364, "ep_reward": 215.90672302246094, "reward": 0.21076816320419312, "action": -0.47234445810317993}
{"mode": "train", "epochs": 7, "timestep": 12365, "ep_reward": 215.9826202392578, "reward": 0.07590055465698242, "action": -1.3043304681777954}
{"mode": "train", "epochs": 7, "timestep": 12366, "ep_reward": 216.02467346191406, "reward": 0.04205375909805298, "action": -0.9240820407867432}
{"mode": "train", "epochs": 7, "timestep": 12367, "ep_reward": 216.20616149902344, "reward": 0.18149185180664062, "action": -0.04229915142059326}
{"mode": "train", "epochs": 7, "timestep": 12368, "ep_reward": 216.53955078125, "reward": 0.3333844542503357, "action": -0.7598516345024109}
{"mode": "train", "epochs": 7, "timestep": 12369, "ep_reward": 217.0083465576172, "reward": 0.46879905462265015, "action": -0.17593705654144287}
{"mode": "train", "epochs": 7, "timestep": 12370, "ep_reward": 217.60366821289062, "reward": 0.5953160524368286, "action": -1.7935110330581665}
{"mode": "train", "epochs": 7, "timestep": 12371, "ep_reward": 218.28761291503906, "reward": 0.6839480400085449, "action": -0.9425447583198547}
{"mode": "train", "epochs": 7, "timestep": 12372, "ep_reward": 219.04855346679688, "reward": 0.7609410881996155, "action": -1.007438063621521}
{"mode": "train", "epochs": 7, "timestep": 12373, "ep_reward": 219.86526489257812, "reward": 0.8167076706886292, "action": -0.5946041345596313}
{"mode": "train", "epochs": 7, "timestep": 12374, "ep_reward": 220.72279357910156, "reward": 0.8575292825698853, "action": -0.8760260343551636}
{"mode": "train", "epochs": 7, "timestep": 12375, "ep_reward": 221.60287475585938, "reward": 0.880074679851532, "action": -0.9367853403091431}
{"mode": "train", "epochs": 7, "timestep": 12376, "ep_reward": 222.49075317382812, "reward": 0.8878799676895142, "action": -1.84059476852417}
{"mode": "train", "epochs": 7, "timestep": 12377, "ep_reward": 223.3651123046875, "reward": 0.8743621110916138, "action": -1.549844741821289}
{"mode": "train", "epochs": 7, "timestep": 12378, "ep_reward": 224.21104431152344, "reward": 0.845924973487854, "action": -0.7557981610298157}
{"mode": "train", "epochs": 7, "timestep": 12379, "ep_reward": 225.0145721435547, "reward": 0.8035241365432739, "action": -0.7620628476142883}
{"mode": "train", "epochs": 7, "timestep": 12380, "ep_reward": 225.74984741210938, "reward": 0.7352710962295532, "action": -0.26112061738967896}
{"mode": "train", "epochs": 7, "timestep": 12381, "ep_reward": 226.39117431640625, "reward": 0.6413341760635376, "action": -0.9939951300621033}
{"mode": "train", "epochs": 7, "timestep": 12382, "ep_reward": 226.89231872558594, "reward": 0.5011505484580994, "action": -0.11559480428695679}
{"mode": "train", "epochs": 7, "timestep": 12383, "ep_reward": 227.23399353027344, "reward": 0.34167951345443726, "action": -1.6144115924835205}
{"mode": "train", "epochs": 7, "timestep": 12384, "ep_reward": 227.4640350341797, "reward": 0.23004722595214844, "action": -1.6796331405639648}
{"mode": "train", "epochs": 7, "timestep": 12385, "ep_reward": 227.5626220703125, "reward": 0.09858042001724243, "action": -0.6200926303863525}
{"mode": "train", "epochs": 7, "timestep": 12386, "ep_reward": 227.58079528808594, "reward": 0.018178820610046387, "action": -1.297187089920044}
{"mode": "train", "epochs": 7, "timestep": 12387, "ep_reward": 227.74156188964844, "reward": 0.16076481342315674, "action": -0.9817708730697632}
{"mode": "train", "epochs": 7, "timestep": 12388, "ep_reward": 228.04234313964844, "reward": 0.3007775545120239, "action": -0.7621334195137024}
{"mode": "train", "epochs": 7, "timestep": 12389, "ep_reward": 228.48204040527344, "reward": 0.4396965503692627, "action": -1.6145133972167969}
{"mode": "train", "epochs": 7, "timestep": 12390, "ep_reward": 229.03732299804688, "reward": 0.5552853345870972, "action": -0.8510141968727112}
{"mode": "train", "epochs": 7, "timestep": 12391, "ep_reward": 229.69784545898438, "reward": 0.6605286598205566, "action": -1.6104888916015625}
{"mode": "train", "epochs": 7, "timestep": 12392, "ep_reward": 230.43312072753906, "reward": 0.7352707386016846, "action": -0.7336342334747314}
{"mode": "train", "epochs": 7, "timestep": 12393, "ep_reward": 231.22982788085938, "reward": 0.7967132925987244, "action": -1.3849328756332397}
{"mode": "train", "epochs": 7, "timestep": 12394, "ep_reward": 232.0613250732422, "reward": 0.831498384475708, "action": -1.522007942199707}
{"mode": "train", "epochs": 7, "timestep": 12395, "ep_reward": 232.90794372558594, "reward": 0.8466233611106873, "action": -1.8861188888549805}
{"mode": "train", "epochs": 7, "timestep": 12396, "ep_reward": 233.7480926513672, "reward": 0.8401507139205933, "action": -0.8651265501976013}
{"mode": "train", "epochs": 7, "timestep": 12397, "ep_reward": 234.57058715820312, "reward": 0.8224889636039734, "action": -1.7033612728118896}
{"mode": "train", "epochs": 7, "timestep": 12398, "ep_reward": 235.3428497314453, "reward": 0.7722585797309875, "action": -0.7428684234619141}
{"mode": "train", "epochs": 7, "timestep": 12399, "ep_reward": 236.04470825195312, "reward": 0.701851487159729, "action": -1.0353262424468994}
{"mode": "train", "epochs": 7, "timestep": 12400, "ep_reward": 236.63604736328125, "reward": 0.5913387537002563, "action": -0.9634577035903931}
{"mode": "train", "epochs": 7, "timestep": 12401, "ep_reward": 237.0749053955078, "reward": 0.4388507008552551, "action": -1.2283339500427246}
{"mode": "train", "epochs": 7, "timestep": 12402, "ep_reward": 237.40805053710938, "reward": 0.3331454396247864, "action": -1.4272172451019287}
{"mode": "train", "epochs": 7, "timestep": 12403, "ep_reward": 237.62802124023438, "reward": 0.2199755311012268, "action": -0.2938106656074524}
{"mode": "train", "epochs": 7, "timestep": 12404, "ep_reward": 237.71469116210938, "reward": 0.08666867017745972, "action": -0.5720514059066772}
{"mode": "train", "epochs": 7, "timestep": 12405, "ep_reward": 237.74557495117188, "reward": 0.030888140201568604, "action": -1.165037751197815}
{"mode": "train", "epochs": 7, "timestep": 12406, "ep_reward": 237.91737365722656, "reward": 0.17179369926452637, "action": -0.8726028800010681}
{"mode": "train", "epochs": 7, "timestep": 12407, "ep_reward": 238.23074340820312, "reward": 0.31336796283721924, "action": -0.5839605331420898}
{"mode": "train", "epochs": 7, "timestep": 12408, "ep_reward": 238.684326171875, "reward": 0.4535788893699646, "action": -0.6966092586517334}
{"mode": "train", "epochs": 7, "timestep": 12409, "ep_reward": 239.26162719726562, "reward": 0.577303409576416, "action": -1.0083764791488647}
{"mode": "train", "epochs": 7, "timestep": 12410, "ep_reward": 239.93858337402344, "reward": 0.6769559383392334, "action": -0.944145679473877}
{"mode": "train", "epochs": 7, "timestep": 12411, "ep_reward": 240.69363403320312, "reward": 0.7550544738769531, "action": -1.7393138408660889}
{"mode": "train", "epochs": 7, "timestep": 12412, "ep_reward": 241.49887084960938, "reward": 0.8052299618721008, "action": -0.4928852319717407}
{"mode": "train", "epochs": 7, "timestep": 12413, "ep_reward": 242.34661865234375, "reward": 0.8477441072463989, "action": -0.36474716663360596}
{"mode": "train", "epochs": 7, "timestep": 12414, "ep_reward": 243.22039794921875, "reward": 0.8737823367118835, "action": -0.9571269154548645}
{"mode": "train", "epochs": 7, "timestep": 12415, "ep_reward": 244.10018920898438, "reward": 0.8797954320907593, "action": -0.17189383506774902}
{"mode": "train", "epochs": 7, "timestep": 12416, "ep_reward": 244.9773712158203, "reward": 0.8771851062774658, "action": -1.2189807891845703}
{"mode": "train", "epochs": 7, "timestep": 12417, "ep_reward": 245.8269805908203, "reward": 0.849614143371582, "action": -0.2795860171318054}
{"mode": "train", "epochs": 7, "timestep": 12418, "ep_reward": 246.637451171875, "reward": 0.8104668855667114, "action": -0.6175925731658936}
{"mode": "train", "epochs": 7, "timestep": 12419, "ep_reward": 247.38124084472656, "reward": 0.7437924146652222, "action": 0.11441093683242798}
{"mode": "train", "epochs": 7, "timestep": 12420, "ep_reward": 248.03688049316406, "reward": 0.6556332111358643, "action": -1.9761031866073608}
{"mode": "train", "epochs": 7, "timestep": 12421, "ep_reward": 248.54147338867188, "reward": 0.5045876502990723, "action": -0.6328377723693848}
{"mode": "train", "epochs": 7, "timestep": 12422, "ep_reward": 248.8822021484375, "reward": 0.3407341241836548, "action": -1.3137271404266357}
{"mode": "train", "epochs": 7, "timestep": 12423, "ep_reward": 249.11111450195312, "reward": 0.22891342639923096, "action": -1.3445210456848145}
{"mode": "train", "epochs": 7, "timestep": 12424, "ep_reward": 249.20806884765625, "reward": 0.09696078300476074, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 12425, "ep_reward": 249.227783203125, "reward": 0.019715189933776855, "action": -1.0428568124771118}
{"mode": "train", "epochs": 7, "timestep": 12426, "ep_reward": 249.389892578125, "reward": 0.16210675239562988, "action": -0.5781198740005493}
{"mode": "train", "epochs": 7, "timestep": 12427, "ep_reward": 249.69703674316406, "reward": 0.3071431517601013, "action": -0.5181706547737122}
{"mode": "train", "epochs": 7, "timestep": 12428, "ep_reward": 250.14498901367188, "reward": 0.4479467272758484, "action": -0.5624588131904602}
{"mode": "train", "epochs": 7, "timestep": 12429, "ep_reward": 250.7183837890625, "reward": 0.573398232460022, "action": -1.885495662689209}
{"mode": "train", "epochs": 7, "timestep": 12430, "ep_reward": 251.3833770751953, "reward": 0.6649956703186035, "action": -1.320397973060608}
{"mode": "train", "epochs": 7, "timestep": 12431, "ep_reward": 252.12579345703125, "reward": 0.7424107789993286, "action": -0.7056487798690796}
{"mode": "train", "epochs": 7, "timestep": 12432, "ep_reward": 252.9300079345703, "reward": 0.8042206764221191, "action": -1.3183279037475586}
{"mode": "train", "epochs": 7, "timestep": 12433, "ep_reward": 253.77108764648438, "reward": 0.8410788178443909, "action": -0.10621857643127441}
{"mode": "train", "epochs": 7, "timestep": 12434, "ep_reward": 254.64186096191406, "reward": 0.8707782626152039, "action": -1.258228063583374}
{"mode": "train", "epochs": 7, "timestep": 12435, "ep_reward": 255.5171661376953, "reward": 0.8753024935722351, "action": -1.1347569227218628}
{"mode": "train", "epochs": 7, "timestep": 12436, "ep_reward": 256.3822326660156, "reward": 0.8650645017623901, "action": -1.4221267700195312}
{"mode": "train", "epochs": 7, "timestep": 12437, "ep_reward": 257.21630859375, "reward": 0.8340797424316406, "action": -0.8911839723587036}
{"mode": "train", "epochs": 7, "timestep": 12438, "ep_reward": 258.0016174316406, "reward": 0.7853071689605713, "action": -0.5775033831596375}
{"mode": "train", "epochs": 7, "timestep": 12439, "ep_reward": 258.7137451171875, "reward": 0.7121197581291199, "action": -0.346916139125824}
{"mode": "train", "epochs": 7, "timestep": 12440, "ep_reward": 259.3222961425781, "reward": 0.6085655689239502, "action": -1.2395683526992798}
{"mode": "train", "epochs": 7, "timestep": 12441, "ep_reward": 259.77630615234375, "reward": 0.45400387048721313, "action": -1.6044692993164062}
{"mode": "train", "epochs": 7, "timestep": 12442, "ep_reward": 260.0945739746094, "reward": 0.3182693123817444, "action": -0.8182475566864014}
{"mode": "train", "epochs": 7, "timestep": 12443, "ep_reward": 260.2966613769531, "reward": 0.20209425687789917, "action": -1.0404472351074219}
{"mode": "train", "epochs": 7, "timestep": 12444, "ep_reward": 260.36260986328125, "reward": 0.06593954563140869, "action": -1.0813676118850708}
{"mode": "train", "epochs": 7, "timestep": 12445, "ep_reward": 260.4148864746094, "reward": 0.0522649884223938, "action": -0.9689870476722717}
{"mode": "train", "epochs": 7, "timestep": 12446, "ep_reward": 260.6051940917969, "reward": 0.19031238555908203, "action": -0.5940167903900146}
{"mode": "train", "epochs": 7, "timestep": 12447, "ep_reward": 260.9407043457031, "reward": 0.3355110287666321, "action": -1.1742985248565674}
{"mode": "train", "epochs": 7, "timestep": 12448, "ep_reward": 261.40753173828125, "reward": 0.46682125329971313, "action": -1.1911718845367432}
{"mode": "train", "epochs": 7, "timestep": 12449, "ep_reward": 261.990966796875, "reward": 0.5834371447563171, "action": -1.3768900632858276}
{"mode": "train", "epochs": 7, "timestep": 12450, "ep_reward": 262.668701171875, "reward": 0.6777303218841553, "action": -1.4704673290252686}
{"mode": "train", "epochs": 7, "timestep": 12451, "ep_reward": 263.41778564453125, "reward": 0.7490857839584351, "action": -1.5118087530136108}
{"mode": "train", "epochs": 7, "timestep": 12452, "ep_reward": 264.21649169921875, "reward": 0.7987083196640015, "action": -1.237566351890564}
{"mode": "train", "epochs": 7, "timestep": 12453, "ep_reward": 265.04730224609375, "reward": 0.8308040499687195, "action": -1.1132140159606934}
{"mode": "train", "epochs": 7, "timestep": 12454, "ep_reward": 265.8921813964844, "reward": 0.8448894023895264, "action": -1.3708490133285522}
{"mode": "train", "epochs": 7, "timestep": 12455, "ep_reward": 266.7297058105469, "reward": 0.8375242948532104, "action": -1.1427092552185059}
{"mode": "train", "epochs": 7, "timestep": 12456, "ep_reward": 267.5407409667969, "reward": 0.8110251426696777, "action": -0.5316336154937744}
{"mode": "train", "epochs": 7, "timestep": 12457, "ep_reward": 268.3066101074219, "reward": 0.7658568620681763, "action": 0.09807074069976807}
{"mode": "train", "epochs": 7, "timestep": 12458, "ep_reward": 269.0056457519531, "reward": 0.699043869972229, "action": -0.6959352493286133}
{"mode": "train", "epochs": 7, "timestep": 12459, "ep_reward": 269.5940856933594, "reward": 0.5884347558021545, "action": -0.8278114795684814}
{"mode": "train", "epochs": 7, "timestep": 12460, "ep_reward": 270.0294494628906, "reward": 0.43534862995147705, "action": -1.117301344871521}
{"mode": "train", "epochs": 7, "timestep": 12461, "ep_reward": 270.34576416015625, "reward": 0.31632542610168457, "action": -1.2196847200393677}
{"mode": "train", "epochs": 7, "timestep": 12462, "ep_reward": 270.5456237792969, "reward": 0.19986259937286377, "action": -0.8992282152175903}
{"mode": "train", "epochs": 7, "timestep": 12463, "ep_reward": 270.60894775390625, "reward": 0.06332969665527344, "action": -1.1178393363952637}
{"mode": "train", "epochs": 7, "timestep": 12464, "ep_reward": 270.6636962890625, "reward": 0.05473828315734863, "action": -1.8636300563812256}
{"mode": "train", "epochs": 7, "timestep": 12465, "ep_reward": 270.8562316894531, "reward": 0.19253861904144287, "action": -1.069362998008728}
{"mode": "train", "epochs": 7, "timestep": 12466, "ep_reward": 271.1880187988281, "reward": 0.33179837465286255, "action": -1.7667731046676636}
{"mode": "train", "epochs": 7, "timestep": 12467, "ep_reward": 271.6451110839844, "reward": 0.4571019411087036, "action": -0.8691167235374451}
{"mode": "train", "epochs": 7, "timestep": 12468, "ep_reward": 272.2242736816406, "reward": 0.5791547298431396, "action": -1.8656015396118164}
{"mode": "train", "epochs": 7, "timestep": 12469, "ep_reward": 272.8929748535156, "reward": 0.6687014698982239, "action": -1.4178292751312256}
{"mode": "train", "epochs": 7, "timestep": 12470, "ep_reward": 273.6338806152344, "reward": 0.7409088611602783, "action": -0.1747528314590454}
{"mode": "train", "epochs": 7, "timestep": 12471, "ep_reward": 274.43585205078125, "reward": 0.8019612431526184, "action": -1.6522414684295654}
{"mode": "train", "epochs": 7, "timestep": 12472, "ep_reward": 275.26336669921875, "reward": 0.8275136351585388, "action": -0.3678455352783203}
{"mode": "train", "epochs": 7, "timestep": 12473, "ep_reward": 276.1086120605469, "reward": 0.8452329039573669, "action": -1.6819086074829102}
{"mode": "train", "epochs": 7, "timestep": 12474, "ep_reward": 276.93994140625, "reward": 0.8313300013542175, "action": -0.8633352518081665}
{"mode": "train", "epochs": 7, "timestep": 12475, "ep_reward": 277.742919921875, "reward": 0.8029689788818359, "action": -1.3536081314086914}
{"mode": "train", "epochs": 7, "timestep": 12476, "ep_reward": 278.48577880859375, "reward": 0.7428483963012695, "action": -0.5462783575057983}
{"mode": "train", "epochs": 7, "timestep": 12477, "ep_reward": 279.1446838378906, "reward": 0.6588922739028931, "action": -1.286855697631836}
{"mode": "train", "epochs": 7, "timestep": 12478, "ep_reward": 279.6705017089844, "reward": 0.5258247256278992, "action": -1.7185940742492676}
{"mode": "train", "epochs": 7, "timestep": 12479, "ep_reward": 280.0567626953125, "reward": 0.3862478733062744, "action": -1.4804747104644775}
{"mode": "train", "epochs": 7, "timestep": 12480, "ep_reward": 280.3406677246094, "reward": 0.2839074730873108, "action": -0.7985203266143799}
{"mode": "train", "epochs": 7, "timestep": 12481, "ep_reward": 280.5021057128906, "reward": 0.1614477038383484, "action": -0.9962009191513062}
{"mode": "train", "epochs": 7, "timestep": 12482, "ep_reward": 280.5210876464844, "reward": 0.018986284732818604, "action": -1.1704944372177124}
{"mode": "train", "epochs": 7, "timestep": 12483, "ep_reward": 280.6187744140625, "reward": 0.09769093990325928, "action": -1.703948974609375}
{"mode": "train", "epochs": 7, "timestep": 12484, "ep_reward": 280.84820556640625, "reward": 0.2294272780418396, "action": -1.63688325881958}
{"mode": "train", "epochs": 7, "timestep": 12485, "ep_reward": 281.2102355957031, "reward": 0.3620181679725647, "action": -0.6166044473648071}
{"mode": "train", "epochs": 7, "timestep": 12486, "ep_reward": 281.7096862792969, "reward": 0.49944359064102173, "action": -0.8963550329208374}
{"mode": "train", "epochs": 7, "timestep": 12487, "ep_reward": 282.32421875, "reward": 0.6145336627960205, "action": -0.6031920313835144}
{"mode": "train", "epochs": 7, "timestep": 12488, "ep_reward": 283.03387451171875, "reward": 0.709640622138977, "action": -0.42412108182907104}
{"mode": "train", "epochs": 7, "timestep": 12489, "ep_reward": 283.816162109375, "reward": 0.7822961211204529, "action": -0.25227200984954834}
{"mode": "train", "epochs": 7, "timestep": 12490, "ep_reward": 284.6504821777344, "reward": 0.8343286514282227, "action": -0.7480578422546387}
{"mode": "train", "epochs": 7, "timestep": 12491, "ep_reward": 285.5138854980469, "reward": 0.8634164333343506, "action": -0.4860236644744873}
{"mode": "train", "epochs": 7, "timestep": 12492, "ep_reward": 286.39251708984375, "reward": 0.8786234855651855, "action": -0.7855414152145386}
{"mode": "train", "epochs": 7, "timestep": 12493, "ep_reward": 287.2687683105469, "reward": 0.8762471079826355, "action": -1.347935676574707}
{"mode": "train", "epochs": 7, "timestep": 12494, "ep_reward": 288.12158203125, "reward": 0.8528249263763428, "action": -1.087554931640625}
{"mode": "train", "epochs": 7, "timestep": 12495, "ep_reward": 288.9328308105469, "reward": 0.8112449645996094, "action": -1.6646828651428223}
{"mode": "train", "epochs": 7, "timestep": 12496, "ep_reward": 289.6701354980469, "reward": 0.7372997999191284, "action": -1.2217720746994019}
{"mode": "train", "epochs": 7, "timestep": 12497, "ep_reward": 290.3037109375, "reward": 0.6335675716400146, "action": -1.0909578800201416}
{"mode": "train", "epochs": 7, "timestep": 12498, "ep_reward": 290.794677734375, "reward": 0.4909587502479553, "action": -1.139481544494629}
{"mode": "train", "epochs": 7, "timestep": 12499, "ep_reward": 291.1435546875, "reward": 0.3488873839378357, "action": -1.835931420326233}
{"mode": "train", "epochs": 7, "timestep": 12500, "ep_reward": 291.3822937011719, "reward": 0.23874837160110474, "action": -1.6444056034088135}
{"mode": "train", "epochs": 7, "timestep": 12501, "ep_reward": 291.490966796875, "reward": 0.10866016149520874, "action": -1.1054601669311523}
{"mode": "train", "epochs": 7, "timestep": 12502, "ep_reward": 291.4981994628906, "reward": 0.0072397589683532715, "action": -0.6118796467781067}
{"mode": "train", "epochs": 7, "timestep": 12503, "ep_reward": 291.64935302734375, "reward": 0.1511426568031311, "action": -1.2635858058929443}
{"mode": "train", "epochs": 7, "timestep": 12504, "ep_reward": 291.9367980957031, "reward": 0.28744256496429443, "action": -0.9787024259567261}
{"mode": "train", "epochs": 7, "timestep": 12505, "ep_reward": 292.3619384765625, "reward": 0.425137460231781, "action": -0.9247188568115234}
{"mode": "train", "epochs": 7, "timestep": 12506, "ep_reward": 292.91265869140625, "reward": 0.5507296919822693, "action": -0.5920489430427551}
{"mode": "train", "epochs": 7, "timestep": 12507, "ep_reward": 293.5722961425781, "reward": 0.6596391201019287, "action": -1.2868812084197998}
{"mode": "train", "epochs": 7, "timestep": 12508, "ep_reward": 294.310546875, "reward": 0.7382478713989258, "action": -0.5186807513237}
{"mode": "train", "epochs": 7, "timestep": 12509, "ep_reward": 295.1128234863281, "reward": 0.8022651672363281, "action": -1.0347577333450317}
{"mode": "train", "epochs": 7, "timestep": 12510, "ep_reward": 295.9541931152344, "reward": 0.8413806557655334, "action": -0.7697552442550659}
{"mode": "train", "epochs": 7, "timestep": 12511, "ep_reward": 296.8194274902344, "reward": 0.8652459979057312, "action": -1.396470546722412}
{"mode": "train", "epochs": 7, "timestep": 12512, "ep_reward": 297.6873474121094, "reward": 0.8679162859916687, "action": -0.6324189901351929}
{"mode": "train", "epochs": 7, "timestep": 12513, "ep_reward": 298.5478210449219, "reward": 0.860471785068512, "action": -1.197730541229248}
{"mode": "train", "epochs": 7, "timestep": 12514, "ep_reward": 299.3772888183594, "reward": 0.8294739723205566, "action": -0.7128211855888367}
{"mode": "train", "epochs": 7, "timestep": 12515, "ep_reward": 300.1573486328125, "reward": 0.7800555229187012, "action": -1.090488076210022}
{"mode": "train", "epochs": 7, "timestep": 12516, "ep_reward": 300.8551330566406, "reward": 0.6977974772453308, "action": -0.735241174697876}
{"mode": "train", "epochs": 7, "timestep": 12517, "ep_reward": 301.4391174316406, "reward": 0.5839947462081909, "action": -0.6451795101165771}
{"mode": "train", "epochs": 7, "timestep": 12518, "ep_reward": 301.8708801269531, "reward": 0.43175309896469116, "action": -0.9102393984794617}
{"mode": "train", "epochs": 7, "timestep": 12519, "ep_reward": 302.1759948730469, "reward": 0.3051258325576782, "action": -0.7450103163719177}
{"mode": "train", "epochs": 7, "timestep": 12520, "ep_reward": 302.362548828125, "reward": 0.18655383586883545, "action": -0.3580607771873474}
{"mode": "train", "epochs": 7, "timestep": 12521, "ep_reward": 302.41046142578125, "reward": 0.04790163040161133, "action": -0.9899027347564697}
{"mode": "train", "epochs": 7, "timestep": 12522, "ep_reward": 302.4807434082031, "reward": 0.07028144598007202, "action": -0.5634203553199768}
{"mode": "train", "epochs": 7, "timestep": 12523, "ep_reward": 302.6938781738281, "reward": 0.21311986446380615, "action": -0.32730215787887573}
{"mode": "train", "epochs": 7, "timestep": 12524, "ep_reward": 303.05401611328125, "reward": 0.36012476682662964, "action": -1.2387633323669434}
{"mode": "train", "epochs": 7, "timestep": 12525, "ep_reward": 303.541748046875, "reward": 0.4877229332923889, "action": -0.40157413482666016}
{"mode": "train", "epochs": 7, "timestep": 12526, "ep_reward": 304.15118408203125, "reward": 0.6094420552253723, "action": -0.5100486278533936}
{"mode": "train", "epochs": 7, "timestep": 12527, "ep_reward": 304.8586730957031, "reward": 0.7075035572052002, "action": -1.3873393535614014}
{"mode": "train", "epochs": 7, "timestep": 12528, "ep_reward": 305.6339111328125, "reward": 0.7752230763435364, "action": -0.9973207712173462}
{"mode": "train", "epochs": 7, "timestep": 12529, "ep_reward": 306.4610595703125, "reward": 0.8271375894546509, "action": -0.7582017779350281}
{"mode": "train", "epochs": 7, "timestep": 12530, "ep_reward": 307.3244934082031, "reward": 0.8634190559387207, "action": -0.49125492572784424}
{"mode": "train", "epochs": 7, "timestep": 12531, "ep_reward": 308.210693359375, "reward": 0.8862064480781555, "action": -1.4592103958129883}
{"mode": "train", "epochs": 7, "timestep": 12532, "ep_reward": 309.0986633300781, "reward": 0.8879604935646057, "action": -0.716762900352478}
{"mode": "train", "epochs": 7, "timestep": 12533, "ep_reward": 309.9799499511719, "reward": 0.8812956809997559, "action": -1.7736327648162842}
{"mode": "train", "epochs": 7, "timestep": 12534, "ep_reward": 310.82977294921875, "reward": 0.8498270511627197, "action": -0.48801904916763306}
{"mode": "train", "epochs": 7, "timestep": 12535, "ep_reward": 311.6389465332031, "reward": 0.8091704845428467, "action": -0.3833357095718384}
{"mode": "train", "epochs": 7, "timestep": 12536, "ep_reward": 312.38421630859375, "reward": 0.7452707290649414, "action": -0.7090657949447632}
{"mode": "train", "epochs": 7, "timestep": 12537, "ep_reward": 313.0315246582031, "reward": 0.6473060846328735, "action": -1.100689172744751}
{"mode": "train", "epochs": 7, "timestep": 12538, "ep_reward": 313.53851318359375, "reward": 0.5069800615310669, "action": 0.039126038551330566}
{"mode": "train", "epochs": 7, "timestep": 12539, "ep_reward": 313.8836669921875, "reward": 0.34515082836151123, "action": -0.9012503027915955}
{"mode": "train", "epochs": 7, "timestep": 12540, "ep_reward": 314.11376953125, "reward": 0.23009932041168213, "action": -1.623930811882019}
{"mode": "train", "epochs": 7, "timestep": 12541, "ep_reward": 314.2123718261719, "reward": 0.09859561920166016, "action": -0.9704923033714294}
{"mode": "train", "epochs": 7, "timestep": 12542, "ep_reward": 314.23046875, "reward": 0.018083274364471436, "action": -1.5176277160644531}
{"mode": "train", "epochs": 7, "timestep": 12543, "ep_reward": 314.39117431640625, "reward": 0.16071665287017822, "action": -0.951926052570343}
{"mode": "train", "epochs": 7, "timestep": 12544, "ep_reward": 314.6922607421875, "reward": 0.30109256505966187, "action": -0.8053367137908936}
{"mode": "train", "epochs": 7, "timestep": 12545, "ep_reward": 315.13177490234375, "reward": 0.4395288825035095, "action": -0.9690454602241516}
{"mode": "train", "epochs": 7, "timestep": 12546, "ep_reward": 315.6939697265625, "reward": 0.5622079372406006, "action": -1.7840285301208496}
{"mode": "train", "epochs": 7, "timestep": 12547, "ep_reward": 316.3506774902344, "reward": 0.6566962003707886, "action": -0.5339958667755127}
{"mode": "train", "epochs": 7, "timestep": 12548, "ep_reward": 317.09326171875, "reward": 0.742576539516449, "action": -0.8053633570671082}
{"mode": "train", "epochs": 7, "timestep": 12549, "ep_reward": 317.8959655761719, "reward": 0.8026904463768005, "action": -1.086105465888977}
{"mode": "train", "epochs": 7, "timestep": 12550, "ep_reward": 318.73626708984375, "reward": 0.8402873277664185, "action": -1.3501720428466797}
{"mode": "train", "epochs": 7, "timestep": 12551, "ep_reward": 319.594482421875, "reward": 0.8582170605659485, "action": -0.514417290687561}
{"mode": "train", "epochs": 7, "timestep": 12552, "ep_reward": 320.4609680175781, "reward": 0.8664730787277222, "action": -1.3783283233642578}
{"mode": "train", "epochs": 7, "timestep": 12553, "ep_reward": 321.3111267089844, "reward": 0.8501468896865845, "action": -1.0743077993392944}
{"mode": "train", "epochs": 7, "timestep": 12554, "ep_reward": 322.12744140625, "reward": 0.8163071870803833, "action": -1.0148279666900635}
{"mode": "train", "epochs": 7, "timestep": 12555, "ep_reward": 322.88555908203125, "reward": 0.758109450340271, "action": -0.7753065228462219}
{"mode": "train", "epochs": 7, "timestep": 12556, "ep_reward": 323.5570373535156, "reward": 0.6714796423912048, "action": -0.9433180689811707}
{"mode": "train", "epochs": 7, "timestep": 12557, "ep_reward": 324.1023254394531, "reward": 0.5453017950057983, "action": 0.16395509243011475}
{"mode": "train", "epochs": 7, "timestep": 12558, "ep_reward": 324.4978332519531, "reward": 0.3955003023147583, "action": -1.0450782775878906}
{"mode": "train", "epochs": 7, "timestep": 12559, "ep_reward": 324.7781677246094, "reward": 0.2803289294242859, "action": -1.5337445735931396}
{"mode": "train", "epochs": 7, "timestep": 12560, "ep_reward": 324.9355163574219, "reward": 0.15735512971878052, "action": -1.0587859153747559}
{"mode": "train", "epochs": 7, "timestep": 12561, "ep_reward": 324.9497375488281, "reward": 0.014212965965270996, "action": -1.6095247268676758}
{"mode": "train", "epochs": 7, "timestep": 12562, "ep_reward": 325.0518493652344, "reward": 0.10212063789367676, "action": -1.2506911754608154}
{"mode": "train", "epochs": 7, "timestep": 12563, "ep_reward": 325.2892150878906, "reward": 0.23736298084259033, "action": -0.4626968502998352}
{"mode": "train", "epochs": 7, "timestep": 12564, "ep_reward": 325.6727600097656, "reward": 0.38354068994522095, "action": -0.7647885680198669}
{"mode": "train", "epochs": 7, "timestep": 12565, "ep_reward": 326.1879577636719, "reward": 0.5151943564414978, "action": -1.1678656339645386}
{"mode": "train", "epochs": 7, "timestep": 12566, "ep_reward": 326.8123779296875, "reward": 0.6244291067123413, "action": -1.024228572845459}
{"mode": "train", "epochs": 7, "timestep": 12567, "ep_reward": 327.5262756347656, "reward": 0.7139030694961548, "action": -0.8137325048446655}
{"mode": "train", "epochs": 7, "timestep": 12568, "ep_reward": 328.30938720703125, "reward": 0.7830963134765625, "action": -0.7903982400894165}
{"mode": "train", "epochs": 7, "timestep": 12569, "ep_reward": 329.1409912109375, "reward": 0.8316117525100708, "action": -1.5558717250823975}
{"mode": "train", "epochs": 7, "timestep": 12570, "ep_reward": 329.9967956542969, "reward": 0.8557994365692139, "action": -1.3857825994491577}
{"mode": "train", "epochs": 7, "timestep": 12571, "ep_reward": 330.86212158203125, "reward": 0.865339994430542, "action": 0.4713493585586548}
{"mode": "train", "epochs": 7, "timestep": 12572, "ep_reward": 331.7364501953125, "reward": 0.8743404150009155, "action": -1.0104732513427734}
{"mode": "train", "epochs": 7, "timestep": 12573, "ep_reward": 332.5909118652344, "reward": 0.8544598817825317, "action": -0.2846836447715759}
{"mode": "train", "epochs": 7, "timestep": 12574, "ep_reward": 333.4128723144531, "reward": 0.8219704627990723, "action": -0.32380253076553345}
{"mode": "train", "epochs": 7, "timestep": 12575, "ep_reward": 334.1792907714844, "reward": 0.7664200663566589, "action": -1.0859683752059937}
{"mode": "train", "epochs": 7, "timestep": 12576, "ep_reward": 334.85260009765625, "reward": 0.673306941986084, "action": -1.3359321355819702}
{"mode": "train", "epochs": 7, "timestep": 12577, "ep_reward": 335.3918151855469, "reward": 0.5392051935195923, "action": -1.1819279193878174}
{"mode": "train", "epochs": 7, "timestep": 12578, "ep_reward": 335.7588806152344, "reward": 0.36706870794296265, "action": -0.18424737453460693}
{"mode": "train", "epochs": 7, "timestep": 12579, "ep_reward": 336.019287109375, "reward": 0.2604169249534607, "action": -1.4433664083480835}
{"mode": "train", "epochs": 7, "timestep": 12580, "ep_reward": 336.1531066894531, "reward": 0.13382530212402344, "action": -1.7833623886108398}
{"mode": "train", "epochs": 7, "timestep": 12581, "ep_reward": 336.14044189453125, "reward": -0.012654900550842285, "action": -1.5822651386260986}
{"mode": "train", "epochs": 7, "timestep": 12582, "ep_reward": 336.26678466796875, "reward": 0.12635481357574463, "action": -0.9807859063148499}
{"mode": "train", "epochs": 7, "timestep": 12583, "ep_reward": 336.53228759765625, "reward": 0.26548880338668823, "action": -1.5448696613311768}
{"mode": "train", "epochs": 7, "timestep": 12584, "ep_reward": 336.92913818359375, "reward": 0.3968504071235657, "action": -0.810130774974823}
{"mode": "train", "epochs": 7, "timestep": 12585, "ep_reward": 337.45654296875, "reward": 0.5274017453193665, "action": -0.9327481389045715}
{"mode": "train", "epochs": 7, "timestep": 12586, "ep_reward": 338.0935974121094, "reward": 0.637057900428772, "action": -1.3865634202957153}
{"mode": "train", "epochs": 7, "timestep": 12587, "ep_reward": 338.8131408691406, "reward": 0.7195417284965515, "action": -0.7203961610794067}
{"mode": "train", "epochs": 7, "timestep": 12588, "ep_reward": 339.59942626953125, "reward": 0.7862861156463623, "action": -0.24059909582138062}
{"mode": "train", "epochs": 7, "timestep": 12589, "ep_reward": 340.4350280761719, "reward": 0.8356130123138428, "action": -1.6643648147583008}
{"mode": "train", "epochs": 7, "timestep": 12590, "ep_reward": 341.2890930175781, "reward": 0.8540669083595276, "action": -1.6307944059371948}
{"mode": "train", "epochs": 7, "timestep": 12591, "ep_reward": 342.1450500488281, "reward": 0.8559629321098328, "action": -1.203749179840088}
{"mode": "train", "epochs": 7, "timestep": 12592, "ep_reward": 342.9884338378906, "reward": 0.8433899879455566, "action": -1.2960920333862305}
{"mode": "train", "epochs": 7, "timestep": 12593, "ep_reward": 343.7972717285156, "reward": 0.8088463544845581, "action": -1.3303258419036865}
{"mode": "train", "epochs": 7, "timestep": 12594, "ep_reward": 344.54486083984375, "reward": 0.7475790977478027, "action": -0.022172749042510986}
{"mode": "train", "epochs": 7, "timestep": 12595, "ep_reward": 345.2144775390625, "reward": 0.6696081757545471, "action": -0.9804490804672241}
{"mode": "train", "epochs": 7, "timestep": 12596, "ep_reward": 345.7574462890625, "reward": 0.5429743528366089, "action": -0.830253005027771}
{"mode": "train", "epochs": 7, "timestep": 12597, "ep_reward": 346.14190673828125, "reward": 0.3844669461250305, "action": -1.4626716375350952}
{"mode": "train", "epochs": 7, "timestep": 12598, "ep_reward": 346.4235534667969, "reward": 0.28164517879486084, "action": -1.4690085649490356}
{"mode": "train", "epochs": 7, "timestep": 12599, "ep_reward": 346.58233642578125, "reward": 0.15878230333328247, "action": -1.6865918636322021}
{"mode": "train", "epochs": 7, "timestep": 12600, "ep_reward": 346.59844970703125, "reward": 0.016099631786346436, "action": -0.8116023540496826}
{"mode": "train", "epochs": 7, "timestep": 12601, "ep_reward": 346.6990051269531, "reward": 0.1005469560623169, "action": -0.807823896408081}
{"mode": "train", "epochs": 7, "timestep": 12602, "ep_reward": 346.94024658203125, "reward": 0.24123382568359375, "action": -0.7255282402038574}
{"mode": "train", "epochs": 7, "timestep": 12603, "ep_reward": 347.32330322265625, "reward": 0.3830539584159851, "action": -1.2107607126235962}
{"mode": "train", "epochs": 7, "timestep": 12604, "ep_reward": 347.8326416015625, "reward": 0.5093367695808411, "action": -1.729932427406311}
{"mode": "train", "epochs": 7, "timestep": 12605, "ep_reward": 348.44610595703125, "reward": 0.6134609580039978, "action": -1.5902702808380127}
{"mode": "train", "epochs": 7, "timestep": 12606, "ep_reward": 349.14520263671875, "reward": 0.6991003751754761, "action": -0.8752757906913757}
{"mode": "train", "epochs": 7, "timestep": 12607, "ep_reward": 349.9148864746094, "reward": 0.769673228263855, "action": -0.7854010462760925}
{"mode": "train", "epochs": 7, "timestep": 12608, "ep_reward": 350.7338562011719, "reward": 0.818962037563324, "action": -0.967548668384552}
{"mode": "train", "epochs": 7, "timestep": 12609, "ep_reward": 351.5808410644531, "reward": 0.8469794988632202, "action": -0.9928934574127197}
{"mode": "train", "epochs": 7, "timestep": 12610, "ep_reward": 352.4377136230469, "reward": 0.856860339641571, "action": -1.4530909061431885}
{"mode": "train", "epochs": 7, "timestep": 12611, "ep_reward": 353.2823486328125, "reward": 0.8446238040924072, "action": -1.5343009233474731}
{"mode": "train", "epochs": 7, "timestep": 12612, "ep_reward": 354.0929870605469, "reward": 0.8106313943862915, "action": -0.7914756536483765}
{"mode": "train", "epochs": 7, "timestep": 12613, "ep_reward": 354.8514709472656, "reward": 0.758482813835144, "action": -0.24320101737976074}
{"mode": "train", "epochs": 7, "timestep": 12614, "ep_reward": 355.5338439941406, "reward": 0.6823642253875732, "action": -0.9242287278175354}
{"mode": "train", "epochs": 7, "timestep": 12615, "ep_reward": 356.09552001953125, "reward": 0.5616821050643921, "action": -0.5860032439231873}
{"mode": "train", "epochs": 7, "timestep": 12616, "ep_reward": 356.5, "reward": 0.40448981523513794, "action": -0.6518459320068359}
{"mode": "train", "epochs": 7, "timestep": 12617, "ep_reward": 356.7964782714844, "reward": 0.296469509601593, "action": -0.16303443908691406}
{"mode": "train", "epochs": 7, "timestep": 12618, "ep_reward": 356.9727478027344, "reward": 0.17627298831939697, "action": -0.4614337682723999}
{"mode": "train", "epochs": 7, "timestep": 12619, "ep_reward": 357.00872802734375, "reward": 0.03598892688751221, "action": -1.3446438312530518}
{"mode": "train", "epochs": 7, "timestep": 12620, "ep_reward": 357.0904541015625, "reward": 0.08172959089279175, "action": -1.0013465881347656}
{"mode": "train", "epochs": 7, "timestep": 12621, "ep_reward": 357.3098449707031, "reward": 0.2193877100944519, "action": -1.2476774454116821}
{"mode": "train", "epochs": 7, "timestep": 12622, "ep_reward": 357.6657409667969, "reward": 0.355907678604126, "action": -1.6545331478118896}
{"mode": "train", "epochs": 7, "timestep": 12623, "ep_reward": 358.14630126953125, "reward": 0.48057031631469727, "action": -1.4318413734436035}
{"mode": "train", "epochs": 7, "timestep": 12624, "ep_reward": 358.7391357421875, "reward": 0.5928407907485962, "action": -0.7325818538665771}
{"mode": "train", "epochs": 7, "timestep": 12625, "ep_reward": 359.4300231933594, "reward": 0.6908801794052124, "action": -1.838677167892456}
{"mode": "train", "epochs": 7, "timestep": 12626, "ep_reward": 360.1838684082031, "reward": 0.7538565397262573, "action": 0.164331316947937}
{"mode": "train", "epochs": 7, "timestep": 12627, "ep_reward": 360.9978332519531, "reward": 0.8139536380767822, "action": -1.4284424781799316}
{"mode": "train", "epochs": 7, "timestep": 12628, "ep_reward": 361.8358154296875, "reward": 0.8379889130592346, "action": -1.7695995569229126}
{"mode": "train", "epochs": 7, "timestep": 12629, "ep_reward": 362.67620849609375, "reward": 0.8403804302215576, "action": -0.08000308275222778}
{"mode": "train", "epochs": 7, "timestep": 12630, "ep_reward": 363.5150146484375, "reward": 0.8388062119483948, "action": -0.810346782207489}
{"mode": "train", "epochs": 7, "timestep": 12631, "ep_reward": 364.32427978515625, "reward": 0.8092737793922424, "action": -1.3821355104446411}
{"mode": "train", "epochs": 7, "timestep": 12632, "ep_reward": 365.07208251953125, "reward": 0.7478042840957642, "action": -1.8250393867492676}
{"mode": "train", "epochs": 7, "timestep": 12633, "ep_reward": 365.71881103515625, "reward": 0.6467271447181702, "action": -0.13853269815444946}
{"mode": "train", "epochs": 7, "timestep": 12634, "ep_reward": 366.245849609375, "reward": 0.5270371437072754, "action": -1.4797096252441406}
{"mode": "train", "epochs": 7, "timestep": 12635, "ep_reward": 366.6271057128906, "reward": 0.3812705874443054, "action": -0.7753077149391174}
{"mode": "train", "epochs": 7, "timestep": 12636, "ep_reward": 366.9048767089844, "reward": 0.27776390314102173, "action": -0.5213069915771484}
{"mode": "train", "epochs": 7, "timestep": 12637, "ep_reward": 367.05902099609375, "reward": 0.154158353805542, "action": -1.2382944822311401}
{"mode": "train", "epochs": 7, "timestep": 12638, "ep_reward": 367.0697326660156, "reward": 0.010709643363952637, "action": -0.5457015633583069}
{"mode": "train", "epochs": 7, "timestep": 12639, "ep_reward": 367.1752624511719, "reward": 0.10553467273712158, "action": -0.7467702627182007}
{"mode": "train", "epochs": 7, "timestep": 12640, "ep_reward": 367.4223327636719, "reward": 0.24706530570983887, "action": -1.1882290840148926}
{"mode": "train", "epochs": 7, "timestep": 12641, "ep_reward": 367.8052978515625, "reward": 0.3829764723777771, "action": -1.0710114240646362}
{"mode": "train", "epochs": 7, "timestep": 12642, "ep_reward": 368.3167724609375, "reward": 0.5114810466766357, "action": -0.5584577322006226}
{"mode": "train", "epochs": 7, "timestep": 12643, "ep_reward": 368.94476318359375, "reward": 0.627989649772644, "action": -0.4278266429901123}
{"mode": "train", "epochs": 7, "timestep": 12644, "ep_reward": 369.6672058105469, "reward": 0.7224307060241699, "action": -1.273061752319336}
{"mode": "train", "epochs": 7, "timestep": 12645, "ep_reward": 370.45318603515625, "reward": 0.7859839200973511, "action": -1.2438030242919922}
{"mode": "train", "epochs": 7, "timestep": 12646, "ep_reward": 371.2834777832031, "reward": 0.8303012251853943, "action": -1.2267850637435913}
{"mode": "train", "epochs": 7, "timestep": 12647, "ep_reward": 372.1407165527344, "reward": 0.8572406768798828, "action": -1.0047444105148315}
{"mode": "train", "epochs": 7, "timestep": 12648, "ep_reward": 373.0105285644531, "reward": 0.8698149919509888, "action": -0.9412747025489807}
{"mode": "train", "epochs": 7, "timestep": 12649, "ep_reward": 373.87738037109375, "reward": 0.8668601512908936, "action": -1.401977300643921}
{"mode": "train", "epochs": 7, "timestep": 12650, "ep_reward": 374.71978759765625, "reward": 0.8423954248428345, "action": -0.6002895832061768}
{"mode": "train", "epochs": 7, "timestep": 12651, "ep_reward": 375.5239562988281, "reward": 0.8041611909866333, "action": -0.6094502210617065}
{"mode": "train", "epochs": 7, "timestep": 12652, "ep_reward": 376.2643737792969, "reward": 0.7404045462608337, "action": -0.9619070291519165}
{"mode": "train", "epochs": 7, "timestep": 12653, "ep_reward": 376.90484619140625, "reward": 0.6404756903648376, "action": -1.3523859977722168}
{"mode": "train", "epochs": 7, "timestep": 12654, "ep_reward": 377.40045166015625, "reward": 0.4956170320510864, "action": -1.0776458978652954}
{"mode": "train", "epochs": 7, "timestep": 12655, "ep_reward": 377.7496643066406, "reward": 0.34919852018356323, "action": -1.2222849130630493}
{"mode": "train", "epochs": 7, "timestep": 12656, "ep_reward": 377.98870849609375, "reward": 0.2390323281288147, "action": -1.3850703239440918}
{"mode": "train", "epochs": 7, "timestep": 12657, "ep_reward": 378.0976867675781, "reward": 0.10896587371826172, "action": -0.8703289031982422}
{"mode": "train", "epochs": 7, "timestep": 12658, "ep_reward": 378.1046142578125, "reward": 0.006941080093383789, "action": -0.49171507358551025}
{"mode": "train", "epochs": 7, "timestep": 12659, "ep_reward": 378.25555419921875, "reward": 0.1509442925453186, "action": -0.6761159896850586}
{"mode": "train", "epochs": 7, "timestep": 12660, "ep_reward": 378.5500793457031, "reward": 0.294527530670166, "action": -0.8242162466049194}
{"mode": "train", "epochs": 7, "timestep": 12661, "ep_reward": 378.982666015625, "reward": 0.43259626626968384, "action": -0.726813554763794}
{"mode": "train", "epochs": 7, "timestep": 12662, "ep_reward": 379.5413818359375, "reward": 0.5587097406387329, "action": -1.2802232503890991}
{"mode": "train", "epochs": 7, "timestep": 12663, "ep_reward": 380.20050048828125, "reward": 0.6591277122497559, "action": -1.0227845907211304}
{"mode": "train", "epochs": 7, "timestep": 12664, "ep_reward": 380.9412841796875, "reward": 0.7407848834991455, "action": -0.3990676999092102}
{"mode": "train", "epochs": 7, "timestep": 12665, "ep_reward": 381.7475891113281, "reward": 0.8063182830810547, "action": -0.34506601095199585}
{"mode": "train", "epochs": 7, "timestep": 12666, "ep_reward": 382.59954833984375, "reward": 0.8519443273544312, "action": -0.9771889448165894}
{"mode": "train", "epochs": 7, "timestep": 12667, "ep_reward": 383.47503662109375, "reward": 0.8754928708076477, "action": -1.9598424434661865}
{"mode": "train", "epochs": 7, "timestep": 12668, "ep_reward": 384.35205078125, "reward": 0.8770096898078918, "action": -0.7839990854263306}
{"mode": "train", "epochs": 7, "timestep": 12669, "ep_reward": 385.2248840332031, "reward": 0.8728388547897339, "action": -0.8509012460708618}
{"mode": "train", "epochs": 7, "timestep": 12670, "ep_reward": 386.07635498046875, "reward": 0.8514765501022339, "action": -0.9586506485939026}
{"mode": "train", "epochs": 7, "timestep": 12671, "ep_reward": 386.8853759765625, "reward": 0.8090282678604126, "action": -0.7671085596084595}
{"mode": "train", "epochs": 7, "timestep": 12672, "ep_reward": 387.6283874511719, "reward": 0.7430245876312256, "action": -0.9556218385696411}
{"mode": "train", "epochs": 7, "timestep": 12673, "ep_reward": 388.27117919921875, "reward": 0.6427929401397705, "action": -1.784385323524475}
{"mode": "train", "epochs": 7, "timestep": 12674, "ep_reward": 388.7628173828125, "reward": 0.4916512966156006, "action": -0.1777207851409912}
{"mode": "train", "epochs": 7, "timestep": 12675, "ep_reward": 389.1081848144531, "reward": 0.3453716039657593, "action": -1.8083157539367676}
{"mode": "train", "epochs": 7, "timestep": 12676, "ep_reward": 389.3428649902344, "reward": 0.23467779159545898, "action": -0.5536061525344849}
{"mode": "train", "epochs": 7, "timestep": 12677, "ep_reward": 389.4465637207031, "reward": 0.10369199514389038, "action": -1.4222716093063354}
{"mode": "train", "epochs": 7, "timestep": 12678, "ep_reward": 389.4590148925781, "reward": 0.012449979782104492, "action": -1.7282826900482178}
{"mode": "train", "epochs": 7, "timestep": 12679, "ep_reward": 389.61492919921875, "reward": 0.15590709447860718, "action": -0.32843732833862305}
{"mode": "train", "epochs": 7, "timestep": 12680, "ep_reward": 389.9187927246094, "reward": 0.3038761615753174, "action": -0.7491440176963806}
{"mode": "train", "epochs": 7, "timestep": 12681, "ep_reward": 390.3604431152344, "reward": 0.44166260957717896, "action": -0.6747734546661377}
{"mode": "train", "epochs": 7, "timestep": 12682, "ep_reward": 390.92730712890625, "reward": 0.5668563842773438, "action": -0.8041417598724365}
{"mode": "train", "epochs": 7, "timestep": 12683, "ep_reward": 391.5979309082031, "reward": 0.6706133484840393, "action": -0.7970499992370605}
{"mode": "train", "epochs": 7, "timestep": 12684, "ep_reward": 392.3503112792969, "reward": 0.7523748278617859, "action": -0.8998206853866577}
{"mode": "train", "epochs": 7, "timestep": 12685, "ep_reward": 393.1625061035156, "reward": 0.8121894598007202, "action": 0.07048702239990234}
{"mode": "train", "epochs": 7, "timestep": 12686, "ep_reward": 394.0235595703125, "reward": 0.8610674142837524, "action": -0.9982032775878906}
{"mode": "train", "epochs": 7, "timestep": 12687, "ep_reward": 394.9090270996094, "reward": 0.8854799270629883, "action": -1.0150119066238403}
{"mode": "train", "epochs": 7, "timestep": 12688, "ep_reward": 395.8056640625, "reward": 0.8966465592384338, "action": -1.0947307348251343}
{"mode": "train", "epochs": 7, "timestep": 12689, "ep_reward": 396.7002868652344, "reward": 0.8946306109428406, "action": -0.7416519522666931}
{"mode": "train", "epochs": 7, "timestep": 12690, "ep_reward": 397.58203125, "reward": 0.8817304372787476, "action": -0.5972180366516113}
{"mode": "train", "epochs": 7, "timestep": 12691, "ep_reward": 398.4362487792969, "reward": 0.8542158603668213, "action": -1.3660317659378052}
{"mode": "train", "epochs": 7, "timestep": 12692, "ep_reward": 399.23583984375, "reward": 0.7996042370796204, "action": -1.0579556226730347}
{"mode": "train", "epochs": 7, "timestep": 12693, "ep_reward": 399.95623779296875, "reward": 0.7204025983810425, "action": -1.9173781871795654}
{"mode": "train", "epochs": 7, "timestep": 12694, "ep_reward": 400.5519104003906, "reward": 0.5956695079803467, "action": -0.1814475655555725}
{"mode": "train", "epochs": 7, "timestep": 12695, "ep_reward": 401.0054016113281, "reward": 0.4534980058670044, "action": -1.6772406101226807}
{"mode": "train", "epochs": 7, "timestep": 12696, "ep_reward": 401.3126220703125, "reward": 0.3072319030761719, "action": -1.4584382772445679}
{"mode": "train", "epochs": 7, "timestep": 12697, "ep_reward": 401.50177001953125, "reward": 0.18914508819580078, "action": -0.6943534016609192}
{"mode": "train", "epochs": 7, "timestep": 12698, "ep_reward": 401.5526428222656, "reward": 0.05086112022399902, "action": -1.415121078491211}
{"mode": "train", "epochs": 7, "timestep": 12699, "ep_reward": 401.61993408203125, "reward": 0.06728553771972656, "action": -0.8306964039802551}
{"mode": "train", "epochs": 7, "timestep": 12700, "ep_reward": 401.82659912109375, "reward": 0.2066742181777954, "action": -0.8065565824508667}
{"mode": "train", "epochs": 7, "timestep": 12701, "ep_reward": 402.17535400390625, "reward": 0.3487498164176941, "action": -0.4130508303642273}
{"mode": "train", "epochs": 7, "timestep": 12702, "ep_reward": 402.6632080078125, "reward": 0.48786187171936035, "action": -1.313075304031372}
{"mode": "train", "epochs": 7, "timestep": 12703, "ep_reward": 403.2629089355469, "reward": 0.5996964573860168, "action": -1.5200926065444946}
{"mode": "train", "epochs": 7, "timestep": 12704, "ep_reward": 403.9524841308594, "reward": 0.6895763874053955, "action": -1.2178078889846802}
{"mode": "train", "epochs": 7, "timestep": 12705, "ep_reward": 404.71343994140625, "reward": 0.7609613537788391, "action": -1.8859953880310059}
{"mode": "train", "epochs": 7, "timestep": 12706, "ep_reward": 405.5189514160156, "reward": 0.8055198788642883, "action": -0.7546645998954773}
{"mode": "train", "epochs": 7, "timestep": 12707, "ep_reward": 406.36016845703125, "reward": 0.841224193572998, "action": -0.31140071153640747}
{"mode": "train", "epochs": 7, "timestep": 12708, "ep_reward": 407.2225036621094, "reward": 0.8623418807983398, "action": -1.321692943572998}
{"mode": "train", "epochs": 7, "timestep": 12709, "ep_reward": 408.0802307128906, "reward": 0.8577125668525696, "action": -0.3807486295700073}
{"mode": "train", "epochs": 7, "timestep": 12710, "ep_reward": 408.9234924316406, "reward": 0.8432562351226807, "action": -0.6083676218986511}
{"mode": "train", "epochs": 7, "timestep": 12711, "ep_reward": 409.7296447753906, "reward": 0.8061391115188599, "action": -1.3731749057769775}
{"mode": "train", "epochs": 7, "timestep": 12712, "ep_reward": 410.4646911621094, "reward": 0.7350376844406128, "action": -0.952886164188385}
{"mode": "train", "epochs": 7, "timestep": 12713, "ep_reward": 411.0993957519531, "reward": 0.6346969604492188, "action": -0.9878726601600647}
{"mode": "train", "epochs": 7, "timestep": 12714, "ep_reward": 411.59344482421875, "reward": 0.49405425786972046, "action": -1.6551318168640137}
{"mode": "train", "epochs": 7, "timestep": 12715, "ep_reward": 411.9440612792969, "reward": 0.3506236672401428, "action": -1.5504313707351685}
{"mode": "train", "epochs": 7, "timestep": 12716, "ep_reward": 412.18499755859375, "reward": 0.2409258484840393, "action": 0.2783161401748657}
{"mode": "train", "epochs": 7, "timestep": 12717, "ep_reward": 412.29608154296875, "reward": 0.11107391119003296, "action": -0.47540372610092163}
{"mode": "train", "epochs": 7, "timestep": 12718, "ep_reward": 412.3006286621094, "reward": 0.004534423351287842, "action": -1.4794656038284302}
{"mode": "train", "epochs": 7, "timestep": 12719, "ep_reward": 412.4495544433594, "reward": 0.1489163637161255, "action": -1.0429089069366455}
{"mode": "train", "epochs": 7, "timestep": 12720, "ep_reward": 412.7374267578125, "reward": 0.2878742218017578, "action": -1.1960020065307617}
{"mode": "train", "epochs": 7, "timestep": 12721, "ep_reward": 413.15997314453125, "reward": 0.42255544662475586, "action": -0.5823312401771545}
{"mode": "train", "epochs": 7, "timestep": 12722, "ep_reward": 413.7121276855469, "reward": 0.5521606206893921, "action": -1.7397665977478027}
{"mode": "train", "epochs": 7, "timestep": 12723, "ep_reward": 414.3610534667969, "reward": 0.6489254236221313, "action": -0.7287025451660156}
{"mode": "train", "epochs": 7, "timestep": 12724, "ep_reward": 415.0958557128906, "reward": 0.7348090410232544, "action": -0.6143510937690735}
{"mode": "train", "epochs": 7, "timestep": 12725, "ep_reward": 415.8944091796875, "reward": 0.7985631227493286, "action": -0.8876482248306274}
{"mode": "train", "epochs": 7, "timestep": 12726, "ep_reward": 416.7336120605469, "reward": 0.8391915559768677, "action": -1.1822596788406372}
{"mode": "train", "epochs": 7, "timestep": 12727, "ep_reward": 417.5931091308594, "reward": 0.8595061898231506, "action": -1.4613871574401855}
{"mode": "train", "epochs": 7, "timestep": 12728, "ep_reward": 418.45391845703125, "reward": 0.8608014583587646, "action": -1.5835766792297363}
{"mode": "train", "epochs": 7, "timestep": 12729, "ep_reward": 419.2969055175781, "reward": 0.8429993987083435, "action": -1.9100418090820312}
{"mode": "train", "epochs": 7, "timestep": 12730, "ep_reward": 420.0971374511719, "reward": 0.800230860710144, "action": -0.8910775780677795}
{"mode": "train", "epochs": 7, "timestep": 12731, "ep_reward": 420.8374938964844, "reward": 0.7403414249420166, "action": 0.36792290210723877}
{"mode": "train", "epochs": 7, "timestep": 12732, "ep_reward": 421.50140380859375, "reward": 0.6638950705528259, "action": -1.7168768644332886}
{"mode": "train", "epochs": 7, "timestep": 12733, "ep_reward": 422.0249328613281, "reward": 0.5235285758972168, "action": -0.6427996158599854}
{"mode": "train", "epochs": 7, "timestep": 12734, "ep_reward": 422.4002380371094, "reward": 0.3753053545951843, "action": -1.582951307296753}
{"mode": "train", "epochs": 7, "timestep": 12735, "ep_reward": 422.6709289550781, "reward": 0.2706872224807739, "action": -0.29785358905792236}
{"mode": "train", "epochs": 7, "timestep": 12736, "ep_reward": 422.8167724609375, "reward": 0.14585715532302856, "action": -1.035714864730835}
{"mode": "train", "epochs": 7, "timestep": 12737, "ep_reward": 422.81793212890625, "reward": 0.0011487603187561035, "action": -0.3484782576560974}
{"mode": "train", "epochs": 7, "timestep": 12738, "ep_reward": 422.9321594238281, "reward": 0.11422741413116455, "action": -0.7602792978286743}
{"mode": "train", "epochs": 7, "timestep": 12739, "ep_reward": 423.18804931640625, "reward": 0.2558802366256714, "action": 0.8302068710327148}
{"mode": "train", "epochs": 7, "timestep": 12740, "ep_reward": 423.6034240722656, "reward": 0.4153681993484497, "action": -1.8416683673858643}
{"mode": "train", "epochs": 7, "timestep": 12741, "ep_reward": 424.13299560546875, "reward": 0.5295649170875549, "action": -1.589188575744629}
{"mode": "train", "epochs": 7, "timestep": 12742, "ep_reward": 424.7648620605469, "reward": 0.6318541765213013, "action": -1.0153907537460327}
{"mode": "train", "epochs": 7, "timestep": 12743, "ep_reward": 425.4849548339844, "reward": 0.7200914621353149, "action": -0.5576649308204651}
{"mode": "train", "epochs": 7, "timestep": 12744, "ep_reward": 426.2754821777344, "reward": 0.7905124425888062, "action": -1.4492374658584595}
{"mode": "train", "epochs": 7, "timestep": 12745, "ep_reward": 427.10858154296875, "reward": 0.8330886960029602, "action": -0.25098878145217896}
{"mode": "train", "epochs": 7, "timestep": 12746, "ep_reward": 427.9768981933594, "reward": 0.8683179616928101, "action": -1.2985444068908691}
{"mode": "train", "epochs": 7, "timestep": 12747, "ep_reward": 428.8565673828125, "reward": 0.8796570897102356, "action": -0.9072136282920837}
{"mode": "train", "epochs": 7, "timestep": 12748, "ep_reward": 429.7361145019531, "reward": 0.8795393705368042, "action": -1.0213531255722046}
{"mode": "train", "epochs": 7, "timestep": 12749, "ep_reward": 430.5989990234375, "reward": 0.8628872632980347, "action": -0.9110335111618042}
{"mode": "train", "epochs": 7, "timestep": 12750, "ep_reward": 431.427490234375, "reward": 0.8284813165664673, "action": -1.9533066749572754}
{"mode": "train", "epochs": 7, "timestep": 12751, "ep_reward": 432.18701171875, "reward": 0.7595212459564209, "action": -1.3256832361221313}
{"mode": "train", "epochs": 7, "timestep": 12752, "ep_reward": 432.85113525390625, "reward": 0.6641281843185425, "action": -0.11051297187805176}
{"mode": "train", "epochs": 7, "timestep": 12753, "ep_reward": 433.39801025390625, "reward": 0.5468608140945435, "action": -0.9546290636062622}
{"mode": "train", "epochs": 7, "timestep": 12754, "ep_reward": 433.77655029296875, "reward": 0.37854981422424316, "action": -1.2081286907196045}
{"mode": "train", "epochs": 7, "timestep": 12755, "ep_reward": 434.04693603515625, "reward": 0.2703755497932434, "action": -0.8890500068664551}
{"mode": "train", "epochs": 7, "timestep": 12756, "ep_reward": 434.1923828125, "reward": 0.14543867111206055, "action": -1.654271125793457}
{"mode": "train", "epochs": 7, "timestep": 12757, "ep_reward": 434.1930236816406, "reward": 0.0006500482559204102, "action": -1.5242893695831299}
{"mode": "train", "epochs": 7, "timestep": 12758, "ep_reward": 434.307373046875, "reward": 0.11433863639831543, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 12759, "ep_reward": 434.55120849609375, "reward": 0.243849515914917, "action": -1.132938265800476}
{"mode": "train", "epochs": 7, "timestep": 12760, "ep_reward": 434.9338073730469, "reward": 0.3825852870941162, "action": -0.8863579034805298}
{"mode": "train", "epochs": 7, "timestep": 12761, "ep_reward": 435.4481201171875, "reward": 0.5142992734909058, "action": -0.5774862766265869}
{"mode": "train", "epochs": 7, "timestep": 12762, "ep_reward": 436.078369140625, "reward": 0.6302622556686401, "action": -0.2808189392089844}
{"mode": "train", "epochs": 7, "timestep": 12763, "ep_reward": 436.803466796875, "reward": 0.7251076698303223, "action": -0.8516044616699219}
{"mode": "train", "epochs": 7, "timestep": 12764, "ep_reward": 437.5938720703125, "reward": 0.7904094457626343, "action": -1.408750295639038}
{"mode": "train", "epochs": 7, "timestep": 12765, "ep_reward": 438.4244384765625, "reward": 0.8305761218070984, "action": -0.7337375283241272}
{"mode": "train", "epochs": 7, "timestep": 12766, "ep_reward": 439.2831115722656, "reward": 0.8586779832839966, "action": -1.0944749116897583}
{"mode": "train", "epochs": 7, "timestep": 12767, "ep_reward": 440.15020751953125, "reward": 0.867107093334198, "action": -0.9064279794692993}
{"mode": "train", "epochs": 7, "timestep": 12768, "ep_reward": 441.01080322265625, "reward": 0.8606024980545044, "action": -0.8444333076477051}
{"mode": "train", "epochs": 7, "timestep": 12769, "ep_reward": 441.8471984863281, "reward": 0.836410403251648, "action": -0.5689436793327332}
{"mode": "train", "epochs": 7, "timestep": 12770, "ep_reward": 442.6403503417969, "reward": 0.793148398399353, "action": -1.0149396657943726}
{"mode": "train", "epochs": 7, "timestep": 12771, "ep_reward": 443.35845947265625, "reward": 0.7181146144866943, "action": -0.8770931363105774}
{"mode": "train", "epochs": 7, "timestep": 12772, "ep_reward": 443.9687194824219, "reward": 0.6102521419525146, "action": -0.6146141886711121}
{"mode": "train", "epochs": 7, "timestep": 12773, "ep_reward": 444.4354248046875, "reward": 0.4666946530342102, "action": -0.3918609619140625}
{"mode": "train", "epochs": 7, "timestep": 12774, "ep_reward": 444.76177978515625, "reward": 0.3263596296310425, "action": -1.2065346240997314}
{"mode": "train", "epochs": 7, "timestep": 12775, "ep_reward": 444.9736022949219, "reward": 0.21181297302246094, "action": -0.7549421787261963}
{"mode": "train", "epochs": 7, "timestep": 12776, "ep_reward": 445.05072021484375, "reward": 0.07712674140930176, "action": -1.3886940479278564}
{"mode": "train", "epochs": 7, "timestep": 12777, "ep_reward": 445.0915222167969, "reward": 0.040813148021698, "action": -0.3943027853965759}
{"mode": "train", "epochs": 7, "timestep": 12778, "ep_reward": 445.27630615234375, "reward": 0.18477720022201538, "action": -0.8922175168991089}
{"mode": "train", "epochs": 7, "timestep": 12779, "ep_reward": 445.60162353515625, "reward": 0.3253273367881775, "action": -0.5014312267303467}
{"mode": "train", "epochs": 7, "timestep": 12780, "ep_reward": 446.0667724609375, "reward": 0.4651374816894531, "action": -0.5323748588562012}
{"mode": "train", "epochs": 7, "timestep": 12781, "ep_reward": 446.65545654296875, "reward": 0.5886749029159546, "action": -1.292445182800293}
{"mode": "train", "epochs": 7, "timestep": 12782, "ep_reward": 447.3388366699219, "reward": 0.6833787560462952, "action": -0.967707633972168}
{"mode": "train", "epochs": 7, "timestep": 12783, "ep_reward": 448.09893798828125, "reward": 0.7601026296615601, "action": -1.146763801574707}
{"mode": "train", "epochs": 7, "timestep": 12784, "ep_reward": 448.91351318359375, "reward": 0.8145662546157837, "action": -0.5607177019119263}
{"mode": "train", "epochs": 7, "timestep": 12785, "ep_reward": 449.7690734863281, "reward": 0.8555598258972168, "action": -0.15836316347122192}
{"mode": "train", "epochs": 7, "timestep": 12786, "ep_reward": 450.6521301269531, "reward": 0.8830626606941223, "action": -1.5838667154312134}
{"mode": "train", "epochs": 7, "timestep": 12787, "ep_reward": 451.5374755859375, "reward": 0.8853544592857361, "action": -1.3203790187835693}
{"mode": "train", "epochs": 7, "timestep": 12788, "ep_reward": 452.4128112792969, "reward": 0.8753293752670288, "action": -0.01924896240234375}
{"mode": "train", "epochs": 7, "timestep": 12789, "ep_reward": 453.27288818359375, "reward": 0.8600825071334839, "action": -0.6919088363647461}
{"mode": "train", "epochs": 7, "timestep": 12790, "ep_reward": 454.0935363769531, "reward": 0.820652961730957, "action": -0.33079296350479126}
{"mode": "train", "epochs": 7, "timestep": 12791, "ep_reward": 454.85504150390625, "reward": 0.7614904642105103, "action": -1.1756911277770996}
{"mode": "train", "epochs": 7, "timestep": 12792, "ep_reward": 455.5185852050781, "reward": 0.6635583639144897, "action": -0.3180946111679077}
{"mode": "train", "epochs": 7, "timestep": 12793, "ep_reward": 456.0587158203125, "reward": 0.5401419401168823, "action": -0.7797384262084961}
{"mode": "train", "epochs": 7, "timestep": 12794, "ep_reward": 456.4315185546875, "reward": 0.37281298637390137, "action": -1.2315101623535156}
{"mode": "train", "epochs": 7, "timestep": 12795, "ep_reward": 456.6807861328125, "reward": 0.2492724061012268, "action": -0.8922079205513}
{"mode": "train", "epochs": 7, "timestep": 12796, "ep_reward": 456.8016357421875, "reward": 0.12084251642227173, "action": -0.8549867868423462}
{"mode": "train", "epochs": 7, "timestep": 12797, "ep_reward": 456.7953796386719, "reward": -0.006258487701416016, "action": -0.4221953749656677}
{"mode": "train", "epochs": 7, "timestep": 12798, "ep_reward": 456.93475341796875, "reward": 0.13935953378677368, "action": -1.3555023670196533}
{"mode": "train", "epochs": 7, "timestep": 12799, "ep_reward": 457.2090148925781, "reward": 0.2742503881454468, "action": -0.968697190284729}
{"mode": "train", "epochs": 7, "timestep": 12800, "ep_reward": 457.6219177246094, "reward": 0.41290372610092163, "action": -0.9342708587646484}
{"mode": "train", "epochs": 7, "timestep": 12801, "ep_reward": 458.1618957519531, "reward": 0.5399852991104126, "action": -0.4448241591453552}
{"mode": "train", "epochs": 7, "timestep": 12802, "ep_reward": 458.8143615722656, "reward": 0.6524678468704224, "action": -1.3852821588516235}
{"mode": "train", "epochs": 7, "timestep": 12803, "ep_reward": 459.5462646484375, "reward": 0.7318915724754333, "action": -0.6788013577461243}
{"mode": "train", "epochs": 7, "timestep": 12804, "ep_reward": 460.34259033203125, "reward": 0.7963178157806396, "action": -1.177809715270996}
{"mode": "train", "epochs": 7, "timestep": 12805, "ep_reward": 461.17852783203125, "reward": 0.8359413146972656, "action": -0.20580697059631348}
{"mode": "train", "epochs": 7, "timestep": 12806, "ep_reward": 462.04449462890625, "reward": 0.8659711480140686, "action": -0.6687111854553223}
{"mode": "train", "epochs": 7, "timestep": 12807, "ep_reward": 462.9202880859375, "reward": 0.8757962584495544, "action": -1.1715004444122314}
{"mode": "train", "epochs": 7, "timestep": 12808, "ep_reward": 463.7860412597656, "reward": 0.8657499551773071, "action": -1.2847367525100708}
{"mode": "train", "epochs": 7, "timestep": 12809, "ep_reward": 464.6227111816406, "reward": 0.836659848690033, "action": -0.9019005298614502}
{"mode": "train", "epochs": 7, "timestep": 12810, "ep_reward": 465.4115295410156, "reward": 0.7888038754463196, "action": -0.7105038166046143}
{"mode": "train", "epochs": 7, "timestep": 12811, "ep_reward": 466.1267395019531, "reward": 0.7152083516120911, "action": -1.7784627676010132}
{"mode": "train", "epochs": 7, "timestep": 12812, "ep_reward": 466.719970703125, "reward": 0.5932402610778809, "action": -1.2742462158203125}
{"mode": "train", "epochs": 7, "timestep": 12813, "ep_reward": 467.1542663574219, "reward": 0.4342913031578064, "action": -0.5061755180358887}
{"mode": "train", "epochs": 7, "timestep": 12814, "ep_reward": 467.47064208984375, "reward": 0.3163772225379944, "action": -0.5306057929992676}
{"mode": "train", "epochs": 7, "timestep": 12815, "ep_reward": 467.67041015625, "reward": 0.1997717022895813, "action": -1.3610806465148926}
{"mode": "train", "epochs": 7, "timestep": 12816, "ep_reward": 467.73370361328125, "reward": 0.06330692768096924, "action": -1.0875223875045776}
{"mode": "train", "epochs": 7, "timestep": 12817, "ep_reward": 467.7886962890625, "reward": 0.054978251457214355, "action": -0.14607179164886475}
{"mode": "train", "epochs": 7, "timestep": 12818, "ep_reward": 467.9910888671875, "reward": 0.20239847898483276, "action": -1.3787720203399658}
{"mode": "train", "epochs": 7, "timestep": 12819, "ep_reward": 468.3270568847656, "reward": 0.33597540855407715, "action": -1.3239156007766724}
{"mode": "train", "epochs": 7, "timestep": 12820, "ep_reward": 468.7924499511719, "reward": 0.46538811922073364, "action": -1.7242677211761475}
{"mode": "train", "epochs": 7, "timestep": 12821, "ep_reward": 469.3689270019531, "reward": 0.5764723420143127, "action": 0.24347293376922607}
{"mode": "train", "epochs": 7, "timestep": 12822, "ep_reward": 470.0575866699219, "reward": 0.6886606216430664, "action": -0.9160600304603577}
{"mode": "train", "epochs": 7, "timestep": 12823, "ep_reward": 470.8211975097656, "reward": 0.7636027336120605, "action": -1.1136633157730103}
{"mode": "train", "epochs": 7, "timestep": 12824, "ep_reward": 471.6365661621094, "reward": 0.8153647184371948, "action": -1.8307721614837646}
{"mode": "train", "epochs": 7, "timestep": 12825, "ep_reward": 472.4791564941406, "reward": 0.8425763845443726, "action": -0.49329453706741333}
{"mode": "train", "epochs": 7, "timestep": 12826, "ep_reward": 473.34320068359375, "reward": 0.8640440702438354, "action": -1.4033454656600952}
{"mode": "train", "epochs": 7, "timestep": 12827, "ep_reward": 474.204345703125, "reward": 0.8611435294151306, "action": -0.6206280589103699}
{"mode": "train", "epochs": 7, "timestep": 12828, "ep_reward": 475.05157470703125, "reward": 0.8472143411636353, "action": -1.6037623882293701}
{"mode": "train", "epochs": 7, "timestep": 12829, "ep_reward": 475.8549499511719, "reward": 0.80336594581604, "action": -0.831824779510498}
{"mode": "train", "epochs": 7, "timestep": 12830, "ep_reward": 476.5953369140625, "reward": 0.7403899431228638, "action": -1.0667692422866821}
{"mode": "train", "epochs": 7, "timestep": 12831, "ep_reward": 477.23712158203125, "reward": 0.6417758464813232, "action": -1.0306813716888428}
{"mode": "train", "epochs": 7, "timestep": 12832, "ep_reward": 477.74078369140625, "reward": 0.5036666989326477, "action": -0.7436673641204834}
{"mode": "train", "epochs": 7, "timestep": 12833, "ep_reward": 478.10052490234375, "reward": 0.35974758863449097, "action": -1.1324779987335205}
{"mode": "train", "epochs": 7, "timestep": 12834, "ep_reward": 478.3523254394531, "reward": 0.2518017888069153, "action": -0.45644038915634155}
{"mode": "train", "epochs": 7, "timestep": 12835, "ep_reward": 478.47607421875, "reward": 0.12376147508621216, "action": -0.8091980218887329}
{"mode": "train", "epochs": 7, "timestep": 12836, "ep_reward": 478.4665222167969, "reward": -0.009553790092468262, "action": -0.5494838356971741}
{"mode": "train", "epochs": 7, "timestep": 12837, "ep_reward": 478.60302734375, "reward": 0.136508047580719, "action": -1.2669589519500732}
{"mode": "train", "epochs": 7, "timestep": 12838, "ep_reward": 478.87542724609375, "reward": 0.2724118232727051, "action": -1.110936164855957}
{"mode": "train", "epochs": 7, "timestep": 12839, "ep_reward": 479.2845153808594, "reward": 0.4090732932090759, "action": -1.9631199836730957}
{"mode": "train", "epochs": 7, "timestep": 12840, "ep_reward": 479.8092346191406, "reward": 0.5247098207473755, "action": -1.363249659538269}
{"mode": "train", "epochs": 7, "timestep": 12841, "ep_reward": 480.4393615722656, "reward": 0.6301153302192688, "action": -1.1232270002365112}
{"mode": "train", "epochs": 7, "timestep": 12842, "ep_reward": 481.1546630859375, "reward": 0.7152983546257019, "action": -0.6029617786407471}
{"mode": "train", "epochs": 7, "timestep": 12843, "ep_reward": 481.9363708496094, "reward": 0.781713604927063, "action": -1.0899840593338013}
{"mode": "train", "epochs": 7, "timestep": 12844, "ep_reward": 482.7574157714844, "reward": 0.8210431933403015, "action": -1.3919776678085327}
{"mode": "train", "epochs": 7, "timestep": 12845, "ep_reward": 483.5953369140625, "reward": 0.8379071354866028, "action": 0.057756662368774414}
{"mode": "train", "epochs": 7, "timestep": 12846, "ep_reward": 484.4442138671875, "reward": 0.8488625288009644, "action": 0.06424391269683838}
{"mode": "train", "epochs": 7, "timestep": 12847, "ep_reward": 485.28497314453125, "reward": 0.8407619595527649, "action": -1.20928156375885}
{"mode": "train", "epochs": 7, "timestep": 12848, "ep_reward": 486.0845031738281, "reward": 0.7995328903198242, "action": -0.9870453476905823}
{"mode": "train", "epochs": 7, "timestep": 12849, "ep_reward": 486.8179626464844, "reward": 0.7334606647491455, "action": -0.4682875871658325}
{"mode": "train", "epochs": 7, "timestep": 12850, "ep_reward": 487.4585266113281, "reward": 0.6405763030052185, "action": -0.7036784291267395}
{"mode": "train", "epochs": 7, "timestep": 12851, "ep_reward": 487.9651794433594, "reward": 0.5066542625427246, "action": -1.0195637941360474}
{"mode": "train", "epochs": 7, "timestep": 12852, "ep_reward": 488.3224792480469, "reward": 0.3573035001754761, "action": -1.7372037172317505}
{"mode": "train", "epochs": 7, "timestep": 12853, "ep_reward": 488.57147216796875, "reward": 0.2489890456199646, "action": -0.48551881313323975}
{"mode": "train", "epochs": 7, "timestep": 12854, "ep_reward": 488.6919860839844, "reward": 0.12050479650497437, "action": -0.42206984758377075}
{"mode": "train", "epochs": 7, "timestep": 12855, "ep_reward": 488.6861267089844, "reward": -0.005863547325134277, "action": -0.7449007034301758}
{"mode": "train", "epochs": 7, "timestep": 12856, "ep_reward": 488.8259582519531, "reward": 0.13983243703842163, "action": -0.3271644711494446}
{"mode": "train", "epochs": 7, "timestep": 12857, "ep_reward": 489.11346435546875, "reward": 0.287506639957428, "action": -0.25238823890686035}
{"mode": "train", "epochs": 7, "timestep": 12858, "ep_reward": 489.5453796386719, "reward": 0.4319092631340027, "action": -1.1129415035247803}
{"mode": "train", "epochs": 7, "timestep": 12859, "ep_reward": 490.0983581542969, "reward": 0.5529718399047852, "action": -1.2310528755187988}
{"mode": "train", "epochs": 7, "timestep": 12860, "ep_reward": 490.7532958984375, "reward": 0.6549485921859741, "action": -0.9148024916648865}
{"mode": "train", "epochs": 7, "timestep": 12861, "ep_reward": 491.492431640625, "reward": 0.7391215562820435, "action": -0.8963295817375183}
{"mode": "train", "epochs": 7, "timestep": 12862, "ep_reward": 492.2945556640625, "reward": 0.8021288514137268, "action": -0.4698013663291931}
{"mode": "train", "epochs": 7, "timestep": 12863, "ep_reward": 493.143798828125, "reward": 0.8492345213890076, "action": -1.7311009168624878}
{"mode": "train", "epochs": 7, "timestep": 12864, "ep_reward": 494.0135803222656, "reward": 0.8697702288627625, "action": -1.8191115856170654}
{"mode": "train", "epochs": 7, "timestep": 12865, "ep_reward": 494.88885498046875, "reward": 0.8752700090408325, "action": -0.7630767226219177}
{"mode": "train", "epochs": 7, "timestep": 12866, "ep_reward": 495.76287841796875, "reward": 0.874030590057373, "action": -1.744470238685608}
{"mode": "train", "epochs": 7, "timestep": 12867, "ep_reward": 496.6107177734375, "reward": 0.8478396534919739, "action": -0.4623846411705017}
{"mode": "train", "epochs": 7, "timestep": 12868, "ep_reward": 497.42340087890625, "reward": 0.8126755356788635, "action": -0.5821725130081177}
{"mode": "train", "epochs": 7, "timestep": 12869, "ep_reward": 498.1754150390625, "reward": 0.7520062327384949, "action": -1.304326057434082}
{"mode": "train", "epochs": 7, "timestep": 12870, "ep_reward": 498.8272399902344, "reward": 0.6518204212188721, "action": -0.07432323694229126}
{"mode": "train", "epochs": 7, "timestep": 12871, "ep_reward": 499.3570861816406, "reward": 0.5298501253128052, "action": -1.5272139310836792}
{"mode": "train", "epochs": 7, "timestep": 12872, "ep_reward": 499.71697998046875, "reward": 0.3598788380622864, "action": 0.022848129272460938}
{"mode": "train", "epochs": 7, "timestep": 12873, "ep_reward": 499.9688415527344, "reward": 0.25185906887054443, "action": -0.5254694223403931}
{"mode": "train", "epochs": 7, "timestep": 12874, "ep_reward": 500.0926513671875, "reward": 0.12381899356842041, "action": -0.9423927068710327}
{"mode": "train", "epochs": 7, "timestep": 12875, "ep_reward": 500.0829162597656, "reward": -0.009747982025146484, "action": -1.4503591060638428}
{"mode": "train", "epochs": 7, "timestep": 12876, "ep_reward": 500.21942138671875, "reward": 0.13650035858154297, "action": -0.7688443064689636}
{"mode": "train", "epochs": 7, "timestep": 12877, "ep_reward": 500.4980773925781, "reward": 0.27865689992904663, "action": 0.18806445598602295}
{"mode": "train", "epochs": 7, "timestep": 12878, "ep_reward": 500.92767333984375, "reward": 0.4295961856842041, "action": -1.3877041339874268}
{"mode": "train", "epochs": 7, "timestep": 12879, "ep_reward": 501.47564697265625, "reward": 0.5479852557182312, "action": -0.8299087882041931}
{"mode": "train", "epochs": 7, "timestep": 12880, "ep_reward": 502.13055419921875, "reward": 0.6549065709114075, "action": -1.2970850467681885}
{"mode": "train", "epochs": 7, "timestep": 12881, "ep_reward": 502.8661193847656, "reward": 0.7355569005012512, "action": -0.9677513241767883}
{"mode": "train", "epochs": 7, "timestep": 12882, "ep_reward": 503.6644592285156, "reward": 0.7983434796333313, "action": -1.881326675415039}
{"mode": "train", "epochs": 7, "timestep": 12883, "ep_reward": 504.4988708496094, "reward": 0.8343967199325562, "action": -1.0809842348098755}
{"mode": "train", "epochs": 7, "timestep": 12884, "ep_reward": 505.359375, "reward": 0.8605045080184937, "action": -0.7298497557640076}
{"mode": "train", "epochs": 7, "timestep": 12885, "ep_reward": 506.232666015625, "reward": 0.8732943534851074, "action": -1.581514596939087}
{"mode": "train", "epochs": 7, "timestep": 12886, "ep_reward": 507.09588623046875, "reward": 0.8632159233093262, "action": -0.7373508214950562}
{"mode": "train", "epochs": 7, "timestep": 12887, "ep_reward": 507.9383544921875, "reward": 0.8424558043479919, "action": -1.125086784362793}
{"mode": "train", "epochs": 7, "timestep": 12888, "ep_reward": 508.7351379394531, "reward": 0.7967924475669861, "action": -0.4934404492378235}
{"mode": "train", "epochs": 7, "timestep": 12889, "ep_reward": 509.4660339355469, "reward": 0.7308813333511353, "action": -1.2351250648498535}
{"mode": "train", "epochs": 7, "timestep": 12890, "ep_reward": 510.0893249511719, "reward": 0.6232893466949463, "action": -0.33849066495895386}
{"mode": "train", "epochs": 7, "timestep": 12891, "ep_reward": 510.57769775390625, "reward": 0.4883880615234375, "action": -0.637876033782959}
{"mode": "train", "epochs": 7, "timestep": 12892, "ep_reward": 510.9165954589844, "reward": 0.33890342712402344, "action": -1.7294318675994873}
{"mode": "train", "epochs": 7, "timestep": 12893, "ep_reward": 511.1434020996094, "reward": 0.22680813074111938, "action": -1.4168177843093872}
{"mode": "train", "epochs": 7, "timestep": 12894, "ep_reward": 511.2381591796875, "reward": 0.09476923942565918, "action": -0.3626940846443176}
{"mode": "train", "epochs": 7, "timestep": 12895, "ep_reward": 511.2605285644531, "reward": 0.02238386869430542, "action": -0.2603381872177124}
{"mode": "train", "epochs": 7, "timestep": 12896, "ep_reward": 511.4278259277344, "reward": 0.16729968786239624, "action": -1.6438674926757812}
{"mode": "train", "epochs": 7, "timestep": 12897, "ep_reward": 511.7264099121094, "reward": 0.29857873916625977, "action": -0.7114711999893188}
{"mode": "train", "epochs": 7, "timestep": 12898, "ep_reward": 512.1654663085938, "reward": 0.439075767993927, "action": -1.2132153511047363}
{"mode": "train", "epochs": 7, "timestep": 12899, "ep_reward": 512.724853515625, "reward": 0.5594139099121094, "action": -1.488938808441162}
{"mode": "train", "epochs": 7, "timestep": 12900, "ep_reward": 513.3821411132812, "reward": 0.6573053598403931, "action": -0.42645782232284546}
{"mode": "train", "epochs": 7, "timestep": 12901, "ep_reward": 514.1256103515625, "reward": 0.7434965968132019, "action": -1.7485606670379639}
{"mode": "train", "epochs": 7, "timestep": 12902, "ep_reward": 514.9197387695312, "reward": 0.7941174507141113, "action": -0.49976062774658203}
{"mode": "train", "epochs": 7, "timestep": 12903, "ep_reward": 515.7559814453125, "reward": 0.836260199546814, "action": -0.38459402322769165}
{"mode": "train", "epochs": 7, "timestep": 12904, "ep_reward": 516.6163940429688, "reward": 0.8603953123092651, "action": -1.1395044326782227}
{"mode": "train", "epochs": 7, "timestep": 12905, "ep_reward": 517.4773559570312, "reward": 0.8609704971313477, "action": -0.6506520509719849}
{"mode": "train", "epochs": 7, "timestep": 12906, "ep_reward": 518.325439453125, "reward": 0.8480938076972961, "action": -1.2201939821243286}
{"mode": "train", "epochs": 7, "timestep": 12907, "ep_reward": 519.1350708007812, "reward": 0.8096305727958679, "action": -0.19902437925338745}
{"mode": "train", "epochs": 7, "timestep": 12908, "ep_reward": 519.8916015625, "reward": 0.7565550804138184, "action": -0.3245803117752075}
{"mode": "train", "epochs": 7, "timestep": 12909, "ep_reward": 520.5645751953125, "reward": 0.6729512214660645, "action": -0.5000004172325134}
{"mode": "train", "epochs": 7, "timestep": 12910, "ep_reward": 521.1165161132812, "reward": 0.5519266724586487, "action": -1.7588096857070923}
{"mode": "train", "epochs": 7, "timestep": 12911, "ep_reward": 521.4918823242188, "reward": 0.3753536343574524, "action": -1.116241216659546}
{"mode": "train", "epochs": 7, "timestep": 12912, "ep_reward": 521.7625122070312, "reward": 0.2706546187400818, "action": 0.1488574743270874}
{"mode": "train", "epochs": 7, "timestep": 12913, "ep_reward": 521.9083251953125, "reward": 0.14580971002578735, "action": -1.0683212280273438}
{"mode": "train", "epochs": 7, "timestep": 12914, "ep_reward": 521.9093017578125, "reward": 0.0009893178939819336, "action": -1.3707090616226196}
{"mode": "train", "epochs": 7, "timestep": 12915, "ep_reward": 522.0235595703125, "reward": 0.11428701877593994, "action": -0.5816663503646851}
{"mode": "train", "epochs": 7, "timestep": 12916, "ep_reward": 522.2815551757812, "reward": 0.25797826051712036, "action": -1.8597530126571655}
{"mode": "train", "epochs": 7, "timestep": 12917, "ep_reward": 522.6665649414062, "reward": 0.3850163221359253, "action": -1.2006628513336182}
{"mode": "train", "epochs": 7, "timestep": 12918, "ep_reward": 523.1788330078125, "reward": 0.5122403502464294, "action": -1.281552791595459}
{"mode": "train", "epochs": 7, "timestep": 12919, "ep_reward": 523.7994995117188, "reward": 0.6206837892532349, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 12920, "ep_reward": 524.4995727539062, "reward": 0.700048565864563, "action": -0.21498018503189087}
{"mode": "train", "epochs": 7, "timestep": 12921, "ep_reward": 525.2745361328125, "reward": 0.7749744653701782, "action": -0.8771471381187439}
{"mode": "train", "epochs": 7, "timestep": 12922, "ep_reward": 526.0948486328125, "reward": 0.8203310370445251, "action": -0.7861030101776123}
{"mode": "train", "epochs": 7, "timestep": 12923, "ep_reward": 526.9415893554688, "reward": 0.8467690348625183, "action": -0.4548358917236328}
{"mode": "train", "epochs": 7, "timestep": 12924, "ep_reward": 527.7994384765625, "reward": 0.8578534722328186, "action": -1.0424675941467285}
{"mode": "train", "epochs": 7, "timestep": 12925, "ep_reward": 528.6451416015625, "reward": 0.8457027673721313, "action": -0.7538834810256958}
{"mode": "train", "epochs": 7, "timestep": 12926, "ep_reward": 529.4610595703125, "reward": 0.8158929347991943, "action": -0.869956374168396}
{"mode": "train", "epochs": 7, "timestep": 12927, "ep_reward": 530.2214965820312, "reward": 0.7604538202285767, "action": -0.1324096918106079}
{"mode": "train", "epochs": 7, "timestep": 12928, "ep_reward": 530.9050903320312, "reward": 0.6835806965827942, "action": -0.37958812713623047}
{"mode": "train", "epochs": 7, "timestep": 12929, "ep_reward": 531.4744262695312, "reward": 0.5693634748458862, "action": -0.91325443983078}
{"mode": "train", "epochs": 7, "timestep": 12930, "ep_reward": 531.8826904296875, "reward": 0.40827852487564087, "action": 0.7386467456817627}
{"mode": "train", "epochs": 7, "timestep": 12931, "ep_reward": 532.1728515625, "reward": 0.2901732325553894, "action": -0.27732229232788086}
{"mode": "train", "epochs": 7, "timestep": 12932, "ep_reward": 532.3416748046875, "reward": 0.16881418228149414, "action": -0.8256639242172241}
{"mode": "train", "epochs": 7, "timestep": 12933, "ep_reward": 532.369140625, "reward": 0.02748316526412964, "action": -0.9207505583763123}
{"mode": "train", "epochs": 7, "timestep": 12934, "ep_reward": 532.4591064453125, "reward": 0.0899396538734436, "action": -0.11968576908111572}
{"mode": "train", "epochs": 7, "timestep": 12935, "ep_reward": 532.6978149414062, "reward": 0.23869317770004272, "action": -1.6423330307006836}
{"mode": "train", "epochs": 7, "timestep": 12936, "ep_reward": 533.06591796875, "reward": 0.36810302734375, "action": -1.1901699304580688}
{"mode": "train", "epochs": 7, "timestep": 12937, "ep_reward": 533.5623779296875, "reward": 0.4964529275894165, "action": -1.2974414825439453}
{"mode": "train", "epochs": 7, "timestep": 12938, "ep_reward": 534.1697998046875, "reward": 0.6073964834213257, "action": -1.4112880229949951}
{"mode": "train", "epochs": 7, "timestep": 12939, "ep_reward": 534.8660278320312, "reward": 0.6962281465530396, "action": -1.4205669164657593}
{"mode": "train", "epochs": 7, "timestep": 12940, "ep_reward": 535.62890625, "reward": 0.7629050612449646, "action": -1.3053396940231323}
{"mode": "train", "epochs": 7, "timestep": 12941, "ep_reward": 536.4383544921875, "reward": 0.8094283938407898, "action": -1.147955060005188}
{"mode": "train", "epochs": 7, "timestep": 12942, "ep_reward": 537.27587890625, "reward": 0.8375398516654968, "action": -1.2537444829940796}
{"mode": "train", "epochs": 7, "timestep": 12943, "ep_reward": 538.1217651367188, "reward": 0.8459064960479736, "action": -1.279794454574585}
{"mode": "train", "epochs": 7, "timestep": 12944, "ep_reward": 538.9564819335938, "reward": 0.8347428441047668, "action": -1.227642297744751}
{"mode": "train", "epochs": 7, "timestep": 12945, "ep_reward": 539.7583618164062, "reward": 0.801886260509491, "action": -1.9854273796081543}
{"mode": "train", "epochs": 7, "timestep": 12946, "ep_reward": 540.4916381835938, "reward": 0.7332823872566223, "action": 0.053987979888916016}
{"mode": "train", "epochs": 7, "timestep": 12947, "ep_reward": 541.14599609375, "reward": 0.6543866395950317, "action": -1.2608506679534912}
{"mode": "train", "epochs": 7, "timestep": 12948, "ep_reward": 541.6658325195312, "reward": 0.5198566317558289, "action": -1.1785657405853271}
{"mode": "train", "epochs": 7, "timestep": 12949, "ep_reward": 542.0477294921875, "reward": 0.3818824887275696, "action": -1.180108666419983}
{"mode": "train", "epochs": 7, "timestep": 12950, "ep_reward": 542.3262939453125, "reward": 0.2785698175430298, "action": -0.4720522165298462}
{"mode": "train", "epochs": 7, "timestep": 12951, "ep_reward": 542.4814453125, "reward": 0.15518099069595337, "action": -0.530725359916687}
{"mode": "train", "epochs": 7, "timestep": 12952, "ep_reward": 542.4931640625, "reward": 0.011728286743164062, "action": -1.1718413829803467}
{"mode": "train", "epochs": 7, "timestep": 12953, "ep_reward": 542.5977172851562, "reward": 0.10455787181854248, "action": -0.5060282349586487}
{"mode": "train", "epochs": 7, "timestep": 12954, "ep_reward": 542.8468017578125, "reward": 0.24905657768249512, "action": -1.1035284996032715}
{"mode": "train", "epochs": 7, "timestep": 12955, "ep_reward": 543.2321166992188, "reward": 0.3853062391281128, "action": -1.732311725616455}
{"mode": "train", "epochs": 7, "timestep": 12956, "ep_reward": 543.7376098632812, "reward": 0.5054912567138672, "action": -1.4405282735824585}
{"mode": "train", "epochs": 7, "timestep": 12957, "ep_reward": 544.35107421875, "reward": 0.6134847402572632, "action": -1.2421143054962158}
{"mode": "train", "epochs": 7, "timestep": 12958, "ep_reward": 545.0534057617188, "reward": 0.7023113965988159, "action": -1.3745673894882202}
{"mode": "train", "epochs": 7, "timestep": 12959, "ep_reward": 545.820556640625, "reward": 0.7671579122543335, "action": -0.8685831427574158}
{"mode": "train", "epochs": 7, "timestep": 12960, "ep_reward": 546.6358032226562, "reward": 0.8152245879173279, "action": -0.6347768902778625}
{"mode": "train", "epochs": 7, "timestep": 12961, "ep_reward": 547.4810791015625, "reward": 0.8452651500701904, "action": -0.566270649433136}
{"mode": "train", "epochs": 7, "timestep": 12962, "ep_reward": 548.3385620117188, "reward": 0.8574665784835815, "action": -1.0374759435653687}
{"mode": "train", "epochs": 7, "timestep": 12963, "ep_reward": 549.18603515625, "reward": 0.8475021719932556, "action": -1.1954668760299683}
{"mode": "train", "epochs": 7, "timestep": 12964, "ep_reward": 550.001708984375, "reward": 0.8156973123550415, "action": -1.3749223947525024}
{"mode": "train", "epochs": 7, "timestep": 12965, "ep_reward": 550.7583618164062, "reward": 0.7566403746604919, "action": -0.5609341859817505}
{"mode": "train", "epochs": 7, "timestep": 12966, "ep_reward": 551.4334106445312, "reward": 0.6750438213348389, "action": -1.3341538906097412}
{"mode": "train", "epochs": 7, "timestep": 12967, "ep_reward": 551.9791259765625, "reward": 0.5456981062889099, "action": -1.1621686220169067}
{"mode": "train", "epochs": 7, "timestep": 12968, "ep_reward": 552.3692626953125, "reward": 0.3901405930519104, "action": -1.5908703804016113}
{"mode": "train", "epochs": 7, "timestep": 12969, "ep_reward": 552.657958984375, "reward": 0.2886732816696167, "action": -0.8086798787117004}
{"mode": "train", "epochs": 7, "timestep": 12970, "ep_reward": 552.8250732421875, "reward": 0.16708499193191528, "action": -0.8505235314369202}
{"mode": "train", "epochs": 7, "timestep": 12971, "ep_reward": 552.8505859375, "reward": 0.025527000427246094, "action": -0.5623910427093506}
{"mode": "train", "epochs": 7, "timestep": 12972, "ep_reward": 552.9422607421875, "reward": 0.09165853261947632, "action": -1.581651210784912}
{"mode": "train", "epochs": 7, "timestep": 12973, "ep_reward": 553.1665649414062, "reward": 0.2242981195449829, "action": -1.1940563917160034}
{"mode": "train", "epochs": 7, "timestep": 12974, "ep_reward": 553.52880859375, "reward": 0.3622194528579712, "action": -1.6964874267578125}
{"mode": "train", "epochs": 7, "timestep": 12975, "ep_reward": 554.014892578125, "reward": 0.4861098527908325, "action": -1.7566386461257935}
{"mode": "train", "epochs": 7, "timestep": 12976, "ep_reward": 554.6087036132812, "reward": 0.5938273668289185, "action": -0.9371490478515625}
{"mode": "train", "epochs": 7, "timestep": 12977, "ep_reward": 555.2977294921875, "reward": 0.689042329788208, "action": -0.7988787889480591}
{"mode": "train", "epochs": 7, "timestep": 12978, "ep_reward": 556.0584716796875, "reward": 0.7607507705688477, "action": -1.4387320280075073}
{"mode": "train", "epochs": 7, "timestep": 12979, "ep_reward": 556.861572265625, "reward": 0.8031010031700134, "action": -0.7525033354759216}
{"mode": "train", "epochs": 7, "timestep": 12980, "ep_reward": 557.6925048828125, "reward": 0.8309026956558228, "action": -1.1313165426254272}
{"mode": "train", "epochs": 7, "timestep": 12981, "ep_reward": 558.52734375, "reward": 0.8348523378372192, "action": -1.420408844947815}
{"mode": "train", "epochs": 7, "timestep": 12982, "ep_reward": 559.3422241210938, "reward": 0.8148608207702637, "action": -1.2059279680252075}
{"mode": "train", "epochs": 7, "timestep": 12983, "ep_reward": 560.1143188476562, "reward": 0.7720863819122314, "action": -0.6941400766372681}
{"mode": "train", "epochs": 7, "timestep": 12984, "ep_reward": 560.8192138671875, "reward": 0.70488440990448, "action": -1.152160882949829}
{"mode": "train", "epochs": 7, "timestep": 12985, "ep_reward": 561.4146118164062, "reward": 0.5953751802444458, "action": -1.5820530652999878}
{"mode": "train", "epochs": 7, "timestep": 12986, "ep_reward": 561.8497314453125, "reward": 0.43512141704559326, "action": -0.2608259320259094}
{"mode": "train", "epochs": 7, "timestep": 12987, "ep_reward": 562.1900634765625, "reward": 0.34031951427459717, "action": -0.9479219317436218}
{"mode": "train", "epochs": 7, "timestep": 12988, "ep_reward": 562.4183349609375, "reward": 0.2282923460006714, "action": -1.6896235942840576}
{"mode": "train", "epochs": 7, "timestep": 12989, "ep_reward": 562.5147705078125, "reward": 0.09643983840942383, "action": -1.4238042831420898}
{"mode": "train", "epochs": 7, "timestep": 12990, "ep_reward": 562.5350952148438, "reward": 0.020337343215942383, "action": -1.4668781757354736}
{"mode": "train", "epochs": 7, "timestep": 12991, "ep_reward": 562.6978149414062, "reward": 0.16270124912261963, "action": -0.5937893390655518}
{"mode": "train", "epochs": 7, "timestep": 12992, "ep_reward": 563.0053100585938, "reward": 0.3074997067451477, "action": -1.1080286502838135}
{"mode": "train", "epochs": 7, "timestep": 12993, "ep_reward": 563.4466552734375, "reward": 0.4413747191429138, "action": -0.5722931623458862}
{"mode": "train", "epochs": 7, "timestep": 12994, "ep_reward": 564.0148315429688, "reward": 0.5681731700897217, "action": -1.6754487752914429}
{"mode": "train", "epochs": 7, "timestep": 12995, "ep_reward": 564.6775512695312, "reward": 0.6627327799797058, "action": -1.2094751596450806}
{"mode": "train", "epochs": 7, "timestep": 12996, "ep_reward": 565.418701171875, "reward": 0.7411282658576965, "action": -1.5170307159423828}
{"mode": "train", "epochs": 7, "timestep": 12997, "ep_reward": 566.2139892578125, "reward": 0.7952951192855835, "action": -0.816173255443573}
{"mode": "train", "epochs": 7, "timestep": 12998, "ep_reward": 567.050048828125, "reward": 0.8360338807106018, "action": -1.1654558181762695}
{"mode": "train", "epochs": 7, "timestep": 12999, "ep_reward": 567.9054565429688, "reward": 0.8554059863090515, "action": -1.2841206789016724}
{"mode": "train", "epochs": 7, "timestep": 13000, "ep_reward": 568.7620239257812, "reward": 0.8565560579299927, "action": -0.9010944962501526}
{"mode": "train", "epochs": 7, "timestep": 13001, "ep_reward": 569.6049194335938, "reward": 0.8428741693496704, "action": -0.6452432870864868}
{"mode": "train", "epochs": 7, "timestep": 13002, "ep_reward": 570.415771484375, "reward": 0.8108457326889038, "action": -1.4763073921203613}
{"mode": "train", "epochs": 7, "timestep": 13003, "ep_reward": 571.160400390625, "reward": 0.7446455955505371, "action": -0.7923755049705505}
{"mode": "train", "epochs": 7, "timestep": 13004, "ep_reward": 571.8132934570312, "reward": 0.6529181003570557, "action": -1.3669257164001465}
{"mode": "train", "epochs": 7, "timestep": 13005, "ep_reward": 572.3273315429688, "reward": 0.5140396356582642, "action": -1.518134355545044}
{"mode": "train", "epochs": 7, "timestep": 13006, "ep_reward": 572.6973876953125, "reward": 0.37006717920303345, "action": -1.11348557472229}
{"mode": "train", "epochs": 7, "timestep": 13007, "ep_reward": 572.9616088867188, "reward": 0.264204740524292, "action": -0.9402028322219849}
{"mode": "train", "epochs": 7, "timestep": 13008, "ep_reward": 573.0999145507812, "reward": 0.1383119821548462, "action": -1.0110923051834106}
{"mode": "train", "epochs": 7, "timestep": 13009, "ep_reward": 573.0923461914062, "reward": -0.00756072998046875, "action": -0.9218791723251343}
{"mode": "train", "epochs": 7, "timestep": 13010, "ep_reward": 573.2142333984375, "reward": 0.12187600135803223, "action": -1.4491255283355713}
{"mode": "train", "epochs": 7, "timestep": 13011, "ep_reward": 573.4694213867188, "reward": 0.25516563653945923, "action": -0.8698036670684814}
{"mode": "train", "epochs": 7, "timestep": 13012, "ep_reward": 573.865478515625, "reward": 0.3960849642753601, "action": -0.8085245490074158}
{"mode": "train", "epochs": 7, "timestep": 13013, "ep_reward": 574.39208984375, "reward": 0.5265898704528809, "action": -0.47039443254470825}
{"mode": "train", "epochs": 7, "timestep": 13014, "ep_reward": 575.0335083007812, "reward": 0.6413924694061279, "action": -0.25196903944015503}
{"mode": "train", "epochs": 7, "timestep": 13015, "ep_reward": 575.7678833007812, "reward": 0.7344006299972534, "action": -0.928231418132782}
{"mode": "train", "epochs": 7, "timestep": 13016, "ep_reward": 576.5657958984375, "reward": 0.7979069948196411, "action": -0.4138404130935669}
{"mode": "train", "epochs": 7, "timestep": 13017, "ep_reward": 577.4119262695312, "reward": 0.8461028933525085, "action": -0.6252604722976685}
{"mode": "train", "epochs": 7, "timestep": 13018, "ep_reward": 578.2871704101562, "reward": 0.8752523064613342, "action": -1.0836104154586792}
{"mode": "train", "epochs": 7, "timestep": 13019, "ep_reward": 579.1734619140625, "reward": 0.8862648606300354, "action": -0.9744071364402771}
{"mode": "train", "epochs": 7, "timestep": 13020, "ep_reward": 580.0576782226562, "reward": 0.8842160105705261, "action": -0.9420779347419739}
{"mode": "train", "epochs": 7, "timestep": 13021, "ep_reward": 580.9249877929688, "reward": 0.8673319220542908, "action": -1.174691915512085}
{"mode": "train", "epochs": 7, "timestep": 13022, "ep_reward": 581.7553100585938, "reward": 0.8302922248840332, "action": -0.5939783453941345}
{"mode": "train", "epochs": 7, "timestep": 13023, "ep_reward": 582.5310668945312, "reward": 0.7757872343063354, "action": -1.0881173610687256}
{"mode": "train", "epochs": 7, "timestep": 13024, "ep_reward": 583.21826171875, "reward": 0.6871812343597412, "action": -1.0137531757354736}
{"mode": "train", "epochs": 7, "timestep": 13025, "ep_reward": 583.78125, "reward": 0.5630136728286743, "action": -0.8011998534202576}
{"mode": "train", "epochs": 7, "timestep": 13026, "ep_reward": 584.1829223632812, "reward": 0.40166175365448, "action": 0.4500235319137573}
{"mode": "train", "epochs": 7, "timestep": 13027, "ep_reward": 584.4616088867188, "reward": 0.27870428562164307, "action": -0.6178337335586548}
{"mode": "train", "epochs": 7, "timestep": 13028, "ep_reward": 584.616943359375, "reward": 0.15535491704940796, "action": -0.46544915437698364}
{"mode": "train", "epochs": 7, "timestep": 13029, "ep_reward": 584.6288452148438, "reward": 0.011904537677764893, "action": -1.2950260639190674}
{"mode": "train", "epochs": 7, "timestep": 13030, "ep_reward": 584.7332153320312, "reward": 0.10437899827957153, "action": -0.5004054307937622}
{"mode": "train", "epochs": 7, "timestep": 13031, "ep_reward": 584.982177734375, "reward": 0.24898749589920044, "action": -0.6797389388084412}
{"mode": "train", "epochs": 7, "timestep": 13032, "ep_reward": 585.3726196289062, "reward": 0.39041417837142944, "action": -1.1106069087982178}
{"mode": "train", "epochs": 7, "timestep": 13033, "ep_reward": 585.8894653320312, "reward": 0.516838788986206, "action": -0.27378004789352417}
{"mode": "train", "epochs": 7, "timestep": 13034, "ep_reward": 586.5245971679688, "reward": 0.6351397633552551, "action": -0.5534922480583191}
{"mode": "train", "epochs": 7, "timestep": 13035, "ep_reward": 587.2518920898438, "reward": 0.7273247241973877, "action": -0.7750399708747864}
{"mode": "train", "epochs": 7, "timestep": 13036, "ep_reward": 588.0471801757812, "reward": 0.7952585220336914, "action": -1.2489209175109863}
{"mode": "train", "epochs": 7, "timestep": 13037, "ep_reward": 588.8872680664062, "reward": 0.8400945067405701, "action": -0.6560831665992737}
{"mode": "train", "epochs": 7, "timestep": 13038, "ep_reward": 589.7605590820312, "reward": 0.8732621669769287, "action": -1.1944637298583984}
{"mode": "train", "epochs": 7, "timestep": 13039, "ep_reward": 590.6484985351562, "reward": 0.8879233002662659, "action": -0.2490590214729309}
{"mode": "train", "epochs": 7, "timestep": 13040, "ep_reward": 591.5448608398438, "reward": 0.8963454365730286, "action": -1.3909997940063477}
{"mode": "train", "epochs": 7, "timestep": 13041, "ep_reward": 592.427490234375, "reward": 0.8826388716697693, "action": -1.5105311870574951}
{"mode": "train", "epochs": 7, "timestep": 13042, "ep_reward": 593.2789916992188, "reward": 0.8515183925628662, "action": -1.4871010780334473}
{"mode": "train", "epochs": 7, "timestep": 13043, "ep_reward": 594.0780639648438, "reward": 0.799090564250946, "action": -1.0227220058441162}
{"mode": "train", "epochs": 7, "timestep": 13044, "ep_reward": 594.8016967773438, "reward": 0.7236089110374451, "action": -1.250819206237793}
{"mode": "train", "epochs": 7, "timestep": 13045, "ep_reward": 595.4126586914062, "reward": 0.6109415292739868, "action": -1.5081932544708252}
{"mode": "train", "epochs": 7, "timestep": 13046, "ep_reward": 595.8658447265625, "reward": 0.4532020092010498, "action": 0.052433133125305176}
{"mode": "train", "epochs": 7, "timestep": 13047, "ep_reward": 596.1865844726562, "reward": 0.32074254751205444, "action": -0.5618647933006287}
{"mode": "train", "epochs": 7, "timestep": 13048, "ep_reward": 596.3915405273438, "reward": 0.20497918128967285, "action": -1.2597222328186035}
{"mode": "train", "epochs": 7, "timestep": 13049, "ep_reward": 596.4608154296875, "reward": 0.06930029392242432, "action": -1.2306530475616455}
{"mode": "train", "epochs": 7, "timestep": 13050, "ep_reward": 596.5096435546875, "reward": 0.04885411262512207, "action": -0.6971473693847656}
{"mode": "train", "epochs": 7, "timestep": 13051, "ep_reward": 596.6989135742188, "reward": 0.18928402662277222, "action": -1.0978907346725464}
{"mode": "train", "epochs": 7, "timestep": 13052, "ep_reward": 597.02685546875, "reward": 0.3279154896736145, "action": -0.3774200677871704}
{"mode": "train", "epochs": 7, "timestep": 13053, "ep_reward": 597.49658203125, "reward": 0.46975237131118774, "action": -0.36435383558273315}
{"mode": "train", "epochs": 7, "timestep": 13054, "ep_reward": 598.0911865234375, "reward": 0.5946193933486938, "action": -1.6378989219665527}
{"mode": "train", "epochs": 7, "timestep": 13055, "ep_reward": 598.7758178710938, "reward": 0.6846398711204529, "action": -1.171382188796997}
{"mode": "train", "epochs": 7, "timestep": 13056, "ep_reward": 599.5343627929688, "reward": 0.75856614112854, "action": -1.3485342264175415}
{"mode": "train", "epochs": 7, "timestep": 13057, "ep_reward": 600.3445434570312, "reward": 0.8102075457572937, "action": -0.7976797819137573}
{"mode": "train", "epochs": 7, "timestep": 13058, "ep_reward": 601.1923217773438, "reward": 0.847750723361969, "action": -1.51303231716156}
{"mode": "train", "epochs": 7, "timestep": 13059, "ep_reward": 602.0546264648438, "reward": 0.8622961640357971, "action": -0.5944175720214844}
{"mode": "train", "epochs": 7, "timestep": 13060, "ep_reward": 602.9228515625, "reward": 0.8682229518890381, "action": -1.2847390174865723}
{"mode": "train", "epochs": 7, "timestep": 13061, "ep_reward": 603.7741088867188, "reward": 0.8512699604034424, "action": -1.0564730167388916}
{"mode": "train", "epochs": 7, "timestep": 13062, "ep_reward": 604.59033203125, "reward": 0.8161958456039429, "action": -1.2581992149353027}
{"mode": "train", "epochs": 7, "timestep": 13063, "ep_reward": 605.3441162109375, "reward": 0.7537925839424133, "action": -1.2229065895080566}
{"mode": "train", "epochs": 7, "timestep": 13064, "ep_reward": 606.0032348632812, "reward": 0.6591390371322632, "action": -1.0859817266464233}
{"mode": "train", "epochs": 7, "timestep": 13065, "ep_reward": 606.5298461914062, "reward": 0.5266116857528687, "action": -1.2761517763137817}
{"mode": "train", "epochs": 7, "timestep": 13066, "ep_reward": 606.9041748046875, "reward": 0.3743419647216797, "action": -1.1226966381072998}
{"mode": "train", "epochs": 7, "timestep": 13067, "ep_reward": 607.1735229492188, "reward": 0.2693758010864258, "action": -0.9500077366828918}
{"mode": "train", "epochs": 7, "timestep": 13068, "ep_reward": 607.31787109375, "reward": 0.1443348526954651, "action": -1.322533130645752}
{"mode": "train", "epochs": 7, "timestep": 13069, "ep_reward": 607.3173217773438, "reward": -0.0005691051483154297, "action": -0.642709493637085}
{"mode": "train", "epochs": 7, "timestep": 13070, "ep_reward": 607.43310546875, "reward": 0.11578100919723511, "action": -0.414935827255249}
{"mode": "train", "epochs": 7, "timestep": 13071, "ep_reward": 607.69482421875, "reward": 0.2617366313934326, "action": -0.8466809988021851}
{"mode": "train", "epochs": 7, "timestep": 13072, "ep_reward": 608.0953979492188, "reward": 0.40055346488952637, "action": -0.412489116191864}
{"mode": "train", "epochs": 7, "timestep": 13073, "ep_reward": 608.6290893554688, "reward": 0.5336877107620239, "action": -1.3320962190628052}
{"mode": "train", "epochs": 7, "timestep": 13074, "ep_reward": 609.26708984375, "reward": 0.6379830837249756, "action": -0.7326234579086304}
{"mode": "train", "epochs": 7, "timestep": 13075, "ep_reward": 609.99462890625, "reward": 0.7275403738021851, "action": -1.707338571548462}
{"mode": "train", "epochs": 7, "timestep": 13076, "ep_reward": 610.7811889648438, "reward": 0.7865862250328064, "action": -1.2287991046905518}
{"mode": "train", "epochs": 7, "timestep": 13077, "ep_reward": 611.6123046875, "reward": 0.8311141133308411, "action": -1.4529547691345215}
{"mode": "train", "epochs": 7, "timestep": 13078, "ep_reward": 612.46875, "reward": 0.8564684391021729, "action": -0.6256344318389893}
{"mode": "train", "epochs": 7, "timestep": 13079, "ep_reward": 613.3411254882812, "reward": 0.872384250164032, "action": -1.7411983013153076}
{"mode": "train", "epochs": 7, "timestep": 13080, "ep_reward": 614.2042236328125, "reward": 0.8631203174591064, "action": -1.5985065698623657}
{"mode": "train", "epochs": 7, "timestep": 13081, "ep_reward": 615.0409545898438, "reward": 0.8367141485214233, "action": -0.7066322565078735}
{"mode": "train", "epochs": 7, "timestep": 13082, "ep_reward": 615.8375244140625, "reward": 0.7965584397315979, "action": -0.5095123052597046}
{"mode": "train", "epochs": 7, "timestep": 13083, "ep_reward": 616.5696411132812, "reward": 0.7321012020111084, "action": -1.2892905473709106}
{"mode": "train", "epochs": 7, "timestep": 13084, "ep_reward": 617.1949462890625, "reward": 0.6252986192703247, "action": -0.8893028497695923}
{"mode": "train", "epochs": 7, "timestep": 13085, "ep_reward": 617.6780395507812, "reward": 0.48311692476272583, "action": -0.5130335688591003}
{"mode": "train", "epochs": 7, "timestep": 13086, "ep_reward": 618.0213623046875, "reward": 0.3433353304862976, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 13087, "ep_reward": 618.2536010742188, "reward": 0.2322407364845276, "action": -1.0700252056121826}
{"mode": "train", "epochs": 7, "timestep": 13088, "ep_reward": 618.3546142578125, "reward": 0.10102713108062744, "action": -0.4540269374847412}
{"mode": "train", "epochs": 7, "timestep": 13089, "ep_reward": 618.3702392578125, "reward": 0.01564347743988037, "action": -0.3606387972831726}
{"mode": "train", "epochs": 7, "timestep": 13090, "ep_reward": 618.5294799804688, "reward": 0.15923315286636353, "action": -0.7483768463134766}
{"mode": "train", "epochs": 7, "timestep": 13091, "ep_reward": 618.831298828125, "reward": 0.30182522535324097, "action": -1.538123369216919}
{"mode": "train", "epochs": 7, "timestep": 13092, "ep_reward": 619.2623291015625, "reward": 0.43100374937057495, "action": -1.1295750141143799}
{"mode": "train", "epochs": 7, "timestep": 13093, "ep_reward": 619.8158569335938, "reward": 0.5535085201263428, "action": -0.598919153213501}
{"mode": "train", "epochs": 7, "timestep": 13094, "ep_reward": 620.4776611328125, "reward": 0.6617759466171265, "action": -1.362165927886963}
{"mode": "train", "epochs": 7, "timestep": 13095, "ep_reward": 621.2163696289062, "reward": 0.7387129068374634, "action": -1.8861186504364014}
{"mode": "train", "epochs": 7, "timestep": 13096, "ep_reward": 622.0059814453125, "reward": 0.7896368503570557, "action": -0.2798256278038025}
{"mode": "train", "epochs": 7, "timestep": 13097, "ep_reward": 622.841064453125, "reward": 0.8350900411605835, "action": -1.8364934921264648}
{"mode": "train", "epochs": 7, "timestep": 13098, "ep_reward": 623.6890869140625, "reward": 0.8480260372161865, "action": -0.7830370664596558}
{"mode": "train", "epochs": 7, "timestep": 13099, "ep_reward": 624.5414428710938, "reward": 0.8523640036582947, "action": -0.7705481052398682}
{"mode": "train", "epochs": 7, "timestep": 13100, "ep_reward": 625.37939453125, "reward": 0.8379480242729187, "action": -1.386103630065918}
{"mode": "train", "epochs": 7, "timestep": 13101, "ep_reward": 626.1751708984375, "reward": 0.7957537174224854, "action": -1.2434495687484741}
{"mode": "train", "epochs": 7, "timestep": 13102, "ep_reward": 626.9019165039062, "reward": 0.7267612218856812, "action": -1.6582331657409668}
{"mode": "train", "epochs": 7, "timestep": 13103, "ep_reward": 627.5186767578125, "reward": 0.616768479347229, "action": -0.9003187417984009}
{"mode": "train", "epochs": 7, "timestep": 13104, "ep_reward": 627.9925537109375, "reward": 0.47387874126434326, "action": -0.9423620700836182}
{"mode": "train", "epochs": 7, "timestep": 13105, "ep_reward": 628.3448486328125, "reward": 0.3522931933403015, "action": -0.9665946960449219}
{"mode": "train", "epochs": 7, "timestep": 13106, "ep_reward": 628.587646484375, "reward": 0.24278998374938965, "action": -0.7474789619445801}
{"mode": "train", "epochs": 7, "timestep": 13107, "ep_reward": 628.7008666992188, "reward": 0.11324518918991089, "action": -0.9257860779762268}
{"mode": "train", "epochs": 7, "timestep": 13108, "ep_reward": 628.7030639648438, "reward": 0.0022035837173461914, "action": -0.6053426265716553}
{"mode": "train", "epochs": 7, "timestep": 13109, "ep_reward": 628.849853515625, "reward": 0.14680486917495728, "action": -0.9051917195320129}
{"mode": "train", "epochs": 7, "timestep": 13110, "ep_reward": 629.1373291015625, "reward": 0.28747981786727905, "action": -0.7028200030326843}
{"mode": "train", "epochs": 7, "timestep": 13111, "ep_reward": 629.5651245117188, "reward": 0.4277898669242859, "action": -0.8506752252578735}
{"mode": "train", "epochs": 7, "timestep": 13112, "ep_reward": 630.118408203125, "reward": 0.5532901287078857, "action": -0.8731483221054077}
{"mode": "train", "epochs": 7, "timestep": 13113, "ep_reward": 630.7772827148438, "reward": 0.6588640213012695, "action": -1.1208299398422241}
{"mode": "train", "epochs": 7, "timestep": 13114, "ep_reward": 631.5170288085938, "reward": 0.7397540807723999, "action": -0.7526316046714783}
{"mode": "train", "epochs": 7, "timestep": 13115, "ep_reward": 632.319580078125, "reward": 0.8025772571563721, "action": -0.6398406624794006}
{"mode": "train", "epochs": 7, "timestep": 13116, "ep_reward": 633.1661376953125, "reward": 0.846532940864563, "action": -0.6024558544158936}
{"mode": "train", "epochs": 7, "timestep": 13117, "ep_reward": 634.039794921875, "reward": 0.8736652135848999, "action": -0.47996485233306885}
{"mode": "train", "epochs": 7, "timestep": 13118, "ep_reward": 634.9263916015625, "reward": 0.8866055607795715, "action": -1.6276623010635376}
{"mode": "train", "epochs": 7, "timestep": 13119, "ep_reward": 635.8024291992188, "reward": 0.8760566711425781, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 13120, "ep_reward": 636.6475830078125, "reward": 0.8451665639877319, "action": -1.5728836059570312}
{"mode": "train", "epochs": 7, "timestep": 13121, "ep_reward": 637.4432373046875, "reward": 0.7956507205963135, "action": -0.8302446007728577}
{"mode": "train", "epochs": 7, "timestep": 13122, "ep_reward": 638.1691284179688, "reward": 0.7259001731872559, "action": -0.5560355186462402}
{"mode": "train", "epochs": 7, "timestep": 13123, "ep_reward": 638.79541015625, "reward": 0.626255214214325, "action": -1.0783092975616455}
{"mode": "train", "epochs": 7, "timestep": 13124, "ep_reward": 639.2761840820312, "reward": 0.48077642917633057, "action": 0.59447181224823}
{"mode": "train", "epochs": 7, "timestep": 13125, "ep_reward": 639.61474609375, "reward": 0.33856046199798584, "action": -1.2748446464538574}
{"mode": "train", "epochs": 7, "timestep": 13126, "ep_reward": 639.8411254882812, "reward": 0.22638863325119019, "action": -0.7233911752700806}
{"mode": "train", "epochs": 7, "timestep": 13127, "ep_reward": 639.9351806640625, "reward": 0.09404730796813965, "action": -1.4649789333343506}
{"mode": "train", "epochs": 7, "timestep": 13128, "ep_reward": 639.9581909179688, "reward": 0.022980570793151855, "action": -0.8432580232620239}
{"mode": "train", "epochs": 7, "timestep": 13129, "ep_reward": 640.1229858398438, "reward": 0.16477322578430176, "action": -1.6372984647750854}
{"mode": "train", "epochs": 7, "timestep": 13130, "ep_reward": 640.419677734375, "reward": 0.2966974377632141, "action": -0.9969264268875122}
{"mode": "train", "epochs": 7, "timestep": 13131, "ep_reward": 640.85400390625, "reward": 0.4343109726905823, "action": -1.1600781679153442}
{"mode": "train", "epochs": 7, "timestep": 13132, "ep_reward": 641.4103393554688, "reward": 0.556309700012207, "action": -0.951964259147644}
{"mode": "train", "epochs": 7, "timestep": 13133, "ep_reward": 642.0706176757812, "reward": 0.6602684259414673, "action": -0.7797583341598511}
{"mode": "train", "epochs": 7, "timestep": 13134, "ep_reward": 642.8129272460938, "reward": 0.7423313856124878, "action": -1.0832408666610718}
{"mode": "train", "epochs": 7, "timestep": 13135, "ep_reward": 643.6114501953125, "reward": 0.7985427975654602, "action": -0.9662200808525085}
{"mode": "train", "epochs": 7, "timestep": 13136, "ep_reward": 644.4469604492188, "reward": 0.8354887962341309, "action": -0.6251837015151978}
{"mode": "train", "epochs": 7, "timestep": 13137, "ep_reward": 645.3038330078125, "reward": 0.8568652272224426, "action": -0.8671271800994873}
{"mode": "train", "epochs": 7, "timestep": 13138, "ep_reward": 646.1625366210938, "reward": 0.8587117791175842, "action": -0.4559429883956909}
{"mode": "train", "epochs": 7, "timestep": 13139, "ep_reward": 647.0087280273438, "reward": 0.8462004661560059, "action": -1.3594839572906494}
{"mode": "train", "epochs": 7, "timestep": 13140, "ep_reward": 647.8133544921875, "reward": 0.8046485185623169, "action": -0.5275963544845581}
{"mode": "train", "epochs": 7, "timestep": 13141, "ep_reward": 648.5586547851562, "reward": 0.7453099489212036, "action": -1.6932982206344604}
{"mode": "train", "epochs": 7, "timestep": 13142, "ep_reward": 649.198486328125, "reward": 0.6398112773895264, "action": -0.09039455652236938}
{"mode": "train", "epochs": 7, "timestep": 13143, "ep_reward": 649.714111328125, "reward": 0.5156123638153076, "action": -0.16701912879943848}
{"mode": "train", "epochs": 7, "timestep": 13144, "ep_reward": 650.0757446289062, "reward": 0.3616446852684021, "action": -0.19364571571350098}
{"mode": "train", "epochs": 7, "timestep": 13145, "ep_reward": 650.3296508789062, "reward": 0.2539035677909851, "action": -1.2802761793136597}
{"mode": "train", "epochs": 7, "timestep": 13146, "ep_reward": 650.4558715820312, "reward": 0.12619709968566895, "action": -1.6417484283447266}
{"mode": "train", "epochs": 7, "timestep": 13147, "ep_reward": 650.443359375, "reward": -0.012531757354736328, "action": -1.1969634294509888}
{"mode": "train", "epochs": 7, "timestep": 13148, "ep_reward": 650.5773315429688, "reward": 0.13396334648132324, "action": -1.3248913288116455}
{"mode": "train", "epochs": 7, "timestep": 13149, "ep_reward": 650.8464965820312, "reward": 0.26913607120513916, "action": -0.686327338218689}
{"mode": "train", "epochs": 7, "timestep": 13150, "ep_reward": 651.2578735351562, "reward": 0.4113866686820984, "action": -0.9042881727218628}
{"mode": "train", "epochs": 7, "timestep": 13151, "ep_reward": 651.7965698242188, "reward": 0.5387088656425476, "action": -0.2810596823692322}
{"mode": "train", "epochs": 7, "timestep": 13152, "ep_reward": 652.44970703125, "reward": 0.6531627774238586, "action": -0.9868905544281006}
{"mode": "train", "epochs": 7, "timestep": 13153, "ep_reward": 653.1864013671875, "reward": 0.736695408821106, "action": -1.0009514093399048}
{"mode": "train", "epochs": 7, "timestep": 13154, "ep_reward": 653.9847412109375, "reward": 0.7983109951019287, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 13155, "ep_reward": 654.8170166015625, "reward": 0.8322958946228027, "action": -0.8687085509300232}
{"mode": "train", "epochs": 7, "timestep": 13156, "ep_reward": 655.6759033203125, "reward": 0.8589017391204834, "action": -0.274092435836792}
{"mode": "train", "epochs": 7, "timestep": 13157, "ep_reward": 656.5498046875, "reward": 0.8739145994186401, "action": 0.23167526721954346}
{"mode": "train", "epochs": 7, "timestep": 13158, "ep_reward": 657.42724609375, "reward": 0.877434253692627, "action": -0.8146750926971436}
{"mode": "train", "epochs": 7, "timestep": 13159, "ep_reward": 658.2835083007812, "reward": 0.856281042098999, "action": -0.958197295665741}
{"mode": "train", "epochs": 7, "timestep": 13160, "ep_reward": 659.0978393554688, "reward": 0.814315676689148, "action": -1.0815623998641968}
{"mode": "train", "epochs": 7, "timestep": 13161, "ep_reward": 659.8436279296875, "reward": 0.7457733750343323, "action": -1.5049322843551636}
{"mode": "train", "epochs": 7, "timestep": 13162, "ep_reward": 660.48291015625, "reward": 0.6392841339111328, "action": -0.974492073059082}
{"mode": "train", "epochs": 7, "timestep": 13163, "ep_reward": 660.9822387695312, "reward": 0.49935370683670044, "action": -1.4444270133972168}
{"mode": "train", "epochs": 7, "timestep": 13164, "ep_reward": 661.3287963867188, "reward": 0.3465726375579834, "action": -0.3387265205383301}
{"mode": "train", "epochs": 7, "timestep": 13165, "ep_reward": 661.5646362304688, "reward": 0.23583626747131348, "action": -1.009219765663147}
{"mode": "train", "epochs": 7, "timestep": 13166, "ep_reward": 661.6697998046875, "reward": 0.10518985986709595, "action": -0.7015912532806396}
{"mode": "train", "epochs": 7, "timestep": 13167, "ep_reward": 661.680908203125, "reward": 0.01108396053314209, "action": -0.6332162618637085}
{"mode": "train", "epochs": 7, "timestep": 13168, "ep_reward": 661.83544921875, "reward": 0.15454167127609253, "action": -0.8368430733680725}
{"mode": "train", "epochs": 7, "timestep": 13169, "ep_reward": 662.1316528320312, "reward": 0.29617416858673096, "action": -1.1625052690505981}
{"mode": "train", "epochs": 7, "timestep": 13170, "ep_reward": 662.5620727539062, "reward": 0.43042969703674316, "action": -0.8676184415817261}
{"mode": "train", "epochs": 7, "timestep": 13171, "ep_reward": 663.1177978515625, "reward": 0.5557141900062561, "action": -1.166898250579834}
{"mode": "train", "epochs": 7, "timestep": 13172, "ep_reward": 663.7755737304688, "reward": 0.6577708721160889, "action": -1.0140970945358276}
{"mode": "train", "epochs": 7, "timestep": 13173, "ep_reward": 664.5147705078125, "reward": 0.739182710647583, "action": -1.103650689125061}
{"mode": "train", "epochs": 7, "timestep": 13174, "ep_reward": 665.3125, "reward": 0.7977201342582703, "action": -1.081196665763855}
{"mode": "train", "epochs": 7, "timestep": 13175, "ep_reward": 666.1491088867188, "reward": 0.8366233706474304, "action": -0.557948648929596}
{"mode": "train", "epochs": 7, "timestep": 13176, "ep_reward": 667.0111083984375, "reward": 0.8619875311851501, "action": -1.1403261423110962}
{"mode": "train", "epochs": 7, "timestep": 13177, "ep_reward": 667.8768920898438, "reward": 0.8658115863800049, "action": -0.9139482975006104}
{"mode": "train", "epochs": 7, "timestep": 13178, "ep_reward": 668.7314453125, "reward": 0.8545827865600586, "action": -1.0583033561706543}
{"mode": "train", "epochs": 7, "timestep": 13179, "ep_reward": 669.5540771484375, "reward": 0.8226193785667419, "action": -1.1896568536758423}
{"mode": "train", "epochs": 7, "timestep": 13180, "ep_reward": 670.319091796875, "reward": 0.76502925157547, "action": -0.8243780136108398}
{"mode": "train", "epochs": 7, "timestep": 13181, "ep_reward": 670.9998168945312, "reward": 0.6807472705841064, "action": -0.4737485647201538}
{"mode": "train", "epochs": 7, "timestep": 13182, "ep_reward": 671.564453125, "reward": 0.5646234750747681, "action": -1.5982385873794556}
{"mode": "train", "epochs": 7, "timestep": 13183, "ep_reward": 671.95556640625, "reward": 0.3911416530609131, "action": 0.13084328174591064}
{"mode": "train", "epochs": 7, "timestep": 13184, "ep_reward": 672.2440185546875, "reward": 0.2884376645088196, "action": 0.12810957431793213}
{"mode": "train", "epochs": 7, "timestep": 13185, "ep_reward": 672.4107055664062, "reward": 0.16670483350753784, "action": -1.2677040100097656}
{"mode": "train", "epochs": 7, "timestep": 13186, "ep_reward": 672.435791015625, "reward": 0.025069236755371094, "action": -1.2860498428344727}
{"mode": "train", "epochs": 7, "timestep": 13187, "ep_reward": 672.52783203125, "reward": 0.09201449155807495, "action": -1.5610814094543457}
{"mode": "train", "epochs": 7, "timestep": 13188, "ep_reward": 672.7525024414062, "reward": 0.22464221715927124, "action": -0.8730387091636658}
{"mode": "train", "epochs": 7, "timestep": 13189, "ep_reward": 673.119140625, "reward": 0.3666132688522339, "action": -1.228255271911621}
{"mode": "train", "epochs": 7, "timestep": 13190, "ep_reward": 673.614501953125, "reward": 0.49534934759140015, "action": -1.2877463102340698}
{"mode": "train", "epochs": 7, "timestep": 13191, "ep_reward": 674.2212524414062, "reward": 0.6067674160003662, "action": -0.8988665342330933}
{"mode": "train", "epochs": 7, "timestep": 13192, "ep_reward": 674.921630859375, "reward": 0.7003900408744812, "action": -1.7708375453948975}
{"mode": "train", "epochs": 7, "timestep": 13193, "ep_reward": 675.683837890625, "reward": 0.7621873617172241, "action": -1.0726653337478638}
{"mode": "train", "epochs": 7, "timestep": 13194, "ep_reward": 676.4932250976562, "reward": 0.8094098567962646, "action": -1.362579107284546}
{"mode": "train", "epochs": 7, "timestep": 13195, "ep_reward": 677.3267211914062, "reward": 0.833491325378418, "action": -1.997442603111267}
{"mode": "train", "epochs": 7, "timestep": 13196, "ep_reward": 678.1591796875, "reward": 0.8324456810951233, "action": -0.8994882106781006}
{"mode": "train", "epochs": 7, "timestep": 13197, "ep_reward": 678.97998046875, "reward": 0.8208081722259521, "action": 0.36143016815185547}
{"mode": "train", "epochs": 7, "timestep": 13198, "ep_reward": 679.7791748046875, "reward": 0.7991830110549927, "action": -1.053579568862915}
{"mode": "train", "epochs": 7, "timestep": 13199, "ep_reward": 680.5158081054688, "reward": 0.7366563081741333, "action": -1.6130406856536865}
{"mode": "train", "epochs": 7, "timestep": 13200, "ep_reward": 681.1486206054688, "reward": 0.632789134979248, "action": -0.8041355013847351}
{"mode": "train", "epochs": 7, "timestep": 13201, "ep_reward": 681.6461791992188, "reward": 0.4975564479827881, "action": -0.4314075708389282}
{"mode": "train", "epochs": 7, "timestep": 13202, "ep_reward": 682.0132446289062, "reward": 0.3670879006385803, "action": -1.5609991550445557}
{"mode": "train", "epochs": 7, "timestep": 13203, "ep_reward": 682.27392578125, "reward": 0.2606682777404785, "action": -1.1547609567642212}
{"mode": "train", "epochs": 7, "timestep": 13204, "ep_reward": 682.4080200195312, "reward": 0.13410282135009766, "action": -1.6040265560150146}
{"mode": "train", "epochs": 7, "timestep": 13205, "ep_reward": 682.3956909179688, "reward": -0.012350678443908691, "action": -1.425576090812683}
{"mode": "train", "epochs": 7, "timestep": 13206, "ep_reward": 682.5218505859375, "reward": 0.1261717677116394, "action": -0.160636305809021}
{"mode": "train", "epochs": 7, "timestep": 13207, "ep_reward": 682.79736328125, "reward": 0.2755368947982788, "action": -0.7724685072898865}
{"mode": "train", "epochs": 7, "timestep": 13208, "ep_reward": 683.2113647460938, "reward": 0.41397398710250854, "action": -1.5820618867874146}
{"mode": "train", "epochs": 7, "timestep": 13209, "ep_reward": 683.7435913085938, "reward": 0.5322219729423523, "action": -1.2102402448654175}
{"mode": "train", "epochs": 7, "timestep": 13210, "ep_reward": 684.381591796875, "reward": 0.6380149126052856, "action": -1.5911731719970703}
{"mode": "train", "epochs": 7, "timestep": 13211, "ep_reward": 685.1004638671875, "reward": 0.718876838684082, "action": -1.2640527486801147}
{"mode": "train", "epochs": 7, "timestep": 13212, "ep_reward": 685.88232421875, "reward": 0.7818489074707031, "action": -0.1324654221534729}
{"mode": "train", "epochs": 7, "timestep": 13213, "ep_reward": 686.716552734375, "reward": 0.8342578411102295, "action": -0.6542698740959167}
{"mode": "train", "epochs": 7, "timestep": 13214, "ep_reward": 687.5797119140625, "reward": 0.8631730079650879, "action": -0.21899157762527466}
{"mode": "train", "epochs": 7, "timestep": 13215, "ep_reward": 688.4591674804688, "reward": 0.8794453144073486, "action": -0.6940141320228577}
{"mode": "train", "epochs": 7, "timestep": 13216, "ep_reward": 689.3359375, "reward": 0.876778781414032, "action": -0.32543128728866577}
{"mode": "train", "epochs": 7, "timestep": 13217, "ep_reward": 690.197265625, "reward": 0.8613333106040955, "action": -1.2437454462051392}
{"mode": "train", "epochs": 7, "timestep": 13218, "ep_reward": 691.016357421875, "reward": 0.819064736366272, "action": -0.9158019423484802}
{"mode": "train", "epochs": 7, "timestep": 13219, "ep_reward": 691.7715454101562, "reward": 0.7551775574684143, "action": -0.5610126256942749}
{"mode": "train", "epochs": 7, "timestep": 13220, "ep_reward": 692.4363403320312, "reward": 0.6648075580596924, "action": -0.45795631408691406}
{"mode": "train", "epochs": 7, "timestep": 13221, "ep_reward": 692.9767456054688, "reward": 0.5404123067855835, "action": -0.6093800067901611}
{"mode": "train", "epochs": 7, "timestep": 13222, "ep_reward": 693.3527221679688, "reward": 0.37599676847457886, "action": -0.5431967973709106}
{"mode": "train", "epochs": 7, "timestep": 13223, "ep_reward": 693.6079711914062, "reward": 0.25523221492767334, "action": -0.6497375965118408}
{"mode": "train", "epochs": 7, "timestep": 13224, "ep_reward": 693.7357177734375, "reward": 0.12776803970336914, "action": -1.0062556266784668}
{"mode": "train", "epochs": 7, "timestep": 13225, "ep_reward": 693.7216186523438, "reward": -0.014113306999206543, "action": 0.1750943660736084}
{"mode": "train", "epochs": 7, "timestep": 13226, "ep_reward": 693.8566284179688, "reward": 0.13498014211654663, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 13227, "ep_reward": 694.1178588867188, "reward": 0.2612133026123047, "action": -0.3011649250984192}
{"mode": "train", "epochs": 7, "timestep": 13228, "ep_reward": 694.5271606445312, "reward": 0.40927380323410034, "action": -1.9897186756134033}
{"mode": "train", "epochs": 7, "timestep": 13229, "ep_reward": 695.051513671875, "reward": 0.5243397951126099, "action": -1.6336851119995117}
{"mode": "train", "epochs": 7, "timestep": 13230, "ep_reward": 695.678466796875, "reward": 0.6269811391830444, "action": -0.45482301712036133}
{"mode": "train", "epochs": 7, "timestep": 13231, "ep_reward": 696.398193359375, "reward": 0.7197329998016357, "action": -0.9882678389549255}
{"mode": "train", "epochs": 7, "timestep": 13232, "ep_reward": 697.1806640625, "reward": 0.7824491858482361, "action": -1.3842196464538574}
{"mode": "train", "epochs": 7, "timestep": 13233, "ep_reward": 698.0006103515625, "reward": 0.8199173808097839, "action": -1.7742208242416382}
{"mode": "train", "epochs": 7, "timestep": 13234, "ep_reward": 698.8350219726562, "reward": 0.8343873023986816, "action": -1.288180947303772}
{"mode": "train", "epochs": 7, "timestep": 13235, "ep_reward": 699.6687622070312, "reward": 0.8337562680244446, "action": -0.14275920391082764}
{"mode": "train", "epochs": 7, "timestep": 13236, "ep_reward": 700.4918823242188, "reward": 0.8231074213981628, "action": -1.408877968788147}
{"mode": "train", "epochs": 7, "timestep": 13237, "ep_reward": 701.2681884765625, "reward": 0.7762849926948547, "action": -0.982200026512146}
{"mode": "train", "epochs": 7, "timestep": 13238, "ep_reward": 701.97216796875, "reward": 0.7039692997932434, "action": -0.3120909333229065}
{"mode": "train", "epochs": 7, "timestep": 13239, "ep_reward": 702.5765991210938, "reward": 0.6044522523880005, "action": -0.4878903031349182}
{"mode": "train", "epochs": 7, "timestep": 13240, "ep_reward": 703.03955078125, "reward": 0.46294546127319336, "action": -1.959641933441162}
{"mode": "train", "epochs": 7, "timestep": 13241, "ep_reward": 703.3782958984375, "reward": 0.3387466073036194, "action": -0.7647079229354858}
{"mode": "train", "epochs": 7, "timestep": 13242, "ep_reward": 703.6046752929688, "reward": 0.22638988494873047, "action": -1.6796679496765137}
{"mode": "train", "epochs": 7, "timestep": 13243, "ep_reward": 703.6988525390625, "reward": 0.09418857097625732, "action": -1.606905460357666}
{"mode": "train", "epochs": 7, "timestep": 13244, "ep_reward": 703.7216796875, "reward": 0.022842466831207275, "action": -0.20211553573608398}
{"mode": "train", "epochs": 7, "timestep": 13245, "ep_reward": 703.8902587890625, "reward": 0.1686091423034668, "action": -0.97773277759552}
{"mode": "train", "epochs": 7, "timestep": 13246, "ep_reward": 704.1980590820312, "reward": 0.307786226272583, "action": -1.7832539081573486}
{"mode": "train", "epochs": 7, "timestep": 13247, "ep_reward": 704.6317138671875, "reward": 0.43367183208465576, "action": -1.2244412899017334}
{"mode": "train", "epochs": 7, "timestep": 13248, "ep_reward": 705.1866455078125, "reward": 0.5549034476280212, "action": -0.7177380323410034}
{"mode": "train", "epochs": 7, "timestep": 13249, "ep_reward": 705.8482666015625, "reward": 0.6616343259811401, "action": -1.0592294931411743}
{"mode": "train", "epochs": 7, "timestep": 13250, "ep_reward": 706.58935546875, "reward": 0.7411131858825684, "action": -1.1931934356689453}
{"mode": "train", "epochs": 7, "timestep": 13251, "ep_reward": 707.3865356445312, "reward": 0.797154426574707, "action": -0.49595212936401367}
{"mode": "train", "epochs": 7, "timestep": 13252, "ep_reward": 708.2257080078125, "reward": 0.8391672968864441, "action": 0.04193007946014404}
{"mode": "train", "epochs": 7, "timestep": 13253, "ep_reward": 709.0927124023438, "reward": 0.8669992089271545, "action": -1.4644410610198975}
{"mode": "train", "epochs": 7, "timestep": 13254, "ep_reward": 709.9581909179688, "reward": 0.865497350692749, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 13255, "ep_reward": 710.7999267578125, "reward": 0.8417547345161438, "action": -0.6646541357040405}
{"mode": "train", "epochs": 7, "timestep": 13256, "ep_reward": 711.60888671875, "reward": 0.8089699745178223, "action": -0.09708720445632935}
{"mode": "train", "epochs": 7, "timestep": 13257, "ep_reward": 712.3662719726562, "reward": 0.7573904395103455, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 13258, "ep_reward": 713.019287109375, "reward": 0.6529916524887085, "action": -0.3704981803894043}
{"mode": "train", "epochs": 7, "timestep": 13259, "ep_reward": 713.5484008789062, "reward": 0.5291438102722168, "action": -1.3634010553359985}
{"mode": "train", "epochs": 7, "timestep": 13260, "ep_reward": 713.92041015625, "reward": 0.3719937801361084, "action": -1.0364693403244019}
{"mode": "train", "epochs": 7, "timestep": 13261, "ep_reward": 714.1869506835938, "reward": 0.2665208578109741, "action": -0.9454656839370728}
{"mode": "train", "epochs": 7, "timestep": 13262, "ep_reward": 714.327880859375, "reward": 0.14095807075500488, "action": -1.4701755046844482}
{"mode": "train", "epochs": 7, "timestep": 13263, "ep_reward": 714.3233032226562, "reward": -0.004569411277770996, "action": -1.6952565908432007}
{"mode": "train", "epochs": 7, "timestep": 13264, "ep_reward": 714.4425048828125, "reward": 0.11922293901443481, "action": -0.42421281337738037}
{"mode": "train", "epochs": 7, "timestep": 13265, "ep_reward": 714.7076416015625, "reward": 0.26514023542404175, "action": -0.9825853109359741}
{"mode": "train", "epochs": 7, "timestep": 13266, "ep_reward": 715.1097412109375, "reward": 0.4021291732788086, "action": -1.2797749042510986}
{"mode": "train", "epochs": 7, "timestep": 13267, "ep_reward": 715.6353149414062, "reward": 0.5255662202835083, "action": -1.0499780178070068}
{"mode": "train", "epochs": 7, "timestep": 13268, "ep_reward": 716.26953125, "reward": 0.634246826171875, "action": -1.4476275444030762}
{"mode": "train", "epochs": 7, "timestep": 13269, "ep_reward": 716.9868774414062, "reward": 0.7173576354980469, "action": -0.8199845552444458}
{"mode": "train", "epochs": 7, "timestep": 13270, "ep_reward": 717.7716674804688, "reward": 0.784812331199646, "action": -1.3658466339111328}
{"mode": "train", "epochs": 7, "timestep": 13271, "ep_reward": 718.5982055664062, "reward": 0.8265529274940491, "action": -1.8560312986373901}
{"mode": "train", "epochs": 7, "timestep": 13272, "ep_reward": 719.4442749023438, "reward": 0.8460680842399597, "action": -1.6259901523590088}
{"mode": "train", "epochs": 7, "timestep": 13273, "ep_reward": 720.2943725585938, "reward": 0.8500943183898926, "action": -1.2849841117858887}
{"mode": "train", "epochs": 7, "timestep": 13274, "ep_reward": 721.1328125, "reward": 0.8384354114532471, "action": -0.5705292224884033}
{"mode": "train", "epochs": 7, "timestep": 13275, "ep_reward": 721.9452514648438, "reward": 0.8124290704727173, "action": -1.0557507276535034}
{"mode": "train", "epochs": 7, "timestep": 13276, "ep_reward": 722.7018432617188, "reward": 0.7565640807151794, "action": -0.49814218282699585}
{"mode": "train", "epochs": 7, "timestep": 13277, "ep_reward": 723.3777465820312, "reward": 0.6758925318717957, "action": -1.108747959136963}
{"mode": "train", "epochs": 7, "timestep": 13278, "ep_reward": 723.927978515625, "reward": 0.5502216815948486, "action": -0.4027417302131653}
{"mode": "train", "epochs": 7, "timestep": 13279, "ep_reward": 724.3208618164062, "reward": 0.3928854465484619, "action": -0.7850828766822815}
{"mode": "train", "epochs": 7, "timestep": 13280, "ep_reward": 724.6107177734375, "reward": 0.28983205556869507, "action": -1.7023175954818726}
{"mode": "train", "epochs": 7, "timestep": 13281, "ep_reward": 724.7793579101562, "reward": 0.16862434148788452, "action": -0.7792960405349731}
{"mode": "train", "epochs": 7, "timestep": 13282, "ep_reward": 724.806640625, "reward": 0.02731144428253174, "action": -0.09614986181259155}
{"mode": "train", "epochs": 7, "timestep": 13283, "ep_reward": 724.8966674804688, "reward": 0.09000259637832642, "action": -1.5462756156921387}
{"mode": "train", "epochs": 7, "timestep": 13284, "ep_reward": 725.1195068359375, "reward": 0.22286057472229004, "action": -1.2446248531341553}
{"mode": "train", "epochs": 7, "timestep": 13285, "ep_reward": 725.4797973632812, "reward": 0.3602657914161682, "action": -1.0700794458389282}
{"mode": "train", "epochs": 7, "timestep": 13286, "ep_reward": 725.9716796875, "reward": 0.4918684959411621, "action": -1.4601421356201172}
{"mode": "train", "epochs": 7, "timestep": 13287, "ep_reward": 726.5736694335938, "reward": 0.6020110845565796, "action": -0.4234888553619385}
{"mode": "train", "epochs": 7, "timestep": 13288, "ep_reward": 727.2750854492188, "reward": 0.7014379501342773, "action": -0.8593458533287048}
{"mode": "train", "epochs": 7, "timestep": 13289, "ep_reward": 728.0468139648438, "reward": 0.7717466354370117, "action": -0.7637845873832703}
{"mode": "train", "epochs": 7, "timestep": 13290, "ep_reward": 728.8677978515625, "reward": 0.8209738731384277, "action": -0.8912485837936401}
{"mode": "train", "epochs": 7, "timestep": 13291, "ep_reward": 729.7172241210938, "reward": 0.8494055867195129, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 13292, "ep_reward": 730.5679931640625, "reward": 0.8507657647132874, "action": -0.8782427310943604}
{"mode": "train", "epochs": 7, "timestep": 13293, "ep_reward": 731.4114379882812, "reward": 0.8434559106826782, "action": -1.8178199529647827}
{"mode": "train", "epochs": 7, "timestep": 13294, "ep_reward": 732.2174682617188, "reward": 0.8060464859008789, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 13295, "ep_reward": 732.9561767578125, "reward": 0.7386950254440308, "action": -1.17625892162323}
{"mode": "train", "epochs": 7, "timestep": 13296, "ep_reward": 733.6015014648438, "reward": 0.6453068852424622, "action": -0.4267114996910095}
{"mode": "train", "epochs": 7, "timestep": 13297, "ep_reward": 734.1229858398438, "reward": 0.5214834213256836, "action": -1.9930710792541504}
{"mode": "train", "epochs": 7, "timestep": 13298, "ep_reward": 734.50634765625, "reward": 0.38337773084640503, "action": -0.8674381375312805}
{"mode": "train", "epochs": 7, "timestep": 13299, "ep_reward": 734.78662109375, "reward": 0.28029531240463257, "action": -0.9454176425933838}
{"mode": "train", "epochs": 7, "timestep": 13300, "ep_reward": 734.9437866210938, "reward": 0.15718978643417358, "action": -1.1894453763961792}
{"mode": "train", "epochs": 7, "timestep": 13301, "ep_reward": 734.9578247070312, "reward": 0.014017045497894287, "action": -1.7384512424468994}
{"mode": "train", "epochs": 7, "timestep": 13302, "ep_reward": 735.0601806640625, "reward": 0.10232895612716675, "action": -0.849547266960144}
{"mode": "train", "epochs": 7, "timestep": 13303, "ep_reward": 735.302734375, "reward": 0.24253308773040771, "action": -0.951796293258667}
{"mode": "train", "epochs": 7, "timestep": 13304, "ep_reward": 735.6842651367188, "reward": 0.3815106749534607, "action": -1.9688972234725952}
{"mode": "train", "epochs": 7, "timestep": 13305, "ep_reward": 736.1837768554688, "reward": 0.49949902296066284, "action": -1.6220026016235352}
{"mode": "train", "epochs": 7, "timestep": 13306, "ep_reward": 736.7904052734375, "reward": 0.6066040992736816, "action": -0.1891026496887207}
{"mode": "train", "epochs": 7, "timestep": 13307, "ep_reward": 737.4974975585938, "reward": 0.7070885896682739, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 13308, "ep_reward": 738.2626953125, "reward": 0.7651832699775696, "action": -0.5589408278465271}
{"mode": "train", "epochs": 7, "timestep": 13309, "ep_reward": 739.07861328125, "reward": 0.8159033060073853, "action": -1.4784319400787354}
{"mode": "train", "epochs": 7, "timestep": 13310, "ep_reward": 739.91650390625, "reward": 0.8379201292991638, "action": -1.4079428911209106}
{"mode": "train", "epochs": 7, "timestep": 13311, "ep_reward": 740.75830078125, "reward": 0.8417761325836182, "action": -0.9036183953285217}
{"mode": "train", "epochs": 7, "timestep": 13312, "ep_reward": 741.5887451171875, "reward": 0.8304356336593628, "action": -0.7958889007568359}
{"mode": "train", "epochs": 7, "timestep": 13313, "ep_reward": 742.3866577148438, "reward": 0.7978916764259338, "action": -0.9557695984840393}
{"mode": "train", "epochs": 7, "timestep": 13314, "ep_reward": 743.1234741210938, "reward": 0.7368000149726868, "action": -0.9971551299095154}
{"mode": "train", "epochs": 7, "timestep": 13315, "ep_reward": 743.7649536132812, "reward": 0.6414998769760132, "action": -1.2843598127365112}
{"mode": "train", "epochs": 7, "timestep": 13316, "ep_reward": 744.2662963867188, "reward": 0.5013461112976074, "action": -0.741005539894104}
{"mode": "train", "epochs": 7, "timestep": 13317, "ep_reward": 744.635986328125, "reward": 0.36969828605651855, "action": -0.45147114992141724}
{"mode": "train", "epochs": 7, "timestep": 13318, "ep_reward": 744.8994750976562, "reward": 0.2634859085083008, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 13319, "ep_reward": 745.037109375, "reward": 0.13762837648391724, "action": -1.459256649017334}
{"mode": "train", "epochs": 7, "timestep": 13320, "ep_reward": 745.0288696289062, "reward": -0.008227705955505371, "action": -0.4946673512458801}
{"mode": "train", "epochs": 7, "timestep": 13321, "ep_reward": 745.1513671875, "reward": 0.12252241373062134, "action": -1.3249382972717285}
{"mode": "train", "epochs": 7, "timestep": 13322, "ep_reward": 745.4087524414062, "reward": 0.2573917508125305, "action": -0.6980280876159668}
{"mode": "train", "epochs": 7, "timestep": 13323, "ep_reward": 745.8086547851562, "reward": 0.3999011516571045, "action": -1.742225170135498}
{"mode": "train", "epochs": 7, "timestep": 13324, "ep_reward": 746.3275146484375, "reward": 0.5188588500022888, "action": -1.3246456384658813}
{"mode": "train", "epochs": 7, "timestep": 13325, "ep_reward": 746.9532470703125, "reward": 0.6257065534591675, "action": -1.868384599685669}
{"mode": "train", "epochs": 7, "timestep": 13326, "ep_reward": 747.6583251953125, "reward": 0.7050492763519287, "action": -0.9290691614151001}
{"mode": "train", "epochs": 7, "timestep": 13327, "ep_reward": 748.4296875, "reward": 0.7713860273361206, "action": -1.5608384609222412}
{"mode": "train", "epochs": 7, "timestep": 13328, "ep_reward": 749.2390747070312, "reward": 0.8093788623809814, "action": -0.852027952671051}
{"mode": "train", "epochs": 7, "timestep": 13329, "ep_reward": 750.0725708007812, "reward": 0.8335066437721252, "action": -1.1219898462295532}
{"mode": "train", "epochs": 7, "timestep": 13330, "ep_reward": 750.9075927734375, "reward": 0.8350253105163574, "action": -1.241210699081421}
{"mode": "train", "epochs": 7, "timestep": 13331, "ep_reward": 751.7218017578125, "reward": 0.8141983151435852, "action": -0.7974117398262024}
{"mode": "train", "epochs": 7, "timestep": 13332, "ep_reward": 752.494873046875, "reward": 0.7730967402458191, "action": -1.492726445198059}
{"mode": "train", "epochs": 7, "timestep": 13333, "ep_reward": 753.1886596679688, "reward": 0.6938154101371765, "action": -0.5258128643035889}
{"mode": "train", "epochs": 7, "timestep": 13334, "ep_reward": 753.7774658203125, "reward": 0.5887871384620667, "action": -0.9223661422729492}
{"mode": "train", "epochs": 7, "timestep": 13335, "ep_reward": 754.2138061523438, "reward": 0.43636101484298706, "action": -0.2507018446922302}
{"mode": "train", "epochs": 7, "timestep": 13336, "ep_reward": 754.5462036132812, "reward": 0.33239680528640747, "action": -0.94451504945755}
{"mode": "train", "epochs": 7, "timestep": 13337, "ep_reward": 754.76513671875, "reward": 0.21893352270126343, "action": -1.0654820203781128}
{"mode": "train", "epochs": 7, "timestep": 13338, "ep_reward": 754.8506469726562, "reward": 0.08551013469696045, "action": -0.8656690716743469}
{"mode": "train", "epochs": 7, "timestep": 13339, "ep_reward": 754.882568359375, "reward": 0.031927645206451416, "action": -1.9312551021575928}
{"mode": "train", "epochs": 7, "timestep": 13340, "ep_reward": 755.0553588867188, "reward": 0.1727951169013977, "action": -1.0869606733322144}
{"mode": "train", "epochs": 7, "timestep": 13341, "ep_reward": 755.366943359375, "reward": 0.31161075830459595, "action": -1.5497069358825684}
{"mode": "train", "epochs": 7, "timestep": 13342, "ep_reward": 755.8076171875, "reward": 0.4406871199607849, "action": -1.6350774765014648}
{"mode": "train", "epochs": 7, "timestep": 13343, "ep_reward": 756.364013671875, "reward": 0.5564045906066895, "action": -0.9699931144714355}
{"mode": "train", "epochs": 7, "timestep": 13344, "ep_reward": 757.02392578125, "reward": 0.6599020957946777, "action": -1.285990834236145}
{"mode": "train", "epochs": 7, "timestep": 13345, "ep_reward": 757.76025390625, "reward": 0.7363374829292297, "action": -1.0877503156661987}
{"mode": "train", "epochs": 7, "timestep": 13346, "ep_reward": 758.552001953125, "reward": 0.7917254567146301, "action": -1.9797744750976562}
{"mode": "train", "epochs": 7, "timestep": 13347, "ep_reward": 759.36962890625, "reward": 0.8176096081733704, "action": -1.72273588180542}
{"mode": "train", "epochs": 7, "timestep": 13348, "ep_reward": 760.1953125, "reward": 0.8256804943084717, "action": -1.7628425359725952}
{"mode": "train", "epochs": 7, "timestep": 13349, "ep_reward": 761.0071411132812, "reward": 0.8118047714233398, "action": -0.4964172840118408}
{"mode": "train", "epochs": 7, "timestep": 13350, "ep_reward": 761.7935180664062, "reward": 0.7863807082176208, "action": -0.8908082842826843}
{"mode": "train", "epochs": 7, "timestep": 13351, "ep_reward": 762.5222778320312, "reward": 0.7287549376487732, "action": -0.6933339834213257}
{"mode": "train", "epochs": 7, "timestep": 13352, "ep_reward": 763.1614379882812, "reward": 0.6391527652740479, "action": -1.5348336696624756}
{"mode": "train", "epochs": 7, "timestep": 13353, "ep_reward": 763.657958984375, "reward": 0.49652016162872314, "action": -0.7931219935417175}
{"mode": "train", "epochs": 7, "timestep": 13354, "ep_reward": 764.0361328125, "reward": 0.37818241119384766, "action": 0.10488808155059814}
{"mode": "train", "epochs": 7, "timestep": 13355, "ep_reward": 764.31005859375, "reward": 0.27391278743743896, "action": -1.1112093925476074}
{"mode": "train", "epochs": 7, "timestep": 13356, "ep_reward": 764.459716796875, "reward": 0.14962923526763916, "action": -1.6404727697372437}
{"mode": "train", "epochs": 7, "timestep": 13357, "ep_reward": 764.46533203125, "reward": 0.005597949028015137, "action": -0.349082887172699}
{"mode": "train", "epochs": 7, "timestep": 13358, "ep_reward": 764.575439453125, "reward": 0.11013597249984741, "action": -1.293900489807129}
{"mode": "train", "epochs": 7, "timestep": 13359, "ep_reward": 764.8203735351562, "reward": 0.24495965242385864, "action": -1.4348578453063965}
{"mode": "train", "epochs": 7, "timestep": 13360, "ep_reward": 765.199462890625, "reward": 0.37906813621520996, "action": -0.7707844972610474}
{"mode": "train", "epochs": 7, "timestep": 13361, "ep_reward": 765.7118530273438, "reward": 0.5123687386512756, "action": -0.4835405945777893}
{"mode": "train", "epochs": 7, "timestep": 13362, "ep_reward": 766.3414306640625, "reward": 0.629594624042511, "action": -0.9858883023262024}
{"mode": "train", "epochs": 7, "timestep": 13363, "ep_reward": 767.059326171875, "reward": 0.717910885810852, "action": -1.1438413858413696}
{"mode": "train", "epochs": 7, "timestep": 13364, "ep_reward": 767.8416137695312, "reward": 0.7822660207748413, "action": -0.6642292141914368}
{"mode": "train", "epochs": 7, "timestep": 13365, "ep_reward": 768.671875, "reward": 0.8302647471427917, "action": -0.7174216508865356}
{"mode": "train", "epochs": 7, "timestep": 13366, "ep_reward": 769.531005859375, "reward": 0.859107494354248, "action": -0.5491222739219666}
{"mode": "train", "epochs": 7, "timestep": 13367, "ep_reward": 770.4036865234375, "reward": 0.8727058172225952, "action": -1.0738980770111084}
{"mode": "train", "epochs": 7, "timestep": 13368, "ep_reward": 771.2697143554688, "reward": 0.8660327196121216, "action": -0.6370912790298462}
{"mode": "train", "epochs": 7, "timestep": 13369, "ep_reward": 772.1154174804688, "reward": 0.8457202911376953, "action": -0.5418331623077393}
{"mode": "train", "epochs": 7, "timestep": 13370, "ep_reward": 772.92138671875, "reward": 0.8059680461883545, "action": -0.9901494383811951}
{"mode": "train", "epochs": 7, "timestep": 13371, "ep_reward": 773.6574096679688, "reward": 0.7360395789146423, "action": -1.1833879947662354}
{"mode": "train", "epochs": 7, "timestep": 13372, "ep_reward": 774.287841796875, "reward": 0.630413830280304, "action": -1.5008080005645752}
{"mode": "train", "epochs": 7, "timestep": 13373, "ep_reward": 774.7674560546875, "reward": 0.47962772846221924, "action": -0.832787275314331}
{"mode": "train", "epochs": 7, "timestep": 13374, "ep_reward": 775.10693359375, "reward": 0.33946818113327026, "action": -0.9374105930328369}
{"mode": "train", "epochs": 7, "timestep": 13375, "ep_reward": 775.3343505859375, "reward": 0.22739577293395996, "action": -0.940814197063446}
{"mode": "train", "epochs": 7, "timestep": 13376, "ep_reward": 775.4295654296875, "reward": 0.09521293640136719, "action": -1.6335067749023438}
{"mode": "train", "epochs": 7, "timestep": 13377, "ep_reward": 775.4512939453125, "reward": 0.021705567836761475, "action": -0.7816774249076843}
{"mode": "train", "epochs": 7, "timestep": 13378, "ep_reward": 775.6151123046875, "reward": 0.16378915309906006, "action": -0.7897148132324219}
{"mode": "train", "epochs": 7, "timestep": 13379, "ep_reward": 775.92138671875, "reward": 0.30625706911087036, "action": -0.384326696395874}
{"mode": "train", "epochs": 7, "timestep": 13380, "ep_reward": 776.3704833984375, "reward": 0.4491155743598938, "action": 0.2227996587753296}
{"mode": "train", "epochs": 7, "timestep": 13381, "ep_reward": 776.9535522460938, "reward": 0.5830528736114502, "action": -1.492343783378601}
{"mode": "train", "epochs": 7, "timestep": 13382, "ep_reward": 777.6305541992188, "reward": 0.6770080327987671, "action": -0.3210288882255554}
{"mode": "train", "epochs": 7, "timestep": 13383, "ep_reward": 778.3920288085938, "reward": 0.7614630460739136, "action": -1.7438470125198364}
{"mode": "train", "epochs": 7, "timestep": 13384, "ep_reward": 779.2045288085938, "reward": 0.8125030398368835, "action": 0.06287288665771484}
{"mode": "train", "epochs": 7, "timestep": 13385, "ep_reward": 780.0654296875, "reward": 0.8609187602996826, "action": -0.502265214920044}
{"mode": "train", "epochs": 7, "timestep": 13386, "ep_reward": 780.9539184570312, "reward": 0.8884628415107727, "action": -0.671762228012085}
{"mode": "train", "epochs": 7, "timestep": 13387, "ep_reward": 781.8554077148438, "reward": 0.901495099067688, "action": -1.1376968622207642}
{"mode": "train", "epochs": 7, "timestep": 13388, "ep_reward": 782.7545166015625, "reward": 0.899081289768219, "action": -0.16054129600524902}
{"mode": "train", "epochs": 7, "timestep": 13389, "ep_reward": 783.6455688476562, "reward": 0.8910611271858215, "action": -1.4725604057312012}
{"mode": "train", "epochs": 7, "timestep": 13390, "ep_reward": 784.50341796875, "reward": 0.8578448295593262, "action": -1.2553342580795288}
{"mode": "train", "epochs": 7, "timestep": 13391, "ep_reward": 785.309326171875, "reward": 0.8059098720550537, "action": 0.64990234375}
{"mode": "train", "epochs": 7, "timestep": 13392, "ep_reward": 786.0580444335938, "reward": 0.7487277984619141, "action": -1.0651307106018066}
{"mode": "train", "epochs": 7, "timestep": 13393, "ep_reward": 786.7022705078125, "reward": 0.644223690032959, "action": -1.4117207527160645}
{"mode": "train", "epochs": 7, "timestep": 13394, "ep_reward": 787.199462890625, "reward": 0.49719351530075073, "action": -0.7437838315963745}
{"mode": "train", "epochs": 7, "timestep": 13395, "ep_reward": 787.52587890625, "reward": 0.3263988494873047, "action": -1.4727818965911865}
{"mode": "train", "epochs": 7, "timestep": 13396, "ep_reward": 787.7377319335938, "reward": 0.21187257766723633, "action": -1.1014976501464844}
{"mode": "train", "epochs": 7, "timestep": 13397, "ep_reward": 787.8150634765625, "reward": 0.07735002040863037, "action": -0.45636892318725586}
{"mode": "train", "epochs": 7, "timestep": 13398, "ep_reward": 787.8557739257812, "reward": 0.040698349475860596, "action": -0.27497947216033936}
{"mode": "train", "epochs": 7, "timestep": 13399, "ep_reward": 788.041748046875, "reward": 0.18596595525741577, "action": -1.893235206604004}
{"mode": "train", "epochs": 7, "timestep": 13400, "ep_reward": 788.35546875, "reward": 0.3137279152870178, "action": -1.787179708480835}
{"mode": "train", "epochs": 7, "timestep": 13401, "ep_reward": 788.7959594726562, "reward": 0.440484881401062, "action": -0.4642931818962097}
{"mode": "train", "epochs": 7, "timestep": 13402, "ep_reward": 789.3658447265625, "reward": 0.569915771484375, "action": -0.8953179121017456}
{"mode": "train", "epochs": 7, "timestep": 13403, "ep_reward": 790.0375366210938, "reward": 0.6716768741607666, "action": -1.1399730443954468}
{"mode": "train", "epochs": 7, "timestep": 13404, "ep_reward": 790.7847900390625, "reward": 0.7472488880157471, "action": -1.730391263961792}
{"mode": "train", "epochs": 7, "timestep": 13405, "ep_reward": 791.5800170898438, "reward": 0.7952223420143127, "action": -1.2412675619125366}
{"mode": "train", "epochs": 7, "timestep": 13406, "ep_reward": 792.4075317382812, "reward": 0.8275160789489746, "action": -1.6694080829620361}
{"mode": "train", "epochs": 7, "timestep": 13407, "ep_reward": 793.2440185546875, "reward": 0.8364583253860474, "action": -1.3096771240234375}
{"mode": "train", "epochs": 7, "timestep": 13408, "ep_reward": 794.07275390625, "reward": 0.8287408947944641, "action": 0.3754626512527466}
{"mode": "train", "epochs": 7, "timestep": 13409, "ep_reward": 794.888671875, "reward": 0.8159297704696655, "action": -0.828194797039032}
{"mode": "train", "epochs": 7, "timestep": 13410, "ep_reward": 795.6556396484375, "reward": 0.7669770121574402, "action": -1.9201533794403076}
{"mode": "train", "epochs": 7, "timestep": 13411, "ep_reward": 796.3297729492188, "reward": 0.6741434335708618, "action": -0.5459140539169312}
{"mode": "train", "epochs": 7, "timestep": 13412, "ep_reward": 796.8886108398438, "reward": 0.5588301420211792, "action": -1.0804537534713745}
{"mode": "train", "epochs": 7, "timestep": 13413, "ep_reward": 797.2908325195312, "reward": 0.40222811698913574, "action": -1.4157536029815674}
{"mode": "train", "epochs": 7, "timestep": 13414, "ep_reward": 797.5940551757812, "reward": 0.3032194972038269, "action": -1.8787646293640137}
{"mode": "train", "epochs": 7, "timestep": 13415, "ep_reward": 797.7783813476562, "reward": 0.18435174226760864, "action": -1.6768014430999756}
{"mode": "train", "epochs": 7, "timestep": 13416, "ep_reward": 797.823974609375, "reward": 0.04560750722885132, "action": -0.35634690523147583}
{"mode": "train", "epochs": 7, "timestep": 13417, "ep_reward": 797.896484375, "reward": 0.07250702381134033, "action": -1.1734073162078857}
{"mode": "train", "epochs": 7, "timestep": 13418, "ep_reward": 798.1041259765625, "reward": 0.2076687216758728, "action": -1.639833927154541}
{"mode": "train", "epochs": 7, "timestep": 13419, "ep_reward": 798.4443359375, "reward": 0.3401864767074585, "action": -0.30934321880340576}
{"mode": "train", "epochs": 7, "timestep": 13420, "ep_reward": 798.9274291992188, "reward": 0.48307251930236816, "action": -1.044524908065796}
{"mode": "train", "epochs": 7, "timestep": 13421, "ep_reward": 799.5264892578125, "reward": 0.5990310311317444, "action": -1.1804265975952148}
{"mode": "train", "epochs": 7, "timestep": 13422, "ep_reward": 800.2183837890625, "reward": 0.6919109225273132, "action": -1.563922643661499}
{"mode": "train", "epochs": 7, "timestep": 13423, "ep_reward": 800.97705078125, "reward": 0.758639395236969, "action": -0.15990477800369263}
{"mode": "train", "epochs": 7, "timestep": 13424, "ep_reward": 801.7940063476562, "reward": 0.8169323205947876, "action": -1.1725633144378662}
{"mode": "train", "epochs": 7, "timestep": 13425, "ep_reward": 802.6397094726562, "reward": 0.8457052707672119, "action": -1.6596572399139404}
{"mode": "train", "epochs": 7, "timestep": 13426, "ep_reward": 803.4923706054688, "reward": 0.8526911735534668, "action": -1.2844151258468628}
{"mode": "train", "epochs": 7, "timestep": 13427, "ep_reward": 804.3372192382812, "reward": 0.8448519706726074, "action": -0.8950225114822388}
{"mode": "train", "epochs": 7, "timestep": 13428, "ep_reward": 805.1575317382812, "reward": 0.8202979564666748, "action": -1.1104172468185425}
{"mode": "train", "epochs": 7, "timestep": 13429, "ep_reward": 805.9269409179688, "reward": 0.7694215774536133, "action": -0.18630027770996094}
{"mode": "train", "epochs": 7, "timestep": 13430, "ep_reward": 806.626220703125, "reward": 0.699294924736023, "action": -1.2576344013214111}
{"mode": "train", "epochs": 7, "timestep": 13431, "ep_reward": 807.206787109375, "reward": 0.5805759429931641, "action": -1.0395392179489136}
{"mode": "train", "epochs": 7, "timestep": 13432, "ep_reward": 807.6286010742188, "reward": 0.42179757356643677, "action": -1.7847204208374023}
{"mode": "train", "epochs": 7, "timestep": 13433, "ep_reward": 807.9415283203125, "reward": 0.3129412531852722, "action": -0.7848054766654968}
{"mode": "train", "epochs": 7, "timestep": 13434, "ep_reward": 808.1373291015625, "reward": 0.1958305835723877, "action": -0.2013871669769287}
{"mode": "train", "epochs": 7, "timestep": 13435, "ep_reward": 808.1958618164062, "reward": 0.058525681495666504, "action": -1.6075612306594849}
{"mode": "train", "epochs": 7, "timestep": 13436, "ep_reward": 808.25537109375, "reward": 0.05952918529510498, "action": -1.600992202758789}
{"mode": "train", "epochs": 7, "timestep": 13437, "ep_reward": 808.4520874023438, "reward": 0.19669568538665771, "action": -0.23323488235473633}
{"mode": "train", "epochs": 7, "timestep": 13438, "ep_reward": 808.7984619140625, "reward": 0.3463994860649109, "action": -1.0163816213607788}
{"mode": "train", "epochs": 7, "timestep": 13439, "ep_reward": 809.2766723632812, "reward": 0.4782230854034424, "action": -1.1615487337112427}
{"mode": "train", "epochs": 7, "timestep": 13440, "ep_reward": 809.8700561523438, "reward": 0.5933771133422852, "action": -0.043637990951538086}
{"mode": "train", "epochs": 7, "timestep": 13441, "ep_reward": 810.5693359375, "reward": 0.6992691159248352, "action": -1.0209650993347168}
{"mode": "train", "epochs": 7, "timestep": 13442, "ep_reward": 811.3409423828125, "reward": 0.7716230750083923, "action": -1.511276125907898}
{"mode": "train", "epochs": 7, "timestep": 13443, "ep_reward": 812.16064453125, "reward": 0.8197292685508728, "action": -0.9195420145988464}
{"mode": "train", "epochs": 7, "timestep": 13444, "ep_reward": 813.0157470703125, "reward": 0.855101466178894, "action": -1.6597458124160767}
{"mode": "train", "epochs": 7, "timestep": 13445, "ep_reward": 813.8842163085938, "reward": 0.8684767484664917, "action": -0.6183991432189941}
{"mode": "train", "epochs": 7, "timestep": 13446, "ep_reward": 814.7590942382812, "reward": 0.8749027252197266, "action": -1.0957574844360352}
{"mode": "train", "epochs": 7, "timestep": 13447, "ep_reward": 815.6204223632812, "reward": 0.8613484501838684, "action": -1.0589934587478638}
{"mode": "train", "epochs": 7, "timestep": 13448, "ep_reward": 816.4498291015625, "reward": 0.8293790221214294, "action": -1.315512776374817}
{"mode": "train", "epochs": 7, "timestep": 13449, "ep_reward": 817.2210693359375, "reward": 0.7712371349334717, "action": -1.1012341976165771}
{"mode": "train", "epochs": 7, "timestep": 13450, "ep_reward": 817.90576171875, "reward": 0.6846751570701599, "action": -1.3618184328079224}
{"mode": "train", "epochs": 7, "timestep": 13451, "ep_reward": 818.4627075195312, "reward": 0.5569211840629578, "action": -0.5771003365516663}
{"mode": "train", "epochs": 7, "timestep": 13452, "ep_reward": 818.8609008789062, "reward": 0.3981892466545105, "action": -0.7707512378692627}
{"mode": "train", "epochs": 7, "timestep": 13453, "ep_reward": 819.1495361328125, "reward": 0.2886260747909546, "action": -1.3255568742752075}
{"mode": "train", "epochs": 7, "timestep": 13454, "ep_reward": 819.3165893554688, "reward": 0.16705209016799927, "action": -1.287724256515503}
{"mode": "train", "epochs": 7, "timestep": 13455, "ep_reward": 819.342041015625, "reward": 0.025476038455963135, "action": -1.2660033702850342}
{"mode": "train", "epochs": 7, "timestep": 13456, "ep_reward": 819.4337158203125, "reward": 0.0917016863822937, "action": -1.1699752807617188}
{"mode": "train", "epochs": 7, "timestep": 13457, "ep_reward": 819.6611328125, "reward": 0.22743314504623413, "action": -1.886777639389038}
{"mode": "train", "epochs": 7, "timestep": 13458, "ep_reward": 820.0174560546875, "reward": 0.3563331961631775, "action": -0.4418807029724121}
{"mode": "train", "epochs": 7, "timestep": 13459, "ep_reward": 820.5137329101562, "reward": 0.4962766766548157, "action": -1.1842848062515259}
{"mode": "train", "epochs": 7, "timestep": 13460, "ep_reward": 821.1224365234375, "reward": 0.608707070350647, "action": -0.5747466087341309}
{"mode": "train", "epochs": 7, "timestep": 13461, "ep_reward": 821.8278198242188, "reward": 0.7053704261779785, "action": -1.1155672073364258}
{"mode": "train", "epochs": 7, "timestep": 13462, "ep_reward": 822.6005249023438, "reward": 0.7726895213127136, "action": -1.5315767526626587}
{"mode": "train", "epochs": 7, "timestep": 13463, "ep_reward": 823.4156494140625, "reward": 0.8151125311851501, "action": -1.4233169555664062}
{"mode": "train", "epochs": 7, "timestep": 13464, "ep_reward": 824.2550048828125, "reward": 0.8393476605415344, "action": -1.9057912826538086}
{"mode": "train", "epochs": 7, "timestep": 13465, "ep_reward": 825.0957641601562, "reward": 0.8407731056213379, "action": -1.3928602933883667}
{"mode": "train", "epochs": 7, "timestep": 13466, "ep_reward": 825.922607421875, "reward": 0.8268640041351318, "action": -1.1974505186080933}
{"mode": "train", "epochs": 7, "timestep": 13467, "ep_reward": 826.7142944335938, "reward": 0.7917137145996094, "action": -1.1601134538650513}
{"mode": "train", "epochs": 7, "timestep": 13468, "ep_reward": 827.4429931640625, "reward": 0.7287241220474243, "action": -0.970685601234436}
{"mode": "train", "epochs": 7, "timestep": 13469, "ep_reward": 828.075927734375, "reward": 0.6329084634780884, "action": -1.7929151058197021}
{"mode": "train", "epochs": 7, "timestep": 13470, "ep_reward": 828.5590209960938, "reward": 0.48311716318130493, "action": -0.20723706483840942}
{"mode": "train", "epochs": 7, "timestep": 13471, "ep_reward": 828.9282836914062, "reward": 0.36926913261413574, "action": -0.44490230083465576}
{"mode": "train", "epochs": 7, "timestep": 13472, "ep_reward": 829.1914672851562, "reward": 0.26318812370300293, "action": -0.6791976690292358}
{"mode": "train", "epochs": 7, "timestep": 13473, "ep_reward": 829.32861328125, "reward": 0.1371370553970337, "action": -0.5053024888038635}
{"mode": "train", "epochs": 7, "timestep": 13474, "ep_reward": 829.319580078125, "reward": -0.00905454158782959, "action": -1.5189980268478394}
{"mode": "train", "epochs": 7, "timestep": 13475, "ep_reward": 829.4426879882812, "reward": 0.12309622764587402, "action": -1.56869637966156}
{"mode": "train", "epochs": 7, "timestep": 13476, "ep_reward": 829.6976318359375, "reward": 0.25496166944503784, "action": -0.35945284366607666}
{"mode": "train", "epochs": 7, "timestep": 13477, "ep_reward": 830.0999145507812, "reward": 0.40230345726013184, "action": -1.1880439519882202}
{"mode": "train", "epochs": 7, "timestep": 13478, "ep_reward": 830.6271362304688, "reward": 0.5271914005279541, "action": -1.7713513374328613}
{"mode": "train", "epochs": 7, "timestep": 13479, "ep_reward": 831.2550659179688, "reward": 0.6279547810554504, "action": -1.138049602508545}
{"mode": "train", "epochs": 7, "timestep": 13480, "ep_reward": 831.9696044921875, "reward": 0.7145203351974487, "action": -0.41044461727142334}
{"mode": "train", "epochs": 7, "timestep": 13481, "ep_reward": 832.7545776367188, "reward": 0.7849559783935547, "action": -0.46800947189331055}
{"mode": "train", "epochs": 7, "timestep": 13482, "ep_reward": 833.587158203125, "reward": 0.8325724601745605, "action": -1.217424750328064}
{"mode": "train", "epochs": 7, "timestep": 13483, "ep_reward": 834.4420776367188, "reward": 0.8549081087112427, "action": -1.145390272140503}
{"mode": "train", "epochs": 7, "timestep": 13484, "ep_reward": 835.3030395507812, "reward": 0.8609590530395508, "action": -0.5220891833305359}
{"mode": "train", "epochs": 7, "timestep": 13485, "ep_reward": 836.157958984375, "reward": 0.8549015522003174, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 13486, "ep_reward": 836.9736938476562, "reward": 0.8157554864883423, "action": -0.8657752275466919}
{"mode": "train", "epochs": 7, "timestep": 13487, "ep_reward": 837.73583984375, "reward": 0.7621370553970337, "action": -0.8037893772125244}
{"mode": "train", "epochs": 7, "timestep": 13488, "ep_reward": 838.4144897460938, "reward": 0.6786353588104248, "action": -0.47365158796310425}
{"mode": "train", "epochs": 7, "timestep": 13489, "ep_reward": 838.977294921875, "reward": 0.5628243684768677, "action": -0.9234649538993835}
{"mode": "train", "epochs": 7, "timestep": 13490, "ep_reward": 839.37744140625, "reward": 0.40013593435287476, "action": -0.48065823316574097}
{"mode": "train", "epochs": 7, "timestep": 13491, "ep_reward": 839.669921875, "reward": 0.29249584674835205, "action": -1.2653741836547852}
{"mode": "train", "epochs": 7, "timestep": 13492, "ep_reward": 839.8414916992188, "reward": 0.17157864570617676, "action": -1.449089765548706}
{"mode": "train", "epochs": 7, "timestep": 13493, "ep_reward": 839.8722534179688, "reward": 0.030778050422668457, "action": -0.8613470792770386}
{"mode": "train", "epochs": 7, "timestep": 13494, "ep_reward": 839.9590454101562, "reward": 0.08679163455963135, "action": -0.7565008401870728}
{"mode": "train", "epochs": 7, "timestep": 13495, "ep_reward": 840.186767578125, "reward": 0.227728009223938, "action": -0.5411906242370605}
{"mode": "train", "epochs": 7, "timestep": 13496, "ep_reward": 840.5588989257812, "reward": 0.3721590042114258, "action": -1.0312421321868896}
{"mode": "train", "epochs": 7, "timestep": 13497, "ep_reward": 841.0604248046875, "reward": 0.5015056133270264, "action": -0.09413492679595947}
{"mode": "train", "epochs": 7, "timestep": 13498, "ep_reward": 841.6846923828125, "reward": 0.6242939233779907, "action": -0.901545524597168}
{"mode": "train", "epochs": 7, "timestep": 13499, "ep_reward": 842.400146484375, "reward": 0.7154368162155151, "action": -1.6978318691253662}
{"mode": "train", "epochs": 7, "timestep": 13500, "ep_reward": 843.1783447265625, "reward": 0.778203010559082, "action": 0.03253757953643799}
{"mode": "train", "epochs": 7, "timestep": 13501, "ep_reward": 844.0149536132812, "reward": 0.8366358280181885, "action": -1.3829739093780518}
{"mode": "train", "epochs": 7, "timestep": 13502, "ep_reward": 844.8802490234375, "reward": 0.8653136491775513, "action": -1.4874277114868164}
{"mode": "train", "epochs": 7, "timestep": 13503, "ep_reward": 845.7587890625, "reward": 0.8785516023635864, "action": -1.160214900970459}
{"mode": "train", "epochs": 7, "timestep": 13504, "ep_reward": 846.638671875, "reward": 0.8798967599868774, "action": -1.5681082010269165}
{"mode": "train", "epochs": 7, "timestep": 13505, "ep_reward": 847.5010986328125, "reward": 0.8623998165130615, "action": -0.7156659364700317}
{"mode": "train", "epochs": 7, "timestep": 13506, "ep_reward": 848.3348388671875, "reward": 0.8337506055831909, "action": -0.9857648611068726}
{"mode": "train", "epochs": 7, "timestep": 13507, "ep_reward": 849.1149291992188, "reward": 0.780109167098999, "action": -0.815031111240387}
{"mode": "train", "epochs": 7, "timestep": 13508, "ep_reward": 849.8143920898438, "reward": 0.6994348168373108, "action": -1.6324834823608398}
{"mode": "train", "epochs": 7, "timestep": 13509, "ep_reward": 850.38671875, "reward": 0.5723525285720825, "action": 0.2694464921951294}
{"mode": "train", "epochs": 7, "timestep": 13510, "ep_reward": 850.8182373046875, "reward": 0.4315122365951538, "action": 0.25879132747650146}
{"mode": "train", "epochs": 7, "timestep": 13511, "ep_reward": 851.1166381835938, "reward": 0.29840171337127686, "action": -0.8883997797966003}
{"mode": "train", "epochs": 7, "timestep": 13512, "ep_reward": 851.2952270507812, "reward": 0.1785663366317749, "action": -0.9785367846488953}
{"mode": "train", "epochs": 7, "timestep": 13513, "ep_reward": 851.333984375, "reward": 0.03877723217010498, "action": -0.6269762516021729}
{"mode": "train", "epochs": 7, "timestep": 13514, "ep_reward": 851.4131469726562, "reward": 0.07916861772537231, "action": -0.6830012798309326}
{"mode": "train", "epochs": 7, "timestep": 13515, "ep_reward": 851.6337890625, "reward": 0.22064584493637085, "action": -1.5891716480255127}
{"mode": "train", "epochs": 7, "timestep": 13516, "ep_reward": 851.9860229492188, "reward": 0.3522394299507141, "action": -1.8097537755966187}
{"mode": "train", "epochs": 7, "timestep": 13517, "ep_reward": 852.46142578125, "reward": 0.4754285216331482, "action": -1.3541172742843628}
{"mode": "train", "epochs": 7, "timestep": 13518, "ep_reward": 853.05078125, "reward": 0.5893394947052002, "action": -1.3195420503616333}
{"mode": "train", "epochs": 7, "timestep": 13519, "ep_reward": 853.7327270507812, "reward": 0.6819676160812378, "action": -1.561680555343628}
{"mode": "train", "epochs": 7, "timestep": 13520, "ep_reward": 854.4815063476562, "reward": 0.7487919330596924, "action": -0.6694322228431702}
{"mode": "train", "epochs": 7, "timestep": 13521, "ep_reward": 855.2830810546875, "reward": 0.8015568256378174, "action": -1.1625844240188599}
{"mode": "train", "epochs": 7, "timestep": 13522, "ep_reward": 856.1110229492188, "reward": 0.8279517889022827, "action": -0.8192965984344482}
{"mode": "train", "epochs": 7, "timestep": 13523, "ep_reward": 856.9484252929688, "reward": 0.8373963236808777, "action": -1.0172473192214966}
{"mode": "train", "epochs": 7, "timestep": 13524, "ep_reward": 857.7728271484375, "reward": 0.8244208097457886, "action": -1.1038349866867065}
{"mode": "train", "epochs": 7, "timestep": 13525, "ep_reward": 858.5601196289062, "reward": 0.7872718572616577, "action": -0.942907452583313}
{"mode": "train", "epochs": 7, "timestep": 13526, "ep_reward": 859.2835083007812, "reward": 0.723372220993042, "action": -1.173722505569458}
{"mode": "train", "epochs": 7, "timestep": 13527, "ep_reward": 859.9049682617188, "reward": 0.6214325428009033, "action": -0.04835432767868042}
{"mode": "train", "epochs": 7, "timestep": 13528, "ep_reward": 860.3993530273438, "reward": 0.49437224864959717, "action": -0.6795819997787476}
{"mode": "train", "epochs": 7, "timestep": 13529, "ep_reward": 860.7611694335938, "reward": 0.3618176579475403, "action": -1.8753503561019897}
{"mode": "train", "epochs": 7, "timestep": 13530, "ep_reward": 861.0155029296875, "reward": 0.2543209195137024, "action": -1.5775771141052246}
{"mode": "train", "epochs": 7, "timestep": 13531, "ep_reward": 861.142333984375, "reward": 0.12685304880142212, "action": -1.004052996635437}
{"mode": "train", "epochs": 7, "timestep": 13532, "ep_reward": 861.1292114257812, "reward": -0.013141512870788574, "action": -1.080673098564148}
{"mode": "train", "epochs": 7, "timestep": 13533, "ep_reward": 861.2626953125, "reward": 0.13347023725509644, "action": -0.9507833123207092}
{"mode": "train", "epochs": 7, "timestep": 13534, "ep_reward": 861.5359497070312, "reward": 0.2732818126678467, "action": -0.5362551808357239}
{"mode": "train", "epochs": 7, "timestep": 13535, "ep_reward": 861.9523315429688, "reward": 0.41639190912246704, "action": -0.6881474852561951}
{"mode": "train", "epochs": 7, "timestep": 13536, "ep_reward": 862.4972534179688, "reward": 0.5449069738388062, "action": -1.2866692543029785}
{"mode": "train", "epochs": 7, "timestep": 13537, "ep_reward": 863.1448974609375, "reward": 0.6476743221282959, "action": -1.544746994972229}
{"mode": "train", "epochs": 7, "timestep": 13538, "ep_reward": 863.8718872070312, "reward": 0.7270060777664185, "action": -1.129880666732788}
{"mode": "train", "epochs": 7, "timestep": 13539, "ep_reward": 864.6611328125, "reward": 0.7892243266105652, "action": -1.5325071811676025}
{"mode": "train", "epochs": 7, "timestep": 13540, "ep_reward": 865.4890747070312, "reward": 0.82793128490448, "action": -1.3025885820388794}
{"mode": "train", "epochs": 7, "timestep": 13541, "ep_reward": 866.3397216796875, "reward": 0.8506722450256348, "action": -1.2961561679840088}
{"mode": "train", "epochs": 7, "timestep": 13542, "ep_reward": 867.1958618164062, "reward": 0.8561186194419861, "action": -1.1387981176376343}
{"mode": "train", "epochs": 7, "timestep": 13543, "ep_reward": 868.040771484375, "reward": 0.8448889851570129, "action": -0.7589709758758545}
{"mode": "train", "epochs": 7, "timestep": 13544, "ep_reward": 868.8575439453125, "reward": 0.8167451620101929, "action": -1.2096836566925049}
{"mode": "train", "epochs": 7, "timestep": 13545, "ep_reward": 869.6168212890625, "reward": 0.7592670917510986, "action": -1.2645705938339233}
{"mode": "train", "epochs": 7, "timestep": 13546, "ep_reward": 870.2857666015625, "reward": 0.668947696685791, "action": -1.4102917909622192}
{"mode": "train", "epochs": 7, "timestep": 13547, "ep_reward": 870.8224487304688, "reward": 0.5366935729980469, "action": -0.990900456905365}
{"mode": "train", "epochs": 7, "timestep": 13548, "ep_reward": 871.2102661132812, "reward": 0.3878045678138733, "action": -1.5567967891693115}
{"mode": "train", "epochs": 7, "timestep": 13549, "ep_reward": 871.4960327148438, "reward": 0.28575217723846436, "action": -1.320917010307312}
{"mode": "train", "epochs": 7, "timestep": 13550, "ep_reward": 871.6597900390625, "reward": 0.16376221179962158, "action": 0.2820160388946533}
{"mode": "train", "epochs": 7, "timestep": 13551, "ep_reward": 871.6813354492188, "reward": 0.02152228355407715, "action": -1.5563616752624512}
{"mode": "train", "epochs": 7, "timestep": 13552, "ep_reward": 871.7767333984375, "reward": 0.09541547298431396, "action": -0.6904515027999878}
{"mode": "train", "epochs": 7, "timestep": 13553, "ep_reward": 872.0140380859375, "reward": 0.2373301386833191, "action": -1.339192271232605}
{"mode": "train", "epochs": 7, "timestep": 13554, "ep_reward": 872.3857421875, "reward": 0.3716813921928406, "action": -0.541982114315033}
{"mode": "train", "epochs": 7, "timestep": 13555, "ep_reward": 872.8931884765625, "reward": 0.507475733757019, "action": -1.4237669706344604}
{"mode": "train", "epochs": 7, "timestep": 13556, "ep_reward": 873.5084228515625, "reward": 0.6152503490447998, "action": -1.1745386123657227}
{"mode": "train", "epochs": 7, "timestep": 13557, "ep_reward": 874.2135009765625, "reward": 0.705062747001648, "action": -0.12435507774353027}
{"mode": "train", "epochs": 7, "timestep": 13558, "ep_reward": 874.9957885742188, "reward": 0.7822785973548889, "action": -0.28809672594070435}
{"mode": "train", "epochs": 7, "timestep": 13559, "ep_reward": 875.8312377929688, "reward": 0.8354697823524475, "action": -1.3634980916976929}
{"mode": "train", "epochs": 7, "timestep": 13560, "ep_reward": 876.6927490234375, "reward": 0.8614967465400696, "action": -1.5902726650238037}
{"mode": "train", "epochs": 7, "timestep": 13561, "ep_reward": 877.5630493164062, "reward": 0.8702991604804993, "action": -0.534476637840271}
{"mode": "train", "epochs": 7, "timestep": 13562, "ep_reward": 878.4351196289062, "reward": 0.8720563650131226, "action": -1.5855071544647217}
{"mode": "train", "epochs": 7, "timestep": 13563, "ep_reward": 879.283203125, "reward": 0.8480992317199707, "action": -0.7115175724029541}
{"mode": "train", "epochs": 7, "timestep": 13564, "ep_reward": 880.0946655273438, "reward": 0.8114438652992249, "action": -0.5505445003509521}
{"mode": "train", "epochs": 7, "timestep": 13565, "ep_reward": 880.8464965820312, "reward": 0.751802384853363, "action": -0.5366363525390625}
{"mode": "train", "epochs": 7, "timestep": 13566, "ep_reward": 881.508544921875, "reward": 0.6620477437973022, "action": -0.8261746764183044}
{"mode": "train", "epochs": 7, "timestep": 13567, "ep_reward": 882.0406494140625, "reward": 0.5320910215377808, "action": -0.9975199103355408}
{"mode": "train", "epochs": 7, "timestep": 13568, "ep_reward": 882.4041748046875, "reward": 0.3635222315788269, "action": -1.0371479988098145}
{"mode": "train", "epochs": 7, "timestep": 13569, "ep_reward": 882.6604614257812, "reward": 0.25630414485931396, "action": -0.8289618492126465}
{"mode": "train", "epochs": 7, "timestep": 13570, "ep_reward": 882.78955078125, "reward": 0.12908262014389038, "action": -0.6038167476654053}
{"mode": "train", "epochs": 7, "timestep": 13571, "ep_reward": 882.7739868164062, "reward": -0.015570282936096191, "action": -0.25447821617126465}
{"mode": "train", "epochs": 7, "timestep": 13572, "ep_reward": 882.9053344726562, "reward": 0.13134139776229858, "action": -0.32006633281707764}
{"mode": "train", "epochs": 7, "timestep": 13573, "ep_reward": 883.1842041015625, "reward": 0.27889198064804077, "action": -0.5530329346656799}
{"mode": "train", "epochs": 7, "timestep": 13574, "ep_reward": 883.6044311523438, "reward": 0.4202275276184082, "action": -0.6506853103637695}
{"mode": "train", "epochs": 7, "timestep": 13575, "ep_reward": 884.1525268554688, "reward": 0.5480756759643555, "action": -0.8408282995223999}
{"mode": "train", "epochs": 7, "timestep": 13576, "ep_reward": 884.8071899414062, "reward": 0.6546465158462524, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 13577, "ep_reward": 885.5362548828125, "reward": 0.7290859222412109, "action": -1.0185365676879883}
{"mode": "train", "epochs": 7, "timestep": 13578, "ep_reward": 886.329345703125, "reward": 0.79311203956604, "action": -1.2210640907287598}
{"mode": "train", "epochs": 7, "timestep": 13579, "ep_reward": 887.1652221679688, "reward": 0.8358842134475708, "action": -1.0895732641220093}
{"mode": "train", "epochs": 7, "timestep": 13580, "ep_reward": 888.0278930664062, "reward": 0.8626550436019897, "action": -0.7305766940116882}
{"mode": "train", "epochs": 7, "timestep": 13581, "ep_reward": 888.9044799804688, "reward": 0.8765581846237183, "action": -1.0937411785125732}
{"mode": "train", "epochs": 7, "timestep": 13582, "ep_reward": 889.776611328125, "reward": 0.8721542954444885, "action": -1.4325463771820068}
{"mode": "train", "epochs": 7, "timestep": 13583, "ep_reward": 890.62451171875, "reward": 0.84787517786026, "action": -1.334986925125122}
{"mode": "train", "epochs": 7, "timestep": 13584, "ep_reward": 891.427734375, "reward": 0.8032052516937256, "action": -0.8512087464332581}
{"mode": "train", "epochs": 7, "timestep": 13585, "ep_reward": 892.1644897460938, "reward": 0.7367456555366516, "action": -0.6107181310653687}
{"mode": "train", "epochs": 7, "timestep": 13586, "ep_reward": 892.8052368164062, "reward": 0.6407442688941956, "action": -0.9213953018188477}
{"mode": "train", "epochs": 7, "timestep": 13587, "ep_reward": 893.3078002929688, "reward": 0.5025333166122437, "action": -1.0116862058639526}
{"mode": "train", "epochs": 7, "timestep": 13588, "ep_reward": 893.6580810546875, "reward": 0.350284218788147, "action": -1.1710761785507202}
{"mode": "train", "epochs": 7, "timestep": 13589, "ep_reward": 893.8983154296875, "reward": 0.24022388458251953, "action": -1.884223222732544}
{"mode": "train", "epochs": 7, "timestep": 13590, "ep_reward": 894.0088500976562, "reward": 0.1105145812034607, "action": -0.350955605506897}
{"mode": "train", "epochs": 7, "timestep": 13591, "ep_reward": 894.0140380859375, "reward": 0.005183696746826172, "action": -1.3361014127731323}
{"mode": "train", "epochs": 7, "timestep": 13592, "ep_reward": 894.1635131835938, "reward": 0.1494728922843933, "action": -0.9342052340507507}
{"mode": "train", "epochs": 7, "timestep": 13593, "ep_reward": 894.4531860351562, "reward": 0.28968238830566406, "action": -1.795820951461792}
{"mode": "train", "epochs": 7, "timestep": 13594, "ep_reward": 894.8699340820312, "reward": 0.41677290201187134, "action": -1.3068606853485107}
{"mode": "train", "epochs": 7, "timestep": 13595, "ep_reward": 895.4093017578125, "reward": 0.5393886566162109, "action": -0.9146761298179626}
{"mode": "train", "epochs": 7, "timestep": 13596, "ep_reward": 896.0562744140625, "reward": 0.6469734907150269, "action": -1.0976636409759521}
{"mode": "train", "epochs": 7, "timestep": 13597, "ep_reward": 896.785400390625, "reward": 0.729098916053772, "action": -0.9706287384033203}
{"mode": "train", "epochs": 7, "timestep": 13598, "ep_reward": 897.57470703125, "reward": 0.7893258333206177, "action": -1.9198646545410156}
{"mode": "train", "epochs": 7, "timestep": 13599, "ep_reward": 898.3945922851562, "reward": 0.8199089765548706, "action": -1.4148380756378174}
{"mode": "train", "epochs": 7, "timestep": 13600, "ep_reward": 899.2304077148438, "reward": 0.83580482006073, "action": -1.3194267749786377}
{"mode": "train", "epochs": 7, "timestep": 13601, "ep_reward": 900.0631103515625, "reward": 0.8327106833457947, "action": -1.6159096956253052}
{"mode": "train", "epochs": 7, "timestep": 13602, "ep_reward": 900.8678588867188, "reward": 0.8047599196434021, "action": -1.410830020904541}
{"mode": "train", "epochs": 7, "timestep": 13603, "ep_reward": 901.6199340820312, "reward": 0.752079427242279, "action": -0.41969674825668335}
{"mode": "train", "epochs": 7, "timestep": 13604, "ep_reward": 902.2985229492188, "reward": 0.6785985231399536, "action": -0.550422191619873}
{"mode": "train", "epochs": 7, "timestep": 13605, "ep_reward": 902.864990234375, "reward": 0.5664898753166199, "action": -0.7140495181083679}
{"mode": "train", "epochs": 7, "timestep": 13606, "ep_reward": 903.27587890625, "reward": 0.41091203689575195, "action": -1.711515188217163}
{"mode": "train", "epochs": 7, "timestep": 13607, "ep_reward": 903.5900268554688, "reward": 0.3141224980354309, "action": -0.8749244809150696}
{"mode": "train", "epochs": 7, "timestep": 13608, "ep_reward": 903.7872314453125, "reward": 0.1971820592880249, "action": -1.0132653713226318}
{"mode": "train", "epochs": 7, "timestep": 13609, "ep_reward": 903.8475341796875, "reward": 0.06028187274932861, "action": -0.8091301918029785}
{"mode": "train", "epochs": 7, "timestep": 13610, "ep_reward": 903.9055786132812, "reward": 0.05801403522491455, "action": -0.78878253698349}
{"mode": "train", "epochs": 7, "timestep": 13611, "ep_reward": 904.1031494140625, "reward": 0.19758641719818115, "action": -1.1983500719070435}
{"mode": "train", "epochs": 7, "timestep": 13612, "ep_reward": 904.4380493164062, "reward": 0.33490246534347534, "action": -1.2768642902374268}
{"mode": "train", "epochs": 7, "timestep": 13613, "ep_reward": 904.9036865234375, "reward": 0.4656604528427124, "action": -1.434491515159607}
{"mode": "train", "epochs": 7, "timestep": 13614, "ep_reward": 905.4837646484375, "reward": 0.580092191696167, "action": -0.21172082424163818}
{"mode": "train", "epochs": 7, "timestep": 13615, "ep_reward": 906.1705932617188, "reward": 0.6868278384208679, "action": -0.46911901235580444}
{"mode": "train", "epochs": 7, "timestep": 13616, "ep_reward": 906.936279296875, "reward": 0.7657070159912109, "action": -0.7763529419898987}
{"mode": "train", "epochs": 7, "timestep": 13617, "ep_reward": 907.755615234375, "reward": 0.8193628787994385, "action": -0.8497241735458374}
{"mode": "train", "epochs": 7, "timestep": 13618, "ep_reward": 908.60888671875, "reward": 0.8532663583755493, "action": -1.437705636024475}
{"mode": "train", "epochs": 7, "timestep": 13619, "ep_reward": 909.4745483398438, "reward": 0.865679144859314, "action": -0.9491313099861145}
{"mode": "train", "epochs": 7, "timestep": 13620, "ep_reward": 910.3406372070312, "reward": 0.8660755157470703, "action": -0.5154144763946533}
{"mode": "train", "epochs": 7, "timestep": 13621, "ep_reward": 911.1937866210938, "reward": 0.853154182434082, "action": -0.8574252128601074}
{"mode": "train", "epochs": 7, "timestep": 13622, "ep_reward": 912.0113525390625, "reward": 0.8175792694091797, "action": -1.6362943649291992}
{"mode": "train", "epochs": 7, "timestep": 13623, "ep_reward": 912.7603149414062, "reward": 0.7489482760429382, "action": -0.06840664148330688}
{"mode": "train", "epochs": 7, "timestep": 13624, "ep_reward": 913.4264526367188, "reward": 0.6661206483840942, "action": -1.2891526222229004}
{"mode": "train", "epochs": 7, "timestep": 13625, "ep_reward": 913.9578247070312, "reward": 0.5313498973846436, "action": -0.8923930525779724}
{"mode": "train", "epochs": 7, "timestep": 13626, "ep_reward": 914.3269653320312, "reward": 0.36912471055984497, "action": -1.3597850799560547}
{"mode": "train", "epochs": 7, "timestep": 13627, "ep_reward": 914.5901489257812, "reward": 0.26316606998443604, "action": -0.1327430009841919}
{"mode": "train", "epochs": 7, "timestep": 13628, "ep_reward": 914.7272338867188, "reward": 0.13705843687057495, "action": -0.7613182067871094}
{"mode": "train", "epochs": 7, "timestep": 13629, "ep_reward": 914.7182006835938, "reward": -0.009016275405883789, "action": -0.7895652055740356}
{"mode": "train", "epochs": 7, "timestep": 13630, "ep_reward": 914.8413696289062, "reward": 0.12316763401031494, "action": -1.5051686763763428}
{"mode": "train", "epochs": 7, "timestep": 13631, "ep_reward": 915.09716796875, "reward": 0.25579726696014404, "action": -0.7813008427619934}
{"mode": "train", "epochs": 7, "timestep": 13632, "ep_reward": 915.4950561523438, "reward": 0.39786916971206665, "action": -0.9795788526535034}
{"mode": "train", "epochs": 7, "timestep": 13633, "ep_reward": 916.021240234375, "reward": 0.5261808633804321, "action": -0.44258445501327515}
{"mode": "train", "epochs": 7, "timestep": 13634, "ep_reward": 916.66259765625, "reward": 0.6413695216178894, "action": -0.2550092935562134}
{"mode": "train", "epochs": 7, "timestep": 13635, "ep_reward": 917.3967895507812, "reward": 0.7341843843460083, "action": -1.5353782176971436}
{"mode": "train", "epochs": 7, "timestep": 13636, "ep_reward": 918.1888427734375, "reward": 0.792072057723999, "action": -1.4033799171447754}
{"mode": "train", "epochs": 7, "timestep": 13637, "ep_reward": 919.0210571289062, "reward": 0.8322073221206665, "action": -1.2430070638656616}
{"mode": "train", "epochs": 7, "timestep": 13638, "ep_reward": 919.8772583007812, "reward": 0.8561906218528748, "action": -1.270739197731018}
{"mode": "train", "epochs": 7, "timestep": 13639, "ep_reward": 920.7405395507812, "reward": 0.8633104562759399, "action": -1.3389384746551514}
{"mode": "train", "epochs": 7, "timestep": 13640, "ep_reward": 921.5932006835938, "reward": 0.8526450395584106, "action": -1.57986319065094}
{"mode": "train", "epochs": 7, "timestep": 13641, "ep_reward": 922.4130859375, "reward": 0.8198732137680054, "action": -0.8524904847145081}
{"mode": "train", "epochs": 7, "timestep": 13642, "ep_reward": 923.1825561523438, "reward": 0.7694981098175049, "action": -1.632620096206665}
{"mode": "train", "epochs": 7, "timestep": 13643, "ep_reward": 923.8619384765625, "reward": 0.6794127821922302, "action": -1.2677420377731323}
{"mode": "train", "epochs": 7, "timestep": 13644, "ep_reward": 924.4158935546875, "reward": 0.5539274215698242, "action": -0.942577064037323}
{"mode": "train", "epochs": 7, "timestep": 13645, "ep_reward": 924.814453125, "reward": 0.3985382914543152, "action": -1.4339182376861572}
{"mode": "train", "epochs": 7, "timestep": 13646, "ep_reward": 925.11328125, "reward": 0.2988241910934448, "action": -1.2896339893341064}
{"mode": "train", "epochs": 7, "timestep": 13647, "ep_reward": 925.2923583984375, "reward": 0.17909371852874756, "action": -1.2414460182189941}
{"mode": "train", "epochs": 7, "timestep": 13648, "ep_reward": 925.3316650390625, "reward": 0.039317309856414795, "action": -1.4718139171600342}
{"mode": "train", "epochs": 7, "timestep": 13649, "ep_reward": 925.41015625, "reward": 0.07847601175308228, "action": -1.2293757200241089}
{"mode": "train", "epochs": 7, "timestep": 13650, "ep_reward": 925.6234130859375, "reward": 0.2132350206375122, "action": -0.845413088798523}
{"mode": "train", "epochs": 7, "timestep": 13651, "ep_reward": 925.9788818359375, "reward": 0.3554760813713074, "action": -1.1158092021942139}
{"mode": "train", "epochs": 7, "timestep": 13652, "ep_reward": 926.4652099609375, "reward": 0.48634952306747437, "action": -1.3512396812438965}
{"mode": "train", "epochs": 7, "timestep": 13653, "ep_reward": 927.0635375976562, "reward": 0.5983344316482544, "action": -1.6521084308624268}
{"mode": "train", "epochs": 7, "timestep": 13654, "ep_reward": 927.75, "reward": 0.68644118309021, "action": -0.5409384965896606}
{"mode": "train", "epochs": 7, "timestep": 13655, "ep_reward": 928.51318359375, "reward": 0.7631866931915283, "action": -1.2072992324829102}
{"mode": "train", "epochs": 7, "timestep": 13656, "ep_reward": 929.3240356445312, "reward": 0.8108601570129395, "action": -0.2824002504348755}
{"mode": "train", "epochs": 7, "timestep": 13657, "ep_reward": 930.1709594726562, "reward": 0.8469133973121643, "action": -0.6316604018211365}
{"mode": "train", "epochs": 7, "timestep": 13658, "ep_reward": 931.032470703125, "reward": 0.8614979386329651, "action": -1.3281968832015991}
{"mode": "train", "epochs": 7, "timestep": 13659, "ep_reward": 931.88525390625, "reward": 0.8527830243110657, "action": 0.2812667489051819}
{"mode": "train", "epochs": 7, "timestep": 13660, "ep_reward": 932.7250366210938, "reward": 0.8397862911224365, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 13661, "ep_reward": 933.5083618164062, "reward": 0.7833444476127625, "action": -0.7305130958557129}
{"mode": "train", "epochs": 7, "timestep": 13662, "ep_reward": 934.2188720703125, "reward": 0.7104816436767578, "action": -0.9099766612052917}
{"mode": "train", "epochs": 7, "timestep": 13663, "ep_reward": 934.8195190429688, "reward": 0.6006588935852051, "action": -0.13546061515808105}
{"mode": "train", "epochs": 7, "timestep": 13664, "ep_reward": 935.2817993164062, "reward": 0.462283194065094, "action": -0.5913739204406738}
{"mode": "train", "epochs": 7, "timestep": 13665, "ep_reward": 935.6075439453125, "reward": 0.32576578855514526, "action": -0.3859800696372986}
{"mode": "train", "epochs": 7, "timestep": 13666, "ep_reward": 935.8184204101562, "reward": 0.21089380979537964, "action": -1.5501389503479004}
{"mode": "train", "epochs": 7, "timestep": 13667, "ep_reward": 935.8947143554688, "reward": 0.07629328966140747, "action": -0.5686995387077332}
{"mode": "train", "epochs": 7, "timestep": 13668, "ep_reward": 935.9365234375, "reward": 0.04177922010421753, "action": -0.3691936731338501}
{"mode": "train", "epochs": 7, "timestep": 13669, "ep_reward": 936.1226196289062, "reward": 0.18610042333602905, "action": -0.7991242408752441}
{"mode": "train", "epochs": 7, "timestep": 13670, "ep_reward": 936.4502563476562, "reward": 0.32763582468032837, "action": -1.1880725622177124}
{"mode": "train", "epochs": 7, "timestep": 13671, "ep_reward": 936.9092407226562, "reward": 0.45895594358444214, "action": -1.3644400835037231}
{"mode": "train", "epochs": 7, "timestep": 13672, "ep_reward": 937.4839477539062, "reward": 0.5747327208518982, "action": -0.7430058121681213}
{"mode": "train", "epochs": 7, "timestep": 13673, "ep_reward": 938.161376953125, "reward": 0.6774271726608276, "action": -0.7735660076141357}
{"mode": "train", "epochs": 7, "timestep": 13674, "ep_reward": 938.9178466796875, "reward": 0.756497859954834, "action": -0.781542181968689}
{"mode": "train", "epochs": 7, "timestep": 13675, "ep_reward": 939.7314453125, "reward": 0.8135867118835449, "action": -0.5999581813812256}
{"mode": "train", "epochs": 7, "timestep": 13676, "ep_reward": 940.5842895507812, "reward": 0.852853536605835, "action": -1.0450290441513062}
{"mode": "train", "epochs": 7, "timestep": 13677, "ep_reward": 941.4560546875, "reward": 0.8717764019966125, "action": -0.606662392616272}
{"mode": "train", "epochs": 7, "timestep": 13678, "ep_reward": 942.3350219726562, "reward": 0.8789505362510681, "action": -1.236914038658142}
{"mode": "train", "epochs": 7, "timestep": 13679, "ep_reward": 943.2003784179688, "reward": 0.8653755187988281, "action": -1.6748583316802979}
{"mode": "train", "epochs": 7, "timestep": 13680, "ep_reward": 944.029541015625, "reward": 0.8291884064674377, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 13681, "ep_reward": 944.7943115234375, "reward": 0.764762282371521, "action": -0.7308337688446045}
{"mode": "train", "epochs": 7, "timestep": 13682, "ep_reward": 945.4763793945312, "reward": 0.682079553604126, "action": -1.9498016834259033}
{"mode": "train", "epochs": 7, "timestep": 13683, "ep_reward": 946.0218505859375, "reward": 0.5454838871955872, "action": -0.9518232941627502}
{"mode": "train", "epochs": 7, "timestep": 13684, "ep_reward": 946.4116821289062, "reward": 0.3898027539253235, "action": -1.4017970561981201}
{"mode": "train", "epochs": 7, "timestep": 13685, "ep_reward": 946.6998291015625, "reward": 0.2881205677986145, "action": -1.490837812423706}
{"mode": "train", "epochs": 7, "timestep": 13686, "ep_reward": 946.8663330078125, "reward": 0.1665305495262146, "action": -1.0077418088912964}
{"mode": "train", "epochs": 7, "timestep": 13687, "ep_reward": 946.8911743164062, "reward": 0.024836480617523193, "action": -1.2175984382629395}
{"mode": "train", "epochs": 7, "timestep": 13688, "ep_reward": 946.9835815429688, "reward": 0.0923951268196106, "action": -0.08289045095443726}
{"mode": "train", "epochs": 7, "timestep": 13689, "ep_reward": 947.225341796875, "reward": 0.24176174402236938, "action": -1.1129456758499146}
{"mode": "train", "epochs": 7, "timestep": 13690, "ep_reward": 947.602783203125, "reward": 0.3774217367172241, "action": -0.5728602409362793}
{"mode": "train", "epochs": 7, "timestep": 13691, "ep_reward": 948.1140747070312, "reward": 0.5112675428390503, "action": -0.48158448934555054}
{"mode": "train", "epochs": 7, "timestep": 13692, "ep_reward": 948.7421875, "reward": 0.6280829906463623, "action": -0.9977664947509766}
{"mode": "train", "epochs": 7, "timestep": 13693, "ep_reward": 949.4598999023438, "reward": 0.7177299857139587, "action": -0.9020097255706787}
{"mode": "train", "epochs": 7, "timestep": 13694, "ep_reward": 950.2468872070312, "reward": 0.7869828343391418, "action": -1.4885096549987793}
{"mode": "train", "epochs": 7, "timestep": 13695, "ep_reward": 951.0789794921875, "reward": 0.8320647478103638, "action": -0.6009929180145264}
{"mode": "train", "epochs": 7, "timestep": 13696, "ep_reward": 951.9465942382812, "reward": 0.8676073551177979, "action": -1.2039473056793213}
{"mode": "train", "epochs": 7, "timestep": 13697, "ep_reward": 952.8298950195312, "reward": 0.8833238482475281, "action": -1.3379826545715332}
{"mode": "train", "epochs": 7, "timestep": 13698, "ep_reward": 953.7139892578125, "reward": 0.8840982913970947, "action": -1.4833049774169922}
{"mode": "train", "epochs": 7, "timestep": 13699, "ep_reward": 954.582763671875, "reward": 0.8687711954116821, "action": -1.0543181896209717}
{"mode": "train", "epochs": 7, "timestep": 13700, "ep_reward": 955.4217529296875, "reward": 0.8390124440193176, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 13701, "ep_reward": 956.198974609375, "reward": 0.7772067189216614, "action": -1.059972882270813}
{"mode": "train", "epochs": 7, "timestep": 13702, "ep_reward": 956.893310546875, "reward": 0.6943367719650269, "action": -0.5369826555252075}
{"mode": "train", "epochs": 7, "timestep": 13703, "ep_reward": 957.4754638671875, "reward": 0.5821787118911743, "action": -0.1892775297164917}
{"mode": "train", "epochs": 7, "timestep": 13704, "ep_reward": 957.9120483398438, "reward": 0.43656837940216064, "action": -1.3604991436004639}
{"mode": "train", "epochs": 7, "timestep": 13705, "ep_reward": 958.2158203125, "reward": 0.30379289388656616, "action": -1.0851327180862427}
{"mode": "train", "epochs": 7, "timestep": 13706, "ep_reward": 958.4007568359375, "reward": 0.18494880199432373, "action": -1.1545015573501587}
{"mode": "train", "epochs": 7, "timestep": 13707, "ep_reward": 958.4469604492188, "reward": 0.046194374561309814, "action": -0.251906156539917}
{"mode": "train", "epochs": 7, "timestep": 13708, "ep_reward": 958.5188598632812, "reward": 0.07187670469284058, "action": -1.536269187927246}
{"mode": "train", "epochs": 7, "timestep": 13709, "ep_reward": 958.7261352539062, "reward": 0.20724564790725708, "action": -1.2685692310333252}
{"mode": "train", "epochs": 7, "timestep": 13710, "ep_reward": 959.0704956054688, "reward": 0.3443618416786194, "action": -0.3639072775840759}
{"mode": "train", "epochs": 7, "timestep": 13711, "ep_reward": 959.55615234375, "reward": 0.4856337904930115, "action": -1.2593533992767334}
{"mode": "train", "epochs": 7, "timestep": 13712, "ep_reward": 960.1549682617188, "reward": 0.5988125801086426, "action": -0.3352953791618347}
{"mode": "train", "epochs": 7, "timestep": 13713, "ep_reward": 960.855224609375, "reward": 0.7002531290054321, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 13714, "ep_reward": 961.6173706054688, "reward": 0.7621763944625854, "action": -0.5473332405090332}
{"mode": "train", "epochs": 7, "timestep": 13715, "ep_reward": 962.4346923828125, "reward": 0.8173375725746155, "action": -1.1467313766479492}
{"mode": "train", "epochs": 7, "timestep": 13716, "ep_reward": 963.2822875976562, "reward": 0.8475959300994873, "action": -0.8383300304412842}
{"mode": "train", "epochs": 7, "timestep": 13717, "ep_reward": 964.1455078125, "reward": 0.863221287727356, "action": -0.7458429336547852}
{"mode": "train", "epochs": 7, "timestep": 13718, "ep_reward": 965.0084228515625, "reward": 0.8628972768783569, "action": -0.6337690353393555}
{"mode": "train", "epochs": 7, "timestep": 13719, "ep_reward": 965.8543090820312, "reward": 0.8458788990974426, "action": -1.3536605834960938}
{"mode": "train", "epochs": 7, "timestep": 13720, "ep_reward": 966.6555786132812, "reward": 0.8012739419937134, "action": -0.804456889629364}
{"mode": "train", "epochs": 7, "timestep": 13721, "ep_reward": 967.3909912109375, "reward": 0.7354100346565247, "action": -0.31426000595092773}
{"mode": "train", "epochs": 7, "timestep": 13722, "ep_reward": 968.0342407226562, "reward": 0.6432563066482544, "action": -1.2454930543899536}
{"mode": "train", "epochs": 7, "timestep": 13723, "ep_reward": 968.5352172851562, "reward": 0.5009946227073669, "action": -0.704833984375}
{"mode": "train", "epochs": 7, "timestep": 13724, "ep_reward": 968.8865356445312, "reward": 0.3512887954711914, "action": -1.4094020128250122}
{"mode": "train", "epochs": 7, "timestep": 13725, "ep_reward": 969.1280517578125, "reward": 0.2415320873260498, "action": -1.6282958984375}
{"mode": "train", "epochs": 7, "timestep": 13726, "ep_reward": 969.2398681640625, "reward": 0.1118273138999939, "action": -1.5791730880737305}
{"mode": "train", "epochs": 7, "timestep": 13727, "ep_reward": 969.2435302734375, "reward": 0.0036736130714416504, "action": -0.5769485235214233}
{"mode": "train", "epochs": 7, "timestep": 13728, "ep_reward": 969.3916625976562, "reward": 0.14811640977859497, "action": -0.6673775911331177}
{"mode": "train", "epochs": 7, "timestep": 13729, "ep_reward": 969.6834106445312, "reward": 0.29174184799194336, "action": -0.9166709780693054}
{"mode": "train", "epochs": 7, "timestep": 13730, "ep_reward": 970.1121826171875, "reward": 0.4287909269332886, "action": -1.1444791555404663}
{"mode": "train", "epochs": 7, "timestep": 13731, "ep_reward": 970.6630249023438, "reward": 0.5508636236190796, "action": -0.8264772891998291}
{"mode": "train", "epochs": 7, "timestep": 13732, "ep_reward": 971.3204956054688, "reward": 0.6574499607086182, "action": 0.05322682857513428}
{"mode": "train", "epochs": 7, "timestep": 13733, "ep_reward": 972.0699462890625, "reward": 0.7494232058525085, "action": -1.535718321800232}
{"mode": "train", "epochs": 7, "timestep": 13734, "ep_reward": 972.8740234375, "reward": 0.8040696382522583, "action": -0.5200330018997192}
{"mode": "train", "epochs": 7, "timestep": 13735, "ep_reward": 973.722900390625, "reward": 0.8488469123840332, "action": -1.599631905555725}
{"mode": "train", "epochs": 7, "timestep": 13736, "ep_reward": 974.591064453125, "reward": 0.8681886792182922, "action": -1.1970912218093872}
{"mode": "train", "epochs": 7, "timestep": 13737, "ep_reward": 975.4668579101562, "reward": 0.8757671117782593, "action": -1.069229245185852}
{"mode": "train", "epochs": 7, "timestep": 13738, "ep_reward": 976.3358764648438, "reward": 0.8690013289451599, "action": 0.059307754039764404}
{"mode": "train", "epochs": 7, "timestep": 13739, "ep_reward": 977.1911010742188, "reward": 0.8552318215370178, "action": -0.5322449207305908}
{"mode": "train", "epochs": 7, "timestep": 13740, "ep_reward": 978.008544921875, "reward": 0.8174204230308533, "action": -1.0071402788162231}
{"mode": "train", "epochs": 7, "timestep": 13741, "ep_reward": 978.7591552734375, "reward": 0.7505995035171509, "action": -1.4196343421936035}
{"mode": "train", "epochs": 7, "timestep": 13742, "ep_reward": 979.4059448242188, "reward": 0.6468147039413452, "action": -0.4779878854751587}
{"mode": "train", "epochs": 7, "timestep": 13743, "ep_reward": 979.9225463867188, "reward": 0.5165802240371704, "action": -1.246024489402771}
{"mode": "train", "epochs": 7, "timestep": 13744, "ep_reward": 980.2734375, "reward": 0.35091930627822876, "action": -0.5271930694580078}
{"mode": "train", "epochs": 7, "timestep": 13745, "ep_reward": 980.5145263671875, "reward": 0.24109399318695068, "action": -0.6041349172592163}
{"mode": "train", "epochs": 7, "timestep": 13746, "ep_reward": 980.625732421875, "reward": 0.11122530698776245, "action": -1.052490472793579}
{"mode": "train", "epochs": 7, "timestep": 13747, "ep_reward": 980.630126953125, "reward": 0.00439983606338501, "action": -0.9401971101760864}
{"mode": "train", "epochs": 7, "timestep": 13748, "ep_reward": 980.7789306640625, "reward": 0.14878427982330322, "action": -0.5936530828475952}
{"mode": "train", "epochs": 7, "timestep": 13749, "ep_reward": 981.072265625, "reward": 0.29334694147109985, "action": -0.8095037937164307}
{"mode": "train", "epochs": 7, "timestep": 13750, "ep_reward": 981.503662109375, "reward": 0.4314247965812683, "action": -1.232519507408142}
{"mode": "train", "epochs": 7, "timestep": 13751, "ep_reward": 982.0557250976562, "reward": 0.5520343780517578, "action": -0.8758900761604309}
{"mode": "train", "epochs": 7, "timestep": 13752, "ep_reward": 982.713623046875, "reward": 0.6578800082206726, "action": -0.4729233980178833}
{"mode": "train", "epochs": 7, "timestep": 13753, "ep_reward": 983.4586181640625, "reward": 0.7449963688850403, "action": -0.6607332229614258}
{"mode": "train", "epochs": 7, "timestep": 13754, "ep_reward": 984.2662963867188, "reward": 0.8077014684677124, "action": -1.2625699043273926}
{"mode": "train", "epochs": 7, "timestep": 13755, "ep_reward": 985.1122436523438, "reward": 0.845917820930481, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 13756, "ep_reward": 985.9742431640625, "reward": 0.8619972467422485, "action": -1.738957405090332}
{"mode": "train", "epochs": 7, "timestep": 13757, "ep_reward": 986.8388671875, "reward": 0.8646506071090698, "action": -0.8685550093650818}
{"mode": "train", "epochs": 7, "timestep": 13758, "ep_reward": 987.69677734375, "reward": 0.8579307198524475, "action": -0.3750114440917969}
{"mode": "train", "epochs": 7, "timestep": 13759, "ep_reward": 988.5339965820312, "reward": 0.83722984790802, "action": -1.26810884475708}
{"mode": "train", "epochs": 7, "timestep": 13760, "ep_reward": 989.3201293945312, "reward": 0.786146342754364, "action": -0.7548333406448364}
{"mode": "train", "epochs": 7, "timestep": 13761, "ep_reward": 990.0321044921875, "reward": 0.7119737863540649, "action": -1.0037769079208374}
{"mode": "train", "epochs": 7, "timestep": 13762, "ep_reward": 990.6322021484375, "reward": 0.6001124382019043, "action": -0.8189536333084106}
{"mode": "train", "epochs": 7, "timestep": 13763, "ep_reward": 991.0823974609375, "reward": 0.4502031207084656, "action": -1.4286048412322998}
{"mode": "train", "epochs": 7, "timestep": 13764, "ep_reward": 991.4022216796875, "reward": 0.31982266902923584, "action": -0.8074694871902466}
{"mode": "train", "epochs": 7, "timestep": 13765, "ep_reward": 991.6061401367188, "reward": 0.20393824577331543, "action": -0.9932425618171692}
{"mode": "train", "epochs": 7, "timestep": 13766, "ep_reward": 991.6742553710938, "reward": 0.06811100244522095, "action": -0.6058567762374878}
{"mode": "train", "epochs": 7, "timestep": 13767, "ep_reward": 991.7243041992188, "reward": 0.050024569034576416, "action": -1.5750370025634766}
{"mode": "train", "epochs": 7, "timestep": 13768, "ep_reward": 991.9127807617188, "reward": 0.1884663701057434, "action": -0.5766134858131409}
{"mode": "train", "epochs": 7, "timestep": 13769, "ep_reward": 992.2467041015625, "reward": 0.333901584148407, "action": -0.8368395566940308}
{"mode": "train", "epochs": 7, "timestep": 13770, "ep_reward": 992.7159423828125, "reward": 0.4692142605781555, "action": -1.37841796875}
{"mode": "train", "epochs": 7, "timestep": 13771, "ep_reward": 993.299072265625, "reward": 0.5831173062324524, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 13772, "ep_reward": 993.9702758789062, "reward": 0.6712319850921631, "action": -0.8931535482406616}
{"mode": "train", "epochs": 7, "timestep": 13773, "ep_reward": 994.7197265625, "reward": 0.7494655847549438, "action": -0.6044108271598816}
{"mode": "train", "epochs": 7, "timestep": 13774, "ep_reward": 995.5274047851562, "reward": 0.8076608180999756, "action": -0.7322614192962646}
{"mode": "train", "epochs": 7, "timestep": 13775, "ep_reward": 996.3716430664062, "reward": 0.8442121744155884, "action": -0.8460531234741211}
{"mode": "train", "epochs": 7, "timestep": 13776, "ep_reward": 997.2335205078125, "reward": 0.8618932962417603, "action": -1.034358263015747}
{"mode": "train", "epochs": 7, "timestep": 13777, "ep_reward": 998.0946044921875, "reward": 0.8611102104187012, "action": -1.1378862857818604}
{"mode": "train", "epochs": 7, "timestep": 13778, "ep_reward": 998.9358520507812, "reward": 0.84126877784729, "action": -1.7502285242080688}
{"mode": "train", "epochs": 7, "timestep": 13779, "ep_reward": 999.7294921875, "reward": 0.7936145067214966, "action": -0.20827889442443848}
{"mode": "train", "epochs": 7, "timestep": 13780, "ep_reward": 1000.4639892578125, "reward": 0.7344976663589478, "action": -1.2450109720230103}
{"mode": "train", "epochs": 7, "timestep": 13781, "ep_reward": 1001.0946044921875, "reward": 0.6305865049362183, "action": -1.1750175952911377}
{"mode": "train", "epochs": 7, "timestep": 13782, "ep_reward": 1001.5809326171875, "reward": 0.48633408546447754, "action": -1.029706597328186}
{"mode": "train", "epochs": 7, "timestep": 13783, "ep_reward": 1001.9317626953125, "reward": 0.35081493854522705, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 13784, "ep_reward": 1002.1728515625, "reward": 0.24111604690551758, "action": -1.5733873844146729}
{"mode": "train", "epochs": 7, "timestep": 13785, "ep_reward": 1002.2841796875, "reward": 0.1113463044166565, "action": -1.4310120344161987}
{"mode": "train", "epochs": 7, "timestep": 13786, "ep_reward": 1002.2884521484375, "reward": 0.0042563676834106445, "action": -0.07675385475158691}
{"mode": "train", "epochs": 7, "timestep": 13787, "ep_reward": 1002.439453125, "reward": 0.1509922742843628, "action": -0.9687519669532776}
{"mode": "train", "epochs": 7, "timestep": 13788, "ep_reward": 1002.7299194335938, "reward": 0.29044270515441895, "action": -0.49311375617980957}
{"mode": "train", "epochs": 7, "timestep": 13789, "ep_reward": 1003.1627807617188, "reward": 0.4328318238258362, "action": -0.7858248949050903}
{"mode": "train", "epochs": 7, "timestep": 13790, "ep_reward": 1003.7208862304688, "reward": 0.5580750107765198, "action": -1.060043215751648}
{"mode": "train", "epochs": 7, "timestep": 13791, "ep_reward": 1004.3817749023438, "reward": 0.6608996391296387, "action": -0.782322883605957}
{"mode": "train", "epochs": 7, "timestep": 13792, "ep_reward": 1005.1265258789062, "reward": 0.7447274327278137, "action": -0.5547300577163696}
{"mode": "train", "epochs": 7, "timestep": 13793, "ep_reward": 1005.9352416992188, "reward": 0.8087331652641296, "action": -0.9606081247329712}
{"mode": "train", "epochs": 7, "timestep": 13794, "ep_reward": 1006.78515625, "reward": 0.8499109745025635, "action": -1.3596551418304443}
{"mode": "train", "epochs": 7, "timestep": 13795, "ep_reward": 1007.6571044921875, "reward": 0.8719289302825928, "action": -0.42007213830947876}
{"mode": "train", "epochs": 7, "timestep": 13796, "ep_reward": 1008.543701171875, "reward": 0.8865712285041809, "action": -1.7115931510925293}
{"mode": "train", "epochs": 7, "timestep": 13797, "ep_reward": 1009.4205932617188, "reward": 0.8769141435623169, "action": -0.10217857360839844}
{"mode": "train", "epochs": 7, "timestep": 13798, "ep_reward": 1010.2852783203125, "reward": 0.8646574020385742, "action": -0.5425112247467041}
{"mode": "train", "epochs": 7, "timestep": 13799, "ep_reward": 1011.1160278320312, "reward": 0.8307614922523499, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 13800, "ep_reward": 1011.8750610351562, "reward": 0.759009838104248, "action": -1.5067139863967896}
{"mode": "train", "epochs": 7, "timestep": 13801, "ep_reward": 1012.5338745117188, "reward": 0.6588292121887207, "action": -1.2847278118133545}
{"mode": "train", "epochs": 7, "timestep": 13802, "ep_reward": 1013.0553588867188, "reward": 0.5214647650718689, "action": -0.7490494251251221}
{"mode": "train", "epochs": 7, "timestep": 13803, "ep_reward": 1013.4185791015625, "reward": 0.3632177710533142, "action": -1.426844596862793}
{"mode": "train", "epochs": 7, "timestep": 13804, "ep_reward": 1013.6746215820312, "reward": 0.2560402750968933, "action": -0.22593098878860474}
{"mode": "train", "epochs": 7, "timestep": 13805, "ep_reward": 1013.8031616210938, "reward": 0.1285451054573059, "action": -1.7635154724121094}
{"mode": "train", "epochs": 7, "timestep": 13806, "ep_reward": 1013.7879638671875, "reward": -0.015181541442871094, "action": -0.8524376153945923}
{"mode": "train", "epochs": 7, "timestep": 13807, "ep_reward": 1013.919677734375, "reward": 0.13169008493423462, "action": -0.833923876285553}
{"mode": "train", "epochs": 7, "timestep": 13808, "ep_reward": 1014.192626953125, "reward": 0.272921085357666, "action": 0.07039380073547363}
{"mode": "train", "epochs": 7, "timestep": 13809, "ep_reward": 1014.615478515625, "reward": 0.4228600263595581, "action": -1.6716697216033936}
{"mode": "train", "epochs": 7, "timestep": 13810, "ep_reward": 1015.154541015625, "reward": 0.5390406847000122, "action": -0.8707159757614136}
{"mode": "train", "epochs": 7, "timestep": 13811, "ep_reward": 1015.8016967773438, "reward": 0.647167444229126, "action": -1.5534346103668213}
{"mode": "train", "epochs": 7, "timestep": 13812, "ep_reward": 1016.5283813476562, "reward": 0.7266841530799866, "action": -1.1471357345581055}
{"mode": "train", "epochs": 7, "timestep": 13813, "ep_reward": 1017.3175659179688, "reward": 0.7891969680786133, "action": -1.315507173538208}
{"mode": "train", "epochs": 7, "timestep": 13814, "ep_reward": 1018.14794921875, "reward": 0.8303539156913757, "action": -1.182192325592041}
{"mode": "train", "epochs": 7, "timestep": 13815, "ep_reward": 1019.0027465820312, "reward": 0.8548266291618347, "action": -1.0485230684280396}
{"mode": "train", "epochs": 7, "timestep": 13816, "ep_reward": 1019.8662719726562, "reward": 0.8635518550872803, "action": -1.4357960224151611}
{"mode": "train", "epochs": 7, "timestep": 13817, "ep_reward": 1020.7180786132812, "reward": 0.8518170118331909, "action": -0.9053452610969543}
{"mode": "train", "epochs": 7, "timestep": 13818, "ep_reward": 1021.5433349609375, "reward": 0.8252332210540771, "action": -0.9512588977813721}
{"mode": "train", "epochs": 7, "timestep": 13819, "ep_reward": 1022.3179931640625, "reward": 0.7746574878692627, "action": -1.0920811891555786}
{"mode": "train", "epochs": 7, "timestep": 13820, "ep_reward": 1023.0107421875, "reward": 0.6927677392959595, "action": -0.24858009815216064}
{"mode": "train", "epochs": 7, "timestep": 13821, "ep_reward": 1023.5963745117188, "reward": 0.5856245160102844, "action": -0.26029741764068604}
{"mode": "train", "epochs": 7, "timestep": 13822, "ep_reward": 1024.0364990234375, "reward": 0.4401177167892456, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 13823, "ep_reward": 1024.3466796875, "reward": 0.3102260231971741, "action": -1.8301441669464111}
{"mode": "train", "epochs": 7, "timestep": 13824, "ep_reward": 1024.539306640625, "reward": 0.1926400065422058, "action": -1.6256983280181885}
{"mode": "train", "epochs": 7, "timestep": 13825, "ep_reward": 1024.5943603515625, "reward": 0.055053770542144775, "action": -1.3780474662780762}
{"mode": "train", "epochs": 7, "timestep": 13826, "ep_reward": 1024.657470703125, "reward": 0.0631672739982605, "action": -0.730093240737915}
{"mode": "train", "epochs": 7, "timestep": 13827, "ep_reward": 1024.861083984375, "reward": 0.2036222219467163, "action": -1.2948647737503052}
{"mode": "train", "epochs": 7, "timestep": 13828, "ep_reward": 1025.2005615234375, "reward": 0.33947503566741943, "action": -1.329537034034729}
{"mode": "train", "epochs": 7, "timestep": 13829, "ep_reward": 1025.669677734375, "reward": 0.46913623809814453, "action": -1.9465324878692627}
{"mode": "train", "epochs": 7, "timestep": 13830, "ep_reward": 1026.2469482421875, "reward": 0.5772916078567505, "action": -0.6452666521072388}
{"mode": "train", "epochs": 7, "timestep": 13831, "ep_reward": 1026.9267578125, "reward": 0.6797912120819092, "action": -1.1258103847503662}
{"mode": "train", "epochs": 7, "timestep": 13832, "ep_reward": 1027.6795654296875, "reward": 0.752774178981781, "action": -1.310043215751648}
{"mode": "train", "epochs": 7, "timestep": 13833, "ep_reward": 1028.481201171875, "reward": 0.801665186882019, "action": -0.9660519957542419}
{"mode": "train", "epochs": 7, "timestep": 13834, "ep_reward": 1029.314453125, "reward": 0.833289623260498, "action": -0.40438902378082275}
{"mode": "train", "epochs": 7, "timestep": 13835, "ep_reward": 1030.1651611328125, "reward": 0.8507047891616821, "action": -0.31166255474090576}
{"mode": "train", "epochs": 7, "timestep": 13836, "ep_reward": 1031.015625, "reward": 0.8504143953323364, "action": -0.5490208864212036}
{"mode": "train", "epochs": 7, "timestep": 13837, "ep_reward": 1031.8443603515625, "reward": 0.8287390470504761, "action": -0.5014489889144897}
{"mode": "train", "epochs": 7, "timestep": 13838, "ep_reward": 1032.629638671875, "reward": 0.7852292656898499, "action": -0.49534112215042114}
{"mode": "train", "epochs": 7, "timestep": 13839, "ep_reward": 1033.3441162109375, "reward": 0.7145279049873352, "action": -1.103143334388733}
{"mode": "train", "epochs": 7, "timestep": 13840, "ep_reward": 1033.9462890625, "reward": 0.6022255420684814, "action": -1.6708133220672607}
{"mode": "train", "epochs": 7, "timestep": 13841, "ep_reward": 1034.385986328125, "reward": 0.43963807821273804, "action": -1.083310604095459}
{"mode": "train", "epochs": 7, "timestep": 13842, "ep_reward": 1034.70654296875, "reward": 0.3205532431602478, "action": -1.767805576324463}
{"mode": "train", "epochs": 7, "timestep": 13843, "ep_reward": 1034.9114990234375, "reward": 0.20494425296783447, "action": -1.315365195274353}
{"mode": "train", "epochs": 7, "timestep": 13844, "ep_reward": 1034.980712890625, "reward": 0.069191575050354, "action": -1.611116886138916}
{"mode": "train", "epochs": 7, "timestep": 13845, "ep_reward": 1035.0296630859375, "reward": 0.04891592264175415, "action": -0.5914541482925415}
{"mode": "train", "epochs": 7, "timestep": 13846, "ep_reward": 1035.2203369140625, "reward": 0.19071203470230103, "action": -0.6775036454200745}
{"mode": "train", "epochs": 7, "timestep": 13847, "ep_reward": 1035.5545654296875, "reward": 0.3342241048812866, "action": -0.5415778160095215}
{"mode": "train", "epochs": 7, "timestep": 13848, "ep_reward": 1036.02734375, "reward": 0.4727708101272583, "action": -0.03167116641998291}
{"mode": "train", "epochs": 7, "timestep": 13849, "ep_reward": 1036.6279296875, "reward": 0.6005550026893616, "action": -0.9370691180229187}
{"mode": "train", "epochs": 7, "timestep": 13850, "ep_reward": 1037.3243408203125, "reward": 0.6964633464813232, "action": -1.0624557733535767}
{"mode": "train", "epochs": 7, "timestep": 13851, "ep_reward": 1038.09423828125, "reward": 0.7698532938957214, "action": -1.622816801071167}
{"mode": "train", "epochs": 7, "timestep": 13852, "ep_reward": 1038.9132080078125, "reward": 0.8190104365348816, "action": -0.6975860595703125}
{"mode": "train", "epochs": 7, "timestep": 13853, "ep_reward": 1039.7718505859375, "reward": 0.8585842847824097, "action": -1.112064242362976}
{"mode": "train", "epochs": 7, "timestep": 13854, "ep_reward": 1040.6510009765625, "reward": 0.8791025876998901, "action": -1.3372259140014648}
{"mode": "train", "epochs": 7, "timestep": 13855, "ep_reward": 1041.53466796875, "reward": 0.8836179971694946, "action": -1.9980932474136353}
{"mode": "train", "epochs": 7, "timestep": 13856, "ep_reward": 1042.4027099609375, "reward": 0.8680955171585083, "action": -1.0655704736709595}
{"mode": "train", "epochs": 7, "timestep": 13857, "ep_reward": 1043.2449951171875, "reward": 0.8423312902450562, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 13858, "ep_reward": 1044.0303955078125, "reward": 0.7853670716285706, "action": -0.19415557384490967}
{"mode": "train", "epochs": 7, "timestep": 13859, "ep_reward": 1044.748779296875, "reward": 0.7184188365936279, "action": -1.7926266193389893}
{"mode": "train", "epochs": 7, "timestep": 13860, "ep_reward": 1045.3466796875, "reward": 0.5979509353637695, "action": -1.1701953411102295}
{"mode": "train", "epochs": 7, "timestep": 13861, "ep_reward": 1045.7890625, "reward": 0.4423385262489319, "action": -0.35013753175735474}
{"mode": "train", "epochs": 7, "timestep": 13862, "ep_reward": 1046.1107177734375, "reward": 0.321679949760437, "action": -0.4843992590904236}
{"mode": "train", "epochs": 7, "timestep": 13863, "ep_reward": 1046.31689453125, "reward": 0.20611578226089478, "action": -0.9946849942207336}
{"mode": "train", "epochs": 7, "timestep": 13864, "ep_reward": 1046.387451171875, "reward": 0.07056182622909546, "action": -1.2416914701461792}
{"mode": "train", "epochs": 7, "timestep": 13865, "ep_reward": 1046.4349365234375, "reward": 0.04750621318817139, "action": -1.269594430923462}
{"mode": "train", "epochs": 7, "timestep": 13866, "ep_reward": 1046.62109375, "reward": 0.18619412183761597, "action": -1.0355128049850464}
{"mode": "train", "epochs": 7, "timestep": 13867, "ep_reward": 1046.947021484375, "reward": 0.32594096660614014, "action": -0.9180700778961182}
{"mode": "train", "epochs": 7, "timestep": 13868, "ep_reward": 1047.40869140625, "reward": 0.46172767877578735, "action": -0.049844980239868164}
{"mode": "train", "epochs": 7, "timestep": 13869, "ep_reward": 1048.00048828125, "reward": 0.5918176174163818, "action": -0.5235374569892883}
{"mode": "train", "epochs": 7, "timestep": 13870, "ep_reward": 1048.69384765625, "reward": 0.6933891773223877, "action": -0.8450391888618469}
{"mode": "train", "epochs": 7, "timestep": 13871, "ep_reward": 1049.462646484375, "reward": 0.7687850594520569, "action": -1.4832344055175781}
{"mode": "train", "epochs": 7, "timestep": 13872, "ep_reward": 1050.2808837890625, "reward": 0.8182119727134705, "action": -0.9899098873138428}
{"mode": "train", "epochs": 7, "timestep": 13873, "ep_reward": 1051.135009765625, "reward": 0.8541128635406494, "action": -1.4088603258132935}
{"mode": "train", "epochs": 7, "timestep": 13874, "ep_reward": 1052.005615234375, "reward": 0.8706043362617493, "action": -0.9696329832077026}
{"mode": "train", "epochs": 7, "timestep": 13875, "ep_reward": 1052.8809814453125, "reward": 0.8754048943519592, "action": -1.335823655128479}
{"mode": "train", "epochs": 7, "timestep": 13876, "ep_reward": 1053.7421875, "reward": 0.8612546920776367, "action": -1.0695101022720337}
{"mode": "train", "epochs": 7, "timestep": 13877, "ep_reward": 1054.5728759765625, "reward": 0.8306323289871216, "action": -1.342086911201477}
{"mode": "train", "epochs": 7, "timestep": 13878, "ep_reward": 1055.3466796875, "reward": 0.7738471031188965, "action": -1.1215780973434448}
{"mode": "train", "epochs": 7, "timestep": 13879, "ep_reward": 1056.03564453125, "reward": 0.6890029907226562, "action": -0.026278257369995117}
{"mode": "train", "epochs": 7, "timestep": 13880, "ep_reward": 1056.617919921875, "reward": 0.5822957754135132, "action": -1.1314810514450073}
{"mode": "train", "epochs": 7, "timestep": 13881, "ep_reward": 1057.0394287109375, "reward": 0.4214586615562439, "action": -1.2167245149612427}
{"mode": "train", "epochs": 7, "timestep": 13882, "ep_reward": 1057.3389892578125, "reward": 0.29957330226898193, "action": -1.2112908363342285}
{"mode": "train", "epochs": 7, "timestep": 13883, "ep_reward": 1057.5189208984375, "reward": 0.17995953559875488, "action": -1.212791919708252}
{"mode": "train", "epochs": 7, "timestep": 13884, "ep_reward": 1057.5592041015625, "reward": 0.04026675224304199, "action": -1.642888069152832}
{"mode": "train", "epochs": 7, "timestep": 13885, "ep_reward": 1057.63671875, "reward": 0.07756876945495605, "action": -1.012062907218933}
{"mode": "train", "epochs": 7, "timestep": 13886, "ep_reward": 1057.851806640625, "reward": 0.21505755186080933, "action": -0.4458876848220825}
{"mode": "train", "epochs": 7, "timestep": 13887, "ep_reward": 1058.2135009765625, "reward": 0.3616921901702881, "action": -0.5836628675460815}
{"mode": "train", "epochs": 7, "timestep": 13888, "ep_reward": 1058.7109375, "reward": 0.4974045157432556, "action": -0.6704686284065247}
{"mode": "train", "epochs": 7, "timestep": 13889, "ep_reward": 1059.32568359375, "reward": 0.6147284507751465, "action": -0.012386798858642578}
{"mode": "train", "epochs": 7, "timestep": 13890, "ep_reward": 1060.0419921875, "reward": 0.7162771224975586, "action": -1.8644115924835205}
{"mode": "train", "epochs": 7, "timestep": 13891, "ep_reward": 1060.8199462890625, "reward": 0.7779781818389893, "action": -0.14752155542373657}
{"mode": "train", "epochs": 7, "timestep": 13892, "ep_reward": 1061.6556396484375, "reward": 0.8357410430908203, "action": -1.0466011762619019}
{"mode": "train", "epochs": 7, "timestep": 13893, "ep_reward": 1062.5238037109375, "reward": 0.8681344985961914, "action": -1.4541419744491577}
{"mode": "train", "epochs": 7, "timestep": 13894, "ep_reward": 1063.4068603515625, "reward": 0.8830283880233765, "action": -0.07461124658584595}
{"mode": "train", "epochs": 7, "timestep": 13895, "ep_reward": 1064.3016357421875, "reward": 0.8948065042495728, "action": -0.9639517664909363}
{"mode": "train", "epochs": 7, "timestep": 13896, "ep_reward": 1065.18798828125, "reward": 0.8863343596458435, "action": -1.1049046516418457}
{"mode": "train", "epochs": 7, "timestep": 13897, "ep_reward": 1066.0494384765625, "reward": 0.8614063858985901, "action": -1.340126872062683}
{"mode": "train", "epochs": 7, "timestep": 13898, "ep_reward": 1066.8642578125, "reward": 0.8148790001869202, "action": -0.7245232462882996}
{"mode": "train", "epochs": 7, "timestep": 13899, "ep_reward": 1067.6134033203125, "reward": 0.7491005659103394, "action": -1.1389427185058594}
{"mode": "train", "epochs": 7, "timestep": 13900, "ep_reward": 1068.2606201171875, "reward": 0.647192120552063, "action": -1.5144734382629395}
{"mode": "train", "epochs": 7, "timestep": 13901, "ep_reward": 1068.761474609375, "reward": 0.5008862018585205, "action": -1.3402677774429321}
{"mode": "train", "epochs": 7, "timestep": 13902, "ep_reward": 1069.105224609375, "reward": 0.3437299132347107, "action": -1.6110055446624756}
{"mode": "train", "epochs": 7, "timestep": 13903, "ep_reward": 1069.3377685546875, "reward": 0.23257869482040405, "action": -1.2122478485107422}
{"mode": "train", "epochs": 7, "timestep": 13904, "ep_reward": 1069.439208984375, "reward": 0.10142272710800171, "action": -0.6158764362335205}
{"mode": "train", "epochs": 7, "timestep": 13905, "ep_reward": 1069.454345703125, "reward": 0.015182971954345703, "action": -0.8014916777610779}
{"mode": "train", "epochs": 7, "timestep": 13906, "ep_reward": 1069.6124267578125, "reward": 0.1580256223678589, "action": -1.533989667892456}
{"mode": "train", "epochs": 7, "timestep": 13907, "ep_reward": 1069.903564453125, "reward": 0.291154682636261, "action": -0.48569995164871216}
{"mode": "train", "epochs": 7, "timestep": 13908, "ep_reward": 1070.338623046875, "reward": 0.4351189136505127, "action": -0.5362615585327148}
{"mode": "train", "epochs": 7, "timestep": 13909, "ep_reward": 1070.9022216796875, "reward": 0.5636000633239746, "action": -0.6444873809814453}
{"mode": "train", "epochs": 7, "timestep": 13910, "ep_reward": 1071.57177734375, "reward": 0.6695839166641235, "action": -0.7747435569763184}
{"mode": "train", "epochs": 7, "timestep": 13911, "ep_reward": 1072.3228759765625, "reward": 0.7511440515518188, "action": -0.8389002084732056}
{"mode": "train", "epochs": 7, "timestep": 13912, "ep_reward": 1073.13330078125, "reward": 0.8103818893432617, "action": -1.0902454853057861}
{"mode": "train", "epochs": 7, "timestep": 13913, "ep_reward": 1073.98193359375, "reward": 0.8485759496688843, "action": -0.5838550329208374}
{"mode": "train", "epochs": 7, "timestep": 13914, "ep_reward": 1074.856201171875, "reward": 0.87428879737854, "action": -1.4752922058105469}
{"mode": "train", "epochs": 7, "timestep": 13915, "ep_reward": 1075.7342529296875, "reward": 0.8779984712600708, "action": -0.7439966201782227}
{"mode": "train", "epochs": 7, "timestep": 13916, "ep_reward": 1076.606689453125, "reward": 0.872477114200592, "action": -0.6959953308105469}
{"mode": "train", "epochs": 7, "timestep": 13917, "ep_reward": 1077.4573974609375, "reward": 0.8506999015808105, "action": -1.0354522466659546}
{"mode": "train", "epochs": 7, "timestep": 13918, "ep_reward": 1078.262939453125, "reward": 0.8055638670921326, "action": -1.260110855102539}
{"mode": "train", "epochs": 7, "timestep": 13919, "ep_reward": 1078.9945068359375, "reward": 0.731564998626709, "action": 0.04964214563369751}
{"mode": "train", "epochs": 7, "timestep": 13920, "ep_reward": 1079.635009765625, "reward": 0.6405580043792725, "action": -0.4695829153060913}
{"mode": "train", "epochs": 7, "timestep": 13921, "ep_reward": 1080.1427001953125, "reward": 0.5077184438705444, "action": -1.42475163936615}
{"mode": "train", "epochs": 7, "timestep": 13922, "ep_reward": 1080.483642578125, "reward": 0.3408961892127991, "action": -0.7272371649742126}
{"mode": "train", "epochs": 7, "timestep": 13923, "ep_reward": 1080.712646484375, "reward": 0.22902578115463257, "action": -1.2529489994049072}
{"mode": "train", "epochs": 7, "timestep": 13924, "ep_reward": 1080.809814453125, "reward": 0.09721297025680542, "action": -1.284088134765625}
{"mode": "train", "epochs": 7, "timestep": 13925, "ep_reward": 1080.829345703125, "reward": 0.019551336765289307, "action": -1.427647590637207}
{"mode": "train", "epochs": 7, "timestep": 13926, "ep_reward": 1080.9913330078125, "reward": 0.16197121143341064, "action": -1.0827747583389282}
{"mode": "train", "epochs": 7, "timestep": 13927, "ep_reward": 1081.2919921875, "reward": 0.30060893297195435, "action": -1.7207739353179932}
{"mode": "train", "epochs": 7, "timestep": 13928, "ep_reward": 1081.7203369140625, "reward": 0.4283406734466553, "action": -0.9795747995376587}
{"mode": "train", "epochs": 7, "timestep": 13929, "ep_reward": 1082.273681640625, "reward": 0.5533379316329956, "action": 0.3637479543685913}
{"mode": "train", "epochs": 7, "timestep": 13930, "ep_reward": 1082.9453125, "reward": 0.6715954542160034, "action": -1.3566999435424805}
{"mode": "train", "epochs": 7, "timestep": 13931, "ep_reward": 1083.692138671875, "reward": 0.746842086315155, "action": -0.36751919984817505}
{"mode": "train", "epochs": 7, "timestep": 13932, "ep_reward": 1084.501953125, "reward": 0.8098490238189697, "action": -0.842570960521698}
{"mode": "train", "epochs": 7, "timestep": 13933, "ep_reward": 1085.3505859375, "reward": 0.8486043214797974, "action": -0.27444881200790405}
{"mode": "train", "epochs": 7, "timestep": 13934, "ep_reward": 1086.2254638671875, "reward": 0.8748874664306641, "action": -1.5455796718597412}
{"mode": "train", "epochs": 7, "timestep": 13935, "ep_reward": 1087.1011962890625, "reward": 0.8757650256156921, "action": -1.0308315753936768}
{"mode": "train", "epochs": 7, "timestep": 13936, "ep_reward": 1087.96630859375, "reward": 0.865146815776825, "action": -0.8184810876846313}
{"mode": "train", "epochs": 7, "timestep": 13937, "ep_reward": 1088.8046875, "reward": 0.8383536338806152, "action": -1.756379246711731}
{"mode": "train", "epochs": 7, "timestep": 13938, "ep_reward": 1089.584716796875, "reward": 0.7800076007843018, "action": -1.056843876838684}
{"mode": "train", "epochs": 7, "timestep": 13939, "ep_reward": 1090.2833251953125, "reward": 0.6986525058746338, "action": -1.315224528312683}
{"mode": "train", "epochs": 7, "timestep": 13940, "ep_reward": 1090.8604736328125, "reward": 0.5771098136901855, "action": -1.8116198778152466}
{"mode": "train", "epochs": 7, "timestep": 13941, "ep_reward": 1091.2646484375, "reward": 0.4041845202445984, "action": -1.5468025207519531}
{"mode": "train", "epochs": 7, "timestep": 13942, "ep_reward": 1091.5673828125, "reward": 0.30276763439178467, "action": -0.9139582514762878}
{"mode": "train", "epochs": 7, "timestep": 13943, "ep_reward": 1091.7510986328125, "reward": 0.1836555004119873, "action": -1.430881142616272}
{"mode": "train", "epochs": 7, "timestep": 13944, "ep_reward": 1091.795654296875, "reward": 0.04459911584854126, "action": -1.5263121128082275}
{"mode": "train", "epochs": 7, "timestep": 13945, "ep_reward": 1091.8690185546875, "reward": 0.07332497835159302, "action": -1.4301908016204834}
{"mode": "train", "epochs": 7, "timestep": 13946, "ep_reward": 1092.07763671875, "reward": 0.2085658311843872, "action": -0.5899211168289185}
{"mode": "train", "epochs": 7, "timestep": 13947, "ep_reward": 1092.431640625, "reward": 0.35405755043029785, "action": -0.35793107748031616}
{"mode": "train", "epochs": 7, "timestep": 13948, "ep_reward": 1092.92529296875, "reward": 0.4935995936393738, "action": -0.32238924503326416}
{"mode": "train", "epochs": 7, "timestep": 13949, "ep_reward": 1093.54052734375, "reward": 0.6152005195617676, "action": -1.1020638942718506}
{"mode": "train", "epochs": 7, "timestep": 13950, "ep_reward": 1094.246826171875, "reward": 0.7063252925872803, "action": -1.5593984127044678}
{"mode": "train", "epochs": 7, "timestep": 13951, "ep_reward": 1095.0189208984375, "reward": 0.77211594581604, "action": -1.4397616386413574}
{"mode": "train", "epochs": 7, "timestep": 13952, "ep_reward": 1095.8387451171875, "reward": 0.8197699785232544, "action": -0.9411174058914185}
{"mode": "train", "epochs": 7, "timestep": 13953, "ep_reward": 1096.6925048828125, "reward": 0.8537800312042236, "action": -0.7918993234634399}
{"mode": "train", "epochs": 7, "timestep": 13954, "ep_reward": 1097.5650634765625, "reward": 0.8725617527961731, "action": -0.24841153621673584}
{"mode": "train", "epochs": 7, "timestep": 13955, "ep_reward": 1098.4453125, "reward": 0.8802967071533203, "action": -1.3274813890457153}
{"mode": "train", "epochs": 7, "timestep": 13956, "ep_reward": 1099.3089599609375, "reward": 0.8636257648468018, "action": -1.5319628715515137}
{"mode": "train", "epochs": 7, "timestep": 13957, "ep_reward": 1100.1351318359375, "reward": 0.826194167137146, "action": -0.9691912531852722}
{"mode": "train", "epochs": 7, "timestep": 13958, "ep_reward": 1100.9051513671875, "reward": 0.769962728023529, "action": -0.848598062992096}
{"mode": "train", "epochs": 7, "timestep": 13959, "ep_reward": 1101.59033203125, "reward": 0.6851358413696289, "action": -1.4242370128631592}
{"mode": "train", "epochs": 7, "timestep": 13960, "ep_reward": 1102.1461181640625, "reward": 0.5558223128318787, "action": -1.1987248659133911}
{"mode": "train", "epochs": 7, "timestep": 13961, "ep_reward": 1102.532470703125, "reward": 0.3863145112991333, "action": -0.8646093010902405}
{"mode": "train", "epochs": 7, "timestep": 13962, "ep_reward": 1102.8157958984375, "reward": 0.28329235315322876, "action": -1.0237678289413452}
{"mode": "train", "epochs": 7, "timestep": 13963, "ep_reward": 1102.9765625, "reward": 0.1607322096824646, "action": -1.1000566482543945}
{"mode": "train", "epochs": 7, "timestep": 13964, "ep_reward": 1102.9947509765625, "reward": 0.018241047859191895, "action": -0.47870874404907227}
{"mode": "train", "epochs": 7, "timestep": 13965, "ep_reward": 1103.09326171875, "reward": 0.09853345155715942, "action": -1.3004051446914673}
{"mode": "train", "epochs": 7, "timestep": 13966, "ep_reward": 1103.3262939453125, "reward": 0.23305076360702515, "action": -0.38456612825393677}
{"mode": "train", "epochs": 7, "timestep": 13967, "ep_reward": 1103.7066650390625, "reward": 0.3803938031196594, "action": -1.2141551971435547}
{"mode": "train", "epochs": 7, "timestep": 13968, "ep_reward": 1104.2138671875, "reward": 0.5071520805358887, "action": -1.460373044013977}
{"mode": "train", "epochs": 7, "timestep": 13969, "ep_reward": 1104.8284912109375, "reward": 0.6146554946899414, "action": -1.0207624435424805}
{"mode": "train", "epochs": 7, "timestep": 13970, "ep_reward": 1105.534423828125, "reward": 0.7058844566345215, "action": -0.11606782674789429}
{"mode": "train", "epochs": 7, "timestep": 13971, "ep_reward": 1106.3170166015625, "reward": 0.7825912237167358, "action": -0.605501651763916}
{"mode": "train", "epochs": 7, "timestep": 13972, "ep_reward": 1107.1494140625, "reward": 0.8324238657951355, "action": -1.239565372467041}
{"mode": "train", "epochs": 7, "timestep": 13973, "ep_reward": 1108.0081787109375, "reward": 0.8587802648544312, "action": -0.4588692784309387}
{"mode": "train", "epochs": 7, "timestep": 13974, "ep_reward": 1108.8836669921875, "reward": 0.8754535913467407, "action": -0.9701309204101562}
{"mode": "train", "epochs": 7, "timestep": 13975, "ep_reward": 1109.756103515625, "reward": 0.8724326491355896, "action": -1.1528435945510864}
{"mode": "train", "epochs": 7, "timestep": 13976, "ep_reward": 1110.6072998046875, "reward": 0.8511908054351807, "action": -0.2959964871406555}
{"mode": "train", "epochs": 7, "timestep": 13977, "ep_reward": 1111.4254150390625, "reward": 0.8180834650993347, "action": -0.315149188041687}
{"mode": "train", "epochs": 7, "timestep": 13978, "ep_reward": 1112.18701171875, "reward": 0.7615535259246826, "action": -1.6662592887878418}
{"mode": "train", "epochs": 7, "timestep": 13979, "ep_reward": 1112.8465576171875, "reward": 0.659536600112915, "action": -1.1076408624649048}
{"mode": "train", "epochs": 7, "timestep": 13980, "ep_reward": 1113.3712158203125, "reward": 0.5247098803520203, "action": -0.9326309561729431}
{"mode": "train", "epochs": 7, "timestep": 13981, "ep_reward": 1113.7332763671875, "reward": 0.3621121644973755, "action": -0.2822365164756775}
{"mode": "train", "epochs": 7, "timestep": 13982, "ep_reward": 1113.98779296875, "reward": 0.254456102848053, "action": -1.3107858896255493}
{"mode": "train", "epochs": 7, "timestep": 13983, "ep_reward": 1114.11474609375, "reward": 0.1269710659980774, "action": -0.7625389099121094}
{"mode": "train", "epochs": 7, "timestep": 13984, "ep_reward": 1114.1015625, "reward": -0.01318204402923584, "action": -0.5866986513137817}
{"mode": "train", "epochs": 7, "timestep": 13985, "ep_reward": 1114.23486328125, "reward": 0.13333970308303833, "action": -1.3694415092468262}
{"mode": "train", "epochs": 7, "timestep": 13986, "ep_reward": 1114.5028076171875, "reward": 0.2678842544555664, "action": -1.123565435409546}
{"mode": "train", "epochs": 7, "timestep": 13987, "ep_reward": 1114.90771484375, "reward": 0.40494465827941895, "action": -1.277243733406067}
{"mode": "train", "epochs": 7, "timestep": 13988, "ep_reward": 1115.4368896484375, "reward": 0.5291483402252197, "action": -0.9381983876228333}
{"mode": "train", "epochs": 7, "timestep": 13989, "ep_reward": 1116.075439453125, "reward": 0.6385089159011841, "action": -0.508971631526947}
{"mode": "train", "epochs": 7, "timestep": 13990, "ep_reward": 1116.8043212890625, "reward": 0.7288655638694763, "action": -0.8067390322685242}
{"mode": "train", "epochs": 7, "timestep": 13991, "ep_reward": 1117.5968017578125, "reward": 0.7924643158912659, "action": -1.6457172632217407}
{"mode": "train", "epochs": 7, "timestep": 13992, "ep_reward": 1118.4249267578125, "reward": 0.8281667232513428, "action": -0.5111352801322937}
{"mode": "train", "epochs": 7, "timestep": 13993, "ep_reward": 1119.280517578125, "reward": 0.8555588722229004, "action": -0.9893045425415039}
{"mode": "train", "epochs": 7, "timestep": 13994, "ep_reward": 1120.1417236328125, "reward": 0.8612298965454102, "action": -2.0}
{"mode": "train", "epochs": 7, "timestep": 13995, "ep_reward": 1120.98193359375, "reward": 0.8401825428009033, "action": -1.0648106336593628}
{"mode": "train", "epochs": 7, "timestep": 13996, "ep_reward": 1121.7879638671875, "reward": 0.8060083389282227, "action": -1.1397510766983032}
{"mode": "train", "epochs": 7, "timestep": 13997, "ep_reward": 1122.5325927734375, "reward": 0.7446784973144531, "action": -1.1833194494247437}
{"mode": "train", "epochs": 7, "timestep": 13998, "ep_reward": 1123.181884765625, "reward": 0.6492987871170044, "action": -1.6548213958740234}
{"mode": "train", "epochs": 7, "timestep": 13999, "ep_reward": 1123.6878662109375, "reward": 0.5059950351715088, "action": -1.4801852703094482}
{"mode": "train", "epochs": 7, "timestep": 14000, "ep_reward": 1124.061279296875, "reward": 0.3734592795372009, "action": -1.0102205276489258}
{"mode": "train", "epochs": 8, "timestep": 14001, "ep_reward": 0.5121753215789795, "reward": 0.5121753215789795, "action": -0.09181183576583862}
{"mode": "train", "epochs": 8, "timestep": 14002, "ep_reward": 1.0217386484146118, "reward": 0.5095633268356323, "action": -0.5875287055969238}
{"mode": "train", "epochs": 8, "timestep": 14003, "ep_reward": 1.521375298500061, "reward": 0.4996366500854492, "action": -1.1899161338806152}
{"mode": "train", "epochs": 8, "timestep": 14004, "ep_reward": 2.001493453979492, "reward": 0.4801182746887207, "action": -1.1985795497894287}
{"mode": "train", "epochs": 8, "timestep": 14005, "ep_reward": 2.4532198905944824, "reward": 0.451726496219635, "action": -1.422701358795166}
{"mode": "train", "epochs": 8, "timestep": 14006, "ep_reward": 2.867570400238037, "reward": 0.41435056924819946, "action": -1.650411605834961}
{"mode": "train", "epochs": 8, "timestep": 14007, "ep_reward": 3.2362124919891357, "reward": 0.3686421513557434, "action": -0.8294199109077454}
{"mode": "train", "epochs": 8, "timestep": 14008, "ep_reward": 3.6220755577087402, "reward": 0.3858630061149597, "action": -1.0829733610153198}
{"mode": "train", "epochs": 8, "timestep": 14009, "ep_reward": 4.047128200531006, "reward": 0.42505282163619995, "action": -0.9034250378608704}
{"mode": "train", "epochs": 8, "timestep": 14010, "ep_reward": 4.512548923492432, "reward": 0.4654209017753601, "action": -1.5853382349014282}
{"mode": "train", "epochs": 8, "timestep": 14011, "ep_reward": 5.016529083251953, "reward": 0.5039799213409424, "action": -1.6021199226379395}
{"mode": "train", "epochs": 8, "timestep": 14012, "ep_reward": 5.558726787567139, "reward": 0.542197585105896, "action": -0.5949912071228027}
{"mode": "train", "epochs": 8, "timestep": 14013, "ep_reward": 6.138560771942139, "reward": 0.579833984375, "action": -0.7991959452629089}
{"mode": "train", "epochs": 8, "timestep": 14014, "ep_reward": 6.749677658081055, "reward": 0.6111171245574951, "action": -0.8708137273788452}
{"mode": "train", "epochs": 8, "timestep": 14015, "ep_reward": 7.385462760925293, "reward": 0.6357848644256592, "action": 0.13598734140396118}
{"mode": "train", "epochs": 8, "timestep": 14016, "ep_reward": 8.037839889526367, "reward": 0.652377188205719, "action": 0.00344887375831604}
{"mode": "train", "epochs": 8, "timestep": 14017, "ep_reward": 8.695249557495117, "reward": 0.6574093103408813, "action": 0.6767678260803223}
{"mode": "train", "epochs": 8, "timestep": 14018, "ep_reward": 9.344195365905762, "reward": 0.6489460468292236, "action": 0.14849114418029785}
{"mode": "train", "epochs": 8, "timestep": 14019, "ep_reward": 9.972407341003418, "reward": 0.6282123327255249, "action": 1.0209755897521973}
{"mode": "train", "epochs": 8, "timestep": 14020, "ep_reward": 10.563665390014648, "reward": 0.5912576913833618, "action": 1.0432567596435547}
{"mode": "train", "epochs": 8, "timestep": 14021, "ep_reward": 11.103256225585938, "reward": 0.5395910739898682, "action": 1.2597100734710693}
{"mode": "train", "epochs": 8, "timestep": 14022, "ep_reward": 11.576741218566895, "reward": 0.47348469495773315, "action": 1.0340346097946167}
{"mode": "train", "epochs": 8, "timestep": 14023, "ep_reward": 11.975127220153809, "reward": 0.3983864188194275, "action": 0.2285701036453247}
{"mode": "train", "epochs": 8, "timestep": 14024, "ep_reward": 12.299386978149414, "reward": 0.32425957918167114, "action": 1.596413493156433}
{"mode": "train", "epochs": 8, "timestep": 14025, "ep_reward": 12.649161338806152, "reward": 0.34977442026138306, "action": 1.211723804473877}
{"mode": "train", "epochs": 8, "timestep": 14026, "ep_reward": 13.064923286437988, "reward": 0.41576170921325684, "action": 1.478621006011963}
{"mode": "train", "epochs": 8, "timestep": 14027, "ep_reward": 13.546479225158691, "reward": 0.481555700302124, "action": 1.2550692558288574}
{"mode": "train", "epochs": 8, "timestep": 14028, "ep_reward": 14.093954086303711, "reward": 0.5474749207496643, "action": 1.170142412185669}
{"mode": "train", "epochs": 8, "timestep": 14029, "ep_reward": 14.703658103942871, "reward": 0.6097043752670288, "action": 0.5219883322715759}
{"mode": "train", "epochs": 8, "timestep": 14030, "ep_reward": 15.370940208435059, "reward": 0.6672818660736084, "action": 1.2882519960403442}
{"mode": "train", "epochs": 8, "timestep": 14031, "ep_reward": 16.08327293395996, "reward": 0.7123334407806396, "action": 1.0948591232299805}
{"mode": "train", "epochs": 8, "timestep": 14032, "ep_reward": 16.831998825073242, "reward": 0.7487256526947021, "action": 0.9758453369140625}
{"mode": "train", "epochs": 8, "timestep": 14033, "ep_reward": 17.606979370117188, "reward": 0.7749812602996826, "action": 1.283862829208374}
{"mode": "train", "epochs": 8, "timestep": 14034, "ep_reward": 18.39759063720703, "reward": 0.7906122207641602, "action": 1.2828055620193481}
{"mode": "train", "epochs": 8, "timestep": 14035, "ep_reward": 19.194128036499023, "reward": 0.7965375781059265, "action": 1.673907995223999}
{"mode": "train", "epochs": 8, "timestep": 14036, "ep_reward": 19.98802947998047, "reward": 0.7939013838768005, "action": 0.2812560200691223}
{"mode": "train", "epochs": 8, "timestep": 14037, "ep_reward": 20.766164779663086, "reward": 0.778135359287262, "action": 0.7843245267868042}
{"mode": "train", "epochs": 8, "timestep": 14038, "ep_reward": 21.51688003540039, "reward": 0.7507148385047913, "action": 0.6075685024261475}
{"mode": "train", "epochs": 8, "timestep": 14039, "ep_reward": 22.22689437866211, "reward": 0.7100145220756531, "action": -1.2706947326660156}
{"mode": "train", "epochs": 8, "timestep": 14040, "ep_reward": 22.869693756103516, "reward": 0.6427997946739197, "action": -0.618067741394043}
{"mode": "train", "epochs": 8, "timestep": 14041, "ep_reward": 23.430166244506836, "reward": 0.5604718923568726, "action": -1.1474425792694092}
{"mode": "train", "epochs": 8, "timestep": 14042, "ep_reward": 23.88751983642578, "reward": 0.45735424757003784, "action": -0.12230545282363892}
{"mode": "train", "epochs": 8, "timestep": 14043, "ep_reward": 24.24007797241211, "reward": 0.3525584936141968, "action": -0.2446913719177246}
{"mode": "train", "epochs": 8, "timestep": 14044, "ep_reward": 24.482818603515625, "reward": 0.2427404522895813, "action": -1.1130861043930054}
{"mode": "train", "epochs": 8, "timestep": 14045, "ep_reward": 24.773807525634766, "reward": 0.29098987579345703, "action": 0.020227432250976562}
{"mode": "train", "epochs": 8, "timestep": 14046, "ep_reward": 25.164518356323242, "reward": 0.3907116651535034, "action": -0.51853346824646}
{"mode": "train", "epochs": 8, "timestep": 14047, "ep_reward": 25.64861488342285, "reward": 0.4840966463088989, "action": -0.4797792434692383}
{"mode": "train", "epochs": 8, "timestep": 14048, "ep_reward": 26.220905303955078, "reward": 0.5722904205322266, "action": -1.255495309829712}
{"mode": "train", "epochs": 8, "timestep": 14049, "ep_reward": 26.86790657043457, "reward": 0.6470004320144653, "action": -0.8019472360610962}
{"mode": "train", "epochs": 8, "timestep": 14050, "ep_reward": 27.582216262817383, "reward": 0.714309811592102, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 14051, "ep_reward": 28.34722328186035, "reward": 0.765006959438324, "action": -0.6191518306732178}
{"mode": "train", "epochs": 8, "timestep": 14052, "ep_reward": 29.158334732055664, "reward": 0.8111109733581543, "action": -1.1177328824996948}
{"mode": "train", "epochs": 8, "timestep": 14053, "ep_reward": 30.00171661376953, "reward": 0.8433810472488403, "action": -0.6804201602935791}
{"mode": "train", "epochs": 8, "timestep": 14054, "ep_reward": 30.867307662963867, "reward": 0.8655915260314941, "action": -0.9527109265327454}
{"mode": "train", "epochs": 8, "timestep": 14055, "ep_reward": 31.744083404541016, "reward": 0.8767764568328857, "action": -0.8371278047561646}
{"mode": "train", "epochs": 8, "timestep": 14056, "ep_reward": 32.62217330932617, "reward": 0.8780890703201294, "action": 0.7160779237747192}
{"mode": "train", "epochs": 8, "timestep": 14057, "ep_reward": 33.487060546875, "reward": 0.8648889064788818, "action": -0.47984322905540466}
{"mode": "train", "epochs": 8, "timestep": 14058, "ep_reward": 34.32685852050781, "reward": 0.839799165725708, "action": -0.008703261613845825}
{"mode": "train", "epochs": 8, "timestep": 14059, "ep_reward": 35.1253776550293, "reward": 0.7985174059867859, "action": -0.4715009927749634}
{"mode": "train", "epochs": 8, "timestep": 14060, "ep_reward": 35.86911392211914, "reward": 0.7437370419502258, "action": -0.39107123017311096}
{"mode": "train", "epochs": 8, "timestep": 14061, "ep_reward": 36.54144287109375, "reward": 0.6723290681838989, "action": -0.44703787565231323}
{"mode": "train", "epochs": 8, "timestep": 14062, "ep_reward": 37.126708984375, "reward": 0.5852673053741455, "action": 0.5944457054138184}
{"mode": "train", "epochs": 8, "timestep": 14063, "ep_reward": 37.59886169433594, "reward": 0.4721536636352539, "action": -0.13321352005004883}
{"mode": "train", "epochs": 8, "timestep": 14064, "ep_reward": 37.95250701904297, "reward": 0.35364454984664917, "action": -0.041440948843955994}
{"mode": "train", "epochs": 8, "timestep": 14065, "ep_reward": 38.18144989013672, "reward": 0.22894221544265747, "action": -0.302889883518219}
{"mode": "train", "epochs": 8, "timestep": 14066, "ep_reward": 38.409034729003906, "reward": 0.2275862693786621, "action": 0.15227138996124268}
{"mode": "train", "epochs": 8, "timestep": 14067, "ep_reward": 38.74534606933594, "reward": 0.3363102674484253, "action": -1.116823673248291}
{"mode": "train", "epochs": 8, "timestep": 14068, "ep_reward": 39.19977951049805, "reward": 0.4544317126274109, "action": -0.09321454167366028}
{"mode": "train", "epochs": 8, "timestep": 14069, "ep_reward": 39.75456619262695, "reward": 0.5547851324081421, "action": 0.37228521704673767}
{"mode": "train", "epochs": 8, "timestep": 14070, "ep_reward": 40.39545822143555, "reward": 0.6408936977386475, "action": 0.6300951242446899}
{"mode": "train", "epochs": 8, "timestep": 14071, "ep_reward": 41.10831069946289, "reward": 0.7128521203994751, "action": 1.2064427137374878}
{"mode": "train", "epochs": 8, "timestep": 14072, "ep_reward": 41.87748718261719, "reward": 0.7691768407821655, "action": 1.1582684516906738}
{"mode": "train", "epochs": 8, "timestep": 14073, "ep_reward": 42.69166564941406, "reward": 0.8141767978668213, "action": 1.0425198078155518}
{"mode": "train", "epochs": 8, "timestep": 14074, "ep_reward": 43.54000473022461, "reward": 0.8483386635780334, "action": 0.5609137415885925}
{"mode": "train", "epochs": 8, "timestep": 14075, "ep_reward": 44.41237258911133, "reward": 0.8723695278167725, "action": 0.7819830179214478}
{"mode": "train", "epochs": 8, "timestep": 14076, "ep_reward": 45.29743957519531, "reward": 0.885068416595459, "action": 0.7368694543838501}
{"mode": "train", "epochs": 8, "timestep": 14077, "ep_reward": 46.1851921081543, "reward": 0.8877530097961426, "action": 0.4565407633781433}
{"mode": "train", "epochs": 8, "timestep": 14078, "ep_reward": 47.06486129760742, "reward": 0.8796679973602295, "action": 0.6604682803153992}
{"mode": "train", "epochs": 8, "timestep": 14079, "ep_reward": 47.92564010620117, "reward": 0.8607796430587769, "action": 0.3081657886505127}
{"mode": "train", "epochs": 8, "timestep": 14080, "ep_reward": 48.753849029541016, "reward": 0.8282083868980408, "action": 0.16388893127441406}
{"mode": "train", "epochs": 8, "timestep": 14081, "ep_reward": 49.53363800048828, "reward": 0.7797873020172119, "action": 1.416076898574829}
{"mode": "train", "epochs": 8, "timestep": 14082, "ep_reward": 50.25825500488281, "reward": 0.7246187925338745, "action": 0.7414225935935974}
{"mode": "train", "epochs": 8, "timestep": 14083, "ep_reward": 50.909305572509766, "reward": 0.6510489583015442, "action": -0.5839453935623169}
{"mode": "train", "epochs": 8, "timestep": 14084, "ep_reward": 51.458377838134766, "reward": 0.5490731596946716, "action": -0.5804983973503113}
{"mode": "train", "epochs": 8, "timestep": 14085, "ep_reward": 51.887245178222656, "reward": 0.4288686513900757, "action": -1.451121211051941}
{"mode": "train", "epochs": 8, "timestep": 14086, "ep_reward": 52.1713752746582, "reward": 0.2841283082962036, "action": -0.5464269518852234}
{"mode": "train", "epochs": 8, "timestep": 14087, "ep_reward": 52.31472396850586, "reward": 0.14334994554519653, "action": -0.8195255398750305}
{"mode": "train", "epochs": 8, "timestep": 14088, "ep_reward": 52.557212829589844, "reward": 0.24249005317687988, "action": -1.7408976554870605}
{"mode": "train", "epochs": 8, "timestep": 14089, "ep_reward": 52.904441833496094, "reward": 0.34723079204559326, "action": -0.786445140838623}
{"mode": "train", "epochs": 8, "timestep": 14090, "ep_reward": 53.36693572998047, "reward": 0.4624927043914795, "action": -1.001430630683899}
{"mode": "train", "epochs": 8, "timestep": 14091, "ep_reward": 53.93559646606445, "reward": 0.5686599016189575, "action": -1.2285021543502808}
{"mode": "train", "epochs": 8, "timestep": 14092, "ep_reward": 54.596893310546875, "reward": 0.6612984538078308, "action": -0.8429916501045227}
{"mode": "train", "epochs": 8, "timestep": 14093, "ep_reward": 55.33935546875, "reward": 0.7424602508544922, "action": -1.2991987466812134}
{"mode": "train", "epochs": 8, "timestep": 14094, "ep_reward": 56.144187927246094, "reward": 0.8048334121704102, "action": -1.2293028831481934}
{"mode": "train", "epochs": 8, "timestep": 14095, "ep_reward": 56.99827194213867, "reward": 0.8540839552879333, "action": -1.0800398588180542}
{"mode": "train", "epochs": 8, "timestep": 14096, "ep_reward": 57.890541076660156, "reward": 0.8922677636146545, "action": -1.0328972339630127}
{"mode": "train", "epochs": 8, "timestep": 14097, "ep_reward": 58.81125259399414, "reward": 0.9207131266593933, "action": -1.7731194496154785}
{"mode": "train", "epochs": 8, "timestep": 14098, "ep_reward": 59.750526428222656, "reward": 0.9392727613449097, "action": -0.9017711281776428}
{"mode": "train", "epochs": 8, "timestep": 14099, "ep_reward": 60.70594024658203, "reward": 0.9554137587547302, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 14100, "ep_reward": 61.670448303222656, "reward": 0.9645096659660339, "action": -0.17795920372009277}
{"mode": "train", "epochs": 8, "timestep": 14101, "ep_reward": 62.64581298828125, "reward": 0.9753652215003967, "action": -1.0172573328018188}
{"mode": "train", "epochs": 8, "timestep": 14102, "ep_reward": 63.62708282470703, "reward": 0.9812707304954529, "action": -1.3561310768127441}
{"mode": "train", "epochs": 8, "timestep": 14103, "ep_reward": 64.61212921142578, "reward": 0.9850449562072754, "action": -0.12581026554107666}
{"mode": "train", "epochs": 8, "timestep": 14104, "ep_reward": 65.60179138183594, "reward": 0.9896658062934875, "action": -0.6037636995315552}
{"mode": "train", "epochs": 8, "timestep": 14105, "ep_reward": 66.59400177001953, "reward": 0.9922069311141968, "action": -0.8744927644729614}
{"mode": "train", "epochs": 8, "timestep": 14106, "ep_reward": 67.58770751953125, "reward": 0.993706226348877, "action": -0.325307160615921}
{"mode": "train", "epochs": 8, "timestep": 14107, "ep_reward": 68.58301544189453, "reward": 0.9953091740608215, "action": 0.8133684396743774}
{"mode": "train", "epochs": 8, "timestep": 14108, "ep_reward": 69.5804672241211, "reward": 0.9974506497383118, "action": 1.136090636253357}
{"mode": "train", "epochs": 8, "timestep": 14109, "ep_reward": 70.57923889160156, "reward": 0.9987745881080627, "action": 1.0222530364990234}
{"mode": "train", "epochs": 8, "timestep": 14110, "ep_reward": 71.57828521728516, "reward": 0.9990472197532654, "action": 0.7468798160552979}
{"mode": "train", "epochs": 8, "timestep": 14111, "ep_reward": 72.57662963867188, "reward": 0.9983416795730591, "action": 1.8520903587341309}
{"mode": "train", "epochs": 8, "timestep": 14112, "ep_reward": 73.5726089477539, "reward": 0.9959762692451477, "action": 0.5187680721282959}
{"mode": "train", "epochs": 8, "timestep": 14113, "ep_reward": 74.56587982177734, "reward": 0.9932676553726196, "action": 0.5286502242088318}
{"mode": "train", "epochs": 8, "timestep": 14114, "ep_reward": 75.55496978759766, "reward": 0.9890871047973633, "action": 0.583578884601593}
{"mode": "train", "epochs": 8, "timestep": 14115, "ep_reward": 76.53755950927734, "reward": 0.982589840888977, "action": 0.775334358215332}
{"mode": "train", "epochs": 8, "timestep": 14116, "ep_reward": 77.50971221923828, "reward": 0.9721499085426331, "action": 0.9361262321472168}
{"mode": "train", "epochs": 8, "timestep": 14117, "ep_reward": 78.4654769897461, "reward": 0.9557619690895081, "action": 1.1099035739898682}
{"mode": "train", "epochs": 8, "timestep": 14118, "ep_reward": 79.3958511352539, "reward": 0.9303774833679199, "action": 1.1136584281921387}
{"mode": "train", "epochs": 8, "timestep": 14119, "ep_reward": 80.28868103027344, "reward": 0.8928311467170715, "action": -1.1849617958068848}
{"mode": "train", "epochs": 8, "timestep": 14120, "ep_reward": 81.14561462402344, "reward": 0.8569338321685791, "action": -0.6292243003845215}
{"mode": "train", "epochs": 8, "timestep": 14121, "ep_reward": 81.94828033447266, "reward": 0.8026674389839172, "action": -1.222305417060852}
{"mode": "train", "epochs": 8, "timestep": 14122, "ep_reward": 82.68433380126953, "reward": 0.7360548377037048, "action": -0.7235479354858398}
{"mode": "train", "epochs": 8, "timestep": 14123, "ep_reward": 83.3291015625, "reward": 0.6447640657424927, "action": -0.8298422694206238}
{"mode": "train", "epochs": 8, "timestep": 14124, "ep_reward": 83.86213684082031, "reward": 0.5330347418785095, "action": -1.068387508392334}
{"mode": "train", "epochs": 8, "timestep": 14125, "ep_reward": 84.26795196533203, "reward": 0.40581387281417847, "action": -0.222304105758667}
{"mode": "train", "epochs": 8, "timestep": 14126, "ep_reward": 84.52180480957031, "reward": 0.2538508176803589, "action": -1.211530089378357}
{"mode": "train", "epochs": 8, "timestep": 14127, "ep_reward": 84.63457489013672, "reward": 0.1127704381942749, "action": -0.8686732649803162}
{"mode": "train", "epochs": 8, "timestep": 14128, "ep_reward": 84.79036712646484, "reward": 0.15579462051391602, "action": -0.7680949568748474}
{"mode": "train", "epochs": 8, "timestep": 14129, "ep_reward": 85.08773040771484, "reward": 0.2973628044128418, "action": -0.49956366419792175}
{"mode": "train", "epochs": 8, "timestep": 14130, "ep_reward": 85.5198745727539, "reward": 0.4321437478065491, "action": -1.1699786186218262}
{"mode": "train", "epochs": 8, "timestep": 14131, "ep_reward": 86.08196258544922, "reward": 0.5620864629745483, "action": -1.1550710201263428}
{"mode": "train", "epochs": 8, "timestep": 14132, "ep_reward": 86.75421905517578, "reward": 0.6722559928894043, "action": -0.14598065614700317}
{"mode": "train", "epochs": 8, "timestep": 14133, "ep_reward": 87.50798797607422, "reward": 0.7537698745727539, "action": 1.5528101921081543}
{"mode": "train", "epochs": 8, "timestep": 14134, "ep_reward": 88.31671905517578, "reward": 0.808729350566864, "action": 2.0}
{"mode": "train", "epochs": 8, "timestep": 14135, "ep_reward": 89.16722106933594, "reward": 0.8505046367645264, "action": 1.8332310914993286}
{"mode": "train", "epochs": 8, "timestep": 14136, "ep_reward": 90.05137634277344, "reward": 0.8841583728790283, "action": 0.8210248351097107}
{"mode": "train", "epochs": 8, "timestep": 14137, "ep_reward": 90.96410369873047, "reward": 0.9127295613288879, "action": 1.8546700477600098}
{"mode": "train", "epochs": 8, "timestep": 14138, "ep_reward": 91.8948974609375, "reward": 0.9307963848114014, "action": 1.5830862522125244}
{"mode": "train", "epochs": 8, "timestep": 14139, "ep_reward": 92.83960723876953, "reward": 0.944709062576294, "action": 1.1125268936157227}
{"mode": "train", "epochs": 8, "timestep": 14140, "ep_reward": 93.79463195800781, "reward": 0.9550220370292664, "action": 0.553045392036438}
{"mode": "train", "epochs": 8, "timestep": 14141, "ep_reward": 94.75591278076172, "reward": 0.9612833261489868, "action": 0.8123763799667358}
{"mode": "train", "epochs": 8, "timestep": 14142, "ep_reward": 95.71890258789062, "reward": 0.9629863500595093, "action": 0.9289646744728088}
{"mode": "train", "epochs": 8, "timestep": 14143, "ep_reward": 96.67972564697266, "reward": 0.9608264565467834, "action": 1.5042309761047363}
{"mode": "train", "epochs": 8, "timestep": 14144, "ep_reward": 97.63582611083984, "reward": 0.9561004042625427, "action": 0.8331477642059326}
{"mode": "train", "epochs": 8, "timestep": 14145, "ep_reward": 98.58195495605469, "reward": 0.9461277723312378, "action": 1.9711428880691528}
{"mode": "train", "epochs": 8, "timestep": 14146, "ep_reward": 99.516845703125, "reward": 0.9348925352096558, "action": 1.0245652198791504}
{"mode": "train", "epochs": 8, "timestep": 14147, "ep_reward": 100.43236541748047, "reward": 0.9155201315879822, "action": 1.2689706087112427}
{"mode": "train", "epochs": 8, "timestep": 14148, "ep_reward": 101.32193756103516, "reward": 0.8895735144615173, "action": 1.1402796506881714}
{"mode": "train", "epochs": 8, "timestep": 14149, "ep_reward": 102.17559051513672, "reward": 0.8536499738693237, "action": 0.920445442199707}
{"mode": "train", "epochs": 8, "timestep": 14150, "ep_reward": 102.97985076904297, "reward": 0.804262101650238, "action": -0.2510816752910614}
{"mode": "train", "epochs": 8, "timestep": 14151, "ep_reward": 103.70913696289062, "reward": 0.7292847633361816, "action": -0.7777612209320068}
{"mode": "train", "epochs": 8, "timestep": 14152, "ep_reward": 104.33539581298828, "reward": 0.6262611150741577, "action": -1.0992932319641113}
{"mode": "train", "epochs": 8, "timestep": 14153, "ep_reward": 104.82884216308594, "reward": 0.49344581365585327, "action": -1.320059061050415}
{"mode": "train", "epochs": 8, "timestep": 14154, "ep_reward": 105.16192626953125, "reward": 0.33308589458465576, "action": 0.01439213752746582}
{"mode": "train", "epochs": 8, "timestep": 14155, "ep_reward": 105.33821868896484, "reward": 0.17629212141036987, "action": -1.4014472961425781}
{"mode": "train", "epochs": 8, "timestep": 14156, "ep_reward": 105.40521240234375, "reward": 0.06699597835540771, "action": -1.120288610458374}
{"mode": "train", "epochs": 8, "timestep": 14157, "ep_reward": 105.59864807128906, "reward": 0.19343334436416626, "action": -1.0012505054473877}
{"mode": "train", "epochs": 8, "timestep": 14158, "ep_reward": 105.925048828125, "reward": 0.3263974189758301, "action": -0.04501765966415405}
{"mode": "train", "epochs": 8, "timestep": 14159, "ep_reward": 106.39176177978516, "reward": 0.46671009063720703, "action": -1.4925343990325928}
{"mode": "train", "epochs": 8, "timestep": 14160, "ep_reward": 106.9692153930664, "reward": 0.5774499177932739, "action": -1.1839344501495361}
{"mode": "train", "epochs": 8, "timestep": 14161, "ep_reward": 107.64434814453125, "reward": 0.67513507604599, "action": -1.5598585605621338}
{"mode": "train", "epochs": 8, "timestep": 14162, "ep_reward": 108.39456939697266, "reward": 0.7502242922782898, "action": -0.5196506977081299}
{"mode": "train", "epochs": 8, "timestep": 14163, "ep_reward": 109.20993041992188, "reward": 0.8153617978096008, "action": -0.9247239232063293}
{"mode": "train", "epochs": 8, "timestep": 14164, "ep_reward": 110.0690689086914, "reward": 0.8591368198394775, "action": -0.21062827110290527}
{"mode": "train", "epochs": 8, "timestep": 14165, "ep_reward": 110.96214294433594, "reward": 0.8930745720863342, "action": -1.0582629442214966}
{"mode": "train", "epochs": 8, "timestep": 14166, "ep_reward": 111.8707275390625, "reward": 0.9085866212844849, "action": -0.7472264766693115}
{"mode": "train", "epochs": 8, "timestep": 14167, "ep_reward": 112.78616333007812, "reward": 0.9154351949691772, "action": -1.097133755683899}
{"mode": "train", "epochs": 8, "timestep": 14168, "ep_reward": 113.69541931152344, "reward": 0.9092528223991394, "action": -1.1802778244018555}
{"mode": "train", "epochs": 8, "timestep": 14169, "ep_reward": 114.58561706542969, "reward": 0.8901986479759216, "action": -1.2353699207305908}
{"mode": "train", "epochs": 8, "timestep": 14170, "ep_reward": 115.44062042236328, "reward": 0.8550053238868713, "action": -1.368222713470459}
{"mode": "train", "epochs": 8, "timestep": 14171, "ep_reward": 116.23821258544922, "reward": 0.7975908517837524, "action": -1.1982601881027222}
{"mode": "train", "epochs": 8, "timestep": 14172, "ep_reward": 116.95211791992188, "reward": 0.7139067649841309, "action": -1.324408769607544}
{"mode": "train", "epochs": 8, "timestep": 14173, "ep_reward": 117.54583740234375, "reward": 0.593721866607666, "action": -0.5198577642440796}
{"mode": "train", "epochs": 8, "timestep": 14174, "ep_reward": 117.99099731445312, "reward": 0.4451601505279541, "action": -1.431869626045227}
{"mode": "train", "epochs": 8, "timestep": 14175, "ep_reward": 118.28693389892578, "reward": 0.2959362864494324, "action": -0.34088557958602905}
{"mode": "train", "epochs": 8, "timestep": 14176, "ep_reward": 118.46256256103516, "reward": 0.17562788724899292, "action": -0.7286013960838318}
{"mode": "train", "epochs": 8, "timestep": 14177, "ep_reward": 118.49790954589844, "reward": 0.03534466028213501, "action": -0.7369627952575684}
{"mode": "train", "epochs": 8, "timestep": 14178, "ep_reward": 118.58026123046875, "reward": 0.08235180377960205, "action": -1.4726366996765137}
{"mode": "train", "epochs": 8, "timestep": 14179, "ep_reward": 118.79657745361328, "reward": 0.2163127064704895, "action": -0.9051744937896729}
{"mode": "train", "epochs": 8, "timestep": 14180, "ep_reward": 119.15435028076172, "reward": 0.357769250869751, "action": -1.7696361541748047}
{"mode": "train", "epochs": 8, "timestep": 14181, "ep_reward": 119.63533782958984, "reward": 0.4809871315956116, "action": 0.25257420539855957}
{"mode": "train", "epochs": 8, "timestep": 14182, "ep_reward": 120.24713897705078, "reward": 0.6118015050888062, "action": -1.15241277217865}
{"mode": "train", "epochs": 8, "timestep": 14183, "ep_reward": 120.94975280761719, "reward": 0.7026146650314331, "action": -0.5302526950836182}
{"mode": "train", "epochs": 8, "timestep": 14184, "ep_reward": 121.72665405273438, "reward": 0.7768992185592651, "action": -0.5143347978591919}
{"mode": "train", "epochs": 8, "timestep": 14185, "ep_reward": 122.55613708496094, "reward": 0.8294834494590759, "action": -0.047397613525390625}
{"mode": "train", "epochs": 8, "timestep": 14186, "ep_reward": 123.42314910888672, "reward": 0.8670120239257812, "action": -1.0751218795776367}
{"mode": "train", "epochs": 8, "timestep": 14187, "ep_reward": 124.30353546142578, "reward": 0.8803889751434326, "action": -0.34991419315338135}
{"mode": "train", "epochs": 8, "timestep": 14188, "ep_reward": 125.18862915039062, "reward": 0.8850950002670288, "action": -0.322712779045105}
{"mode": "train", "epochs": 8, "timestep": 14189, "ep_reward": 126.0640640258789, "reward": 0.8754383325576782, "action": -0.7952435612678528}
{"mode": "train", "epochs": 8, "timestep": 14190, "ep_reward": 126.90933990478516, "reward": 0.8452739119529724, "action": -1.5295310020446777}
{"mode": "train", "epochs": 8, "timestep": 14191, "ep_reward": 127.69596099853516, "reward": 0.7866213321685791, "action": -1.1484415531158447}
{"mode": "train", "epochs": 8, "timestep": 14192, "ep_reward": 128.39834594726562, "reward": 0.7023807764053345, "action": -1.8985596895217896}
{"mode": "train", "epochs": 8, "timestep": 14193, "ep_reward": 128.9701385498047, "reward": 0.5717964768409729, "action": -0.882757306098938}
{"mode": "train", "epochs": 8, "timestep": 14194, "ep_reward": 129.382080078125, "reward": 0.4119415283203125, "action": -1.0749694108963013}
{"mode": "train", "epochs": 8, "timestep": 14195, "ep_reward": 129.67498779296875, "reward": 0.29290759563446045, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 14196, "ep_reward": 129.84732055664062, "reward": 0.17233651876449585, "action": -0.7429144382476807}
{"mode": "train", "epochs": 8, "timestep": 14197, "ep_reward": 129.87884521484375, "reward": 0.03153026103973389, "action": -0.9316480159759521}
{"mode": "train", "epochs": 8, "timestep": 14198, "ep_reward": 129.96481323242188, "reward": 0.08597433567047119, "action": -1.4582496881484985}
{"mode": "train", "epochs": 8, "timestep": 14199, "ep_reward": 130.1840362548828, "reward": 0.21923011541366577, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 14200, "ep_reward": 130.5312957763672, "reward": 0.34725409746170044, "action": -0.9925476312637329}
{"mode": "train", "epochs": 8, "timestep": 14201, "ep_reward": 131.01332092285156, "reward": 0.482019305229187, "action": -0.4494665861129761}
{"mode": "train", "epochs": 8, "timestep": 14202, "ep_reward": 131.6183319091797, "reward": 0.6050134897232056, "action": -1.4890563488006592}
{"mode": "train", "epochs": 8, "timestep": 14203, "ep_reward": 132.31130981445312, "reward": 0.6929831504821777, "action": -1.0366097688674927}
{"mode": "train", "epochs": 8, "timestep": 14204, "ep_reward": 133.07406616210938, "reward": 0.7627491354942322, "action": -0.022912800312042236}
{"mode": "train", "epochs": 8, "timestep": 14205, "ep_reward": 133.893310546875, "reward": 0.8192399740219116, "action": -1.151153802871704}
{"mode": "train", "epochs": 8, "timestep": 14206, "ep_reward": 134.73825073242188, "reward": 0.844937264919281, "action": -0.3829975128173828}
{"mode": "train", "epochs": 8, "timestep": 14207, "ep_reward": 135.59742736816406, "reward": 0.8591723442077637, "action": -1.8329501152038574}
{"mode": "train", "epochs": 8, "timestep": 14208, "ep_reward": 136.44004821777344, "reward": 0.8426276445388794, "action": -1.4911761283874512}
{"mode": "train", "epochs": 8, "timestep": 14209, "ep_reward": 137.24766540527344, "reward": 0.8076119422912598, "action": -1.6787192821502686}
{"mode": "train", "epochs": 8, "timestep": 14210, "ep_reward": 137.9911346435547, "reward": 0.7434762120246887, "action": -1.3605848550796509}
{"mode": "train", "epochs": 8, "timestep": 14211, "ep_reward": 138.63926696777344, "reward": 0.6481281518936157, "action": -1.098280906677246}
{"mode": "train", "epochs": 8, "timestep": 14212, "ep_reward": 139.1538543701172, "reward": 0.514589786529541, "action": -1.6062562465667725}
{"mode": "train", "epochs": 8, "timestep": 14213, "ep_reward": 139.53543090820312, "reward": 0.3815762400627136, "action": -1.7164591550827026}
{"mode": "train", "epochs": 8, "timestep": 14214, "ep_reward": 139.81370544433594, "reward": 0.2782711982727051, "action": -0.9554926156997681}
{"mode": "train", "epochs": 8, "timestep": 14215, "ep_reward": 139.96853637695312, "reward": 0.1548250913619995, "action": -1.066043734550476}
{"mode": "train", "epochs": 8, "timestep": 14216, "ep_reward": 139.97996520996094, "reward": 0.011426985263824463, "action": -0.7708699107170105}
{"mode": "train", "epochs": 8, "timestep": 14217, "ep_reward": 140.08474731445312, "reward": 0.10478830337524414, "action": -1.3188766241073608}
{"mode": "train", "epochs": 8, "timestep": 14218, "ep_reward": 140.32386779785156, "reward": 0.23911350965499878, "action": -1.5942692756652832}
{"mode": "train", "epochs": 8, "timestep": 14219, "ep_reward": 140.69529724121094, "reward": 0.3714327812194824, "action": -1.4015843868255615}
{"mode": "train", "epochs": 8, "timestep": 14220, "ep_reward": 141.19358825683594, "reward": 0.4982879161834717, "action": -1.019302487373352}
{"mode": "train", "epochs": 8, "timestep": 14221, "ep_reward": 141.80577087402344, "reward": 0.6121854782104492, "action": -1.2317472696304321}
{"mode": "train", "epochs": 8, "timestep": 14222, "ep_reward": 142.50640869140625, "reward": 0.700637936592102, "action": -1.8862509727478027}
{"mode": "train", "epochs": 8, "timestep": 14223, "ep_reward": 143.265869140625, "reward": 0.7594661712646484, "action": -0.011942744255065918}
{"mode": "train", "epochs": 8, "timestep": 14224, "ep_reward": 144.08009338378906, "reward": 0.8142189383506775, "action": -1.406883716583252}
{"mode": "train", "epochs": 8, "timestep": 14225, "ep_reward": 144.9146270751953, "reward": 0.834531843662262, "action": -1.2014154195785522}
{"mode": "train", "epochs": 8, "timestep": 14226, "ep_reward": 145.75184631347656, "reward": 0.8372251391410828, "action": -0.9309439659118652}
{"mode": "train", "epochs": 8, "timestep": 14227, "ep_reward": 146.5736846923828, "reward": 0.8218423128128052, "action": -0.22216874361038208}
{"mode": "train", "epochs": 8, "timestep": 14228, "ep_reward": 147.36412048339844, "reward": 0.7904356718063354, "action": -1.5305278301239014}
{"mode": "train", "epochs": 8, "timestep": 14229, "ep_reward": 148.0811767578125, "reward": 0.7170496582984924, "action": -1.523857593536377}
{"mode": "train", "epochs": 8, "timestep": 14230, "ep_reward": 148.68748474121094, "reward": 0.6063016653060913, "action": -0.8707327842712402}
{"mode": "train", "epochs": 8, "timestep": 14231, "ep_reward": 149.1484375, "reward": 0.4609453082084656, "action": -1.1119977235794067}
{"mode": "train", "epochs": 8, "timestep": 14232, "ep_reward": 149.49673461914062, "reward": 0.348294198513031, "action": -1.4264485836029053}
{"mode": "train", "epochs": 8, "timestep": 14233, "ep_reward": 149.73464965820312, "reward": 0.23790967464447021, "action": -1.7735059261322021}
{"mode": "train", "epochs": 8, "timestep": 14234, "ep_reward": 149.84228515625, "reward": 0.1076391339302063, "action": -1.5598299503326416}
{"mode": "train", "epochs": 8, "timestep": 14235, "ep_reward": 149.85040283203125, "reward": 0.008114993572235107, "action": -1.7195930480957031}
{"mode": "train", "epochs": 8, "timestep": 14236, "ep_reward": 150.00241088867188, "reward": 0.15201538801193237, "action": -1.4329681396484375}
{"mode": "train", "epochs": 8, "timestep": 14237, "ep_reward": 150.2886505126953, "reward": 0.28624069690704346, "action": -0.864532470703125}
{"mode": "train", "epochs": 8, "timestep": 14238, "ep_reward": 150.71437072753906, "reward": 0.42572182416915894, "action": -0.62320876121521}
{"mode": "train", "epochs": 8, "timestep": 14239, "ep_reward": 151.26902770996094, "reward": 0.5546584725379944, "action": -0.9577260613441467}
{"mode": "train", "epochs": 8, "timestep": 14240, "ep_reward": 151.92816162109375, "reward": 0.6591349840164185, "action": -0.3115583062171936}
{"mode": "train", "epochs": 8, "timestep": 14241, "ep_reward": 152.67514038085938, "reward": 0.7469800710678101, "action": -1.3337162733078003}
{"mode": "train", "epochs": 8, "timestep": 14242, "ep_reward": 153.4778289794922, "reward": 0.8026810884475708, "action": -0.3029715418815613}
{"mode": "train", "epochs": 8, "timestep": 14243, "ep_reward": 154.325927734375, "reward": 0.8481038808822632, "action": -0.6357731819152832}
{"mode": "train", "epochs": 8, "timestep": 14244, "ep_reward": 155.1990966796875, "reward": 0.8731690645217896, "action": -1.374825119972229}
{"mode": "train", "epochs": 8, "timestep": 14245, "ep_reward": 156.07635498046875, "reward": 0.8772627711296082, "action": -0.7921367883682251}
{"mode": "train", "epochs": 8, "timestep": 14246, "ep_reward": 156.9470977783203, "reward": 0.8707483410835266, "action": -1.1761181354522705}
{"mode": "train", "epochs": 8, "timestep": 14247, "ep_reward": 157.79086303710938, "reward": 0.8437594175338745, "action": -1.0435669422149658}
{"mode": "train", "epochs": 8, "timestep": 14248, "ep_reward": 158.5873565673828, "reward": 0.796491265296936, "action": -0.5215375423431396}
{"mode": "train", "epochs": 8, "timestep": 14249, "ep_reward": 159.31509399414062, "reward": 0.7277380228042603, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 14250, "ep_reward": 159.92236328125, "reward": 0.6072646379470825, "action": -0.8399710655212402}
{"mode": "train", "epochs": 8, "timestep": 14251, "ep_reward": 160.3818359375, "reward": 0.4594745635986328, "action": -0.9537244439125061}
{"mode": "train", "epochs": 8, "timestep": 14252, "ep_reward": 160.70814514160156, "reward": 0.3263077139854431, "action": -0.9420338273048401}
{"mode": "train", "epochs": 8, "timestep": 14253, "ep_reward": 160.91986083984375, "reward": 0.21171700954437256, "action": -0.6339493989944458}
{"mode": "train", "epochs": 8, "timestep": 14254, "ep_reward": 160.9968719482422, "reward": 0.0770111083984375, "action": -1.3253757953643799}
{"mode": "train", "epochs": 8, "timestep": 14255, "ep_reward": 161.03778076171875, "reward": 0.04090684652328491, "action": -0.890144944190979}
{"mode": "train", "epochs": 8, "timestep": 14256, "ep_reward": 161.2182159423828, "reward": 0.1804305911064148, "action": -1.0179866552352905}
{"mode": "train", "epochs": 8, "timestep": 14257, "ep_reward": 161.53834533691406, "reward": 0.3201271891593933, "action": -1.9517302513122559}
{"mode": "train", "epochs": 8, "timestep": 14258, "ep_reward": 161.9821319580078, "reward": 0.4437931180000305, "action": -1.4577816724777222}
{"mode": "train", "epochs": 8, "timestep": 14259, "ep_reward": 162.54339599609375, "reward": 0.5612583160400391, "action": -1.0845391750335693}
{"mode": "train", "epochs": 8, "timestep": 14260, "ep_reward": 163.20579528808594, "reward": 0.6624035835266113, "action": -1.417392611503601}
{"mode": "train", "epochs": 8, "timestep": 14261, "ep_reward": 163.94210815429688, "reward": 0.7363054156303406, "action": -1.314309000968933}
{"mode": "train", "epochs": 8, "timestep": 14262, "ep_reward": 164.7305145263672, "reward": 0.788410484790802, "action": -0.9265159368515015}
{"mode": "train", "epochs": 8, "timestep": 14263, "ep_reward": 165.55300903320312, "reward": 0.8224931955337524, "action": -1.1538562774658203}
{"mode": "train", "epochs": 8, "timestep": 14264, "ep_reward": 166.38694763183594, "reward": 0.833935022354126, "action": -0.9324445724487305}
{"mode": "train", "epochs": 8, "timestep": 14265, "ep_reward": 167.21389770507812, "reward": 0.826946496963501, "action": -0.5376366376876831}
{"mode": "train", "epochs": 8, "timestep": 14266, "ep_reward": 168.01531982421875, "reward": 0.8014198541641235, "action": -1.4357328414916992}
{"mode": "train", "epochs": 8, "timestep": 14267, "ep_reward": 168.755126953125, "reward": 0.7398110032081604, "action": -0.6468816995620728}
{"mode": "train", "epochs": 8, "timestep": 14268, "ep_reward": 169.4088134765625, "reward": 0.6536885499954224, "action": -0.20519405603408813}
{"mode": "train", "epochs": 8, "timestep": 14269, "ep_reward": 169.94430541992188, "reward": 0.5354906320571899, "action": -0.3265969753265381}
{"mode": "train", "epochs": 8, "timestep": 14270, "ep_reward": 170.330078125, "reward": 0.38577091693878174, "action": -1.3848546743392944}
{"mode": "train", "epochs": 8, "timestep": 14271, "ep_reward": 170.61334228515625, "reward": 0.28326350450515747, "action": -1.1519767045974731}
{"mode": "train", "epochs": 8, "timestep": 14272, "ep_reward": 170.77406311035156, "reward": 0.16072022914886475, "action": -1.1437816619873047}
{"mode": "train", "epochs": 8, "timestep": 14273, "ep_reward": 170.792236328125, "reward": 0.01817190647125244, "action": -1.1692875623703003}
{"mode": "train", "epochs": 8, "timestep": 14274, "ep_reward": 170.89076232910156, "reward": 0.09852182865142822, "action": -1.3103657960891724}
{"mode": "train", "epochs": 8, "timestep": 14275, "ep_reward": 171.12362670898438, "reward": 0.2328680157661438, "action": -0.9888622164726257}
{"mode": "train", "epochs": 8, "timestep": 14276, "ep_reward": 171.49647521972656, "reward": 0.37284451723098755, "action": -1.3380467891693115}
{"mode": "train", "epochs": 8, "timestep": 14277, "ep_reward": 171.99609375, "reward": 0.4996183514595032, "action": -1.4315814971923828}
{"mode": "train", "epochs": 8, "timestep": 14278, "ep_reward": 172.6048583984375, "reward": 0.6087626218795776, "action": -0.8171796202659607}
{"mode": "train", "epochs": 8, "timestep": 14279, "ep_reward": 173.30763244628906, "reward": 0.7027744054794312, "action": -0.5181753635406494}
{"mode": "train", "epochs": 8, "timestep": 14280, "ep_reward": 174.08323669433594, "reward": 0.7756010890007019, "action": -0.8985293507575989}
{"mode": "train", "epochs": 8, "timestep": 14281, "ep_reward": 174.90582275390625, "reward": 0.8225797414779663, "action": -0.9334486722946167}
{"mode": "train", "epochs": 8, "timestep": 14282, "ep_reward": 175.75588989257812, "reward": 0.8500629663467407, "action": -0.9536663293838501}
{"mode": "train", "epochs": 8, "timestep": 14283, "ep_reward": 176.61575317382812, "reward": 0.8598558902740479, "action": -0.7162573337554932}
{"mode": "train", "epochs": 8, "timestep": 14284, "ep_reward": 177.4700164794922, "reward": 0.8542689681053162, "action": -1.0226538181304932}
{"mode": "train", "epochs": 8, "timestep": 14285, "ep_reward": 178.29676818847656, "reward": 0.8267493844032288, "action": -0.9557204246520996}
{"mode": "train", "epochs": 8, "timestep": 14286, "ep_reward": 179.07325744628906, "reward": 0.7764840722084045, "action": -0.4499892592430115}
{"mode": "train", "epochs": 8, "timestep": 14287, "ep_reward": 179.77621459960938, "reward": 0.7029564380645752, "action": -1.1962162256240845}
{"mode": "train", "epochs": 8, "timestep": 14288, "ep_reward": 180.3612518310547, "reward": 0.5850346684455872, "action": -1.633598804473877}
{"mode": "train", "epochs": 8, "timestep": 14289, "ep_reward": 180.77883911132812, "reward": 0.41758298873901367, "action": -1.2553293704986572}
{"mode": "train", "epochs": 8, "timestep": 14290, "ep_reward": 181.08811950683594, "reward": 0.3092758059501648, "action": -0.42529773712158203}
{"mode": "train", "epochs": 8, "timestep": 14291, "ep_reward": 181.27951049804688, "reward": 0.1913928985595703, "action": -0.9645326733589172}
{"mode": "train", "epochs": 8, "timestep": 14292, "ep_reward": 181.33309936523438, "reward": 0.05359464883804321, "action": -0.5686747431755066}
{"mode": "train", "epochs": 8, "timestep": 14293, "ep_reward": 181.39781188964844, "reward": 0.06471318006515503, "action": -0.6060384511947632}
{"mode": "train", "epochs": 8, "timestep": 14294, "ep_reward": 181.6046142578125, "reward": 0.2067973017692566, "action": -0.9730350375175476}
{"mode": "train", "epochs": 8, "timestep": 14295, "ep_reward": 181.9508514404297, "reward": 0.3462405800819397, "action": -1.2691806554794312}
{"mode": "train", "epochs": 8, "timestep": 14296, "ep_reward": 182.4264678955078, "reward": 0.47561436891555786, "action": -0.8463922739028931}
{"mode": "train", "epochs": 8, "timestep": 14297, "ep_reward": 183.02122497558594, "reward": 0.5947613716125488, "action": -1.2754085063934326}
{"mode": "train", "epochs": 8, "timestep": 14298, "ep_reward": 183.70916748046875, "reward": 0.6879353523254395, "action": -1.1695942878723145}
{"mode": "train", "epochs": 8, "timestep": 14299, "ep_reward": 184.4693145751953, "reward": 0.7601456642150879, "action": -0.5863468647003174}
{"mode": "train", "epochs": 8, "timestep": 14300, "ep_reward": 185.28549194335938, "reward": 0.8161699771881104, "action": -1.0763901472091675}
{"mode": "train", "epochs": 8, "timestep": 14301, "ep_reward": 186.13385009765625, "reward": 0.8483530879020691, "action": -0.5281423330307007}
{"mode": "train", "epochs": 8, "timestep": 14302, "ep_reward": 187.0018310546875, "reward": 0.8679759502410889, "action": -1.0297540426254272}
{"mode": "train", "epochs": 8, "timestep": 14303, "ep_reward": 187.86880493164062, "reward": 0.8669676780700684, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 14304, "ep_reward": 188.70875549316406, "reward": 0.8399500846862793, "action": -1.0131824016571045}
{"mode": "train", "epochs": 8, "timestep": 14305, "ep_reward": 189.5085906982422, "reward": 0.7998316884040833, "action": -1.1362229585647583}
{"mode": "train", "epochs": 8, "timestep": 14306, "ep_reward": 190.2398223876953, "reward": 0.7312355637550354, "action": -1.5253610610961914}
{"mode": "train", "epochs": 8, "timestep": 14307, "ep_reward": 190.86276245117188, "reward": 0.6229469776153564, "action": -1.2872939109802246}
{"mode": "train", "epochs": 8, "timestep": 14308, "ep_reward": 191.3376922607422, "reward": 0.4749232530593872, "action": -1.396048665046692}
{"mode": "train", "epochs": 8, "timestep": 14309, "ep_reward": 191.68690490722656, "reward": 0.3492138385772705, "action": -1.9072198867797852}
{"mode": "train", "epochs": 8, "timestep": 14310, "ep_reward": 191.9261932373047, "reward": 0.23929011821746826, "action": -0.7883493304252625}
{"mode": "train", "epochs": 8, "timestep": 14311, "ep_reward": 192.035400390625, "reward": 0.1092061996459961, "action": -0.4080577492713928}
{"mode": "train", "epochs": 8, "timestep": 14312, "ep_reward": 192.04202270507812, "reward": 0.006629824638366699, "action": -1.2999005317687988}
{"mode": "train", "epochs": 8, "timestep": 14313, "ep_reward": 192.1927490234375, "reward": 0.15072447061538696, "action": -0.9703826904296875}
{"mode": "train", "epochs": 8, "timestep": 14314, "ep_reward": 192.4833526611328, "reward": 0.2906101942062378, "action": -1.271954894065857}
{"mode": "train", "epochs": 8, "timestep": 14315, "ep_reward": 192.907470703125, "reward": 0.4241209030151367, "action": -0.4055309295654297}
{"mode": "train", "epochs": 8, "timestep": 14316, "ep_reward": 193.4630126953125, "reward": 0.555538535118103, "action": -1.6176284551620483}
{"mode": "train", "epochs": 8, "timestep": 14317, "ep_reward": 194.1160125732422, "reward": 0.6529964804649353, "action": -0.829318642616272}
{"mode": "train", "epochs": 8, "timestep": 14318, "ep_reward": 194.85304260253906, "reward": 0.7370288372039795, "action": -1.7551920413970947}
{"mode": "train", "epochs": 8, "timestep": 14319, "ep_reward": 195.6431884765625, "reward": 0.7901437878608704, "action": -1.1474107503890991}
{"mode": "train", "epochs": 8, "timestep": 14320, "ep_reward": 196.4723358154297, "reward": 0.8291519284248352, "action": -1.2024554014205933}
{"mode": "train", "epochs": 8, "timestep": 14321, "ep_reward": 197.32130432128906, "reward": 0.8489638566970825, "action": -1.3489954471588135}
{"mode": "train", "epochs": 8, "timestep": 14322, "ep_reward": 198.17083740234375, "reward": 0.8495258688926697, "action": -0.9337896108627319}
{"mode": "train", "epochs": 8, "timestep": 14323, "ep_reward": 199.00546264648438, "reward": 0.8346311450004578, "action": -1.3070327043533325}
{"mode": "train", "epochs": 8, "timestep": 14324, "ep_reward": 199.7993621826172, "reward": 0.7938929200172424, "action": -0.7843301296234131}
{"mode": "train", "epochs": 8, "timestep": 14325, "ep_reward": 200.53036499023438, "reward": 0.7310048341751099, "action": -0.45694655179977417}
{"mode": "train", "epochs": 8, "timestep": 14326, "ep_reward": 201.16932678222656, "reward": 0.638958215713501, "action": -1.4524660110473633}
{"mode": "train", "epochs": 8, "timestep": 14327, "ep_reward": 201.6632843017578, "reward": 0.4939568042755127, "action": -0.14684957265853882}
{"mode": "train", "epochs": 8, "timestep": 14328, "ep_reward": 202.02304077148438, "reward": 0.3597499132156372, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 14329, "ep_reward": 202.2750244140625, "reward": 0.2519844174385071, "action": -0.7529879808425903}
{"mode": "train", "epochs": 8, "timestep": 14330, "ep_reward": 202.3990478515625, "reward": 0.1240202784538269, "action": -0.5565478801727295}
{"mode": "train", "epochs": 8, "timestep": 14331, "ep_reward": 202.38922119140625, "reward": -0.009827375411987305, "action": -0.6563681960105896}
{"mode": "train", "epochs": 8, "timestep": 14332, "ep_reward": 202.5255584716797, "reward": 0.13633191585540771, "action": -0.8723130226135254}
{"mode": "train", "epochs": 8, "timestep": 14333, "ep_reward": 202.8026885986328, "reward": 0.2771322727203369, "action": -1.0811289548873901}
{"mode": "train", "epochs": 8, "timestep": 14334, "ep_reward": 203.216064453125, "reward": 0.4133705496788025, "action": -0.8359661102294922}
{"mode": "train", "epochs": 8, "timestep": 14335, "ep_reward": 203.75709533691406, "reward": 0.5410289168357849, "action": -1.4553649425506592}
{"mode": "train", "epochs": 8, "timestep": 14336, "ep_reward": 204.39984130859375, "reward": 0.6427392363548279, "action": -1.3299720287322998}
{"mode": "train", "epochs": 8, "timestep": 14337, "ep_reward": 205.1243438720703, "reward": 0.7245007753372192, "action": -1.237510085105896}
{"mode": "train", "epochs": 8, "timestep": 14338, "ep_reward": 205.9096221923828, "reward": 0.7852813601493835, "action": -0.8395830392837524}
{"mode": "train", "epochs": 8, "timestep": 14339, "ep_reward": 206.73867797851562, "reward": 0.82905513048172, "action": -0.5285866260528564}
{"mode": "train", "epochs": 8, "timestep": 14340, "ep_reward": 207.5950927734375, "reward": 0.8564211130142212, "action": -1.7514015436172485}
{"mode": "train", "epochs": 8, "timestep": 14341, "ep_reward": 208.45114135742188, "reward": 0.856053352355957, "action": -1.1893558502197266}
{"mode": "train", "epochs": 8, "timestep": 14342, "ep_reward": 209.29342651367188, "reward": 0.8422896862030029, "action": -1.3904104232788086}
{"mode": "train", "epochs": 8, "timestep": 14343, "ep_reward": 210.0986785888672, "reward": 0.8052477240562439, "action": -1.3640611171722412}
{"mode": "train", "epochs": 8, "timestep": 14344, "ep_reward": 210.84011840820312, "reward": 0.741439163684845, "action": -0.724659264087677}
{"mode": "train", "epochs": 8, "timestep": 14345, "ep_reward": 211.49168395996094, "reward": 0.651565432548523, "action": -1.1061190366744995}
{"mode": "train", "epochs": 8, "timestep": 14346, "ep_reward": 212.009033203125, "reward": 0.5173429846763611, "action": -0.5187514424324036}
{"mode": "train", "epochs": 8, "timestep": 14347, "ep_reward": 212.38417053222656, "reward": 0.37514352798461914, "action": -0.5968564748764038}
{"mode": "train", "epochs": 8, "timestep": 14348, "ep_reward": 212.6544189453125, "reward": 0.270241916179657, "action": -1.2009944915771484}
{"mode": "train", "epochs": 8, "timestep": 14349, "ep_reward": 212.79983520507812, "reward": 0.14541786909103394, "action": -1.1326853036880493}
{"mode": "train", "epochs": 8, "timestep": 14350, "ep_reward": 212.8004913330078, "reward": 0.0006570219993591309, "action": -0.33436572551727295}
{"mode": "train", "epochs": 8, "timestep": 14351, "ep_reward": 212.91519165039062, "reward": 0.11470448970794678, "action": -0.27976053953170776}
{"mode": "train", "epochs": 8, "timestep": 14352, "ep_reward": 213.17747497558594, "reward": 0.2622869610786438, "action": -0.9538761973381042}
{"mode": "train", "epochs": 8, "timestep": 14353, "ep_reward": 213.5769500732422, "reward": 0.39947545528411865, "action": -0.9970319271087646}
{"mode": "train", "epochs": 8, "timestep": 14354, "ep_reward": 214.10317993164062, "reward": 0.5262237787246704, "action": -0.8247179985046387}
{"mode": "train", "epochs": 8, "timestep": 14355, "ep_reward": 214.74017333984375, "reward": 0.6370003819465637, "action": -1.7324373722076416}
{"mode": "train", "epochs": 8, "timestep": 14356, "ep_reward": 215.45745849609375, "reward": 0.717287540435791, "action": -0.745674729347229}
{"mode": "train", "epochs": 8, "timestep": 14357, "ep_reward": 216.24365234375, "reward": 0.7861968874931335, "action": -1.2473206520080566}
{"mode": "train", "epochs": 8, "timestep": 14358, "ep_reward": 217.07388305664062, "reward": 0.8302276134490967, "action": -0.7354295253753662}
{"mode": "train", "epochs": 8, "timestep": 14359, "ep_reward": 217.9347381591797, "reward": 0.8608587980270386, "action": -0.7906259894371033}
{"mode": "train", "epochs": 8, "timestep": 14360, "ep_reward": 218.8095703125, "reward": 0.8748263120651245, "action": -0.8178704977035522}
{"mode": "train", "epochs": 8, "timestep": 14361, "ep_reward": 219.68275451660156, "reward": 0.8731783628463745, "action": -0.6820216178894043}
{"mode": "train", "epochs": 8, "timestep": 14362, "ep_reward": 220.53895568847656, "reward": 0.8561965823173523, "action": -1.610302209854126}
{"mode": "train", "epochs": 8, "timestep": 14363, "ep_reward": 221.3498992919922, "reward": 0.8109411597251892, "action": -1.533978819847107}
{"mode": "train", "epochs": 8, "timestep": 14364, "ep_reward": 222.08924865722656, "reward": 0.7393515110015869, "action": -0.8003032803535461}
{"mode": "train", "epochs": 8, "timestep": 14365, "ep_reward": 222.731689453125, "reward": 0.6424428224563599, "action": -1.025262475013733}
{"mode": "train", "epochs": 8, "timestep": 14366, "ep_reward": 223.2353973388672, "reward": 0.50370192527771, "action": -0.7350480556488037}
{"mode": "train", "epochs": 8, "timestep": 14367, "ep_reward": 223.58973693847656, "reward": 0.35434019565582275, "action": -1.1568723917007446}
{"mode": "train", "epochs": 8, "timestep": 14368, "ep_reward": 223.83494567871094, "reward": 0.24520355463027954, "action": -1.3177021741867065}
{"mode": "train", "epochs": 8, "timestep": 14369, "ep_reward": 223.95101928710938, "reward": 0.11607116460800171, "action": -1.4367812871932983}
{"mode": "train", "epochs": 8, "timestep": 14370, "ep_reward": 223.94976806640625, "reward": -0.001245260238647461, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 14371, "ep_reward": 224.09376525878906, "reward": 0.14399874210357666, "action": -0.932144045829773}
{"mode": "train", "epochs": 8, "timestep": 14372, "ep_reward": 224.3779754638672, "reward": 0.28420448303222656, "action": -1.3050992488861084}
{"mode": "train", "epochs": 8, "timestep": 14373, "ep_reward": 224.79534912109375, "reward": 0.4173774719238281, "action": -1.7777502536773682}
{"mode": "train", "epochs": 8, "timestep": 14374, "ep_reward": 225.32952880859375, "reward": 0.5341764688491821, "action": -0.6364389657974243}
{"mode": "train", "epochs": 8, "timestep": 14375, "ep_reward": 225.97531127929688, "reward": 0.6457763910293579, "action": -0.8842973113059998}
{"mode": "train", "epochs": 8, "timestep": 14376, "ep_reward": 226.70602416992188, "reward": 0.7307195067405701, "action": -0.7264407873153687}
{"mode": "train", "epochs": 8, "timestep": 14377, "ep_reward": 227.50001525878906, "reward": 0.7939976453781128, "action": -1.330812931060791}
{"mode": "train", "epochs": 8, "timestep": 14378, "ep_reward": 228.33106994628906, "reward": 0.8310542702674866, "action": -1.1584184169769287}
{"mode": "train", "epochs": 8, "timestep": 14379, "ep_reward": 229.18240356445312, "reward": 0.8513385057449341, "action": -1.1861799955368042}
{"mode": "train", "epochs": 8, "timestep": 14380, "ep_reward": 230.03616333007812, "reward": 0.8537622094154358, "action": -0.47459566593170166}
{"mode": "train", "epochs": 8, "timestep": 14381, "ep_reward": 230.88035583496094, "reward": 0.8441988229751587, "action": -0.17233043909072876}
{"mode": "train", "epochs": 8, "timestep": 14382, "ep_reward": 231.6978759765625, "reward": 0.8175216913223267, "action": -0.7730709314346313}
{"mode": "train", "epochs": 8, "timestep": 14383, "ep_reward": 232.45901489257812, "reward": 0.7611452341079712, "action": -0.8833814859390259}
{"mode": "train", "epochs": 8, "timestep": 14384, "ep_reward": 233.13189697265625, "reward": 0.6728800535202026, "action": -1.839288353919983}
{"mode": "train", "epochs": 8, "timestep": 14385, "ep_reward": 233.6652069091797, "reward": 0.5333124995231628, "action": -1.6705224514007568}
{"mode": "train", "epochs": 8, "timestep": 14386, "ep_reward": 234.04364013671875, "reward": 0.37842655181884766, "action": -1.6000311374664307}
{"mode": "train", "epochs": 8, "timestep": 14387, "ep_reward": 234.31809997558594, "reward": 0.2744605541229248, "action": 0.5109076499938965}
{"mode": "train", "epochs": 8, "timestep": 14388, "ep_reward": 234.46829223632812, "reward": 0.1501980423927307, "action": -1.6449756622314453}
{"mode": "train", "epochs": 8, "timestep": 14389, "ep_reward": 234.4744415283203, "reward": 0.006148695945739746, "action": -1.3173917531967163}
{"mode": "train", "epochs": 8, "timestep": 14390, "ep_reward": 234.58387756347656, "reward": 0.10943114757537842, "action": -1.8774687051773071}
{"mode": "train", "epochs": 8, "timestep": 14391, "ep_reward": 234.8235626220703, "reward": 0.23967987298965454, "action": -0.5916374921798706}
{"mode": "train", "epochs": 8, "timestep": 14392, "ep_reward": 235.20860290527344, "reward": 0.38503575325012207, "action": -1.336293339729309}
{"mode": "train", "epochs": 8, "timestep": 14393, "ep_reward": 235.71923828125, "reward": 0.5106291770935059, "action": -0.5410839915275574}
{"mode": "train", "epochs": 8, "timestep": 14394, "ep_reward": 236.34669494628906, "reward": 0.6274566650390625, "action": -1.6177579164505005}
{"mode": "train", "epochs": 8, "timestep": 14395, "ep_reward": 237.05661010742188, "reward": 0.709909200668335, "action": -0.6587395668029785}
{"mode": "train", "epochs": 8, "timestep": 14396, "ep_reward": 237.83633422851562, "reward": 0.7797219753265381, "action": -1.1259657144546509}
{"mode": "train", "epochs": 8, "timestep": 14397, "ep_reward": 238.659912109375, "reward": 0.8235741257667542, "action": -0.7425093054771423}
{"mode": "train", "epochs": 8, "timestep": 14398, "ep_reward": 239.51182556152344, "reward": 0.8519128561019897, "action": -0.13945555686950684}
{"mode": "train", "epochs": 8, "timestep": 14399, "ep_reward": 240.37960815429688, "reward": 0.8677895069122314, "action": -1.4439358711242676}
{"mode": "train", "epochs": 8, "timestep": 14400, "ep_reward": 241.2353515625, "reward": 0.8557388782501221, "action": -0.4907223582267761}
{"mode": "train", "epochs": 8, "timestep": 14401, "ep_reward": 242.06869506835938, "reward": 0.8333435654640198, "action": -0.5259951949119568}
{"mode": "train", "epochs": 8, "timestep": 14402, "ep_reward": 242.8574981689453, "reward": 0.7888067960739136, "action": -1.2399548292160034}
{"mode": "train", "epochs": 8, "timestep": 14403, "ep_reward": 243.56626892089844, "reward": 0.7087640762329102, "action": -1.7488385438919067}
{"mode": "train", "epochs": 8, "timestep": 14404, "ep_reward": 244.15164184570312, "reward": 0.5853791236877441, "action": -0.09512978792190552}
{"mode": "train", "epochs": 8, "timestep": 14405, "ep_reward": 244.59474182128906, "reward": 0.44310230016708374, "action": -1.0703438520431519}
{"mode": "train", "epochs": 8, "timestep": 14406, "ep_reward": 244.90997314453125, "reward": 0.3152293562889099, "action": -1.5592153072357178}
{"mode": "train", "epochs": 8, "timestep": 14407, "ep_reward": 245.1085205078125, "reward": 0.19854342937469482, "action": -1.486295223236084}
{"mode": "train", "epochs": 8, "timestep": 14408, "ep_reward": 245.17042541503906, "reward": 0.061906635761260986, "action": -1.0941834449768066}
{"mode": "train", "epochs": 8, "timestep": 14409, "ep_reward": 245.2267303466797, "reward": 0.056300222873687744, "action": -1.2043342590332031}
{"mode": "train", "epochs": 8, "timestep": 14410, "ep_reward": 245.4205780029297, "reward": 0.1938457489013672, "action": -0.29152971506118774}
{"mode": "train", "epochs": 8, "timestep": 14411, "ep_reward": 245.76339721679688, "reward": 0.34282195568084717, "action": -0.9285703897476196}
{"mode": "train", "epochs": 8, "timestep": 14412, "ep_reward": 246.2393798828125, "reward": 0.4759793281555176, "action": -1.3453190326690674}
{"mode": "train", "epochs": 8, "timestep": 14413, "ep_reward": 246.8286590576172, "reward": 0.5892717838287354, "action": -1.646672010421753}
{"mode": "train", "epochs": 8, "timestep": 14414, "ep_reward": 247.5084991455078, "reward": 0.679840624332428, "action": -1.4024666547775269}
{"mode": "train", "epochs": 8, "timestep": 14415, "ep_reward": 248.26019287109375, "reward": 0.7516963481903076, "action": -0.5477524995803833}
{"mode": "train", "epochs": 8, "timestep": 14416, "ep_reward": 249.0701446533203, "reward": 0.8099538087844849, "action": -0.8404625654220581}
{"mode": "train", "epochs": 8, "timestep": 14417, "ep_reward": 249.91529846191406, "reward": 0.845150351524353, "action": -1.7600834369659424}
{"mode": "train", "epochs": 8, "timestep": 14418, "ep_reward": 250.7703094482422, "reward": 0.855005145072937, "action": -0.7673256397247314}
{"mode": "train", "epochs": 8, "timestep": 14419, "ep_reward": 251.62643432617188, "reward": 0.8561273813247681, "action": -0.6290093660354614}
{"mode": "train", "epochs": 8, "timestep": 14420, "ep_reward": 252.46646118164062, "reward": 0.8400318026542664, "action": -1.278099536895752}
{"mode": "train", "epochs": 8, "timestep": 14421, "ep_reward": 253.2626190185547, "reward": 0.7961509823799133, "action": -1.5257936716079712}
{"mode": "train", "epochs": 8, "timestep": 14422, "ep_reward": 253.98387145996094, "reward": 0.7212539911270142, "action": -1.136488437652588}
{"mode": "train", "epochs": 8, "timestep": 14423, "ep_reward": 254.59873962402344, "reward": 0.6148690581321716, "action": -0.5803673267364502}
{"mode": "train", "epochs": 8, "timestep": 14424, "ep_reward": 255.07386779785156, "reward": 0.47512543201446533, "action": -1.4245922565460205}
{"mode": "train", "epochs": 8, "timestep": 14425, "ep_reward": 255.41822814941406, "reward": 0.34436458349227905, "action": -1.136886477470398}
{"mode": "train", "epochs": 8, "timestep": 14426, "ep_reward": 255.65151977539062, "reward": 0.2332872748374939, "action": -0.9189690947532654}
{"mode": "train", "epochs": 8, "timestep": 14427, "ep_reward": 255.75350952148438, "reward": 0.10198467969894409, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 14428, "ep_reward": 255.7677764892578, "reward": 0.014264881610870361, "action": -1.234002709388733}
{"mode": "train", "epochs": 8, "timestep": 14429, "ep_reward": 255.92507934570312, "reward": 0.1573047637939453, "action": -1.326925277709961}
{"mode": "train", "epochs": 8, "timestep": 14430, "ep_reward": 256.2180480957031, "reward": 0.29297059774398804, "action": -0.7544013261795044}
{"mode": "train", "epochs": 8, "timestep": 14431, "ep_reward": 256.6511535644531, "reward": 0.43309497833251953, "action": -1.4854624271392822}
{"mode": "train", "epochs": 8, "timestep": 14432, "ep_reward": 257.2022705078125, "reward": 0.5511032342910767, "action": -1.4940718412399292}
{"mode": "train", "epochs": 8, "timestep": 14433, "ep_reward": 257.8526306152344, "reward": 0.6503591537475586, "action": -1.3110017776489258}
{"mode": "train", "epochs": 8, "timestep": 14434, "ep_reward": 258.5820617675781, "reward": 0.7294261455535889, "action": -1.1080372333526611}
{"mode": "train", "epochs": 8, "timestep": 14435, "ep_reward": 259.369873046875, "reward": 0.7878077626228333, "action": -1.2022993564605713}
{"mode": "train", "epochs": 8, "timestep": 14436, "ep_reward": 260.1940002441406, "reward": 0.8241400718688965, "action": -0.5675307512283325}
{"mode": "train", "epochs": 8, "timestep": 14437, "ep_reward": 261.04058837890625, "reward": 0.8465840816497803, "action": -1.2287073135375977}
{"mode": "train", "epochs": 8, "timestep": 14438, "ep_reward": 261.8848571777344, "reward": 0.8442633152008057, "action": -0.7880057096481323}
{"mode": "train", "epochs": 8, "timestep": 14439, "ep_reward": 262.71087646484375, "reward": 0.8260171413421631, "action": -0.9491825103759766}
{"mode": "train", "epochs": 8, "timestep": 14440, "ep_reward": 263.4938659667969, "reward": 0.7829892635345459, "action": -1.3327094316482544}
{"mode": "train", "epochs": 8, "timestep": 14441, "ep_reward": 264.200439453125, "reward": 0.7065749168395996, "action": -0.24888885021209717}
{"mode": "train", "epochs": 8, "timestep": 14442, "ep_reward": 264.8081970214844, "reward": 0.6077549457550049, "action": -0.7973003387451172}
{"mode": "train", "epochs": 8, "timestep": 14443, "ep_reward": 265.2702331542969, "reward": 0.4620470404624939, "action": -0.8141124844551086}
{"mode": "train", "epochs": 8, "timestep": 14444, "ep_reward": 265.6066589355469, "reward": 0.3364373445510864, "action": -1.916834831237793}
{"mode": "train", "epochs": 8, "timestep": 14445, "ep_reward": 265.8304443359375, "reward": 0.22378456592559814, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 14446, "ep_reward": 265.92181396484375, "reward": 0.09137314558029175, "action": -0.6789795160293579}
{"mode": "train", "epochs": 8, "timestep": 14447, "ep_reward": 265.9476623535156, "reward": 0.02586263418197632, "action": -1.419631004333496}
{"mode": "train", "epochs": 8, "timestep": 14448, "ep_reward": 266.1150817871094, "reward": 0.16743320226669312, "action": -1.1520684957504272}
{"mode": "train", "epochs": 8, "timestep": 14449, "ep_reward": 266.4205627441406, "reward": 0.30548954010009766, "action": -0.36989080905914307}
{"mode": "train", "epochs": 8, "timestep": 14450, "ep_reward": 266.8697509765625, "reward": 0.4491913318634033, "action": -1.1222281455993652}
{"mode": "train", "epochs": 8, "timestep": 14451, "ep_reward": 267.43853759765625, "reward": 0.568780779838562, "action": -1.6166794300079346}
{"mode": "train", "epochs": 8, "timestep": 14452, "ep_reward": 268.10223388671875, "reward": 0.663683295249939, "action": -1.3950048685073853}
{"mode": "train", "epochs": 8, "timestep": 14453, "ep_reward": 268.8419189453125, "reward": 0.7396903038024902, "action": -1.1660349369049072}
{"mode": "train", "epochs": 8, "timestep": 14454, "ep_reward": 269.63818359375, "reward": 0.7962599992752075, "action": -1.048284888267517}
{"mode": "train", "epochs": 8, "timestep": 14455, "ep_reward": 270.4718017578125, "reward": 0.8336083889007568, "action": -1.130415916442871}
{"mode": "train", "epochs": 8, "timestep": 14456, "ep_reward": 271.3235778808594, "reward": 0.8517912030220032, "action": -0.07916748523712158}
{"mode": "train", "epochs": 8, "timestep": 14457, "ep_reward": 272.1849365234375, "reward": 0.8613709211349487, "action": -1.5749197006225586}
{"mode": "train", "epochs": 8, "timestep": 14458, "ep_reward": 273.02459716796875, "reward": 0.8396676778793335, "action": -1.2773278951644897}
{"mode": "train", "epochs": 8, "timestep": 14459, "ep_reward": 273.8232421875, "reward": 0.798642098903656, "action": -1.0351808071136475}
{"mode": "train", "epochs": 8, "timestep": 14460, "ep_reward": 274.5558776855469, "reward": 0.7326465249061584, "action": -1.3618323802947998}
{"mode": "train", "epochs": 8, "timestep": 14461, "ep_reward": 275.18414306640625, "reward": 0.6282640695571899, "action": -0.5848272442817688}
{"mode": "train", "epochs": 8, "timestep": 14462, "ep_reward": 275.6775207519531, "reward": 0.49338167905807495, "action": -0.7922837734222412}
{"mode": "train", "epochs": 8, "timestep": 14463, "ep_reward": 276.0340881347656, "reward": 0.35656988620758057, "action": -0.9620482921600342}
{"mode": "train", "epochs": 8, "timestep": 14464, "ep_reward": 276.281982421875, "reward": 0.24789828062057495, "action": -1.0069571733474731}
{"mode": "train", "epochs": 8, "timestep": 14465, "ep_reward": 276.40118408203125, "reward": 0.11919516324996948, "action": -1.266845703125}
{"mode": "train", "epochs": 8, "timestep": 14466, "ep_reward": 276.39666748046875, "reward": -0.004518270492553711, "action": -1.0016566514968872}
{"mode": "train", "epochs": 8, "timestep": 14467, "ep_reward": 276.53765869140625, "reward": 0.1409841775894165, "action": -0.9314359426498413}
{"mode": "train", "epochs": 8, "timestep": 14468, "ep_reward": 276.8187255859375, "reward": 0.28107786178588867, "action": -1.5915262699127197}
{"mode": "train", "epochs": 8, "timestep": 14469, "ep_reward": 277.2297668457031, "reward": 0.4110405445098877, "action": -1.2816436290740967}
{"mode": "train", "epochs": 8, "timestep": 14470, "ep_reward": 277.7643127441406, "reward": 0.5345361828804016, "action": -0.12054961919784546}
{"mode": "train", "epochs": 8, "timestep": 14471, "ep_reward": 278.4159240722656, "reward": 0.6515979766845703, "action": -0.372140109539032}
{"mode": "train", "epochs": 8, "timestep": 14472, "ep_reward": 279.1565856933594, "reward": 0.7406745553016663, "action": -1.2517297267913818}
{"mode": "train", "epochs": 8, "timestep": 14473, "ep_reward": 279.95513916015625, "reward": 0.7985427975654602, "action": -1.463897943496704}
{"mode": "train", "epochs": 8, "timestep": 14474, "ep_reward": 280.79052734375, "reward": 0.8353997468948364, "action": -1.1663140058517456}
{"mode": "train", "epochs": 8, "timestep": 14475, "ep_reward": 281.64794921875, "reward": 0.8574264049530029, "action": -0.6284186840057373}
{"mode": "train", "epochs": 8, "timestep": 14476, "ep_reward": 282.5152893066406, "reward": 0.8673317432403564, "action": -0.3726784586906433}
{"mode": "train", "epochs": 8, "timestep": 14477, "ep_reward": 283.37811279296875, "reward": 0.8628290891647339, "action": -0.8845325708389282}
{"mode": "train", "epochs": 8, "timestep": 14478, "ep_reward": 284.21392822265625, "reward": 0.8358108401298523, "action": -1.2631314992904663}
{"mode": "train", "epochs": 8, "timestep": 14479, "ep_reward": 284.99658203125, "reward": 0.782645046710968, "action": -0.9161878824234009}
{"mode": "train", "epochs": 8, "timestep": 14480, "ep_reward": 285.7006530761719, "reward": 0.7040591239929199, "action": -0.9372131824493408}
{"mode": "train", "epochs": 8, "timestep": 14481, "ep_reward": 286.29046630859375, "reward": 0.5898170471191406, "action": 0.019648075103759766}
{"mode": "train", "epochs": 8, "timestep": 14482, "ep_reward": 286.7404479980469, "reward": 0.4499736428260803, "action": -1.144316554069519}
{"mode": "train", "epochs": 8, "timestep": 14483, "ep_reward": 287.0524597167969, "reward": 0.31201183795928955, "action": -1.6736106872558594}
{"mode": "train", "epochs": 8, "timestep": 14484, "ep_reward": 287.247314453125, "reward": 0.19486898183822632, "action": -0.5796459913253784}
{"mode": "train", "epochs": 8, "timestep": 14485, "ep_reward": 287.3049011230469, "reward": 0.057572007179260254, "action": -0.5779271125793457}
{"mode": "train", "epochs": 8, "timestep": 14486, "ep_reward": 287.3656005859375, "reward": 0.06070059537887573, "action": -1.1573940515518188}
{"mode": "train", "epochs": 8, "timestep": 14487, "ep_reward": 287.5632019042969, "reward": 0.19761234521865845, "action": -0.7489725947380066}
{"mode": "train", "epochs": 8, "timestep": 14488, "ep_reward": 287.9042053222656, "reward": 0.3409941792488098, "action": -1.0941404104232788}
{"mode": "train", "epochs": 8, "timestep": 14489, "ep_reward": 288.3772888183594, "reward": 0.47307288646698, "action": -1.4426536560058594}
{"mode": "train", "epochs": 8, "timestep": 14490, "ep_reward": 288.96337890625, "reward": 0.5860785245895386, "action": -1.228196382522583}
{"mode": "train", "epochs": 8, "timestep": 14491, "ep_reward": 289.64453125, "reward": 0.6811608076095581, "action": -1.4316489696502686}
{"mode": "train", "epochs": 8, "timestep": 14492, "ep_reward": 290.3961486816406, "reward": 0.7516140341758728, "action": -1.340232253074646}
{"mode": "train", "epochs": 8, "timestep": 14493, "ep_reward": 291.1973571777344, "reward": 0.8012083768844604, "action": -1.818788766860962}
{"mode": "train", "epochs": 8, "timestep": 14494, "ep_reward": 292.0235900878906, "reward": 0.8262270092964172, "action": -1.7963738441467285}
{"mode": "train", "epochs": 8, "timestep": 14495, "ep_reward": 292.855712890625, "reward": 0.8321149349212646, "action": -0.44613850116729736}
{"mode": "train", "epochs": 8, "timestep": 14496, "ep_reward": 293.6860046386719, "reward": 0.8303064107894897, "action": -0.1889859437942505}
{"mode": "train", "epochs": 8, "timestep": 14497, "ep_reward": 294.4954528808594, "reward": 0.8094401359558105, "action": -0.6818292140960693}
{"mode": "train", "epochs": 8, "timestep": 14498, "ep_reward": 295.2542419433594, "reward": 0.7587795257568359, "action": -1.3564287424087524}
{"mode": "train", "epochs": 8, "timestep": 14499, "ep_reward": 295.9231262207031, "reward": 0.6688709855079651, "action": -0.9986798763275146}
{"mode": "train", "epochs": 8, "timestep": 14500, "ep_reward": 296.4669494628906, "reward": 0.543832004070282, "action": -0.6245654225349426}
{"mode": "train", "epochs": 8, "timestep": 14501, "ep_reward": 296.86016845703125, "reward": 0.39320749044418335, "action": -1.5229105949401855}
{"mode": "train", "epochs": 8, "timestep": 14502, "ep_reward": 297.1525573730469, "reward": 0.29237914085388184, "action": -0.9460167288780212}
{"mode": "train", "epochs": 8, "timestep": 14503, "ep_reward": 297.3238525390625, "reward": 0.17130905389785767, "action": -1.8261055946350098}
{"mode": "train", "epochs": 8, "timestep": 14504, "ep_reward": 297.3543701171875, "reward": 0.03052276372909546, "action": -1.109488844871521}
{"mode": "train", "epochs": 8, "timestep": 14505, "ep_reward": 297.4413146972656, "reward": 0.08695322275161743, "action": -1.2019720077514648}
{"mode": "train", "epochs": 8, "timestep": 14506, "ep_reward": 297.6636047363281, "reward": 0.22228968143463135, "action": -1.0943106412887573}
{"mode": "train", "epochs": 8, "timestep": 14507, "ep_reward": 298.0248107910156, "reward": 0.3611985445022583, "action": -0.3519202470779419}
{"mode": "train", "epochs": 8, "timestep": 14508, "ep_reward": 298.52557373046875, "reward": 0.5007727742195129, "action": -0.5403080582618713}
{"mode": "train", "epochs": 8, "timestep": 14509, "ep_reward": 299.1446838378906, "reward": 0.6191248893737793, "action": -1.1412428617477417}
{"mode": "train", "epochs": 8, "timestep": 14510, "ep_reward": 299.85333251953125, "reward": 0.7086594700813293, "action": -1.7959208488464355}
{"mode": "train", "epochs": 8, "timestep": 14511, "ep_reward": 300.6239318847656, "reward": 0.7705957889556885, "action": -1.2491214275360107}
{"mode": "train", "epochs": 8, "timestep": 14512, "ep_reward": 301.4417724609375, "reward": 0.8178520202636719, "action": -1.0810884237289429}
{"mode": "train", "epochs": 8, "timestep": 14513, "ep_reward": 302.2894287109375, "reward": 0.8476630449295044, "action": -1.8811287879943848}
{"mode": "train", "epochs": 8, "timestep": 14514, "ep_reward": 303.1427001953125, "reward": 0.8532861471176147, "action": -1.2915759086608887}
{"mode": "train", "epochs": 8, "timestep": 14515, "ep_reward": 303.9887390136719, "reward": 0.846052348613739, "action": -1.20981764793396}
{"mode": "train", "epochs": 8, "timestep": 14516, "ep_reward": 304.8080139160156, "reward": 0.8192831873893738, "action": -0.789447009563446}
{"mode": "train", "epochs": 8, "timestep": 14517, "ep_reward": 305.58050537109375, "reward": 0.7724785804748535, "action": -0.5919348001480103}
{"mode": "train", "epochs": 8, "timestep": 14518, "ep_reward": 306.2791748046875, "reward": 0.6986602544784546, "action": -0.4001857042312622}
{"mode": "train", "epochs": 8, "timestep": 14519, "ep_reward": 306.87164306640625, "reward": 0.5924590229988098, "action": -0.28235888481140137}
{"mode": "train", "epochs": 8, "timestep": 14520, "ep_reward": 307.32080078125, "reward": 0.44914454221725464, "action": -1.7290163040161133}
{"mode": "train", "epochs": 8, "timestep": 14521, "ep_reward": 307.6405029296875, "reward": 0.3196870684623718, "action": -1.2237669229507446}
{"mode": "train", "epochs": 8, "timestep": 14522, "ep_reward": 307.8443298339844, "reward": 0.20382815599441528, "action": -1.1352921724319458}
{"mode": "train", "epochs": 8, "timestep": 14523, "ep_reward": 307.912353515625, "reward": 0.06802010536193848, "action": -0.5133726596832275}
{"mode": "train", "epochs": 8, "timestep": 14524, "ep_reward": 307.9626159667969, "reward": 0.05025899410247803, "action": -0.42069685459136963}
{"mode": "train", "epochs": 8, "timestep": 14525, "ep_reward": 308.15667724609375, "reward": 0.19405359029769897, "action": -1.749194860458374}
{"mode": "train", "epochs": 8, "timestep": 14526, "ep_reward": 308.48052978515625, "reward": 0.3238487243652344, "action": -1.3296910524368286}
{"mode": "train", "epochs": 8, "timestep": 14527, "ep_reward": 308.9357604980469, "reward": 0.45524394512176514, "action": -0.8976892232894897}
{"mode": "train", "epochs": 8, "timestep": 14528, "ep_reward": 309.51300048828125, "reward": 0.5772388577461243, "action": -1.4030401706695557}
{"mode": "train", "epochs": 8, "timestep": 14529, "ep_reward": 310.18524169921875, "reward": 0.6722270250320435, "action": -1.252777099609375}
{"mode": "train", "epochs": 8, "timestep": 14530, "ep_reward": 310.931396484375, "reward": 0.7461482286453247, "action": -1.2393171787261963}
{"mode": "train", "epochs": 8, "timestep": 14531, "ep_reward": 311.7292785644531, "reward": 0.7978706359863281, "action": -1.0530037879943848}
{"mode": "train", "epochs": 8, "timestep": 14532, "ep_reward": 312.5599365234375, "reward": 0.8306705951690674, "action": 0.09224677085876465}
{"mode": "train", "epochs": 8, "timestep": 14533, "ep_reward": 313.4141845703125, "reward": 0.8542388677597046, "action": -1.6957895755767822}
{"mode": "train", "epochs": 8, "timestep": 14534, "ep_reward": 314.2575378417969, "reward": 0.843361496925354, "action": -1.1750410795211792}
{"mode": "train", "epochs": 8, "timestep": 14535, "ep_reward": 315.0740661621094, "reward": 0.8165138363838196, "action": -1.1091980934143066}
{"mode": "train", "epochs": 8, "timestep": 14536, "ep_reward": 315.8394775390625, "reward": 0.765417754650116, "action": -0.9244612455368042}
{"mode": "train", "epochs": 8, "timestep": 14537, "ep_reward": 316.52490234375, "reward": 0.6854385137557983, "action": -1.0014493465423584}
{"mode": "train", "epochs": 8, "timestep": 14538, "ep_reward": 317.0916442871094, "reward": 0.5667552351951599, "action": -1.210068941116333}
{"mode": "train", "epochs": 8, "timestep": 14539, "ep_reward": 317.4975891113281, "reward": 0.40593427419662476, "action": -0.9964867234230042}
{"mode": "train", "epochs": 8, "timestep": 14540, "ep_reward": 317.8053283691406, "reward": 0.3077455759048462, "action": -1.593268871307373}
{"mode": "train", "epochs": 8, "timestep": 14541, "ep_reward": 317.9950866699219, "reward": 0.18975692987442017, "action": -0.9588488936424255}
{"mode": "train", "epochs": 8, "timestep": 14542, "ep_reward": 318.046630859375, "reward": 0.05155324935913086, "action": -1.6583272218704224}
{"mode": "train", "epochs": 8, "timestep": 14543, "ep_reward": 318.11309814453125, "reward": 0.06645858287811279, "action": -1.5064449310302734}
{"mode": "train", "epochs": 8, "timestep": 14544, "ep_reward": 318.31573486328125, "reward": 0.20263022184371948, "action": -0.7660658359527588}
{"mode": "train", "epochs": 8, "timestep": 14545, "ep_reward": 318.6615295410156, "reward": 0.3458033800125122, "action": -1.3756279945373535}
{"mode": "train", "epochs": 8, "timestep": 14546, "ep_reward": 319.1358642578125, "reward": 0.4743354916572571, "action": -0.8918312788009644}
{"mode": "train", "epochs": 8, "timestep": 14547, "ep_reward": 319.7291564941406, "reward": 0.5933055281639099, "action": -1.5606613159179688}
{"mode": "train", "epochs": 8, "timestep": 14548, "ep_reward": 320.41278076171875, "reward": 0.6836330890655518, "action": -0.9129940867424011}
{"mode": "train", "epochs": 8, "timestep": 14549, "ep_reward": 321.17108154296875, "reward": 0.7582913637161255, "action": -0.9978695511817932}
{"mode": "train", "epochs": 8, "timestep": 14550, "ep_reward": 321.9809265136719, "reward": 0.8098524808883667, "action": -0.9684705138206482}
{"mode": "train", "epochs": 8, "timestep": 14551, "ep_reward": 322.8224792480469, "reward": 0.8415651917457581, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 14552, "ep_reward": 323.6686096191406, "reward": 0.8461353182792664, "action": -1.1811331510543823}
{"mode": "train", "epochs": 8, "timestep": 14553, "ep_reward": 324.5077819824219, "reward": 0.8391868472099304, "action": -0.9831083416938782}
{"mode": "train", "epochs": 8, "timestep": 14554, "ep_reward": 325.3208312988281, "reward": 0.8130595684051514, "action": -0.9768415689468384}
{"mode": "train", "epochs": 8, "timestep": 14555, "ep_reward": 326.0826721191406, "reward": 0.7618298530578613, "action": -1.5431110858917236}
{"mode": "train", "epochs": 8, "timestep": 14556, "ep_reward": 326.7547912597656, "reward": 0.6721247434616089, "action": -1.4739646911621094}
{"mode": "train", "epochs": 8, "timestep": 14557, "ep_reward": 327.2970886230469, "reward": 0.5423018932342529, "action": -0.7912012934684753}
{"mode": "train", "epochs": 8, "timestep": 14558, "ep_reward": 327.6960754394531, "reward": 0.398997962474823, "action": -0.9051151871681213}
{"mode": "train", "epochs": 8, "timestep": 14559, "ep_reward": 327.995361328125, "reward": 0.2993006110191345, "action": -1.2339500188827515}
{"mode": "train", "epochs": 8, "timestep": 14560, "ep_reward": 328.1750793457031, "reward": 0.17971175909042358, "action": -0.7060703039169312}
{"mode": "train", "epochs": 8, "timestep": 14561, "ep_reward": 328.2151794433594, "reward": 0.04008650779724121, "action": -0.26163458824157715}
{"mode": "train", "epochs": 8, "timestep": 14562, "ep_reward": 328.2931213378906, "reward": 0.07793235778808594, "action": -0.5970462560653687}
{"mode": "train", "epochs": 8, "timestep": 14563, "ep_reward": 328.5134582519531, "reward": 0.2203446626663208, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 14564, "ep_reward": 328.8603515625, "reward": 0.34690046310424805, "action": -0.7307154536247253}
{"mode": "train", "epochs": 8, "timestep": 14565, "ep_reward": 329.34417724609375, "reward": 0.4838247299194336, "action": -1.0062572956085205}
{"mode": "train", "epochs": 8, "timestep": 14566, "ep_reward": 329.9443359375, "reward": 0.6001439094543457, "action": -1.0973008871078491}
{"mode": "train", "epochs": 8, "timestep": 14567, "ep_reward": 330.63800048828125, "reward": 0.6936718821525574, "action": -0.7214108109474182}
{"mode": "train", "epochs": 8, "timestep": 14568, "ep_reward": 331.40582275390625, "reward": 0.7678074240684509, "action": -0.978208601474762}
{"mode": "train", "epochs": 8, "timestep": 14569, "ep_reward": 332.2233581542969, "reward": 0.8175438642501831, "action": -0.5370920896530151}
{"mode": "train", "epochs": 8, "timestep": 14570, "ep_reward": 333.0751647949219, "reward": 0.8518099188804626, "action": -0.38378477096557617}
{"mode": "train", "epochs": 8, "timestep": 14571, "ep_reward": 333.945068359375, "reward": 0.8698917627334595, "action": -0.7176713347434998}
{"mode": "train", "epochs": 8, "timestep": 14572, "ep_reward": 334.8140563964844, "reward": 0.8690005540847778, "action": -0.980318009853363}
{"mode": "train", "epochs": 8, "timestep": 14573, "ep_reward": 335.6628723144531, "reward": 0.8488237857818604, "action": -0.9470281600952148}
{"mode": "train", "epochs": 8, "timestep": 14574, "ep_reward": 336.4713134765625, "reward": 0.8084387183189392, "action": -1.3796273469924927}
{"mode": "train", "epochs": 8, "timestep": 14575, "ep_reward": 337.2087097167969, "reward": 0.7374089956283569, "action": -0.07507449388504028}
{"mode": "train", "epochs": 8, "timestep": 14576, "ep_reward": 337.85760498046875, "reward": 0.6489031314849854, "action": -1.6772181987762451}
{"mode": "train", "epochs": 8, "timestep": 14577, "ep_reward": 338.3593444824219, "reward": 0.5017467141151428, "action": -1.1885292530059814}
{"mode": "train", "epochs": 8, "timestep": 14578, "ep_reward": 338.7120056152344, "reward": 0.35265976190567017, "action": -1.1824257373809814}
{"mode": "train", "epochs": 8, "timestep": 14579, "ep_reward": 338.9552001953125, "reward": 0.2431950569152832, "action": -1.2955727577209473}
{"mode": "train", "epochs": 8, "timestep": 14580, "ep_reward": 339.06903076171875, "reward": 0.11382728815078735, "action": -0.6453757286071777}
{"mode": "train", "epochs": 8, "timestep": 14581, "ep_reward": 339.070556640625, "reward": 0.0015146136283874512, "action": -1.2455623149871826}
{"mode": "train", "epochs": 8, "timestep": 14582, "ep_reward": 339.2168273925781, "reward": 0.1462620496749878, "action": -0.9689384698867798}
{"mode": "train", "epochs": 8, "timestep": 14583, "ep_reward": 339.5029296875, "reward": 0.2860877513885498, "action": -1.1514307260513306}
{"mode": "train", "epochs": 8, "timestep": 14584, "ep_reward": 339.9241027832031, "reward": 0.42116063833236694, "action": -1.3767619132995605}
{"mode": "train", "epochs": 8, "timestep": 14585, "ep_reward": 340.4660339355469, "reward": 0.5419427156448364, "action": -1.2064929008483887}
{"mode": "train", "epochs": 8, "timestep": 14586, "ep_reward": 341.1120300292969, "reward": 0.6459882259368896, "action": -1.4690961837768555}
{"mode": "train", "epochs": 8, "timestep": 14587, "ep_reward": 341.8370666503906, "reward": 0.7250466346740723, "action": -1.0273027420043945}
{"mode": "train", "epochs": 8, "timestep": 14588, "ep_reward": 342.6231994628906, "reward": 0.7861264944076538, "action": -1.3565913438796997}
{"mode": "train", "epochs": 8, "timestep": 14589, "ep_reward": 343.44622802734375, "reward": 0.8230436444282532, "action": -0.9320864677429199}
{"mode": "train", "epochs": 8, "timestep": 14590, "ep_reward": 344.2907409667969, "reward": 0.8445208072662354, "action": -0.6775782108306885}
{"mode": "train", "epochs": 8, "timestep": 14591, "ep_reward": 345.14031982421875, "reward": 0.8495924472808838, "action": -0.8949591517448425}
{"mode": "train", "epochs": 8, "timestep": 14592, "ep_reward": 345.97381591796875, "reward": 0.833503007888794, "action": -0.3592965602874756}
{"mode": "train", "epochs": 8, "timestep": 14593, "ep_reward": 346.77471923828125, "reward": 0.8009180426597595, "action": -0.7942063808441162}
{"mode": "train", "epochs": 8, "timestep": 14594, "ep_reward": 347.5127258300781, "reward": 0.7380043268203735, "action": -0.2862948179244995}
{"mode": "train", "epochs": 8, "timestep": 14595, "ep_reward": 348.161865234375, "reward": 0.6491380333900452, "action": -0.8601102232933044}
{"mode": "train", "epochs": 8, "timestep": 14596, "ep_reward": 348.67730712890625, "reward": 0.5154386758804321, "action": -1.4171770811080933}
{"mode": "train", "epochs": 8, "timestep": 14597, "ep_reward": 349.0390930175781, "reward": 0.36179816722869873, "action": -0.8016241192817688}
{"mode": "train", "epochs": 8, "timestep": 14598, "ep_reward": 349.2930908203125, "reward": 0.25398653745651245, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 14599, "ep_reward": 349.41961669921875, "reward": 0.12652432918548584, "action": -1.3324249982833862}
{"mode": "train", "epochs": 8, "timestep": 14600, "ep_reward": 349.40673828125, "reward": -0.012864470481872559, "action": -1.359510898590088}
{"mode": "train", "epochs": 8, "timestep": 14601, "ep_reward": 349.5404968261719, "reward": 0.13375979661941528, "action": -0.8553277254104614}
{"mode": "train", "epochs": 8, "timestep": 14602, "ep_reward": 349.815185546875, "reward": 0.27469682693481445, "action": -1.1560137271881104}
{"mode": "train", "epochs": 8, "timestep": 14603, "ep_reward": 350.22528076171875, "reward": 0.4100826382637024, "action": -1.1000335216522217}
{"mode": "train", "epochs": 8, "timestep": 14604, "ep_reward": 350.76055908203125, "reward": 0.5352645516395569, "action": -0.989824116230011}
{"mode": "train", "epochs": 8, "timestep": 14605, "ep_reward": 351.4034729003906, "reward": 0.6429271697998047, "action": -1.179804801940918}
{"mode": "train", "epochs": 8, "timestep": 14606, "ep_reward": 352.1297302246094, "reward": 0.7262474894523621, "action": -1.0817533731460571}
{"mode": "train", "epochs": 8, "timestep": 14607, "ep_reward": 352.918212890625, "reward": 0.7884867787361145, "action": 0.012510895729064941}
{"mode": "train", "epochs": 8, "timestep": 14608, "ep_reward": 353.7578430175781, "reward": 0.8396421670913696, "action": -0.9386852979660034}
{"mode": "train", "epochs": 8, "timestep": 14609, "ep_reward": 354.621826171875, "reward": 0.8639968633651733, "action": -1.0461487770080566}
{"mode": "train", "epochs": 8, "timestep": 14610, "ep_reward": 355.4933166503906, "reward": 0.871501088142395, "action": -0.885796070098877}
{"mode": "train", "epochs": 8, "timestep": 14611, "ep_reward": 356.35760498046875, "reward": 0.8642982244491577, "action": -0.8154268860816956}
{"mode": "train", "epochs": 8, "timestep": 14612, "ep_reward": 357.1975402832031, "reward": 0.8399351835250854, "action": -0.3721504807472229}
{"mode": "train", "epochs": 8, "timestep": 14613, "ep_reward": 357.99615478515625, "reward": 0.7986228466033936, "action": -1.4302308559417725}
{"mode": "train", "epochs": 8, "timestep": 14614, "ep_reward": 358.7157897949219, "reward": 0.7196468710899353, "action": -0.6797384023666382}
{"mode": "train", "epochs": 8, "timestep": 14615, "ep_reward": 359.33050537109375, "reward": 0.6147103309631348, "action": -0.8319066762924194}
{"mode": "train", "epochs": 8, "timestep": 14616, "ep_reward": 359.7991943359375, "reward": 0.4686881899833679, "action": -1.897515058517456}
{"mode": "train", "epochs": 8, "timestep": 14617, "ep_reward": 360.12603759765625, "reward": 0.32684946060180664, "action": -0.1272435188293457}
{"mode": "train", "epochs": 8, "timestep": 14618, "ep_reward": 360.3383483886719, "reward": 0.21231985092163086, "action": -0.2867138385772705}
{"mode": "train", "epochs": 8, "timestep": 14619, "ep_reward": 360.4161071777344, "reward": 0.07775634527206421, "action": -0.8361247777938843}
{"mode": "train", "epochs": 8, "timestep": 14620, "ep_reward": 360.4562683105469, "reward": 0.04017162322998047, "action": -1.1253358125686646}
{"mode": "train", "epochs": 8, "timestep": 14621, "ep_reward": 360.6361389160156, "reward": 0.1798805594444275, "action": -0.12865447998046875}
{"mode": "train", "epochs": 8, "timestep": 14622, "ep_reward": 360.9667663574219, "reward": 0.3306235671043396, "action": -1.3137316703796387}
{"mode": "train", "epochs": 8, "timestep": 14623, "ep_reward": 361.42645263671875, "reward": 0.45969563722610474, "action": -1.9862854480743408}
{"mode": "train", "epochs": 8, "timestep": 14624, "ep_reward": 361.9948425292969, "reward": 0.5683966875076294, "action": -0.6978560090065002}
{"mode": "train", "epochs": 8, "timestep": 14625, "ep_reward": 362.6675109863281, "reward": 0.6726776361465454, "action": -1.1359480619430542}
{"mode": "train", "epochs": 8, "timestep": 14626, "ep_reward": 363.41656494140625, "reward": 0.7490675449371338, "action": -0.3001171946525574}
{"mode": "train", "epochs": 8, "timestep": 14627, "ep_reward": 364.2275085449219, "reward": 0.8109383583068848, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 14628, "ep_reward": 365.06561279296875, "reward": 0.8380890488624573, "action": -0.8500417470932007}
{"mode": "train", "epochs": 8, "timestep": 14629, "ep_reward": 365.9234924316406, "reward": 0.8578896522521973, "action": -0.5837408304214478}
{"mode": "train", "epochs": 8, "timestep": 14630, "ep_reward": 366.7862854003906, "reward": 0.8627914786338806, "action": -1.0285223722457886}
{"mode": "train", "epochs": 8, "timestep": 14631, "ep_reward": 367.63250732421875, "reward": 0.846234917640686, "action": 0.030332446098327637}
{"mode": "train", "epochs": 8, "timestep": 14632, "ep_reward": 368.4521484375, "reward": 0.8196448683738708, "action": -0.9302515983581543}
{"mode": "train", "epochs": 8, "timestep": 14633, "ep_reward": 369.212158203125, "reward": 0.7600036859512329, "action": -1.5638847351074219}
{"mode": "train", "epochs": 8, "timestep": 14634, "ep_reward": 369.8736267089844, "reward": 0.6614828109741211, "action": -0.9431875944137573}
{"mode": "train", "epochs": 8, "timestep": 14635, "ep_reward": 370.4048156738281, "reward": 0.5312008857727051, "action": -0.6494108438491821}
{"mode": "train", "epochs": 8, "timestep": 14636, "ep_reward": 370.77691650390625, "reward": 0.3720964193344116, "action": -1.1882683038711548}
{"mode": "train", "epochs": 8, "timestep": 14637, "ep_reward": 371.0436096191406, "reward": 0.266693651676178, "action": -0.7251119017601013}
{"mode": "train", "epochs": 8, "timestep": 14638, "ep_reward": 371.18475341796875, "reward": 0.1411374807357788, "action": -1.4498488903045654}
{"mode": "train", "epochs": 8, "timestep": 14639, "ep_reward": 371.1805725097656, "reward": -0.0041953325271606445, "action": -0.3378050923347473}
{"mode": "train", "epochs": 8, "timestep": 14640, "ep_reward": 371.2995910644531, "reward": 0.11901414394378662, "action": -0.80165696144104}
{"mode": "train", "epochs": 8, "timestep": 14641, "ep_reward": 371.55987548828125, "reward": 0.26028960943222046, "action": -0.7316857576370239}
{"mode": "train", "epochs": 8, "timestep": 14642, "ep_reward": 371.961181640625, "reward": 0.4013066291809082, "action": -0.977331280708313}
{"mode": "train", "epochs": 8, "timestep": 14643, "ep_reward": 372.4895324707031, "reward": 0.5283454656600952, "action": -1.3873403072357178}
{"mode": "train", "epochs": 8, "timestep": 14644, "ep_reward": 373.12261962890625, "reward": 0.6330912113189697, "action": -0.5047860145568848}
{"mode": "train", "epochs": 8, "timestep": 14645, "ep_reward": 373.84796142578125, "reward": 0.7253278493881226, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 14646, "ep_reward": 374.6290283203125, "reward": 0.7810672521591187, "action": -0.7695003747940063}
{"mode": "train", "epochs": 8, "timestep": 14647, "ep_reward": 375.4574890136719, "reward": 0.8284526467323303, "action": -1.8106975555419922}
{"mode": "train", "epochs": 8, "timestep": 14648, "ep_reward": 376.3059997558594, "reward": 0.8485123515129089, "action": -0.641838550567627}
{"mode": "train", "epochs": 8, "timestep": 14649, "ep_reward": 377.1675109863281, "reward": 0.861519455909729, "action": -0.49387502670288086}
{"mode": "train", "epochs": 8, "timestep": 14650, "ep_reward": 378.0260925292969, "reward": 0.858590304851532, "action": -0.8277259469032288}
{"mode": "train", "epochs": 8, "timestep": 14651, "ep_reward": 378.86029052734375, "reward": 0.8342050313949585, "action": -1.3826289176940918}
{"mode": "train", "epochs": 8, "timestep": 14652, "ep_reward": 379.641845703125, "reward": 0.78156578540802, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 14653, "ep_reward": 380.3330993652344, "reward": 0.6912490129470825, "action": -1.3156154155731201}
{"mode": "train", "epochs": 8, "timestep": 14654, "ep_reward": 380.9025573730469, "reward": 0.5694502592086792, "action": -0.8596577048301697}
{"mode": "train", "epochs": 8, "timestep": 14655, "ep_reward": 381.3133239746094, "reward": 0.410753071308136, "action": -0.28504061698913574}
{"mode": "train", "epochs": 8, "timestep": 14656, "ep_reward": 381.6220703125, "reward": 0.30874180793762207, "action": -1.1268665790557861}
{"mode": "train", "epochs": 8, "timestep": 14657, "ep_reward": 381.81280517578125, "reward": 0.19074732065200806, "action": -1.5688732862472534}
{"mode": "train", "epochs": 8, "timestep": 14658, "ep_reward": 381.86572265625, "reward": 0.05291855335235596, "action": -1.0054446458816528}
{"mode": "train", "epochs": 8, "timestep": 14659, "ep_reward": 381.9310607910156, "reward": 0.06535130739212036, "action": -0.36439478397369385}
{"mode": "train", "epochs": 8, "timestep": 14660, "ep_reward": 382.1413269042969, "reward": 0.21026122570037842, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 14661, "ep_reward": 382.47784423828125, "reward": 0.3365181088447571, "action": -1.308135986328125}
{"mode": "train", "epochs": 8, "timestep": 14662, "ep_reward": 382.9450988769531, "reward": 0.46725034713745117, "action": -1.1825889348983765}
{"mode": "train", "epochs": 8, "timestep": 14663, "ep_reward": 383.52947998046875, "reward": 0.5843833684921265, "action": 0.3417978286743164}
{"mode": "train", "epochs": 8, "timestep": 14664, "ep_reward": 384.22503662109375, "reward": 0.6955422163009644, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 14665, "ep_reward": 384.983154296875, "reward": 0.7581328749656677, "action": -1.3983800411224365}
{"mode": "train", "epochs": 8, "timestep": 14666, "ep_reward": 385.7893371582031, "reward": 0.8061971068382263, "action": -1.2712211608886719}
{"mode": "train", "epochs": 8, "timestep": 14667, "ep_reward": 386.6251220703125, "reward": 0.8357734680175781, "action": -0.8274822235107422}
{"mode": "train", "epochs": 8, "timestep": 14668, "ep_reward": 387.4755859375, "reward": 0.8504534959793091, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 14669, "ep_reward": 388.3115234375, "reward": 0.8359506130218506, "action": -0.5832880139350891}
{"mode": "train", "epochs": 8, "timestep": 14670, "ep_reward": 389.12493896484375, "reward": 0.8134064674377441, "action": -0.41945213079452515}
{"mode": "train", "epochs": 8, "timestep": 14671, "ep_reward": 389.8933410644531, "reward": 0.7683882713317871, "action": -0.6711570024490356}
{"mode": "train", "epochs": 8, "timestep": 14672, "ep_reward": 390.5845642089844, "reward": 0.691216766834259, "action": -1.4296060800552368}
{"mode": "train", "epochs": 8, "timestep": 14673, "ep_reward": 391.15191650390625, "reward": 0.5673673748970032, "action": -0.48340052366256714}
{"mode": "train", "epochs": 8, "timestep": 14674, "ep_reward": 391.5660400390625, "reward": 0.41411495208740234, "action": -0.5075380802154541}
{"mode": "train", "epochs": 8, "timestep": 14675, "ep_reward": 391.8731689453125, "reward": 0.3071216940879822, "action": -0.36901432275772095}
{"mode": "train", "epochs": 8, "timestep": 14676, "ep_reward": 392.0618896484375, "reward": 0.18872082233428955, "action": -1.6802773475646973}
{"mode": "train", "epochs": 8, "timestep": 14677, "ep_reward": 392.1124267578125, "reward": 0.05055046081542969, "action": -1.3531533479690552}
{"mode": "train", "epochs": 8, "timestep": 14678, "ep_reward": 392.17999267578125, "reward": 0.06755101680755615, "action": -1.227410912513733}
{"mode": "train", "epochs": 8, "timestep": 14679, "ep_reward": 392.383544921875, "reward": 0.20354777574539185, "action": -0.5765525102615356}
{"mode": "train", "epochs": 8, "timestep": 14680, "ep_reward": 392.7325439453125, "reward": 0.34901195764541626, "action": -1.6043667793273926}
{"mode": "train", "epochs": 8, "timestep": 14681, "ep_reward": 393.2068176269531, "reward": 0.47428184747695923, "action": -1.3697075843811035}
{"mode": "train", "epochs": 8, "timestep": 14682, "ep_reward": 393.7948913574219, "reward": 0.5880733132362366, "action": -0.9838762283325195}
{"mode": "train", "epochs": 8, "timestep": 14683, "ep_reward": 394.48004150390625, "reward": 0.6851609945297241, "action": -0.7490179538726807}
{"mode": "train", "epochs": 8, "timestep": 14684, "ep_reward": 395.2409973144531, "reward": 0.7609477043151855, "action": -1.302091360092163}
{"mode": "train", "epochs": 8, "timestep": 14685, "ep_reward": 396.05029296875, "reward": 0.8092893362045288, "action": -0.8655426502227783}
{"mode": "train", "epochs": 8, "timestep": 14686, "ep_reward": 396.8922119140625, "reward": 0.8419272303581238, "action": -0.9125144481658936}
{"mode": "train", "epochs": 8, "timestep": 14687, "ep_reward": 397.74810791015625, "reward": 0.8558868765830994, "action": -0.909765899181366}
{"mode": "train", "epochs": 8, "timestep": 14688, "ep_reward": 398.6001892089844, "reward": 0.8520939350128174, "action": -0.9664282202720642}
{"mode": "train", "epochs": 8, "timestep": 14689, "ep_reward": 399.4287109375, "reward": 0.8285181522369385, "action": -0.7665382623672485}
{"mode": "train", "epochs": 8, "timestep": 14690, "ep_reward": 400.212646484375, "reward": 0.7839300632476807, "action": -1.4221458435058594}
{"mode": "train", "epochs": 8, "timestep": 14691, "ep_reward": 400.915771484375, "reward": 0.7031203508377075, "action": -1.8291265964508057}
{"mode": "train", "epochs": 8, "timestep": 14692, "ep_reward": 401.4944152832031, "reward": 0.5786476731300354, "action": -1.3278921842575073}
{"mode": "train", "epochs": 8, "timestep": 14693, "ep_reward": 401.90985107421875, "reward": 0.41544103622436523, "action": -1.0306763648986816}
{"mode": "train", "epochs": 8, "timestep": 14694, "ep_reward": 402.2277526855469, "reward": 0.3179129958152771, "action": -0.4937983751296997}
{"mode": "train", "epochs": 8, "timestep": 14695, "ep_reward": 402.429443359375, "reward": 0.20168530941009521, "action": -0.6203129291534424}
{"mode": "train", "epochs": 8, "timestep": 14696, "ep_reward": 402.4949035644531, "reward": 0.06546902656555176, "action": -0.5922211408615112}
{"mode": "train", "epochs": 8, "timestep": 14697, "ep_reward": 402.5476989746094, "reward": 0.05279046297073364, "action": -0.966391384601593}
{"mode": "train", "epochs": 8, "timestep": 14698, "ep_reward": 402.7384033203125, "reward": 0.190712571144104, "action": -1.0852861404418945}
{"mode": "train", "epochs": 8, "timestep": 14699, "ep_reward": 403.0683288574219, "reward": 0.329912006855011, "action": -0.7744114995002747}
{"mode": "train", "epochs": 8, "timestep": 14700, "ep_reward": 403.5354919433594, "reward": 0.46717745065689087, "action": -0.6792585849761963}
{"mode": "train", "epochs": 8, "timestep": 14701, "ep_reward": 404.12493896484375, "reward": 0.5894548892974854, "action": -1.2181535959243774}
{"mode": "train", "epochs": 8, "timestep": 14702, "ep_reward": 404.809326171875, "reward": 0.6843785047531128, "action": -1.061958909034729}
{"mode": "train", "epochs": 8, "timestep": 14703, "ep_reward": 405.5679931640625, "reward": 0.7586750984191895, "action": -1.4513592720031738}
{"mode": "train", "epochs": 8, "timestep": 14704, "ep_reward": 406.3761291503906, "reward": 0.8081320524215698, "action": -1.4207873344421387}
{"mode": "train", "epochs": 8, "timestep": 14705, "ep_reward": 407.2149353027344, "reward": 0.8387973308563232, "action": -1.865835428237915}
{"mode": "train", "epochs": 8, "timestep": 14706, "ep_reward": 408.0628662109375, "reward": 0.8479180335998535, "action": -0.2843232750892639}
{"mode": "train", "epochs": 8, "timestep": 14707, "ep_reward": 408.9157409667969, "reward": 0.8528744578361511, "action": -1.4794056415557861}
{"mode": "train", "epochs": 8, "timestep": 14708, "ep_reward": 409.7434997558594, "reward": 0.8277640342712402, "action": -0.7146687507629395}
{"mode": "train", "epochs": 8, "timestep": 14709, "ep_reward": 410.5304260253906, "reward": 0.786941409111023, "action": -0.23512578010559082}
{"mode": "train", "epochs": 8, "timestep": 14710, "ep_reward": 411.2544860839844, "reward": 0.724071741104126, "action": -1.451902151107788}
{"mode": "train", "epochs": 8, "timestep": 14711, "ep_reward": 411.8674011230469, "reward": 0.612905740737915, "action": -0.5032862424850464}
{"mode": "train", "epochs": 8, "timestep": 14712, "ep_reward": 412.3406677246094, "reward": 0.4732663631439209, "action": -1.3080484867095947}
{"mode": "train", "epochs": 8, "timestep": 14713, "ep_reward": 412.6804504394531, "reward": 0.3397791385650635, "action": -1.4232710599899292}
{"mode": "train", "epochs": 8, "timestep": 14714, "ep_reward": 412.9083251953125, "reward": 0.22786402702331543, "action": -0.8461010456085205}
{"mode": "train", "epochs": 8, "timestep": 14715, "ep_reward": 413.0041809082031, "reward": 0.09585815668106079, "action": -0.9312691688537598}
{"mode": "train", "epochs": 8, "timestep": 14716, "ep_reward": 413.0252990722656, "reward": 0.021131157875061035, "action": -0.8204975128173828}
{"mode": "train", "epochs": 8, "timestep": 14717, "ep_reward": 413.1885070800781, "reward": 0.1632061004638672, "action": -1.4226858615875244}
{"mode": "train", "epochs": 8, "timestep": 14718, "ep_reward": 413.4862365722656, "reward": 0.2977277636528015, "action": -1.3031375408172607}
{"mode": "train", "epochs": 8, "timestep": 14719, "ep_reward": 413.91729736328125, "reward": 0.43105947971343994, "action": -1.9275362491607666}
{"mode": "train", "epochs": 8, "timestep": 14720, "ep_reward": 414.4620361328125, "reward": 0.5447342991828918, "action": -0.8071309328079224}
{"mode": "train", "epochs": 8, "timestep": 14721, "ep_reward": 415.11431884765625, "reward": 0.6522945165634155, "action": -0.1295526623725891}
{"mode": "train", "epochs": 8, "timestep": 14722, "ep_reward": 415.85614013671875, "reward": 0.7418112754821777, "action": -1.6844353675842285}
{"mode": "train", "epochs": 8, "timestep": 14723, "ep_reward": 416.64825439453125, "reward": 0.792108416557312, "action": -1.2722052335739136}
{"mode": "train", "epochs": 8, "timestep": 14724, "ep_reward": 417.4743347167969, "reward": 0.8260740041732788, "action": -0.7000678777694702}
{"mode": "train", "epochs": 8, "timestep": 14725, "ep_reward": 418.32000732421875, "reward": 0.8456724286079407, "action": -1.5810227394104004}
{"mode": "train", "epochs": 8, "timestep": 14726, "ep_reward": 419.15826416015625, "reward": 0.8382426500320435, "action": -1.1124446392059326}
{"mode": "train", "epochs": 8, "timestep": 14727, "ep_reward": 419.9723205566406, "reward": 0.8140643835067749, "action": -0.979033887386322}
{"mode": "train", "epochs": 8, "timestep": 14728, "ep_reward": 420.7386169433594, "reward": 0.7663036584854126, "action": -0.7096956968307495}
{"mode": "train", "epochs": 8, "timestep": 14729, "ep_reward": 421.4297790527344, "reward": 0.6911667585372925, "action": -0.7521205544471741}
{"mode": "train", "epochs": 8, "timestep": 14730, "ep_reward": 422.0086975097656, "reward": 0.5789065957069397, "action": -1.3104876279830933}
{"mode": "train", "epochs": 8, "timestep": 14731, "ep_reward": 422.42449951171875, "reward": 0.41578906774520874, "action": -1.7119594812393188}
{"mode": "train", "epochs": 8, "timestep": 14732, "ep_reward": 422.7410583496094, "reward": 0.31656700372695923, "action": -1.636646032333374}
{"mode": "train", "epochs": 8, "timestep": 14733, "ep_reward": 422.9412536621094, "reward": 0.20020973682403564, "action": -1.140220046043396}
{"mode": "train", "epochs": 8, "timestep": 14734, "ep_reward": 423.0049743652344, "reward": 0.06371748447418213, "action": -1.4459829330444336}
{"mode": "train", "epochs": 8, "timestep": 14735, "ep_reward": 423.059326171875, "reward": 0.05435281991958618, "action": -1.5779709815979004}
{"mode": "train", "epochs": 8, "timestep": 14736, "ep_reward": 423.2514953613281, "reward": 0.19218093156814575, "action": -0.8041843175888062}
{"mode": "train", "epochs": 8, "timestep": 14737, "ep_reward": 423.5862731933594, "reward": 0.33477139472961426, "action": -1.45302152633667}
{"mode": "train", "epochs": 8, "timestep": 14738, "ep_reward": 424.0494079589844, "reward": 0.46314162015914917, "action": -1.3979454040527344}
{"mode": "train", "epochs": 8, "timestep": 14739, "ep_reward": 424.627685546875, "reward": 0.578292727470398, "action": -0.8037230968475342}
{"mode": "train", "epochs": 8, "timestep": 14740, "ep_reward": 425.3070373535156, "reward": 0.6793421506881714, "action": -0.41582608222961426}
{"mode": "train", "epochs": 8, "timestep": 14741, "ep_reward": 426.06719970703125, "reward": 0.7601744532585144, "action": -0.5873562097549438}
{"mode": "train", "epochs": 8, "timestep": 14742, "ep_reward": 426.8833923339844, "reward": 0.8162046670913696, "action": -1.5779744386672974}
{"mode": "train", "epochs": 8, "timestep": 14743, "ep_reward": 427.7275085449219, "reward": 0.8441118597984314, "action": -1.6972312927246094}
{"mode": "train", "epochs": 8, "timestep": 14744, "ep_reward": 428.5814208984375, "reward": 0.8539080023765564, "action": -0.8790779709815979}
{"mode": "train", "epochs": 8, "timestep": 14745, "ep_reward": 429.4346923828125, "reward": 0.8532859086990356, "action": -0.406610906124115}
{"mode": "train", "epochs": 8, "timestep": 14746, "ep_reward": 430.2728576660156, "reward": 0.8381772041320801, "action": -1.3168244361877441}
{"mode": "train", "epochs": 8, "timestep": 14747, "ep_reward": 431.0655517578125, "reward": 0.7926796674728394, "action": -0.9175119996070862}
{"mode": "train", "epochs": 8, "timestep": 14748, "ep_reward": 431.7889099121094, "reward": 0.7233612537384033, "action": -0.17431330680847168}
{"mode": "train", "epochs": 8, "timestep": 14749, "ep_reward": 432.41864013671875, "reward": 0.6297225952148438, "action": -1.2980457544326782}
{"mode": "train", "epochs": 8, "timestep": 14750, "ep_reward": 432.901123046875, "reward": 0.4824841022491455, "action": -0.7806865572929382}
{"mode": "train", "epochs": 8, "timestep": 14751, "ep_reward": 433.24560546875, "reward": 0.3444770574569702, "action": -1.072373867034912}
{"mode": "train", "epochs": 8, "timestep": 14752, "ep_reward": 433.4790344238281, "reward": 0.23342812061309814, "action": -0.7823444604873657}
{"mode": "train", "epochs": 8, "timestep": 14753, "ep_reward": 433.5813903808594, "reward": 0.10236632823944092, "action": -0.5401963591575623}
{"mode": "train", "epochs": 8, "timestep": 14754, "ep_reward": 433.5954895019531, "reward": 0.014106929302215576, "action": -1.1844978332519531}
{"mode": "train", "epochs": 8, "timestep": 14755, "ep_reward": 433.752685546875, "reward": 0.1572113037109375, "action": -0.95579993724823}
{"mode": "train", "epochs": 8, "timestep": 14756, "ep_reward": 434.050048828125, "reward": 0.2973633408546448, "action": -1.53871488571167}
{"mode": "train", "epochs": 8, "timestep": 14757, "ep_reward": 434.4772644042969, "reward": 0.4272180199623108, "action": -1.186523199081421}
{"mode": "train", "epochs": 8, "timestep": 14758, "ep_reward": 435.0270080566406, "reward": 0.5497432947158813, "action": -0.7949535846710205}
{"mode": "train", "epochs": 8, "timestep": 14759, "ep_reward": 435.6837463378906, "reward": 0.6567294001579285, "action": -0.4985787272453308}
{"mode": "train", "epochs": 8, "timestep": 14760, "ep_reward": 436.426513671875, "reward": 0.7427793741226196, "action": -1.3272526264190674}
{"mode": "train", "epochs": 8, "timestep": 14761, "ep_reward": 437.2245178222656, "reward": 0.7980066537857056, "action": -0.9839799404144287}
{"mode": "train", "epochs": 8, "timestep": 14762, "ep_reward": 438.0609130859375, "reward": 0.8364065885543823, "action": -1.8907747268676758}
{"mode": "train", "epochs": 8, "timestep": 14763, "ep_reward": 438.90985107421875, "reward": 0.848949134349823, "action": -1.25260591506958}
{"mode": "train", "epochs": 8, "timestep": 14764, "ep_reward": 439.75909423828125, "reward": 0.8492336273193359, "action": -1.2568244934082031}
{"mode": "train", "epochs": 8, "timestep": 14765, "ep_reward": 440.5891418457031, "reward": 0.8300606608390808, "action": -0.9110866189002991}
{"mode": "train", "epochs": 8, "timestep": 14766, "ep_reward": 441.3805236816406, "reward": 0.791392982006073, "action": -1.4867370128631592}
{"mode": "train", "epochs": 8, "timestep": 14767, "ep_reward": 442.0986022949219, "reward": 0.7180868983268738, "action": -1.4817651510238647}
{"mode": "train", "epochs": 8, "timestep": 14768, "ep_reward": 442.706298828125, "reward": 0.6077055931091309, "action": -0.847678542137146}
{"mode": "train", "epochs": 8, "timestep": 14769, "ep_reward": 443.169189453125, "reward": 0.46288764476776123, "action": 0.18421781063079834}
{"mode": "train", "epochs": 8, "timestep": 14770, "ep_reward": 443.516357421875, "reward": 0.34718209505081177, "action": -1.3613600730895996}
{"mode": "train", "epochs": 8, "timestep": 14771, "ep_reward": 443.75299072265625, "reward": 0.2366427183151245, "action": -1.375}
{"mode": "train", "epochs": 8, "timestep": 14772, "ep_reward": 443.8591613769531, "reward": 0.10618126392364502, "action": -0.8297850489616394}
{"mode": "train", "epochs": 8, "timestep": 14773, "ep_reward": 443.8691711425781, "reward": 0.00999981164932251, "action": -0.4573879837989807}
{"mode": "train", "epochs": 8, "timestep": 14774, "ep_reward": 444.0226745605469, "reward": 0.15349674224853516, "action": -1.4716625213623047}
{"mode": "train", "epochs": 8, "timestep": 14775, "ep_reward": 444.3099670410156, "reward": 0.28728121519088745, "action": -0.7905967235565186}
{"mode": "train", "epochs": 8, "timestep": 14776, "ep_reward": 444.7376403808594, "reward": 0.4276737570762634, "action": -0.557021975517273}
{"mode": "train", "epochs": 8, "timestep": 14777, "ep_reward": 445.29473876953125, "reward": 0.5571112036705017, "action": -0.5409085750579834}
{"mode": "train", "epochs": 8, "timestep": 14778, "ep_reward": 445.96014404296875, "reward": 0.6654015779495239, "action": -0.7315766215324402}
{"mode": "train", "epochs": 8, "timestep": 14779, "ep_reward": 446.7083740234375, "reward": 0.7482161521911621, "action": -1.0342878103256226}
{"mode": "train", "epochs": 8, "timestep": 14780, "ep_reward": 447.51483154296875, "reward": 0.8064458966255188, "action": -0.28767985105514526}
{"mode": "train", "epochs": 8, "timestep": 14781, "ep_reward": 448.3665771484375, "reward": 0.8517365455627441, "action": -0.7021999955177307}
{"mode": "train", "epochs": 8, "timestep": 14782, "ep_reward": 449.2431945800781, "reward": 0.8766080141067505, "action": -0.3966635465621948}
{"mode": "train", "epochs": 8, "timestep": 14783, "ep_reward": 450.1323547363281, "reward": 0.8891491293907166, "action": -1.2074761390686035}
{"mode": "train", "epochs": 8, "timestep": 14784, "ep_reward": 451.013671875, "reward": 0.881325900554657, "action": -1.4566489458084106}
{"mode": "train", "epochs": 8, "timestep": 14785, "ep_reward": 451.8691101074219, "reward": 0.8554390072822571, "action": -0.9825040102005005}
{"mode": "train", "epochs": 8, "timestep": 14786, "ep_reward": 452.6827697753906, "reward": 0.8136589527130127, "action": -0.28569674491882324}
{"mode": "train", "epochs": 8, "timestep": 14787, "ep_reward": 453.4370422363281, "reward": 0.7542774081230164, "action": -1.918809413909912}
{"mode": "train", "epochs": 8, "timestep": 14788, "ep_reward": 454.082275390625, "reward": 0.6452325582504272, "action": -0.6147927045822144}
{"mode": "train", "epochs": 8, "timestep": 14789, "ep_reward": 454.5950012207031, "reward": 0.512734055519104, "action": -0.8439679145812988}
{"mode": "train", "epochs": 8, "timestep": 14790, "ep_reward": 454.9462890625, "reward": 0.3512890338897705, "action": -0.06361901760101318}
{"mode": "train", "epochs": 8, "timestep": 14791, "ep_reward": 455.1877136230469, "reward": 0.24141907691955566, "action": -1.4436601400375366}
{"mode": "train", "epochs": 8, "timestep": 14792, "ep_reward": 455.29937744140625, "reward": 0.11166501045227051, "action": -1.5227954387664795}
{"mode": "train", "epochs": 8, "timestep": 14793, "ep_reward": 455.3030700683594, "reward": 0.0036844611167907715, "action": -1.7417241334915161}
{"mode": "train", "epochs": 8, "timestep": 14794, "ep_reward": 455.4512634277344, "reward": 0.14817947149276733, "action": -1.3320863246917725}
{"mode": "train", "epochs": 8, "timestep": 14795, "ep_reward": 455.73480224609375, "reward": 0.283544659614563, "action": -1.1135190725326538}
{"mode": "train", "epochs": 8, "timestep": 14796, "ep_reward": 456.15460205078125, "reward": 0.41980671882629395, "action": -1.735377311706543}
{"mode": "train", "epochs": 8, "timestep": 14797, "ep_reward": 456.6915588378906, "reward": 0.5369640588760376, "action": -0.4814321994781494}
{"mode": "train", "epochs": 8, "timestep": 14798, "ep_reward": 457.34124755859375, "reward": 0.6496974229812622, "action": -0.41013652086257935}
{"mode": "train", "epochs": 8, "timestep": 14799, "ep_reward": 458.07952880859375, "reward": 0.7382763624191284, "action": 0.17586910724639893}
{"mode": "train", "epochs": 8, "timestep": 14800, "ep_reward": 458.8875732421875, "reward": 0.8080310225486755, "action": -1.3063774108886719}
{"mode": "train", "epochs": 8, "timestep": 14801, "ep_reward": 459.7314453125, "reward": 0.8438658118247986, "action": -1.128702998161316}
{"mode": "train", "epochs": 8, "timestep": 14802, "ep_reward": 460.5958251953125, "reward": 0.8643707036972046, "action": -1.1242148876190186}
{"mode": "train", "epochs": 8, "timestep": 14803, "ep_reward": 461.4646301269531, "reward": 0.8687903881072998, "action": -1.7552402019500732}
{"mode": "train", "epochs": 8, "timestep": 14804, "ep_reward": 462.3157043457031, "reward": 0.8510806560516357, "action": -0.43686848878860474}
{"mode": "train", "epochs": 8, "timestep": 14805, "ep_reward": 463.1412658691406, "reward": 0.8255614638328552, "action": -0.6543180346488953}
{"mode": "train", "epochs": 8, "timestep": 14806, "ep_reward": 463.91619873046875, "reward": 0.7749378681182861, "action": -1.8288112878799438}
{"mode": "train", "epochs": 8, "timestep": 14807, "ep_reward": 464.5973815917969, "reward": 0.681189775466919, "action": -1.2908269166946411}
{"mode": "train", "epochs": 8, "timestep": 14808, "ep_reward": 465.15155029296875, "reward": 0.5541786551475525, "action": -0.7951789498329163}
{"mode": "train", "epochs": 8, "timestep": 14809, "ep_reward": 465.543212890625, "reward": 0.3916534185409546, "action": -1.7955927848815918}
{"mode": "train", "epochs": 8, "timestep": 14810, "ep_reward": 465.83380126953125, "reward": 0.2905903458595276, "action": -0.5721980333328247}
{"mode": "train", "epochs": 8, "timestep": 14811, "ep_reward": 466.00311279296875, "reward": 0.16930091381072998, "action": -1.0309114456176758}
{"mode": "train", "epochs": 8, "timestep": 14812, "ep_reward": 466.0311584472656, "reward": 0.028039991855621338, "action": -1.161803960800171}
{"mode": "train", "epochs": 8, "timestep": 14813, "ep_reward": 466.1204833984375, "reward": 0.0893145203590393, "action": -1.0614386796951294}
{"mode": "train", "epochs": 8, "timestep": 14814, "ep_reward": 466.34698486328125, "reward": 0.22650909423828125, "action": -0.814881443977356}
{"mode": "train", "epochs": 8, "timestep": 14815, "ep_reward": 466.71533203125, "reward": 0.3683449625968933, "action": -1.0029826164245605}
{"mode": "train", "epochs": 8, "timestep": 14816, "ep_reward": 467.2144470214844, "reward": 0.4991166591644287, "action": -0.2522962689399719}
{"mode": "train", "epochs": 8, "timestep": 14817, "ep_reward": 467.8353271484375, "reward": 0.6208861470222473, "action": -1.1708828210830688}
{"mode": "train", "epochs": 8, "timestep": 14818, "ep_reward": 468.5453186035156, "reward": 0.7099851369857788, "action": -0.35915952920913696}
{"mode": "train", "epochs": 8, "timestep": 14819, "ep_reward": 469.3300476074219, "reward": 0.7847180962562561, "action": -1.077614426612854}
{"mode": "train", "epochs": 8, "timestep": 14820, "ep_reward": 470.16217041015625, "reward": 0.832119882106781, "action": -0.4772675633430481}
{"mode": "train", "epochs": 8, "timestep": 14821, "ep_reward": 471.029052734375, "reward": 0.866887092590332, "action": -1.0973241329193115}
{"mode": "train", "epochs": 8, "timestep": 14822, "ep_reward": 471.9102783203125, "reward": 0.8812103271484375, "action": -1.3332939147949219}
{"mode": "train", "epochs": 8, "timestep": 14823, "ep_reward": 472.7896728515625, "reward": 0.8793846368789673, "action": -0.5332697033882141}
{"mode": "train", "epochs": 8, "timestep": 14824, "ep_reward": 473.65838623046875, "reward": 0.8686990141868591, "action": -0.9153226613998413}
{"mode": "train", "epochs": 8, "timestep": 14825, "ep_reward": 474.4956970214844, "reward": 0.8373231291770935, "action": -0.19147562980651855}
{"mode": "train", "epochs": 8, "timestep": 14826, "ep_reward": 475.28704833984375, "reward": 0.7913647294044495, "action": -1.1754295825958252}
{"mode": "train", "epochs": 8, "timestep": 14827, "ep_reward": 475.995361328125, "reward": 0.7083255648612976, "action": -1.4595160484313965}
{"mode": "train", "epochs": 8, "timestep": 14828, "ep_reward": 476.58123779296875, "reward": 0.5858711004257202, "action": -0.41278886795043945}
{"mode": "train", "epochs": 8, "timestep": 14829, "ep_reward": 477.0185852050781, "reward": 0.4373352527618408, "action": -1.2541074752807617}
{"mode": "train", "epochs": 8, "timestep": 14830, "ep_reward": 477.3186950683594, "reward": 0.30011749267578125, "action": -0.9019830226898193}
{"mode": "train", "epochs": 8, "timestep": 14831, "ep_reward": 477.49920654296875, "reward": 0.18051058053970337, "action": -1.5282487869262695}
{"mode": "train", "epochs": 8, "timestep": 14832, "ep_reward": 477.540283203125, "reward": 0.04108089208602905, "action": -1.0151784420013428}
{"mode": "train", "epochs": 8, "timestep": 14833, "ep_reward": 477.6169738769531, "reward": 0.07670313119888306, "action": -1.9273308515548706}
{"mode": "train", "epochs": 8, "timestep": 14834, "ep_reward": 477.82855224609375, "reward": 0.2115740180015564, "action": -0.30516135692596436}
{"mode": "train", "epochs": 8, "timestep": 14835, "ep_reward": 478.1890869140625, "reward": 0.3605422377586365, "action": -0.645842432975769}
{"mode": "train", "epochs": 8, "timestep": 14836, "ep_reward": 478.6847839355469, "reward": 0.4957082271575928, "action": -1.1792577505111694}
{"mode": "train", "epochs": 8, "timestep": 14837, "ep_reward": 479.2927551269531, "reward": 0.6079572439193726, "action": -0.18695759773254395}
{"mode": "train", "epochs": 8, "timestep": 14838, "ep_reward": 480.0020446777344, "reward": 0.7092869281768799, "action": -1.2437615394592285}
{"mode": "train", "epochs": 8, "timestep": 14839, "ep_reward": 480.7792663574219, "reward": 0.7772233486175537, "action": -0.08462053537368774}
{"mode": "train", "epochs": 8, "timestep": 14840, "ep_reward": 481.6143798828125, "reward": 0.8351273536682129, "action": -0.8713634014129639}
{"mode": "train", "epochs": 8, "timestep": 14841, "ep_reward": 482.4825439453125, "reward": 0.8681738376617432, "action": -1.2969141006469727}
{"mode": "train", "epochs": 8, "timestep": 14842, "ep_reward": 483.3655700683594, "reward": 0.8830109238624573, "action": -1.998221755027771}
{"mode": "train", "epochs": 8, "timestep": 14843, "ep_reward": 484.24420166015625, "reward": 0.878633975982666, "action": -0.5216587781906128}
{"mode": "train", "epochs": 8, "timestep": 14844, "ep_reward": 485.1150207519531, "reward": 0.8708222508430481, "action": -0.8180526494979858}
{"mode": "train", "epochs": 8, "timestep": 14845, "ep_reward": 485.9585266113281, "reward": 0.843504786491394, "action": -0.4000449776649475}
{"mode": "train", "epochs": 8, "timestep": 14846, "ep_reward": 486.75787353515625, "reward": 0.799333393573761, "action": -1.1658653020858765}
{"mode": "train", "epochs": 8, "timestep": 14847, "ep_reward": 487.4789123535156, "reward": 0.7210493087768555, "action": -0.9206051230430603}
{"mode": "train", "epochs": 8, "timestep": 14848, "ep_reward": 488.0903015136719, "reward": 0.6113971471786499, "action": -0.7783644199371338}
{"mode": "train", "epochs": 8, "timestep": 14849, "ep_reward": 488.5550231933594, "reward": 0.464713454246521, "action": -1.0487350225448608}
{"mode": "train", "epochs": 8, "timestep": 14850, "ep_reward": 488.8729553222656, "reward": 0.3179473280906677, "action": -0.5121669173240662}
{"mode": "train", "epochs": 8, "timestep": 14851, "ep_reward": 489.0746154785156, "reward": 0.201674222946167, "action": -1.1117843389511108}
{"mode": "train", "epochs": 8, "timestep": 14852, "ep_reward": 489.1400146484375, "reward": 0.06538647413253784, "action": -1.5664827823638916}
{"mode": "train", "epochs": 8, "timestep": 14853, "ep_reward": 489.1927185058594, "reward": 0.05271846055984497, "action": -1.1385283470153809}
{"mode": "train", "epochs": 8, "timestep": 14854, "ep_reward": 489.3834228515625, "reward": 0.19070887565612793, "action": -0.7445807456970215}
{"mode": "train", "epochs": 8, "timestep": 14855, "ep_reward": 489.7174987792969, "reward": 0.33406949043273926, "action": -1.1189175844192505}
{"mode": "train", "epochs": 8, "timestep": 14856, "ep_reward": 490.1838073730469, "reward": 0.4663044810295105, "action": -1.5668939352035522}
{"mode": "train", "epochs": 8, "timestep": 14857, "ep_reward": 490.7625732421875, "reward": 0.5787614583969116, "action": -1.9543757438659668}
{"mode": "train", "epochs": 8, "timestep": 14858, "ep_reward": 491.4303283691406, "reward": 0.6677662134170532, "action": -1.0971150398254395}
{"mode": "train", "epochs": 8, "timestep": 14859, "ep_reward": 492.17425537109375, "reward": 0.7439308166503906, "action": -0.40713852643966675}
{"mode": "train", "epochs": 8, "timestep": 14860, "ep_reward": 492.9776916503906, "reward": 0.8034505844116211, "action": -1.4825854301452637}
{"mode": "train", "epochs": 8, "timestep": 14861, "ep_reward": 493.80963134765625, "reward": 0.8319362998008728, "action": -0.9796572923660278}
{"mode": "train", "epochs": 8, "timestep": 14862, "ep_reward": 494.65570068359375, "reward": 0.8460737466812134, "action": -0.894942581653595}
{"mode": "train", "epochs": 8, "timestep": 14863, "ep_reward": 495.4977111816406, "reward": 0.8420132398605347, "action": -0.9724838137626648}
{"mode": "train", "epochs": 8, "timestep": 14864, "ep_reward": 496.3143615722656, "reward": 0.816643476486206, "action": -0.8532449007034302}
{"mode": "train", "epochs": 8, "timestep": 14865, "ep_reward": 497.0823974609375, "reward": 0.7680427432060242, "action": -0.2812473773956299}
{"mode": "train", "epochs": 8, "timestep": 14866, "ep_reward": 497.7788391113281, "reward": 0.6964447498321533, "action": -0.782258927822113}
{"mode": "train", "epochs": 8, "timestep": 14867, "ep_reward": 498.3623352050781, "reward": 0.5834994316101074, "action": -1.8131117820739746}
{"mode": "train", "epochs": 8, "timestep": 14868, "ep_reward": 498.7752380371094, "reward": 0.41290146112442017, "action": -1.6635582447052002}
{"mode": "train", "epochs": 8, "timestep": 14869, "ep_reward": 499.0867919921875, "reward": 0.3115389943122864, "action": -1.0738961696624756}
{"mode": "train", "epochs": 8, "timestep": 14870, "ep_reward": 499.2809753417969, "reward": 0.19419682025909424, "action": -0.445864200592041}
{"mode": "train", "epochs": 8, "timestep": 14871, "ep_reward": 499.3377380371094, "reward": 0.05677729845046997, "action": -0.7018702030181885}
{"mode": "train", "epochs": 8, "timestep": 14872, "ep_reward": 499.3992614746094, "reward": 0.06151682138442993, "action": -0.8642144203186035}
{"mode": "train", "epochs": 8, "timestep": 14873, "ep_reward": 499.599609375, "reward": 0.20033276081085205, "action": -0.4247701168060303}
{"mode": "train", "epochs": 8, "timestep": 14874, "ep_reward": 499.9468994140625, "reward": 0.34729844331741333, "action": -0.7894328236579895}
{"mode": "train", "epochs": 8, "timestep": 14875, "ep_reward": 500.4287109375, "reward": 0.48181504011154175, "action": -0.2714576721191406}
{"mode": "train", "epochs": 8, "timestep": 14876, "ep_reward": 501.0345153808594, "reward": 0.6058100461959839, "action": -0.9591805934906006}
{"mode": "train", "epochs": 8, "timestep": 14877, "ep_reward": 501.7348327636719, "reward": 0.7003041505813599, "action": -1.452322244644165}
{"mode": "train", "epochs": 8, "timestep": 14878, "ep_reward": 502.5037536621094, "reward": 0.7689212560653687, "action": -0.6438016891479492}
{"mode": "train", "epochs": 8, "timestep": 14879, "ep_reward": 503.3286437988281, "reward": 0.8248932957649231, "action": -1.34549081325531}
{"mode": "train", "epochs": 8, "timestep": 14880, "ep_reward": 504.1856689453125, "reward": 0.8570113182067871, "action": -0.45500099658966064}
{"mode": "train", "epochs": 8, "timestep": 14881, "ep_reward": 505.0661315917969, "reward": 0.8804765343666077, "action": -1.8020853996276855}
{"mode": "train", "epochs": 8, "timestep": 14882, "ep_reward": 505.945068359375, "reward": 0.878932774066925, "action": -1.3589123487472534}
{"mode": "train", "epochs": 8, "timestep": 14883, "ep_reward": 506.810546875, "reward": 0.8654652237892151, "action": -0.8934762477874756}
{"mode": "train", "epochs": 8, "timestep": 14884, "ep_reward": 507.6484375, "reward": 0.8378956913948059, "action": -1.3899998664855957}
{"mode": "train", "epochs": 8, "timestep": 14885, "ep_reward": 508.431640625, "reward": 0.7831997871398926, "action": -0.8210968971252441}
{"mode": "train", "epochs": 8, "timestep": 14886, "ep_reward": 509.13702392578125, "reward": 0.7053864002227783, "action": -1.3078117370605469}
{"mode": "train", "epochs": 8, "timestep": 14887, "ep_reward": 509.7229309082031, "reward": 0.5859181880950928, "action": -1.2984588146209717}
{"mode": "train", "epochs": 8, "timestep": 14888, "ep_reward": 510.1468811035156, "reward": 0.4239591360092163, "action": -0.4885614514350891}
{"mode": "train", "epochs": 8, "timestep": 14889, "ep_reward": 510.4539489746094, "reward": 0.3070668578147888, "action": -1.4904780387878418}
{"mode": "train", "epochs": 8, "timestep": 14890, "ep_reward": 510.64288330078125, "reward": 0.1889241337776184, "action": -1.0003929138183594}
{"mode": "train", "epochs": 8, "timestep": 14891, "ep_reward": 510.693603515625, "reward": 0.050727903842926025, "action": -0.8032779693603516}
{"mode": "train", "epochs": 8, "timestep": 14892, "ep_reward": 510.760986328125, "reward": 0.06739044189453125, "action": -1.5644721984863281}
{"mode": "train", "epochs": 8, "timestep": 14893, "ep_reward": 510.9643249511719, "reward": 0.203344464302063, "action": -1.476577639579773}
{"mode": "train", "epochs": 8, "timestep": 14894, "ep_reward": 511.3020935058594, "reward": 0.33777332305908203, "action": -1.1945337057113647}
{"mode": "train", "epochs": 8, "timestep": 14895, "ep_reward": 511.7720947265625, "reward": 0.46999460458755493, "action": -1.5050103664398193}
{"mode": "train", "epochs": 8, "timestep": 14896, "ep_reward": 512.355224609375, "reward": 0.5831164121627808, "action": -0.0929214358329773}
{"mode": "train", "epochs": 8, "timestep": 14897, "ep_reward": 513.0452270507812, "reward": 0.690021276473999, "action": -1.5043325424194336}
{"mode": "train", "epochs": 8, "timestep": 14898, "ep_reward": 513.802490234375, "reward": 0.7572652697563171, "action": -1.9282808303833008}
{"mode": "train", "epochs": 8, "timestep": 14899, "ep_reward": 514.6018676757812, "reward": 0.7994011640548706, "action": -0.8874847292900085}
{"mode": "train", "epochs": 8, "timestep": 14900, "ep_reward": 515.4329833984375, "reward": 0.8310891389846802, "action": -0.9335997104644775}
{"mode": "train", "epochs": 8, "timestep": 14901, "ep_reward": 516.2755126953125, "reward": 0.8425536751747131, "action": -1.5384392738342285}
{"mode": "train", "epochs": 8, "timestep": 14902, "ep_reward": 517.1041870117188, "reward": 0.828666090965271, "action": -0.594234049320221}
{"mode": "train", "epochs": 8, "timestep": 14903, "ep_reward": 517.905517578125, "reward": 0.8013339042663574, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 14904, "ep_reward": 518.63720703125, "reward": 0.7317184209823608, "action": -1.910394549369812}
{"mode": "train", "epochs": 8, "timestep": 14905, "ep_reward": 519.2627563476562, "reward": 0.6255632638931274, "action": -0.17434293031692505}
{"mode": "train", "epochs": 8, "timestep": 14906, "ep_reward": 519.7627563476562, "reward": 0.5000062584877014, "action": -1.7259585857391357}
{"mode": "train", "epochs": 8, "timestep": 14907, "ep_reward": 520.1376342773438, "reward": 0.37485837936401367, "action": -1.3914237022399902}
{"mode": "train", "epochs": 8, "timestep": 14908, "ep_reward": 520.40771484375, "reward": 0.27009081840515137, "action": -0.5313925743103027}
{"mode": "train", "epochs": 8, "timestep": 14909, "ep_reward": 520.5526733398438, "reward": 0.14498817920684814, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 14910, "ep_reward": 520.552978515625, "reward": 0.0002849698066711426, "action": -1.1558729410171509}
{"mode": "train", "epochs": 8, "timestep": 14911, "ep_reward": 520.66796875, "reward": 0.11497116088867188, "action": -0.15243583917617798}
{"mode": "train", "epochs": 8, "timestep": 14912, "ep_reward": 520.93212890625, "reward": 0.2641664743423462, "action": -0.49997615814208984}
{"mode": "train", "epochs": 8, "timestep": 14913, "ep_reward": 521.3384399414062, "reward": 0.40632349252700806, "action": -1.3792071342468262}
{"mode": "train", "epochs": 8, "timestep": 14914, "ep_reward": 521.8659057617188, "reward": 0.5274426937103271, "action": -0.6045202612876892}
{"mode": "train", "epochs": 8, "timestep": 14915, "ep_reward": 522.5062255859375, "reward": 0.6403112411499023, "action": -1.2131356000900269}
{"mode": "train", "epochs": 8, "timestep": 14916, "ep_reward": 523.2313232421875, "reward": 0.7251068353652954, "action": -1.131998896598816}
{"mode": "train", "epochs": 8, "timestep": 14917, "ep_reward": 524.0211181640625, "reward": 0.7898038029670715, "action": -1.2851121425628662}
{"mode": "train", "epochs": 8, "timestep": 14918, "ep_reward": 524.8549194335938, "reward": 0.8337955474853516, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 14919, "ep_reward": 525.7100830078125, "reward": 0.8551884889602661, "action": -1.1775856018066406}
{"mode": "train", "epochs": 8, "timestep": 14920, "ep_reward": 526.57763671875, "reward": 0.8675482869148254, "action": -1.0147063732147217}
{"mode": "train", "epochs": 8, "timestep": 14921, "ep_reward": 527.4428100585938, "reward": 0.8651646971702576, "action": -0.2240300178527832}
{"mode": "train", "epochs": 8, "timestep": 14922, "ep_reward": 528.2951049804688, "reward": 0.8523082137107849, "action": -1.8832433223724365}
{"mode": "train", "epochs": 8, "timestep": 14923, "ep_reward": 529.0990600585938, "reward": 0.8039453625679016, "action": -1.5801596641540527}
{"mode": "train", "epochs": 8, "timestep": 14924, "ep_reward": 529.8292846679688, "reward": 0.7302163243293762, "action": -1.2589361667633057}
{"mode": "train", "epochs": 8, "timestep": 14925, "ep_reward": 530.4539794921875, "reward": 0.6246805191040039, "action": -1.0643998384475708}
{"mode": "train", "epochs": 8, "timestep": 14926, "ep_reward": 530.9342041015625, "reward": 0.4802090525627136, "action": -1.5492782592773438}
{"mode": "train", "epochs": 8, "timestep": 14927, "ep_reward": 531.2821044921875, "reward": 0.3478946089744568, "action": -1.4022538661956787}
{"mode": "train", "epochs": 8, "timestep": 14928, "ep_reward": 531.5195922851562, "reward": 0.23749446868896484, "action": -1.4375056028366089}
{"mode": "train", "epochs": 8, "timestep": 14929, "ep_reward": 531.6267700195312, "reward": 0.10719764232635498, "action": -0.7237621545791626}
{"mode": "train", "epochs": 8, "timestep": 14930, "ep_reward": 531.6356811523438, "reward": 0.008890092372894287, "action": -0.5945680141448975}
{"mode": "train", "epochs": 8, "timestep": 14931, "ep_reward": 531.7882080078125, "reward": 0.1525557041168213, "action": -1.3789716958999634}
{"mode": "train", "epochs": 8, "timestep": 14932, "ep_reward": 532.07568359375, "reward": 0.28746676445007324, "action": -0.8297719955444336}
{"mode": "train", "epochs": 8, "timestep": 14933, "ep_reward": 532.5028686523438, "reward": 0.42718327045440674, "action": -0.7958953976631165}
{"mode": "train", "epochs": 8, "timestep": 14934, "ep_reward": 533.0567626953125, "reward": 0.553884744644165, "action": -1.1631959676742554}
{"mode": "train", "epochs": 8, "timestep": 14935, "ep_reward": 533.713134765625, "reward": 0.6563493609428406, "action": -0.4701468348503113}
{"mode": "train", "epochs": 8, "timestep": 14936, "ep_reward": 534.4562377929688, "reward": 0.7431131601333618, "action": -1.4425060749053955}
{"mode": "train", "epochs": 8, "timestep": 14937, "ep_reward": 535.2543334960938, "reward": 0.7981122136116028, "action": -0.5690879821777344}
{"mode": "train", "epochs": 8, "timestep": 14938, "ep_reward": 536.0956420898438, "reward": 0.8413277864456177, "action": -0.9817646145820618}
{"mode": "train", "epochs": 8, "timestep": 14939, "ep_reward": 536.9588012695312, "reward": 0.8631518483161926, "action": -0.50797438621521}
{"mode": "train", "epochs": 8, "timestep": 14940, "ep_reward": 537.8314208984375, "reward": 0.8726487159729004, "action": -1.221940040588379}
{"mode": "train", "epochs": 8, "timestep": 14941, "ep_reward": 538.6912841796875, "reward": 0.8598575592041016, "action": -1.472349762916565}
{"mode": "train", "epochs": 8, "timestep": 14942, "ep_reward": 539.51708984375, "reward": 0.8257894515991211, "action": -0.03332364559173584}
{"mode": "train", "epochs": 8, "timestep": 14943, "ep_reward": 540.2997436523438, "reward": 0.7826840877532959, "action": -0.5394573211669922}
{"mode": "train", "epochs": 8, "timestep": 14944, "ep_reward": 541.0071411132812, "reward": 0.7074156999588013, "action": -0.24647647142410278}
{"mode": "train", "epochs": 8, "timestep": 14945, "ep_reward": 541.60986328125, "reward": 0.6026918888092041, "action": -0.8869110345840454}
{"mode": "train", "epochs": 8, "timestep": 14946, "ep_reward": 542.061279296875, "reward": 0.451430082321167, "action": -1.91531240940094}
{"mode": "train", "epochs": 8, "timestep": 14947, "ep_reward": 542.37158203125, "reward": 0.3103039860725403, "action": -0.9603279232978821}
{"mode": "train", "epochs": 8, "timestep": 14948, "ep_reward": 542.5642700195312, "reward": 0.1926947832107544, "action": -0.7224525809288025}
{"mode": "train", "epochs": 8, "timestep": 14949, "ep_reward": 542.6193237304688, "reward": 0.05505239963531494, "action": -0.8150044083595276}
{"mode": "train", "epochs": 8, "timestep": 14950, "ep_reward": 542.6825561523438, "reward": 0.06324046850204468, "action": -0.6571329832077026}
{"mode": "train", "epochs": 8, "timestep": 14951, "ep_reward": 542.88720703125, "reward": 0.20466625690460205, "action": -0.7472410202026367}
{"mode": "train", "epochs": 8, "timestep": 14952, "ep_reward": 543.2342529296875, "reward": 0.34706199169158936, "action": -1.1096614599227905}
{"mode": "train", "epochs": 8, "timestep": 14953, "ep_reward": 543.7122802734375, "reward": 0.47800034284591675, "action": -0.7745038270950317}
{"mode": "train", "epochs": 8, "timestep": 14954, "ep_reward": 544.3097534179688, "reward": 0.5974431037902832, "action": -0.9401059746742249}
{"mode": "train", "epochs": 8, "timestep": 14955, "ep_reward": 545.0033569335938, "reward": 0.6936267614364624, "action": -1.042478322982788}
{"mode": "train", "epochs": 8, "timestep": 14956, "ep_reward": 545.7698364257812, "reward": 0.766465961933136, "action": -1.2106720209121704}
{"mode": "train", "epochs": 8, "timestep": 14957, "ep_reward": 546.5869750976562, "reward": 0.8171432614326477, "action": -0.06594705581665039}
{"mode": "train", "epochs": 8, "timestep": 14958, "ep_reward": 547.44580078125, "reward": 0.8588505983352661, "action": -0.6366128921508789}
{"mode": "train", "epochs": 8, "timestep": 14959, "ep_reward": 548.3247680664062, "reward": 0.8789903521537781, "action": -1.1981582641601562}
{"mode": "train", "epochs": 8, "timestep": 14960, "ep_reward": 549.204833984375, "reward": 0.8800389766693115, "action": -0.6622438430786133}
{"mode": "train", "epochs": 8, "timestep": 14961, "ep_reward": 550.0751342773438, "reward": 0.8702720999717712, "action": 0.036965906620025635}
{"mode": "train", "epochs": 8, "timestep": 14962, "ep_reward": 550.925048828125, "reward": 0.849901020526886, "action": -0.6617643237113953}
{"mode": "train", "epochs": 8, "timestep": 14963, "ep_reward": 551.728759765625, "reward": 0.8037040829658508, "action": -0.8238389492034912}
{"mode": "train", "epochs": 8, "timestep": 14964, "ep_reward": 552.458984375, "reward": 0.7302228212356567, "action": -0.8536520600318909}
{"mode": "train", "epochs": 8, "timestep": 14965, "ep_reward": 553.0828247070312, "reward": 0.6238381862640381, "action": -1.224069595336914}
{"mode": "train", "epochs": 8, "timestep": 14966, "ep_reward": 553.556640625, "reward": 0.4737962484359741, "action": -0.8526986837387085}
{"mode": "train", "epochs": 8, "timestep": 14967, "ep_reward": 553.8779296875, "reward": 0.32131505012512207, "action": -1.3300817012786865}
{"mode": "train", "epochs": 8, "timestep": 14968, "ep_reward": 554.0835571289062, "reward": 0.20565736293792725, "action": -1.8323839902877808}
{"mode": "train", "epochs": 8, "timestep": 14969, "ep_reward": 554.1537475585938, "reward": 0.07020151615142822, "action": -1.3145231008529663}
{"mode": "train", "epochs": 8, "timestep": 14970, "ep_reward": 554.20166015625, "reward": 0.04792308807373047, "action": -0.6768046021461487}
{"mode": "train", "epochs": 8, "timestep": 14971, "ep_reward": 554.3901977539062, "reward": 0.1885509490966797, "action": -1.2665621042251587}
{"mode": "train", "epochs": 8, "timestep": 14972, "ep_reward": 554.7152709960938, "reward": 0.3250555396080017, "action": -0.6199012994766235}
{"mode": "train", "epochs": 8, "timestep": 14973, "ep_reward": 555.1797485351562, "reward": 0.4644995927810669, "action": -0.6810281276702881}
{"mode": "train", "epochs": 8, "timestep": 14974, "ep_reward": 555.766845703125, "reward": 0.587098240852356, "action": -0.876724123954773}
{"mode": "train", "epochs": 8, "timestep": 14975, "ep_reward": 556.452880859375, "reward": 0.6860103607177734, "action": -1.0785523653030396}
{"mode": "train", "epochs": 8, "timestep": 14976, "ep_reward": 557.21337890625, "reward": 0.7604841589927673, "action": -0.3641912341117859}
{"mode": "train", "epochs": 8, "timestep": 14977, "ep_reward": 558.033447265625, "reward": 0.8200828433036804, "action": -1.0773365497589111}
{"mode": "train", "epochs": 8, "timestep": 14978, "ep_reward": 558.8876953125, "reward": 0.8542259931564331, "action": -1.9976081848144531}
{"mode": "train", "epochs": 8, "timestep": 14979, "ep_reward": 559.752685546875, "reward": 0.864966094493866, "action": -1.3377548456192017}
{"mode": "train", "epochs": 8, "timestep": 14980, "ep_reward": 560.6178588867188, "reward": 0.8651808500289917, "action": -1.783263921737671}
{"mode": "train", "epochs": 8, "timestep": 14981, "ep_reward": 561.4618530273438, "reward": 0.8440049886703491, "action": -1.105600118637085}
{"mode": "train", "epochs": 8, "timestep": 14982, "ep_reward": 562.26953125, "reward": 0.8076858520507812, "action": -0.936720609664917}
{"mode": "train", "epochs": 8, "timestep": 14983, "ep_reward": 563.0166015625, "reward": 0.7470824122428894, "action": -1.1316883563995361}
{"mode": "train", "epochs": 8, "timestep": 14984, "ep_reward": 563.668212890625, "reward": 0.6516073942184448, "action": -0.8003414273262024}
{"mode": "train", "epochs": 8, "timestep": 14985, "ep_reward": 564.1893310546875, "reward": 0.5211108326911926, "action": -0.051028668880462646}
{"mode": "train", "epochs": 8, "timestep": 14986, "ep_reward": 564.5604248046875, "reward": 0.37111538648605347, "action": -0.4518292546272278}
{"mode": "train", "epochs": 8, "timestep": 14987, "ep_reward": 564.8258056640625, "reward": 0.2653881907463074, "action": -0.9849849343299866}
{"mode": "train", "epochs": 8, "timestep": 14988, "ep_reward": 564.96533203125, "reward": 0.1395512819290161, "action": -1.8708772659301758}
{"mode": "train", "epochs": 8, "timestep": 14989, "ep_reward": 564.9592895507812, "reward": -0.006049394607543945, "action": -1.5037485361099243}
{"mode": "train", "epochs": 8, "timestep": 14990, "ep_reward": 565.079833984375, "reward": 0.1205294132232666, "action": -0.955816388130188}
{"mode": "train", "epochs": 8, "timestep": 14991, "ep_reward": 565.339599609375, "reward": 0.2597927451133728, "action": -1.6644691228866577}
{"mode": "train", "epochs": 8, "timestep": 14992, "ep_reward": 565.7293701171875, "reward": 0.38978421688079834, "action": -1.4929322004318237}
{"mode": "train", "epochs": 8, "timestep": 14993, "ep_reward": 566.2424926757812, "reward": 0.5131150484085083, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 14994, "ep_reward": 566.85595703125, "reward": 0.6134380102157593, "action": -1.9885854721069336}
{"mode": "train", "epochs": 8, "timestep": 14995, "ep_reward": 567.5488891601562, "reward": 0.6929266452789307, "action": -1.6002098321914673}
{"mode": "train", "epochs": 8, "timestep": 14996, "ep_reward": 568.3023681640625, "reward": 0.7534555196762085, "action": -0.9698273539543152}
{"mode": "train", "epochs": 8, "timestep": 14997, "ep_reward": 569.0991821289062, "reward": 0.7968329787254333, "action": -0.41710448265075684}
{"mode": "train", "epochs": 8, "timestep": 14998, "ep_reward": 569.9219360351562, "reward": 0.8227803707122803, "action": -0.8900233507156372}
{"mode": "train", "epochs": 8, "timestep": 14999, "ep_reward": 570.744140625, "reward": 0.822199821472168, "action": -1.5435419082641602}
{"mode": "train", "epochs": 8, "timestep": 15000, "ep_reward": 571.535888671875, "reward": 0.7917399406433105, "action": -1.6064701080322266}
{"mode": "train", "epochs": 8, "timestep": 15001, "ep_reward": 572.267578125, "reward": 0.7316982746124268, "action": -1.6330320835113525}
{"mode": "train", "epochs": 8, "timestep": 15002, "ep_reward": 572.902099609375, "reward": 0.6345101594924927, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 15003, "ep_reward": 573.3884887695312, "reward": 0.48638027906417847, "action": -1.4161615371704102}
{"mode": "train", "epochs": 8, "timestep": 15004, "ep_reward": 573.7772827148438, "reward": 0.3888102173805237, "action": -0.9173111319541931}
{"mode": "train", "epochs": 8, "timestep": 15005, "ep_reward": 574.064208984375, "reward": 0.28690892457962036, "action": -0.9483492374420166}
{"mode": "train", "epochs": 8, "timestep": 15006, "ep_reward": 574.2291870117188, "reward": 0.16499584913253784, "action": -1.0755054950714111}
{"mode": "train", "epochs": 8, "timestep": 15007, "ep_reward": 574.2522583007812, "reward": 0.023081719875335693, "action": -1.200481653213501}
{"mode": "train", "epochs": 8, "timestep": 15008, "ep_reward": 574.3460693359375, "reward": 0.09379410743713379, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 15009, "ep_reward": 574.5721435546875, "reward": 0.22610169649124146, "action": -1.7961784601211548}
{"mode": "train", "epochs": 8, "timestep": 15010, "ep_reward": 574.9286499023438, "reward": 0.35649770498275757, "action": -1.9470570087432861}
{"mode": "train", "epochs": 8, "timestep": 15011, "ep_reward": 575.4073486328125, "reward": 0.47870177030563354, "action": -0.7669292688369751}
{"mode": "train", "epochs": 8, "timestep": 15012, "ep_reward": 576.0062255859375, "reward": 0.5988547801971436, "action": -1.2396689653396606}
{"mode": "train", "epochs": 8, "timestep": 15013, "ep_reward": 576.6959228515625, "reward": 0.6896681785583496, "action": -1.0942877531051636}
{"mode": "train", "epochs": 8, "timestep": 15014, "ep_reward": 577.4536743164062, "reward": 0.7577311992645264, "action": -1.0387918949127197}
{"mode": "train", "epochs": 8, "timestep": 15015, "ep_reward": 578.2567138671875, "reward": 0.8030475974082947, "action": -0.5111873149871826}
{"mode": "train", "epochs": 8, "timestep": 15016, "ep_reward": 579.0883178710938, "reward": 0.8316272497177124, "action": -1.4750988483428955}
{"mode": "train", "epochs": 8, "timestep": 15017, "ep_reward": 579.9190673828125, "reward": 0.8307583332061768, "action": -0.8062210083007812}
{"mode": "train", "epochs": 8, "timestep": 15018, "ep_reward": 580.73388671875, "reward": 0.8148046731948853, "action": -0.8218613862991333}
{"mode": "train", "epochs": 8, "timestep": 15019, "ep_reward": 581.5079956054688, "reward": 0.7741344571113586, "action": -1.9822700023651123}
{"mode": "train", "epochs": 8, "timestep": 15020, "ep_reward": 582.1976318359375, "reward": 0.689616322517395, "action": -0.20780211687088013}
{"mode": "train", "epochs": 8, "timestep": 15021, "ep_reward": 582.7862548828125, "reward": 0.5886093974113464, "action": -1.4547502994537354}
{"mode": "train", "epochs": 8, "timestep": 15022, "ep_reward": 583.2139282226562, "reward": 0.42766737937927246, "action": -0.39546072483062744}
{"mode": "train", "epochs": 8, "timestep": 15023, "ep_reward": 583.5465087890625, "reward": 0.33258968591690063, "action": -1.3235713243484497}
{"mode": "train", "epochs": 8, "timestep": 15024, "ep_reward": 583.7657470703125, "reward": 0.2192094922065735, "action": -1.1948387622833252}
{"mode": "train", "epochs": 8, "timestep": 15025, "ep_reward": 583.8516235351562, "reward": 0.08588910102844238, "action": -0.39502835273742676}
{"mode": "train", "epochs": 8, "timestep": 15026, "ep_reward": 583.88330078125, "reward": 0.03169018030166626, "action": -1.334194540977478}
{"mode": "train", "epochs": 8, "timestep": 15027, "ep_reward": 584.0557250976562, "reward": 0.17240750789642334, "action": -1.547987937927246}
{"mode": "train", "epochs": 8, "timestep": 15028, "ep_reward": 584.3612670898438, "reward": 0.30553334951400757, "action": -1.318683385848999}
{"mode": "train", "epochs": 8, "timestep": 15029, "ep_reward": 584.7999267578125, "reward": 0.438659131526947, "action": -0.3755113482475281}
{"mode": "train", "epochs": 8, "timestep": 15030, "ep_reward": 585.3690185546875, "reward": 0.5690895915031433, "action": -1.1437084674835205}
{"mode": "train", "epochs": 8, "timestep": 15031, "ep_reward": 586.0377197265625, "reward": 0.6686926484107971, "action": -0.38656163215637207}
{"mode": "train", "epochs": 8, "timestep": 15032, "ep_reward": 586.7904052734375, "reward": 0.7527045011520386, "action": -1.4968242645263672}
{"mode": "train", "epochs": 8, "timestep": 15033, "ep_reward": 587.5939331054688, "reward": 0.8035305738449097, "action": -1.2269644737243652}
{"mode": "train", "epochs": 8, "timestep": 15034, "ep_reward": 588.4315185546875, "reward": 0.8376119136810303, "action": -0.6058123111724854}
{"mode": "train", "epochs": 8, "timestep": 15035, "ep_reward": 589.2904052734375, "reward": 0.8588952422142029, "action": -1.6833778619766235}
{"mode": "train", "epochs": 8, "timestep": 15036, "ep_reward": 590.1441040039062, "reward": 0.8536745309829712, "action": -0.3101619482040405}
{"mode": "train", "epochs": 8, "timestep": 15037, "ep_reward": 590.9862670898438, "reward": 0.8421636819839478, "action": -0.7181620597839355}
{"mode": "train", "epochs": 8, "timestep": 15038, "ep_reward": 591.7924194335938, "reward": 0.8061358332633972, "action": -1.2963240146636963}
{"mode": "train", "epochs": 8, "timestep": 15039, "ep_reward": 592.5303955078125, "reward": 0.7379640936851501, "action": -1.0908899307250977}
{"mode": "train", "epochs": 8, "timestep": 15040, "ep_reward": 593.16845703125, "reward": 0.6380862593650818, "action": -1.406649112701416}
{"mode": "train", "epochs": 8, "timestep": 15041, "ep_reward": 593.6614990234375, "reward": 0.49307191371917725, "action": 0.04373204708099365}
{"mode": "train", "epochs": 8, "timestep": 15042, "ep_reward": 594.0184936523438, "reward": 0.3569692373275757, "action": -0.46128183603286743}
{"mode": "train", "epochs": 8, "timestep": 15043, "ep_reward": 594.2667846679688, "reward": 0.24827593564987183, "action": -1.35536527633667}
{"mode": "train", "epochs": 8, "timestep": 15044, "ep_reward": 594.3865966796875, "reward": 0.11979955434799194, "action": -0.01952970027923584}
{"mode": "train", "epochs": 8, "timestep": 15045, "ep_reward": 594.381591796875, "reward": -0.005024552345275879, "action": -0.09026223421096802}
{"mode": "train", "epochs": 8, "timestep": 15046, "ep_reward": 594.5228271484375, "reward": 0.14121013879776, "action": -1.2081608772277832}
{"mode": "train", "epochs": 8, "timestep": 15047, "ep_reward": 594.8005981445312, "reward": 0.27774399518966675, "action": -1.3938237428665161}
{"mode": "train", "epochs": 8, "timestep": 15048, "ep_reward": 595.2113037109375, "reward": 0.4106993079185486, "action": -0.8842077255249023}
{"mode": "train", "epochs": 8, "timestep": 15049, "ep_reward": 595.7498779296875, "reward": 0.5385676622390747, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 15050, "ep_reward": 596.3846435546875, "reward": 0.6347509622573853, "action": -1.407454013824463}
{"mode": "train", "epochs": 8, "timestep": 15051, "ep_reward": 597.1008911132812, "reward": 0.7162342071533203, "action": -1.2902048826217651}
{"mode": "train", "epochs": 8, "timestep": 15052, "ep_reward": 597.8767700195312, "reward": 0.7758772373199463, "action": -1.536123275756836}
{"mode": "train", "epochs": 8, "timestep": 15053, "ep_reward": 598.688232421875, "reward": 0.8114654421806335, "action": -0.6501017212867737}
{"mode": "train", "epochs": 8, "timestep": 15054, "ep_reward": 599.5230102539062, "reward": 0.8347993493080139, "action": -0.6317334175109863}
{"mode": "train", "epochs": 8, "timestep": 15055, "ep_reward": 600.3611450195312, "reward": 0.8381204605102539, "action": -1.1974924802780151}
{"mode": "train", "epochs": 8, "timestep": 15056, "ep_reward": 601.1762084960938, "reward": 0.8150333166122437, "action": -1.5597593784332275}
{"mode": "train", "epochs": 8, "timestep": 15057, "ep_reward": 601.9390258789062, "reward": 0.7627990245819092, "action": -1.5146846771240234}
{"mode": "train", "epochs": 8, "timestep": 15058, "ep_reward": 602.6173095703125, "reward": 0.6782985925674438, "action": -0.9646088480949402}
{"mode": "train", "epochs": 8, "timestep": 15059, "ep_reward": 603.17822265625, "reward": 0.5609056353569031, "action": -0.6909619569778442}
{"mode": "train", "epochs": 8, "timestep": 15060, "ep_reward": 603.5913696289062, "reward": 0.4131678342819214, "action": -1.2907891273498535}
{"mode": "train", "epochs": 8, "timestep": 15061, "ep_reward": 603.9081420898438, "reward": 0.31676602363586426, "action": -1.156079888343811}
{"mode": "train", "epochs": 8, "timestep": 15062, "ep_reward": 604.1085205078125, "reward": 0.20038819313049316, "action": -0.7947880029678345}
{"mode": "train", "epochs": 8, "timestep": 15063, "ep_reward": 604.1724853515625, "reward": 0.06396102905273438, "action": -0.8523337841033936}
{"mode": "train", "epochs": 8, "timestep": 15064, "ep_reward": 604.226806640625, "reward": 0.05434352159500122, "action": -0.28773146867752075}
{"mode": "train", "epochs": 8, "timestep": 15065, "ep_reward": 604.4266967773438, "reward": 0.19987648725509644, "action": -1.9437203407287598}
{"mode": "train", "epochs": 8, "timestep": 15066, "ep_reward": 604.753662109375, "reward": 0.32698309421539307, "action": -0.4493604898452759}
{"mode": "train", "epochs": 8, "timestep": 15067, "ep_reward": 605.2222900390625, "reward": 0.4686298370361328, "action": -1.0392054319381714}
{"mode": "train", "epochs": 8, "timestep": 15068, "ep_reward": 605.8089599609375, "reward": 0.5866960287094116, "action": -1.1764533519744873}
{"mode": "train", "epochs": 8, "timestep": 15069, "ep_reward": 606.491455078125, "reward": 0.6825119256973267, "action": -0.9781998991966248}
{"mode": "train", "epochs": 8, "timestep": 15070, "ep_reward": 607.2493286132812, "reward": 0.7578669786453247, "action": -0.9786244630813599}
{"mode": "train", "epochs": 8, "timestep": 15071, "ep_reward": 608.060791015625, "reward": 0.8114675879478455, "action": -1.110042929649353}
{"mode": "train", "epochs": 8, "timestep": 15072, "ep_reward": 608.9052734375, "reward": 0.8444836139678955, "action": -1.3843474388122559}
{"mode": "train", "epochs": 8, "timestep": 15073, "ep_reward": 609.7631225585938, "reward": 0.8578223586082458, "action": -0.40388935804367065}
{"mode": "train", "epochs": 8, "timestep": 15074, "ep_reward": 610.6256713867188, "reward": 0.8625466823577881, "action": -0.9593935608863831}
{"mode": "train", "epochs": 8, "timestep": 15075, "ep_reward": 611.4703979492188, "reward": 0.8447189331054688, "action": -0.6112853288650513}
{"mode": "train", "epochs": 8, "timestep": 15076, "ep_reward": 612.2799682617188, "reward": 0.8095831274986267, "action": -0.7361551523208618}
{"mode": "train", "epochs": 8, "timestep": 15077, "ep_reward": 613.0281372070312, "reward": 0.7481859922409058, "action": -0.9815115928649902}
{"mode": "train", "epochs": 8, "timestep": 15078, "ep_reward": 613.6803588867188, "reward": 0.6522293090820312, "action": -1.2141010761260986}
{"mode": "train", "epochs": 8, "timestep": 15079, "ep_reward": 614.1943359375, "reward": 0.5139797329902649, "action": -1.499145746231079}
{"mode": "train", "epochs": 8, "timestep": 15080, "ep_reward": 614.5559692382812, "reward": 0.36164993047714233, "action": 0.4007779359817505}
{"mode": "train", "epochs": 8, "timestep": 15081, "ep_reward": 614.809814453125, "reward": 0.2538486123085022, "action": -1.6633260250091553}
{"mode": "train", "epochs": 8, "timestep": 15082, "ep_reward": 614.9360961914062, "reward": 0.1263008713722229, "action": -1.1516566276550293}
{"mode": "train", "epochs": 8, "timestep": 15083, "ep_reward": 614.9235229492188, "reward": -0.012570500373840332, "action": -1.3119033575057983}
{"mode": "train", "epochs": 8, "timestep": 15084, "ep_reward": 615.0575561523438, "reward": 0.13402152061462402, "action": -0.7319458723068237}
{"mode": "train", "epochs": 8, "timestep": 15085, "ep_reward": 615.333984375, "reward": 0.2764478325843811, "action": -1.437037467956543}
{"mode": "train", "epochs": 8, "timestep": 15086, "ep_reward": 615.7421264648438, "reward": 0.4081294536590576, "action": -1.201507329940796}
{"mode": "train", "epochs": 8, "timestep": 15087, "ep_reward": 616.2747192382812, "reward": 0.5325791239738464, "action": -0.2702291011810303}
{"mode": "train", "epochs": 8, "timestep": 15088, "ep_reward": 616.923095703125, "reward": 0.648349940776825, "action": -0.9987653493881226}
{"mode": "train", "epochs": 8, "timestep": 15089, "ep_reward": 617.6556396484375, "reward": 0.7325268983840942, "action": -1.0216374397277832}
{"mode": "train", "epochs": 8, "timestep": 15090, "ep_reward": 618.4501953125, "reward": 0.7945623397827148, "action": -0.5673697590827942}
{"mode": "train", "epochs": 8, "timestep": 15091, "ep_reward": 619.2907104492188, "reward": 0.840512216091156, "action": -0.7025418281555176}
{"mode": "train", "epochs": 8, "timestep": 15092, "ep_reward": 620.1581420898438, "reward": 0.8674207329750061, "action": -1.2414023876190186}
{"mode": "train", "epochs": 8, "timestep": 15093, "ep_reward": 621.0325317382812, "reward": 0.874384880065918, "action": -0.03175508975982666}
{"mode": "train", "epochs": 8, "timestep": 15094, "ep_reward": 621.908447265625, "reward": 0.8759136199951172, "action": -0.7189114093780518}
{"mode": "train", "epochs": 8, "timestep": 15095, "ep_reward": 622.7640380859375, "reward": 0.8555734753608704, "action": -1.160995364189148}
{"mode": "train", "epochs": 8, "timestep": 15096, "ep_reward": 623.5756225585938, "reward": 0.8115688562393188, "action": -0.9280688166618347}
{"mode": "train", "epochs": 8, "timestep": 15097, "ep_reward": 624.3198852539062, "reward": 0.7442718148231506, "action": 0.21749693155288696}
{"mode": "train", "epochs": 8, "timestep": 15098, "ep_reward": 624.9795532226562, "reward": 0.6596416234970093, "action": -1.6738085746765137}
{"mode": "train", "epochs": 8, "timestep": 15099, "ep_reward": 625.4945068359375, "reward": 0.5149651765823364, "action": -1.6421785354614258}
{"mode": "train", "epochs": 8, "timestep": 15100, "ep_reward": 625.8450317382812, "reward": 0.3505120873451233, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 15101, "ep_reward": 626.0859375, "reward": 0.24090129137039185, "action": -0.49076133966445923}
{"mode": "train", "epochs": 8, "timestep": 15102, "ep_reward": 626.1969604492188, "reward": 0.11104011535644531, "action": -0.7067700624465942}
{"mode": "train", "epochs": 8, "timestep": 15103, "ep_reward": 626.2015380859375, "reward": 0.004572093486785889, "action": -1.3708757162094116}
{"mode": "train", "epochs": 8, "timestep": 15104, "ep_reward": 626.3504638671875, "reward": 0.14891934394836426, "action": -1.1379880905151367}
{"mode": "train", "epochs": 8, "timestep": 15105, "ep_reward": 626.6371459960938, "reward": 0.2867075204849243, "action": -1.1238503456115723}
{"mode": "train", "epochs": 8, "timestep": 15106, "ep_reward": 627.0596313476562, "reward": 0.422507643699646, "action": -0.38099002838134766}
{"mode": "train", "epochs": 8, "timestep": 15107, "ep_reward": 627.6141967773438, "reward": 0.5545480251312256, "action": -0.8483020067214966}
{"mode": "train", "epochs": 8, "timestep": 15108, "ep_reward": 628.2742309570312, "reward": 0.660051703453064, "action": -1.6011210680007935}
{"mode": "train", "epochs": 8, "timestep": 15109, "ep_reward": 629.010009765625, "reward": 0.7357808351516724, "action": -1.3080813884735107}
{"mode": "train", "epochs": 8, "timestep": 15110, "ep_reward": 629.8035278320312, "reward": 0.7934924364089966, "action": -1.1382110118865967}
{"mode": "train", "epochs": 8, "timestep": 15111, "ep_reward": 630.636474609375, "reward": 0.8329606056213379, "action": 0.4399571418762207}
{"mode": "train", "epochs": 8, "timestep": 15112, "ep_reward": 631.5040283203125, "reward": 0.8675320148468018, "action": -1.0336110591888428}
{"mode": "train", "epochs": 8, "timestep": 15113, "ep_reward": 632.377197265625, "reward": 0.8731886744499207, "action": -0.77065110206604}
{"mode": "train", "epochs": 8, "timestep": 15114, "ep_reward": 633.2423706054688, "reward": 0.865149974822998, "action": -0.2740994095802307}
{"mode": "train", "epochs": 8, "timestep": 15115, "ep_reward": 634.08642578125, "reward": 0.8440480828285217, "action": -0.6593049764633179}
{"mode": "train", "epochs": 8, "timestep": 15116, "ep_reward": 634.88525390625, "reward": 0.7988119125366211, "action": -1.7390069961547852}
{"mode": "train", "epochs": 8, "timestep": 15117, "ep_reward": 635.6002197265625, "reward": 0.71494060754776, "action": -1.0887235403060913}
{"mode": "train", "epochs": 8, "timestep": 15118, "ep_reward": 636.2024536132812, "reward": 0.6022528409957886, "action": -0.5877999067306519}
{"mode": "train", "epochs": 8, "timestep": 15119, "ep_reward": 636.6588745117188, "reward": 0.45643728971481323, "action": -1.089688777923584}
{"mode": "train", "epochs": 8, "timestep": 15120, "ep_reward": 636.97802734375, "reward": 0.3191351294517517, "action": -0.9650497436523438}
{"mode": "train", "epochs": 8, "timestep": 15121, "ep_reward": 637.18115234375, "reward": 0.2031385898590088, "action": -1.090216040611267}
{"mode": "train", "epochs": 8, "timestep": 15122, "ep_reward": 637.2483520507812, "reward": 0.06717449426651001, "action": -0.9672859311103821}
{"mode": "train", "epochs": 8, "timestep": 15123, "ep_reward": 637.2993774414062, "reward": 0.051037609577178955, "action": -0.8565369248390198}
{"mode": "train", "epochs": 8, "timestep": 15124, "ep_reward": 637.4889526367188, "reward": 0.18956732749938965, "action": -0.9714230298995972}
{"mode": "train", "epochs": 8, "timestep": 15125, "ep_reward": 637.8190307617188, "reward": 0.3300754427909851, "action": -0.8756977319717407}
{"mode": "train", "epochs": 8, "timestep": 15126, "ep_reward": 638.284912109375, "reward": 0.46588385105133057, "action": -0.8043209910392761}
{"mode": "train", "epochs": 8, "timestep": 15127, "ep_reward": 638.8719482421875, "reward": 0.5870198607444763, "action": -0.5480796694755554}
{"mode": "train", "epochs": 8, "timestep": 15128, "ep_reward": 639.5611572265625, "reward": 0.6892281770706177, "action": -0.646763801574707}
{"mode": "train", "epochs": 8, "timestep": 15129, "ep_reward": 640.3280029296875, "reward": 0.7668561935424805, "action": -1.103509783744812}
{"mode": "train", "epochs": 8, "timestep": 15130, "ep_reward": 641.1469116210938, "reward": 0.8188812732696533, "action": -1.8612818717956543}
{"mode": "train", "epochs": 8, "timestep": 15131, "ep_reward": 641.9935913085938, "reward": 0.846676766872406, "action": -0.19495773315429688}
{"mode": "train", "epochs": 8, "timestep": 15132, "ep_reward": 642.8652954101562, "reward": 0.8716855049133301, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 15133, "ep_reward": 643.7313232421875, "reward": 0.866000771522522, "action": -1.7312942743301392}
{"mode": "train", "epochs": 8, "timestep": 15134, "ep_reward": 644.5762939453125, "reward": 0.8449894189834595, "action": -0.8268251419067383}
{"mode": "train", "epochs": 8, "timestep": 15135, "ep_reward": 645.3876342773438, "reward": 0.8113170266151428, "action": -0.5920624732971191}
{"mode": "train", "epochs": 8, "timestep": 15136, "ep_reward": 646.1427001953125, "reward": 0.7550917863845825, "action": -1.4985358715057373}
{"mode": "train", "epochs": 8, "timestep": 15137, "ep_reward": 646.7996215820312, "reward": 0.6569114327430725, "action": -0.5482850670814514}
{"mode": "train", "epochs": 8, "timestep": 15138, "ep_reward": 647.331298828125, "reward": 0.531661868095398, "action": -0.9319745898246765}
{"mode": "train", "epochs": 8, "timestep": 15139, "ep_reward": 647.7050170898438, "reward": 0.37369346618652344, "action": -1.0206563472747803}
{"mode": "train", "epochs": 8, "timestep": 15140, "ep_reward": 647.9735107421875, "reward": 0.26849228143692017, "action": -1.4877381324768066}
{"mode": "train", "epochs": 8, "timestep": 15141, "ep_reward": 648.116943359375, "reward": 0.14346027374267578, "action": -0.8295625448226929}
{"mode": "train", "epochs": 8, "timestep": 15142, "ep_reward": 648.1150512695312, "reward": -0.001865983009338379, "action": -1.9702134132385254}
{"mode": "train", "epochs": 8, "timestep": 15143, "ep_reward": 648.231689453125, "reward": 0.11661869287490845, "action": -1.5083330869674683}
{"mode": "train", "epochs": 8, "timestep": 15144, "ep_reward": 648.4807739257812, "reward": 0.24906820058822632, "action": -0.29297661781311035}
{"mode": "train", "epochs": 8, "timestep": 15145, "ep_reward": 648.8781127929688, "reward": 0.39733821153640747, "action": -1.212600827217102}
{"mode": "train", "epochs": 8, "timestep": 15146, "ep_reward": 649.4005126953125, "reward": 0.5224162340164185, "action": -1.569535255432129}
{"mode": "train", "epochs": 8, "timestep": 15147, "ep_reward": 650.0267333984375, "reward": 0.6262288093566895, "action": -0.7308364510536194}
{"mode": "train", "epochs": 8, "timestep": 15148, "ep_reward": 650.7442626953125, "reward": 0.7175232172012329, "action": -0.7593969702720642}
{"mode": "train", "epochs": 8, "timestep": 15149, "ep_reward": 651.5291748046875, "reward": 0.7849317789077759, "action": -1.6394844055175781}
{"mode": "train", "epochs": 8, "timestep": 15150, "ep_reward": 652.3527221679688, "reward": 0.8235230445861816, "action": -1.4805986881256104}
{"mode": "train", "epochs": 8, "timestep": 15151, "ep_reward": 653.1980590820312, "reward": 0.8453241586685181, "action": -0.905969500541687}
{"mode": "train", "epochs": 8, "timestep": 15152, "ep_reward": 654.0523681640625, "reward": 0.854320764541626, "action": -0.8361583352088928}
{"mode": "train", "epochs": 8, "timestep": 15153, "ep_reward": 654.8978881835938, "reward": 0.8455342650413513, "action": -1.786298394203186}
{"mode": "train", "epochs": 8, "timestep": 15154, "ep_reward": 655.7049560546875, "reward": 0.8070417642593384, "action": 0.11022931337356567}
{"mode": "train", "epochs": 8, "timestep": 15155, "ep_reward": 656.4673461914062, "reward": 0.7624014616012573, "action": -1.3036035299301147}
{"mode": "train", "epochs": 8, "timestep": 15156, "ep_reward": 657.1393432617188, "reward": 0.6719964742660522, "action": -0.709101676940918}
{"mode": "train", "epochs": 8, "timestep": 15157, "ep_reward": 657.6900024414062, "reward": 0.5506360530853271, "action": -1.1396352052688599}
{"mode": "train", "epochs": 8, "timestep": 15158, "ep_reward": 658.0787353515625, "reward": 0.38873445987701416, "action": -1.5228033065795898}
{"mode": "train", "epochs": 8, "timestep": 15159, "ep_reward": 658.3656616210938, "reward": 0.28693681955337524, "action": -0.881951630115509}
{"mode": "train", "epochs": 8, "timestep": 15160, "ep_reward": 658.5305786132812, "reward": 0.1649380922317505, "action": -1.5694900751113892}
{"mode": "train", "epochs": 8, "timestep": 15161, "ep_reward": 658.5535888671875, "reward": 0.022992849349975586, "action": -1.817461609840393}
{"mode": "train", "epochs": 8, "timestep": 15162, "ep_reward": 658.6475830078125, "reward": 0.09401482343673706, "action": -0.23292475938796997}
{"mode": "train", "epochs": 8, "timestep": 15163, "ep_reward": 658.8892211914062, "reward": 0.2416379451751709, "action": -0.6255465745925903}
{"mode": "train", "epochs": 8, "timestep": 15164, "ep_reward": 659.2726440429688, "reward": 0.38339751958847046, "action": -1.0792144536972046}
{"mode": "train", "epochs": 8, "timestep": 15165, "ep_reward": 659.7831420898438, "reward": 0.5104827880859375, "action": -0.6729058027267456}
{"mode": "train", "epochs": 8, "timestep": 15166, "ep_reward": 660.40869140625, "reward": 0.6255422830581665, "action": -0.6530141830444336}
{"mode": "train", "epochs": 8, "timestep": 15167, "ep_reward": 661.1275634765625, "reward": 0.7188509106636047, "action": -1.143172025680542}
{"mode": "train", "epochs": 8, "timestep": 15168, "ep_reward": 661.9132690429688, "reward": 0.7857170104980469, "action": -1.2037564516067505}
{"mode": "train", "epochs": 8, "timestep": 15169, "ep_reward": 662.7461547851562, "reward": 0.8328857421875, "action": -1.4775081872940063}
{"mode": "train", "epochs": 8, "timestep": 15170, "ep_reward": 663.6072387695312, "reward": 0.8610974550247192, "action": -1.2434970140457153}
{"mode": "train", "epochs": 8, "timestep": 15171, "ep_reward": 664.4833374023438, "reward": 0.8760917782783508, "action": -0.8328941464424133}
{"mode": "train", "epochs": 8, "timestep": 15172, "ep_reward": 665.36279296875, "reward": 0.8794732093811035, "action": -1.6445341110229492}
{"mode": "train", "epochs": 8, "timestep": 15173, "ep_reward": 666.2232666015625, "reward": 0.8604476451873779, "action": -1.708280086517334}
{"mode": "train", "epochs": 8, "timestep": 15174, "ep_reward": 667.0444946289062, "reward": 0.821198582649231, "action": 0.07785522937774658}
{"mode": "train", "epochs": 8, "timestep": 15175, "ep_reward": 667.820068359375, "reward": 0.775595486164093, "action": -1.2793183326721191}
{"mode": "train", "epochs": 8, "timestep": 15176, "ep_reward": 668.507080078125, "reward": 0.6870245933532715, "action": -0.6705012321472168}
{"mode": "train", "epochs": 8, "timestep": 15177, "ep_reward": 669.0763549804688, "reward": 0.5692487955093384, "action": -0.7664344310760498}
{"mode": "train", "epochs": 8, "timestep": 15178, "ep_reward": 669.4866333007812, "reward": 0.41029345989227295, "action": -1.7640843391418457}
{"mode": "train", "epochs": 8, "timestep": 15179, "ep_reward": 669.77587890625, "reward": 0.2892366051673889, "action": -0.7606505155563354}
{"mode": "train", "epochs": 8, "timestep": 15180, "ep_reward": 669.9436645507812, "reward": 0.16776132583618164, "action": -0.6646674871444702}
{"mode": "train", "epochs": 8, "timestep": 15181, "ep_reward": 669.9698486328125, "reward": 0.026214599609375, "action": -1.207033395767212}
{"mode": "train", "epochs": 8, "timestep": 15182, "ep_reward": 670.0607299804688, "reward": 0.09088975191116333, "action": -1.837247610092163}
{"mode": "train", "epochs": 8, "timestep": 15183, "ep_reward": 670.284423828125, "reward": 0.22371900081634521, "action": -0.9305701851844788}
{"mode": "train", "epochs": 8, "timestep": 15184, "ep_reward": 670.6494750976562, "reward": 0.3650369644165039, "action": -0.794569730758667}
{"mode": "train", "epochs": 8, "timestep": 15185, "ep_reward": 671.1484985351562, "reward": 0.49900949001312256, "action": -1.5477876663208008}
{"mode": "train", "epochs": 8, "timestep": 15186, "ep_reward": 671.7554321289062, "reward": 0.6069060564041138, "action": -1.0996081829071045}
{"mode": "train", "epochs": 8, "timestep": 15187, "ep_reward": 672.4541015625, "reward": 0.6986808180809021, "action": -1.1098712682724}
{"mode": "train", "epochs": 8, "timestep": 15188, "ep_reward": 673.221435546875, "reward": 0.7673172354698181, "action": -0.1983112096786499}
{"mode": "train", "epochs": 8, "timestep": 15189, "ep_reward": 674.0438232421875, "reward": 0.822370171546936, "action": -0.889424204826355}
{"mode": "train", "epochs": 8, "timestep": 15190, "ep_reward": 674.8949584960938, "reward": 0.8511372208595276, "action": -1.5371296405792236}
{"mode": "train", "epochs": 8, "timestep": 15191, "ep_reward": 675.7520751953125, "reward": 0.8570984601974487, "action": -0.5135369896888733}
{"mode": "train", "epochs": 8, "timestep": 15192, "ep_reward": 676.6065063476562, "reward": 0.8544202446937561, "action": -1.0919528007507324}
{"mode": "train", "epochs": 8, "timestep": 15193, "ep_reward": 677.4339599609375, "reward": 0.827475905418396, "action": -0.1181676983833313}
{"mode": "train", "epochs": 8, "timestep": 15194, "ep_reward": 678.221435546875, "reward": 0.7874520421028137, "action": -1.2500978708267212}
{"mode": "train", "epochs": 8, "timestep": 15195, "ep_reward": 678.9291381835938, "reward": 0.7076737880706787, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 15196, "ep_reward": 679.5098266601562, "reward": 0.5807110071182251, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 15197, "ep_reward": 679.919677734375, "reward": 0.40986567735671997, "action": -1.7328622341156006}
{"mode": "train", "epochs": 8, "timestep": 15198, "ep_reward": 680.2324829101562, "reward": 0.312835156917572, "action": -0.9308869242668152}
{"mode": "train", "epochs": 8, "timestep": 15199, "ep_reward": 680.4281616210938, "reward": 0.1956920623779297, "action": -0.7345404028892517}
{"mode": "train", "epochs": 8, "timestep": 15200, "ep_reward": 680.4866943359375, "reward": 0.05850327014923096, "action": -0.9773804545402527}
{"mode": "train", "epochs": 8, "timestep": 15201, "ep_reward": 680.5465087890625, "reward": 0.0597955584526062, "action": -0.5340059995651245}
{"mode": "train", "epochs": 8, "timestep": 15202, "ep_reward": 680.7489624023438, "reward": 0.20242667198181152, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 15203, "ep_reward": 681.0782470703125, "reward": 0.32928258180618286, "action": -0.528436541557312}
{"mode": "train", "epochs": 8, "timestep": 15204, "ep_reward": 681.5484008789062, "reward": 0.47017109394073486, "action": -1.3708560466766357}
{"mode": "train", "epochs": 8, "timestep": 15205, "ep_reward": 682.1329956054688, "reward": 0.5845819115638733, "action": -0.1721300482749939}
{"mode": "train", "epochs": 8, "timestep": 15206, "ep_reward": 682.82373046875, "reward": 0.690748929977417, "action": -1.3155471086502075}
{"mode": "train", "epochs": 8, "timestep": 15207, "ep_reward": 683.5848388671875, "reward": 0.761081874370575, "action": -0.5443053245544434}
{"mode": "train", "epochs": 8, "timestep": 15208, "ep_reward": 684.402099609375, "reward": 0.8172710537910461, "action": -1.076938509941101}
{"mode": "train", "epochs": 8, "timestep": 15209, "ep_reward": 685.2514038085938, "reward": 0.8493189811706543, "action": -0.1857951283454895}
{"mode": "train", "epochs": 8, "timestep": 15210, "ep_reward": 686.1231689453125, "reward": 0.8717787265777588, "action": -0.47261083126068115}
{"mode": "train", "epochs": 8, "timestep": 15211, "ep_reward": 686.9990234375, "reward": 0.8758822679519653, "action": -1.3387240171432495}
{"mode": "train", "epochs": 8, "timestep": 15212, "ep_reward": 687.8556518554688, "reward": 0.8566502332687378, "action": -0.7766276597976685}
{"mode": "train", "epochs": 8, "timestep": 15213, "ep_reward": 688.6786499023438, "reward": 0.8229829668998718, "action": -1.240574598312378}
{"mode": "train", "epochs": 8, "timestep": 15214, "ep_reward": 689.439208984375, "reward": 0.7605836987495422, "action": -1.2406249046325684}
{"mode": "train", "epochs": 8, "timestep": 15215, "ep_reward": 690.1055908203125, "reward": 0.6663608551025391, "action": -0.961260974407196}
{"mode": "train", "epochs": 8, "timestep": 15216, "ep_reward": 690.6427612304688, "reward": 0.53715980052948, "action": -0.5035908818244934}
{"mode": "train", "epochs": 8, "timestep": 15217, "ep_reward": 691.0166015625, "reward": 0.3738445043563843, "action": -1.2213373184204102}
{"mode": "train", "epochs": 8, "timestep": 15218, "ep_reward": 691.2850341796875, "reward": 0.2684352993965149, "action": -0.6400731801986694}
{"mode": "train", "epochs": 8, "timestep": 15219, "ep_reward": 691.4282836914062, "reward": 0.1432437300682068, "action": -0.9829219579696655}
{"mode": "train", "epochs": 8, "timestep": 15220, "ep_reward": 691.4262084960938, "reward": -0.0020742416381835938, "action": -1.8856568336486816}
{"mode": "train", "epochs": 8, "timestep": 15221, "ep_reward": 691.5431518554688, "reward": 0.11696112155914307, "action": 0.27159571647644043}
{"mode": "train", "epochs": 8, "timestep": 15222, "ep_reward": 691.8145141601562, "reward": 0.27139216661453247, "action": -0.6942936182022095}
{"mode": "train", "epochs": 8, "timestep": 15223, "ep_reward": 692.2246704101562, "reward": 0.4101572036743164, "action": -0.450322687625885}
{"mode": "train", "epochs": 8, "timestep": 15224, "ep_reward": 692.7654418945312, "reward": 0.5407423377037048, "action": -1.1545400619506836}
{"mode": "train", "epochs": 8, "timestep": 15225, "ep_reward": 693.410888671875, "reward": 0.6454644203186035, "action": -0.4264216423034668}
{"mode": "train", "epochs": 8, "timestep": 15226, "ep_reward": 694.147705078125, "reward": 0.7367912530899048, "action": -0.47076278924942017}
{"mode": "train", "epochs": 8, "timestep": 15227, "ep_reward": 694.953369140625, "reward": 0.805691123008728, "action": -1.092002511024475}
{"mode": "train", "epochs": 8, "timestep": 15228, "ep_reward": 695.803955078125, "reward": 0.8506088256835938, "action": -1.9694421291351318}
{"mode": "train", "epochs": 8, "timestep": 15229, "ep_reward": 696.67822265625, "reward": 0.8742543458938599, "action": -0.6797870397567749}
{"mode": "train", "epochs": 8, "timestep": 15230, "ep_reward": 697.5723876953125, "reward": 0.894166111946106, "action": -1.5483477115631104}
{"mode": "train", "epochs": 8, "timestep": 15231, "ep_reward": 698.4674072265625, "reward": 0.8949975371360779, "action": -1.6086900234222412}
{"mode": "train", "epochs": 8, "timestep": 15232, "ep_reward": 699.3494262695312, "reward": 0.8819922208786011, "action": -0.2723710536956787}
{"mode": "train", "epochs": 8, "timestep": 15233, "ep_reward": 700.213623046875, "reward": 0.8641966581344604, "action": -0.9851815104484558}
{"mode": "train", "epochs": 8, "timestep": 15234, "ep_reward": 701.0355834960938, "reward": 0.821945071220398, "action": -1.4153419733047485}
{"mode": "train", "epochs": 8, "timestep": 15235, "ep_reward": 701.7862548828125, "reward": 0.7506915330886841, "action": -0.885036826133728}
{"mode": "train", "epochs": 8, "timestep": 15236, "ep_reward": 702.4393920898438, "reward": 0.6531184315681458, "action": -0.8095614314079285}
{"mode": "train", "epochs": 8, "timestep": 15237, "ep_reward": 702.958740234375, "reward": 0.5193420648574829, "action": -0.757783830165863}
{"mode": "train", "epochs": 8, "timestep": 15238, "ep_reward": 703.3079223632812, "reward": 0.34919989109039307, "action": -1.143873929977417}
{"mode": "train", "epochs": 8, "timestep": 15239, "ep_reward": 703.546875, "reward": 0.23896294832229614, "action": -1.6826999187469482}
{"mode": "train", "epochs": 8, "timestep": 15240, "ep_reward": 703.6558837890625, "reward": 0.10898512601852417, "action": -0.4677248001098633}
{"mode": "train", "epochs": 8, "timestep": 15241, "ep_reward": 703.662841796875, "reward": 0.006963372230529785, "action": -0.37006235122680664}
{"mode": "train", "epochs": 8, "timestep": 15242, "ep_reward": 703.813720703125, "reward": 0.15090018510818481, "action": -1.175389289855957}
{"mode": "train", "epochs": 8, "timestep": 15243, "ep_reward": 704.10205078125, "reward": 0.2883179187774658, "action": -0.7081677913665771}
{"mode": "train", "epochs": 8, "timestep": 15244, "ep_reward": 704.531005859375, "reward": 0.42898106575012207, "action": -1.3544362783432007}
{"mode": "train", "epochs": 8, "timestep": 15245, "ep_reward": 705.0798950195312, "reward": 0.5489174127578735, "action": -0.9757625460624695}
{"mode": "train", "epochs": 8, "timestep": 15246, "ep_reward": 705.734130859375, "reward": 0.6542462706565857, "action": -0.5445941686630249}
{"mode": "train", "epochs": 8, "timestep": 15247, "ep_reward": 706.4750366210938, "reward": 0.7409172058105469, "action": -0.3835713267326355}
{"mode": "train", "epochs": 8, "timestep": 15248, "ep_reward": 707.2808227539062, "reward": 0.805794894695282, "action": -0.8232346177101135}
{"mode": "train", "epochs": 8, "timestep": 15249, "ep_reward": 708.1273193359375, "reward": 0.846498429775238, "action": -0.97269606590271}
{"mode": "train", "epochs": 8, "timestep": 15250, "ep_reward": 708.996337890625, "reward": 0.8690066337585449, "action": -0.8285505771636963}
{"mode": "train", "epochs": 8, "timestep": 15251, "ep_reward": 709.8734741210938, "reward": 0.8771570920944214, "action": -1.5316061973571777}
{"mode": "train", "epochs": 8, "timestep": 15252, "ep_reward": 710.7373657226562, "reward": 0.8638779520988464, "action": -1.5130430459976196}
{"mode": "train", "epochs": 8, "timestep": 15253, "ep_reward": 711.5695190429688, "reward": 0.8321524858474731, "action": -0.16855406761169434}
{"mode": "train", "epochs": 8, "timestep": 15254, "ep_reward": 712.3603515625, "reward": 0.7908408641815186, "action": -1.1025991439819336}
{"mode": "train", "epochs": 8, "timestep": 15255, "ep_reward": 713.0731201171875, "reward": 0.7127878665924072, "action": -0.7659305334091187}
{"mode": "train", "epochs": 8, "timestep": 15256, "ep_reward": 713.6769409179688, "reward": 0.6038445830345154, "action": -1.4807305335998535}
{"mode": "train", "epochs": 8, "timestep": 15257, "ep_reward": 714.1212158203125, "reward": 0.4442899823188782, "action": -1.5089139938354492}
{"mode": "train", "epochs": 8, "timestep": 15258, "ep_reward": 714.4387817382812, "reward": 0.3175487518310547, "action": -1.083367109298706}
{"mode": "train", "epochs": 8, "timestep": 15259, "ep_reward": 714.6400146484375, "reward": 0.20123404264450073, "action": -1.3356153964996338}
{"mode": "train", "epochs": 8, "timestep": 15260, "ep_reward": 714.7050170898438, "reward": 0.06498432159423828, "action": -1.168461561203003}
{"mode": "train", "epochs": 8, "timestep": 15261, "ep_reward": 714.7582397460938, "reward": 0.053206443786621094, "action": -1.0471011400222778}
{"mode": "train", "epochs": 8, "timestep": 15262, "ep_reward": 714.9492797851562, "reward": 0.19102954864501953, "action": -1.4150950908660889}
{"mode": "train", "epochs": 8, "timestep": 15263, "ep_reward": 715.2753295898438, "reward": 0.32606232166290283, "action": -1.3933625221252441}
{"mode": "train", "epochs": 8, "timestep": 15264, "ep_reward": 715.7321166992188, "reward": 0.45678287744522095, "action": 0.1719287633895874}
{"mode": "train", "epochs": 8, "timestep": 15265, "ep_reward": 716.3225708007812, "reward": 0.5904703140258789, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 15266, "ep_reward": 716.9996948242188, "reward": 0.677101731300354, "action": -1.0158073902130127}
{"mode": "train", "epochs": 8, "timestep": 15267, "ep_reward": 717.752197265625, "reward": 0.7525243759155273, "action": -1.0546377897262573}
{"mode": "train", "epochs": 8, "timestep": 15268, "ep_reward": 718.5574340820312, "reward": 0.8052150011062622, "action": -1.3537895679473877}
{"mode": "train", "epochs": 8, "timestep": 15269, "ep_reward": 719.3926391601562, "reward": 0.8352097272872925, "action": -0.5386964082717896}
{"mode": "train", "epochs": 8, "timestep": 15270, "ep_reward": 720.2465209960938, "reward": 0.8538963198661804, "action": -0.7300785779953003}
{"mode": "train", "epochs": 8, "timestep": 15271, "ep_reward": 721.0993041992188, "reward": 0.8528122305870056, "action": -0.9979826807975769}
{"mode": "train", "epochs": 8, "timestep": 15272, "ep_reward": 721.929443359375, "reward": 0.8301336765289307, "action": -1.22892165184021}
{"mode": "train", "epochs": 8, "timestep": 15273, "ep_reward": 722.7114868164062, "reward": 0.7820603847503662, "action": -1.2134668827056885}
{"mode": "train", "epochs": 8, "timestep": 15274, "ep_reward": 723.416015625, "reward": 0.7045085430145264, "action": -1.2305468320846558}
{"mode": "train", "epochs": 8, "timestep": 15275, "ep_reward": 724.005615234375, "reward": 0.5895819664001465, "action": -1.330414056777954}
{"mode": "train", "epochs": 8, "timestep": 15276, "ep_reward": 724.4352416992188, "reward": 0.42961204051971436, "action": -1.1259639263153076}
{"mode": "train", "epochs": 8, "timestep": 15277, "ep_reward": 724.7590942382812, "reward": 0.32386910915374756, "action": -0.8534840941429138}
{"mode": "train", "epochs": 8, "timestep": 15278, "ep_reward": 724.9678955078125, "reward": 0.20877104997634888, "action": -0.9623848795890808}
{"mode": "train", "epochs": 8, "timestep": 15279, "ep_reward": 725.0414428710938, "reward": 0.07354259490966797, "action": -1.7942445278167725}
{"mode": "train", "epochs": 8, "timestep": 15280, "ep_reward": 725.0858154296875, "reward": 0.044351160526275635, "action": -1.1540740728378296}
{"mode": "train", "epochs": 8, "timestep": 15281, "ep_reward": 725.269287109375, "reward": 0.1834719181060791, "action": -0.7273764610290527}
{"mode": "train", "epochs": 8, "timestep": 15282, "ep_reward": 725.59619140625, "reward": 0.3269226551055908, "action": -1.331668734550476}
{"mode": "train", "epochs": 8, "timestep": 15283, "ep_reward": 726.0534057617188, "reward": 0.45718836784362793, "action": -0.9450450539588928}
{"mode": "train", "epochs": 8, "timestep": 15284, "ep_reward": 726.6314086914062, "reward": 0.5780237913131714, "action": -1.5285804271697998}
{"mode": "train", "epochs": 8, "timestep": 15285, "ep_reward": 727.3032836914062, "reward": 0.6718646287918091, "action": -1.2693191766738892}
{"mode": "train", "epochs": 8, "timestep": 15286, "ep_reward": 728.0497436523438, "reward": 0.7464523315429688, "action": -1.4510667324066162}
{"mode": "train", "epochs": 8, "timestep": 15287, "ep_reward": 728.8473510742188, "reward": 0.7975900173187256, "action": -0.05012381076812744}
{"mode": "train", "epochs": 8, "timestep": 15288, "ep_reward": 729.6883544921875, "reward": 0.8410072326660156, "action": -1.175812005996704}
{"mode": "train", "epochs": 8, "timestep": 15289, "ep_reward": 730.5439453125, "reward": 0.855610728263855, "action": -1.143550157546997}
{"mode": "train", "epochs": 8, "timestep": 15290, "ep_reward": 731.3967895507812, "reward": 0.8528258204460144, "action": -1.678511619567871}
{"mode": "train", "epochs": 8, "timestep": 15291, "ep_reward": 732.222412109375, "reward": 0.8256500959396362, "action": -1.6921542882919312}
{"mode": "train", "epochs": 8, "timestep": 15292, "ep_reward": 732.9961547851562, "reward": 0.7737551927566528, "action": -0.7438634634017944}
{"mode": "train", "epochs": 8, "timestep": 15293, "ep_reward": 733.6978759765625, "reward": 0.7017178535461426, "action": -0.5311560034751892}
{"mode": "train", "epochs": 8, "timestep": 15294, "ep_reward": 734.294677734375, "reward": 0.5967953205108643, "action": -1.4644145965576172}
{"mode": "train", "epochs": 8, "timestep": 15295, "ep_reward": 734.7317504882812, "reward": 0.43705445528030396, "action": -0.5379531383514404}
{"mode": "train", "epochs": 8, "timestep": 15296, "ep_reward": 735.0602416992188, "reward": 0.32849109172821045, "action": -1.6040165424346924}
{"mode": "train", "epochs": 8, "timestep": 15297, "ep_reward": 735.274658203125, "reward": 0.21442824602127075, "action": -0.8336884379386902}
{"mode": "train", "epochs": 8, "timestep": 15298, "ep_reward": 735.35498046875, "reward": 0.08029192686080933, "action": -0.028595447540283203}
{"mode": "train", "epochs": 8, "timestep": 15299, "ep_reward": 735.3923950195312, "reward": 0.03742128610610962, "action": -1.973655343055725}
{"mode": "train", "epochs": 8, "timestep": 15300, "ep_reward": 735.5700073242188, "reward": 0.17764025926589966, "action": -0.09516990184783936}
{"mode": "train", "epochs": 8, "timestep": 15301, "ep_reward": 735.8987426757812, "reward": 0.32873523235321045, "action": -1.4887570142745972}
{"mode": "train", "epochs": 8, "timestep": 15302, "ep_reward": 736.3546142578125, "reward": 0.45587319135665894, "action": -1.7601840496063232}
{"mode": "train", "epochs": 8, "timestep": 15303, "ep_reward": 736.9221801757812, "reward": 0.5675751566886902, "action": -1.3783131837844849}
{"mode": "train", "epochs": 8, "timestep": 15304, "ep_reward": 737.587158203125, "reward": 0.664950966835022, "action": -1.2663347721099854}
{"mode": "train", "epochs": 8, "timestep": 15305, "ep_reward": 738.3284912109375, "reward": 0.741323709487915, "action": 0.24006140232086182}
{"mode": "train", "epochs": 8, "timestep": 15306, "ep_reward": 739.1375732421875, "reward": 0.8090709447860718, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 15307, "ep_reward": 739.9735107421875, "reward": 0.8359388113021851, "action": -0.8556258678436279}
{"mode": "train", "epochs": 8, "timestep": 15308, "ep_reward": 740.8284912109375, "reward": 0.8549656867980957, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 15309, "ep_reward": 741.6747436523438, "reward": 0.8462560176849365, "action": -1.3074591159820557}
{"mode": "train", "epochs": 8, "timestep": 15310, "ep_reward": 742.4983520507812, "reward": 0.8236281871795654, "action": -1.259589672088623}
{"mode": "train", "epochs": 8, "timestep": 15311, "ep_reward": 743.2756958007812, "reward": 0.7773572206497192, "action": -1.3446871042251587}
{"mode": "train", "epochs": 8, "timestep": 15312, "ep_reward": 743.9754638671875, "reward": 0.6997765302658081, "action": -0.8872731924057007}
{"mode": "train", "epochs": 8, "timestep": 15313, "ep_reward": 744.565673828125, "reward": 0.5901821255683899, "action": -1.9428484439849854}
{"mode": "train", "epochs": 8, "timestep": 15314, "ep_reward": 744.9889526367188, "reward": 0.4232602119445801, "action": -1.7198339700698853}
{"mode": "train", "epochs": 8, "timestep": 15315, "ep_reward": 745.318359375, "reward": 0.32940250635147095, "action": -0.3419153690338135}
{"mode": "train", "epochs": 8, "timestep": 15316, "ep_reward": 745.53369140625, "reward": 0.21534115076065063, "action": -0.7379187941551208}
{"mode": "train", "epochs": 8, "timestep": 15317, "ep_reward": 745.614990234375, "reward": 0.0813027024269104, "action": -0.7844418287277222}
{"mode": "train", "epochs": 8, "timestep": 15318, "ep_reward": 745.6515502929688, "reward": 0.036542654037475586, "action": -0.6892588138580322}
{"mode": "train", "epochs": 8, "timestep": 15319, "ep_reward": 745.8282470703125, "reward": 0.17671304941177368, "action": -0.7375028729438782}
{"mode": "train", "epochs": 8, "timestep": 15320, "ep_reward": 746.1481323242188, "reward": 0.3199101686477661, "action": -1.4706242084503174}
{"mode": "train", "epochs": 8, "timestep": 15321, "ep_reward": 746.5971069335938, "reward": 0.448974072933197, "action": -0.9107900261878967}
{"mode": "train", "epochs": 8, "timestep": 15322, "ep_reward": 747.1685180664062, "reward": 0.5714136958122253, "action": -1.5704455375671387}
{"mode": "train", "epochs": 8, "timestep": 15323, "ep_reward": 747.8346557617188, "reward": 0.6661532521247864, "action": -0.8119163513183594}
{"mode": "train", "epochs": 8, "timestep": 15324, "ep_reward": 748.5812377929688, "reward": 0.7465757131576538, "action": -0.8885751366615295}
{"mode": "train", "epochs": 8, "timestep": 15325, "ep_reward": 749.3847045898438, "reward": 0.8034930229187012, "action": -0.8238767385482788}
{"mode": "train", "epochs": 8, "timestep": 15326, "ep_reward": 750.2252807617188, "reward": 0.8405634760856628, "action": -1.7279491424560547}
{"mode": "train", "epochs": 8, "timestep": 15327, "ep_reward": 751.0771484375, "reward": 0.8518856167793274, "action": -0.8327014446258545}
{"mode": "train", "epochs": 8, "timestep": 15328, "ep_reward": 751.9304809570312, "reward": 0.8533076643943787, "action": -1.300418496131897}
{"mode": "train", "epochs": 8, "timestep": 15329, "ep_reward": 752.761962890625, "reward": 0.831501841545105, "action": -0.5246673822402954}
{"mode": "train", "epochs": 8, "timestep": 15330, "ep_reward": 753.5568237304688, "reward": 0.7948444485664368, "action": -0.598840594291687}
{"mode": "train", "epochs": 8, "timestep": 15331, "ep_reward": 754.2877197265625, "reward": 0.7309187650680542, "action": -1.1081949472427368}
{"mode": "train", "epochs": 8, "timestep": 15332, "ep_reward": 754.915283203125, "reward": 0.6275525093078613, "action": -1.3080592155456543}
{"mode": "train", "epochs": 8, "timestep": 15333, "ep_reward": 755.3955078125, "reward": 0.4802089333534241, "action": -0.6692415475845337}
{"mode": "train", "epochs": 8, "timestep": 15334, "ep_reward": 755.7437133789062, "reward": 0.34821808338165283, "action": -1.6845632791519165}
{"mode": "train", "epochs": 8, "timestep": 15335, "ep_reward": 755.981689453125, "reward": 0.2379867434501648, "action": -1.2007744312286377}
{"mode": "train", "epochs": 8, "timestep": 15336, "ep_reward": 756.08935546875, "reward": 0.10767948627471924, "action": -1.1272428035736084}
{"mode": "train", "epochs": 8, "timestep": 15337, "ep_reward": 756.0975341796875, "reward": 0.008181273937225342, "action": -1.5579124689102173}
{"mode": "train", "epochs": 8, "timestep": 15338, "ep_reward": 756.24951171875, "reward": 0.1519637107849121, "action": -1.820033311843872}
{"mode": "train", "epochs": 8, "timestep": 15339, "ep_reward": 756.5308837890625, "reward": 0.2813418507575989, "action": -1.0244189500808716}
{"mode": "train", "epochs": 8, "timestep": 15340, "ep_reward": 756.9507446289062, "reward": 0.4198375940322876, "action": -0.9255073070526123}
{"mode": "train", "epochs": 8, "timestep": 15341, "ep_reward": 757.4973754882812, "reward": 0.5466110706329346, "action": 0.034644126892089844}
{"mode": "train", "epochs": 8, "timestep": 15342, "ep_reward": 758.16015625, "reward": 0.6627760529518127, "action": -1.5843555927276611}
{"mode": "train", "epochs": 8, "timestep": 15343, "ep_reward": 758.8977661132812, "reward": 0.7375874519348145, "action": -1.0301188230514526}
{"mode": "train", "epochs": 8, "timestep": 15344, "ep_reward": 759.6941528320312, "reward": 0.7964070439338684, "action": -1.2363163232803345}
{"mode": "train", "epochs": 8, "timestep": 15345, "ep_reward": 760.5272827148438, "reward": 0.8331319689750671, "action": -1.213299036026001}
{"mode": "train", "epochs": 8, "timestep": 15346, "ep_reward": 761.379150390625, "reward": 0.8518406748771667, "action": -0.9597684741020203}
{"mode": "train", "epochs": 8, "timestep": 15347, "ep_reward": 762.2342529296875, "reward": 0.8550993204116821, "action": -1.0537418127059937}
{"mode": "train", "epochs": 8, "timestep": 15348, "ep_reward": 763.0731811523438, "reward": 0.8389102816581726, "action": -1.4167349338531494}
{"mode": "train", "epochs": 8, "timestep": 15349, "ep_reward": 763.8705444335938, "reward": 0.7973378300666809, "action": -1.2072340250015259}
{"mode": "train", "epochs": 8, "timestep": 15350, "ep_reward": 764.6005859375, "reward": 0.7300165295600891, "action": -0.7320520877838135}
{"mode": "train", "epochs": 8, "timestep": 15351, "ep_reward": 765.2344970703125, "reward": 0.6338982582092285, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 15352, "ep_reward": 765.7134399414062, "reward": 0.4789355993270874, "action": -0.9814865589141846}
{"mode": "train", "epochs": 8, "timestep": 15353, "ep_reward": 766.0708618164062, "reward": 0.35739463567733765, "action": -1.3402374982833862}
{"mode": "train", "epochs": 8, "timestep": 15354, "ep_reward": 766.3197631835938, "reward": 0.24892765283584595, "action": -1.2257121801376343}
{"mode": "train", "epochs": 8, "timestep": 15355, "ep_reward": 766.4402465820312, "reward": 0.12049651145935059, "action": -0.8027992248535156}
{"mode": "train", "epochs": 8, "timestep": 15356, "ep_reward": 766.4343872070312, "reward": -0.005873203277587891, "action": -0.5793930292129517}
{"mode": "train", "epochs": 8, "timestep": 15357, "ep_reward": 766.5740356445312, "reward": 0.1396591067314148, "action": -1.5984833240509033}
{"mode": "train", "epochs": 8, "timestep": 15358, "ep_reward": 766.8455200195312, "reward": 0.2714589834213257, "action": -1.4285190105438232}
{"mode": "train", "epochs": 8, "timestep": 15359, "ep_reward": 767.2506103515625, "reward": 0.405092716217041, "action": -1.0302188396453857}
{"mode": "train", "epochs": 8, "timestep": 15360, "ep_reward": 767.783203125, "reward": 0.5326037406921387, "action": -0.8192424774169922}
{"mode": "train", "epochs": 8, "timestep": 15361, "ep_reward": 768.4257202148438, "reward": 0.642547070980072, "action": -0.6369447708129883}
{"mode": "train", "epochs": 8, "timestep": 15362, "ep_reward": 769.1561279296875, "reward": 0.7304167151451111, "action": -0.7050309181213379}
{"mode": "train", "epochs": 8, "timestep": 15363, "ep_reward": 769.9500122070312, "reward": 0.7938739657402039, "action": -0.8473535180091858}
{"mode": "train", "epochs": 8, "timestep": 15364, "ep_reward": 770.7849731445312, "reward": 0.8349693417549133, "action": -1.1819179058074951}
{"mode": "train", "epochs": 8, "timestep": 15365, "ep_reward": 771.6397094726562, "reward": 0.8547510504722595, "action": -1.5321964025497437}
{"mode": "train", "epochs": 8, "timestep": 15366, "ep_reward": 772.4940185546875, "reward": 0.8543192148208618, "action": -0.4763014316558838}
{"mode": "train", "epochs": 8, "timestep": 15367, "ep_reward": 773.3389892578125, "reward": 0.844999372959137, "action": -0.2736150026321411}
{"mode": "train", "epochs": 8, "timestep": 15368, "ep_reward": 774.1566162109375, "reward": 0.8176119327545166, "action": -1.1534779071807861}
{"mode": "train", "epochs": 8, "timestep": 15369, "ep_reward": 774.9136962890625, "reward": 0.7570509910583496, "action": -1.9428822994232178}
{"mode": "train", "epochs": 8, "timestep": 15370, "ep_reward": 775.5680541992188, "reward": 0.6543571352958679, "action": -1.3050273656845093}
{"mode": "train", "epochs": 8, "timestep": 15371, "ep_reward": 776.0857543945312, "reward": 0.5176721811294556, "action": -0.7589036822319031}
{"mode": "train", "epochs": 8, "timestep": 15372, "ep_reward": 776.4602661132812, "reward": 0.37451082468032837, "action": -1.1459094285964966}
{"mode": "train", "epochs": 8, "timestep": 15373, "ep_reward": 776.7298583984375, "reward": 0.2696187496185303, "action": -0.5900529026985168}
{"mode": "train", "epochs": 8, "timestep": 15374, "ep_reward": 776.87451171875, "reward": 0.1446777582168579, "action": -0.4185100793838501}
{"mode": "train", "epochs": 8, "timestep": 15375, "ep_reward": 776.874267578125, "reward": -0.00026237964630126953, "action": -0.011300444602966309}
{"mode": "train", "epochs": 8, "timestep": 15376, "ep_reward": 776.9896240234375, "reward": 0.11538398265838623, "action": -1.5783439874649048}
{"mode": "train", "epochs": 8, "timestep": 15377, "ep_reward": 777.2365112304688, "reward": 0.24687039852142334, "action": -0.9495929479598999}
{"mode": "train", "epochs": 8, "timestep": 15378, "ep_reward": 777.6239013671875, "reward": 0.38738441467285156, "action": -1.1430816650390625}
{"mode": "train", "epochs": 8, "timestep": 15379, "ep_reward": 778.1389770507812, "reward": 0.5150489211082458, "action": -1.7679468393325806}
{"mode": "train", "epochs": 8, "timestep": 15380, "ep_reward": 778.7567749023438, "reward": 0.6178258657455444, "action": -1.3227362632751465}
{"mode": "train", "epochs": 8, "timestep": 15381, "ep_reward": 779.4609985351562, "reward": 0.7042394876480103, "action": -0.15458661317825317}
{"mode": "train", "epochs": 8, "timestep": 15382, "ep_reward": 780.2396240234375, "reward": 0.7786157131195068, "action": -0.6194243431091309}
{"mode": "train", "epochs": 8, "timestep": 15383, "ep_reward": 781.06494140625, "reward": 0.825346052646637, "action": -0.06941014528274536}
{"mode": "train", "epochs": 8, "timestep": 15384, "ep_reward": 781.9220581054688, "reward": 0.8570964932441711, "action": -1.316570520401001}
{"mode": "train", "epochs": 8, "timestep": 15385, "ep_reward": 782.78271484375, "reward": 0.8606608510017395, "action": -0.8112189769744873}
{"mode": "train", "epochs": 8, "timestep": 15386, "ep_reward": 783.6338500976562, "reward": 0.8511291742324829, "action": -0.7220378518104553}
{"mode": "train", "epochs": 8, "timestep": 15387, "ep_reward": 784.4567260742188, "reward": 0.8228955864906311, "action": -0.8921196460723877}
{"mode": "train", "epochs": 8, "timestep": 15388, "ep_reward": 785.2260131835938, "reward": 0.7693023681640625, "action": -1.2095410823822021}
{"mode": "train", "epochs": 8, "timestep": 15389, "ep_reward": 785.90771484375, "reward": 0.6816878914833069, "action": -1.65446138381958}
{"mode": "train", "epochs": 8, "timestep": 15390, "ep_reward": 786.4570922851562, "reward": 0.5493533611297607, "action": -0.700610876083374}
{"mode": "train", "epochs": 8, "timestep": 15391, "ep_reward": 786.8474731445312, "reward": 0.3904009461402893, "action": -1.4819214344024658}
{"mode": "train", "epochs": 8, "timestep": 15392, "ep_reward": 787.1363525390625, "reward": 0.2888702154159546, "action": -1.4739160537719727}
{"mode": "train", "epochs": 8, "timestep": 15393, "ep_reward": 787.3037109375, "reward": 0.16738712787628174, "action": -1.1808768510818481}
{"mode": "train", "epochs": 8, "timestep": 15394, "ep_reward": 787.3296508789062, "reward": 0.025911033153533936, "action": -0.718570351600647}
{"mode": "train", "epochs": 8, "timestep": 15395, "ep_reward": 787.4208984375, "reward": 0.09121954441070557, "action": -1.8864902257919312}
{"mode": "train", "epochs": 8, "timestep": 15396, "ep_reward": 787.6447143554688, "reward": 0.2238166332244873, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 15397, "ep_reward": 787.9963989257812, "reward": 0.35167133808135986, "action": -1.9444340467453003}
{"mode": "train", "epochs": 8, "timestep": 15398, "ep_reward": 788.4708862304688, "reward": 0.47449904680252075, "action": -1.034401535987854}
{"mode": "train", "epochs": 8, "timestep": 15399, "ep_reward": 789.063232421875, "reward": 0.5923658013343811, "action": -0.809394121170044}
{"mode": "train", "epochs": 8, "timestep": 15400, "ep_reward": 789.7518920898438, "reward": 0.6886898279190063, "action": -1.716454029083252}
{"mode": "train", "epochs": 8, "timestep": 15401, "ep_reward": 790.50244140625, "reward": 0.7505316734313965, "action": -1.4264583587646484}
{"mode": "train", "epochs": 8, "timestep": 15402, "ep_reward": 791.2946166992188, "reward": 0.7921676635742188, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 15403, "ep_reward": 792.1002807617188, "reward": 0.8056870102882385, "action": -1.836464524269104}
{"mode": "train", "epochs": 8, "timestep": 15404, "ep_reward": 792.8978271484375, "reward": 0.7975488901138306, "action": -1.2746152877807617}
{"mode": "train", "epochs": 8, "timestep": 15405, "ep_reward": 793.6668090820312, "reward": 0.76900714635849, "action": -0.4915335178375244}
{"mode": "train", "epochs": 8, "timestep": 15406, "ep_reward": 794.385986328125, "reward": 0.7191504240036011, "action": -0.764992356300354}
{"mode": "train", "epochs": 8, "timestep": 15407, "ep_reward": 795.0167846679688, "reward": 0.6307868957519531, "action": -0.23594969511032104}
{"mode": "train", "epochs": 8, "timestep": 15408, "ep_reward": 795.5255737304688, "reward": 0.5087623000144958, "action": -0.7935560345649719}
{"mode": "train", "epochs": 8, "timestep": 15409, "ep_reward": 795.9140014648438, "reward": 0.38844144344329834, "action": -0.7436363697052002}
{"mode": "train", "epochs": 8, "timestep": 15410, "ep_reward": 796.2003784179688, "reward": 0.28637754917144775, "action": -1.3663886785507202}
{"mode": "train", "epochs": 8, "timestep": 15411, "ep_reward": 796.3648071289062, "reward": 0.1644536256790161, "action": -0.975731372833252}
{"mode": "train", "epochs": 8, "timestep": 15412, "ep_reward": 796.3872680664062, "reward": 0.022470951080322266, "action": -0.9928090572357178}
{"mode": "train", "epochs": 8, "timestep": 15413, "ep_reward": 796.4818725585938, "reward": 0.0946265459060669, "action": -0.5038997530937195}
{"mode": "train", "epochs": 8, "timestep": 15414, "ep_reward": 796.7207641601562, "reward": 0.23887556791305542, "action": -1.028343915939331}
{"mode": "train", "epochs": 8, "timestep": 15415, "ep_reward": 797.09716796875, "reward": 0.3763960003852844, "action": -1.6587682962417603}
{"mode": "train", "epochs": 8, "timestep": 15416, "ep_reward": 797.595458984375, "reward": 0.4982823133468628, "action": -1.1853461265563965}
{"mode": "train", "epochs": 8, "timestep": 15417, "ep_reward": 798.2056274414062, "reward": 0.61018967628479, "action": -1.4449191093444824}
{"mode": "train", "epochs": 8, "timestep": 15418, "ep_reward": 798.9037475585938, "reward": 0.6981071829795837, "action": -0.008403360843658447}
{"mode": "train", "epochs": 8, "timestep": 15419, "ep_reward": 799.68115234375, "reward": 0.7773927450180054, "action": -0.9511759877204895}
{"mode": "train", "epochs": 8, "timestep": 15420, "ep_reward": 800.50634765625, "reward": 0.8251768350601196, "action": -1.0904873609542847}
{"mode": "train", "epochs": 8, "timestep": 15421, "ep_reward": 801.359619140625, "reward": 0.8532747030258179, "action": 0.2260274887084961}
{"mode": "train", "epochs": 8, "timestep": 15422, "ep_reward": 802.2349853515625, "reward": 0.8753957748413086, "action": -1.5582361221313477}
{"mode": "train", "epochs": 8, "timestep": 15423, "ep_reward": 803.1019287109375, "reward": 0.8669723272323608, "action": -0.5011833906173706}
{"mode": "train", "epochs": 8, "timestep": 15424, "ep_reward": 803.9520874023438, "reward": 0.8501607775688171, "action": -1.8684782981872559}
{"mode": "train", "epochs": 8, "timestep": 15425, "ep_reward": 804.7521362304688, "reward": 0.8000308871269226, "action": -1.1516509056091309}
{"mode": "train", "epochs": 8, "timestep": 15426, "ep_reward": 805.4810791015625, "reward": 0.7289683818817139, "action": -0.6472584009170532}
{"mode": "train", "epochs": 8, "timestep": 15427, "ep_reward": 806.1112060546875, "reward": 0.6301482319831848, "action": -0.6575250625610352}
{"mode": "train", "epochs": 8, "timestep": 15428, "ep_reward": 806.6038208007812, "reward": 0.4926079511642456, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 15429, "ep_reward": 806.9492797851562, "reward": 0.34547150135040283, "action": -1.165311336517334}
{"mode": "train", "epochs": 8, "timestep": 15430, "ep_reward": 807.1838989257812, "reward": 0.2346208691596985, "action": -0.9164694547653198}
{"mode": "train", "epochs": 8, "timestep": 15431, "ep_reward": 807.2876586914062, "reward": 0.1037440299987793, "action": -0.867335319519043}
{"mode": "train", "epochs": 8, "timestep": 15432, "ep_reward": 807.30029296875, "reward": 0.01266169548034668, "action": -0.27586615085601807}
{"mode": "train", "epochs": 8, "timestep": 15433, "ep_reward": 807.45751953125, "reward": 0.15723729133605957, "action": -0.4226134419441223}
{"mode": "train", "epochs": 8, "timestep": 15434, "ep_reward": 807.76123046875, "reward": 0.30373865365982056, "action": -1.007690191268921}
{"mode": "train", "epochs": 8, "timestep": 15435, "ep_reward": 808.19970703125, "reward": 0.4384956955909729, "action": -0.5031852126121521}
{"mode": "train", "epochs": 8, "timestep": 15436, "ep_reward": 808.7659301757812, "reward": 0.5662159323692322, "action": -0.7199845910072327}
{"mode": "train", "epochs": 8, "timestep": 15437, "ep_reward": 809.4368896484375, "reward": 0.6709612607955933, "action": -0.5354954600334167}
{"mode": "train", "epochs": 8, "timestep": 15438, "ep_reward": 810.1917114257812, "reward": 0.754828691482544, "action": -1.9135535955429077}
{"mode": "train", "epochs": 8, "timestep": 15439, "ep_reward": 810.997314453125, "reward": 0.8056291341781616, "action": -1.1738041639328003}
{"mode": "train", "epochs": 8, "timestep": 15440, "ep_reward": 811.8426513671875, "reward": 0.8453162908554077, "action": -1.1087045669555664}
{"mode": "train", "epochs": 8, "timestep": 15441, "ep_reward": 812.7117309570312, "reward": 0.8690676689147949, "action": -1.3590081930160522}
{"mode": "train", "epochs": 8, "timestep": 15442, "ep_reward": 813.5874633789062, "reward": 0.8757326602935791, "action": -0.832646906375885}
{"mode": "train", "epochs": 8, "timestep": 15443, "ep_reward": 814.4588012695312, "reward": 0.8713440895080566, "action": -0.907978892326355}
{"mode": "train", "epochs": 8, "timestep": 15444, "ep_reward": 815.3082275390625, "reward": 0.849396288394928, "action": -1.4257423877716064}
{"mode": "train", "epochs": 8, "timestep": 15445, "ep_reward": 816.1101684570312, "reward": 0.8019148707389832, "action": -0.05235868692398071}
{"mode": "train", "epochs": 8, "timestep": 15446, "ep_reward": 816.8525390625, "reward": 0.7423504590988159, "action": -1.7264087200164795}
{"mode": "train", "epochs": 8, "timestep": 15447, "ep_reward": 817.4840698242188, "reward": 0.6315242648124695, "action": -1.889501929283142}
{"mode": "train", "epochs": 8, "timestep": 15448, "ep_reward": 817.9594116210938, "reward": 0.4753488302230835, "action": -0.4117947220802307}
{"mode": "train", "epochs": 8, "timestep": 15449, "ep_reward": 818.300537109375, "reward": 0.3411102890968323, "action": -0.6657539010047913}
{"mode": "train", "epochs": 8, "timestep": 15450, "ep_reward": 818.5299072265625, "reward": 0.22938281297683716, "action": -0.03166639804840088}
{"mode": "train", "epochs": 8, "timestep": 15451, "ep_reward": 818.6273803710938, "reward": 0.09746909141540527, "action": -1.596207618713379}
{"mode": "train", "epochs": 8, "timestep": 15452, "ep_reward": 818.646728515625, "reward": 0.019329071044921875, "action": -0.19607514142990112}
{"mode": "train", "epochs": 8, "timestep": 15453, "ep_reward": 818.8117065429688, "reward": 0.16500639915466309, "action": -1.3487930297851562}
{"mode": "train", "epochs": 8, "timestep": 15454, "ep_reward": 819.1115112304688, "reward": 0.29979968070983887, "action": -0.9698094725608826}
{"mode": "train", "epochs": 8, "timestep": 15455, "ep_reward": 819.548095703125, "reward": 0.43656229972839355, "action": -1.1319122314453125}
{"mode": "train", "epochs": 8, "timestep": 15456, "ep_reward": 820.106201171875, "reward": 0.5580912828445435, "action": -1.4883019924163818}
{"mode": "train", "epochs": 8, "timestep": 15457, "ep_reward": 820.7625122070312, "reward": 0.6562914252281189, "action": -0.6190528869628906}
{"mode": "train", "epochs": 8, "timestep": 15458, "ep_reward": 821.503662109375, "reward": 0.7411456108093262, "action": -1.3392208814620972}
{"mode": "train", "epochs": 8, "timestep": 15459, "ep_reward": 822.2998046875, "reward": 0.7961288690567017, "action": -1.6063992977142334}
{"mode": "train", "epochs": 8, "timestep": 15460, "ep_reward": 823.1287841796875, "reward": 0.8290050625801086, "action": -0.6449536681175232}
{"mode": "train", "epochs": 8, "timestep": 15461, "ep_reward": 823.980712890625, "reward": 0.8518985509872437, "action": -0.5947700142860413}
{"mode": "train", "epochs": 8, "timestep": 15462, "ep_reward": 824.837890625, "reward": 0.8571889996528625, "action": -1.3140157461166382}
{"mode": "train", "epochs": 8, "timestep": 15463, "ep_reward": 825.6754760742188, "reward": 0.8376010656356812, "action": -1.1604697704315186}
{"mode": "train", "epochs": 8, "timestep": 15464, "ep_reward": 826.4727172851562, "reward": 0.7972660064697266, "action": -1.676407814025879}
{"mode": "train", "epochs": 8, "timestep": 15465, "ep_reward": 827.1958618164062, "reward": 0.7231718301773071, "action": -1.558992862701416}
{"mode": "train", "epochs": 8, "timestep": 15466, "ep_reward": 827.8092041015625, "reward": 0.6133254766464233, "action": -1.141239881515503}
{"mode": "train", "epochs": 8, "timestep": 15467, "ep_reward": 828.2747192382812, "reward": 0.465492308139801, "action": -1.2088212966918945}
{"mode": "train", "epochs": 8, "timestep": 15468, "ep_reward": 828.62451171875, "reward": 0.34977948665618896, "action": -0.8468743562698364}
{"mode": "train", "epochs": 8, "timestep": 15469, "ep_reward": 828.8642578125, "reward": 0.23974639177322388, "action": -0.8449566960334778}
{"mode": "train", "epochs": 8, "timestep": 15470, "ep_reward": 828.9739379882812, "reward": 0.1096612811088562, "action": -1.245934009552002}
{"mode": "train", "epochs": 8, "timestep": 15471, "ep_reward": 828.9799194335938, "reward": 0.005975663661956787, "action": -1.6049941778182983}
{"mode": "train", "epochs": 8, "timestep": 15472, "ep_reward": 829.1300659179688, "reward": 0.15015113353729248, "action": -1.3178679943084717}
{"mode": "train", "epochs": 8, "timestep": 15473, "ep_reward": 829.4158325195312, "reward": 0.28577721118927, "action": -0.8231452107429504}
{"mode": "train", "epochs": 8, "timestep": 15474, "ep_reward": 829.8413696289062, "reward": 0.4255107045173645, "action": -1.1221920251846313}
{"mode": "train", "epochs": 8, "timestep": 15475, "ep_reward": 830.3900146484375, "reward": 0.5486352443695068, "action": -1.4358537197113037}
{"mode": "train", "epochs": 8, "timestep": 15476, "ep_reward": 831.0391235351562, "reward": 0.6491318941116333, "action": -0.8506461977958679}
{"mode": "train", "epochs": 8, "timestep": 15477, "ep_reward": 831.7726440429688, "reward": 0.7335115671157837, "action": -1.2406301498413086}
{"mode": "train", "epochs": 8, "timestep": 15478, "ep_reward": 832.56396484375, "reward": 0.7913017272949219, "action": -1.0903598070144653}
{"mode": "train", "epochs": 8, "timestep": 15479, "ep_reward": 833.3939208984375, "reward": 0.829952597618103, "action": -1.6538773775100708}
{"mode": "train", "epochs": 8, "timestep": 15480, "ep_reward": 834.239013671875, "reward": 0.8450672626495361, "action": -0.1627710461616516}
{"mode": "train", "epochs": 8, "timestep": 15481, "ep_reward": 835.09423828125, "reward": 0.8552342057228088, "action": -1.0206588506698608}
{"mode": "train", "epochs": 8, "timestep": 15482, "ep_reward": 835.9332275390625, "reward": 0.839008629322052, "action": -1.5229113101959229}
{"mode": "train", "epochs": 8, "timestep": 15483, "ep_reward": 836.7293090820312, "reward": 0.7960869669914246, "action": -0.46174484491348267}
{"mode": "train", "epochs": 8, "timestep": 15484, "ep_reward": 837.46630859375, "reward": 0.7369768619537354, "action": -0.9252121448516846}
{"mode": "train", "epochs": 8, "timestep": 15485, "ep_reward": 838.1062622070312, "reward": 0.6399784088134766, "action": -0.7100270390510559}
{"mode": "train", "epochs": 8, "timestep": 15486, "ep_reward": 838.6128540039062, "reward": 0.5065632462501526, "action": -0.3640645146369934}
{"mode": "train", "epochs": 8, "timestep": 15487, "ep_reward": 838.9743041992188, "reward": 0.36144137382507324, "action": -0.5114834904670715}
{"mode": "train", "epochs": 8, "timestep": 15488, "ep_reward": 839.22802734375, "reward": 0.25369471311569214, "action": -1.1539678573608398}
{"mode": "train", "epochs": 8, "timestep": 15489, "ep_reward": 839.3540649414062, "reward": 0.12601977586746216, "action": -1.1239333152770996}
{"mode": "train", "epochs": 8, "timestep": 15490, "ep_reward": 839.3418579101562, "reward": -0.0121840238571167, "action": -0.8500711917877197}
{"mode": "train", "epochs": 8, "timestep": 15491, "ep_reward": 839.4760131835938, "reward": 0.13413238525390625, "action": -1.812269687652588}
{"mode": "train", "epochs": 8, "timestep": 15492, "ep_reward": 839.7391967773438, "reward": 0.26321059465408325, "action": -0.7257659435272217}
{"mode": "train", "epochs": 8, "timestep": 15493, "ep_reward": 840.1455078125, "reward": 0.40628641843795776, "action": -0.4386000633239746}
{"mode": "train", "epochs": 8, "timestep": 15494, "ep_reward": 840.685546875, "reward": 0.5400576591491699, "action": -0.17065197229385376}
{"mode": "train", "epochs": 8, "timestep": 15495, "ep_reward": 841.3408813476562, "reward": 0.6553308963775635, "action": -1.558786153793335}
{"mode": "train", "epochs": 8, "timestep": 15496, "ep_reward": 842.0737915039062, "reward": 0.732903242111206, "action": -0.9194742441177368}
{"mode": "train", "epochs": 8, "timestep": 15497, "ep_reward": 842.869384765625, "reward": 0.7955768704414368, "action": -1.1947977542877197}
{"mode": "train", "epochs": 8, "timestep": 15498, "ep_reward": 843.7052001953125, "reward": 0.8358294367790222, "action": -1.4275779724121094}
{"mode": "train", "epochs": 8, "timestep": 15499, "ep_reward": 844.5619506835938, "reward": 0.856726348400116, "action": -0.3351472020149231}
{"mode": "train", "epochs": 8, "timestep": 15500, "ep_reward": 845.4322509765625, "reward": 0.8702757358551025, "action": -0.8536186814308167}
{"mode": "train", "epochs": 8, "timestep": 15501, "ep_reward": 846.295166015625, "reward": 0.8629150390625, "action": -1.883558988571167}
{"mode": "train", "epochs": 8, "timestep": 15502, "ep_reward": 847.1231079101562, "reward": 0.8279171586036682, "action": -0.18003231287002563}
{"mode": "train", "epochs": 8, "timestep": 15503, "ep_reward": 847.9091796875, "reward": 0.7860724925994873, "action": -0.8111752271652222}
{"mode": "train", "epochs": 8, "timestep": 15504, "ep_reward": 848.619384765625, "reward": 0.710208535194397, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 15505, "ep_reward": 849.202880859375, "reward": 0.583469808101654, "action": -0.5419002771377563}
{"mode": "train", "epochs": 8, "timestep": 15506, "ep_reward": 849.6363525390625, "reward": 0.433476984500885, "action": -0.7340149879455566}
{"mode": "train", "epochs": 8, "timestep": 15507, "ep_reward": 849.9493408203125, "reward": 0.31300657987594604, "action": -0.42952942848205566}
{"mode": "train", "epochs": 8, "timestep": 15508, "ep_reward": 850.1450805664062, "reward": 0.19572019577026367, "action": -1.5921881198883057}
{"mode": "train", "epochs": 8, "timestep": 15509, "ep_reward": 850.2037963867188, "reward": 0.05872553586959839, "action": -0.47693175077438354}
{"mode": "train", "epochs": 8, "timestep": 15510, "ep_reward": 850.2632446289062, "reward": 0.0594630241394043, "action": -1.6674964427947998}
{"mode": "train", "epochs": 8, "timestep": 15511, "ep_reward": 850.4597778320312, "reward": 0.1965455412864685, "action": -1.3151379823684692}
{"mode": "train", "epochs": 8, "timestep": 15512, "ep_reward": 850.7927856445312, "reward": 0.3330010175704956, "action": 0.004622220993041992}
{"mode": "train", "epochs": 8, "timestep": 15513, "ep_reward": 851.2723388671875, "reward": 0.47955960035324097, "action": -1.1368327140808105}
{"mode": "train", "epochs": 8, "timestep": 15514, "ep_reward": 851.8671264648438, "reward": 0.5948144197463989, "action": -0.6004685759544373}
{"mode": "train", "epochs": 8, "timestep": 15515, "ep_reward": 852.56201171875, "reward": 0.6949051022529602, "action": -0.580836296081543}
{"mode": "train", "epochs": 8, "timestep": 15516, "ep_reward": 853.3338623046875, "reward": 0.7718209028244019, "action": 0.07121884822845459}
{"mode": "train", "epochs": 8, "timestep": 15517, "ep_reward": 854.1664428710938, "reward": 0.8325844407081604, "action": -0.984795868396759}
{"mode": "train", "epochs": 8, "timestep": 15518, "ep_reward": 855.0324096679688, "reward": 0.8659785985946655, "action": -0.5937572717666626}
{"mode": "train", "epochs": 8, "timestep": 15519, "ep_reward": 855.9197998046875, "reward": 0.8874028325080872, "action": -1.098036289215088}
{"mode": "train", "epochs": 8, "timestep": 15520, "ep_reward": 856.8113403320312, "reward": 0.8915121555328369, "action": -0.3195852041244507}
{"mode": "train", "epochs": 8, "timestep": 15521, "ep_reward": 857.6994018554688, "reward": 0.8880590796470642, "action": -1.1089767217636108}
{"mode": "train", "epochs": 8, "timestep": 15522, "ep_reward": 858.5629272460938, "reward": 0.8635332584381104, "action": 0.2708943486213684}
{"mode": "train", "epochs": 8, "timestep": 15523, "ep_reward": 859.3960571289062, "reward": 0.8331193923950195, "action": -1.2939858436584473}
{"mode": "train", "epochs": 8, "timestep": 15524, "ep_reward": 860.1621704101562, "reward": 0.7661392688751221, "action": -0.9529332518577576}
{"mode": "train", "epochs": 8, "timestep": 15525, "ep_reward": 860.8343505859375, "reward": 0.6721853613853455, "action": -1.598768711090088}
{"mode": "train", "epochs": 8, "timestep": 15526, "ep_reward": 861.366943359375, "reward": 0.5325742363929749, "action": -1.693692922592163}
{"mode": "train", "epochs": 8, "timestep": 15527, "ep_reward": 861.7235717773438, "reward": 0.3566449284553528, "action": -1.3174505233764648}
{"mode": "train", "epochs": 8, "timestep": 15528, "ep_reward": 861.9715576171875, "reward": 0.2480027675628662, "action": -1.3406567573547363}
{"mode": "train", "epochs": 8, "timestep": 15529, "ep_reward": 862.0909423828125, "reward": 0.11938583850860596, "action": -1.2112654447555542}
{"mode": "train", "epochs": 8, "timestep": 15530, "ep_reward": 862.0863037109375, "reward": -0.004666328430175781, "action": -0.24180984497070312}
{"mode": "train", "epochs": 8, "timestep": 15531, "ep_reward": 862.2271118164062, "reward": 0.14080935716629028, "action": -0.8579700589179993}
{"mode": "train", "epochs": 8, "timestep": 15532, "ep_reward": 862.509033203125, "reward": 0.28189361095428467, "action": -1.0517704486846924}
{"mode": "train", "epochs": 8, "timestep": 15533, "ep_reward": 862.92724609375, "reward": 0.4182182550430298, "action": -0.96014803647995}
{"mode": "train", "epochs": 8, "timestep": 15534, "ep_reward": 863.47119140625, "reward": 0.5439669489860535, "action": -0.562358021736145}
{"mode": "train", "epochs": 8, "timestep": 15535, "ep_reward": 864.1257934570312, "reward": 0.6545791625976562, "action": 0.05895376205444336}
{"mode": "train", "epochs": 8, "timestep": 15536, "ep_reward": 864.873291015625, "reward": 0.7474738359451294, "action": -0.845528244972229}
{"mode": "train", "epochs": 8, "timestep": 15537, "ep_reward": 865.6819458007812, "reward": 0.8086830377578735, "action": -1.1932927370071411}
{"mode": "train", "epochs": 8, "timestep": 15538, "ep_reward": 866.5302734375, "reward": 0.8483415842056274, "action": -0.7666622400283813}
{"mode": "train", "epochs": 8, "timestep": 15539, "ep_reward": 867.4055786132812, "reward": 0.8753066658973694, "action": -1.041694164276123}
{"mode": "train", "epochs": 8, "timestep": 15540, "ep_reward": 868.2910766601562, "reward": 0.8854828476905823, "action": -1.6230850219726562}
{"mode": "train", "epochs": 8, "timestep": 15541, "ep_reward": 869.1680297851562, "reward": 0.8769282102584839, "action": -0.963234543800354}
{"mode": "train", "epochs": 8, "timestep": 15542, "ep_reward": 870.0255126953125, "reward": 0.8574548959732056, "action": -1.391635775566101}
{"mode": "train", "epochs": 8, "timestep": 15543, "ep_reward": 870.8397827148438, "reward": 0.8142660856246948, "action": -1.8918392658233643}
{"mode": "train", "epochs": 8, "timestep": 15544, "ep_reward": 871.5790405273438, "reward": 0.7392634153366089, "action": -0.6604008078575134}
{"mode": "train", "epochs": 8, "timestep": 15545, "ep_reward": 872.22314453125, "reward": 0.6440838575363159, "action": -1.4325971603393555}
{"mode": "train", "epochs": 8, "timestep": 15546, "ep_reward": 872.7227783203125, "reward": 0.49963051080703735, "action": -0.4100378751754761}
{"mode": "train", "epochs": 8, "timestep": 15547, "ep_reward": 873.0767211914062, "reward": 0.35394197702407837, "action": -1.0394465923309326}
{"mode": "train", "epochs": 8, "timestep": 15548, "ep_reward": 873.3214721679688, "reward": 0.2447342872619629, "action": -1.1472148895263672}
{"mode": "train", "epochs": 8, "timestep": 15549, "ep_reward": 873.4368286132812, "reward": 0.11537408828735352, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 15550, "ep_reward": 873.4364624023438, "reward": -0.00037026405334472656, "action": -0.47115230560302734}
{"mode": "train", "epochs": 8, "timestep": 15551, "ep_reward": 873.5809936523438, "reward": 0.14455169439315796, "action": -0.9393011927604675}
{"mode": "train", "epochs": 8, "timestep": 15552, "ep_reward": 873.8655395507812, "reward": 0.2845592498779297, "action": -1.9107725620269775}
{"mode": "train", "epochs": 8, "timestep": 15553, "ep_reward": 874.2760620117188, "reward": 0.41052675247192383, "action": -1.1853773593902588}
{"mode": "train", "epochs": 8, "timestep": 15554, "ep_reward": 874.8114624023438, "reward": 0.5353730916976929, "action": -1.1263245344161987}
{"mode": "train", "epochs": 8, "timestep": 15555, "ep_reward": 875.4530029296875, "reward": 0.6415103673934937, "action": -0.437516987323761}
{"mode": "train", "epochs": 8, "timestep": 15556, "ep_reward": 876.184326171875, "reward": 0.7313106656074524, "action": -1.1831592321395874}
{"mode": "train", "epochs": 8, "timestep": 15557, "ep_reward": 876.9743041992188, "reward": 0.7899581789970398, "action": -0.6135572195053101}
{"mode": "train", "epochs": 8, "timestep": 15558, "ep_reward": 877.807373046875, "reward": 0.8330420851707458, "action": -0.37341177463531494}
{"mode": "train", "epochs": 8, "timestep": 15559, "ep_reward": 878.6664428710938, "reward": 0.8590885400772095, "action": -1.3149187564849854}
{"mode": "train", "epochs": 8, "timestep": 15560, "ep_reward": 879.5262451171875, "reward": 0.8598114848136902, "action": -1.402410864830017}
{"mode": "train", "epochs": 8, "timestep": 15561, "ep_reward": 880.3679809570312, "reward": 0.8417406678199768, "action": -0.6633011698722839}
{"mode": "train", "epochs": 8, "timestep": 15562, "ep_reward": 881.177490234375, "reward": 0.8095129132270813, "action": -0.821864902973175}
{"mode": "train", "epochs": 8, "timestep": 15563, "ep_reward": 881.927978515625, "reward": 0.7504651546478271, "action": -1.2264786958694458}
{"mode": "train", "epochs": 8, "timestep": 15564, "ep_reward": 882.58251953125, "reward": 0.6545436978340149, "action": -1.1944520473480225}
{"mode": "train", "epochs": 8, "timestep": 15565, "ep_reward": 883.1013793945312, "reward": 0.5188593864440918, "action": -1.3174598217010498}
{"mode": "train", "epochs": 8, "timestep": 15566, "ep_reward": 883.4727172851562, "reward": 0.37133389711380005, "action": -1.689903974533081}
{"mode": "train", "epochs": 8, "timestep": 15567, "ep_reward": 883.7386474609375, "reward": 0.2659011483192444, "action": -0.442402184009552}
{"mode": "train", "epochs": 8, "timestep": 15568, "ep_reward": 883.8787231445312, "reward": 0.14006495475769043, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 15569, "ep_reward": 883.8733520507812, "reward": -0.005388379096984863, "action": -1.299867868423462}
{"mode": "train", "epochs": 8, "timestep": 15570, "ep_reward": 883.9932250976562, "reward": 0.11984497308731079, "action": -1.7204540967941284}
{"mode": "train", "epochs": 8, "timestep": 15571, "ep_reward": 884.2428588867188, "reward": 0.2496398687362671, "action": -1.2102549076080322}
{"mode": "train", "epochs": 8, "timestep": 15572, "ep_reward": 884.6300659179688, "reward": 0.38718825578689575, "action": -0.4716750383377075}
{"mode": "train", "epochs": 8, "timestep": 15573, "ep_reward": 885.1533203125, "reward": 0.5232387185096741, "action": -0.8434500694274902}
{"mode": "train", "epochs": 8, "timestep": 15574, "ep_reward": 885.7880249023438, "reward": 0.6346802711486816, "action": -0.8063223361968994}
{"mode": "train", "epochs": 8, "timestep": 15575, "ep_reward": 886.5114135742188, "reward": 0.7234036922454834, "action": -0.8759621381759644}
{"mode": "train", "epochs": 8, "timestep": 15576, "ep_reward": 887.2998657226562, "reward": 0.7884528040885925, "action": -0.599805474281311}
{"mode": "train", "epochs": 8, "timestep": 15577, "ep_reward": 888.1348876953125, "reward": 0.8350018858909607, "action": -1.547389268875122}
{"mode": "train", "epochs": 8, "timestep": 15578, "ep_reward": 888.9901733398438, "reward": 0.8552983999252319, "action": -1.227531909942627}
{"mode": "train", "epochs": 8, "timestep": 15579, "ep_reward": 889.8518676757812, "reward": 0.8616880178451538, "action": -0.8927761316299438}
{"mode": "train", "epochs": 8, "timestep": 15580, "ep_reward": 890.70556640625, "reward": 0.8537120819091797, "action": -0.812100887298584}
{"mode": "train", "epochs": 8, "timestep": 15581, "ep_reward": 891.5327758789062, "reward": 0.8272111415863037, "action": -1.377881407737732}
{"mode": "train", "epochs": 8, "timestep": 15582, "ep_reward": 892.3042602539062, "reward": 0.7715121507644653, "action": -1.0831621885299683}
{"mode": "train", "epochs": 8, "timestep": 15583, "ep_reward": 892.9924926757812, "reward": 0.688205361366272, "action": -1.0953658819198608}
{"mode": "train", "epochs": 8, "timestep": 15584, "ep_reward": 893.5595703125, "reward": 0.5670534372329712, "action": -1.703985571861267}
{"mode": "train", "epochs": 8, "timestep": 15585, "ep_reward": 893.9590454101562, "reward": 0.3994949460029602, "action": -0.9724442958831787}
{"mode": "train", "epochs": 8, "timestep": 15586, "ep_reward": 894.2589111328125, "reward": 0.299862802028656, "action": -1.5521366596221924}
{"mode": "train", "epochs": 8, "timestep": 15587, "ep_reward": 894.4393920898438, "reward": 0.18046659231185913, "action": -0.3271923065185547}
{"mode": "train", "epochs": 8, "timestep": 15588, "ep_reward": 894.4802856445312, "reward": 0.040918827056884766, "action": -0.48786550760269165}
{"mode": "train", "epochs": 8, "timestep": 15589, "ep_reward": 894.5574340820312, "reward": 0.07713240385055542, "action": -0.3479239344596863}
{"mode": "train", "epochs": 8, "timestep": 15590, "ep_reward": 894.7802124023438, "reward": 0.22275835275650024, "action": -1.2886908054351807}
{"mode": "train", "epochs": 8, "timestep": 15591, "ep_reward": 895.1375122070312, "reward": 0.35729944705963135, "action": -1.6399967670440674}
{"mode": "train", "epochs": 8, "timestep": 15592, "ep_reward": 895.6189575195312, "reward": 0.48142337799072266, "action": 0.16549646854400635}
{"mode": "train", "epochs": 8, "timestep": 15593, "ep_reward": 896.229736328125, "reward": 0.6107907891273499, "action": -1.4125933647155762}
{"mode": "train", "epochs": 8, "timestep": 15594, "ep_reward": 896.9293212890625, "reward": 0.6995554566383362, "action": -1.2264331579208374}
{"mode": "train", "epochs": 8, "timestep": 15595, "ep_reward": 897.6981201171875, "reward": 0.7687879800796509, "action": -1.5122714042663574}
{"mode": "train", "epochs": 8, "timestep": 15596, "ep_reward": 898.51318359375, "reward": 0.815051794052124, "action": -0.953934371471405}
{"mode": "train", "epochs": 8, "timestep": 15597, "ep_reward": 899.3609008789062, "reward": 0.8476971983909607, "action": 0.07475888729095459}
{"mode": "train", "epochs": 8, "timestep": 15598, "ep_reward": 900.232421875, "reward": 0.8715337514877319, "action": -1.1129056215286255}
{"mode": "train", "epochs": 8, "timestep": 15599, "ep_reward": 901.1016845703125, "reward": 0.8692516684532166, "action": -1.5198860168457031}
{"mode": "train", "epochs": 8, "timestep": 15600, "ep_reward": 901.947998046875, "reward": 0.8463386297225952, "action": -0.2845596671104431}
{"mode": "train", "epochs": 8, "timestep": 15601, "ep_reward": 902.76220703125, "reward": 0.814206063747406, "action": -1.6369941234588623}
{"mode": "train", "epochs": 8, "timestep": 15602, "ep_reward": 903.5054931640625, "reward": 0.7432808876037598, "action": -1.3518444299697876}
{"mode": "train", "epochs": 8, "timestep": 15603, "ep_reward": 904.1466064453125, "reward": 0.6411157846450806, "action": -0.8104584217071533}
{"mode": "train", "epochs": 8, "timestep": 15604, "ep_reward": 904.6525268554688, "reward": 0.5058989524841309, "action": -0.7747514247894287}
{"mode": "train", "epochs": 8, "timestep": 15605, "ep_reward": 905.0108642578125, "reward": 0.3583559989929199, "action": -0.8752481937408447}
{"mode": "train", "epochs": 8, "timestep": 15606, "ep_reward": 905.2609252929688, "reward": 0.25005507469177246, "action": -0.8558872938156128}
{"mode": "train", "epochs": 8, "timestep": 15607, "ep_reward": 905.382568359375, "reward": 0.1216421127319336, "action": -1.5811796188354492}
{"mode": "train", "epochs": 8, "timestep": 15608, "ep_reward": 905.3751831054688, "reward": -0.007406115531921387, "action": -1.4642961025238037}
{"mode": "train", "epochs": 8, "timestep": 15609, "ep_reward": 905.5137329101562, "reward": 0.1385498046875, "action": -0.7082551717758179}
{"mode": "train", "epochs": 8, "timestep": 15610, "ep_reward": 905.795166015625, "reward": 0.28143781423568726, "action": -1.0251420736312866}
{"mode": "train", "epochs": 8, "timestep": 15611, "ep_reward": 906.2130126953125, "reward": 0.4178661108016968, "action": 0.11613583564758301}
{"mode": "train", "epochs": 8, "timestep": 15612, "ep_reward": 906.768310546875, "reward": 0.5552852153778076, "action": -1.8350870609283447}
{"mode": "train", "epochs": 8, "timestep": 15613, "ep_reward": 907.4190063476562, "reward": 0.6507095098495483, "action": -0.7803758382797241}
{"mode": "train", "epochs": 8, "timestep": 15614, "ep_reward": 908.15576171875, "reward": 0.7367432117462158, "action": -0.6046661734580994}
{"mode": "train", "epochs": 8, "timestep": 15615, "ep_reward": 908.9579467773438, "reward": 0.8022097945213318, "action": -0.15462970733642578}
{"mode": "train", "epochs": 8, "timestep": 15616, "ep_reward": 909.8092041015625, "reward": 0.851243257522583, "action": -1.3034510612487793}
{"mode": "train", "epochs": 8, "timestep": 15617, "ep_reward": 910.6834716796875, "reward": 0.8742793202400208, "action": -0.736416220664978}
{"mode": "train", "epochs": 8, "timestep": 15618, "ep_reward": 911.5709228515625, "reward": 0.887427031993866, "action": -0.916102409362793}
{"mode": "train", "epochs": 8, "timestep": 15619, "ep_reward": 912.4561767578125, "reward": 0.8852351903915405, "action": -1.3273282051086426}
{"mode": "train", "epochs": 8, "timestep": 15620, "ep_reward": 913.3207397460938, "reward": 0.8645616769790649, "action": -1.3610069751739502}
{"mode": "train", "epochs": 8, "timestep": 15621, "ep_reward": 914.145263671875, "reward": 0.8245431780815125, "action": -1.2241026163101196}
{"mode": "train", "epochs": 8, "timestep": 15622, "ep_reward": 914.9064331054688, "reward": 0.7611980438232422, "action": -0.511160135269165}
{"mode": "train", "epochs": 8, "timestep": 15623, "ep_reward": 915.5817260742188, "reward": 0.6752641201019287, "action": -0.09505665302276611}
{"mode": "train", "epochs": 8, "timestep": 15624, "ep_reward": 916.1420288085938, "reward": 0.5602730512619019, "action": -0.5891987085342407}
{"mode": "train", "epochs": 8, "timestep": 15625, "ep_reward": 916.5433959960938, "reward": 0.40139496326446533, "action": -1.167901635169983}
{"mode": "train", "epochs": 8, "timestep": 15626, "ep_reward": 916.8153686523438, "reward": 0.271992027759552, "action": -0.3508869409561157}
{"mode": "train", "epochs": 8, "timestep": 15627, "ep_reward": 916.9627685546875, "reward": 0.14740324020385742, "action": -0.9457350969314575}
{"mode": "train", "epochs": 8, "timestep": 15628, "ep_reward": 916.9656372070312, "reward": 0.002841055393218994, "action": -1.1181411743164062}
{"mode": "train", "epochs": 8, "timestep": 15629, "ep_reward": 917.0782470703125, "reward": 0.1125936508178711, "action": -1.1289035081863403}
{"mode": "train", "epochs": 8, "timestep": 15630, "ep_reward": 917.32763671875, "reward": 0.24941706657409668, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 15631, "ep_reward": 917.70361328125, "reward": 0.3759811520576477, "action": -1.616461992263794}
{"mode": "train", "epochs": 8, "timestep": 15632, "ep_reward": 918.2035522460938, "reward": 0.4999459981918335, "action": -1.3445260524749756}
{"mode": "train", "epochs": 8, "timestep": 15633, "ep_reward": 918.8134765625, "reward": 0.6099339127540588, "action": -0.9646751284599304}
{"mode": "train", "epochs": 8, "timestep": 15634, "ep_reward": 919.5145263671875, "reward": 0.7010213732719421, "action": -1.2403016090393066}
{"mode": "train", "epochs": 8, "timestep": 15635, "ep_reward": 920.2794189453125, "reward": 0.7648810744285583, "action": 0.30381155014038086}
{"mode": "train", "epochs": 8, "timestep": 15636, "ep_reward": 921.0997924804688, "reward": 0.8203525543212891, "action": -1.8352060317993164}
{"mode": "train", "epochs": 8, "timestep": 15637, "ep_reward": 921.9347534179688, "reward": 0.8349872827529907, "action": -0.7802749872207642}
{"mode": "train", "epochs": 8, "timestep": 15638, "ep_reward": 922.7747192382812, "reward": 0.8399457335472107, "action": -0.5923773050308228}
{"mode": "train", "epochs": 8, "timestep": 15639, "ep_reward": 923.6011352539062, "reward": 0.8264135122299194, "action": -0.6602588891983032}
{"mode": "train", "epochs": 8, "timestep": 15640, "ep_reward": 924.390625, "reward": 0.7895111441612244, "action": -1.2125122547149658}
{"mode": "train", "epochs": 8, "timestep": 15641, "ep_reward": 925.1093139648438, "reward": 0.7186871767044067, "action": -0.7725093364715576}
{"mode": "train", "epochs": 8, "timestep": 15642, "ep_reward": 925.7271728515625, "reward": 0.6178523302078247, "action": -0.525794506072998}
{"mode": "train", "epochs": 8, "timestep": 15643, "ep_reward": 926.2074584960938, "reward": 0.4802861213684082, "action": -1.702874779701233}
{"mode": "train", "epochs": 8, "timestep": 15644, "ep_reward": 926.5565795898438, "reward": 0.3491395115852356, "action": -1.1309798955917358}
{"mode": "train", "epochs": 8, "timestep": 15645, "ep_reward": 926.7955932617188, "reward": 0.23901987075805664, "action": -0.8525972366333008}
{"mode": "train", "epochs": 8, "timestep": 15646, "ep_reward": 926.9044799804688, "reward": 0.10888713598251343, "action": -0.6274693608283997}
{"mode": "train", "epochs": 8, "timestep": 15647, "ep_reward": 926.9115600585938, "reward": 0.007055222988128662, "action": -0.4442296624183655}
{"mode": "train", "epochs": 8, "timestep": 15648, "ep_reward": 927.0626220703125, "reward": 0.15106165409088135, "action": -0.3595014810562134}
{"mode": "train", "epochs": 8, "timestep": 15649, "ep_reward": 927.3611450195312, "reward": 0.29850852489471436, "action": -1.0971684455871582}
{"mode": "train", "epochs": 8, "timestep": 15650, "ep_reward": 927.7936401367188, "reward": 0.43250948190689087, "action": -1.0642528533935547}
{"mode": "train", "epochs": 8, "timestep": 15651, "ep_reward": 928.3485717773438, "reward": 0.554919958114624, "action": -0.6670125722885132}
{"mode": "train", "epochs": 8, "timestep": 15652, "ep_reward": 929.0108642578125, "reward": 0.6623002290725708, "action": -1.1036800146102905}
{"mode": "train", "epochs": 8, "timestep": 15653, "ep_reward": 929.7535400390625, "reward": 0.7426931858062744, "action": -0.5257605910301208}
{"mode": "train", "epochs": 8, "timestep": 15654, "ep_reward": 930.5604858398438, "reward": 0.8069530725479126, "action": -0.15085923671722412}
{"mode": "train", "epochs": 8, "timestep": 15655, "ep_reward": 931.414794921875, "reward": 0.854317307472229, "action": -0.39034324884414673}
{"mode": "train", "epochs": 8, "timestep": 15656, "ep_reward": 932.2975463867188, "reward": 0.8827278017997742, "action": -1.0163376331329346}
{"mode": "train", "epochs": 8, "timestep": 15657, "ep_reward": 933.1898803710938, "reward": 0.892304003238678, "action": -1.5440382957458496}
{"mode": "train", "epochs": 8, "timestep": 15658, "ep_reward": 934.07421875, "reward": 0.8843388557434082, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 15659, "ep_reward": 934.93115234375, "reward": 0.856907844543457, "action": -0.4573752284049988}
{"mode": "train", "epochs": 8, "timestep": 15660, "ep_reward": 935.7545166015625, "reward": 0.8233433961868286, "action": -0.13369959592819214}
{"mode": "train", "epochs": 8, "timestep": 15661, "ep_reward": 936.5249633789062, "reward": 0.7704699635505676, "action": -0.9978358745574951}
{"mode": "train", "epochs": 8, "timestep": 15662, "ep_reward": 937.2048950195312, "reward": 0.6799184679985046, "action": -0.6679126024246216}
{"mode": "train", "epochs": 8, "timestep": 15663, "ep_reward": 937.7623901367188, "reward": 0.5574912428855896, "action": -1.3639888763427734}
{"mode": "train", "epochs": 8, "timestep": 15664, "ep_reward": 938.1476440429688, "reward": 0.385251522064209, "action": -1.0198986530303955}
{"mode": "train", "epochs": 8, "timestep": 15665, "ep_reward": 938.4154663085938, "reward": 0.2678428292274475, "action": -0.05222231149673462}
{"mode": "train", "epochs": 8, "timestep": 15666, "ep_reward": 938.5579833984375, "reward": 0.1425425410270691, "action": -0.7633334994316101}
{"mode": "train", "epochs": 8, "timestep": 15667, "ep_reward": 938.5551147460938, "reward": -0.0028651952743530273, "action": -1.7006263732910156}
{"mode": "train", "epochs": 8, "timestep": 15668, "ep_reward": 938.6727905273438, "reward": 0.11767995357513428, "action": -0.7039701342582703}
{"mode": "train", "epochs": 8, "timestep": 15669, "ep_reward": 938.9329223632812, "reward": 0.2601446509361267, "action": -0.5687039494514465}
{"mode": "train", "epochs": 8, "timestep": 15670, "ep_reward": 939.3358154296875, "reward": 0.40291815996170044, "action": -0.8933601975440979}
{"mode": "train", "epochs": 8, "timestep": 15671, "ep_reward": 939.8662719726562, "reward": 0.530479907989502, "action": -1.074342966079712}
{"mode": "train", "epochs": 8, "timestep": 15672, "ep_reward": 940.5043334960938, "reward": 0.6380906701087952, "action": -0.5539939403533936}
{"mode": "train", "epochs": 8, "timestep": 15673, "ep_reward": 941.2337036132812, "reward": 0.7293521165847778, "action": -0.04764533042907715}
{"mode": "train", "epochs": 8, "timestep": 15674, "ep_reward": 942.0359497070312, "reward": 0.8022485375404358, "action": -0.7372012138366699}
{"mode": "train", "epochs": 8, "timestep": 15675, "ep_reward": 942.8847045898438, "reward": 0.848737895488739, "action": -0.9517030715942383}
{"mode": "train", "epochs": 8, "timestep": 15676, "ep_reward": 943.7620849609375, "reward": 0.8773919939994812, "action": -0.13503408432006836}
{"mode": "train", "epochs": 8, "timestep": 15677, "ep_reward": 944.6602172851562, "reward": 0.8981083631515503, "action": -0.916968584060669}
{"mode": "train", "epochs": 8, "timestep": 15678, "ep_reward": 945.560546875, "reward": 0.9003491401672363, "action": -1.6003355979919434}
{"mode": "train", "epochs": 8, "timestep": 15679, "ep_reward": 946.4449462890625, "reward": 0.8843779563903809, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 15680, "ep_reward": 947.2935180664062, "reward": 0.848551869392395, "action": -0.5057034492492676}
{"mode": "train", "epochs": 8, "timestep": 15681, "ep_reward": 948.0983276367188, "reward": 0.8047909736633301, "action": -0.7902827262878418}
{"mode": "train", "epochs": 8, "timestep": 15682, "ep_reward": 948.8311767578125, "reward": 0.7328693866729736, "action": -0.7913548350334167}
{"mode": "train", "epochs": 8, "timestep": 15683, "ep_reward": 949.4598999023438, "reward": 0.6287274360656738, "action": -0.911932647228241}
{"mode": "train", "epochs": 8, "timestep": 15684, "ep_reward": 949.9450073242188, "reward": 0.4851378798484802, "action": -0.16199380159378052}
{"mode": "train", "epochs": 8, "timestep": 15685, "ep_reward": 950.2719116210938, "reward": 0.3268807530403137, "action": -0.7063039541244507}
{"mode": "train", "epochs": 8, "timestep": 15686, "ep_reward": 950.4842529296875, "reward": 0.2123529314994812, "action": -0.850918710231781}
{"mode": "train", "epochs": 8, "timestep": 15687, "ep_reward": 950.5620727539062, "reward": 0.07783597707748413, "action": -0.8862000703811646}
{"mode": "train", "epochs": 8, "timestep": 15688, "ep_reward": 950.6019897460938, "reward": 0.03994143009185791, "action": -1.8825958967208862}
{"mode": "train", "epochs": 8, "timestep": 15689, "ep_reward": 950.78173828125, "reward": 0.17974913120269775, "action": -0.9486145377159119}
{"mode": "train", "epochs": 8, "timestep": 15690, "ep_reward": 951.1021118164062, "reward": 0.32038313150405884, "action": -1.5278799533843994}
{"mode": "train", "epochs": 8, "timestep": 15691, "ep_reward": 951.5512084960938, "reward": 0.44906777143478394, "action": -1.0350127220153809}
{"mode": "train", "epochs": 8, "timestep": 15692, "ep_reward": 952.1215209960938, "reward": 0.5702927112579346, "action": -1.4698057174682617}
{"mode": "train", "epochs": 8, "timestep": 15693, "ep_reward": 952.7874755859375, "reward": 0.665981113910675, "action": -1.5885705947875977}
{"mode": "train", "epochs": 8, "timestep": 15694, "ep_reward": 953.5258178710938, "reward": 0.7383249998092651, "action": -0.6767894625663757}
{"mode": "train", "epochs": 8, "timestep": 15695, "ep_reward": 954.3230590820312, "reward": 0.7972511649131775, "action": -0.4712541103363037}
{"mode": "train", "epochs": 8, "timestep": 15696, "ep_reward": 955.1595458984375, "reward": 0.8364576697349548, "action": -0.6631611585617065}
{"mode": "train", "epochs": 8, "timestep": 15697, "ep_reward": 956.0142822265625, "reward": 0.8547565937042236, "action": -1.1476562023162842}
{"mode": "train", "epochs": 8, "timestep": 15698, "ep_reward": 956.8651733398438, "reward": 0.8509104251861572, "action": -0.5843188762664795}
{"mode": "train", "epochs": 8, "timestep": 15699, "ep_reward": 957.6982421875, "reward": 0.8330666422843933, "action": -0.21687549352645874}
{"mode": "train", "epochs": 8, "timestep": 15700, "ep_reward": 958.4954833984375, "reward": 0.7972412705421448, "action": -0.9953567981719971}
{"mode": "train", "epochs": 8, "timestep": 15701, "ep_reward": 959.222412109375, "reward": 0.7269082069396973, "action": -1.453810453414917}
{"mode": "train", "epochs": 8, "timestep": 15702, "ep_reward": 959.8386840820312, "reward": 0.6162869334220886, "action": -0.641596794128418}
{"mode": "train", "epochs": 8, "timestep": 15703, "ep_reward": 960.3140258789062, "reward": 0.4753519892692566, "action": -0.8946830034255981}
{"mode": "train", "epochs": 8, "timestep": 15704, "ep_reward": 960.6541137695312, "reward": 0.3400636315345764, "action": -1.3067963123321533}
{"mode": "train", "epochs": 8, "timestep": 15705, "ep_reward": 960.8821411132812, "reward": 0.22802293300628662, "action": -1.7997136116027832}
{"mode": "train", "epochs": 8, "timestep": 15706, "ep_reward": 960.9783325195312, "reward": 0.09619134664535522, "action": -1.1963047981262207}
{"mode": "train", "epochs": 8, "timestep": 15707, "ep_reward": 960.9989624023438, "reward": 0.02061384916305542, "action": -1.6222069263458252}
{"mode": "train", "epochs": 8, "timestep": 15708, "ep_reward": 961.1619262695312, "reward": 0.16295135021209717, "action": -0.7812948226928711}
{"mode": "train", "epochs": 8, "timestep": 15709, "ep_reward": 961.4674072265625, "reward": 0.30545347929000854, "action": -1.0311143398284912}
{"mode": "train", "epochs": 8, "timestep": 15710, "ep_reward": 961.9078979492188, "reward": 0.44051098823547363, "action": -1.7772271633148193}
{"mode": "train", "epochs": 8, "timestep": 15711, "ep_reward": 962.4620971679688, "reward": 0.554226279258728, "action": -0.6206650733947754}
{"mode": "train", "epochs": 8, "timestep": 15712, "ep_reward": 963.124267578125, "reward": 0.6621401906013489, "action": -1.0073593854904175}
{"mode": "train", "epochs": 8, "timestep": 15713, "ep_reward": 963.8665161132812, "reward": 0.7422387599945068, "action": -1.3221784830093384}
{"mode": "train", "epochs": 8, "timestep": 15714, "ep_reward": 964.6636962890625, "reward": 0.7972092628479004, "action": -1.8007807731628418}
{"mode": "train", "epochs": 8, "timestep": 15715, "ep_reward": 965.4920654296875, "reward": 0.8283681869506836, "action": -0.3262166380882263}
{"mode": "train", "epochs": 8, "timestep": 15716, "ep_reward": 966.34619140625, "reward": 0.8541073799133301, "action": -1.0742748975753784}
{"mode": "train", "epochs": 8, "timestep": 15717, "ep_reward": 967.2015991210938, "reward": 0.8554045557975769, "action": -0.6590626239776611}
{"mode": "train", "epochs": 8, "timestep": 15718, "ep_reward": 968.0436401367188, "reward": 0.8420515060424805, "action": -0.5955852270126343}
{"mode": "train", "epochs": 8, "timestep": 15719, "ep_reward": 968.8522338867188, "reward": 0.8086234927177429, "action": -0.9693319797515869}
{"mode": "train", "epochs": 8, "timestep": 15720, "ep_reward": 969.5982666015625, "reward": 0.7460614442825317, "action": -0.18482661247253418}
{"mode": "train", "epochs": 8, "timestep": 15721, "ep_reward": 970.2594604492188, "reward": 0.6611876487731934, "action": -1.3856589794158936}
{"mode": "train", "epochs": 8, "timestep": 15722, "ep_reward": 970.7830810546875, "reward": 0.5236402153968811, "action": -0.8564122319221497}
{"mode": "train", "epochs": 8, "timestep": 15723, "ep_reward": 971.15087890625, "reward": 0.36777955293655396, "action": -1.3323382139205933}
{"mode": "train", "epochs": 8, "timestep": 15724, "ep_reward": 971.412353515625, "reward": 0.26149284839630127, "action": -0.837670087814331}
{"mode": "train", "epochs": 8, "timestep": 15725, "ep_reward": 971.5475463867188, "reward": 0.13518303632736206, "action": -0.09248805046081543}
{"mode": "train", "epochs": 8, "timestep": 15726, "ep_reward": 971.5363159179688, "reward": -0.011220693588256836, "action": -0.910420298576355}
{"mode": "train", "epochs": 8, "timestep": 15727, "ep_reward": 971.6614379882812, "reward": 0.1251031756401062, "action": -1.5591340065002441}
{"mode": "train", "epochs": 8, "timestep": 15728, "ep_reward": 971.9185180664062, "reward": 0.257076621055603, "action": -1.0823938846588135}
{"mode": "train", "epochs": 8, "timestep": 15729, "ep_reward": 972.3140869140625, "reward": 0.3955846428871155, "action": -0.22988682985305786}
{"mode": "train", "epochs": 8, "timestep": 15730, "ep_reward": 972.8471069335938, "reward": 0.533005952835083, "action": -1.4695099592208862}
{"mode": "train", "epochs": 8, "timestep": 15731, "ep_reward": 973.483154296875, "reward": 0.6360258460044861, "action": -0.9588526487350464}
{"mode": "train", "epochs": 8, "timestep": 15732, "ep_reward": 974.2060546875, "reward": 0.7228787541389465, "action": -1.1228508949279785}
{"mode": "train", "epochs": 8, "timestep": 15733, "ep_reward": 974.9915161132812, "reward": 0.7854702472686768, "action": -1.0947059392929077}
{"mode": "train", "epochs": 8, "timestep": 15734, "ep_reward": 975.8192749023438, "reward": 0.8277692198753357, "action": -0.6305598020553589}
{"mode": "train", "epochs": 8, "timestep": 15735, "ep_reward": 976.6746826171875, "reward": 0.8554102778434753, "action": -1.0387095212936401}
{"mode": "train", "epochs": 8, "timestep": 15736, "ep_reward": 977.536865234375, "reward": 0.8622130751609802, "action": -1.5217894315719604}
{"mode": "train", "epochs": 8, "timestep": 15737, "ep_reward": 978.38427734375, "reward": 0.8473896384239197, "action": -0.3782232403755188}
{"mode": "train", "epochs": 8, "timestep": 15738, "ep_reward": 979.2073364257812, "reward": 0.8230457901954651, "action": -1.0908937454223633}
{"mode": "train", "epochs": 8, "timestep": 15739, "ep_reward": 979.975341796875, "reward": 0.7680052518844604, "action": -1.657843828201294}
{"mode": "train", "epochs": 8, "timestep": 15740, "ep_reward": 980.6503295898438, "reward": 0.6750069856643677, "action": -1.7812206745147705}
{"mode": "train", "epochs": 8, "timestep": 15741, "ep_reward": 981.1896362304688, "reward": 0.5393141508102417, "action": -0.669259786605835}
{"mode": "train", "epochs": 8, "timestep": 15742, "ep_reward": 981.5798950195312, "reward": 0.3902428150177002, "action": -1.2901890277862549}
{"mode": "train", "epochs": 8, "timestep": 15743, "ep_reward": 981.86865234375, "reward": 0.28876280784606934, "action": -0.15192115306854248}
{"mode": "train", "epochs": 8, "timestep": 15744, "ep_reward": 982.0358276367188, "reward": 0.1671541929244995, "action": -0.6311452388763428}
{"mode": "train", "epochs": 8, "timestep": 15745, "ep_reward": 982.0613403320312, "reward": 0.025538742542266846, "action": -0.9196847677230835}
{"mode": "train", "epochs": 8, "timestep": 15746, "ep_reward": 982.1531372070312, "reward": 0.09178179502487183, "action": 0.17307662963867188}
{"mode": "train", "epochs": 8, "timestep": 15747, "ep_reward": 982.3973999023438, "reward": 0.2442542314529419, "action": -1.303438425064087}
{"mode": "train", "epochs": 8, "timestep": 15748, "ep_reward": 982.7743530273438, "reward": 0.3769662380218506, "action": -1.0784504413604736}
{"mode": "train", "epochs": 8, "timestep": 15749, "ep_reward": 983.2794189453125, "reward": 0.5050357580184937, "action": -0.38477516174316406}
{"mode": "train", "epochs": 8, "timestep": 15750, "ep_reward": 983.903564453125, "reward": 0.6241363286972046, "action": -0.5721496343612671}
{"mode": "train", "epochs": 8, "timestep": 15751, "ep_reward": 984.6220092773438, "reward": 0.7184640169143677, "action": -1.4066188335418701}
{"mode": "train", "epochs": 8, "timestep": 15752, "ep_reward": 985.4052734375, "reward": 0.7832842469215393, "action": -0.14149630069732666}
{"mode": "train", "epochs": 8, "timestep": 15753, "ep_reward": 986.2449340820312, "reward": 0.8396434187889099, "action": -0.48739784955978394}
{"mode": "train", "epochs": 8, "timestep": 15754, "ep_reward": 987.1201171875, "reward": 0.8752123117446899, "action": -0.6746469736099243}
{"mode": "train", "epochs": 8, "timestep": 15755, "ep_reward": 988.0150756835938, "reward": 0.8949403166770935, "action": -0.47718727588653564}
{"mode": "train", "epochs": 8, "timestep": 15756, "ep_reward": 988.9185791015625, "reward": 0.9035124778747559, "action": 0.4000033736228943}
{"mode": "train", "epochs": 8, "timestep": 15757, "ep_reward": 989.8250732421875, "reward": 0.906521201133728, "action": -0.6839001178741455}
{"mode": "train", "epochs": 8, "timestep": 15758, "ep_reward": 990.71435546875, "reward": 0.8892524838447571, "action": -1.9414567947387695}
{"mode": "train", "epochs": 8, "timestep": 15759, "ep_reward": 991.5604248046875, "reward": 0.846084713935852, "action": -0.8891878128051758}
{"mode": "train", "epochs": 8, "timestep": 15760, "ep_reward": 992.3502197265625, "reward": 0.7897909879684448, "action": 0.06283432245254517}
{"mode": "train", "epochs": 8, "timestep": 15761, "ep_reward": 993.0673828125, "reward": 0.7171856164932251, "action": -1.7459675073623657}
{"mode": "train", "epochs": 8, "timestep": 15762, "ep_reward": 993.6585083007812, "reward": 0.5911493301391602, "action": -1.0731161832809448}
{"mode": "train", "epochs": 8, "timestep": 15763, "ep_reward": 994.0916137695312, "reward": 0.43308621644973755, "action": -0.5343644618988037}
{"mode": "train", "epochs": 8, "timestep": 15764, "ep_reward": 994.3788452148438, "reward": 0.2872520089149475, "action": -0.8133711218833923}
{"mode": "train", "epochs": 8, "timestep": 15765, "ep_reward": 994.5442504882812, "reward": 0.16541510820388794, "action": -0.6915124654769897}
{"mode": "train", "epochs": 8, "timestep": 15766, "ep_reward": 994.5678100585938, "reward": 0.023548781871795654, "action": -0.8519321084022522}
{"mode": "train", "epochs": 8, "timestep": 15767, "ep_reward": 994.6614379882812, "reward": 0.09361785650253296, "action": -0.8129977583885193}
{"mode": "train", "epochs": 8, "timestep": 15768, "ep_reward": 994.8953857421875, "reward": 0.23392361402511597, "action": -1.5859959125518799}
{"mode": "train", "epochs": 8, "timestep": 15769, "ep_reward": 995.260986328125, "reward": 0.36561131477355957, "action": -0.6462604403495789}
{"mode": "train", "epochs": 8, "timestep": 15770, "ep_reward": 995.7623291015625, "reward": 0.5013470649719238, "action": -1.2002177238464355}
{"mode": "train", "epochs": 8, "timestep": 15771, "ep_reward": 996.3748779296875, "reward": 0.6125649213790894, "action": -1.5147122144699097}
{"mode": "train", "epochs": 8, "timestep": 15772, "ep_reward": 997.0741577148438, "reward": 0.6992640495300293, "action": -0.8721058368682861}
{"mode": "train", "epochs": 8, "timestep": 15773, "ep_reward": 997.8443603515625, "reward": 0.7701761722564697, "action": -0.3468623757362366}
{"mode": "train", "epochs": 8, "timestep": 15774, "ep_reward": 998.6680908203125, "reward": 0.8237346410751343, "action": -1.203560471534729}
{"mode": "train", "epochs": 8, "timestep": 15775, "ep_reward": 999.518310546875, "reward": 0.8502489328384399, "action": -0.7818254828453064}
{"mode": "train", "epochs": 8, "timestep": 15776, "ep_reward": 1000.3814086914062, "reward": 0.8631237745285034, "action": -1.2404333353042603}
{"mode": "train", "epochs": 8, "timestep": 15777, "ep_reward": 1001.2362060546875, "reward": 0.854785680770874, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 15778, "ep_reward": 1002.0560913085938, "reward": 0.8198972940444946, "action": -0.48038482666015625}
{"mode": "train", "epochs": 8, "timestep": 15779, "ep_reward": 1002.8314208984375, "reward": 0.7753595113754272, "action": -1.1776771545410156}
{"mode": "train", "epochs": 8, "timestep": 15780, "ep_reward": 1003.5252685546875, "reward": 0.6938697099685669, "action": -1.2870450019836426}
{"mode": "train", "epochs": 8, "timestep": 15781, "ep_reward": 1004.0983276367188, "reward": 0.573072075843811, "action": -1.5820558071136475}
{"mode": "train", "epochs": 8, "timestep": 15782, "ep_reward": 1004.5052490234375, "reward": 0.40692925453186035, "action": -0.8368829488754272}
{"mode": "train", "epochs": 8, "timestep": 15783, "ep_reward": 1004.8142700195312, "reward": 0.30899691581726074, "action": -1.263357400894165}
{"mode": "train", "epochs": 8, "timestep": 15784, "ep_reward": 1005.0054931640625, "reward": 0.19121074676513672, "action": -0.341075599193573}
{"mode": "train", "epochs": 8, "timestep": 15785, "ep_reward": 1005.0586547851562, "reward": 0.053137242794036865, "action": -1.7872395515441895}
{"mode": "train", "epochs": 8, "timestep": 15786, "ep_reward": 1005.1235961914062, "reward": 0.06495648622512817, "action": -1.005001187324524}
{"mode": "train", "epochs": 8, "timestep": 15787, "ep_reward": 1005.3257446289062, "reward": 0.2021251916885376, "action": -0.31767040491104126}
{"mode": "train", "epochs": 8, "timestep": 15788, "ep_reward": 1005.6763305664062, "reward": 0.3506006598472595, "action": -1.405442237854004}
{"mode": "train", "epochs": 8, "timestep": 15789, "ep_reward": 1006.154052734375, "reward": 0.4777039885520935, "action": -0.6306401491165161}
{"mode": "train", "epochs": 8, "timestep": 15790, "ep_reward": 1006.7529296875, "reward": 0.5988888740539551, "action": -0.6260051727294922}
{"mode": "train", "epochs": 8, "timestep": 15791, "ep_reward": 1007.4508666992188, "reward": 0.6979268789291382, "action": -0.3411409258842468}
{"mode": "train", "epochs": 8, "timestep": 15792, "ep_reward": 1008.2271118164062, "reward": 0.7762384414672852, "action": -1.3334770202636719}
{"mode": "train", "epochs": 8, "timestep": 15793, "ep_reward": 1009.0516967773438, "reward": 0.8246116638183594, "action": -0.8690574169158936}
{"mode": "train", "epochs": 8, "timestep": 15794, "ep_reward": 1009.9109497070312, "reward": 0.8592690229415894, "action": -1.5804736614227295}
{"mode": "train", "epochs": 8, "timestep": 15795, "ep_reward": 1010.7835083007812, "reward": 0.8725437521934509, "action": -1.1130292415618896}
{"mode": "train", "epochs": 8, "timestep": 15796, "ep_reward": 1011.6578369140625, "reward": 0.8743481636047363, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 15797, "ep_reward": 1012.5101928710938, "reward": 0.852338969707489, "action": -1.1472604274749756}
{"mode": "train", "epochs": 8, "timestep": 15798, "ep_reward": 1013.3276977539062, "reward": 0.8175203204154968, "action": -0.21862691640853882}
{"mode": "train", "epochs": 8, "timestep": 15799, "ep_reward": 1014.0956420898438, "reward": 0.7679433822631836, "action": -1.0270805358886719}
{"mode": "train", "epochs": 8, "timestep": 15800, "ep_reward": 1014.77587890625, "reward": 0.6802277565002441, "action": -1.3716425895690918}
{"mode": "train", "epochs": 8, "timestep": 15801, "ep_reward": 1015.3261108398438, "reward": 0.5502191781997681, "action": -0.617485523223877}
{"mode": "train", "epochs": 8, "timestep": 15802, "ep_reward": 1015.7149047851562, "reward": 0.38877493143081665, "action": -1.0602729320526123}
{"mode": "train", "epochs": 8, "timestep": 15803, "ep_reward": 1015.9964599609375, "reward": 0.281557559967041, "action": 0.0004686117172241211}
{"mode": "train", "epochs": 8, "timestep": 15804, "ep_reward": 1016.1550903320312, "reward": 0.15866035223007202, "action": -0.6662628650665283}
{"mode": "train", "epochs": 8, "timestep": 15805, "ep_reward": 1016.1708374023438, "reward": 0.01577681303024292, "action": -0.7928838133811951}
{"mode": "train", "epochs": 8, "timestep": 15806, "ep_reward": 1016.271728515625, "reward": 0.10088521242141724, "action": -0.46434569358825684}
{"mode": "train", "epochs": 8, "timestep": 15807, "ep_reward": 1016.517578125, "reward": 0.24584758281707764, "action": -0.6351616382598877}
{"mode": "train", "epochs": 8, "timestep": 15808, "ep_reward": 1016.905517578125, "reward": 0.3879220485687256, "action": -0.4063214063644409}
{"mode": "train", "epochs": 8, "timestep": 15809, "ep_reward": 1017.4279174804688, "reward": 0.5224224925041199, "action": -0.44910728931427}
{"mode": "train", "epochs": 8, "timestep": 15810, "ep_reward": 1018.0653686523438, "reward": 0.6374599933624268, "action": -1.705382227897644}
{"mode": "train", "epochs": 8, "timestep": 15811, "ep_reward": 1018.783935546875, "reward": 0.7185550928115845, "action": -1.144973874092102}
{"mode": "train", "epochs": 8, "timestep": 15812, "ep_reward": 1019.5689697265625, "reward": 0.7850406169891357, "action": -1.8370890617370605}
{"mode": "train", "epochs": 8, "timestep": 15813, "ep_reward": 1020.3955688476562, "reward": 0.826623797416687, "action": -0.838577926158905}
{"mode": "train", "epochs": 8, "timestep": 15814, "ep_reward": 1021.255126953125, "reward": 0.8595412373542786, "action": -1.4352216720581055}
{"mode": "train", "epochs": 8, "timestep": 15815, "ep_reward": 1022.1268310546875, "reward": 0.8716833591461182, "action": -1.2535479068756104}
{"mode": "train", "epochs": 8, "timestep": 15816, "ep_reward": 1022.9967651367188, "reward": 0.8699115514755249, "action": -0.7034820318222046}
{"mode": "train", "epochs": 8, "timestep": 15817, "ep_reward": 1023.8529052734375, "reward": 0.856157660484314, "action": -0.5852545499801636}
{"mode": "train", "epochs": 8, "timestep": 15818, "ep_reward": 1024.6773681640625, "reward": 0.8244675397872925, "action": -1.4437028169631958}
{"mode": "train", "epochs": 8, "timestep": 15819, "ep_reward": 1025.437744140625, "reward": 0.7604078054428101, "action": -0.898185133934021}
{"mode": "train", "epochs": 8, "timestep": 15820, "ep_reward": 1026.1083984375, "reward": 0.6706933379173279, "action": -1.0348223447799683}
{"mode": "train", "epochs": 8, "timestep": 15821, "ep_reward": 1026.6500244140625, "reward": 0.5415673851966858, "action": -1.5919666290283203}
{"mode": "train", "epochs": 8, "timestep": 15822, "ep_reward": 1027.0252685546875, "reward": 0.3752196431159973, "action": -1.0273679494857788}
{"mode": "train", "epochs": 8, "timestep": 15823, "ep_reward": 1027.2955322265625, "reward": 0.2702845335006714, "action": -1.725114107131958}
{"mode": "train", "epochs": 8, "timestep": 15824, "ep_reward": 1027.441162109375, "reward": 0.1455850601196289, "action": -1.0427160263061523}
{"mode": "train", "epochs": 8, "timestep": 15825, "ep_reward": 1027.4420166015625, "reward": 0.0008034706115722656, "action": -0.6880550384521484}
{"mode": "train", "epochs": 8, "timestep": 15826, "ep_reward": 1027.5565185546875, "reward": 0.11446303129196167, "action": -1.2786481380462646}
{"mode": "train", "epochs": 8, "timestep": 15827, "ep_reward": 1027.80615234375, "reward": 0.2496049404144287, "action": -1.3466929197311401}
{"mode": "train", "epochs": 8, "timestep": 15828, "ep_reward": 1028.1907958984375, "reward": 0.3846197724342346, "action": -0.2033410668373108}
{"mode": "train", "epochs": 8, "timestep": 15829, "ep_reward": 1028.7144775390625, "reward": 0.5236443281173706, "action": -1.2796247005462646}
{"mode": "train", "epochs": 8, "timestep": 15830, "ep_reward": 1029.3448486328125, "reward": 0.6303707957267761, "action": -0.4044647216796875}
{"mode": "train", "epochs": 8, "timestep": 15831, "ep_reward": 1030.069091796875, "reward": 0.7242262363433838, "action": -0.6559417247772217}
{"mode": "train", "epochs": 8, "timestep": 15832, "ep_reward": 1030.8609619140625, "reward": 0.7918901443481445, "action": -1.5220286846160889}
{"mode": "train", "epochs": 8, "timestep": 15833, "ep_reward": 1031.6925048828125, "reward": 0.831555962562561, "action": -1.9730117321014404}
{"mode": "train", "epochs": 8, "timestep": 15834, "ep_reward": 1032.5428466796875, "reward": 0.8503580093383789, "action": -0.4746614098548889}
{"mode": "train", "epochs": 8, "timestep": 15835, "ep_reward": 1033.407958984375, "reward": 0.865164041519165, "action": -0.319232702255249}
{"mode": "train", "epochs": 8, "timestep": 15836, "ep_reward": 1034.2724609375, "reward": 0.8644742369651794, "action": -1.2694672346115112}
{"mode": "train", "epochs": 8, "timestep": 15837, "ep_reward": 1035.1099853515625, "reward": 0.8375688791275024, "action": -1.3385648727416992}
{"mode": "train", "epochs": 8, "timestep": 15838, "ep_reward": 1035.8973388671875, "reward": 0.7874063849449158, "action": -0.6379280686378479}
{"mode": "train", "epochs": 8, "timestep": 15839, "ep_reward": 1036.6136474609375, "reward": 0.7163429260253906, "action": -0.8413572907447815}
{"mode": "train", "epochs": 8, "timestep": 15840, "ep_reward": 1037.222412109375, "reward": 0.6088221669197083, "action": -1.4335695505142212}
{"mode": "train", "epochs": 8, "timestep": 15841, "ep_reward": 1037.674560546875, "reward": 0.45218390226364136, "action": -0.6805243492126465}
{"mode": "train", "epochs": 8, "timestep": 15842, "ep_reward": 1038.00048828125, "reward": 0.32596534490585327, "action": -0.8740730285644531}
{"mode": "train", "epochs": 8, "timestep": 15843, "ep_reward": 1038.211669921875, "reward": 0.21118319034576416, "action": -1.4688398838043213}
{"mode": "train", "epochs": 8, "timestep": 15844, "ep_reward": 1038.2882080078125, "reward": 0.07651764154434204, "action": -1.282524824142456}
{"mode": "train", "epochs": 8, "timestep": 15845, "ep_reward": 1038.3297119140625, "reward": 0.04146420955657959, "action": -0.5366700887680054}
{"mode": "train", "epochs": 8, "timestep": 15846, "ep_reward": 1038.513427734375, "reward": 0.18365883827209473, "action": -1.0124324560165405}
{"mode": "train", "epochs": 8, "timestep": 15847, "ep_reward": 1038.8365478515625, "reward": 0.3230748176574707, "action": -0.622502326965332}
{"mode": "train", "epochs": 8, "timestep": 15848, "ep_reward": 1039.298583984375, "reward": 0.46208298206329346, "action": -0.5658777952194214}
{"mode": "train", "epochs": 8, "timestep": 15849, "ep_reward": 1039.8846435546875, "reward": 0.586076021194458, "action": -0.5887928605079651}
{"mode": "train", "epochs": 8, "timestep": 15850, "ep_reward": 1040.5728759765625, "reward": 0.6881965398788452, "action": -0.9046967029571533}
{"mode": "train", "epochs": 8, "timestep": 15851, "ep_reward": 1041.3372802734375, "reward": 0.7643899321556091, "action": -1.6508986949920654}
{"mode": "train", "epochs": 8, "timestep": 15852, "ep_reward": 1042.15087890625, "reward": 0.8136414885520935, "action": -1.5329084396362305}
{"mode": "train", "epochs": 8, "timestep": 15853, "ep_reward": 1042.997314453125, "reward": 0.8464852571487427, "action": -0.8048210144042969}
{"mode": "train", "epochs": 8, "timestep": 15854, "ep_reward": 1043.8662109375, "reward": 0.8689571022987366, "action": -0.5932512283325195}
{"mode": "train", "epochs": 8, "timestep": 15855, "ep_reward": 1044.7437744140625, "reward": 0.8775511384010315, "action": -0.1362076997756958}
{"mode": "train", "epochs": 8, "timestep": 15856, "ep_reward": 1045.6181640625, "reward": 0.8744142055511475, "action": -1.9446017742156982}
{"mode": "train", "epochs": 8, "timestep": 15857, "ep_reward": 1046.45703125, "reward": 0.8388819098472595, "action": -1.363885521888733}
{"mode": "train", "epochs": 8, "timestep": 15858, "ep_reward": 1047.242431640625, "reward": 0.785396933555603, "action": 0.06020498275756836}
{"mode": "train", "epochs": 8, "timestep": 15859, "ep_reward": 1047.9617919921875, "reward": 0.719325065612793, "action": -1.5215280055999756}
{"mode": "train", "epochs": 8, "timestep": 15860, "ep_reward": 1048.563232421875, "reward": 0.6014419198036194, "action": -0.419161319732666}
{"mode": "train", "epochs": 8, "timestep": 15861, "ep_reward": 1049.0211181640625, "reward": 0.4579200744628906, "action": -0.8753936290740967}
{"mode": "train", "epochs": 8, "timestep": 15862, "ep_reward": 1049.338623046875, "reward": 0.3174988627433777, "action": -0.40693044662475586}
{"mode": "train", "epochs": 8, "timestep": 15863, "ep_reward": 1049.539794921875, "reward": 0.20116817951202393, "action": -0.7332175374031067}
{"mode": "train", "epochs": 8, "timestep": 15864, "ep_reward": 1049.6046142578125, "reward": 0.06479650735855103, "action": -1.2355389595031738}
{"mode": "train", "epochs": 8, "timestep": 15865, "ep_reward": 1049.6580810546875, "reward": 0.05343127250671387, "action": -0.743647575378418}
{"mode": "train", "epochs": 8, "timestep": 15866, "ep_reward": 1049.8515625, "reward": 0.19346719980239868, "action": -0.7286806106567383}
{"mode": "train", "epochs": 8, "timestep": 15867, "ep_reward": 1050.1881103515625, "reward": 0.3365941047668457, "action": -0.8985952734947205}
{"mode": "train", "epochs": 8, "timestep": 15868, "ep_reward": 1050.6590576171875, "reward": 0.4709700345993042, "action": -1.3136868476867676}
{"mode": "train", "epochs": 8, "timestep": 15869, "ep_reward": 1051.2445068359375, "reward": 0.5855079293251038, "action": -1.2939379215240479}
{"mode": "train", "epochs": 8, "timestep": 15870, "ep_reward": 1051.9249267578125, "reward": 0.6803759932518005, "action": -1.2094581127166748}
{"mode": "train", "epochs": 8, "timestep": 15871, "ep_reward": 1052.678955078125, "reward": 0.7540634274482727, "action": -0.9511639475822449}
{"mode": "train", "epochs": 8, "timestep": 15872, "ep_reward": 1053.4874267578125, "reward": 0.8084934949874878, "action": -1.6490631103515625}
{"mode": "train", "epochs": 8, "timestep": 15873, "ep_reward": 1054.32470703125, "reward": 0.8372440338134766, "action": -1.0308837890625}
{"mode": "train", "epochs": 8, "timestep": 15874, "ep_reward": 1055.17822265625, "reward": 0.8535385131835938, "action": -0.9854304194450378}
{"mode": "train", "epochs": 8, "timestep": 15875, "ep_reward": 1056.0306396484375, "reward": 0.8523668646812439, "action": -1.286950945854187}
{"mode": "train", "epochs": 8, "timestep": 15876, "ep_reward": 1056.8597412109375, "reward": 0.8291152119636536, "action": -1.5697237253189087}
{"mode": "train", "epochs": 8, "timestep": 15877, "ep_reward": 1057.6390380859375, "reward": 0.7792952060699463, "action": -1.6781085729599}
{"mode": "train", "epochs": 8, "timestep": 15878, "ep_reward": 1058.3363037109375, "reward": 0.6972979307174683, "action": 0.28944796323776245}
{"mode": "train", "epochs": 8, "timestep": 15879, "ep_reward": 1058.939697265625, "reward": 0.6034172773361206, "action": -0.7815567851066589}
{"mode": "train", "epochs": 8, "timestep": 15880, "ep_reward": 1059.396240234375, "reward": 0.4564870595932007, "action": -0.4215192198753357}
{"mode": "train", "epochs": 8, "timestep": 15881, "ep_reward": 1059.7288818359375, "reward": 0.33269304037094116, "action": -1.0854626893997192}
{"mode": "train", "epochs": 8, "timestep": 15882, "ep_reward": 1059.9482421875, "reward": 0.21935927867889404, "action": -0.412408709526062}
{"mode": "train", "epochs": 8, "timestep": 15883, "ep_reward": 1060.0341796875, "reward": 0.08594632148742676, "action": -0.625527024269104}
{"mode": "train", "epochs": 8, "timestep": 15884, "ep_reward": 1060.06591796875, "reward": 0.03170698881149292, "action": -0.698222815990448}
{"mode": "train", "epochs": 8, "timestep": 15885, "ep_reward": 1060.23828125, "reward": 0.1724228858947754, "action": -1.192973017692566}
{"mode": "train", "epochs": 8, "timestep": 15886, "ep_reward": 1060.54833984375, "reward": 0.3100764751434326, "action": -0.05638521909713745}
{"mode": "train", "epochs": 8, "timestep": 15887, "ep_reward": 1061.005615234375, "reward": 0.4572628140449524, "action": -1.1948778629302979}
{"mode": "train", "epochs": 8, "timestep": 15888, "ep_reward": 1061.58056640625, "reward": 0.5749034285545349, "action": -0.9851915240287781}
{"mode": "train", "epochs": 8, "timestep": 15889, "ep_reward": 1062.2557373046875, "reward": 0.6752134561538696, "action": -0.882446825504303}
{"mode": "train", "epochs": 8, "timestep": 15890, "ep_reward": 1063.009765625, "reward": 0.7540732622146606, "action": -1.5524694919586182}
{"mode": "train", "epochs": 8, "timestep": 15891, "ep_reward": 1063.8154296875, "reward": 0.805680513381958, "action": -0.4213934540748596}
{"mode": "train", "epochs": 8, "timestep": 15892, "ep_reward": 1064.663818359375, "reward": 0.8483277559280396, "action": -0.1074974536895752}
{"mode": "train", "epochs": 8, "timestep": 15893, "ep_reward": 1065.539794921875, "reward": 0.8759198784828186, "action": -0.8261419534683228}
{"mode": "train", "epochs": 8, "timestep": 15894, "ep_reward": 1066.4222412109375, "reward": 0.8824251890182495, "action": -1.3565845489501953}
{"mode": "train", "epochs": 8, "timestep": 15895, "ep_reward": 1067.291748046875, "reward": 0.8695091605186462, "action": -2.0}
{"mode": "train", "epochs": 8, "timestep": 15896, "ep_reward": 1068.1246337890625, "reward": 0.8328822255134583, "action": -0.5417760610580444}
{"mode": "train", "epochs": 8, "timestep": 15897, "ep_reward": 1068.911376953125, "reward": 0.7867643237113953, "action": -1.1930742263793945}
{"mode": "train", "epochs": 8, "timestep": 15898, "ep_reward": 1069.6171875, "reward": 0.7058058977127075, "action": -0.6153935194015503}
{"mode": "train", "epochs": 8, "timestep": 15899, "ep_reward": 1070.2137451171875, "reward": 0.5965439081192017, "action": -0.6692646741867065}
{"mode": "train", "epochs": 8, "timestep": 15900, "ep_reward": 1070.6612548828125, "reward": 0.44753265380859375, "action": -1.289070725440979}
{"mode": "train", "epochs": 8, "timestep": 15901, "ep_reward": 1070.9742431640625, "reward": 0.3130159378051758, "action": -1.7970455884933472}
{"mode": "train", "epochs": 8, "timestep": 15902, "ep_reward": 1071.1702880859375, "reward": 0.19605916738510132, "action": -0.8654792308807373}
{"mode": "train", "epochs": 8, "timestep": 15903, "ep_reward": 1071.229248046875, "reward": 0.05892235040664673, "action": -1.053120732307434}
{"mode": "train", "epochs": 8, "timestep": 15904, "ep_reward": 1071.28857421875, "reward": 0.05938225984573364, "action": -0.47317075729370117}
{"mode": "train", "epochs": 8, "timestep": 15905, "ep_reward": 1071.4915771484375, "reward": 0.20295023918151855, "action": -0.908014178276062}
{"mode": "train", "epochs": 8, "timestep": 15906, "ep_reward": 1071.8345947265625, "reward": 0.3430684208869934, "action": -0.609036922454834}
{"mode": "train", "epochs": 8, "timestep": 15907, "ep_reward": 1072.314697265625, "reward": 0.4801466464996338, "action": -0.7554621696472168}
{"mode": "train", "epochs": 8, "timestep": 15908, "ep_reward": 1072.9136962890625, "reward": 0.5990476608276367, "action": -1.7635470628738403}
{"mode": "train", "epochs": 8, "timestep": 15909, "ep_reward": 1073.6005859375, "reward": 0.6868516206741333, "action": -1.4905531406402588}
{"mode": "train", "epochs": 8, "timestep": 15910, "ep_reward": 1074.357421875, "reward": 0.7568828463554382, "action": -1.8466253280639648}
{"mode": "train", "epochs": 8, "timestep": 15911, "ep_reward": 1075.160888671875, "reward": 0.8034662008285522, "action": -0.6481360197067261}
{"mode": "train", "epochs": 8, "timestep": 15912, "ep_reward": 1076.0025634765625, "reward": 0.8416312336921692, "action": -1.2585349082946777}
{"mode": "train", "epochs": 8, "timestep": 15913, "ep_reward": 1076.8590087890625, "reward": 0.8564260601997375, "action": -0.11295074224472046}
{"mode": "train", "epochs": 8, "timestep": 15914, "ep_reward": 1077.722900390625, "reward": 0.8639376163482666, "action": -0.8178030848503113}
{"mode": "train", "epochs": 8, "timestep": 15915, "ep_reward": 1078.5706787109375, "reward": 0.8477582335472107, "action": -1.1993261575698853}
{"mode": "train", "epochs": 8, "timestep": 15916, "ep_reward": 1079.378173828125, "reward": 0.807464599609375, "action": -1.0901312828063965}
{"mode": "train", "epochs": 8, "timestep": 15917, "ep_reward": 1080.1199951171875, "reward": 0.7418457269668579, "action": -1.4331368207931519}
{"mode": "train", "epochs": 8, "timestep": 15918, "ep_reward": 1080.7584228515625, "reward": 0.6383854150772095, "action": -1.6804242134094238}
{"mode": "train", "epochs": 8, "timestep": 15919, "ep_reward": 1081.2476806640625, "reward": 0.4892536997795105, "action": -1.016727328300476}
{"mode": "train", "epochs": 8, "timestep": 15920, "ep_reward": 1081.6046142578125, "reward": 0.35698240995407104, "action": 0.008190274238586426}
{"mode": "train", "epochs": 8, "timestep": 15921, "ep_reward": 1081.8529052734375, "reward": 0.24823665618896484, "action": -1.5221996307373047}
{"mode": "train", "epochs": 8, "timestep": 15922, "ep_reward": 1081.9725341796875, "reward": 0.11967891454696655, "action": -1.2606430053710938}
{"mode": "train", "epochs": 8, "timestep": 15923, "ep_reward": 1081.967529296875, "reward": -0.005008578300476074, "action": -0.5699305534362793}
{"mode": "train", "epochs": 8, "timestep": 15924, "ep_reward": 1082.1080322265625, "reward": 0.14045053720474243, "action": -1.449958324432373}
{"mode": "train", "epochs": 8, "timestep": 15925, "ep_reward": 1082.3822021484375, "reward": 0.27417099475860596, "action": -1.064415454864502}
{"mode": "train", "epochs": 8, "timestep": 15926, "ep_reward": 1082.7940673828125, "reward": 0.4119073152542114, "action": -0.16263806819915771}
{"mode": "train", "epochs": 8, "timestep": 15927, "ep_reward": 1083.342041015625, "reward": 0.5479319095611572, "action": -1.5066616535186768}
{"mode": "train", "epochs": 8, "timestep": 15928, "ep_reward": 1083.989990234375, "reward": 0.6479203701019287, "action": -0.9641734957695007}
{"mode": "train", "epochs": 8, "timestep": 15929, "ep_reward": 1084.721923828125, "reward": 0.7318993210792542, "action": -1.8957600593566895}
{"mode": "train", "epochs": 8, "timestep": 15930, "ep_reward": 1085.5068359375, "reward": 0.7849116325378418, "action": -1.9716691970825195}
{"mode": "train", "epochs": 8, "timestep": 15931, "ep_reward": 1086.324462890625, "reward": 0.8176568746566772, "action": -1.8874447345733643}
{"mode": "train", "epochs": 8, "timestep": 15932, "ep_reward": 1087.1566162109375, "reward": 0.8321181535720825, "action": -1.30028235912323}
{"mode": "train", "epochs": 8, "timestep": 15933, "ep_reward": 1087.9888916015625, "reward": 0.8322583436965942, "action": -0.6549440026283264}
{"mode": "train", "epochs": 8, "timestep": 15934, "ep_reward": 1088.80615234375, "reward": 0.8172624111175537, "action": -1.1914935111999512}
{"mode": "train", "epochs": 8, "timestep": 15935, "ep_reward": 1089.5787353515625, "reward": 0.7725719213485718, "action": -0.4528743624687195}
{"mode": "train", "epochs": 8, "timestep": 15936, "ep_reward": 1090.2850341796875, "reward": 0.706345796585083, "action": -1.1968636512756348}
{"mode": "train", "epochs": 8, "timestep": 15937, "ep_reward": 1090.880126953125, "reward": 0.5951130986213684, "action": -0.955417275428772}
{"mode": "train", "epochs": 8, "timestep": 15938, "ep_reward": 1091.32421875, "reward": 0.444055438041687, "action": -1.0884226560592651}
{"mode": "train", "epochs": 8, "timestep": 15939, "ep_reward": 1091.6605224609375, "reward": 0.3362535834312439, "action": -0.772604763507843}
{"mode": "train", "epochs": 8, "timestep": 15940, "ep_reward": 1091.884033203125, "reward": 0.22351813316345215, "action": -0.9805501699447632}
{"mode": "train", "epochs": 8, "timestep": 15941, "ep_reward": 1091.9747314453125, "reward": 0.09072297811508179, "action": -1.4967591762542725}
{"mode": "train", "epochs": 8, "timestep": 15942, "ep_reward": 1092.0010986328125, "reward": 0.026413559913635254, "action": -1.579585075378418}
{"mode": "train", "epochs": 8, "timestep": 15943, "ep_reward": 1092.1690673828125, "reward": 0.16796565055847168, "action": -0.9984865188598633}
{"mode": "train", "epochs": 8, "timestep": 15944, "ep_reward": 1092.4769287109375, "reward": 0.3078640103340149, "action": -1.1276817321777344}
{"mode": "train", "epochs": 8, "timestep": 15945, "ep_reward": 1092.9190673828125, "reward": 0.442171573638916, "action": -0.9408242106437683}
{"mode": "train", "epochs": 8, "timestep": 15946, "ep_reward": 1093.484375, "reward": 0.5652825236320496, "action": -0.45106756687164307}
{"mode": "train", "epochs": 8, "timestep": 15947, "ep_reward": 1094.1572265625, "reward": 0.6728386878967285, "action": -0.8973177671432495}
{"mode": "train", "epochs": 8, "timestep": 15948, "ep_reward": 1094.9093017578125, "reward": 0.7520864009857178, "action": -0.8128691911697388}
{"mode": "train", "epochs": 8, "timestep": 15949, "ep_reward": 1095.7196044921875, "reward": 0.8103129267692566, "action": -1.242835521697998}
{"mode": "train", "epochs": 8, "timestep": 15950, "ep_reward": 1096.565185546875, "reward": 0.8455750346183777, "action": -1.4536503553390503}
{"mode": "train", "epochs": 8, "timestep": 15951, "ep_reward": 1097.427490234375, "reward": 0.8622565269470215, "action": -1.7489314079284668}
{"mode": "train", "epochs": 8, "timestep": 15952, "ep_reward": 1098.28759765625, "reward": 0.8601596355438232, "action": -1.5585665702819824}
{"mode": "train", "epochs": 8, "timestep": 15953, "ep_reward": 1099.1292724609375, "reward": 0.8416931629180908, "action": -0.3966381549835205}
{"mode": "train", "epochs": 8, "timestep": 15954, "ep_reward": 1099.9423828125, "reward": 0.8131610155105591, "action": -1.0415854454040527}
{"mode": "train", "epochs": 8, "timestep": 15955, "ep_reward": 1100.69580078125, "reward": 0.7534046173095703, "action": -0.6793151497840881}
{"mode": "train", "epochs": 8, "timestep": 15956, "ep_reward": 1101.3619384765625, "reward": 0.6661388874053955, "action": -1.6427329778671265}
{"mode": "train", "epochs": 8, "timestep": 15957, "ep_reward": 1101.8896484375, "reward": 0.5276516675949097, "action": -0.8610108494758606}
{"mode": "train", "epochs": 8, "timestep": 15958, "ep_reward": 1102.2666015625, "reward": 0.3769957423210144, "action": -0.9035382866859436}
{"mode": "train", "epochs": 8, "timestep": 15959, "ep_reward": 1102.5390625, "reward": 0.2725116014480591, "action": -1.2155553102493286}
{"mode": "train", "epochs": 8, "timestep": 15960, "ep_reward": 1102.687255859375, "reward": 0.14813709259033203, "action": -0.5872794389724731}
{"mode": "train", "epochs": 8, "timestep": 15961, "ep_reward": 1102.69091796875, "reward": 0.003621339797973633, "action": -1.1974698305130005}
{"mode": "train", "epochs": 8, "timestep": 15962, "ep_reward": 1102.802734375, "reward": 0.11182135343551636, "action": -1.5326361656188965}
{"mode": "train", "epochs": 8, "timestep": 15963, "ep_reward": 1103.0465087890625, "reward": 0.24381911754608154, "action": 0.5788981914520264}
{"mode": "train", "epochs": 8, "timestep": 15964, "ep_reward": 1103.449462890625, "reward": 0.40297436714172363, "action": -0.5839537382125854}
{"mode": "train", "epochs": 8, "timestep": 15965, "ep_reward": 1103.983154296875, "reward": 0.5336599349975586, "action": -0.9891123175621033}
{"mode": "train", "epochs": 8, "timestep": 15966, "ep_reward": 1104.6243896484375, "reward": 0.6412493586540222, "action": -1.9492459297180176}
{"mode": "train", "epochs": 8, "timestep": 15967, "ep_reward": 1105.3431396484375, "reward": 0.7187315225601196, "action": -1.930540680885315}
{"mode": "train", "epochs": 8, "timestep": 15968, "ep_reward": 1106.1202392578125, "reward": 0.7771399617195129, "action": -0.6363949775695801}
{"mode": "train", "epochs": 8, "timestep": 15969, "ep_reward": 1106.947998046875, "reward": 0.8277899622917175, "action": -0.6551312208175659}
{"mode": "train", "epochs": 8, "timestep": 15970, "ep_reward": 1107.8074951171875, "reward": 0.8594595193862915, "action": -0.7810385227203369}
{"mode": "train", "epochs": 8, "timestep": 15971, "ep_reward": 1108.6810302734375, "reward": 0.8735110759735107, "action": -1.689894199371338}
{"mode": "train", "epochs": 8, "timestep": 15972, "ep_reward": 1109.54541015625, "reward": 0.8644164800643921, "action": -0.6838442087173462}
{"mode": "train", "epochs": 8, "timestep": 15973, "ep_reward": 1110.3917236328125, "reward": 0.8463045358657837, "action": -0.7976688146591187}
{"mode": "train", "epochs": 8, "timestep": 15974, "ep_reward": 1111.198486328125, "reward": 0.8067314624786377, "action": -0.5673385262489319}
{"mode": "train", "epochs": 8, "timestep": 15975, "ep_reward": 1111.942626953125, "reward": 0.7441211938858032, "action": -1.4382392168045044}
{"mode": "train", "epochs": 8, "timestep": 15976, "ep_reward": 1112.581787109375, "reward": 0.6392139196395874, "action": -0.6676255464553833}
{"mode": "train", "epochs": 8, "timestep": 15977, "ep_reward": 1113.086181640625, "reward": 0.5044262409210205, "action": -1.8677884340286255}
{"mode": "train", "epochs": 8, "timestep": 15978, "ep_reward": 1113.4376220703125, "reward": 0.35140150785446167, "action": -0.49264460802078247}
{"mode": "train", "epochs": 8, "timestep": 15979, "ep_reward": 1113.67919921875, "reward": 0.2415449619293213, "action": -1.5392515659332275}
{"mode": "train", "epochs": 8, "timestep": 15980, "ep_reward": 1113.7911376953125, "reward": 0.11193382740020752, "action": 0.7289869785308838}
{"mode": "train", "epochs": 8, "timestep": 15981, "ep_reward": 1113.7947998046875, "reward": 0.0037047863006591797, "action": -0.34453922510147095}
{"mode": "train", "epochs": 8, "timestep": 15982, "ep_reward": 1113.94287109375, "reward": 0.1480867862701416, "action": -1.0803436040878296}
{"mode": "train", "epochs": 8, "timestep": 15983, "ep_reward": 1114.2294921875, "reward": 0.28664350509643555, "action": -0.5622790455818176}
{"mode": "train", "epochs": 8, "timestep": 15984, "ep_reward": 1114.6585693359375, "reward": 0.42906343936920166, "action": -0.08965599536895752}
{"mode": "train", "epochs": 8, "timestep": 15985, "ep_reward": 1115.221435546875, "reward": 0.5628141164779663, "action": -1.2628532648086548}
{"mode": "train", "epochs": 8, "timestep": 15986, "ep_reward": 1115.8841552734375, "reward": 0.6626780033111572, "action": -1.0816165208816528}
{"mode": "train", "epochs": 8, "timestep": 15987, "ep_reward": 1116.62744140625, "reward": 0.743303656578064, "action": -1.1185909509658813}
{"mode": "train", "epochs": 8, "timestep": 15988, "ep_reward": 1117.4300537109375, "reward": 0.8025663495063782, "action": -1.1078863143920898}
{"mode": "train", "epochs": 8, "timestep": 15989, "ep_reward": 1118.2730712890625, "reward": 0.8429950475692749, "action": -0.8278918862342834}
{"mode": "train", "epochs": 8, "timestep": 15990, "ep_reward": 1119.1419677734375, "reward": 0.8689042329788208, "action": -0.4100486636161804}
{"mode": "train", "epochs": 8, "timestep": 15991, "ep_reward": 1120.0245361328125, "reward": 0.8826022148132324, "action": -1.719667673110962}
{"mode": "train", "epochs": 8, "timestep": 15992, "ep_reward": 1120.8953857421875, "reward": 0.8709002733230591, "action": -1.5558710098266602}
{"mode": "train", "epochs": 8, "timestep": 15993, "ep_reward": 1121.73828125, "reward": 0.8429539799690247, "action": -0.8331296443939209}
{"mode": "train", "epochs": 8, "timestep": 15994, "ep_reward": 1122.538330078125, "reward": 0.8000378608703613, "action": -0.8877585530281067}
{"mode": "train", "epochs": 8, "timestep": 15995, "ep_reward": 1123.2684326171875, "reward": 0.7300582528114319, "action": -0.7391329407691956}
{"mode": "train", "epochs": 8, "timestep": 15996, "ep_reward": 1123.897216796875, "reward": 0.6287652254104614, "action": -0.9080331325531006}
{"mode": "train", "epochs": 8, "timestep": 15997, "ep_reward": 1124.3836669921875, "reward": 0.48650622367858887, "action": -0.5820434093475342}
{"mode": "train", "epochs": 8, "timestep": 15998, "ep_reward": 1124.72265625, "reward": 0.33898401260375977, "action": -1.2071729898452759}
{"mode": "train", "epochs": 8, "timestep": 15999, "ep_reward": 1124.949462890625, "reward": 0.22674572467803955, "action": -1.601564645767212}
{"mode": "train", "epochs": 8, "timestep": 16000, "ep_reward": 1125.0440673828125, "reward": 0.09465664625167847, "action": -1.1163702011108398}
{"mode": "train", "epochs": 9, "timestep": 16001, "ep_reward": 0.9962973594665527, "reward": 0.9962973594665527, "action": 1.593435287475586}
{"mode": "train", "epochs": 9, "timestep": 16002, "ep_reward": 1.988978624343872, "reward": 0.9926812648773193, "action": 0.9484609961509705}
{"mode": "train", "epochs": 9, "timestep": 16003, "ep_reward": 2.976132392883301, "reward": 0.9871537089347839, "action": 1.1004221439361572}
{"mode": "train", "epochs": 9, "timestep": 16004, "ep_reward": 3.9541850090026855, "reward": 0.9780526757240295, "action": 0.20335179567337036}
{"mode": "train", "epochs": 9, "timestep": 16005, "ep_reward": 4.921350479125977, "reward": 0.9671652913093567, "action": 1.655107021331787}
{"mode": "train", "epochs": 9, "timestep": 16006, "ep_reward": 5.866132736206055, "reward": 0.9447821974754333, "action": -0.259727418422699}
{"mode": "train", "epochs": 9, "timestep": 16007, "ep_reward": 6.788198471069336, "reward": 0.922065794467926, "action": 0.1639174222946167}
{"mode": "train", "epochs": 9, "timestep": 16008, "ep_reward": 7.675008773803711, "reward": 0.8868103623390198, "action": -0.5706772804260254}
{"mode": "train", "epochs": 9, "timestep": 16009, "ep_reward": 8.517955780029297, "reward": 0.8429473638534546, "action": -0.653306245803833}
{"mode": "train", "epochs": 9, "timestep": 16010, "ep_reward": 9.301763534545898, "reward": 0.7838079929351807, "action": -0.9711053371429443}
{"mode": "train", "epochs": 9, "timestep": 16011, "ep_reward": 10.010638236999512, "reward": 0.7088744044303894, "action": -0.46229130029678345}
{"mode": "train", "epochs": 9, "timestep": 16012, "ep_reward": 10.618001937866211, "reward": 0.6073633432388306, "action": -1.7781343460083008}
{"mode": "train", "epochs": 9, "timestep": 16013, "ep_reward": 11.11911678314209, "reward": 0.5011152029037476, "action": -1.5931780338287354}
{"mode": "train", "epochs": 9, "timestep": 16014, "ep_reward": 11.498333930969238, "reward": 0.37921756505966187, "action": -0.7674672603607178}
{"mode": "train", "epochs": 9, "timestep": 16015, "ep_reward": 11.736356735229492, "reward": 0.23802292346954346, "action": -0.8457744121551514}
{"mode": "train", "epochs": 9, "timestep": 16016, "ep_reward": 11.833907127380371, "reward": 0.09755033254623413, "action": -1.1112899780273438}
{"mode": "train", "epochs": 9, "timestep": 16017, "ep_reward": 12.039814949035645, "reward": 0.20590758323669434, "action": -1.011227011680603}
{"mode": "train", "epochs": 9, "timestep": 16018, "ep_reward": 12.384431838989258, "reward": 0.3446171283721924, "action": -0.19109219312667847}
{"mode": "train", "epochs": 9, "timestep": 16019, "ep_reward": 12.85344123840332, "reward": 0.46900951862335205, "action": -1.1091382503509521}
{"mode": "train", "epochs": 9, "timestep": 16020, "ep_reward": 13.443806648254395, "reward": 0.5903656482696533, "action": -0.06432074308395386}
{"mode": "train", "epochs": 9, "timestep": 16021, "ep_reward": 14.12874984741211, "reward": 0.6849430799484253, "action": 0.9904799461364746}
{"mode": "train", "epochs": 9, "timestep": 16022, "ep_reward": 14.884810447692871, "reward": 0.7560603022575378, "action": 0.8275110125541687}
{"mode": "train", "epochs": 9, "timestep": 16023, "ep_reward": 15.698945999145508, "reward": 0.8141356706619263, "action": 0.5608073472976685}
{"mode": "train", "epochs": 9, "timestep": 16024, "ep_reward": 16.558612823486328, "reward": 0.8596676588058472, "action": 1.5086991786956787}
{"mode": "train", "epochs": 9, "timestep": 16025, "ep_reward": 17.44882583618164, "reward": 0.8902126550674438, "action": 0.8912975192070007}
{"mode": "train", "epochs": 9, "timestep": 16026, "ep_reward": 18.362751007080078, "reward": 0.9139245748519897, "action": 1.4311699867248535}
{"mode": "train", "epochs": 9, "timestep": 16027, "ep_reward": 19.291763305664062, "reward": 0.9290114641189575, "action": 1.124618411064148}
{"mode": "train", "epochs": 9, "timestep": 16028, "ep_reward": 20.23044204711914, "reward": 0.938677966594696, "action": 1.1024502515792847}
{"mode": "train", "epochs": 9, "timestep": 16029, "ep_reward": 21.1733455657959, "reward": 0.9429039359092712, "action": 0.09334725141525269}
{"mode": "train", "epochs": 9, "timestep": 16030, "ep_reward": 22.11360740661621, "reward": 0.9402625560760498, "action": 1.5956135988235474}
{"mode": "train", "epochs": 9, "timestep": 16031, "ep_reward": 23.046932220458984, "reward": 0.9333255887031555, "action": 0.7508589625358582}
{"mode": "train", "epochs": 9, "timestep": 16032, "ep_reward": 23.96564483642578, "reward": 0.9187129139900208, "action": 1.2206368446350098}
{"mode": "train", "epochs": 9, "timestep": 16033, "ep_reward": 24.863540649414062, "reward": 0.897895097732544, "action": 1.2788820266723633}
{"mode": "train", "epochs": 9, "timestep": 16034, "ep_reward": 25.732412338256836, "reward": 0.8688717484474182, "action": 1.5516431331634521}
{"mode": "train", "epochs": 9, "timestep": 16035, "ep_reward": 26.563833236694336, "reward": 0.8314212560653687, "action": 1.9353013038635254}
{"mode": "train", "epochs": 9, "timestep": 16036, "ep_reward": 27.349796295166016, "reward": 0.7859631776809692, "action": 1.4207396507263184}
{"mode": "train", "epochs": 9, "timestep": 16037, "ep_reward": 28.07488250732422, "reward": 0.7250867486000061, "action": -0.37727081775665283}
{"mode": "train", "epochs": 9, "timestep": 16038, "ep_reward": 28.707347869873047, "reward": 0.6324660778045654, "action": -0.6575363874435425}
{"mode": "train", "epochs": 9, "timestep": 16039, "ep_reward": 29.22243881225586, "reward": 0.5150910019874573, "action": -0.5376046299934387}
{"mode": "train", "epochs": 9, "timestep": 16040, "ep_reward": 29.60173988342285, "reward": 0.3793003559112549, "action": -1.6589387655258179}
{"mode": "train", "epochs": 9, "timestep": 16041, "ep_reward": 29.81610870361328, "reward": 0.214369535446167, "action": -0.8629521131515503}
{"mode": "train", "epochs": 9, "timestep": 16042, "ep_reward": 29.921815872192383, "reward": 0.10570663213729858, "action": -0.5832862854003906}
{"mode": "train", "epochs": 9, "timestep": 16043, "ep_reward": 30.151037216186523, "reward": 0.22922128438949585, "action": -1.50895094871521}
{"mode": "train", "epochs": 9, "timestep": 16044, "ep_reward": 30.49738121032715, "reward": 0.34634387493133545, "action": -1.7545530796051025}
{"mode": "train", "epochs": 9, "timestep": 16045, "ep_reward": 30.957782745361328, "reward": 0.46040135622024536, "action": -0.6941927671432495}
{"mode": "train", "epochs": 9, "timestep": 16046, "ep_reward": 31.535383224487305, "reward": 0.5775997042655945, "action": -0.834994375705719}
{"mode": "train", "epochs": 9, "timestep": 16047, "ep_reward": 32.212520599365234, "reward": 0.6771386861801147, "action": -0.9249006509780884}
{"mode": "train", "epochs": 9, "timestep": 16048, "ep_reward": 32.9700927734375, "reward": 0.7575740218162537, "action": -0.6003086566925049}
{"mode": "train", "epochs": 9, "timestep": 16049, "ep_reward": 33.79245376586914, "reward": 0.8223611116409302, "action": -1.5886523723602295}
{"mode": "train", "epochs": 9, "timestep": 16050, "ep_reward": 34.656982421875, "reward": 0.8645282983779907, "action": -1.7925575971603394}
{"mode": "train", "epochs": 9, "timestep": 16051, "ep_reward": 35.5508918762207, "reward": 0.8939082026481628, "action": -0.2220563292503357}
{"mode": "train", "epochs": 9, "timestep": 16052, "ep_reward": 36.47311782836914, "reward": 0.9222277402877808, "action": -1.5407792329788208}
{"mode": "train", "epochs": 9, "timestep": 16053, "ep_reward": 37.40745544433594, "reward": 0.9343366622924805, "action": -0.750043511390686}
{"mode": "train", "epochs": 9, "timestep": 16054, "ep_reward": 38.35100173950195, "reward": 0.9435469508171082, "action": -0.66712486743927}
{"mode": "train", "epochs": 9, "timestep": 16055, "ep_reward": 39.29740905761719, "reward": 0.9464077353477478, "action": -0.6973960399627686}
{"mode": "train", "epochs": 9, "timestep": 16056, "ep_reward": 40.23973846435547, "reward": 0.9423292279243469, "action": -0.6201784610748291}
{"mode": "train", "epochs": 9, "timestep": 16057, "ep_reward": 41.17072677612305, "reward": 0.9309865236282349, "action": -0.9376816153526306}
{"mode": "train", "epochs": 9, "timestep": 16058, "ep_reward": 42.0785026550293, "reward": 0.9077773094177246, "action": -1.717792272567749}
{"mode": "train", "epochs": 9, "timestep": 16059, "ep_reward": 42.94327163696289, "reward": 0.8647674918174744, "action": -1.3821736574172974}
{"mode": "train", "epochs": 9, "timestep": 16060, "ep_reward": 43.74679183959961, "reward": 0.8035193681716919, "action": -0.02790600061416626}
{"mode": "train", "epochs": 9, "timestep": 16061, "ep_reward": 44.47682189941406, "reward": 0.7300311923027039, "action": -1.1706249713897705}
{"mode": "train", "epochs": 9, "timestep": 16062, "ep_reward": 45.090965270996094, "reward": 0.6141420006752014, "action": -0.7731525301933289}
{"mode": "train", "epochs": 9, "timestep": 16063, "ep_reward": 45.55802917480469, "reward": 0.4670630693435669, "action": -0.5325453877449036}
{"mode": "train", "epochs": 9, "timestep": 16064, "ep_reward": 45.847843170166016, "reward": 0.28981393575668335, "action": -0.8497132658958435}
{"mode": "train", "epochs": 9, "timestep": 16065, "ep_reward": 46.009544372558594, "reward": 0.16170233488082886, "action": 0.5694959163665771}
{"mode": "train", "epochs": 9, "timestep": 16066, "ep_reward": 46.0286865234375, "reward": 0.01914215087890625, "action": -1.674973487854004}
{"mode": "train", "epochs": 9, "timestep": 16067, "ep_reward": 46.12614822387695, "reward": 0.09746289253234863, "action": -1.7005326747894287}
{"mode": "train", "epochs": 9, "timestep": 16068, "ep_reward": 46.355499267578125, "reward": 0.22935110330581665, "action": -0.8630979657173157}
{"mode": "train", "epochs": 9, "timestep": 16069, "ep_reward": 46.72700119018555, "reward": 0.37150096893310547, "action": -0.675728440284729}
{"mode": "train", "epochs": 9, "timestep": 16070, "ep_reward": 47.233154296875, "reward": 0.5061520934104919, "action": -1.7815083265304565}
{"mode": "train", "epochs": 9, "timestep": 16071, "ep_reward": 47.84339904785156, "reward": 0.6102449893951416, "action": -1.6209795475006104}
{"mode": "train", "epochs": 9, "timestep": 16072, "ep_reward": 48.53926086425781, "reward": 0.6958632469177246, "action": -0.9646226763725281}
{"mode": "train", "epochs": 9, "timestep": 16073, "ep_reward": 49.30488586425781, "reward": 0.7656255960464478, "action": 0.06276345252990723}
{"mode": "train", "epochs": 9, "timestep": 16074, "ep_reward": 50.12710189819336, "reward": 0.8222149610519409, "action": -1.1276832818984985}
{"mode": "train", "epochs": 9, "timestep": 16075, "ep_reward": 50.974788665771484, "reward": 0.8476862907409668, "action": -0.6295228004455566}
{"mode": "train", "epochs": 9, "timestep": 16076, "ep_reward": 51.834495544433594, "reward": 0.8597067594528198, "action": -1.2535513639450073}
{"mode": "train", "epochs": 9, "timestep": 16077, "ep_reward": 52.68286895751953, "reward": 0.8483752012252808, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 16078, "ep_reward": 53.49227523803711, "reward": 0.809407114982605, "action": -0.4427867531776428}
{"mode": "train", "epochs": 9, "timestep": 16079, "ep_reward": 54.2524299621582, "reward": 0.7601556181907654, "action": -1.3632627725601196}
{"mode": "train", "epochs": 9, "timestep": 16080, "ep_reward": 54.9218864440918, "reward": 0.6694555282592773, "action": -0.9700011610984802}
{"mode": "train", "epochs": 9, "timestep": 16081, "ep_reward": 55.46603775024414, "reward": 0.544151782989502, "action": -1.7205438613891602}
{"mode": "train", "epochs": 9, "timestep": 16082, "ep_reward": 55.85666275024414, "reward": 0.3906257152557373, "action": -0.9168445467948914}
{"mode": "train", "epochs": 9, "timestep": 16083, "ep_reward": 56.14569854736328, "reward": 0.28903669118881226, "action": -1.487189531326294}
{"mode": "train", "epochs": 9, "timestep": 16084, "ep_reward": 56.31330490112305, "reward": 0.1676068902015686, "action": -1.0179275274276733}
{"mode": "train", "epochs": 9, "timestep": 16085, "ep_reward": 56.339454650878906, "reward": 0.026151061058044434, "action": -0.5281463861465454}
{"mode": "train", "epochs": 9, "timestep": 16086, "ep_reward": 56.4306526184082, "reward": 0.0911981463432312, "action": -0.735657811164856}
{"mode": "train", "epochs": 9, "timestep": 16087, "ep_reward": 56.66313934326172, "reward": 0.23248547315597534, "action": -0.9534852504730225}
{"mode": "train", "epochs": 9, "timestep": 16088, "ep_reward": 57.03486633300781, "reward": 0.3717283606529236, "action": -1.007490634918213}
{"mode": "train", "epochs": 9, "timestep": 16089, "ep_reward": 57.53656005859375, "reward": 0.5016936659812927, "action": -1.677370309829712}
{"mode": "train", "epochs": 9, "timestep": 16090, "ep_reward": 58.144256591796875, "reward": 0.6076956987380981, "action": -1.031480073928833}
{"mode": "train", "epochs": 9, "timestep": 16091, "ep_reward": 58.844547271728516, "reward": 0.7002913951873779, "action": -1.0329500436782837}
{"mode": "train", "epochs": 9, "timestep": 16092, "ep_reward": 59.61454772949219, "reward": 0.7699992656707764, "action": -0.7942425608634949}
{"mode": "train", "epochs": 9, "timestep": 16093, "ep_reward": 60.434837341308594, "reward": 0.8202905654907227, "action": -1.6269199848175049}
{"mode": "train", "epochs": 9, "timestep": 16094, "ep_reward": 61.279075622558594, "reward": 0.8442373275756836, "action": -0.7964094281196594}
{"mode": "train", "epochs": 9, "timestep": 16095, "ep_reward": 62.1368408203125, "reward": 0.8577667474746704, "action": -1.4204765558242798}
{"mode": "train", "epochs": 9, "timestep": 16096, "ep_reward": 62.984947204589844, "reward": 0.8481050729751587, "action": -0.678044319152832}
{"mode": "train", "epochs": 9, "timestep": 16097, "ep_reward": 63.81040954589844, "reward": 0.8254620432853699, "action": -0.13017165660858154}
{"mode": "train", "epochs": 9, "timestep": 16098, "ep_reward": 64.59618377685547, "reward": 0.7857739925384521, "action": -0.6378572583198547}
{"mode": "train", "epochs": 9, "timestep": 16099, "ep_reward": 65.30988311767578, "reward": 0.7137007117271423, "action": -1.1195869445800781}
{"mode": "train", "epochs": 9, "timestep": 16100, "ep_reward": 65.91116333007812, "reward": 0.6012774705886841, "action": -0.5173120498657227}
{"mode": "train", "epochs": 9, "timestep": 16101, "ep_reward": 66.36783599853516, "reward": 0.4566692113876343, "action": -1.6576685905456543}
{"mode": "train", "epochs": 9, "timestep": 16102, "ep_reward": 66.69110870361328, "reward": 0.323276162147522, "action": -1.0462805032730103}
{"mode": "train", "epochs": 9, "timestep": 16103, "ep_reward": 66.8990478515625, "reward": 0.2079371213912964, "action": -1.8393630981445312}
{"mode": "train", "epochs": 9, "timestep": 16104, "ep_reward": 66.97180938720703, "reward": 0.07276427745819092, "action": -1.736410140991211}
{"mode": "train", "epochs": 9, "timestep": 16105, "ep_reward": 67.01702880859375, "reward": 0.045220255851745605, "action": -0.6751817464828491}
{"mode": "train", "epochs": 9, "timestep": 16106, "ep_reward": 67.20282745361328, "reward": 0.1857951283454895, "action": -1.1759730577468872}
{"mode": "train", "epochs": 9, "timestep": 16107, "ep_reward": 67.52632141113281, "reward": 0.3234931230545044, "action": -0.1851823925971985}
{"mode": "train", "epochs": 9, "timestep": 16108, "ep_reward": 67.99440002441406, "reward": 0.4680808186531067, "action": -0.038976430892944336}
{"mode": "train", "epochs": 9, "timestep": 16109, "ep_reward": 68.59099578857422, "reward": 0.596598744392395, "action": -1.6671454906463623}
{"mode": "train", "epochs": 9, "timestep": 16110, "ep_reward": 69.27692413330078, "reward": 0.6859266757965088, "action": -1.9881222248077393}
{"mode": "train", "epochs": 9, "timestep": 16111, "ep_reward": 70.0294189453125, "reward": 0.7524911165237427, "action": -0.9119517803192139}
{"mode": "train", "epochs": 9, "timestep": 16112, "ep_reward": 70.83855438232422, "reward": 0.8091338276863098, "action": -1.505268931388855}
{"mode": "train", "epochs": 9, "timestep": 16113, "ep_reward": 71.68001556396484, "reward": 0.8414597511291504, "action": -0.7433285713195801}
{"mode": "train", "epochs": 9, "timestep": 16114, "ep_reward": 72.54301452636719, "reward": 0.8629991412162781, "action": -1.3366347551345825}
{"mode": "train", "epochs": 9, "timestep": 16115, "ep_reward": 73.40589904785156, "reward": 0.8628811836242676, "action": -1.6374421119689941}
{"mode": "train", "epochs": 9, "timestep": 16116, "ep_reward": 74.24829864501953, "reward": 0.8423984050750732, "action": -0.09700000286102295}
{"mode": "train", "epochs": 9, "timestep": 16117, "ep_reward": 75.06371307373047, "reward": 0.8154131174087524, "action": -1.8477001190185547}
{"mode": "train", "epochs": 9, "timestep": 16118, "ep_reward": 75.80934143066406, "reward": 0.7456260919570923, "action": -1.6036187410354614}
{"mode": "train", "epochs": 9, "timestep": 16119, "ep_reward": 76.45270538330078, "reward": 0.6433635950088501, "action": -1.315759301185608}
{"mode": "train", "epochs": 9, "timestep": 16120, "ep_reward": 76.9552230834961, "reward": 0.5025181770324707, "action": -1.9145829677581787}
{"mode": "train", "epochs": 9, "timestep": 16121, "ep_reward": 77.32262420654297, "reward": 0.3674023747444153, "action": -0.871812105178833}
{"mode": "train", "epochs": 9, "timestep": 16122, "ep_reward": 77.58351135253906, "reward": 0.26088887453079224, "action": -1.351400375366211}
{"mode": "train", "epochs": 9, "timestep": 16123, "ep_reward": 77.71800994873047, "reward": 0.13450217247009277, "action": -0.9307774305343628}
{"mode": "train", "epochs": 9, "timestep": 16124, "ep_reward": 77.70609283447266, "reward": -0.011920332908630371, "action": -0.692295491695404}
{"mode": "train", "epochs": 9, "timestep": 16125, "ep_reward": 77.83184051513672, "reward": 0.12574774026870728, "action": -1.4656591415405273}
{"mode": "train", "epochs": 9, "timestep": 16126, "ep_reward": 78.09074401855469, "reward": 0.25890570878982544, "action": -1.0905295610427856}
{"mode": "train", "epochs": 9, "timestep": 16127, "ep_reward": 78.48778533935547, "reward": 0.3970375657081604, "action": -0.43202292919158936}
{"mode": "train", "epochs": 9, "timestep": 16128, "ep_reward": 79.01966857910156, "reward": 0.5318828821182251, "action": -1.423721432685852}
{"mode": "train", "epochs": 9, "timestep": 16129, "ep_reward": 79.65528869628906, "reward": 0.635623574256897, "action": -0.5301353931427002}
{"mode": "train", "epochs": 9, "timestep": 16130, "ep_reward": 80.38191223144531, "reward": 0.726626992225647, "action": -1.7127678394317627}
{"mode": "train", "epochs": 9, "timestep": 16131, "ep_reward": 81.1652603149414, "reward": 0.7833470702171326, "action": -0.8618308305740356}
{"mode": "train", "epochs": 9, "timestep": 16132, "ep_reward": 81.99303436279297, "reward": 0.8277771472930908, "action": -1.6194424629211426}
{"mode": "train", "epochs": 9, "timestep": 16133, "ep_reward": 82.8398666381836, "reward": 0.8468305468559265, "action": -1.2186673879623413}
{"mode": "train", "epochs": 9, "timestep": 16134, "ep_reward": 83.69152069091797, "reward": 0.851654052734375, "action": -0.8858370780944824}
{"mode": "train", "epochs": 9, "timestep": 16135, "ep_reward": 84.5323715209961, "reward": 0.8408505320549011, "action": -0.21838468313217163}
{"mode": "train", "epochs": 9, "timestep": 16136, "ep_reward": 85.34806060791016, "reward": 0.8156893849372864, "action": -1.8169405460357666}
{"mode": "train", "epochs": 9, "timestep": 16137, "ep_reward": 86.0972900390625, "reward": 0.7492289543151855, "action": -1.4519479274749756}
{"mode": "train", "epochs": 9, "timestep": 16138, "ep_reward": 86.74959564208984, "reward": 0.652305006980896, "action": -1.2668930292129517}
{"mode": "train", "epochs": 9, "timestep": 16139, "ep_reward": 87.26602935791016, "reward": 0.5164358019828796, "action": -0.1488734483718872}
{"mode": "train", "epochs": 9, "timestep": 16140, "ep_reward": 87.64372253417969, "reward": 0.3776929974555969, "action": -1.4959946870803833}
{"mode": "train", "epochs": 9, "timestep": 16141, "ep_reward": 87.91722869873047, "reward": 0.27350914478302, "action": -0.9344344735145569}
{"mode": "train", "epochs": 9, "timestep": 16142, "ep_reward": 88.06649017333984, "reward": 0.14926278591156006, "action": -0.7150106430053711}
{"mode": "train", "epochs": 9, "timestep": 16143, "ep_reward": 88.0712661743164, "reward": 0.004775643348693848, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 16144, "ep_reward": 88.18182373046875, "reward": 0.11055940389633179, "action": -1.8303362131118774}
{"mode": "train", "epochs": 9, "timestep": 16145, "ep_reward": 88.42227935791016, "reward": 0.2404543161392212, "action": -1.8085845708847046}
{"mode": "train", "epochs": 9, "timestep": 16146, "ep_reward": 88.79301452636719, "reward": 0.37073183059692383, "action": -1.5891506671905518}
{"mode": "train", "epochs": 9, "timestep": 16147, "ep_reward": 89.28901672363281, "reward": 0.49600499868392944, "action": -0.6156036257743835}
{"mode": "train", "epochs": 9, "timestep": 16148, "ep_reward": 89.90388488769531, "reward": 0.6148691773414612, "action": -0.6909120678901672}
{"mode": "train", "epochs": 9, "timestep": 16149, "ep_reward": 90.6119155883789, "reward": 0.7080273628234863, "action": -0.46784210205078125}
{"mode": "train", "epochs": 9, "timestep": 16150, "ep_reward": 91.39028930664062, "reward": 0.7783769369125366, "action": -1.5060226917266846}
{"mode": "train", "epochs": 9, "timestep": 16151, "ep_reward": 92.20680236816406, "reward": 0.8165110349655151, "action": -1.2836631536483765}
{"mode": "train", "epochs": 9, "timestep": 16152, "ep_reward": 93.0438461303711, "reward": 0.8370475172996521, "action": -1.3539960384368896}
{"mode": "train", "epochs": 9, "timestep": 16153, "ep_reward": 93.88126373291016, "reward": 0.83741694688797, "action": -1.9559905529022217}
{"mode": "train", "epochs": 9, "timestep": 16154, "ep_reward": 94.692138671875, "reward": 0.8108742237091064, "action": -1.189591407775879}
{"mode": "train", "epochs": 9, "timestep": 16155, "ep_reward": 95.45829010009766, "reward": 0.7661503553390503, "action": -1.2825535535812378}
{"mode": "train", "epochs": 9, "timestep": 16156, "ep_reward": 96.14717102050781, "reward": 0.6888846755027771, "action": -0.3176141381263733}
{"mode": "train", "epochs": 9, "timestep": 16157, "ep_reward": 96.73328399658203, "reward": 0.5861148834228516, "action": -1.3004673719406128}
{"mode": "train", "epochs": 9, "timestep": 16158, "ep_reward": 97.16017150878906, "reward": 0.42688947916030884, "action": -1.3317327499389648}
{"mode": "train", "epochs": 9, "timestep": 16159, "ep_reward": 97.49217987060547, "reward": 0.3320092558860779, "action": -1.1427768468856812}
{"mode": "train", "epochs": 9, "timestep": 16160, "ep_reward": 97.71073150634766, "reward": 0.21855288743972778, "action": -0.5302435755729675}
{"mode": "train", "epochs": 9, "timestep": 16161, "ep_reward": 97.79570007324219, "reward": 0.08496886491775513, "action": -1.1393874883651733}
{"mode": "train", "epochs": 9, "timestep": 16162, "ep_reward": 97.82838439941406, "reward": 0.03268545866012573, "action": -0.4114316701889038}
{"mode": "train", "epochs": 9, "timestep": 16163, "ep_reward": 98.00443267822266, "reward": 0.17604798078536987, "action": -1.6827812194824219}
{"mode": "train", "epochs": 9, "timestep": 16164, "ep_reward": 98.3113784790039, "reward": 0.30694878101348877, "action": -1.3997291326522827}
{"mode": "train", "epochs": 9, "timestep": 16165, "ep_reward": 98.75011444091797, "reward": 0.43873852491378784, "action": -1.4114532470703125}
{"mode": "train", "epochs": 9, "timestep": 16166, "ep_reward": 99.30742645263672, "reward": 0.5573152303695679, "action": -1.4698712825775146}
{"mode": "train", "epochs": 9, "timestep": 16167, "ep_reward": 99.96273040771484, "reward": 0.6553035974502563, "action": -0.9005343317985535}
{"mode": "train", "epochs": 9, "timestep": 16168, "ep_reward": 100.6987075805664, "reward": 0.7359762787818909, "action": -1.5891823768615723}
{"mode": "train", "epochs": 9, "timestep": 16169, "ep_reward": 101.4850082397461, "reward": 0.7862977981567383, "action": -1.581984519958496}
{"mode": "train", "epochs": 9, "timestep": 16170, "ep_reward": 102.30043029785156, "reward": 0.8154250383377075, "action": -1.5111780166625977}
{"mode": "train", "epochs": 9, "timestep": 16171, "ep_reward": 103.12496185302734, "reward": 0.8245342373847961, "action": -0.5561912059783936}
{"mode": "train", "epochs": 9, "timestep": 16172, "ep_reward": 103.94632720947266, "reward": 0.8213646411895752, "action": -1.1220310926437378}
{"mode": "train", "epochs": 9, "timestep": 16173, "ep_reward": 104.73550415039062, "reward": 0.789180338382721, "action": -0.9755730628967285}
{"mode": "train", "epochs": 9, "timestep": 16174, "ep_reward": 105.46589660644531, "reward": 0.7303929328918457, "action": -0.619412899017334}
{"mode": "train", "epochs": 9, "timestep": 16175, "ep_reward": 106.10760498046875, "reward": 0.6417086124420166, "action": -1.5672448873519897}
{"mode": "train", "epochs": 9, "timestep": 16176, "ep_reward": 106.60662078857422, "reward": 0.49901336431503296, "action": -0.8996241688728333}
{"mode": "train", "epochs": 9, "timestep": 16177, "ep_reward": 106.9842529296875, "reward": 0.3776310682296753, "action": -1.025945782661438}
{"mode": "train", "epochs": 9, "timestep": 16178, "ep_reward": 107.25752258300781, "reward": 0.27327215671539307, "action": -1.421341896057129}
{"mode": "train", "epochs": 9, "timestep": 16179, "ep_reward": 107.40657043457031, "reward": 0.14905142784118652, "action": -0.8791075348854065}
{"mode": "train", "epochs": 9, "timestep": 16180, "ep_reward": 107.41133117675781, "reward": 0.004758596420288086, "action": -0.8231378793716431}
{"mode": "train", "epochs": 9, "timestep": 16181, "ep_reward": 107.52226257324219, "reward": 0.11093205213546753, "action": -0.8110368251800537}
{"mode": "train", "epochs": 9, "timestep": 16182, "ep_reward": 107.77408599853516, "reward": 0.25182586908340454, "action": -1.1397671699523926}
{"mode": "train", "epochs": 9, "timestep": 16183, "ep_reward": 108.16236877441406, "reward": 0.38828301429748535, "action": -1.0210254192352295}
{"mode": "train", "epochs": 9, "timestep": 16184, "ep_reward": 108.67918395996094, "reward": 0.5168160200119019, "action": -0.44421952962875366}
{"mode": "train", "epochs": 9, "timestep": 16185, "ep_reward": 109.31275177001953, "reward": 0.6335662603378296, "action": -0.8007328510284424}
{"mode": "train", "epochs": 9, "timestep": 16186, "ep_reward": 110.03604125976562, "reward": 0.7232915163040161, "action": -0.7461822032928467}
{"mode": "train", "epochs": 9, "timestep": 16187, "ep_reward": 110.82709503173828, "reward": 0.7910510301589966, "action": -1.1274563074111938}
{"mode": "train", "epochs": 9, "timestep": 16188, "ep_reward": 111.66240692138672, "reward": 0.835309624671936, "action": -1.4158353805541992}
{"mode": "train", "epochs": 9, "timestep": 16189, "ep_reward": 112.52251434326172, "reward": 0.8601089715957642, "action": -0.6689090132713318}
{"mode": "train", "epochs": 9, "timestep": 16190, "ep_reward": 113.39768981933594, "reward": 0.8751751184463501, "action": -1.3159594535827637}
{"mode": "train", "epochs": 9, "timestep": 16191, "ep_reward": 114.2670669555664, "reward": 0.8693805932998657, "action": -1.608537197113037}
{"mode": "train", "epochs": 9, "timestep": 16192, "ep_reward": 115.1106948852539, "reward": 0.8436299562454224, "action": -1.1088058948516846}
{"mode": "train", "epochs": 9, "timestep": 16193, "ep_reward": 115.91145324707031, "reward": 0.8007608652114868, "action": -0.9294959306716919}
{"mode": "train", "epochs": 9, "timestep": 16194, "ep_reward": 116.6443862915039, "reward": 0.7329338788986206, "action": -0.014734923839569092}
{"mode": "train", "epochs": 9, "timestep": 16195, "ep_reward": 117.2882080078125, "reward": 0.643823504447937, "action": -1.3185813426971436}
{"mode": "train", "epochs": 9, "timestep": 16196, "ep_reward": 117.78862762451172, "reward": 0.5004180669784546, "action": -0.6753197908401489}
{"mode": "train", "epochs": 9, "timestep": 16197, "ep_reward": 118.13858032226562, "reward": 0.34995031356811523, "action": -0.7412914037704468}
{"mode": "train", "epochs": 9, "timestep": 16198, "ep_reward": 118.37850952148438, "reward": 0.23992717266082764, "action": -0.9296878576278687}
{"mode": "train", "epochs": 9, "timestep": 16199, "ep_reward": 118.48823547363281, "reward": 0.10972899198532104, "action": -1.9938688278198242}
{"mode": "train", "epochs": 9, "timestep": 16200, "ep_reward": 118.49412536621094, "reward": 0.00588679313659668, "action": -0.43029314279556274}
{"mode": "train", "epochs": 9, "timestep": 16201, "ep_reward": 118.64417266845703, "reward": 0.1500474214553833, "action": -0.3441327214241028}
{"mode": "train", "epochs": 9, "timestep": 16202, "ep_reward": 118.94185638427734, "reward": 0.29768115282058716, "action": -0.9589009284973145}
{"mode": "train", "epochs": 9, "timestep": 16203, "ep_reward": 119.37521362304688, "reward": 0.43335968255996704, "action": -0.7300058603286743}
{"mode": "train", "epochs": 9, "timestep": 16204, "ep_reward": 119.93431091308594, "reward": 0.5591009855270386, "action": -1.531535267829895}
{"mode": "train", "epochs": 9, "timestep": 16205, "ep_reward": 120.59121704101562, "reward": 0.6569056510925293, "action": -0.934955894947052}
{"mode": "train", "epochs": 9, "timestep": 16206, "ep_reward": 121.33104705810547, "reward": 0.7398333549499512, "action": -1.265440821647644}
{"mode": "train", "epochs": 9, "timestep": 16207, "ep_reward": 122.12916564941406, "reward": 0.7981165647506714, "action": -0.8479852676391602}
{"mode": "train", "epochs": 9, "timestep": 16208, "ep_reward": 122.9698486328125, "reward": 0.8406844735145569, "action": -1.164661169052124}
{"mode": "train", "epochs": 9, "timestep": 16209, "ep_reward": 123.83301544189453, "reward": 0.863168478012085, "action": -1.1741286516189575}
{"mode": "train", "epochs": 9, "timestep": 16210, "ep_reward": 124.70269775390625, "reward": 0.8696795701980591, "action": -0.6872783899307251}
{"mode": "train", "epochs": 9, "timestep": 16211, "ep_reward": 125.56676483154297, "reward": 0.8640690445899963, "action": -0.8248679637908936}
{"mode": "train", "epochs": 9, "timestep": 16212, "ep_reward": 126.40624237060547, "reward": 0.8394744992256165, "action": -0.7865908741950989}
{"mode": "train", "epochs": 9, "timestep": 16213, "ep_reward": 127.20001983642578, "reward": 0.7937779426574707, "action": -0.05180239677429199}
{"mode": "train", "epochs": 9, "timestep": 16214, "ep_reward": 127.92972564697266, "reward": 0.7297022342681885, "action": -1.2259732484817505}
{"mode": "train", "epochs": 9, "timestep": 16215, "ep_reward": 128.5496063232422, "reward": 0.6198776960372925, "action": -1.1085374355316162}
{"mode": "train", "epochs": 9, "timestep": 16216, "ep_reward": 129.0207977294922, "reward": 0.47119593620300293, "action": -0.823246419429779}
{"mode": "train", "epochs": 9, "timestep": 16217, "ep_reward": 129.3489532470703, "reward": 0.32815492153167725, "action": -0.8355703353881836}
{"mode": "train", "epochs": 9, "timestep": 16218, "ep_reward": 129.5627899169922, "reward": 0.21384131908416748, "action": -1.1839960813522339}
{"mode": "train", "epochs": 9, "timestep": 16219, "ep_reward": 129.64231872558594, "reward": 0.07953250408172607, "action": -1.423147439956665}
{"mode": "train", "epochs": 9, "timestep": 16220, "ep_reward": 129.68038940429688, "reward": 0.03807556629180908, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 16221, "ep_reward": 129.8585662841797, "reward": 0.17817288637161255, "action": -0.8295100927352905}
{"mode": "train", "epochs": 9, "timestep": 16222, "ep_reward": 130.1788330078125, "reward": 0.32027333974838257, "action": -1.4278806447982788}
{"mode": "train", "epochs": 9, "timestep": 16223, "ep_reward": 130.62884521484375, "reward": 0.45001649856567383, "action": -0.5163861513137817}
{"mode": "train", "epochs": 9, "timestep": 16224, "ep_reward": 131.2057342529297, "reward": 0.576881468296051, "action": -0.44200563430786133}
{"mode": "train", "epochs": 9, "timestep": 16225, "ep_reward": 131.88792419433594, "reward": 0.6821960210800171, "action": -1.020717978477478}
{"mode": "train", "epochs": 9, "timestep": 16226, "ep_reward": 132.6461639404297, "reward": 0.7582378387451172, "action": -0.36686408519744873}
{"mode": "train", "epochs": 9, "timestep": 16227, "ep_reward": 133.46485900878906, "reward": 0.8187010288238525, "action": -1.272264003753662}
{"mode": "train", "epochs": 9, "timestep": 16228, "ep_reward": 134.31712341308594, "reward": 0.8522689938545227, "action": -1.4982500076293945}
{"mode": "train", "epochs": 9, "timestep": 16229, "ep_reward": 135.18516540527344, "reward": 0.8680374622344971, "action": -1.124653935432434}
{"mode": "train", "epochs": 9, "timestep": 16230, "ep_reward": 136.05650329589844, "reward": 0.8713343143463135, "action": -1.2479430437088013}
{"mode": "train", "epochs": 9, "timestep": 16231, "ep_reward": 136.91372680664062, "reward": 0.8572276830673218, "action": -0.003465116024017334}
{"mode": "train", "epochs": 9, "timestep": 16232, "ep_reward": 137.7494354248047, "reward": 0.8357052803039551, "action": -1.1828324794769287}
{"mode": "train", "epochs": 9, "timestep": 16233, "ep_reward": 138.53057861328125, "reward": 0.7811431884765625, "action": -1.1096827983856201}
{"mode": "train", "epochs": 9, "timestep": 16234, "ep_reward": 139.2285614013672, "reward": 0.6979877352714539, "action": -0.6695929765701294}
{"mode": "train", "epochs": 9, "timestep": 16235, "ep_reward": 139.8130645751953, "reward": 0.5845057368278503, "action": -0.9719163179397583}
{"mode": "train", "epochs": 9, "timestep": 16236, "ep_reward": 140.2400360107422, "reward": 0.4269717335700989, "action": -0.6510533690452576}
{"mode": "train", "epochs": 9, "timestep": 16237, "ep_reward": 140.541748046875, "reward": 0.30170518159866333, "action": -0.6444514989852905}
{"mode": "train", "epochs": 9, "timestep": 16238, "ep_reward": 140.72418212890625, "reward": 0.18243712186813354, "action": -1.0232031345367432}
{"mode": "train", "epochs": 9, "timestep": 16239, "ep_reward": 140.7674560546875, "reward": 0.043267905712127686, "action": -0.3107178807258606}
{"mode": "train", "epochs": 9, "timestep": 16240, "ep_reward": 140.84230041503906, "reward": 0.07484638690948486, "action": -0.6751583814620972}
{"mode": "train", "epochs": 9, "timestep": 16241, "ep_reward": 141.05868530273438, "reward": 0.21638089418411255, "action": -1.024371862411499}
{"mode": "train", "epochs": 9, "timestep": 16242, "ep_reward": 141.4138641357422, "reward": 0.35517770051956177, "action": -0.44014739990234375}
{"mode": "train", "epochs": 9, "timestep": 16243, "ep_reward": 141.90724182128906, "reward": 0.4933827519416809, "action": -1.5344239473342896}
{"mode": "train", "epochs": 9, "timestep": 16244, "ep_reward": 142.50933837890625, "reward": 0.6021016836166382, "action": -1.0207775831222534}
{"mode": "train", "epochs": 9, "timestep": 16245, "ep_reward": 143.20571899414062, "reward": 0.6963813304901123, "action": -1.03733229637146}
{"mode": "train", "epochs": 9, "timestep": 16246, "ep_reward": 143.97381591796875, "reward": 0.7681000828742981, "action": -0.889147162437439}
{"mode": "train", "epochs": 9, "timestep": 16247, "ep_reward": 144.7938995361328, "reward": 0.8200766444206238, "action": -1.0631697177886963}
{"mode": "train", "epochs": 9, "timestep": 16248, "ep_reward": 145.6455841064453, "reward": 0.8516921401023865, "action": -1.5110437870025635}
{"mode": "train", "epochs": 9, "timestep": 16249, "ep_reward": 146.50852966308594, "reward": 0.8629505038261414, "action": -0.6031101942062378}
{"mode": "train", "epochs": 9, "timestep": 16250, "ep_reward": 147.37399291992188, "reward": 0.8654581308364868, "action": -0.5169310569763184}
{"mode": "train", "epochs": 9, "timestep": 16251, "ep_reward": 148.2255859375, "reward": 0.8515961170196533, "action": -0.2857052683830261}
{"mode": "train", "epochs": 9, "timestep": 16252, "ep_reward": 149.04624938964844, "reward": 0.8206702470779419, "action": -0.6481154561042786}
{"mode": "train", "epochs": 9, "timestep": 16253, "ep_reward": 149.80923461914062, "reward": 0.7629902362823486, "action": -0.3605309724807739}
{"mode": "train", "epochs": 9, "timestep": 16254, "ep_reward": 150.48863220214844, "reward": 0.679404616355896, "action": -0.6813721656799316}
{"mode": "train", "epochs": 9, "timestep": 16255, "ep_reward": 151.04556274414062, "reward": 0.5569366216659546, "action": -1.9398293495178223}
{"mode": "train", "epochs": 9, "timestep": 16256, "ep_reward": 151.420654296875, "reward": 0.37508541345596313, "action": -1.2819323539733887}
{"mode": "train", "epochs": 9, "timestep": 16257, "ep_reward": 151.68966674804688, "reward": 0.2690160870552063, "action": -0.7060871124267578}
{"mode": "train", "epochs": 9, "timestep": 16258, "ep_reward": 151.83360290527344, "reward": 0.14393681287765503, "action": -0.9206708073616028}
{"mode": "train", "epochs": 9, "timestep": 16259, "ep_reward": 151.83250427246094, "reward": -0.001095414161682129, "action": -0.6632275581359863}
{"mode": "train", "epochs": 9, "timestep": 16260, "ep_reward": 151.94866943359375, "reward": 0.11615818738937378, "action": -1.3097691535949707}
{"mode": "train", "epochs": 9, "timestep": 16261, "ep_reward": 152.19973754882812, "reward": 0.25106412172317505, "action": -0.461484432220459}
{"mode": "train", "epochs": 9, "timestep": 16262, "ep_reward": 152.5964813232422, "reward": 0.39673686027526855, "action": -1.4446756839752197}
{"mode": "train", "epochs": 9, "timestep": 16263, "ep_reward": 153.11581420898438, "reward": 0.5193289518356323, "action": -0.4902230501174927}
{"mode": "train", "epochs": 9, "timestep": 16264, "ep_reward": 153.7510223388672, "reward": 0.6352086067199707, "action": -0.7348045110702515}
{"mode": "train", "epochs": 9, "timestep": 16265, "ep_reward": 154.47604370117188, "reward": 0.7250183820724487, "action": -0.4972267746925354}
{"mode": "train", "epochs": 9, "timestep": 16266, "ep_reward": 155.2702178955078, "reward": 0.7941759824752808, "action": -0.7526847124099731}
{"mode": "train", "epochs": 9, "timestep": 16267, "ep_reward": 156.11045837402344, "reward": 0.8402448892593384, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 16268, "ep_reward": 156.96951293945312, "reward": 0.8590602874755859, "action": -1.5058822631835938}
{"mode": "train", "epochs": 9, "timestep": 16269, "ep_reward": 157.83566284179688, "reward": 0.8661548495292664, "action": -1.8866894245147705}
{"mode": "train", "epochs": 9, "timestep": 16270, "ep_reward": 158.68902587890625, "reward": 0.8533597588539124, "action": -1.067888855934143}
{"mode": "train", "epochs": 9, "timestep": 16271, "ep_reward": 159.51718139648438, "reward": 0.8281564116477966, "action": -1.9298319816589355}
{"mode": "train", "epochs": 9, "timestep": 16272, "ep_reward": 160.28759765625, "reward": 0.7704212665557861, "action": -0.17728036642074585}
{"mode": "train", "epochs": 9, "timestep": 16273, "ep_reward": 160.98904418945312, "reward": 0.7014472484588623, "action": -0.7142871618270874}
{"mode": "train", "epochs": 9, "timestep": 16274, "ep_reward": 161.58059692382812, "reward": 0.5915566682815552, "action": -0.7253544926643372}
{"mode": "train", "epochs": 9, "timestep": 16275, "ep_reward": 162.0216827392578, "reward": 0.4410783052444458, "action": -1.3448312282562256}
{"mode": "train", "epochs": 9, "timestep": 16276, "ep_reward": 162.3406982421875, "reward": 0.3190174698829651, "action": -1.8444914817810059}
{"mode": "train", "epochs": 9, "timestep": 16277, "ep_reward": 162.5438995361328, "reward": 0.20319485664367676, "action": -0.9741303324699402}
{"mode": "train", "epochs": 9, "timestep": 16278, "ep_reward": 162.61114501953125, "reward": 0.06725138425827026, "action": -0.6528595685958862}
{"mode": "train", "epochs": 9, "timestep": 16279, "ep_reward": 162.66209411621094, "reward": 0.050952374935150146, "action": -1.1876598596572876}
{"mode": "train", "epochs": 9, "timestep": 16280, "ep_reward": 162.85116577148438, "reward": 0.18907779455184937, "action": -1.532555341720581}
{"mode": "train", "epochs": 9, "timestep": 16281, "ep_reward": 163.17381286621094, "reward": 0.32264697551727295, "action": -1.2951765060424805}
{"mode": "train", "epochs": 9, "timestep": 16282, "ep_reward": 163.62860107421875, "reward": 0.45479434728622437, "action": -1.6091516017913818}
{"mode": "train", "epochs": 9, "timestep": 16283, "ep_reward": 164.1975555419922, "reward": 0.568953275680542, "action": -0.9416134357452393}
{"mode": "train", "epochs": 9, "timestep": 16284, "ep_reward": 164.86758422851562, "reward": 0.6700237989425659, "action": -1.0321624279022217}
{"mode": "train", "epochs": 9, "timestep": 16285, "ep_reward": 165.61349487304688, "reward": 0.7459044456481934, "action": -0.6688330173492432}
{"mode": "train", "epochs": 9, "timestep": 16286, "ep_reward": 166.41543579101562, "reward": 0.8019460439682007, "action": -1.412063717842102}
{"mode": "train", "epochs": 9, "timestep": 16287, "ep_reward": 167.2454071044922, "reward": 0.829966127872467, "action": -1.1872305870056152}
{"mode": "train", "epochs": 9, "timestep": 16288, "ep_reward": 168.08599853515625, "reward": 0.8405888080596924, "action": -1.8037728071212769}
{"mode": "train", "epochs": 9, "timestep": 16289, "ep_reward": 168.91156005859375, "reward": 0.8255670666694641, "action": -0.7210977077484131}
{"mode": "train", "epochs": 9, "timestep": 16290, "ep_reward": 169.70977783203125, "reward": 0.7982206344604492, "action": -0.6011765003204346}
{"mode": "train", "epochs": 9, "timestep": 16291, "ep_reward": 170.45562744140625, "reward": 0.7458556890487671, "action": -0.22173947095870972}
{"mode": "train", "epochs": 9, "timestep": 16292, "ep_reward": 171.12228393554688, "reward": 0.6666578054428101, "action": -0.8725310564041138}
{"mode": "train", "epochs": 9, "timestep": 16293, "ep_reward": 171.66403198242188, "reward": 0.541745126247406, "action": -1.761336088180542}
{"mode": "train", "epochs": 9, "timestep": 16294, "ep_reward": 172.05264282226562, "reward": 0.3886081576347351, "action": -1.6602264642715454}
{"mode": "train", "epochs": 9, "timestep": 16295, "ep_reward": 172.33938598632812, "reward": 0.2867472767829895, "action": -1.3590115308761597}
{"mode": "train", "epochs": 9, "timestep": 16296, "ep_reward": 172.50425720214844, "reward": 0.16487061977386475, "action": -1.0900170803070068}
{"mode": "train", "epochs": 9, "timestep": 16297, "ep_reward": 172.52719116210938, "reward": 0.022932052612304688, "action": -1.2312426567077637}
{"mode": "train", "epochs": 9, "timestep": 16298, "ep_reward": 172.6212615966797, "reward": 0.0940672755241394, "action": -1.3577982187271118}
{"mode": "train", "epochs": 9, "timestep": 16299, "ep_reward": 172.84896850585938, "reward": 0.22771310806274414, "action": -0.745211124420166}
{"mode": "train", "epochs": 9, "timestep": 16300, "ep_reward": 173.22003173828125, "reward": 0.3710630536079407, "action": -0.3664570450782776}
{"mode": "train", "epochs": 9, "timestep": 16301, "ep_reward": 173.7292022705078, "reward": 0.5091710090637207, "action": -0.5735172033309937}
{"mode": "train", "epochs": 9, "timestep": 16302, "ep_reward": 174.35491943359375, "reward": 0.6257144212722778, "action": -0.9718450903892517}
{"mode": "train", "epochs": 9, "timestep": 16303, "ep_reward": 175.0706787109375, "reward": 0.7157548666000366, "action": -0.4174049496650696}
{"mode": "train", "epochs": 9, "timestep": 16304, "ep_reward": 175.8594512939453, "reward": 0.788776695728302, "action": -0.9598696827888489}
{"mode": "train", "epochs": 9, "timestep": 16305, "ep_reward": 176.69581604003906, "reward": 0.8363683223724365, "action": -1.1441471576690674}
{"mode": "train", "epochs": 9, "timestep": 16306, "ep_reward": 177.56129455566406, "reward": 0.8654731512069702, "action": -0.5932324528694153}
{"mode": "train", "epochs": 9, "timestep": 16307, "ep_reward": 178.44500732421875, "reward": 0.8837121725082397, "action": -1.4154915809631348}
{"mode": "train", "epochs": 9, "timestep": 16308, "ep_reward": 179.32632446289062, "reward": 0.8813201189041138, "action": -0.9065858721733093}
{"mode": "train", "epochs": 9, "timestep": 16309, "ep_reward": 180.194091796875, "reward": 0.8677648901939392, "action": -0.7201586961746216}
{"mode": "train", "epochs": 9, "timestep": 16310, "ep_reward": 181.0322723388672, "reward": 0.83817458152771, "action": -1.1276417970657349}
{"mode": "train", "epochs": 9, "timestep": 16311, "ep_reward": 181.8150177001953, "reward": 0.782741367816925, "action": -0.1571812629699707}
{"mode": "train", "epochs": 9, "timestep": 16312, "ep_reward": 182.52496337890625, "reward": 0.709944486618042, "action": -0.40819817781448364}
{"mode": "train", "epochs": 9, "timestep": 16313, "ep_reward": 183.1272430419922, "reward": 0.6022852659225464, "action": -0.20585119724273682}
{"mode": "train", "epochs": 9, "timestep": 16314, "ep_reward": 183.58837890625, "reward": 0.461139976978302, "action": -1.5970442295074463}
{"mode": "train", "epochs": 9, "timestep": 16315, "ep_reward": 183.8931427001953, "reward": 0.30475932359695435, "action": -1.3926557302474976}
{"mode": "train", "epochs": 9, "timestep": 16316, "ep_reward": 184.07919311523438, "reward": 0.18604528903961182, "action": -1.7204313278198242}
{"mode": "train", "epochs": 9, "timestep": 16317, "ep_reward": 184.1266632080078, "reward": 0.047473251819610596, "action": -1.3060264587402344}
{"mode": "train", "epochs": 9, "timestep": 16318, "ep_reward": 184.1973114013672, "reward": 0.07065069675445557, "action": -0.6417993903160095}
{"mode": "train", "epochs": 9, "timestep": 16319, "ep_reward": 184.40965270996094, "reward": 0.21234798431396484, "action": -1.724924087524414}
{"mode": "train", "epochs": 9, "timestep": 16320, "ep_reward": 184.75213623046875, "reward": 0.3424835801124573, "action": -1.4284439086914062}
{"mode": "train", "epochs": 9, "timestep": 16321, "ep_reward": 185.22348022460938, "reward": 0.47133708000183105, "action": 0.0141066312789917}
{"mode": "train", "epochs": 9, "timestep": 16322, "ep_reward": 185.82464599609375, "reward": 0.6011701822280884, "action": -0.01774829626083374}
{"mode": "train", "epochs": 9, "timestep": 16323, "ep_reward": 186.52996826171875, "reward": 0.7053205370903015, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 16324, "ep_reward": 187.29661560058594, "reward": 0.7666431069374084, "action": -1.2611944675445557}
{"mode": "train", "epochs": 9, "timestep": 16325, "ep_reward": 188.11199951171875, "reward": 0.8153911828994751, "action": -0.5239418745040894}
{"mode": "train", "epochs": 9, "timestep": 16326, "ep_reward": 188.96359252929688, "reward": 0.8515898585319519, "action": -0.8268159627914429}
{"mode": "train", "epochs": 9, "timestep": 16327, "ep_reward": 189.8314971923828, "reward": 0.8679075837135315, "action": -0.8563830256462097}
{"mode": "train", "epochs": 9, "timestep": 16328, "ep_reward": 190.69918823242188, "reward": 0.8676870465278625, "action": -1.7874867916107178}
{"mode": "train", "epochs": 9, "timestep": 16329, "ep_reward": 191.54107666015625, "reward": 0.8418838381767273, "action": -1.553469181060791}
{"mode": "train", "epochs": 9, "timestep": 16330, "ep_reward": 192.3368377685547, "reward": 0.7957639694213867, "action": -1.3613245487213135}
{"mode": "train", "epochs": 9, "timestep": 16331, "ep_reward": 193.05990600585938, "reward": 0.7230732440948486, "action": -0.6649895906448364}
{"mode": "train", "epochs": 9, "timestep": 16332, "ep_reward": 193.68368530273438, "reward": 0.6237785816192627, "action": -0.975577712059021}
{"mode": "train", "epochs": 9, "timestep": 16333, "ep_reward": 194.16407775878906, "reward": 0.48039084672927856, "action": -1.1552163362503052}
{"mode": "train", "epochs": 9, "timestep": 16334, "ep_reward": 194.51107788085938, "reward": 0.34699827432632446, "action": -1.4431926012039185}
{"mode": "train", "epochs": 9, "timestep": 16335, "ep_reward": 194.7476348876953, "reward": 0.2365545630455017, "action": -0.11040711402893066}
{"mode": "train", "epochs": 9, "timestep": 16336, "ep_reward": 194.85362243652344, "reward": 0.10598158836364746, "action": -0.08604925870895386}
{"mode": "train", "epochs": 9, "timestep": 16337, "ep_reward": 194.8638153076172, "reward": 0.010185539722442627, "action": -1.2333940267562866}
{"mode": "train", "epochs": 9, "timestep": 16338, "ep_reward": 195.0176544189453, "reward": 0.1538325548171997, "action": -0.7473869323730469}
{"mode": "train", "epochs": 9, "timestep": 16339, "ep_reward": 195.31423950195312, "reward": 0.2965860366821289, "action": -0.9251786470413208}
{"mode": "train", "epochs": 9, "timestep": 16340, "ep_reward": 195.7476348876953, "reward": 0.43339645862579346, "action": -1.4039182662963867}
{"mode": "train", "epochs": 9, "timestep": 16341, "ep_reward": 196.2997589111328, "reward": 0.5521216988563538, "action": -0.005303740501403809}
{"mode": "train", "epochs": 9, "timestep": 16342, "ep_reward": 196.96658325195312, "reward": 0.6668249368667603, "action": -1.2277352809906006}
{"mode": "train", "epochs": 9, "timestep": 16343, "ep_reward": 197.7114715576172, "reward": 0.7448910474777222, "action": -1.300450325012207}
{"mode": "train", "epochs": 9, "timestep": 16344, "ep_reward": 198.51292419433594, "reward": 0.8014503717422485, "action": -1.2948142290115356}
{"mode": "train", "epochs": 9, "timestep": 16345, "ep_reward": 199.35203552246094, "reward": 0.8391150236129761, "action": -1.2303991317749023}
{"mode": "train", "epochs": 9, "timestep": 16346, "ep_reward": 200.2122344970703, "reward": 0.8601967096328735, "action": -0.38640296459198}
{"mode": "train", "epochs": 9, "timestep": 16347, "ep_reward": 201.0841827392578, "reward": 0.8719514012336731, "action": -1.1649976968765259}
{"mode": "train", "epochs": 9, "timestep": 16348, "ep_reward": 201.94488525390625, "reward": 0.8607097864151001, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 16349, "ep_reward": 202.7676544189453, "reward": 0.8227678537368774, "action": -1.4747079610824585}
{"mode": "train", "epochs": 9, "timestep": 16350, "ep_reward": 203.5319366455078, "reward": 0.7642784118652344, "action": -1.408121109008789}
{"mode": "train", "epochs": 9, "timestep": 16351, "ep_reward": 204.2060089111328, "reward": 0.6740703582763672, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 16352, "ep_reward": 204.7411651611328, "reward": 0.5351583957672119, "action": -1.1503945589065552}
{"mode": "train", "epochs": 9, "timestep": 16353, "ep_reward": 205.13235473632812, "reward": 0.3911967873573303, "action": -0.6852858066558838}
{"mode": "train", "epochs": 9, "timestep": 16354, "ep_reward": 205.42205810546875, "reward": 0.28971004486083984, "action": -1.4538183212280273}
{"mode": "train", "epochs": 9, "timestep": 16355, "ep_reward": 205.59043884277344, "reward": 0.16838502883911133, "action": -1.08049476146698}
{"mode": "train", "epochs": 9, "timestep": 16356, "ep_reward": 205.6175079345703, "reward": 0.02707117795944214, "action": -0.1983562707901001}
{"mode": "train", "epochs": 9, "timestep": 16357, "ep_reward": 205.70777893066406, "reward": 0.09027767181396484, "action": -1.2771981954574585}
{"mode": "train", "epochs": 9, "timestep": 16358, "ep_reward": 205.93260192871094, "reward": 0.22482270002365112, "action": -0.6715075969696045}
{"mode": "train", "epochs": 9, "timestep": 16359, "ep_reward": 206.301513671875, "reward": 0.3689144253730774, "action": -1.1992249488830566}
{"mode": "train", "epochs": 9, "timestep": 16360, "ep_reward": 206.798828125, "reward": 0.497317910194397, "action": -1.4620144367218018}
{"mode": "train", "epochs": 9, "timestep": 16361, "ep_reward": 207.40530395507812, "reward": 0.6064714789390564, "action": -0.663856029510498}
{"mode": "train", "epochs": 9, "timestep": 16362, "ep_reward": 208.1082305908203, "reward": 0.702919602394104, "action": -0.2286354899406433}
{"mode": "train", "epochs": 9, "timestep": 16363, "ep_reward": 208.88760375976562, "reward": 0.7793776988983154, "action": -1.1455339193344116}
{"mode": "train", "epochs": 9, "timestep": 16364, "ep_reward": 209.71310424804688, "reward": 0.8255060911178589, "action": -0.5172973871231079}
{"mode": "train", "epochs": 9, "timestep": 16365, "ep_reward": 210.57171630859375, "reward": 0.858610987663269, "action": -0.9603294134140015}
{"mode": "train", "epochs": 9, "timestep": 16366, "ep_reward": 211.4430389404297, "reward": 0.8713184595108032, "action": -1.4935438632965088}
{"mode": "train", "epochs": 9, "timestep": 16367, "ep_reward": 212.30657958984375, "reward": 0.8635411858558655, "action": -1.8857619762420654}
{"mode": "train", "epochs": 9, "timestep": 16368, "ep_reward": 213.140380859375, "reward": 0.8337951898574829, "action": -1.6180167198181152}
{"mode": "train", "epochs": 9, "timestep": 16369, "ep_reward": 213.9231719970703, "reward": 0.7827871441841125, "action": -0.9719970226287842}
{"mode": "train", "epochs": 9, "timestep": 16370, "ep_reward": 214.63209533691406, "reward": 0.7089288830757141, "action": -1.2226998805999756}
{"mode": "train", "epochs": 9, "timestep": 16371, "ep_reward": 215.22793579101562, "reward": 0.5958340167999268, "action": -0.40939515829086304}
{"mode": "train", "epochs": 9, "timestep": 16372, "ep_reward": 215.68051147460938, "reward": 0.4525829553604126, "action": -1.1220251321792603}
{"mode": "train", "epochs": 9, "timestep": 16373, "ep_reward": 216.010009765625, "reward": 0.32949942350387573, "action": -1.6290940046310425}
{"mode": "train", "epochs": 9, "timestep": 16374, "ep_reward": 216.2254638671875, "reward": 0.2154557704925537, "action": -1.882994532585144}
{"mode": "train", "epochs": 9, "timestep": 16375, "ep_reward": 216.30709838867188, "reward": 0.08163869380950928, "action": -0.900429904460907}
{"mode": "train", "epochs": 9, "timestep": 16376, "ep_reward": 216.34324645996094, "reward": 0.036147117614746094, "action": -1.0202707052230835}
{"mode": "train", "epochs": 9, "timestep": 16377, "ep_reward": 216.5194854736328, "reward": 0.17624318599700928, "action": -1.5028104782104492}
{"mode": "train", "epochs": 9, "timestep": 16378, "ep_reward": 216.8295135498047, "reward": 0.31002962589263916, "action": -1.0961902141571045}
{"mode": "train", "epochs": 9, "timestep": 16379, "ep_reward": 217.2749481201172, "reward": 0.44543594121932983, "action": -1.0122283697128296}
{"mode": "train", "epochs": 9, "timestep": 16380, "ep_reward": 217.8425750732422, "reward": 0.567628026008606, "action": -0.4036615490913391}
{"mode": "train", "epochs": 9, "timestep": 16381, "ep_reward": 218.5176544189453, "reward": 0.6750733256340027, "action": -0.7180777788162231}
{"mode": "train", "epochs": 9, "timestep": 16382, "ep_reward": 219.2723388671875, "reward": 0.7546897530555725, "action": -1.1814401149749756}
{"mode": "train", "epochs": 9, "timestep": 16383, "ep_reward": 220.0801239013672, "reward": 0.8077914714813232, "action": -1.2799361944198608}
{"mode": "train", "epochs": 9, "timestep": 16384, "ep_reward": 220.92088317871094, "reward": 0.8407554030418396, "action": -1.3731634616851807}
{"mode": "train", "epochs": 9, "timestep": 16385, "ep_reward": 221.77630615234375, "reward": 0.8554198741912842, "action": -0.3320455551147461}
{"mode": "train", "epochs": 9, "timestep": 16386, "ep_reward": 222.6381072998047, "reward": 0.8617971539497375, "action": -1.2298296689987183}
{"mode": "train", "epochs": 9, "timestep": 16387, "ep_reward": 223.48046875, "reward": 0.8423650860786438, "action": -1.1983978748321533}
{"mode": "train", "epochs": 9, "timestep": 16388, "ep_reward": 224.28208923339844, "reward": 0.8016209006309509, "action": -1.5965819358825684}
{"mode": "train", "epochs": 9, "timestep": 16389, "ep_reward": 225.01112365722656, "reward": 0.7290285229682922, "action": -1.217872142791748}
{"mode": "train", "epochs": 9, "timestep": 16390, "ep_reward": 225.63612365722656, "reward": 0.6249995231628418, "action": -1.795531988143921}
{"mode": "train", "epochs": 9, "timestep": 16391, "ep_reward": 226.10606384277344, "reward": 0.46993643045425415, "action": -1.6637942790985107}
{"mode": "train", "epochs": 9, "timestep": 16392, "ep_reward": 226.45751953125, "reward": 0.35145992040634155, "action": -1.0935941934585571}
{"mode": "train", "epochs": 9, "timestep": 16393, "ep_reward": 226.69923400878906, "reward": 0.2417106032371521, "action": -1.4477646350860596}
{"mode": "train", "epochs": 9, "timestep": 16394, "ep_reward": 226.81137084960938, "reward": 0.11214375495910645, "action": 0.27259302139282227}
{"mode": "train", "epochs": 9, "timestep": 16395, "ep_reward": 226.81480407714844, "reward": 0.003435969352722168, "action": -1.0342864990234375}
{"mode": "train", "epochs": 9, "timestep": 16396, "ep_reward": 226.96273803710938, "reward": 0.1479398012161255, "action": -0.6930228471755981}
{"mode": "train", "epochs": 9, "timestep": 16397, "ep_reward": 227.25392150878906, "reward": 0.29118144512176514, "action": -1.3372492790222168}
{"mode": "train", "epochs": 9, "timestep": 16398, "ep_reward": 227.6772918701172, "reward": 0.4233688712120056, "action": -0.5507609844207764}
{"mode": "train", "epochs": 9, "timestep": 16399, "ep_reward": 228.2303009033203, "reward": 0.553010106086731, "action": -1.7695512771606445}
{"mode": "train", "epochs": 9, "timestep": 16400, "ep_reward": 228.8796844482422, "reward": 0.6493862867355347, "action": -0.5943605303764343}
{"mode": "train", "epochs": 9, "timestep": 16401, "ep_reward": 229.61636352539062, "reward": 0.7366758584976196, "action": -0.9505447745323181}
{"mode": "train", "epochs": 9, "timestep": 16402, "ep_reward": 230.41400146484375, "reward": 0.7976348400115967, "action": -0.14606821537017822}
{"mode": "train", "epochs": 9, "timestep": 16403, "ep_reward": 231.2592010498047, "reward": 0.8451993465423584, "action": -1.5262551307678223}
{"mode": "train", "epochs": 9, "timestep": 16404, "ep_reward": 232.1227569580078, "reward": 0.8635585308074951, "action": -0.6316490769386292}
{"mode": "train", "epochs": 9, "timestep": 16405, "ep_reward": 232.99610900878906, "reward": 0.8733583688735962, "action": -1.7944438457489014}
{"mode": "train", "epochs": 9, "timestep": 16406, "ep_reward": 233.85345458984375, "reward": 0.8573498129844666, "action": -0.3252466320991516}
{"mode": "train", "epochs": 9, "timestep": 16407, "ep_reward": 234.6890106201172, "reward": 0.8355611562728882, "action": -0.7185705304145813}
{"mode": "train", "epochs": 9, "timestep": 16408, "ep_reward": 235.47744750976562, "reward": 0.7884330749511719, "action": -1.1160238981246948}
{"mode": "train", "epochs": 9, "timestep": 16409, "ep_reward": 236.18655395507812, "reward": 0.7091021537780762, "action": -1.4334319829940796}
{"mode": "train", "epochs": 9, "timestep": 16410, "ep_reward": 236.77621459960938, "reward": 0.5896536111831665, "action": -0.758048415184021}
{"mode": "train", "epochs": 9, "timestep": 16411, "ep_reward": 237.2138671875, "reward": 0.4376552104949951, "action": -0.7217606902122498}
{"mode": "train", "epochs": 9, "timestep": 16412, "ep_reward": 237.5266876220703, "reward": 0.31281572580337524, "action": -1.189254879951477}
{"mode": "train", "epochs": 9, "timestep": 16413, "ep_reward": 237.72238159179688, "reward": 0.19569635391235352, "action": -0.8454056978225708}
{"mode": "train", "epochs": 9, "timestep": 16414, "ep_reward": 237.78079223632812, "reward": 0.058409154415130615, "action": -1.642049789428711}
{"mode": "train", "epochs": 9, "timestep": 16415, "ep_reward": 237.840576171875, "reward": 0.05978524684906006, "action": -0.511515736579895}
{"mode": "train", "epochs": 9, "timestep": 16416, "ep_reward": 238.04339599609375, "reward": 0.2028135061264038, "action": -1.458204984664917}
{"mode": "train", "epochs": 9, "timestep": 16417, "ep_reward": 238.3796844482422, "reward": 0.3362863063812256, "action": -0.5838160514831543}
{"mode": "train", "epochs": 9, "timestep": 16418, "ep_reward": 238.8547821044922, "reward": 0.47509992122650146, "action": -1.1038113832473755}
{"mode": "train", "epochs": 9, "timestep": 16419, "ep_reward": 239.4461212158203, "reward": 0.591343104839325, "action": -1.5883970260620117}
{"mode": "train", "epochs": 9, "timestep": 16420, "ep_reward": 240.1280975341797, "reward": 0.6819701194763184, "action": -1.5663204193115234}
{"mode": "train", "epochs": 9, "timestep": 16421, "ep_reward": 240.87953186035156, "reward": 0.7514369487762451, "action": -1.3121001720428467}
{"mode": "train", "epochs": 9, "timestep": 16422, "ep_reward": 241.68167114257812, "reward": 0.8021321296691895, "action": -0.9743524193763733}
{"mode": "train", "epochs": 9, "timestep": 16423, "ep_reward": 242.51736450195312, "reward": 0.8356915712356567, "action": -1.5968648195266724}
{"mode": "train", "epochs": 9, "timestep": 16424, "ep_reward": 243.3623504638672, "reward": 0.844990074634552, "action": -1.101269006729126}
{"mode": "train", "epochs": 9, "timestep": 16425, "ep_reward": 244.2021484375, "reward": 0.8397969007492065, "action": -1.2081828117370605}
{"mode": "train", "epochs": 9, "timestep": 16426, "ep_reward": 245.0147705078125, "reward": 0.812624454498291, "action": -0.19675558805465698}
{"mode": "train", "epochs": 9, "timestep": 16427, "ep_reward": 245.78594970703125, "reward": 0.7711772322654724, "action": -1.4344372749328613}
{"mode": "train", "epochs": 9, "timestep": 16428, "ep_reward": 246.47215270996094, "reward": 0.686198353767395, "action": -1.158803939819336}
{"mode": "train", "epochs": 9, "timestep": 16429, "ep_reward": 247.03785705566406, "reward": 0.5657014846801758, "action": -0.82572340965271}
{"mode": "train", "epochs": 9, "timestep": 16430, "ep_reward": 247.4445343017578, "reward": 0.4066840410232544, "action": -1.0445979833602905}
{"mode": "train", "epochs": 9, "timestep": 16431, "ep_reward": 247.75331115722656, "reward": 0.3087801933288574, "action": -0.9094607830047607}
{"mode": "train", "epochs": 9, "timestep": 16432, "ep_reward": 247.9442138671875, "reward": 0.19090694189071655, "action": -0.2671486735343933}
{"mode": "train", "epochs": 9, "timestep": 16433, "ep_reward": 247.99720764160156, "reward": 0.052990078926086426, "action": -0.10877209901809692}
{"mode": "train", "epochs": 9, "timestep": 16434, "ep_reward": 248.0625457763672, "reward": 0.06534528732299805, "action": -0.36310261487960815}
{"mode": "train", "epochs": 9, "timestep": 16435, "ep_reward": 248.2728271484375, "reward": 0.21028578281402588, "action": -1.9339396953582764}
{"mode": "train", "epochs": 9, "timestep": 16436, "ep_reward": 248.61013793945312, "reward": 0.3373088836669922, "action": -1.5500917434692383}
{"mode": "train", "epochs": 9, "timestep": 16437, "ep_reward": 249.07516479492188, "reward": 0.465023398399353, "action": -1.0190753936767578}
{"mode": "train", "epochs": 9, "timestep": 16438, "ep_reward": 249.65939331054688, "reward": 0.5842249989509583, "action": -1.6732746362686157}
{"mode": "train", "epochs": 9, "timestep": 16439, "ep_reward": 250.3341064453125, "reward": 0.6747164726257324, "action": -0.90397709608078}
{"mode": "train", "epochs": 9, "timestep": 16440, "ep_reward": 251.08456420898438, "reward": 0.7504518032073975, "action": -0.37184858322143555}
{"mode": "train", "epochs": 9, "timestep": 16441, "ep_reward": 251.89222717285156, "reward": 0.8076604604721069, "action": -1.7392675876617432}
{"mode": "train", "epochs": 9, "timestep": 16442, "ep_reward": 252.7235565185547, "reward": 0.8313232064247131, "action": -1.4552485942840576}
{"mode": "train", "epochs": 9, "timestep": 16443, "ep_reward": 253.5620574951172, "reward": 0.8384982347488403, "action": -1.1115224361419678}
{"mode": "train", "epochs": 9, "timestep": 16444, "ep_reward": 254.39080810546875, "reward": 0.8287478685379028, "action": -1.2360546588897705}
{"mode": "train", "epochs": 9, "timestep": 16445, "ep_reward": 255.185791015625, "reward": 0.794989287853241, "action": -1.5141940116882324}
{"mode": "train", "epochs": 9, "timestep": 16446, "ep_reward": 255.9158477783203, "reward": 0.730059802532196, "action": -0.7498794794082642}
{"mode": "train", "epochs": 9, "timestep": 16447, "ep_reward": 256.5549621582031, "reward": 0.6391295194625854, "action": -0.7730541229248047}
{"mode": "train", "epochs": 9, "timestep": 16448, "ep_reward": 257.0626525878906, "reward": 0.5076764822006226, "action": -0.6798374652862549}
{"mode": "train", "epochs": 9, "timestep": 16449, "ep_reward": 257.4393615722656, "reward": 0.3767154812812805, "action": -1.72049880027771}
{"mode": "train", "epochs": 9, "timestep": 16450, "ep_reward": 257.7117919921875, "reward": 0.27242428064346313, "action": -0.379660427570343}
{"mode": "train", "epochs": 9, "timestep": 16451, "ep_reward": 257.8596496582031, "reward": 0.14784765243530273, "action": -1.3898584842681885}
{"mode": "train", "epochs": 9, "timestep": 16452, "ep_reward": 257.8631591796875, "reward": 0.003499150276184082, "action": -0.28244656324386597}
{"mode": "train", "epochs": 9, "timestep": 16453, "ep_reward": 257.9752197265625, "reward": 0.11206686496734619, "action": -1.1150659322738647}
{"mode": "train", "epochs": 9, "timestep": 16454, "ep_reward": 258.2244873046875, "reward": 0.24925851821899414, "action": -0.7947314381599426}
{"mode": "train", "epochs": 9, "timestep": 16455, "ep_reward": 258.6151428222656, "reward": 0.39064955711364746, "action": -0.7462730407714844}
{"mode": "train", "epochs": 9, "timestep": 16456, "ep_reward": 259.1371765136719, "reward": 0.5220261812210083, "action": -0.5287117958068848}
{"mode": "train", "epochs": 9, "timestep": 16457, "ep_reward": 259.7740478515625, "reward": 0.6368744373321533, "action": -0.97059565782547}
{"mode": "train", "epochs": 9, "timestep": 16458, "ep_reward": 260.4983825683594, "reward": 0.7243414521217346, "action": -0.9921568036079407}
{"mode": "train", "epochs": 9, "timestep": 16459, "ep_reward": 261.2881164550781, "reward": 0.7897399663925171, "action": -1.3215988874435425}
{"mode": "train", "epochs": 9, "timestep": 16460, "ep_reward": 262.1207580566406, "reward": 0.8326309323310852, "action": -0.5459117293357849}
{"mode": "train", "epochs": 9, "timestep": 16461, "ep_reward": 262.98529052734375, "reward": 0.8645403981208801, "action": -1.0250145196914673}
{"mode": "train", "epochs": 9, "timestep": 16462, "ep_reward": 263.8619384765625, "reward": 0.8766575455665588, "action": -1.0176430940628052}
{"mode": "train", "epochs": 9, "timestep": 16463, "ep_reward": 264.7356262207031, "reward": 0.8736972808837891, "action": -0.9980754256248474}
{"mode": "train", "epochs": 9, "timestep": 16464, "ep_reward": 265.590087890625, "reward": 0.8544464111328125, "action": -0.7355362772941589}
{"mode": "train", "epochs": 9, "timestep": 16465, "ep_reward": 266.40802001953125, "reward": 0.8179255127906799, "action": -1.520146369934082}
{"mode": "train", "epochs": 9, "timestep": 16466, "ep_reward": 267.1566162109375, "reward": 0.7486056685447693, "action": -0.4026128649711609}
{"mode": "train", "epochs": 9, "timestep": 16467, "ep_reward": 267.8163757324219, "reward": 0.659745454788208, "action": -1.104458212852478}
{"mode": "train", "epochs": 9, "timestep": 16468, "ep_reward": 268.3412780761719, "reward": 0.5249146223068237, "action": -1.5010873079299927}
{"mode": "train", "epochs": 9, "timestep": 16469, "ep_reward": 268.7032165527344, "reward": 0.36194539070129395, "action": -1.3490780591964722}
{"mode": "train", "epochs": 9, "timestep": 16470, "ep_reward": 268.9576110839844, "reward": 0.25439703464508057, "action": -1.299203872680664}
{"mode": "train", "epochs": 9, "timestep": 16471, "ep_reward": 269.08453369140625, "reward": 0.12691283226013184, "action": -0.7349622249603271}
{"mode": "train", "epochs": 9, "timestep": 16472, "ep_reward": 269.0713806152344, "reward": -0.013153314590454102, "action": -0.8955197334289551}
{"mode": "train", "epochs": 9, "timestep": 16473, "ep_reward": 269.20477294921875, "reward": 0.13339662551879883, "action": -1.263885736465454}
{"mode": "train", "epochs": 9, "timestep": 16474, "ep_reward": 269.4740905761719, "reward": 0.26932328939437866, "action": -0.5008563995361328}
{"mode": "train", "epochs": 9, "timestep": 16475, "ep_reward": 269.8877868652344, "reward": 0.41369950771331787, "action": -0.6559568047523499}
{"mode": "train", "epochs": 9, "timestep": 16476, "ep_reward": 270.4310607910156, "reward": 0.5432855486869812, "action": -0.5217055082321167}
{"mode": "train", "epochs": 9, "timestep": 16477, "ep_reward": 271.08544921875, "reward": 0.6543810963630676, "action": -0.508449375629425}
{"mode": "train", "epochs": 9, "timestep": 16478, "ep_reward": 271.82769775390625, "reward": 0.7422493696212769, "action": -1.5413739681243896}
{"mode": "train", "epochs": 9, "timestep": 16479, "ep_reward": 272.62677001953125, "reward": 0.7990697622299194, "action": -0.03666353225708008}
{"mode": "train", "epochs": 9, "timestep": 16480, "ep_reward": 273.4766845703125, "reward": 0.8499264121055603, "action": -1.0475285053253174}
{"mode": "train", "epochs": 9, "timestep": 16481, "ep_reward": 274.35211181640625, "reward": 0.8754252195358276, "action": -1.0635666847229004}
{"mode": "train", "epochs": 9, "timestep": 16482, "ep_reward": 275.23870849609375, "reward": 0.8866087198257446, "action": -0.35491228103637695}
{"mode": "train", "epochs": 9, "timestep": 16483, "ep_reward": 276.128173828125, "reward": 0.8894639015197754, "action": -1.0482122898101807}
{"mode": "train", "epochs": 9, "timestep": 16484, "ep_reward": 277.0006408691406, "reward": 0.8724736571311951, "action": -1.0498952865600586}
{"mode": "train", "epochs": 9, "timestep": 16485, "ep_reward": 277.83856201171875, "reward": 0.8379295468330383, "action": -1.3169748783111572}
{"mode": "train", "epochs": 9, "timestep": 16486, "ep_reward": 278.6166687011719, "reward": 0.7780916094779968, "action": -1.341961145401001}
{"mode": "train", "epochs": 9, "timestep": 16487, "ep_reward": 279.304443359375, "reward": 0.6877869367599487, "action": -0.8092861175537109}
{"mode": "train", "epochs": 9, "timestep": 16488, "ep_reward": 279.8716735839844, "reward": 0.5672440528869629, "action": -0.6718457341194153}
{"mode": "train", "epochs": 9, "timestep": 16489, "ep_reward": 280.2809143066406, "reward": 0.4092356562614441, "action": 0.014969229698181152}
{"mode": "train", "epochs": 9, "timestep": 16490, "ep_reward": 280.5641784667969, "reward": 0.28324997425079346, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 16491, "ep_reward": 280.7250061035156, "reward": 0.16083920001983643, "action": -1.5285520553588867}
{"mode": "train", "epochs": 9, "timestep": 16492, "ep_reward": 280.74334716796875, "reward": 0.01833939552307129, "action": -1.4523043632507324}
{"mode": "train", "epochs": 9, "timestep": 16493, "ep_reward": 280.8417053222656, "reward": 0.09837305545806885, "action": -0.936583399772644}
{"mode": "train", "epochs": 9, "timestep": 16494, "ep_reward": 281.0791015625, "reward": 0.23740708827972412, "action": -0.6398823261260986}
{"mode": "train", "epochs": 9, "timestep": 16495, "ep_reward": 281.4596862792969, "reward": 0.3805816173553467, "action": -1.7663801908493042}
{"mode": "train", "epochs": 9, "timestep": 16496, "ep_reward": 281.9605407714844, "reward": 0.500855565071106, "action": -1.2900264263153076}
{"mode": "train", "epochs": 9, "timestep": 16497, "ep_reward": 282.5718994140625, "reward": 0.6113454103469849, "action": -0.4461323618888855}
{"mode": "train", "epochs": 9, "timestep": 16498, "ep_reward": 283.28070068359375, "reward": 0.7087899446487427, "action": -1.3212611675262451}
{"mode": "train", "epochs": 9, "timestep": 16499, "ep_reward": 284.0544738769531, "reward": 0.7737680673599243, "action": -1.5517606735229492}
{"mode": "train", "epochs": 9, "timestep": 16500, "ep_reward": 284.87060546875, "reward": 0.8161422610282898, "action": -1.052618384361267}
{"mode": "train", "epochs": 9, "timestep": 16501, "ep_reward": 285.7146301269531, "reward": 0.8440134525299072, "action": -1.185255765914917}
{"mode": "train", "epochs": 9, "timestep": 16502, "ep_reward": 286.5672607421875, "reward": 0.8526228666305542, "action": -1.0094877481460571}
{"mode": "train", "epochs": 9, "timestep": 16503, "ep_reward": 287.41162109375, "reward": 0.8443670272827148, "action": -1.4874441623687744}
{"mode": "train", "epochs": 9, "timestep": 16504, "ep_reward": 288.22235107421875, "reward": 0.8107370734214783, "action": -1.5820852518081665}
{"mode": "train", "epochs": 9, "timestep": 16505, "ep_reward": 288.9719543457031, "reward": 0.7495980262756348, "action": -0.5122942328453064}
{"mode": "train", "epochs": 9, "timestep": 16506, "ep_reward": 289.63995361328125, "reward": 0.6679904460906982, "action": -0.7642560601234436}
{"mode": "train", "epochs": 9, "timestep": 16507, "ep_reward": 290.1855773925781, "reward": 0.5456364154815674, "action": -0.6285682916641235}
{"mode": "train", "epochs": 9, "timestep": 16508, "ep_reward": 290.57666015625, "reward": 0.3910900950431824, "action": -1.3415417671203613}
{"mode": "train", "epochs": 9, "timestep": 16509, "ep_reward": 290.866455078125, "reward": 0.28980016708374023, "action": -0.4963521361351013}
{"mode": "train", "epochs": 9, "timestep": 16510, "ep_reward": 291.03472900390625, "reward": 0.16827458143234253, "action": -1.5724620819091797}
{"mode": "train", "epochs": 9, "timestep": 16511, "ep_reward": 291.0616455078125, "reward": 0.026916980743408203, "action": -1.4219919443130493}
{"mode": "train", "epochs": 9, "timestep": 16512, "ep_reward": 291.15203857421875, "reward": 0.09038692712783813, "action": -0.5449656248092651}
{"mode": "train", "epochs": 9, "timestep": 16513, "ep_reward": 291.3861083984375, "reward": 0.23407167196273804, "action": -0.09448868036270142}
{"mode": "train", "epochs": 9, "timestep": 16514, "ep_reward": 291.76922607421875, "reward": 0.3831304907798767, "action": -1.1933704614639282}
{"mode": "train", "epochs": 9, "timestep": 16515, "ep_reward": 292.2778625488281, "reward": 0.5086487531661987, "action": -1.1537437438964844}
{"mode": "train", "epochs": 9, "timestep": 16516, "ep_reward": 292.8968200683594, "reward": 0.6189448833465576, "action": -0.5494193434715271}
{"mode": "train", "epochs": 9, "timestep": 16517, "ep_reward": 293.61138916015625, "reward": 0.7145693302154541, "action": -1.007412075996399}
{"mode": "train", "epochs": 9, "timestep": 16518, "ep_reward": 294.39483642578125, "reward": 0.7834361791610718, "action": -0.9794859886169434}
{"mode": "train", "epochs": 9, "timestep": 16519, "ep_reward": 295.2276611328125, "reward": 0.8328393697738647, "action": -1.1367257833480835}
{"mode": "train", "epochs": 9, "timestep": 16520, "ep_reward": 296.09149169921875, "reward": 0.8638314604759216, "action": -0.6786605715751648}
{"mode": "train", "epochs": 9, "timestep": 16521, "ep_reward": 296.97479248046875, "reward": 0.8833016753196716, "action": -0.305486798286438}
{"mode": "train", "epochs": 9, "timestep": 16522, "ep_reward": 297.8663330078125, "reward": 0.8915557861328125, "action": -0.7338651418685913}
{"mode": "train", "epochs": 9, "timestep": 16523, "ep_reward": 298.7490539550781, "reward": 0.8827177882194519, "action": -0.4567369818687439}
{"mode": "train", "epochs": 9, "timestep": 16524, "ep_reward": 299.6097717285156, "reward": 0.8607244491577148, "action": -1.33368718624115}
{"mode": "train", "epochs": 9, "timestep": 16525, "ep_reward": 300.4216613769531, "reward": 0.8118964433670044, "action": -0.931758463382721}
{"mode": "train", "epochs": 9, "timestep": 16526, "ep_reward": 301.162841796875, "reward": 0.7411754727363586, "action": -0.3418896794319153}
{"mode": "train", "epochs": 9, "timestep": 16527, "ep_reward": 301.80877685546875, "reward": 0.6459375619888306, "action": -1.6754159927368164}
{"mode": "train", "epochs": 9, "timestep": 16528, "ep_reward": 302.3048400878906, "reward": 0.4960533380508423, "action": -1.6418375968933105}
{"mode": "train", "epochs": 9, "timestep": 16529, "ep_reward": 302.6405029296875, "reward": 0.3356507420539856, "action": -0.9672349095344543}
{"mode": "train", "epochs": 9, "timestep": 16530, "ep_reward": 302.8631591796875, "reward": 0.22266530990600586, "action": -1.907334327697754}
{"mode": "train", "epochs": 9, "timestep": 16531, "ep_reward": 302.9531555175781, "reward": 0.0899999737739563, "action": -1.108574390411377}
{"mode": "train", "epochs": 9, "timestep": 16532, "ep_reward": 302.98052978515625, "reward": 0.027370572090148926, "action": -0.5829800367355347}
{"mode": "train", "epochs": 9, "timestep": 16533, "ep_reward": 303.1492614746094, "reward": 0.16872423887252808, "action": -0.3424309492111206}
{"mode": "train", "epochs": 9, "timestep": 16534, "ep_reward": 303.4659423828125, "reward": 0.3166900873184204, "action": -1.2664120197296143}
{"mode": "train", "epochs": 9, "timestep": 16535, "ep_reward": 303.9136962890625, "reward": 0.44774746894836426, "action": -0.2646494507789612}
{"mode": "train", "epochs": 9, "timestep": 16536, "ep_reward": 304.49072265625, "reward": 0.5770392417907715, "action": -1.3772313594818115}
{"mode": "train", "epochs": 9, "timestep": 16537, "ep_reward": 305.1638488769531, "reward": 0.673133373260498, "action": -0.37590885162353516}
{"mode": "train", "epochs": 9, "timestep": 16538, "ep_reward": 305.92132568359375, "reward": 0.7574801445007324, "action": -1.375715732574463}
{"mode": "train", "epochs": 9, "timestep": 16539, "ep_reward": 306.7323303222656, "reward": 0.8110078573226929, "action": -0.9364693760871887}
{"mode": "train", "epochs": 9, "timestep": 16540, "ep_reward": 307.5824890136719, "reward": 0.8501513004302979, "action": -0.6196293234825134}
{"mode": "train", "epochs": 9, "timestep": 16541, "ep_reward": 308.4578552246094, "reward": 0.8753702640533447, "action": -0.442607045173645}
{"mode": "train", "epochs": 9, "timestep": 16542, "ep_reward": 309.3448181152344, "reward": 0.8869656324386597, "action": -1.5946307182312012}
{"mode": "train", "epochs": 9, "timestep": 16543, "ep_reward": 310.2200012207031, "reward": 0.8751760721206665, "action": -0.7310526371002197}
{"mode": "train", "epochs": 9, "timestep": 16544, "ep_reward": 311.0739440917969, "reward": 0.8539391756057739, "action": -0.9255689382553101}
{"mode": "train", "epochs": 9, "timestep": 16545, "ep_reward": 311.8852233886719, "reward": 0.8112754225730896, "action": 0.058603644371032715}
{"mode": "train", "epochs": 9, "timestep": 16546, "ep_reward": 312.6395568847656, "reward": 0.7543250322341919, "action": -1.082383632659912}
{"mode": "train", "epochs": 9, "timestep": 16547, "ep_reward": 313.294677734375, "reward": 0.655113935470581, "action": -1.5230358839035034}
{"mode": "train", "epochs": 9, "timestep": 16548, "ep_reward": 313.8060302734375, "reward": 0.5113637447357178, "action": -0.9700415134429932}
{"mode": "train", "epochs": 9, "timestep": 16549, "ep_reward": 314.1549377441406, "reward": 0.3489192724227905, "action": -1.1514731645584106}
{"mode": "train", "epochs": 9, "timestep": 16550, "ep_reward": 314.3937072753906, "reward": 0.23878264427185059, "action": -0.5922905206680298}
{"mode": "train", "epochs": 9, "timestep": 16551, "ep_reward": 314.5021667480469, "reward": 0.1084553599357605, "action": -1.5610069036483765}
{"mode": "train", "epochs": 9, "timestep": 16552, "ep_reward": 314.5095520019531, "reward": 0.007382631301879883, "action": -0.5526204109191895}
{"mode": "train", "epochs": 9, "timestep": 16553, "ep_reward": 314.6608581542969, "reward": 0.15129828453063965, "action": -0.9976575970649719}
{"mode": "train", "epochs": 9, "timestep": 16554, "ep_reward": 314.95166015625, "reward": 0.290799617767334, "action": -1.6070795059204102}
{"mode": "train", "epochs": 9, "timestep": 16555, "ep_reward": 315.37188720703125, "reward": 0.42023706436157227, "action": -1.2038915157318115}
{"mode": "train", "epochs": 9, "timestep": 16556, "ep_reward": 315.9153747558594, "reward": 0.5434881448745728, "action": -1.1065073013305664}
{"mode": "train", "epochs": 9, "timestep": 16557, "ep_reward": 316.5636901855469, "reward": 0.6483123898506165, "action": -0.9047181606292725}
{"mode": "train", "epochs": 9, "timestep": 16558, "ep_reward": 317.29583740234375, "reward": 0.732134222984314, "action": -0.47455596923828125}
{"mode": "train", "epochs": 9, "timestep": 16559, "ep_reward": 318.09259033203125, "reward": 0.7967453002929688, "action": -0.4128926396369934}
{"mode": "train", "epochs": 9, "timestep": 16560, "ep_reward": 318.9330139160156, "reward": 0.8404278755187988, "action": -0.5716390013694763}
{"mode": "train", "epochs": 9, "timestep": 16561, "ep_reward": 319.7972412109375, "reward": 0.8642420172691345, "action": -1.2660012245178223}
{"mode": "train", "epochs": 9, "timestep": 16562, "ep_reward": 320.6630859375, "reward": 0.8658572435379028, "action": -0.38853979110717773}
{"mode": "train", "epochs": 9, "timestep": 16563, "ep_reward": 321.5212707519531, "reward": 0.8581897020339966, "action": -0.016948223114013672}
{"mode": "train", "epochs": 9, "timestep": 16564, "ep_reward": 322.3570556640625, "reward": 0.8357948660850525, "action": -0.8297516107559204}
{"mode": "train", "epochs": 9, "timestep": 16565, "ep_reward": 323.14129638671875, "reward": 0.7842506766319275, "action": -0.9403254985809326}
{"mode": "train", "epochs": 9, "timestep": 16566, "ep_reward": 323.8446350097656, "reward": 0.7033309936523438, "action": -0.7616547346115112}
{"mode": "train", "epochs": 9, "timestep": 16567, "ep_reward": 324.4343566894531, "reward": 0.5897093415260315, "action": -0.20526325702667236}
{"mode": "train", "epochs": 9, "timestep": 16568, "ep_reward": 324.8799743652344, "reward": 0.44560766220092773, "action": -1.1520448923110962}
{"mode": "train", "epochs": 9, "timestep": 16569, "ep_reward": 325.18377685546875, "reward": 0.3037896156311035, "action": -0.7706044912338257}
{"mode": "train", "epochs": 9, "timestep": 16570, "ep_reward": 325.3687438964844, "reward": 0.18497610092163086, "action": -0.38116270303726196}
{"mode": "train", "epochs": 9, "timestep": 16571, "ep_reward": 325.414794921875, "reward": 0.04605436325073242, "action": -1.1983507871627808}
{"mode": "train", "epochs": 9, "timestep": 16572, "ep_reward": 325.4867858886719, "reward": 0.07197761535644531, "action": -1.2627185583114624}
{"mode": "train", "epochs": 9, "timestep": 16573, "ep_reward": 325.6941223144531, "reward": 0.20734035968780518, "action": -0.9079778790473938}
{"mode": "train", "epochs": 9, "timestep": 16574, "ep_reward": 326.0428771972656, "reward": 0.3487679958343506, "action": -1.5302751064300537}
{"mode": "train", "epochs": 9, "timestep": 16575, "ep_reward": 326.51837158203125, "reward": 0.4755059480667114, "action": -0.3130589723587036}
{"mode": "train", "epochs": 9, "timestep": 16576, "ep_reward": 327.1192321777344, "reward": 0.6008620262145996, "action": -1.283043622970581}
{"mode": "train", "epochs": 9, "timestep": 16577, "ep_reward": 327.8116760253906, "reward": 0.6924381852149963, "action": -1.659729242324829}
{"mode": "train", "epochs": 9, "timestep": 16578, "ep_reward": 328.5700378417969, "reward": 0.7583701610565186, "action": -0.32542848587036133}
{"mode": "train", "epochs": 9, "timestep": 16579, "ep_reward": 329.3855285644531, "reward": 0.8154952526092529, "action": -1.1133594512939453}
{"mode": "train", "epochs": 9, "timestep": 16580, "ep_reward": 330.2308349609375, "reward": 0.8453186750411987, "action": -0.9001095294952393}
{"mode": "train", "epochs": 9, "timestep": 16581, "ep_reward": 331.0901794433594, "reward": 0.8593373894691467, "action": -0.7397116422653198}
{"mode": "train", "epochs": 9, "timestep": 16582, "ep_reward": 331.9474182128906, "reward": 0.857245147228241, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 16583, "ep_reward": 332.7721862792969, "reward": 0.8247649073600769, "action": -0.8439459800720215}
{"mode": "train", "epochs": 9, "timestep": 16584, "ep_reward": 333.5514221191406, "reward": 0.77923983335495, "action": -1.05691397190094}
{"mode": "train", "epochs": 9, "timestep": 16585, "ep_reward": 334.2535095214844, "reward": 0.7020833492279053, "action": -1.7173233032226562}
{"mode": "train", "epochs": 9, "timestep": 16586, "ep_reward": 334.83258056640625, "reward": 0.5790776014328003, "action": -0.3016729950904846}
{"mode": "train", "epochs": 9, "timestep": 16587, "ep_reward": 335.2653503417969, "reward": 0.4327748417854309, "action": -0.6938658952713013}
{"mode": "train", "epochs": 9, "timestep": 16588, "ep_reward": 335.58551025390625, "reward": 0.32017332315444946, "action": -0.6713732481002808}
{"mode": "train", "epochs": 9, "timestep": 16589, "ep_reward": 335.7898254394531, "reward": 0.20432263612747192, "action": -1.192461609840393}
{"mode": "train", "epochs": 9, "timestep": 16590, "ep_reward": 335.8583984375, "reward": 0.06856697797775269, "action": -0.93846195936203}
{"mode": "train", "epochs": 9, "timestep": 16591, "ep_reward": 335.9079284667969, "reward": 0.049537062644958496, "action": -1.4682281017303467}
{"mode": "train", "epochs": 9, "timestep": 16592, "ep_reward": 336.0958251953125, "reward": 0.18789809942245483, "action": -1.4962092638015747}
{"mode": "train", "epochs": 9, "timestep": 16593, "ep_reward": 336.4177551269531, "reward": 0.3219248652458191, "action": -1.164250373840332}
{"mode": "train", "epochs": 9, "timestep": 16594, "ep_reward": 336.8735046386719, "reward": 0.45575499534606934, "action": -0.836862325668335}
{"mode": "train", "epochs": 9, "timestep": 16595, "ep_reward": 337.4519958496094, "reward": 0.5784885883331299, "action": -0.47969353199005127}
{"mode": "train", "epochs": 9, "timestep": 16596, "ep_reward": 338.1348876953125, "reward": 0.6828970313072205, "action": -0.4119415283203125}
{"mode": "train", "epochs": 9, "timestep": 16597, "ep_reward": 338.8981628417969, "reward": 0.7632614374160767, "action": -1.359316349029541}
{"mode": "train", "epochs": 9, "timestep": 16598, "ep_reward": 339.7107849121094, "reward": 0.8126236200332642, "action": -1.1546119451522827}
{"mode": "train", "epochs": 9, "timestep": 16599, "ep_reward": 340.5557556152344, "reward": 0.8449679017066956, "action": -1.5327816009521484}
{"mode": "train", "epochs": 9, "timestep": 16600, "ep_reward": 341.4124755859375, "reward": 0.8567252159118652, "action": -1.4755091667175293}
{"mode": "train", "epochs": 9, "timestep": 16601, "ep_reward": 342.2641296386719, "reward": 0.8516675233840942, "action": -0.7545844316482544}
{"mode": "train", "epochs": 9, "timestep": 16602, "ep_reward": 343.0981140136719, "reward": 0.8339934945106506, "action": -0.8609225749969482}
{"mode": "train", "epochs": 9, "timestep": 16603, "ep_reward": 343.891357421875, "reward": 0.7932505011558533, "action": -0.9921555519104004}
{"mode": "train", "epochs": 9, "timestep": 16604, "ep_reward": 344.6149597167969, "reward": 0.7235944271087646, "action": -0.9881263971328735}
{"mode": "train", "epochs": 9, "timestep": 16605, "ep_reward": 345.2342529296875, "reward": 0.6192814111709595, "action": -1.6059389114379883}
{"mode": "train", "epochs": 9, "timestep": 16606, "ep_reward": 345.69873046875, "reward": 0.4644714593887329, "action": -1.3375632762908936}
{"mode": "train", "epochs": 9, "timestep": 16607, "ep_reward": 346.04119873046875, "reward": 0.3424530029296875, "action": -0.6987424492835999}
{"mode": "train", "epochs": 9, "timestep": 16608, "ep_reward": 346.27215576171875, "reward": 0.2309654951095581, "action": -0.6666843891143799}
{"mode": "train", "epochs": 9, "timestep": 16609, "ep_reward": 346.37152099609375, "reward": 0.09937626123428345, "action": -1.4270646572113037}
{"mode": "train", "epochs": 9, "timestep": 16610, "ep_reward": 346.38873291015625, "reward": 0.017226099967956543, "action": -1.1708940267562866}
{"mode": "train", "epochs": 9, "timestep": 16611, "ep_reward": 346.548583984375, "reward": 0.15983766317367554, "action": -1.49738347530365}
{"mode": "train", "epochs": 9, "timestep": 16612, "ep_reward": 346.842041015625, "reward": 0.2934507131576538, "action": -0.5758440494537354}
{"mode": "train", "epochs": 9, "timestep": 16613, "ep_reward": 347.2780456542969, "reward": 0.43600553274154663, "action": -1.5356554985046387}
{"mode": "train", "epochs": 9, "timestep": 16614, "ep_reward": 347.8312683105469, "reward": 0.5532125234603882, "action": -0.21253442764282227}
{"mode": "train", "epochs": 9, "timestep": 16615, "ep_reward": 348.49688720703125, "reward": 0.665620744228363, "action": -0.6029400825500488}
{"mode": "train", "epochs": 9, "timestep": 16616, "ep_reward": 349.2459411621094, "reward": 0.749048113822937, "action": -1.4116652011871338}
{"mode": "train", "epochs": 9, "timestep": 16617, "ep_reward": 350.0487976074219, "reward": 0.8028531074523926, "action": -0.5889544486999512}
{"mode": "train", "epochs": 9, "timestep": 16618, "ep_reward": 350.89349365234375, "reward": 0.8446908593177795, "action": -0.5005448460578918}
{"mode": "train", "epochs": 9, "timestep": 16619, "ep_reward": 351.76300048828125, "reward": 0.8695043921470642, "action": -1.1500109434127808}
{"mode": "train", "epochs": 9, "timestep": 16620, "ep_reward": 352.6362609863281, "reward": 0.873253583908081, "action": -0.7839917540550232}
{"mode": "train", "epochs": 9, "timestep": 16621, "ep_reward": 353.5003662109375, "reward": 0.8641200065612793, "action": -0.1637343168258667}
{"mode": "train", "epochs": 9, "timestep": 16622, "ep_reward": 354.3431701660156, "reward": 0.842808187007904, "action": -1.5263254642486572}
{"mode": "train", "epochs": 9, "timestep": 16623, "ep_reward": 355.13043212890625, "reward": 0.7872477173805237, "action": -1.9808188676834106}
{"mode": "train", "epochs": 9, "timestep": 16624, "ep_reward": 355.8267822265625, "reward": 0.6963623762130737, "action": -0.6757034063339233}
{"mode": "train", "epochs": 9, "timestep": 16625, "ep_reward": 356.4102478027344, "reward": 0.5834677219390869, "action": -0.32052528858184814}
{"mode": "train", "epochs": 9, "timestep": 16626, "ep_reward": 356.8465576171875, "reward": 0.4363059997558594, "action": -1.7287135124206543}
{"mode": "train", "epochs": 9, "timestep": 16627, "ep_reward": 357.1539611816406, "reward": 0.30741405487060547, "action": -0.6253475546836853}
{"mode": "train", "epochs": 9, "timestep": 16628, "ep_reward": 357.3431396484375, "reward": 0.1891912817955017, "action": -1.0675103664398193}
{"mode": "train", "epochs": 9, "timestep": 16629, "ep_reward": 357.3941345214844, "reward": 0.05099070072174072, "action": -1.242055892944336}
{"mode": "train", "epochs": 9, "timestep": 16630, "ep_reward": 357.4612731933594, "reward": 0.06712651252746582, "action": -1.2828583717346191}
{"mode": "train", "epochs": 9, "timestep": 16631, "ep_reward": 357.6644287109375, "reward": 0.20316648483276367, "action": -0.8320976495742798}
{"mode": "train", "epochs": 9, "timestep": 16632, "ep_reward": 358.01007080078125, "reward": 0.34563732147216797, "action": -0.434404194355011}
{"mode": "train", "epochs": 9, "timestep": 16633, "ep_reward": 358.4953918457031, "reward": 0.48531925678253174, "action": -0.7293474674224854}
{"mode": "train", "epochs": 9, "timestep": 16634, "ep_reward": 359.0994567871094, "reward": 0.6040631532669067, "action": -0.915954053401947}
{"mode": "train", "epochs": 9, "timestep": 16635, "ep_reward": 359.7985534667969, "reward": 0.6991024017333984, "action": -1.4797734022140503}
{"mode": "train", "epochs": 9, "timestep": 16636, "ep_reward": 360.5653991699219, "reward": 0.7668427228927612, "action": -0.7170621156692505}
{"mode": "train", "epochs": 9, "timestep": 16637, "ep_reward": 361.38665771484375, "reward": 0.8212598562240601, "action": -0.8865002393722534}
{"mode": "train", "epochs": 9, "timestep": 16638, "ep_reward": 362.2420959472656, "reward": 0.8554370403289795, "action": -0.37732505798339844}
{"mode": "train", "epochs": 9, "timestep": 16639, "ep_reward": 363.11932373046875, "reward": 0.877240777015686, "action": -1.3561865091323853}
{"mode": "train", "epochs": 9, "timestep": 16640, "ep_reward": 363.9954833984375, "reward": 0.876154899597168, "action": -0.6874165534973145}
{"mode": "train", "epochs": 9, "timestep": 16641, "ep_reward": 364.86029052734375, "reward": 0.8648054003715515, "action": -0.7839718461036682}
{"mode": "train", "epochs": 9, "timestep": 16642, "ep_reward": 365.69482421875, "reward": 0.8345353603363037, "action": -1.9225883483886719}
{"mode": "train", "epochs": 9, "timestep": 16643, "ep_reward": 366.4648742675781, "reward": 0.7700584530830383, "action": -0.05017447471618652}
{"mode": "train", "epochs": 9, "timestep": 16644, "ep_reward": 367.1604919433594, "reward": 0.6956259608268738, "action": -1.1070530414581299}
{"mode": "train", "epochs": 9, "timestep": 16645, "ep_reward": 367.7345886230469, "reward": 0.5740859508514404, "action": -0.7405028343200684}
{"mode": "train", "epochs": 9, "timestep": 16646, "ep_reward": 368.151611328125, "reward": 0.41702717542648315, "action": -1.1127718687057495}
{"mode": "train", "epochs": 9, "timestep": 16647, "ep_reward": 368.44390869140625, "reward": 0.2922857999801636, "action": -0.8387666344642639}
{"mode": "train", "epochs": 9, "timestep": 16648, "ep_reward": 368.615234375, "reward": 0.1713375449180603, "action": -0.9647903442382812}
{"mode": "train", "epochs": 9, "timestep": 16649, "ep_reward": 368.6456604003906, "reward": 0.030435800552368164, "action": -0.6507657170295715}
{"mode": "train", "epochs": 9, "timestep": 16650, "ep_reward": 368.73272705078125, "reward": 0.08707553148269653, "action": -1.2370411157608032}
{"mode": "train", "epochs": 9, "timestep": 16651, "ep_reward": 368.95477294921875, "reward": 0.22205066680908203, "action": -0.1807866096496582}
{"mode": "train", "epochs": 9, "timestep": 16652, "ep_reward": 369.3269348144531, "reward": 0.3721489906311035, "action": -1.0751876831054688}
{"mode": "train", "epochs": 9, "timestep": 16653, "ep_reward": 369.8279724121094, "reward": 0.5010489225387573, "action": -1.3631081581115723}
{"mode": "train", "epochs": 9, "timestep": 16654, "ep_reward": 370.4383239746094, "reward": 0.6103441715240479, "action": -1.9120090007781982}
{"mode": "train", "epochs": 9, "timestep": 16655, "ep_reward": 371.1321716308594, "reward": 0.6938518285751343, "action": -0.7891713380813599}
{"mode": "train", "epochs": 9, "timestep": 16656, "ep_reward": 371.8993835449219, "reward": 0.767200231552124, "action": -0.45974570512771606}
{"mode": "train", "epochs": 9, "timestep": 16657, "ep_reward": 372.72064208984375, "reward": 0.8212725520133972, "action": -1.0651013851165771}
{"mode": "train", "epochs": 9, "timestep": 16658, "ep_reward": 373.5711669921875, "reward": 0.8505341410636902, "action": 0.016437768936157227}
{"mode": "train", "epochs": 9, "timestep": 16659, "ep_reward": 374.4429016113281, "reward": 0.8717489242553711, "action": -0.8226308822631836}
{"mode": "train", "epochs": 9, "timestep": 16660, "ep_reward": 375.3127746582031, "reward": 0.8698582053184509, "action": -0.24149054288864136}
{"mode": "train", "epochs": 9, "timestep": 16661, "ep_reward": 376.1690979003906, "reward": 0.8563269972801208, "action": -0.9984142780303955}
{"mode": "train", "epochs": 9, "timestep": 16662, "ep_reward": 376.9859619140625, "reward": 0.8168712854385376, "action": -1.252441167831421}
{"mode": "train", "epochs": 9, "timestep": 16663, "ep_reward": 377.735595703125, "reward": 0.7496426105499268, "action": -1.2803694009780884}
{"mode": "train", "epochs": 9, "timestep": 16664, "ep_reward": 378.38482666015625, "reward": 0.6492371559143066, "action": 0.5177711844444275}
{"mode": "train", "epochs": 9, "timestep": 16665, "ep_reward": 378.9203796386719, "reward": 0.5355610847473145, "action": -0.6259084939956665}
{"mode": "train", "epochs": 9, "timestep": 16666, "ep_reward": 379.2899475097656, "reward": 0.3695598244667053, "action": -1.1353622674942017}
{"mode": "train", "epochs": 9, "timestep": 16667, "ep_reward": 379.5435791015625, "reward": 0.25363820791244507, "action": -1.5870866775512695}
{"mode": "train", "epochs": 9, "timestep": 16668, "ep_reward": 379.66961669921875, "reward": 0.12602275609970093, "action": -1.2436308860778809}
{"mode": "train", "epochs": 9, "timestep": 16669, "ep_reward": 379.6572265625, "reward": -0.01237785816192627, "action": -1.8570268154144287}
{"mode": "train", "epochs": 9, "timestep": 16670, "ep_reward": 379.7915344238281, "reward": 0.13431167602539062, "action": 0.2956603765487671}
{"mode": "train", "epochs": 9, "timestep": 16671, "ep_reward": 380.0808410644531, "reward": 0.2893202304840088, "action": -1.621914267539978}
{"mode": "train", "epochs": 9, "timestep": 16672, "ep_reward": 380.4971618652344, "reward": 0.41632193326950073, "action": -1.2722570896148682}
{"mode": "train", "epochs": 9, "timestep": 16673, "ep_reward": 381.0352478027344, "reward": 0.5380951166152954, "action": -1.4230268001556396}
{"mode": "train", "epochs": 9, "timestep": 16674, "ep_reward": 381.67578125, "reward": 0.6405476927757263, "action": -1.9836890697479248}
{"mode": "train", "epochs": 9, "timestep": 16675, "ep_reward": 382.39251708984375, "reward": 0.7167401313781738, "action": -0.8298001289367676}
{"mode": "train", "epochs": 9, "timestep": 16676, "ep_reward": 383.1754455566406, "reward": 0.7829229235649109, "action": -1.7886192798614502}
{"mode": "train", "epochs": 9, "timestep": 16677, "ep_reward": 383.99481201171875, "reward": 0.8193736672401428, "action": 0.25783324241638184}
{"mode": "train", "epochs": 9, "timestep": 16678, "ep_reward": 384.8498840332031, "reward": 0.855066180229187, "action": -0.8221525549888611}
{"mode": "train", "epochs": 9, "timestep": 16679, "ep_reward": 385.71307373046875, "reward": 0.863201916217804, "action": -1.7681218385696411}
{"mode": "train", "epochs": 9, "timestep": 16680, "ep_reward": 386.55877685546875, "reward": 0.8456951379776001, "action": -0.6277248859405518}
{"mode": "train", "epochs": 9, "timestep": 16681, "ep_reward": 387.3769226074219, "reward": 0.8181589245796204, "action": -0.642529308795929}
{"mode": "train", "epochs": 9, "timestep": 16682, "ep_reward": 388.14349365234375, "reward": 0.7665602564811707, "action": -1.2562826871871948}
{"mode": "train", "epochs": 9, "timestep": 16683, "ep_reward": 388.8211975097656, "reward": 0.6776948571205139, "action": -1.3204084634780884}
{"mode": "train", "epochs": 9, "timestep": 16684, "ep_reward": 389.3702087402344, "reward": 0.5490247011184692, "action": -0.8001654148101807}
{"mode": "train", "epochs": 9, "timestep": 16685, "ep_reward": 389.7597961425781, "reward": 0.38958507776260376, "action": -1.1265522241592407}
{"mode": "train", "epochs": 9, "timestep": 16686, "ep_reward": 390.0477294921875, "reward": 0.2879405617713928, "action": 0.11637258529663086}
{"mode": "train", "epochs": 9, "timestep": 16687, "ep_reward": 390.2138366699219, "reward": 0.16612201929092407, "action": -1.24560546875}
{"mode": "train", "epochs": 9, "timestep": 16688, "ep_reward": 390.23822021484375, "reward": 0.02436959743499756, "action": -1.4285279512405396}
{"mode": "train", "epochs": 9, "timestep": 16689, "ep_reward": 390.3309326171875, "reward": 0.09271955490112305, "action": -1.1429643630981445}
{"mode": "train", "epochs": 9, "timestep": 16690, "ep_reward": 390.5599670410156, "reward": 0.22902631759643555, "action": -0.5342167019844055}
{"mode": "train", "epochs": 9, "timestep": 16691, "ep_reward": 390.9343566894531, "reward": 0.3743770122528076, "action": -0.995522677898407}
{"mode": "train", "epochs": 9, "timestep": 16692, "ep_reward": 391.4385986328125, "reward": 0.5042333006858826, "action": -1.5790897607803345}
{"mode": "train", "epochs": 9, "timestep": 16693, "ep_reward": 392.0495300292969, "reward": 0.6109443306922913, "action": -0.4805172085762024}
{"mode": "train", "epochs": 9, "timestep": 16694, "ep_reward": 392.75799560546875, "reward": 0.708458423614502, "action": -0.5110405087471008}
{"mode": "train", "epochs": 9, "timestep": 16695, "ep_reward": 393.5396423339844, "reward": 0.7816346287727356, "action": -1.1650662422180176}
{"mode": "train", "epochs": 9, "timestep": 16696, "ep_reward": 394.3674011230469, "reward": 0.8277599215507507, "action": -1.2207077741622925}
{"mode": "train", "epochs": 9, "timestep": 16697, "ep_reward": 395.2230529785156, "reward": 0.8556510806083679, "action": -0.6457102298736572}
{"mode": "train", "epochs": 9, "timestep": 16698, "ep_reward": 396.09503173828125, "reward": 0.8719699382781982, "action": -0.5793194770812988}
{"mode": "train", "epochs": 9, "timestep": 16699, "ep_reward": 396.9681091308594, "reward": 0.8730655908584595, "action": -1.061263918876648}
{"mode": "train", "epochs": 9, "timestep": 16700, "ep_reward": 397.82171630859375, "reward": 0.8536083102226257, "action": -0.8745557069778442}
{"mode": "train", "epochs": 9, "timestep": 16701, "ep_reward": 398.6378173828125, "reward": 0.8160938024520874, "action": 0.17595332860946655}
{"mode": "train", "epochs": 9, "timestep": 16702, "ep_reward": 399.4033508300781, "reward": 0.7655301094055176, "action": -1.5161678791046143}
{"mode": "train", "epochs": 9, "timestep": 16703, "ep_reward": 400.07049560546875, "reward": 0.667151153087616, "action": -1.2356377840042114}
{"mode": "train", "epochs": 9, "timestep": 16704, "ep_reward": 400.6034240722656, "reward": 0.5329248309135437, "action": -1.4490742683410645}
{"mode": "train", "epochs": 9, "timestep": 16705, "ep_reward": 400.97003173828125, "reward": 0.3666207790374756, "action": -1.8878090381622314}
{"mode": "train", "epochs": 9, "timestep": 16706, "ep_reward": 401.2300720214844, "reward": 0.2600520849227905, "action": -1.8789951801300049}
{"mode": "train", "epochs": 9, "timestep": 16707, "ep_reward": 401.3636779785156, "reward": 0.13359403610229492, "action": -1.3183002471923828}
{"mode": "train", "epochs": 9, "timestep": 16708, "ep_reward": 401.3507080078125, "reward": -0.012978434562683105, "action": -1.3350896835327148}
{"mode": "train", "epochs": 9, "timestep": 16709, "ep_reward": 401.4773864746094, "reward": 0.12668073177337646, "action": -0.965378999710083}
{"mode": "train", "epochs": 9, "timestep": 16710, "ep_reward": 401.7434387207031, "reward": 0.2660422921180725, "action": -1.384874701499939}
{"mode": "train", "epochs": 9, "timestep": 16711, "ep_reward": 402.14276123046875, "reward": 0.3993299603462219, "action": 0.18323934078216553}
{"mode": "train", "epochs": 9, "timestep": 16712, "ep_reward": 402.6834411621094, "reward": 0.5406932830810547, "action": -1.0131961107254028}
{"mode": "train", "epochs": 9, "timestep": 16713, "ep_reward": 403.3304443359375, "reward": 0.6470046043395996, "action": -1.7003809213638306}
{"mode": "train", "epochs": 9, "timestep": 16714, "ep_reward": 404.0556335449219, "reward": 0.725174069404602, "action": -1.11368989944458}
{"mode": "train", "epochs": 9, "timestep": 16715, "ep_reward": 404.8439636230469, "reward": 0.7883176207542419, "action": -0.6789838075637817}
{"mode": "train", "epochs": 9, "timestep": 16716, "ep_reward": 405.6790466308594, "reward": 0.8350740671157837, "action": -0.7236431241035461}
{"mode": "train", "epochs": 9, "timestep": 16717, "ep_reward": 406.5423278808594, "reward": 0.8632841110229492, "action": -0.40016812086105347}
{"mode": "train", "epochs": 9, "timestep": 16718, "ep_reward": 407.4202880859375, "reward": 0.8779577016830444, "action": -1.2247809171676636}
{"mode": "train", "epochs": 9, "timestep": 16719, "ep_reward": 408.29083251953125, "reward": 0.8705425262451172, "action": -1.221932053565979}
{"mode": "train", "epochs": 9, "timestep": 16720, "ep_reward": 409.13677978515625, "reward": 0.8459442853927612, "action": -0.6561278700828552}
{"mode": "train", "epochs": 9, "timestep": 16721, "ep_reward": 409.9425048828125, "reward": 0.8057234287261963, "action": -1.0460443496704102}
{"mode": "train", "epochs": 9, "timestep": 16722, "ep_reward": 410.6781311035156, "reward": 0.735623836517334, "action": -1.4190998077392578}
{"mode": "train", "epochs": 9, "timestep": 16723, "ep_reward": 411.3053894042969, "reward": 0.6272629499435425, "action": -0.6854878664016724}
{"mode": "train", "epochs": 9, "timestep": 16724, "ep_reward": 411.7936706542969, "reward": 0.48829054832458496, "action": -1.2257566452026367}
{"mode": "train", "epochs": 9, "timestep": 16725, "ep_reward": 412.13525390625, "reward": 0.34158241748809814, "action": -1.7366158962249756}
{"mode": "train", "epochs": 9, "timestep": 16726, "ep_reward": 412.36529541015625, "reward": 0.2300460934638977, "action": -1.227854609489441}
{"mode": "train", "epochs": 9, "timestep": 16727, "ep_reward": 412.4636535644531, "reward": 0.09837085008621216, "action": -1.4934296607971191}
{"mode": "train", "epochs": 9, "timestep": 16728, "ep_reward": 412.48193359375, "reward": 0.018285751342773438, "action": -1.2445378303527832}
{"mode": "train", "epochs": 9, "timestep": 16729, "ep_reward": 412.6427917480469, "reward": 0.16086900234222412, "action": -0.7922419905662537}
{"mode": "train", "epochs": 9, "timestep": 16730, "ep_reward": 412.946044921875, "reward": 0.30326133966445923, "action": 0.09474122524261475}
{"mode": "train", "epochs": 9, "timestep": 16731, "ep_reward": 413.39794921875, "reward": 0.45190536975860596, "action": -0.31365013122558594}
{"mode": "train", "epochs": 9, "timestep": 16732, "ep_reward": 413.9772033691406, "reward": 0.5792564153671265, "action": -1.298232078552246}
{"mode": "train", "epochs": 9, "timestep": 16733, "ep_reward": 414.65289306640625, "reward": 0.675688624382019, "action": -1.5028462409973145}
{"mode": "train", "epochs": 9, "timestep": 16734, "ep_reward": 415.4028015136719, "reward": 0.7499040365219116, "action": -1.6533985137939453}
{"mode": "train", "epochs": 9, "timestep": 16735, "ep_reward": 416.20623779296875, "reward": 0.8034307956695557, "action": 0.04414355754852295}
{"mode": "train", "epochs": 9, "timestep": 16736, "ep_reward": 417.05914306640625, "reward": 0.8529133200645447, "action": -0.5431172847747803}
{"mode": "train", "epochs": 9, "timestep": 16737, "ep_reward": 417.9394226074219, "reward": 0.8802906274795532, "action": -0.8405929803848267}
{"mode": "train", "epochs": 9, "timestep": 16738, "ep_reward": 418.8305358886719, "reward": 0.8911252617835999, "action": -1.3440511226654053}
{"mode": "train", "epochs": 9, "timestep": 16739, "ep_reward": 419.715087890625, "reward": 0.8845579624176025, "action": -1.2072477340698242}
{"mode": "train", "epochs": 9, "timestep": 16740, "ep_reward": 420.5788269042969, "reward": 0.8637514114379883, "action": -0.6511827111244202}
{"mode": "train", "epochs": 9, "timestep": 16741, "ep_reward": 421.4081115722656, "reward": 0.8292876482009888, "action": -0.9846186637878418}
{"mode": "train", "epochs": 9, "timestep": 16742, "ep_reward": 422.1767578125, "reward": 0.7686339020729065, "action": -1.138795256614685}
{"mode": "train", "epochs": 9, "timestep": 16743, "ep_reward": 422.8528137207031, "reward": 0.676071047782898, "action": -1.1049774885177612}
{"mode": "train", "epochs": 9, "timestep": 16744, "ep_reward": 423.3992919921875, "reward": 0.5464935302734375, "action": -1.014816164970398}
{"mode": "train", "epochs": 9, "timestep": 16745, "ep_reward": 423.7763671875, "reward": 0.37706995010375977, "action": -0.443445086479187}
{"mode": "train", "epochs": 9, "timestep": 16746, "ep_reward": 424.0419921875, "reward": 0.26561737060546875, "action": -1.2756787538528442}
{"mode": "train", "epochs": 9, "timestep": 16747, "ep_reward": 424.18206787109375, "reward": 0.14006400108337402, "action": -0.6069059371948242}
{"mode": "train", "epochs": 9, "timestep": 16748, "ep_reward": 424.1764831542969, "reward": -0.005575060844421387, "action": -0.7018333673477173}
{"mode": "train", "epochs": 9, "timestep": 16749, "ep_reward": 424.296630859375, "reward": 0.12014663219451904, "action": -1.3638076782226562}
{"mode": "train", "epochs": 9, "timestep": 16750, "ep_reward": 424.55108642578125, "reward": 0.2544483542442322, "action": -0.9284849762916565}
{"mode": "train", "epochs": 9, "timestep": 16751, "ep_reward": 424.9455871582031, "reward": 0.39451324939727783, "action": -0.798088014125824}
{"mode": "train", "epochs": 9, "timestep": 16752, "ep_reward": 425.47088623046875, "reward": 0.5252860188484192, "action": -0.5227705240249634}
{"mode": "train", "epochs": 9, "timestep": 16753, "ep_reward": 426.1106262207031, "reward": 0.6397315263748169, "action": -0.8080632090568542}
{"mode": "train", "epochs": 9, "timestep": 16754, "ep_reward": 426.83843994140625, "reward": 0.7278038859367371, "action": -0.8118003606796265}
{"mode": "train", "epochs": 9, "timestep": 16755, "ep_reward": 427.6317443847656, "reward": 0.7932941913604736, "action": -1.3652044534683228}
{"mode": "train", "epochs": 9, "timestep": 16756, "ep_reward": 428.46575927734375, "reward": 0.8340120315551758, "action": -0.8641698360443115}
{"mode": "train", "epochs": 9, "timestep": 16757, "ep_reward": 429.3273010253906, "reward": 0.8615365028381348, "action": -1.2589077949523926}
{"mode": "train", "epochs": 9, "timestep": 16758, "ep_reward": 430.19696044921875, "reward": 0.8696504235267639, "action": -1.2349311113357544}
{"mode": "train", "epochs": 9, "timestep": 16759, "ep_reward": 431.05877685546875, "reward": 0.8618091344833374, "action": -0.6642823219299316}
{"mode": "train", "epochs": 9, "timestep": 16760, "ep_reward": 431.89971923828125, "reward": 0.8409532308578491, "action": -0.7124184370040894}
{"mode": "train", "epochs": 9, "timestep": 16761, "ep_reward": 432.69818115234375, "reward": 0.7984610795974731, "action": -1.570615530014038}
{"mode": "train", "epochs": 9, "timestep": 16762, "ep_reward": 433.4178161621094, "reward": 0.7196496725082397, "action": -0.8263672590255737}
{"mode": "train", "epochs": 9, "timestep": 16763, "ep_reward": 434.03192138671875, "reward": 0.6141068935394287, "action": -0.8055536150932312}
{"mode": "train", "epochs": 9, "timestep": 16764, "ep_reward": 434.50091552734375, "reward": 0.4689936637878418, "action": -1.8165247440338135}
{"mode": "train", "epochs": 9, "timestep": 16765, "ep_reward": 434.8332824707031, "reward": 0.3323785662651062, "action": -0.9622939825057983}
{"mode": "train", "epochs": 9, "timestep": 16766, "ep_reward": 435.0522155761719, "reward": 0.21894341707229614, "action": -0.8177725076675415}
{"mode": "train", "epochs": 9, "timestep": 16767, "ep_reward": 435.13775634765625, "reward": 0.0855303406715393, "action": -0.2602273225784302}
{"mode": "train", "epochs": 9, "timestep": 16768, "ep_reward": 435.169921875, "reward": 0.03215140104293823, "action": -0.7259803414344788}
{"mode": "train", "epochs": 9, "timestep": 16769, "ep_reward": 435.3426513671875, "reward": 0.17272895574569702, "action": -1.602178931236267}
{"mode": "train", "epochs": 9, "timestep": 16770, "ep_reward": 435.64788818359375, "reward": 0.3052409887313843, "action": -0.9317367076873779}
{"mode": "train", "epochs": 9, "timestep": 16771, "ep_reward": 436.0910339355469, "reward": 0.4431307911872864, "action": -0.6439563632011414}
{"mode": "train", "epochs": 9, "timestep": 16772, "ep_reward": 436.66070556640625, "reward": 0.5696857571601868, "action": -1.0844494104385376}
{"mode": "train", "epochs": 9, "timestep": 16773, "ep_reward": 437.3304138183594, "reward": 0.6697163581848145, "action": -1.313188910484314}
{"mode": "train", "epochs": 9, "timestep": 16774, "ep_reward": 438.0751953125, "reward": 0.744784951210022, "action": -1.1261519193649292}
{"mode": "train", "epochs": 9, "timestep": 16775, "ep_reward": 438.8750915527344, "reward": 0.7998830080032349, "action": -0.9264865517616272}
{"mode": "train", "epochs": 9, "timestep": 16776, "ep_reward": 439.711669921875, "reward": 0.8365901708602905, "action": -0.18087273836135864}
{"mode": "train", "epochs": 9, "timestep": 16777, "ep_reward": 440.5729064941406, "reward": 0.861250638961792, "action": -0.5738072395324707}
{"mode": "train", "epochs": 9, "timestep": 16778, "ep_reward": 441.43829345703125, "reward": 0.865379810333252, "action": -0.49211210012435913}
{"mode": "train", "epochs": 9, "timestep": 16779, "ep_reward": 442.29144287109375, "reward": 0.8531367778778076, "action": -0.5192004442214966}
{"mode": "train", "epochs": 9, "timestep": 16780, "ep_reward": 443.11285400390625, "reward": 0.8214126229286194, "action": -1.4739024639129639}
{"mode": "train", "epochs": 9, "timestep": 16781, "ep_reward": 443.86883544921875, "reward": 0.7559676766395569, "action": -0.7798128724098206}
{"mode": "train", "epochs": 9, "timestep": 16782, "ep_reward": 444.53509521484375, "reward": 0.6662610173225403, "action": -1.0025125741958618}
{"mode": "train", "epochs": 9, "timestep": 16783, "ep_reward": 445.07122802734375, "reward": 0.5361385941505432, "action": -1.2588558197021484}
{"mode": "train", "epochs": 9, "timestep": 16784, "ep_reward": 445.4435729980469, "reward": 0.37234461307525635, "action": -0.11136549711227417}
{"mode": "train", "epochs": 9, "timestep": 16785, "ep_reward": 445.71038818359375, "reward": 0.2668015956878662, "action": -1.3809112310409546}
{"mode": "train", "epochs": 9, "timestep": 16786, "ep_reward": 445.851806640625, "reward": 0.14141452312469482, "action": -1.1476610898971558}
{"mode": "train", "epochs": 9, "timestep": 16787, "ep_reward": 445.8478698730469, "reward": -0.003929734230041504, "action": -0.22792977094650269}
{"mode": "train", "epochs": 9, "timestep": 16788, "ep_reward": 445.9666442871094, "reward": 0.11877435445785522, "action": -0.8621886968612671}
{"mode": "train", "epochs": 9, "timestep": 16789, "ep_reward": 446.2258605957031, "reward": 0.2592235207557678, "action": -1.3067704439163208}
{"mode": "train", "epochs": 9, "timestep": 16790, "ep_reward": 446.6192932128906, "reward": 0.3934297561645508, "action": -1.3288544416427612}
{"mode": "train", "epochs": 9, "timestep": 16791, "ep_reward": 447.1373596191406, "reward": 0.5180772542953491, "action": -0.5158231258392334}
{"mode": "train", "epochs": 9, "timestep": 16792, "ep_reward": 447.7713317871094, "reward": 0.6339651346206665, "action": -0.6168431043624878}
{"mode": "train", "epochs": 9, "timestep": 16793, "ep_reward": 448.4963073730469, "reward": 0.7249857187271118, "action": 0.360819935798645}
{"mode": "train", "epochs": 9, "timestep": 16794, "ep_reward": 449.2975769042969, "reward": 0.8012832999229431, "action": -1.4836527109146118}
{"mode": "train", "epochs": 9, "timestep": 16795, "ep_reward": 450.1379699707031, "reward": 0.8404039144515991, "action": -0.5599068403244019}
{"mode": "train", "epochs": 9, "timestep": 16796, "ep_reward": 451.00848388671875, "reward": 0.8705070614814758, "action": -0.9797709584236145}
{"mode": "train", "epochs": 9, "timestep": 16797, "ep_reward": 451.8904113769531, "reward": 0.8819239139556885, "action": -1.626737117767334}
{"mode": "train", "epochs": 9, "timestep": 16798, "ep_reward": 452.7640686035156, "reward": 0.8736439943313599, "action": -0.47961699962615967}
{"mode": "train", "epochs": 9, "timestep": 16799, "ep_reward": 453.62261962890625, "reward": 0.8585542440414429, "action": -0.5636893510818481}
{"mode": "train", "epochs": 9, "timestep": 16800, "ep_reward": 454.4468078613281, "reward": 0.8241790533065796, "action": -0.5907212495803833}
{"mode": "train", "epochs": 9, "timestep": 16801, "ep_reward": 455.21337890625, "reward": 0.7665572166442871, "action": -0.618638277053833}
{"mode": "train", "epochs": 9, "timestep": 16802, "ep_reward": 455.89300537109375, "reward": 0.679624080657959, "action": -1.4371356964111328}
{"mode": "train", "epochs": 9, "timestep": 16803, "ep_reward": 456.43902587890625, "reward": 0.546032726764679, "action": -1.3478049039840698}
{"mode": "train", "epochs": 9, "timestep": 16804, "ep_reward": 456.80999755859375, "reward": 0.370974600315094, "action": -0.1531209945678711}
{"mode": "train", "epochs": 9, "timestep": 16805, "ep_reward": 457.073974609375, "reward": 0.26398253440856934, "action": -1.1187665462493896}
{"mode": "train", "epochs": 9, "timestep": 16806, "ep_reward": 457.21209716796875, "reward": 0.1381186842918396, "action": -0.614797055721283}
{"mode": "train", "epochs": 9, "timestep": 16807, "ep_reward": 457.2042541503906, "reward": -0.007834553718566895, "action": -0.9719296097755432}
{"mode": "train", "epochs": 9, "timestep": 16808, "ep_reward": 457.3263854980469, "reward": 0.1221194863319397, "action": -1.4166896343231201}
{"mode": "train", "epochs": 9, "timestep": 16809, "ep_reward": 457.58209228515625, "reward": 0.2557200789451599, "action": -1.5196528434753418}
{"mode": "train", "epochs": 9, "timestep": 16810, "ep_reward": 457.9705810546875, "reward": 0.3884739279747009, "action": -1.6628196239471436}
{"mode": "train", "epochs": 9, "timestep": 16811, "ep_reward": 458.48101806640625, "reward": 0.5104494690895081, "action": -0.725508451461792}
{"mode": "train", "epochs": 9, "timestep": 16812, "ep_reward": 459.1063537597656, "reward": 0.6253210306167603, "action": -1.7599462270736694}
{"mode": "train", "epochs": 9, "timestep": 16813, "ep_reward": 459.8116760253906, "reward": 0.7053334712982178, "action": -1.5551507472991943}
{"mode": "train", "epochs": 9, "timestep": 16814, "ep_reward": 460.5765075683594, "reward": 0.7648196816444397, "action": -1.4789156913757324}
{"mode": "train", "epochs": 9, "timestep": 16815, "ep_reward": 461.3792419433594, "reward": 0.8027297258377075, "action": -1.5007340908050537}
{"mode": "train", "epochs": 9, "timestep": 16816, "ep_reward": 462.1982727050781, "reward": 0.8190445303916931, "action": -0.27850574254989624}
{"mode": "train", "epochs": 9, "timestep": 16817, "ep_reward": 463.0238037109375, "reward": 0.8255269527435303, "action": -1.6437675952911377}
{"mode": "train", "epochs": 9, "timestep": 16818, "ep_reward": 463.8194580078125, "reward": 0.7956602573394775, "action": -1.2829447984695435}
{"mode": "train", "epochs": 9, "timestep": 16819, "ep_reward": 464.56097412109375, "reward": 0.7415250539779663, "action": -1.6034374237060547}
{"mode": "train", "epochs": 9, "timestep": 16820, "ep_reward": 465.2095031738281, "reward": 0.6485257744789124, "action": -1.665881872177124}
{"mode": "train", "epochs": 9, "timestep": 16821, "ep_reward": 465.7200622558594, "reward": 0.5105545520782471, "action": -1.5502620935440063}
{"mode": "train", "epochs": 9, "timestep": 16822, "ep_reward": 466.11737060546875, "reward": 0.3973016142845154, "action": -0.24200642108917236}
{"mode": "train", "epochs": 9, "timestep": 16823, "ep_reward": 466.41455078125, "reward": 0.2971770167350769, "action": -1.1772874593734741}
{"mode": "train", "epochs": 9, "timestep": 16824, "ep_reward": 466.5917053222656, "reward": 0.17715990543365479, "action": -1.0018935203552246}
{"mode": "train", "epochs": 9, "timestep": 16825, "ep_reward": 466.6288757324219, "reward": 0.03718084096908569, "action": -0.15432965755462646}
{"mode": "train", "epochs": 9, "timestep": 16826, "ep_reward": 466.7095947265625, "reward": 0.08072066307067871, "action": -0.7474035024642944}
{"mode": "train", "epochs": 9, "timestep": 16827, "ep_reward": 466.9311218261719, "reward": 0.22153407335281372, "action": -1.0645943880081177}
{"mode": "train", "epochs": 9, "timestep": 16828, "ep_reward": 467.29095458984375, "reward": 0.35981929302215576, "action": -0.7880969643592834}
{"mode": "train", "epochs": 9, "timestep": 16829, "ep_reward": 467.7847595214844, "reward": 0.49381399154663086, "action": -0.712599515914917}
{"mode": "train", "epochs": 9, "timestep": 16830, "ep_reward": 468.396240234375, "reward": 0.6114840507507324, "action": -0.7226511240005493}
{"mode": "train", "epochs": 9, "timestep": 16831, "ep_reward": 469.1029052734375, "reward": 0.7066787481307983, "action": -1.977229356765747}
{"mode": "train", "epochs": 9, "timestep": 16832, "ep_reward": 469.870849609375, "reward": 0.767943263053894, "action": -0.807938814163208}
{"mode": "train", "epochs": 9, "timestep": 16833, "ep_reward": 470.6910095214844, "reward": 0.8201547861099243, "action": -1.7741469144821167}
{"mode": "train", "epochs": 9, "timestep": 16834, "ep_reward": 471.5364074707031, "reward": 0.8454052209854126, "action": -0.30990493297576904}
{"mode": "train", "epochs": 9, "timestep": 16835, "ep_reward": 472.4024963378906, "reward": 0.866097629070282, "action": -0.7862452268600464}
{"mode": "train", "epochs": 9, "timestep": 16836, "ep_reward": 473.2686462402344, "reward": 0.8661454916000366, "action": -0.8510305285453796}
{"mode": "train", "epochs": 9, "timestep": 16837, "ep_reward": 474.1170654296875, "reward": 0.848412036895752, "action": 0.11184126138687134}
{"mode": "train", "epochs": 9, "timestep": 16838, "ep_reward": 474.9371337890625, "reward": 0.8200551867485046, "action": -1.0035921335220337}
{"mode": "train", "epochs": 9, "timestep": 16839, "ep_reward": 475.6944580078125, "reward": 0.7573193311691284, "action": -1.1827589273452759}
{"mode": "train", "epochs": 9, "timestep": 16840, "ep_reward": 476.35546875, "reward": 0.6610071063041687, "action": -1.3352172374725342}
{"mode": "train", "epochs": 9, "timestep": 16841, "ep_reward": 476.87896728515625, "reward": 0.5235017538070679, "action": -1.3943796157836914}
{"mode": "train", "epochs": 9, "timestep": 16842, "ep_reward": 477.2432861328125, "reward": 0.36431026458740234, "action": -1.024317741394043}
{"mode": "train", "epochs": 9, "timestep": 16843, "ep_reward": 477.50054931640625, "reward": 0.25726574659347534, "action": -0.6881489157676697}
{"mode": "train", "epochs": 9, "timestep": 16844, "ep_reward": 477.6307373046875, "reward": 0.13018816709518433, "action": -0.6608098745346069}
{"mode": "train", "epochs": 9, "timestep": 16845, "ep_reward": 477.61383056640625, "reward": -0.01689767837524414, "action": -0.9862573742866516}
{"mode": "train", "epochs": 9, "timestep": 16846, "ep_reward": 477.7440490722656, "reward": 0.13020557165145874, "action": -0.7316104173660278}
{"mode": "train", "epochs": 9, "timestep": 16847, "ep_reward": 478.0166320800781, "reward": 0.2725846767425537, "action": -1.1708139181137085}
{"mode": "train", "epochs": 9, "timestep": 16848, "ep_reward": 478.42431640625, "reward": 0.40769124031066895, "action": -0.7184282541275024}
{"mode": "train", "epochs": 9, "timestep": 16849, "ep_reward": 478.9617004394531, "reward": 0.537387490272522, "action": -0.7884052991867065}
{"mode": "train", "epochs": 9, "timestep": 16850, "ep_reward": 479.60845947265625, "reward": 0.6467686891555786, "action": -1.082261562347412}
{"mode": "train", "epochs": 9, "timestep": 16851, "ep_reward": 480.33905029296875, "reward": 0.7305808067321777, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 16852, "ep_reward": 481.12371826171875, "reward": 0.7846786975860596, "action": -1.380354881286621}
{"mode": "train", "epochs": 9, "timestep": 16853, "ep_reward": 481.9490966796875, "reward": 0.8253639936447144, "action": -1.135081171989441}
{"mode": "train", "epochs": 9, "timestep": 16854, "ep_reward": 482.7987976074219, "reward": 0.8497001528739929, "action": -1.6155674457550049}
{"mode": "train", "epochs": 9, "timestep": 16855, "ep_reward": 483.6511535644531, "reward": 0.8523465991020203, "action": -0.9038128852844238}
{"mode": "train", "epochs": 9, "timestep": 16856, "ep_reward": 484.4940185546875, "reward": 0.8428716659545898, "action": -0.7836474180221558}
{"mode": "train", "epochs": 9, "timestep": 16857, "ep_reward": 485.3079833984375, "reward": 0.813951849937439, "action": -0.6135896444320679}
{"mode": "train", "epochs": 9, "timestep": 16858, "ep_reward": 486.0700378417969, "reward": 0.7620678544044495, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 16859, "ep_reward": 486.7326354980469, "reward": 0.6625899076461792, "action": -1.5935657024383545}
{"mode": "train", "epochs": 9, "timestep": 16860, "ep_reward": 487.2583312988281, "reward": 0.5257008075714111, "action": -0.5428506731987}
{"mode": "train", "epochs": 9, "timestep": 16861, "ep_reward": 487.643310546875, "reward": 0.38498151302337646, "action": -1.3370256423950195}
{"mode": "train", "epochs": 9, "timestep": 16862, "ep_reward": 487.92559814453125, "reward": 0.2822950482368469, "action": -1.1576989889144897}
{"mode": "train", "epochs": 9, "timestep": 16863, "ep_reward": 488.0851745605469, "reward": 0.1595757007598877, "action": -1.1957632303237915}
{"mode": "train", "epochs": 9, "timestep": 16864, "ep_reward": 488.10211181640625, "reward": 0.01694875955581665, "action": 0.2257910966873169}
{"mode": "train", "epochs": 9, "timestep": 16865, "ep_reward": 488.2019348144531, "reward": 0.09982061386108398, "action": -0.5115132927894592}
{"mode": "train", "epochs": 9, "timestep": 16866, "ep_reward": 488.446044921875, "reward": 0.2441219687461853, "action": -1.0706526041030884}
{"mode": "train", "epochs": 9, "timestep": 16867, "ep_reward": 488.8271789550781, "reward": 0.381131649017334, "action": -0.41671687364578247}
{"mode": "train", "epochs": 9, "timestep": 16868, "ep_reward": 489.3439636230469, "reward": 0.5167787671089172, "action": -1.3362834453582764}
{"mode": "train", "epochs": 9, "timestep": 16869, "ep_reward": 489.9678649902344, "reward": 0.6239141225814819, "action": -0.5285654067993164}
{"mode": "train", "epochs": 9, "timestep": 16870, "ep_reward": 490.686279296875, "reward": 0.7183992266654968, "action": -1.613063097000122}
{"mode": "train", "epochs": 9, "timestep": 16871, "ep_reward": 491.4664611816406, "reward": 0.7801914215087891, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 16872, "ep_reward": 492.2862548828125, "reward": 0.819791316986084, "action": -1.198669195175171}
{"mode": "train", "epochs": 9, "timestep": 16873, "ep_reward": 493.135009765625, "reward": 0.8487624526023865, "action": -0.3821374177932739}
{"mode": "train", "epochs": 9, "timestep": 16874, "ep_reward": 494.00250244140625, "reward": 0.8674928545951843, "action": -0.5322248935699463}
{"mode": "train", "epochs": 9, "timestep": 16875, "ep_reward": 494.8710632324219, "reward": 0.868564248085022, "action": -0.3322782516479492}
{"mode": "train", "epochs": 9, "timestep": 16876, "ep_reward": 495.7255859375, "reward": 0.854521632194519, "action": -1.448704481124878}
{"mode": "train", "epochs": 9, "timestep": 16877, "ep_reward": 496.5362548828125, "reward": 0.8106821179389954, "action": -0.8392503261566162}
{"mode": "train", "epochs": 9, "timestep": 16878, "ep_reward": 497.2832336425781, "reward": 0.7469727993011475, "action": -0.6397128105163574}
{"mode": "train", "epochs": 9, "timestep": 16879, "ep_reward": 497.9374084472656, "reward": 0.6541609764099121, "action": -0.6948617100715637}
{"mode": "train", "epochs": 9, "timestep": 16880, "ep_reward": 498.46099853515625, "reward": 0.5235780477523804, "action": -1.4448432922363281}
{"mode": "train", "epochs": 9, "timestep": 16881, "ep_reward": 498.82012939453125, "reward": 0.35912418365478516, "action": -1.1971698999404907}
{"mode": "train", "epochs": 9, "timestep": 16882, "ep_reward": 499.0710754394531, "reward": 0.25095152854919434, "action": -1.4092026948928833}
{"mode": "train", "epochs": 9, "timestep": 16883, "ep_reward": 499.1938781738281, "reward": 0.12280172109603882, "action": -1.4774236679077148}
{"mode": "train", "epochs": 9, "timestep": 16884, "ep_reward": 499.1852111816406, "reward": -0.00866401195526123, "action": -1.3026272058486938}
{"mode": "train", "epochs": 9, "timestep": 16885, "ep_reward": 499.3224792480469, "reward": 0.13728046417236328, "action": -1.6958922147750854}
{"mode": "train", "epochs": 9, "timestep": 16886, "ep_reward": 499.59039306640625, "reward": 0.2679229974746704, "action": -0.43428993225097656}
{"mode": "train", "epochs": 9, "timestep": 16887, "ep_reward": 500.0044860839844, "reward": 0.4140920639038086, "action": -0.09812593460083008}
{"mode": "train", "epochs": 9, "timestep": 16888, "ep_reward": 500.5546569824219, "reward": 0.5501762628555298, "action": -1.441044569015503}
{"mode": "train", "epochs": 9, "timestep": 16889, "ep_reward": 501.2052001953125, "reward": 0.6505477428436279, "action": -0.2799733281135559}
{"mode": "train", "epochs": 9, "timestep": 16890, "ep_reward": 501.9463195800781, "reward": 0.7411320209503174, "action": -0.45352184772491455}
{"mode": "train", "epochs": 9, "timestep": 16891, "ep_reward": 502.7530517578125, "reward": 0.8067429065704346, "action": -0.9901642799377441}
{"mode": "train", "epochs": 9, "timestep": 16892, "ep_reward": 503.6011657714844, "reward": 0.8481144905090332, "action": -0.9460387229919434}
{"mode": "train", "epochs": 9, "timestep": 16893, "ep_reward": 504.4747314453125, "reward": 0.8735761642456055, "action": -0.22265243530273438}
{"mode": "train", "epochs": 9, "timestep": 16894, "ep_reward": 505.36468505859375, "reward": 0.8899673819541931, "action": -0.7342392206192017}
{"mode": "train", "epochs": 9, "timestep": 16895, "ep_reward": 506.2532653808594, "reward": 0.8885778188705444, "action": -1.2947193384170532}
{"mode": "train", "epochs": 9, "timestep": 16896, "ep_reward": 507.121337890625, "reward": 0.8680813908576965, "action": -0.872285008430481}
{"mode": "train", "epochs": 9, "timestep": 16897, "ep_reward": 507.95440673828125, "reward": 0.8330620527267456, "action": -0.7081718444824219}
{"mode": "train", "epochs": 9, "timestep": 16898, "ep_reward": 508.7314147949219, "reward": 0.777004599571228, "action": -1.8064090013504028}
{"mode": "train", "epochs": 9, "timestep": 16899, "ep_reward": 509.4107666015625, "reward": 0.6793467998504639, "action": -0.8234925866127014}
{"mode": "train", "epochs": 9, "timestep": 16900, "ep_reward": 509.96600341796875, "reward": 0.5552349090576172, "action": -1.9043349027633667}
{"mode": "train", "epochs": 9, "timestep": 16901, "ep_reward": 510.3418884277344, "reward": 0.3758889436721802, "action": -1.74642014503479}
{"mode": "train", "epochs": 9, "timestep": 16902, "ep_reward": 510.61322021484375, "reward": 0.27132976055145264, "action": -1.333404779434204}
{"mode": "train", "epochs": 9, "timestep": 16903, "ep_reward": 510.7599792480469, "reward": 0.1467646360397339, "action": -0.7812641263008118}
{"mode": "train", "epochs": 9, "timestep": 16904, "ep_reward": 510.7619934082031, "reward": 0.002002418041229248, "action": -1.6143934726715088}
{"mode": "train", "epochs": 9, "timestep": 16905, "ep_reward": 510.875244140625, "reward": 0.11325353384017944, "action": -1.2674858570098877}
{"mode": "train", "epochs": 9, "timestep": 16906, "ep_reward": 511.123779296875, "reward": 0.24852466583251953, "action": -1.2389652729034424}
{"mode": "train", "epochs": 9, "timestep": 16907, "ep_reward": 511.5086364746094, "reward": 0.38487231731414795, "action": -0.506142258644104}
{"mode": "train", "epochs": 9, "timestep": 16908, "ep_reward": 512.02880859375, "reward": 0.520194411277771, "action": -1.58393394947052}
{"mode": "train", "epochs": 9, "timestep": 16909, "ep_reward": 512.6529541015625, "reward": 0.624133288860321, "action": -1.4159408807754517}
{"mode": "train", "epochs": 9, "timestep": 16910, "ep_reward": 513.36181640625, "reward": 0.7088474035263062, "action": -1.7208921909332275}
{"mode": "train", "epochs": 9, "timestep": 16911, "ep_reward": 514.1303100585938, "reward": 0.7684682011604309, "action": -1.1434574127197266}
{"mode": "train", "epochs": 9, "timestep": 16912, "ep_reward": 514.9428100585938, "reward": 0.812518298625946, "action": -0.39626991748809814}
{"mode": "train", "epochs": 9, "timestep": 16913, "ep_reward": 515.785888671875, "reward": 0.8430953621864319, "action": -0.20214885473251343}
{"mode": "train", "epochs": 9, "timestep": 16914, "ep_reward": 516.642333984375, "reward": 0.8564222455024719, "action": -0.6730812788009644}
{"mode": "train", "epochs": 9, "timestep": 16915, "ep_reward": 517.48974609375, "reward": 0.8473840951919556, "action": -0.5879478454589844}
{"mode": "train", "epochs": 9, "timestep": 16916, "ep_reward": 518.30908203125, "reward": 0.8193141222000122, "action": -0.03770560026168823}
{"mode": "train", "epochs": 9, "timestep": 16917, "ep_reward": 519.082763671875, "reward": 0.7736619710922241, "action": -1.0611529350280762}
{"mode": "train", "epochs": 9, "timestep": 16918, "ep_reward": 519.7711791992188, "reward": 0.6884009838104248, "action": -0.9424780607223511}
{"mode": "train", "epochs": 9, "timestep": 16919, "ep_reward": 520.3389892578125, "reward": 0.5678149461746216, "action": -0.7687494158744812}
{"mode": "train", "epochs": 9, "timestep": 16920, "ep_reward": 520.7477416992188, "reward": 0.40876340866088867, "action": -1.251269817352295}
{"mode": "train", "epochs": 9, "timestep": 16921, "ep_reward": 521.040283203125, "reward": 0.29253697395324707, "action": -1.347796082496643}
{"mode": "train", "epochs": 9, "timestep": 16922, "ep_reward": 521.2119750976562, "reward": 0.1716967225074768, "action": -1.1139041185379028}
{"mode": "train", "epochs": 9, "timestep": 16923, "ep_reward": 521.2426147460938, "reward": 0.03064870834350586, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 16924, "ep_reward": 521.3292846679688, "reward": 0.08666080236434937, "action": -1.240290641784668}
{"mode": "train", "epochs": 9, "timestep": 16925, "ep_reward": 521.55078125, "reward": 0.22148263454437256, "action": -1.275508165359497}
{"mode": "train", "epochs": 9, "timestep": 16926, "ep_reward": 521.9088745117188, "reward": 0.35809093713760376, "action": -1.7153123617172241}
{"mode": "train", "epochs": 9, "timestep": 16927, "ep_reward": 522.39111328125, "reward": 0.48223018646240234, "action": -0.38975000381469727}
{"mode": "train", "epochs": 9, "timestep": 16928, "ep_reward": 522.9970703125, "reward": 0.6059353351593018, "action": -0.39616578817367554}
{"mode": "train", "epochs": 9, "timestep": 16929, "ep_reward": 523.7019653320312, "reward": 0.7049208879470825, "action": -1.7803435325622559}
{"mode": "train", "epochs": 9, "timestep": 16930, "ep_reward": 524.4684448242188, "reward": 0.7664898633956909, "action": -0.9565457105636597}
{"mode": "train", "epochs": 9, "timestep": 16931, "ep_reward": 525.2836303710938, "reward": 0.8151733875274658, "action": -0.680214524269104}
{"mode": "train", "epochs": 9, "timestep": 16932, "ep_reward": 526.130126953125, "reward": 0.8465040922164917, "action": -0.6844549179077148}
{"mode": "train", "epochs": 9, "timestep": 16933, "ep_reward": 526.9898681640625, "reward": 0.8597412109375, "action": 0.05744826793670654}
{"mode": "train", "epochs": 9, "timestep": 16934, "ep_reward": 527.8519287109375, "reward": 0.8620686531066895, "action": -1.4346884489059448}
{"mode": "train", "epochs": 9, "timestep": 16935, "ep_reward": 528.6849365234375, "reward": 0.833025336265564, "action": -0.3676716089248657}
{"mode": "train", "epochs": 9, "timestep": 16936, "ep_reward": 529.4766845703125, "reward": 0.7917316555976868, "action": -1.4266166687011719}
{"mode": "train", "epochs": 9, "timestep": 16937, "ep_reward": 530.1884155273438, "reward": 0.7117026448249817, "action": -1.0195255279541016}
{"mode": "train", "epochs": 9, "timestep": 16938, "ep_reward": 530.7885131835938, "reward": 0.6001229882240295, "action": -1.9407305717468262}
{"mode": "train", "epochs": 9, "timestep": 16939, "ep_reward": 531.2213134765625, "reward": 0.43280959129333496, "action": -0.612683892250061}
{"mode": "train", "epochs": 9, "timestep": 16940, "ep_reward": 531.5421752929688, "reward": 0.32089006900787354, "action": -0.8598516583442688}
{"mode": "train", "epochs": 9, "timestep": 16941, "ep_reward": 531.7471923828125, "reward": 0.20503520965576172, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 16942, "ep_reward": 531.8167114257812, "reward": 0.06953585147857666, "action": -1.258234977722168}
{"mode": "train", "epochs": 9, "timestep": 16943, "ep_reward": 531.8652954101562, "reward": 0.048566341400146484, "action": -1.0863885879516602}
{"mode": "train", "epochs": 9, "timestep": 16944, "ep_reward": 532.0523681640625, "reward": 0.1870984435081482, "action": -0.8665430545806885}
{"mode": "train", "epochs": 9, "timestep": 16945, "ep_reward": 532.3812866210938, "reward": 0.3289165496826172, "action": -1.1357258558273315}
{"mode": "train", "epochs": 9, "timestep": 16946, "ep_reward": 532.8428955078125, "reward": 0.4616164565086365, "action": -0.7549097537994385}
{"mode": "train", "epochs": 9, "timestep": 16947, "ep_reward": 533.4266967773438, "reward": 0.5837887525558472, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 16948, "ep_reward": 534.098388671875, "reward": 0.6717144250869751, "action": -1.260035514831543}
{"mode": "train", "epochs": 9, "timestep": 16949, "ep_reward": 534.844482421875, "reward": 0.7460951805114746, "action": -1.5629398822784424}
{"mode": "train", "epochs": 9, "timestep": 16950, "ep_reward": 535.64013671875, "reward": 0.7956294417381287, "action": -1.210451602935791}
{"mode": "train", "epochs": 9, "timestep": 16951, "ep_reward": 536.4683227539062, "reward": 0.828186571598053, "action": -0.1987546682357788}
{"mode": "train", "epochs": 9, "timestep": 16952, "ep_reward": 537.3187255859375, "reward": 0.8504139184951782, "action": -1.053870439529419}
{"mode": "train", "epochs": 9, "timestep": 16953, "ep_reward": 538.1648559570312, "reward": 0.8461431264877319, "action": -1.6133670806884766}
{"mode": "train", "epochs": 9, "timestep": 16954, "ep_reward": 538.9810180664062, "reward": 0.8161389827728271, "action": -1.8338475227355957}
{"mode": "train", "epochs": 9, "timestep": 16955, "ep_reward": 539.7388916015625, "reward": 0.7578762769699097, "action": -0.7060055732727051}
{"mode": "train", "epochs": 9, "timestep": 16956, "ep_reward": 540.418701171875, "reward": 0.6798250675201416, "action": -0.5486682653427124}
{"mode": "train", "epochs": 9, "timestep": 16957, "ep_reward": 540.9854125976562, "reward": 0.5667340159416199, "action": -0.22836947441101074}
{"mode": "train", "epochs": 9, "timestep": 16958, "ep_reward": 541.403076171875, "reward": 0.4176769256591797, "action": -1.436659574508667}
{"mode": "train", "epochs": 9, "timestep": 16959, "ep_reward": 541.713134765625, "reward": 0.31004399061203003, "action": -0.7044092416763306}
{"mode": "train", "epochs": 9, "timestep": 16960, "ep_reward": 541.905517578125, "reward": 0.19238030910491943, "action": -0.3414009213447571}
{"mode": "train", "epochs": 9, "timestep": 16961, "ep_reward": 541.9600830078125, "reward": 0.054590463638305664, "action": -1.3283143043518066}
{"mode": "train", "epochs": 9, "timestep": 16962, "ep_reward": 542.023681640625, "reward": 0.06357800960540771, "action": -1.1270917654037476}
{"mode": "train", "epochs": 9, "timestep": 16963, "ep_reward": 542.2236938476562, "reward": 0.19998818635940552, "action": -1.4868730306625366}
{"mode": "train", "epochs": 9, "timestep": 16964, "ep_reward": 542.5579223632812, "reward": 0.3342283368110657, "action": -1.3669044971466064}
{"mode": "train", "epochs": 9, "timestep": 16965, "ep_reward": 543.0226440429688, "reward": 0.4647221565246582, "action": -1.122062087059021}
{"mode": "train", "epochs": 9, "timestep": 16966, "ep_reward": 543.60546875, "reward": 0.5828518867492676, "action": -1.6231786012649536}
{"mode": "train", "epochs": 9, "timestep": 16967, "ep_reward": 544.2794799804688, "reward": 0.6740298271179199, "action": -0.6170473694801331}
{"mode": "train", "epochs": 9, "timestep": 16968, "ep_reward": 545.0319213867188, "reward": 0.7524665594100952, "action": -0.9268937706947327}
{"mode": "train", "epochs": 9, "timestep": 16969, "ep_reward": 545.8361206054688, "reward": 0.8042182922363281, "action": -0.5163581371307373}
{"mode": "train", "epochs": 9, "timestep": 16970, "ep_reward": 546.6748657226562, "reward": 0.8387575149536133, "action": -0.9497713446617126}
{"mode": "train", "epochs": 9, "timestep": 16971, "ep_reward": 547.5252075195312, "reward": 0.850323498249054, "action": -0.8806322813034058}
{"mode": "train", "epochs": 9, "timestep": 16972, "ep_reward": 548.369140625, "reward": 0.8439622521400452, "action": -0.18840426206588745}
{"mode": "train", "epochs": 9, "timestep": 16973, "ep_reward": 549.1931762695312, "reward": 0.82405686378479, "action": -1.2897573709487915}
{"mode": "train", "epochs": 9, "timestep": 16974, "ep_reward": 549.9630126953125, "reward": 0.7698177099227905, "action": -0.7713529467582703}
{"mode": "train", "epochs": 9, "timestep": 16975, "ep_reward": 550.6538696289062, "reward": 0.6908771991729736, "action": -0.711449146270752}
{"mode": "train", "epochs": 9, "timestep": 16976, "ep_reward": 551.2302856445312, "reward": 0.5763872861862183, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 16977, "ep_reward": 551.6332397460938, "reward": 0.4029696583747864, "action": -1.065802812576294}
{"mode": "train", "epochs": 9, "timestep": 16978, "ep_reward": 551.9374389648438, "reward": 0.30422520637512207, "action": -0.9541314840316772}
{"mode": "train", "epochs": 9, "timestep": 16979, "ep_reward": 552.1229248046875, "reward": 0.18548154830932617, "action": -0.8262253403663635}
{"mode": "train", "epochs": 9, "timestep": 16980, "ep_reward": 552.1696166992188, "reward": 0.046715497970581055, "action": -0.9066474437713623}
{"mode": "train", "epochs": 9, "timestep": 16981, "ep_reward": 552.240966796875, "reward": 0.07134610414505005, "action": -1.4013868570327759}
{"mode": "train", "epochs": 9, "timestep": 16982, "ep_reward": 552.44775390625, "reward": 0.2067728042602539, "action": -1.2289729118347168}
{"mode": "train", "epochs": 9, "timestep": 16983, "ep_reward": 552.7920532226562, "reward": 0.34432220458984375, "action": -1.0072226524353027}
{"mode": "train", "epochs": 9, "timestep": 16984, "ep_reward": 553.2700805664062, "reward": 0.47803252935409546, "action": -0.5803406238555908}
{"mode": "train", "epochs": 9, "timestep": 16985, "ep_reward": 553.8701171875, "reward": 0.6000409126281738, "action": -0.6250829696655273}
{"mode": "train", "epochs": 9, "timestep": 16986, "ep_reward": 554.568603515625, "reward": 0.6985108852386475, "action": -0.990998387336731}
{"mode": "train", "epochs": 9, "timestep": 16987, "ep_reward": 555.3385009765625, "reward": 0.7698971629142761, "action": -1.1327455043792725}
{"mode": "train", "epochs": 9, "timestep": 16988, "ep_reward": 556.157470703125, "reward": 0.818946123123169, "action": -1.1593858003616333}
{"mode": "train", "epochs": 9, "timestep": 16989, "ep_reward": 557.006591796875, "reward": 0.8491388559341431, "action": -0.9560481309890747}
{"mode": "train", "epochs": 9, "timestep": 16990, "ep_reward": 557.87060546875, "reward": 0.8640164136886597, "action": -0.7890334129333496}
{"mode": "train", "epochs": 9, "timestep": 16991, "ep_reward": 558.7342529296875, "reward": 0.8636216521263123, "action": -1.462679147720337}
{"mode": "train", "epochs": 9, "timestep": 16992, "ep_reward": 559.573486328125, "reward": 0.8392540812492371, "action": -1.9623252153396606}
{"mode": "train", "epochs": 9, "timestep": 16993, "ep_reward": 560.3607788085938, "reward": 0.7872756719589233, "action": -0.566815972328186}
{"mode": "train", "epochs": 9, "timestep": 16994, "ep_reward": 561.081787109375, "reward": 0.7210042476654053, "action": -0.5401830673217773}
{"mode": "train", "epochs": 9, "timestep": 16995, "ep_reward": 561.703369140625, "reward": 0.6215642690658569, "action": -1.9259079694747925}
{"mode": "train", "epochs": 9, "timestep": 16996, "ep_reward": 562.16552734375, "reward": 0.46218782663345337, "action": -0.6024806499481201}
{"mode": "train", "epochs": 9, "timestep": 16997, "ep_reward": 562.505859375, "reward": 0.3403344750404358, "action": -0.8199707269668579}
{"mode": "train", "epochs": 9, "timestep": 16998, "ep_reward": 562.7343139648438, "reward": 0.22845906019210815, "action": -0.45204174518585205}
{"mode": "train", "epochs": 9, "timestep": 16999, "ep_reward": 562.8307495117188, "reward": 0.09642773866653442, "action": -1.4967284202575684}
{"mode": "train", "epochs": 9, "timestep": 17000, "ep_reward": 562.8511962890625, "reward": 0.020430803298950195, "action": -0.7971270680427551}
{"mode": "train", "epochs": 9, "timestep": 17001, "ep_reward": 563.013916015625, "reward": 0.1626909375190735, "action": -0.707288920879364}
{"mode": "train", "epochs": 9, "timestep": 17002, "ep_reward": 563.320068359375, "reward": 0.3061347007751465, "action": -0.7444614768028259}
{"mode": "train", "epochs": 9, "timestep": 17003, "ep_reward": 563.7645263671875, "reward": 0.4444727897644043, "action": -1.4326715469360352}
{"mode": "train", "epochs": 9, "timestep": 17004, "ep_reward": 564.3257446289062, "reward": 0.5612215995788574, "action": -1.3306732177734375}
{"mode": "train", "epochs": 9, "timestep": 17005, "ep_reward": 564.986328125, "reward": 0.6605955362319946, "action": -0.21525275707244873}
{"mode": "train", "epochs": 9, "timestep": 17006, "ep_reward": 565.735107421875, "reward": 0.7488008737564087, "action": -1.02531099319458}
{"mode": "train", "epochs": 9, "timestep": 17007, "ep_reward": 566.5413818359375, "reward": 0.8062943816184998, "action": -0.7148054242134094}
{"mode": "train", "epochs": 9, "timestep": 17008, "ep_reward": 567.3884887695312, "reward": 0.8470973968505859, "action": -1.0736057758331299}
{"mode": "train", "epochs": 9, "timestep": 17009, "ep_reward": 568.2561645507812, "reward": 0.8676469922065735, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 17010, "ep_reward": 569.1212158203125, "reward": 0.8650729060173035, "action": -0.4886150360107422}
{"mode": "train", "epochs": 9, "timestep": 17011, "ep_reward": 569.9796752929688, "reward": 0.858482301235199, "action": -0.5469145774841309}
{"mode": "train", "epochs": 9, "timestep": 17012, "ep_reward": 570.8125, "reward": 0.8328105211257935, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 17013, "ep_reward": 571.5823364257812, "reward": 0.769826352596283, "action": -0.31402134895324707}
{"mode": "train", "epochs": 9, "timestep": 17014, "ep_reward": 572.2767333984375, "reward": 0.6943941712379456, "action": -0.6567187309265137}
{"mode": "train", "epochs": 9, "timestep": 17015, "ep_reward": 572.8568725585938, "reward": 0.5801156759262085, "action": -1.9733349084854126}
{"mode": "train", "epochs": 9, "timestep": 17016, "ep_reward": 573.2621459960938, "reward": 0.40524822473526, "action": -0.28105485439300537}
{"mode": "train", "epochs": 9, "timestep": 17017, "ep_reward": 573.5608520507812, "reward": 0.2986980676651001, "action": -0.8715357780456543}
{"mode": "train", "epochs": 9, "timestep": 17018, "ep_reward": 573.7396850585938, "reward": 0.17885512113571167, "action": -1.3801100254058838}
{"mode": "train", "epochs": 9, "timestep": 17019, "ep_reward": 573.7788696289062, "reward": 0.03919798135757446, "action": -0.2950352430343628}
{"mode": "train", "epochs": 9, "timestep": 17020, "ep_reward": 573.8575439453125, "reward": 0.07866674661636353, "action": -1.5175600051879883}
{"mode": "train", "epochs": 9, "timestep": 17021, "ep_reward": 574.0706176757812, "reward": 0.21304452419281006, "action": -1.5550906658172607}
{"mode": "train", "epochs": 9, "timestep": 17022, "ep_reward": 574.417236328125, "reward": 0.34661996364593506, "action": -0.6834673881530762}
{"mode": "train", "epochs": 9, "timestep": 17023, "ep_reward": 574.9016723632812, "reward": 0.48446565866470337, "action": -0.7479108572006226}
{"mode": "train", "epochs": 9, "timestep": 17024, "ep_reward": 575.5051879882812, "reward": 0.6035255789756775, "action": -1.44788658618927}
{"mode": "train", "epochs": 9, "timestep": 17025, "ep_reward": 576.197998046875, "reward": 0.6928086280822754, "action": -0.07285112142562866}
{"mode": "train", "epochs": 9, "timestep": 17026, "ep_reward": 576.970947265625, "reward": 0.7729288339614868, "action": -0.5076178312301636}
{"mode": "train", "epochs": 9, "timestep": 17027, "ep_reward": 577.796630859375, "reward": 0.8256688117980957, "action": -1.56315016746521}
{"mode": "train", "epochs": 9, "timestep": 17028, "ep_reward": 578.647216796875, "reward": 0.85056471824646, "action": -0.3467990756034851}
{"mode": "train", "epochs": 9, "timestep": 17029, "ep_reward": 579.5162353515625, "reward": 0.8690005540847778, "action": -0.18541258573532104}
{"mode": "train", "epochs": 9, "timestep": 17030, "ep_reward": 580.3887939453125, "reward": 0.8725366592407227, "action": -0.9403544068336487}
{"mode": "train", "epochs": 9, "timestep": 17031, "ep_reward": 581.241943359375, "reward": 0.8531582951545715, "action": -0.7726529836654663}
{"mode": "train", "epochs": 9, "timestep": 17032, "ep_reward": 582.0575561523438, "reward": 0.8155902624130249, "action": -0.8383104205131531}
{"mode": "train", "epochs": 9, "timestep": 17033, "ep_reward": 582.8104248046875, "reward": 0.7528471946716309, "action": -0.2782782316207886}
{"mode": "train", "epochs": 9, "timestep": 17034, "ep_reward": 583.4766235351562, "reward": 0.6661853790283203, "action": -0.8725759983062744}
{"mode": "train", "epochs": 9, "timestep": 17035, "ep_reward": 584.0130615234375, "reward": 0.5364323854446411, "action": -0.9862883687019348}
{"mode": "train", "epochs": 9, "timestep": 17036, "ep_reward": 584.3778076171875, "reward": 0.3647383451461792, "action": -0.6094496846199036}
{"mode": "train", "epochs": 9, "timestep": 17037, "ep_reward": 584.6337280273438, "reward": 0.2558954954147339, "action": -0.8263313174247742}
{"mode": "train", "epochs": 9, "timestep": 17038, "ep_reward": 584.7623291015625, "reward": 0.12860727310180664, "action": -0.5574688911437988}
{"mode": "train", "epochs": 9, "timestep": 17039, "ep_reward": 584.7472534179688, "reward": -0.015059113502502441, "action": -0.7995792627334595}
{"mode": "train", "epochs": 9, "timestep": 17040, "ep_reward": 584.87890625, "reward": 0.1316353678703308, "action": -1.742074966430664}
{"mode": "train", "epochs": 9, "timestep": 17041, "ep_reward": 585.140380859375, "reward": 0.2614750266075134, "action": -1.2339701652526855}
{"mode": "train", "epochs": 9, "timestep": 17042, "ep_reward": 585.5386352539062, "reward": 0.3982408046722412, "action": -0.8419371843338013}
{"mode": "train", "epochs": 9, "timestep": 17043, "ep_reward": 586.0672607421875, "reward": 0.528651237487793, "action": -1.3826346397399902}
{"mode": "train", "epochs": 9, "timestep": 17044, "ep_reward": 586.700439453125, "reward": 0.6331831216812134, "action": -1.442987084388733}
{"mode": "train", "epochs": 9, "timestep": 17045, "ep_reward": 587.4153442382812, "reward": 0.714880108833313, "action": -1.0558362007141113}
{"mode": "train", "epochs": 9, "timestep": 17046, "ep_reward": 588.1929321289062, "reward": 0.7775952816009521, "action": -0.07760351896286011}
{"mode": "train", "epochs": 9, "timestep": 17047, "ep_reward": 589.0200805664062, "reward": 0.827146589756012, "action": -1.2353914976119995}
{"mode": "train", "epochs": 9, "timestep": 17048, "ep_reward": 589.8661499023438, "reward": 0.8460641503334045, "action": -1.2642264366149902}
{"mode": "train", "epochs": 9, "timestep": 17049, "ep_reward": 590.7125244140625, "reward": 0.8463632464408875, "action": -0.8379570245742798}
{"mode": "train", "epochs": 9, "timestep": 17050, "ep_reward": 591.54345703125, "reward": 0.8309627771377563, "action": -1.1111650466918945}
{"mode": "train", "epochs": 9, "timestep": 17051, "ep_reward": 592.3336181640625, "reward": 0.7901709675788879, "action": -1.8424158096313477}
{"mode": "train", "epochs": 9, "timestep": 17052, "ep_reward": 593.0459594726562, "reward": 0.7123671770095825, "action": 0.004293680191040039}
{"mode": "train", "epochs": 9, "timestep": 17053, "ep_reward": 593.6668090820312, "reward": 0.6208648681640625, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 17054, "ep_reward": 594.1279296875, "reward": 0.4610973000526428, "action": -1.4723892211914062}
{"mode": "train", "epochs": 9, "timestep": 17055, "ep_reward": 594.4756469726562, "reward": 0.3477383255958557, "action": -0.7495865821838379}
{"mode": "train", "epochs": 9, "timestep": 17056, "ep_reward": 594.7128295898438, "reward": 0.23716944456100464, "action": -1.6072359085083008}
{"mode": "train", "epochs": 9, "timestep": 17057, "ep_reward": 594.8197021484375, "reward": 0.10686171054840088, "action": -0.6609019041061401}
{"mode": "train", "epochs": 9, "timestep": 17058, "ep_reward": 594.828857421875, "reward": 0.009159505367279053, "action": -1.4214143753051758}
{"mode": "train", "epochs": 9, "timestep": 17059, "ep_reward": 594.9818115234375, "reward": 0.15292876958847046, "action": -1.064713478088379}
{"mode": "train", "epochs": 9, "timestep": 17060, "ep_reward": 595.2736206054688, "reward": 0.29179155826568604, "action": -0.04459047317504883}
{"mode": "train", "epochs": 9, "timestep": 17061, "ep_reward": 595.713623046875, "reward": 0.44002437591552734, "action": -0.519993782043457}
{"mode": "train", "epochs": 9, "timestep": 17062, "ep_reward": 596.2807006835938, "reward": 0.5670954585075378, "action": -1.3609282970428467}
{"mode": "train", "epochs": 9, "timestep": 17063, "ep_reward": 596.9459228515625, "reward": 0.6652454137802124, "action": -0.4811176061630249}
{"mode": "train", "epochs": 9, "timestep": 17064, "ep_reward": 597.6968383789062, "reward": 0.7509053945541382, "action": -0.7548816800117493}
{"mode": "train", "epochs": 9, "timestep": 17065, "ep_reward": 598.5088500976562, "reward": 0.8120362758636475, "action": -1.1267539262771606}
{"mode": "train", "epochs": 9, "timestep": 17066, "ep_reward": 599.3603515625, "reward": 0.8514946699142456, "action": -0.789440393447876}
{"mode": "train", "epochs": 9, "timestep": 17067, "ep_reward": 600.2381591796875, "reward": 0.877821147441864, "action": 0.2660735845565796}
{"mode": "train", "epochs": 9, "timestep": 17068, "ep_reward": 601.135986328125, "reward": 0.897799015045166, "action": -0.9718422293663025}
{"mode": "train", "epochs": 9, "timestep": 17069, "ep_reward": 602.0313110351562, "reward": 0.8953157067298889, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 17070, "ep_reward": 602.9021606445312, "reward": 0.8708756566047668, "action": -0.8013259768486023}
{"mode": "train", "epochs": 9, "timestep": 17071, "ep_reward": 603.7404174804688, "reward": 0.838230311870575, "action": -1.1318795680999756}
{"mode": "train", "epochs": 9, "timestep": 17072, "ep_reward": 604.5206298828125, "reward": 0.7802070379257202, "action": -1.4880105257034302}
{"mode": "train", "epochs": 9, "timestep": 17073, "ep_reward": 605.208984375, "reward": 0.6883717775344849, "action": -1.9132294654846191}
{"mode": "train", "epochs": 9, "timestep": 17074, "ep_reward": 605.76123046875, "reward": 0.5522174835205078, "action": -0.38873857259750366}
{"mode": "train", "epochs": 9, "timestep": 17075, "ep_reward": 606.1561279296875, "reward": 0.3948964476585388, "action": -1.0468469858169556}
{"mode": "train", "epochs": 9, "timestep": 17076, "ep_reward": 606.4356689453125, "reward": 0.27953433990478516, "action": -0.6085583567619324}
{"mode": "train", "epochs": 9, "timestep": 17077, "ep_reward": 606.5918579101562, "reward": 0.15621894598007202, "action": -1.4156286716461182}
{"mode": "train", "epochs": 9, "timestep": 17078, "ep_reward": 606.6049194335938, "reward": 0.013054966926574707, "action": -1.1065270900726318}
{"mode": "train", "epochs": 9, "timestep": 17079, "ep_reward": 606.7081909179688, "reward": 0.10329139232635498, "action": -1.073167324066162}
{"mode": "train", "epochs": 9, "timestep": 17080, "ep_reward": 606.948974609375, "reward": 0.2407938838005066, "action": 0.034223198890686035}
{"mode": "train", "epochs": 9, "timestep": 17081, "ep_reward": 607.3414306640625, "reward": 0.392461359500885, "action": -0.34261399507522583}
{"mode": "train", "epochs": 9, "timestep": 17082, "ep_reward": 607.8684692382812, "reward": 0.5270662307739258, "action": -1.0417643785476685}
{"mode": "train", "epochs": 9, "timestep": 17083, "ep_reward": 608.5037841796875, "reward": 0.6353099346160889, "action": -1.283518671989441}
{"mode": "train", "epochs": 9, "timestep": 17084, "ep_reward": 609.224365234375, "reward": 0.7205978631973267, "action": -1.2867614030838013}
{"mode": "train", "epochs": 9, "timestep": 17085, "ep_reward": 610.0097045898438, "reward": 0.7853223085403442, "action": -1.1208574771881104}
{"mode": "train", "epochs": 9, "timestep": 17086, "ep_reward": 610.8419799804688, "reward": 0.832281768321991, "action": -1.1237751245498657}
{"mode": "train", "epochs": 9, "timestep": 17087, "ep_reward": 611.7039184570312, "reward": 0.8619284629821777, "action": -1.4220834970474243}
{"mode": "train", "epochs": 9, "timestep": 17088, "ep_reward": 612.5775756835938, "reward": 0.8736619353294373, "action": -1.599489688873291}
{"mode": "train", "epochs": 9, "timestep": 17089, "ep_reward": 613.4462890625, "reward": 0.8686895370483398, "action": -1.1059613227844238}
{"mode": "train", "epochs": 9, "timestep": 17090, "ep_reward": 614.297119140625, "reward": 0.8508416414260864, "action": -0.2522673010826111}
{"mode": "train", "epochs": 9, "timestep": 17091, "ep_reward": 615.1183471679688, "reward": 0.8212281465530396, "action": -0.7500112652778625}
{"mode": "train", "epochs": 9, "timestep": 17092, "ep_reward": 615.8818359375, "reward": 0.7634967565536499, "action": 0.3123701214790344}
{"mode": "train", "epochs": 9, "timestep": 17093, "ep_reward": 616.571044921875, "reward": 0.6892273426055908, "action": -0.7694684267044067}
{"mode": "train", "epochs": 9, "timestep": 17094, "ep_reward": 617.139892578125, "reward": 0.568830668926239, "action": -0.8739563226699829}
{"mode": "train", "epochs": 9, "timestep": 17095, "ep_reward": 617.547607421875, "reward": 0.4077315330505371, "action": -1.1662334203720093}
{"mode": "train", "epochs": 9, "timestep": 17096, "ep_reward": 617.8265380859375, "reward": 0.27894753217697144, "action": -1.0516713857650757}
{"mode": "train", "epochs": 9, "timestep": 17097, "ep_reward": 617.9822387695312, "reward": 0.15568947792053223, "action": -0.5437032580375671}
{"mode": "train", "epochs": 9, "timestep": 17098, "ep_reward": 617.9944458007812, "reward": 0.012212932109832764, "action": -1.728969931602478}
{"mode": "train", "epochs": 9, "timestep": 17099, "ep_reward": 618.0984497070312, "reward": 0.1039772629737854, "action": -0.9703124165534973}
{"mode": "train", "epochs": 9, "timestep": 17100, "ep_reward": 618.3411865234375, "reward": 0.2427615523338318, "action": -0.5913314819335938}
{"mode": "train", "epochs": 9, "timestep": 17101, "ep_reward": 618.7276611328125, "reward": 0.3864527940750122, "action": -1.5038414001464844}
{"mode": "train", "epochs": 9, "timestep": 17102, "ep_reward": 619.2369384765625, "reward": 0.5092476606369019, "action": 0.03874659538269043}
{"mode": "train", "epochs": 9, "timestep": 17103, "ep_reward": 619.869384765625, "reward": 0.6324282884597778, "action": -1.0136516094207764}
{"mode": "train", "epochs": 9, "timestep": 17104, "ep_reward": 620.58984375, "reward": 0.7204753160476685, "action": -1.5099742412567139}
{"mode": "train", "epochs": 9, "timestep": 17105, "ep_reward": 621.372314453125, "reward": 0.7824608087539673, "action": -1.1972761154174805}
{"mode": "train", "epochs": 9, "timestep": 17106, "ep_reward": 622.2001342773438, "reward": 0.827822208404541, "action": -1.4237419366836548}
{"mode": "train", "epochs": 9, "timestep": 17107, "ep_reward": 623.0536499023438, "reward": 0.8535219430923462, "action": -0.971670925617218}
{"mode": "train", "epochs": 9, "timestep": 17108, "ep_reward": 623.920166015625, "reward": 0.8665390610694885, "action": -0.6781824827194214}
{"mode": "train", "epochs": 9, "timestep": 17109, "ep_reward": 624.785888671875, "reward": 0.8656976222991943, "action": -0.5389996767044067}
{"mode": "train", "epochs": 9, "timestep": 17110, "ep_reward": 625.6347045898438, "reward": 0.8488187789916992, "action": -0.8862293362617493}
{"mode": "train", "epochs": 9, "timestep": 17111, "ep_reward": 626.4432373046875, "reward": 0.8085527420043945, "action": -1.4663738012313843}
{"mode": "train", "epochs": 9, "timestep": 17112, "ep_reward": 627.1793212890625, "reward": 0.736061692237854, "action": -1.0491548776626587}
{"mode": "train", "epochs": 9, "timestep": 17113, "ep_reward": 627.8134765625, "reward": 0.6341341733932495, "action": -0.5967048406600952}
{"mode": "train", "epochs": 9, "timestep": 17114, "ep_reward": 628.3126220703125, "reward": 0.49915069341659546, "action": -0.5582613348960876}
{"mode": "train", "epochs": 9, "timestep": 17115, "ep_reward": 628.6617431640625, "reward": 0.34912335872650146, "action": -1.2047455310821533}
{"mode": "train", "epochs": 9, "timestep": 17116, "ep_reward": 628.9006958007812, "reward": 0.23897624015808105, "action": -1.149668574333191}
{"mode": "train", "epochs": 9, "timestep": 17117, "ep_reward": 629.009521484375, "reward": 0.10879749059677124, "action": -1.307042121887207}
{"mode": "train", "epochs": 9, "timestep": 17118, "ep_reward": 629.0165405273438, "reward": 0.007014274597167969, "action": -0.9930689334869385}
{"mode": "train", "epochs": 9, "timestep": 17119, "ep_reward": 629.1675415039062, "reward": 0.15097510814666748, "action": -1.2767452001571655}
{"mode": "train", "epochs": 9, "timestep": 17120, "ep_reward": 629.4546508789062, "reward": 0.2871362566947937, "action": -0.7409431338310242}
{"mode": "train", "epochs": 9, "timestep": 17121, "ep_reward": 629.8822631835938, "reward": 0.42762577533721924, "action": -1.5804336071014404}
{"mode": "train", "epochs": 9, "timestep": 17122, "ep_reward": 630.427490234375, "reward": 0.545202910900116, "action": -1.442672848701477}
{"mode": "train", "epochs": 9, "timestep": 17123, "ep_reward": 631.0736694335938, "reward": 0.6462013721466064, "action": -0.6117205023765564}
{"mode": "train", "epochs": 9, "timestep": 17124, "ep_reward": 631.8069458007812, "reward": 0.7332931756973267, "action": -1.192140817642212}
{"mode": "train", "epochs": 9, "timestep": 17125, "ep_reward": 632.5982666015625, "reward": 0.7913320064544678, "action": -0.5744990110397339}
{"mode": "train", "epochs": 9, "timestep": 17126, "ep_reward": 633.4324340820312, "reward": 0.8341786861419678, "action": -1.5084189176559448}
{"mode": "train", "epochs": 9, "timestep": 17127, "ep_reward": 634.2825317382812, "reward": 0.8500806093215942, "action": -1.1220703125}
{"mode": "train", "epochs": 9, "timestep": 17128, "ep_reward": 635.134033203125, "reward": 0.8515310287475586, "action": -1.3694038391113281}
{"mode": "train", "epochs": 9, "timestep": 17129, "ep_reward": 635.965576171875, "reward": 0.8315709233283997, "action": -1.0355379581451416}
{"mode": "train", "epochs": 9, "timestep": 17130, "ep_reward": 636.7576904296875, "reward": 0.7920994758605957, "action": -0.788253128528595}
{"mode": "train", "epochs": 9, "timestep": 17131, "ep_reward": 637.4853515625, "reward": 0.727637529373169, "action": -0.8830654621124268}
{"mode": "train", "epochs": 9, "timestep": 17132, "ep_reward": 638.113525390625, "reward": 0.6281657218933105, "action": -0.8656718134880066}
{"mode": "train", "epochs": 9, "timestep": 17133, "ep_reward": 638.6021728515625, "reward": 0.48862314224243164, "action": -1.175283670425415}
{"mode": "train", "epochs": 9, "timestep": 17134, "ep_reward": 638.956787109375, "reward": 0.3546137809753418, "action": -0.9158526659011841}
{"mode": "train", "epochs": 9, "timestep": 17135, "ep_reward": 639.202392578125, "reward": 0.24557572603225708, "action": -0.6924344897270203}
{"mode": "train", "epochs": 9, "timestep": 17136, "ep_reward": 639.3189086914062, "reward": 0.1164969801902771, "action": -0.8833915591239929}
{"mode": "train", "epochs": 9, "timestep": 17137, "ep_reward": 639.3173828125, "reward": -0.0015403032302856445, "action": -1.5840635299682617}
{"mode": "train", "epochs": 9, "timestep": 17138, "ep_reward": 639.4611206054688, "reward": 0.14371126890182495, "action": -0.13230770826339722}
{"mode": "train", "epochs": 9, "timestep": 17139, "ep_reward": 639.7548217773438, "reward": 0.2936849594116211, "action": -1.7147796154022217}
{"mode": "train", "epochs": 9, "timestep": 17140, "ep_reward": 640.1749267578125, "reward": 0.42010432481765747, "action": -1.6508448123931885}
{"mode": "train", "epochs": 9, "timestep": 17141, "ep_reward": 640.7125854492188, "reward": 0.5376808643341064, "action": -1.0704020261764526}
{"mode": "train", "epochs": 9, "timestep": 17142, "ep_reward": 641.3565673828125, "reward": 0.6439809799194336, "action": -1.4286987781524658}
{"mode": "train", "epochs": 9, "timestep": 17143, "ep_reward": 642.0807495117188, "reward": 0.7241758108139038, "action": -0.717505693435669}
{"mode": "train", "epochs": 9, "timestep": 17144, "ep_reward": 642.8697509765625, "reward": 0.7890238165855408, "action": -0.22906219959259033}
{"mode": "train", "epochs": 9, "timestep": 17145, "ep_reward": 643.7063598632812, "reward": 0.8366165161132812, "action": -1.139411449432373}
{"mode": "train", "epochs": 9, "timestep": 17146, "ep_reward": 644.5639038085938, "reward": 0.8575597405433655, "action": -0.6152083277702332}
{"mode": "train", "epochs": 9, "timestep": 17147, "ep_reward": 645.4301147460938, "reward": 0.8661949038505554, "action": -0.17795443534851074}
{"mode": "train", "epochs": 9, "timestep": 17148, "ep_reward": 646.291748046875, "reward": 0.8616504669189453, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 17149, "ep_reward": 647.11376953125, "reward": 0.8220498561859131, "action": -1.609628677368164}
{"mode": "train", "epochs": 9, "timestep": 17150, "ep_reward": 647.8740234375, "reward": 0.7602676153182983, "action": -1.1568896770477295}
{"mode": "train", "epochs": 9, "timestep": 17151, "ep_reward": 648.5450439453125, "reward": 0.6710172891616821, "action": -0.8399732112884521}
{"mode": "train", "epochs": 9, "timestep": 17152, "ep_reward": 649.0924072265625, "reward": 0.5473687648773193, "action": -0.6332167387008667}
{"mode": "train", "epochs": 9, "timestep": 17153, "ep_reward": 649.47998046875, "reward": 0.3875778913497925, "action": -1.1146347522735596}
{"mode": "train", "epochs": 9, "timestep": 17154, "ep_reward": 649.7654418945312, "reward": 0.28548264503479004, "action": -0.4554148316383362}
{"mode": "train", "epochs": 9, "timestep": 17155, "ep_reward": 649.9287109375, "reward": 0.16325461864471436, "action": -1.1427321434020996}
{"mode": "train", "epochs": 9, "timestep": 17156, "ep_reward": 649.9498901367188, "reward": 0.021155238151550293, "action": -0.5956264734268188}
{"mode": "train", "epochs": 9, "timestep": 17157, "ep_reward": 650.045654296875, "reward": 0.09578263759613037, "action": -1.4190726280212402}
{"mode": "train", "epochs": 9, "timestep": 17158, "ep_reward": 650.2744140625, "reward": 0.2287508249282837, "action": -0.040956854820251465}
{"mode": "train", "epochs": 9, "timestep": 17159, "ep_reward": 650.6550903320312, "reward": 0.3806842565536499, "action": -1.3512942790985107}
{"mode": "train", "epochs": 9, "timestep": 17160, "ep_reward": 651.1607055664062, "reward": 0.5056005716323853, "action": -1.4576492309570312}
{"mode": "train", "epochs": 9, "timestep": 17161, "ep_reward": 651.7738647460938, "reward": 0.6131854057312012, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 17162, "ep_reward": 652.4686889648438, "reward": 0.6948378086090088, "action": -0.9817647933959961}
{"mode": "train", "epochs": 9, "timestep": 17163, "ep_reward": 653.23388671875, "reward": 0.7652143239974976, "action": -0.8653828501701355}
{"mode": "train", "epochs": 9, "timestep": 17164, "ep_reward": 654.0482177734375, "reward": 0.8143041133880615, "action": -1.7201857566833496}
{"mode": "train", "epochs": 9, "timestep": 17165, "ep_reward": 654.8840942382812, "reward": 0.8358873724937439, "action": -0.6976104974746704}
{"mode": "train", "epochs": 9, "timestep": 17166, "ep_reward": 655.7320556640625, "reward": 0.8479797840118408, "action": -0.6093779802322388}
{"mode": "train", "epochs": 9, "timestep": 17167, "ep_reward": 656.5737915039062, "reward": 0.8417236804962158, "action": -1.8564766645431519}
{"mode": "train", "epochs": 9, "timestep": 17168, "ep_reward": 657.376220703125, "reward": 0.8023993968963623, "action": -0.5448278188705444}
{"mode": "train", "epochs": 9, "timestep": 17169, "ep_reward": 658.1258544921875, "reward": 0.7496265172958374, "action": -1.7444137334823608}
{"mode": "train", "epochs": 9, "timestep": 17170, "ep_reward": 658.7759399414062, "reward": 0.6501072645187378, "action": -1.2680729627609253}
{"mode": "train", "epochs": 9, "timestep": 17171, "ep_reward": 659.2901611328125, "reward": 0.5142117738723755, "action": -1.694761872291565}
{"mode": "train", "epochs": 9, "timestep": 17172, "ep_reward": 659.6708374023438, "reward": 0.38068515062332153, "action": -1.108201503753662}
{"mode": "train", "epochs": 9, "timestep": 17173, "ep_reward": 659.9478759765625, "reward": 0.2770688533782959, "action": -0.8862411975860596}
{"mode": "train", "epochs": 9, "timestep": 17174, "ep_reward": 660.1012573242188, "reward": 0.15336811542510986, "action": -1.3050748109817505}
{"mode": "train", "epochs": 9, "timestep": 17175, "ep_reward": 660.1110229492188, "reward": 0.009795427322387695, "action": -0.7629343271255493}
{"mode": "train", "epochs": 9, "timestep": 17176, "ep_reward": 660.2173461914062, "reward": 0.10634386539459229, "action": -0.8591029644012451}
{"mode": "train", "epochs": 9, "timestep": 17177, "ep_reward": 660.4638671875, "reward": 0.2465144395828247, "action": -1.1670856475830078}
{"mode": "train", "epochs": 9, "timestep": 17178, "ep_reward": 660.8468017578125, "reward": 0.38292378187179565, "action": -1.1206231117248535}
{"mode": "train", "epochs": 9, "timestep": 17179, "ep_reward": 661.3577880859375, "reward": 0.5109825134277344, "action": -0.08689522743225098}
{"mode": "train", "epochs": 9, "timestep": 17180, "ep_reward": 661.9903564453125, "reward": 0.6325924396514893, "action": -0.8172097206115723}
{"mode": "train", "epochs": 9, "timestep": 17181, "ep_reward": 662.7127075195312, "reward": 0.7223385572433472, "action": -1.6197528839111328}
{"mode": "train", "epochs": 9, "timestep": 17182, "ep_reward": 663.4954223632812, "reward": 0.7826985716819763, "action": -1.4665827751159668}
{"mode": "train", "epochs": 9, "timestep": 17183, "ep_reward": 664.3206176757812, "reward": 0.8251855969429016, "action": -1.7323329448699951}
{"mode": "train", "epochs": 9, "timestep": 17184, "ep_reward": 665.1682739257812, "reward": 0.8476799726486206, "action": -1.0098532438278198}
{"mode": "train", "epochs": 9, "timestep": 17185, "ep_reward": 666.027587890625, "reward": 0.8592892289161682, "action": -0.8292036056518555}
{"mode": "train", "epochs": 9, "timestep": 17186, "ep_reward": 666.8826904296875, "reward": 0.8551092147827148, "action": -0.6974484324455261}
{"mode": "train", "epochs": 9, "timestep": 17187, "ep_reward": 667.7160034179688, "reward": 0.8333366513252258, "action": -0.8938170671463013}
{"mode": "train", "epochs": 9, "timestep": 17188, "ep_reward": 668.5034790039062, "reward": 0.7874965667724609, "action": -0.15883606672286987}
{"mode": "train", "epochs": 9, "timestep": 17189, "ep_reward": 669.2258911132812, "reward": 0.722419023513794, "action": -0.8102269172668457}
{"mode": "train", "epochs": 9, "timestep": 17190, "ep_reward": 669.843017578125, "reward": 0.6171078085899353, "action": -1.2895927429199219}
{"mode": "train", "epochs": 9, "timestep": 17191, "ep_reward": 670.3082275390625, "reward": 0.46520763635635376, "action": -0.1585744023323059}
{"mode": "train", "epochs": 9, "timestep": 17192, "ep_reward": 670.6382446289062, "reward": 0.3300091624259949, "action": -0.9830016493797302}
{"mode": "train", "epochs": 9, "timestep": 17193, "ep_reward": 670.8543701171875, "reward": 0.21614277362823486, "action": -0.5504733324050903}
{"mode": "train", "epochs": 9, "timestep": 17194, "ep_reward": 670.9365844726562, "reward": 0.08218473196029663, "action": -1.0569374561309814}
{"mode": "train", "epochs": 9, "timestep": 17195, "ep_reward": 670.9720458984375, "reward": 0.035436809062957764, "action": -1.7096014022827148}
{"mode": "train", "epochs": 9, "timestep": 17196, "ep_reward": 671.1478881835938, "reward": 0.1758406162261963, "action": -0.662415623664856}
{"mode": "train", "epochs": 9, "timestep": 17197, "ep_reward": 671.4678344726562, "reward": 0.31995946168899536, "action": -1.4657394886016846}
{"mode": "train", "epochs": 9, "timestep": 17198, "ep_reward": 671.916748046875, "reward": 0.44889283180236816, "action": -1.4275401830673218}
{"mode": "train", "epochs": 9, "timestep": 17199, "ep_reward": 672.4823608398438, "reward": 0.5655961036682129, "action": -1.00989830493927}
{"mode": "train", "epochs": 9, "timestep": 17200, "ep_reward": 673.1495971679688, "reward": 0.6672144532203674, "action": -0.3192812204360962}
{"mode": "train", "epochs": 9, "timestep": 17201, "ep_reward": 673.9017944335938, "reward": 0.7521819472312927, "action": -1.1510154008865356}
{"mode": "train", "epochs": 9, "timestep": 17202, "ep_reward": 674.7080078125, "reward": 0.8061941862106323, "action": -0.8031189441680908}
{"mode": "train", "epochs": 9, "timestep": 17203, "ep_reward": 675.5517578125, "reward": 0.8437553644180298, "action": -0.5136426687240601}
{"mode": "train", "epochs": 9, "timestep": 17204, "ep_reward": 676.4177856445312, "reward": 0.8660123944282532, "action": -0.6589248776435852}
{"mode": "train", "epochs": 9, "timestep": 17205, "ep_reward": 677.2885131835938, "reward": 0.8707178831100464, "action": -0.6876156330108643}
{"mode": "train", "epochs": 9, "timestep": 17206, "ep_reward": 678.1471557617188, "reward": 0.8586443066596985, "action": -1.4746100902557373}
{"mode": "train", "epochs": 9, "timestep": 17207, "ep_reward": 678.9673461914062, "reward": 0.8202091455459595, "action": -1.7690000534057617}
{"mode": "train", "epochs": 9, "timestep": 17208, "ep_reward": 679.7202758789062, "reward": 0.7529557943344116, "action": -1.096318006515503}
{"mode": "train", "epochs": 9, "timestep": 17209, "ep_reward": 680.3798828125, "reward": 0.6596299409866333, "action": -1.9986214637756348}
{"mode": "train", "epochs": 9, "timestep": 17210, "ep_reward": 680.8934936523438, "reward": 0.5135980844497681, "action": -1.38486909866333}
{"mode": "train", "epochs": 9, "timestep": 17211, "ep_reward": 681.2666015625, "reward": 0.37308984994888306, "action": -0.8651868104934692}
{"mode": "train", "epochs": 9, "timestep": 17212, "ep_reward": 681.534423828125, "reward": 0.2678527235984802, "action": -0.6365712881088257}
{"mode": "train", "epochs": 9, "timestep": 17213, "ep_reward": 681.6768188476562, "reward": 0.14241057634353638, "action": -1.830956220626831}
{"mode": "train", "epochs": 9, "timestep": 17214, "ep_reward": 681.674072265625, "reward": -0.002736687660217285, "action": -1.2608628273010254}
{"mode": "train", "epochs": 9, "timestep": 17215, "ep_reward": 681.7916259765625, "reward": 0.11758005619049072, "action": -1.191090703010559}
{"mode": "train", "epochs": 9, "timestep": 17216, "ep_reward": 682.0455322265625, "reward": 0.25389981269836426, "action": -1.377556324005127}
{"mode": "train", "epochs": 9, "timestep": 17217, "ep_reward": 682.4337158203125, "reward": 0.38816601037979126, "action": -0.8583475351333618}
{"mode": "train", "epochs": 9, "timestep": 17218, "ep_reward": 682.9529418945312, "reward": 0.5192166566848755, "action": -0.8668777346611023}
{"mode": "train", "epochs": 9, "timestep": 17219, "ep_reward": 683.5840454101562, "reward": 0.6311215162277222, "action": -0.8173568844795227}
{"mode": "train", "epochs": 9, "timestep": 17220, "ep_reward": 684.3045654296875, "reward": 0.7205145359039307, "action": -1.2781343460083008}
{"mode": "train", "epochs": 9, "timestep": 17221, "ep_reward": 685.0872192382812, "reward": 0.7826738953590393, "action": -0.5745206475257874}
{"mode": "train", "epochs": 9, "timestep": 17222, "ep_reward": 685.9177856445312, "reward": 0.8305512070655823, "action": -1.0597692728042603}
{"mode": "train", "epochs": 9, "timestep": 17223, "ep_reward": 686.7732543945312, "reward": 0.8554720878601074, "action": -0.36018306016921997}
{"mode": "train", "epochs": 9, "timestep": 17224, "ep_reward": 687.642578125, "reward": 0.8693419694900513, "action": -1.4406921863555908}
{"mode": "train", "epochs": 9, "timestep": 17225, "ep_reward": 688.5, "reward": 0.8574423789978027, "action": -1.3164883852005005}
{"mode": "train", "epochs": 9, "timestep": 17226, "ep_reward": 689.3274536132812, "reward": 0.8274266123771667, "action": -0.7922520041465759}
{"mode": "train", "epochs": 9, "timestep": 17227, "ep_reward": 690.1063232421875, "reward": 0.7788914442062378, "action": -1.8413665294647217}
{"mode": "train", "epochs": 9, "timestep": 17228, "ep_reward": 690.7950439453125, "reward": 0.6887352466583252, "action": -1.5927995443344116}
{"mode": "train", "epochs": 9, "timestep": 17229, "ep_reward": 691.3565063476562, "reward": 0.5614472031593323, "action": -0.7316848635673523}
{"mode": "train", "epochs": 9, "timestep": 17230, "ep_reward": 691.7588500976562, "reward": 0.4023730158805847, "action": -0.940775454044342}
{"mode": "train", "epochs": 9, "timestep": 17231, "ep_reward": 692.0618286132812, "reward": 0.30298012495040894, "action": -0.6554286479949951}
{"mode": "train", "epochs": 9, "timestep": 17232, "ep_reward": 692.2457885742188, "reward": 0.18394428491592407, "action": -1.0619441270828247}
{"mode": "train", "epochs": 9, "timestep": 17233, "ep_reward": 692.2907104492188, "reward": 0.0448993444442749, "action": -1.4078145027160645}
{"mode": "train", "epochs": 9, "timestep": 17234, "ep_reward": 692.36376953125, "reward": 0.07305347919464111, "action": -1.367775321006775}
{"mode": "train", "epochs": 9, "timestep": 17235, "ep_reward": 692.572021484375, "reward": 0.20826643705368042, "action": -1.044049859046936}
{"mode": "train", "epochs": 9, "timestep": 17236, "ep_reward": 692.920166015625, "reward": 0.3481152057647705, "action": -0.9706588983535767}
{"mode": "train", "epochs": 9, "timestep": 17237, "ep_reward": 693.40185546875, "reward": 0.4816845655441284, "action": -0.638304591178894}
{"mode": "train", "epochs": 9, "timestep": 17238, "ep_reward": 694.004150390625, "reward": 0.602289617061615, "action": -1.3896816968917847}
{"mode": "train", "epochs": 9, "timestep": 17239, "ep_reward": 694.69677734375, "reward": 0.6926454305648804, "action": -1.099150538444519}
{"mode": "train", "epochs": 9, "timestep": 17240, "ep_reward": 695.4605712890625, "reward": 0.7638139128684998, "action": -1.1413289308547974}
{"mode": "train", "epochs": 9, "timestep": 17241, "ep_reward": 696.2737426757812, "reward": 0.8131521940231323, "action": -0.8580701351165771}
{"mode": "train", "epochs": 9, "timestep": 17242, "ep_reward": 697.1192626953125, "reward": 0.8455443978309631, "action": -1.111217975616455}
{"mode": "train", "epochs": 9, "timestep": 17243, "ep_reward": 697.9771728515625, "reward": 0.8578993082046509, "action": -1.2405786514282227}
{"mode": "train", "epochs": 9, "timestep": 17244, "ep_reward": 698.82861328125, "reward": 0.851464033126831, "action": -1.8608157634735107}
{"mode": "train", "epochs": 9, "timestep": 17245, "ep_reward": 699.6480102539062, "reward": 0.8194084763526917, "action": -1.1846246719360352}
{"mode": "train", "epochs": 9, "timestep": 17246, "ep_reward": 700.4166870117188, "reward": 0.7686930894851685, "action": -1.7856379747390747}
{"mode": "train", "epochs": 9, "timestep": 17247, "ep_reward": 701.0960693359375, "reward": 0.6793814897537231, "action": -1.1293258666992188}
{"mode": "train", "epochs": 9, "timestep": 17248, "ep_reward": 701.6538696289062, "reward": 0.5577920079231262, "action": -1.882591724395752}
{"mode": "train", "epochs": 9, "timestep": 17249, "ep_reward": 702.0604858398438, "reward": 0.40663301944732666, "action": -1.3891851902008057}
{"mode": "train", "epochs": 9, "timestep": 17250, "ep_reward": 702.3692016601562, "reward": 0.30869799852371216, "action": -1.4844521284103394}
{"mode": "train", "epochs": 9, "timestep": 17251, "ep_reward": 702.5599975585938, "reward": 0.19077515602111816, "action": -1.5141937732696533}
{"mode": "train", "epochs": 9, "timestep": 17252, "ep_reward": 702.6129150390625, "reward": 0.05294239521026611, "action": -0.9745686054229736}
{"mode": "train", "epochs": 9, "timestep": 17253, "ep_reward": 702.67822265625, "reward": 0.06530201435089111, "action": 0.7789301872253418}
{"mode": "train", "epochs": 9, "timestep": 17254, "ep_reward": 702.9026489257812, "reward": 0.22442811727523804, "action": -1.1284234523773193}
{"mode": "train", "epochs": 9, "timestep": 17255, "ep_reward": 703.2611083984375, "reward": 0.3584432005882263, "action": -1.3634902238845825}
{"mode": "train", "epochs": 9, "timestep": 17256, "ep_reward": 703.7451171875, "reward": 0.48400187492370605, "action": 0.11642873287200928}
{"mode": "train", "epochs": 9, "timestep": 17257, "ep_reward": 704.3565063476562, "reward": 0.6113754510879517, "action": -1.0482873916625977}
{"mode": "train", "epochs": 9, "timestep": 17258, "ep_reward": 705.0606689453125, "reward": 0.704157829284668, "action": -0.7396091818809509}
{"mode": "train", "epochs": 9, "timestep": 17259, "ep_reward": 705.839599609375, "reward": 0.7789344787597656, "action": -0.15195238590240479}
{"mode": "train", "epochs": 9, "timestep": 17260, "ep_reward": 706.6779174804688, "reward": 0.8383306860923767, "action": -1.0110735893249512}
{"mode": "train", "epochs": 9, "timestep": 17261, "ep_reward": 707.551513671875, "reward": 0.8735861778259277, "action": -1.357404112815857}
{"mode": "train", "epochs": 9, "timestep": 17262, "ep_reward": 708.4443359375, "reward": 0.8928446173667908, "action": -1.0358963012695312}
{"mode": "train", "epochs": 9, "timestep": 17263, "ep_reward": 709.3466186523438, "reward": 0.9022629857063293, "action": -1.114176869392395}
{"mode": "train", "epochs": 9, "timestep": 17264, "ep_reward": 710.2457275390625, "reward": 0.8991261124610901, "action": -0.9303291440010071}
{"mode": "train", "epochs": 9, "timestep": 17265, "ep_reward": 711.1298217773438, "reward": 0.884121835231781, "action": -1.32841956615448}
{"mode": "train", "epochs": 9, "timestep": 17266, "ep_reward": 711.9796752929688, "reward": 0.8498387336730957, "action": -0.5584722757339478}
{"mode": "train", "epochs": 9, "timestep": 17267, "ep_reward": 712.7814331054688, "reward": 0.8017439842224121, "action": -0.7780478000640869}
{"mode": "train", "epochs": 9, "timestep": 17268, "ep_reward": 713.50732421875, "reward": 0.7259063720703125, "action": -0.6117904186248779}
{"mode": "train", "epochs": 9, "timestep": 17269, "ep_reward": 714.1272583007812, "reward": 0.6199402809143066, "action": -0.7228480577468872}
{"mode": "train", "epochs": 9, "timestep": 17270, "ep_reward": 714.6030883789062, "reward": 0.4758341312408447, "action": -0.9263274669647217}
{"mode": "train", "epochs": 9, "timestep": 17271, "ep_reward": 714.9151611328125, "reward": 0.31205523014068604, "action": -0.41550981998443604}
{"mode": "train", "epochs": 9, "timestep": 17272, "ep_reward": 715.10986328125, "reward": 0.19467824697494507, "action": -1.0638248920440674}
{"mode": "train", "epochs": 9, "timestep": 17273, "ep_reward": 715.1671142578125, "reward": 0.05725473165512085, "action": -1.686790943145752}
{"mode": "train", "epochs": 9, "timestep": 17274, "ep_reward": 715.2278442382812, "reward": 0.06073319911956787, "action": -1.8248960971832275}
{"mode": "train", "epochs": 9, "timestep": 17275, "ep_reward": 715.4255981445312, "reward": 0.1977614164352417, "action": -0.5540275573730469}
{"mode": "train", "epochs": 9, "timestep": 17276, "ep_reward": 715.7691650390625, "reward": 0.3435761332511902, "action": -0.8144558668136597}
{"mode": "train", "epochs": 9, "timestep": 17277, "ep_reward": 716.2477416992188, "reward": 0.4785539507865906, "action": -0.08743906021118164}
{"mode": "train", "epochs": 9, "timestep": 17278, "ep_reward": 716.85302734375, "reward": 0.6052622199058533, "action": -0.7366807460784912}
{"mode": "train", "epochs": 9, "timestep": 17279, "ep_reward": 717.5551147460938, "reward": 0.7020846605300903, "action": -0.7311400175094604}
{"mode": "train", "epochs": 9, "timestep": 17280, "ep_reward": 718.3318481445312, "reward": 0.7767181396484375, "action": -0.6574433445930481}
{"mode": "train", "epochs": 9, "timestep": 17281, "ep_reward": 719.163330078125, "reward": 0.8314582109451294, "action": -0.918445885181427}
{"mode": "train", "epochs": 9, "timestep": 17282, "ep_reward": 720.0298461914062, "reward": 0.8665016293525696, "action": -1.1019489765167236}
{"mode": "train", "epochs": 9, "timestep": 17283, "ep_reward": 720.9152221679688, "reward": 0.8854005932807922, "action": -1.1132137775421143}
{"mode": "train", "epochs": 9, "timestep": 17284, "ep_reward": 721.8060302734375, "reward": 0.890819787979126, "action": -0.7806527614593506}
{"mode": "train", "epochs": 9, "timestep": 17285, "ep_reward": 722.6912231445312, "reward": 0.8851928114891052, "action": -0.49968183040618896}
{"mode": "train", "epochs": 9, "timestep": 17286, "ep_reward": 723.55810546875, "reward": 0.8669013977050781, "action": -0.8102154731750488}
{"mode": "train", "epochs": 9, "timestep": 17287, "ep_reward": 724.3861083984375, "reward": 0.8280181288719177, "action": -1.5253691673278809}
{"mode": "train", "epochs": 9, "timestep": 17288, "ep_reward": 725.1444091796875, "reward": 0.7582899332046509, "action": -1.032627820968628}
{"mode": "train", "epochs": 9, "timestep": 17289, "ep_reward": 725.8063354492188, "reward": 0.661920964717865, "action": -1.211868166923523}
{"mode": "train", "epochs": 9, "timestep": 17290, "ep_reward": 726.3316650390625, "reward": 0.525321364402771, "action": -0.9994317293167114}
{"mode": "train", "epochs": 9, "timestep": 17291, "ep_reward": 726.6879272460938, "reward": 0.3562893867492676, "action": -1.1118651628494263}
{"mode": "train", "epochs": 9, "timestep": 17292, "ep_reward": 726.935546875, "reward": 0.24759286642074585, "action": -0.9558854699134827}
{"mode": "train", "epochs": 9, "timestep": 17293, "ep_reward": 727.054443359375, "reward": 0.11887127161026001, "action": -1.001147747039795}
{"mode": "train", "epochs": 9, "timestep": 17294, "ep_reward": 727.0504150390625, "reward": -0.0040585994720458984, "action": -0.29453045129776}
{"mode": "train", "epochs": 9, "timestep": 17295, "ep_reward": 727.1917724609375, "reward": 0.14138585329055786, "action": -0.09506595134735107}
{"mode": "train", "epochs": 9, "timestep": 17296, "ep_reward": 727.483642578125, "reward": 0.29188233613967896, "action": -0.9927698969841003}
{"mode": "train", "epochs": 9, "timestep": 17297, "ep_reward": 727.91064453125, "reward": 0.42700082063674927, "action": -0.2937996983528137}
{"mode": "train", "epochs": 9, "timestep": 17298, "ep_reward": 728.4688720703125, "reward": 0.5582175254821777, "action": 0.0711979866027832}
{"mode": "train", "epochs": 9, "timestep": 17299, "ep_reward": 729.14111328125, "reward": 0.6722128391265869, "action": -0.316494345664978}
{"mode": "train", "epochs": 9, "timestep": 17300, "ep_reward": 729.899658203125, "reward": 0.7585715055465698, "action": -0.7795929908752441}
{"mode": "train", "epochs": 9, "timestep": 17301, "ep_reward": 730.719482421875, "reward": 0.819807767868042, "action": -1.1362621784210205}
{"mode": "train", "epochs": 9, "timestep": 17302, "ep_reward": 731.5804443359375, "reward": 0.8609718680381775, "action": -1.3488844633102417}
{"mode": "train", "epochs": 9, "timestep": 17303, "ep_reward": 732.4669189453125, "reward": 0.8865031599998474, "action": -0.9650941491127014}
{"mode": "train", "epochs": 9, "timestep": 17304, "ep_reward": 733.3692016601562, "reward": 0.9022557139396667, "action": -1.7851364612579346}
{"mode": "train", "epochs": 9, "timestep": 17305, "ep_reward": 734.2699584960938, "reward": 0.9007373452186584, "action": -0.5565231442451477}
{"mode": "train", "epochs": 9, "timestep": 17306, "ep_reward": 735.1657104492188, "reward": 0.8957338929176331, "action": -0.5904940962791443}
{"mode": "train", "epochs": 9, "timestep": 17307, "ep_reward": 736.0426025390625, "reward": 0.87686687707901, "action": -0.6302036643028259}
{"mode": "train", "epochs": 9, "timestep": 17308, "ep_reward": 736.8836669921875, "reward": 0.8410449624061584, "action": -1.6300158500671387}
{"mode": "train", "epochs": 9, "timestep": 17309, "ep_reward": 737.6574096679688, "reward": 0.773750901222229, "action": -0.5909850597381592}
{"mode": "train", "epochs": 9, "timestep": 17310, "ep_reward": 738.3447875976562, "reward": 0.6873778104782104, "action": -1.8664367198944092}
{"mode": "train", "epochs": 9, "timestep": 17311, "ep_reward": 738.8941650390625, "reward": 0.5493640303611755, "action": -0.16734981536865234}
{"mode": "train", "epochs": 9, "timestep": 17312, "ep_reward": 739.2886352539062, "reward": 0.39448899030685425, "action": -0.761734127998352}
{"mode": "train", "epochs": 9, "timestep": 17313, "ep_reward": 739.5517578125, "reward": 0.26309794187545776, "action": -1.1754895448684692}
{"mode": "train", "epochs": 9, "timestep": 17314, "ep_reward": 739.6888427734375, "reward": 0.13705694675445557, "action": -0.9618435502052307}
{"mode": "train", "epochs": 9, "timestep": 17315, "ep_reward": 739.6798706054688, "reward": -0.008956193923950195, "action": -0.18204432725906372}
{"mode": "train", "epochs": 9, "timestep": 17316, "ep_reward": 739.8031005859375, "reward": 0.12324857711791992, "action": -0.8021836280822754}
{"mode": "train", "epochs": 9, "timestep": 17317, "ep_reward": 740.0677490234375, "reward": 0.26462286710739136, "action": -0.8395428657531738}
{"mode": "train", "epochs": 9, "timestep": 17318, "ep_reward": 740.4718017578125, "reward": 0.4040331244468689, "action": -1.74351167678833}
{"mode": "train", "epochs": 9, "timestep": 17319, "ep_reward": 740.9940795898438, "reward": 0.5222489833831787, "action": -0.8477700352668762}
{"mode": "train", "epochs": 9, "timestep": 17320, "ep_reward": 741.6278686523438, "reward": 0.6337615847587585, "action": -1.232444167137146}
{"mode": "train", "epochs": 9, "timestep": 17321, "ep_reward": 742.3464965820312, "reward": 0.7186272740364075, "action": -0.7094147205352783}
{"mode": "train", "epochs": 9, "timestep": 17322, "ep_reward": 743.132568359375, "reward": 0.7860878109931946, "action": -1.2082781791687012}
{"mode": "train", "epochs": 9, "timestep": 17323, "ep_reward": 743.9605712890625, "reward": 0.8280125260353088, "action": -0.5872138738632202}
{"mode": "train", "epochs": 9, "timestep": 17324, "ep_reward": 744.8174438476562, "reward": 0.8568422794342041, "action": -1.1577666997909546}
{"mode": "train", "epochs": 9, "timestep": 17325, "ep_reward": 745.6810302734375, "reward": 0.8636005520820618, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 17326, "ep_reward": 746.5267944335938, "reward": 0.8457528948783875, "action": -1.0281260013580322}
{"mode": "train", "epochs": 9, "timestep": 17327, "ep_reward": 747.3427124023438, "reward": 0.815910279750824, "action": -1.2762421369552612}
{"mode": "train", "epochs": 9, "timestep": 17328, "ep_reward": 748.10107421875, "reward": 0.7583815455436707, "action": -1.0995163917541504}
{"mode": "train", "epochs": 9, "timestep": 17329, "ep_reward": 748.7717895507812, "reward": 0.67072594165802, "action": -0.7258633375167847}
{"mode": "train", "epochs": 9, "timestep": 17330, "ep_reward": 749.3212890625, "reward": 0.5494846105575562, "action": -0.9111875295639038}
{"mode": "train", "epochs": 9, "timestep": 17331, "ep_reward": 749.712646484375, "reward": 0.39134132862091064, "action": -1.2186310291290283}
{"mode": "train", "epochs": 9, "timestep": 17332, "ep_reward": 750.0025634765625, "reward": 0.28993719816207886, "action": -1.6032909154891968}
{"mode": "train", "epochs": 9, "timestep": 17333, "ep_reward": 750.1712036132812, "reward": 0.16866081953048706, "action": -1.2729356288909912}
{"mode": "train", "epochs": 9, "timestep": 17334, "ep_reward": 750.1986083984375, "reward": 0.02738511562347412, "action": -0.8184618949890137}
{"mode": "train", "epochs": 9, "timestep": 17335, "ep_reward": 750.28857421875, "reward": 0.08998990058898926, "action": -0.9263733625411987}
{"mode": "train", "epochs": 9, "timestep": 17336, "ep_reward": 750.5172729492188, "reward": 0.22867822647094727, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 17337, "ep_reward": 750.8728637695312, "reward": 0.3555721640586853, "action": -1.3474291563034058}
{"mode": "train", "epochs": 9, "timestep": 17338, "ep_reward": 751.3576049804688, "reward": 0.48473691940307617, "action": -0.724001407623291}
{"mode": "train", "epochs": 9, "timestep": 17339, "ep_reward": 751.9617919921875, "reward": 0.6041648387908936, "action": -1.6178946495056152}
{"mode": "train", "epochs": 9, "timestep": 17340, "ep_reward": 752.6527099609375, "reward": 0.6909022331237793, "action": -0.614405632019043}
{"mode": "train", "epochs": 9, "timestep": 17341, "ep_reward": 753.4175415039062, "reward": 0.7648487687110901, "action": -0.8016595840454102}
{"mode": "train", "epochs": 9, "timestep": 17342, "ep_reward": 754.2312622070312, "reward": 0.8137138485908508, "action": -1.4965249300003052}
{"mode": "train", "epochs": 9, "timestep": 17343, "ep_reward": 755.0673828125, "reward": 0.8361109495162964, "action": -0.5755248069763184}
{"mode": "train", "epochs": 9, "timestep": 17344, "ep_reward": 755.9151611328125, "reward": 0.8477925658226013, "action": -1.5567162036895752}
{"mode": "train", "epochs": 9, "timestep": 17345, "ep_reward": 756.7462158203125, "reward": 0.8310337066650391, "action": -1.4511562585830688}
{"mode": "train", "epochs": 9, "timestep": 17346, "ep_reward": 757.53857421875, "reward": 0.7923523783683777, "action": -0.5250140428543091}
{"mode": "train", "epochs": 9, "timestep": 17347, "ep_reward": 758.2742919921875, "reward": 0.7357077598571777, "action": -1.6414623260498047}
{"mode": "train", "epochs": 9, "timestep": 17348, "ep_reward": 758.906005859375, "reward": 0.6316913366317749, "action": -1.4805413484573364}
{"mode": "train", "epochs": 9, "timestep": 17349, "ep_reward": 759.3919067382812, "reward": 0.4859156608581543, "action": -1.3083691596984863}
{"mode": "train", "epochs": 9, "timestep": 17350, "ep_reward": 759.75927734375, "reward": 0.36736321449279785, "action": -1.2060356140136719}
{"mode": "train", "epochs": 9, "timestep": 17351, "ep_reward": 760.0202026367188, "reward": 0.2609378695487976, "action": -1.072893738746643}
{"mode": "train", "epochs": 9, "timestep": 17352, "ep_reward": 760.1546630859375, "reward": 0.13447368144989014, "action": -1.2165052890777588}
{"mode": "train", "epochs": 9, "timestep": 17353, "ep_reward": 760.142578125, "reward": -0.012079000473022461, "action": -1.7984917163848877}
{"mode": "train", "epochs": 9, "timestep": 17354, "ep_reward": 760.268310546875, "reward": 0.1257193684577942, "action": -1.5426204204559326}
{"mode": "train", "epochs": 9, "timestep": 17355, "ep_reward": 760.526123046875, "reward": 0.2578132152557373, "action": -1.6785688400268555}
{"mode": "train", "epochs": 9, "timestep": 17356, "ep_reward": 760.9150390625, "reward": 0.38892942667007446, "action": -0.16954940557479858}
{"mode": "train", "epochs": 9, "timestep": 17357, "ep_reward": 761.443603515625, "reward": 0.5285856127738953, "action": -0.8054312467575073}
{"mode": "train", "epochs": 9, "timestep": 17358, "ep_reward": 762.0830688476562, "reward": 0.6394612789154053, "action": -0.8164337277412415}
{"mode": "train", "epochs": 9, "timestep": 17359, "ep_reward": 762.81005859375, "reward": 0.7269985675811768, "action": -0.7247079610824585}
{"mode": "train", "epochs": 9, "timestep": 17360, "ep_reward": 763.6024169921875, "reward": 0.7923535108566284, "action": -1.2553012371063232}
{"mode": "train", "epochs": 9, "timestep": 17361, "ep_reward": 764.434814453125, "reward": 0.8324141502380371, "action": -0.9450594782829285}
{"mode": "train", "epochs": 9, "timestep": 17362, "ep_reward": 765.2920532226562, "reward": 0.8572211861610413, "action": -0.990646481513977}
{"mode": "train", "epochs": 9, "timestep": 17363, "ep_reward": 766.15673828125, "reward": 0.8646917343139648, "action": -1.7853500843048096}
{"mode": "train", "epochs": 9, "timestep": 17364, "ep_reward": 767.0048828125, "reward": 0.8481671810150146, "action": -0.33837950229644775}
{"mode": "train", "epochs": 9, "timestep": 17365, "ep_reward": 767.8296508789062, "reward": 0.824778139591217, "action": -1.6079483032226562}
{"mode": "train", "epochs": 9, "timestep": 17366, "ep_reward": 768.5947265625, "reward": 0.7650872468948364, "action": -0.7753865718841553}
{"mode": "train", "epochs": 9, "timestep": 17367, "ep_reward": 769.2779541015625, "reward": 0.6832296848297119, "action": -0.12805050611495972}
{"mode": "train", "epochs": 9, "timestep": 17368, "ep_reward": 769.8519897460938, "reward": 0.5740200877189636, "action": -0.7795077562332153}
{"mode": "train", "epochs": 9, "timestep": 17369, "ep_reward": 770.268798828125, "reward": 0.4168103337287903, "action": -0.2701260447502136}
{"mode": "train", "epochs": 9, "timestep": 17370, "ep_reward": 770.5675659179688, "reward": 0.2987692356109619, "action": -0.31792402267456055}
{"mode": "train", "epochs": 9, "timestep": 17371, "ep_reward": 770.7463989257812, "reward": 0.17883288860321045, "action": -1.6820650100708008}
{"mode": "train", "epochs": 9, "timestep": 17372, "ep_reward": 770.78564453125, "reward": 0.039236485958099365, "action": -0.35822099447250366}
{"mode": "train", "epochs": 9, "timestep": 17373, "ep_reward": 770.8643798828125, "reward": 0.07874691486358643, "action": -0.6222960352897644}
{"mode": "train", "epochs": 9, "timestep": 17374, "ep_reward": 771.08544921875, "reward": 0.22108113765716553, "action": -0.8590800166130066}
{"mode": "train", "epochs": 9, "timestep": 17375, "ep_reward": 771.4469604492188, "reward": 0.36150306463241577, "action": -1.5082173347473145}
{"mode": "train", "epochs": 9, "timestep": 17376, "ep_reward": 771.9335327148438, "reward": 0.4865623712539673, "action": -0.8473892211914062}
{"mode": "train", "epochs": 9, "timestep": 17377, "ep_reward": 772.5375366210938, "reward": 0.6040279865264893, "action": -1.2162195444107056}
{"mode": "train", "epochs": 9, "timestep": 17378, "ep_reward": 773.2333984375, "reward": 0.6958651542663574, "action": -0.7675004601478577}
{"mode": "train", "epochs": 9, "timestep": 17379, "ep_reward": 774.0030517578125, "reward": 0.769651472568512, "action": -1.2850196361541748}
{"mode": "train", "epochs": 9, "timestep": 17380, "ep_reward": 774.8203735351562, "reward": 0.8173089027404785, "action": -0.6202554702758789}
{"mode": "train", "epochs": 9, "timestep": 17381, "ep_reward": 775.6722412109375, "reward": 0.8518592715263367, "action": -1.489185094833374}
{"mode": "train", "epochs": 9, "timestep": 17382, "ep_reward": 776.5341186523438, "reward": 0.8618859648704529, "action": -1.367267370223999}
{"mode": "train", "epochs": 9, "timestep": 17383, "ep_reward": 777.39013671875, "reward": 0.8560308814048767, "action": -1.4160270690917969}
{"mode": "train", "epochs": 9, "timestep": 17384, "ep_reward": 778.2208862304688, "reward": 0.8307585120201111, "action": 0.1466813087463379}
{"mode": "train", "epochs": 9, "timestep": 17385, "ep_reward": 779.0194702148438, "reward": 0.7985752820968628, "action": -0.8404603600502014}
{"mode": "train", "epochs": 9, "timestep": 17386, "ep_reward": 779.7498168945312, "reward": 0.7303421497344971, "action": -1.8962376117706299}
{"mode": "train", "epochs": 9, "timestep": 17387, "ep_reward": 780.3645629882812, "reward": 0.6147355437278748, "action": -0.9712634086608887}
{"mode": "train", "epochs": 9, "timestep": 17388, "ep_reward": 780.8329467773438, "reward": 0.4683636426925659, "action": -0.7134090662002563}
{"mode": "train", "epochs": 9, "timestep": 17389, "ep_reward": 781.1727905273438, "reward": 0.3398301601409912, "action": -0.9775092601776123}
{"mode": "train", "epochs": 9, "timestep": 17390, "ep_reward": 781.4005737304688, "reward": 0.22778981924057007, "action": -1.264165997505188}
{"mode": "train", "epochs": 9, "timestep": 17391, "ep_reward": 781.4962768554688, "reward": 0.09570932388305664, "action": -1.7009334564208984}
{"mode": "train", "epochs": 9, "timestep": 17392, "ep_reward": 781.5174560546875, "reward": 0.021185755729675293, "action": -0.42581838369369507}
{"mode": "train", "epochs": 9, "timestep": 17393, "ep_reward": 781.681640625, "reward": 0.16417580842971802, "action": -0.014214277267456055}
{"mode": "train", "epochs": 9, "timestep": 17394, "ep_reward": 781.9976196289062, "reward": 0.3159629702568054, "action": -0.5533593893051147}
{"mode": "train", "epochs": 9, "timestep": 17395, "ep_reward": 782.4521484375, "reward": 0.45450252294540405, "action": -1.4938430786132812}
{"mode": "train", "epochs": 9, "timestep": 17396, "ep_reward": 783.0208129882812, "reward": 0.5686385631561279, "action": -1.1282306909561157}
{"mode": "train", "epochs": 9, "timestep": 17397, "ep_reward": 783.6896362304688, "reward": 0.668825626373291, "action": -0.5428161025047302}
{"mode": "train", "epochs": 9, "timestep": 17398, "ep_reward": 784.4425659179688, "reward": 0.752918541431427, "action": -1.208024024963379}
{"mode": "train", "epochs": 9, "timestep": 17399, "ep_reward": 785.2520141601562, "reward": 0.8094258904457092, "action": -0.4833947420120239}
{"mode": "train", "epochs": 9, "timestep": 17400, "ep_reward": 786.1053466796875, "reward": 0.8533411026000977, "action": -1.7609212398529053}
{"mode": "train", "epochs": 9, "timestep": 17401, "ep_reward": 786.9761352539062, "reward": 0.8708034157752991, "action": -1.560572862625122}
{"mode": "train", "epochs": 9, "timestep": 17402, "ep_reward": 787.851318359375, "reward": 0.8751692175865173, "action": -1.5328409671783447}
{"mode": "train", "epochs": 9, "timestep": 17403, "ep_reward": 788.7154541015625, "reward": 0.8641348481178284, "action": -0.8978086709976196}
{"mode": "train", "epochs": 9, "timestep": 17404, "ep_reward": 789.5560302734375, "reward": 0.8405623435974121, "action": -0.860344409942627}
{"mode": "train", "epochs": 9, "timestep": 17405, "ep_reward": 790.3517456054688, "reward": 0.7957406640052795, "action": -1.726324439048767}
{"mode": "train", "epochs": 9, "timestep": 17406, "ep_reward": 791.0654907226562, "reward": 0.7137315273284912, "action": -0.9602318406105042}
{"mode": "train", "epochs": 9, "timestep": 17407, "ep_reward": 791.6697387695312, "reward": 0.604229211807251, "action": -0.8826990723609924}
{"mode": "train", "epochs": 9, "timestep": 17408, "ep_reward": 792.1246948242188, "reward": 0.4549409747123718, "action": -1.7998759746551514}
{"mode": "train", "epochs": 9, "timestep": 17409, "ep_reward": 792.451171875, "reward": 0.3264734148979187, "action": -1.1714551448822021}
{"mode": "train", "epochs": 9, "timestep": 17410, "ep_reward": 792.6630249023438, "reward": 0.21183550357818604, "action": -1.5096595287322998}
{"mode": "train", "epochs": 9, "timestep": 17411, "ep_reward": 792.740234375, "reward": 0.0772354006767273, "action": -1.6096982955932617}
{"mode": "train", "epochs": 9, "timestep": 17412, "ep_reward": 792.7808837890625, "reward": 0.040625035762786865, "action": -0.824337363243103}
{"mode": "train", "epochs": 9, "timestep": 17413, "ep_reward": 792.9611206054688, "reward": 0.1802372932434082, "action": -0.2930065989494324}
{"mode": "train", "epochs": 9, "timestep": 17414, "ep_reward": 793.2901611328125, "reward": 0.32906216382980347, "action": -0.6365126371383667}
{"mode": "train", "epochs": 9, "timestep": 17415, "ep_reward": 793.7566528320312, "reward": 0.46651965379714966, "action": -1.3447463512420654}
{"mode": "train", "epochs": 9, "timestep": 17416, "ep_reward": 794.3377685546875, "reward": 0.5810995101928711, "action": -0.5308446884155273}
{"mode": "train", "epochs": 9, "timestep": 17417, "ep_reward": 795.0224609375, "reward": 0.6847032308578491, "action": -1.3628095388412476}
{"mode": "train", "epochs": 9, "timestep": 17418, "ep_reward": 795.780029296875, "reward": 0.7575414180755615, "action": -0.5862681865692139}
{"mode": "train", "epochs": 9, "timestep": 17419, "ep_reward": 796.596923828125, "reward": 0.8169108033180237, "action": -0.7717567682266235}
{"mode": "train", "epochs": 9, "timestep": 17420, "ep_reward": 797.4525146484375, "reward": 0.8556128144264221, "action": -0.937102198600769}
{"mode": "train", "epochs": 9, "timestep": 17421, "ep_reward": 798.3294067382812, "reward": 0.8768805265426636, "action": -0.8944843411445618}
{"mode": "train", "epochs": 9, "timestep": 17422, "ep_reward": 799.2133178710938, "reward": 0.8839259147644043, "action": -1.0056068897247314}
{"mode": "train", "epochs": 9, "timestep": 17423, "ep_reward": 800.088623046875, "reward": 0.8752822279930115, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 17424, "ep_reward": 800.9297485351562, "reward": 0.841148853302002, "action": -0.6019814014434814}
{"mode": "train", "epochs": 9, "timestep": 17425, "ep_reward": 801.7274169921875, "reward": 0.7976624369621277, "action": -1.304258942604065}
{"mode": "train", "epochs": 9, "timestep": 17426, "ep_reward": 802.447265625, "reward": 0.7198753356933594, "action": -1.1911442279815674}
{"mode": "train", "epochs": 9, "timestep": 17427, "ep_reward": 803.0552978515625, "reward": 0.6080350875854492, "action": -0.47974538803100586}
{"mode": "train", "epochs": 9, "timestep": 17428, "ep_reward": 803.521240234375, "reward": 0.4659295678138733, "action": -0.71952223777771}
{"mode": "train", "epochs": 9, "timestep": 17429, "ep_reward": 803.8465576171875, "reward": 0.3253302574157715, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 17430, "ep_reward": 804.0573120117188, "reward": 0.2107735276222229, "action": -0.7842015027999878}
{"mode": "train", "epochs": 9, "timestep": 17431, "ep_reward": 804.13330078125, "reward": 0.07601338624954224, "action": -0.7037661075592041}
{"mode": "train", "epochs": 9, "timestep": 17432, "ep_reward": 804.1753540039062, "reward": 0.04202854633331299, "action": -0.76874840259552}
{"mode": "train", "epochs": 9, "timestep": 17433, "ep_reward": 804.356689453125, "reward": 0.181349515914917, "action": -1.290329098701477}
{"mode": "train", "epochs": 9, "timestep": 17434, "ep_reward": 804.6744384765625, "reward": 0.3177453279495239, "action": -1.708275318145752}
{"mode": "train", "epochs": 9, "timestep": 17435, "ep_reward": 805.1193237304688, "reward": 0.4448620080947876, "action": -1.6304450035095215}
{"mode": "train", "epochs": 9, "timestep": 17436, "ep_reward": 805.6793823242188, "reward": 0.5600708723068237, "action": -1.845001220703125}
{"mode": "train", "epochs": 9, "timestep": 17437, "ep_reward": 806.33251953125, "reward": 0.6531268358230591, "action": -1.1619919538497925}
{"mode": "train", "epochs": 9, "timestep": 17438, "ep_reward": 807.0630493164062, "reward": 0.730559229850769, "action": -0.6416367292404175}
{"mode": "train", "epochs": 9, "timestep": 17439, "ep_reward": 807.8519287109375, "reward": 0.7888504266738892, "action": -1.1798382997512817}
{"mode": "train", "epochs": 9, "timestep": 17440, "ep_reward": 808.6710815429688, "reward": 0.8191728591918945, "action": -1.517547369003296}
{"mode": "train", "epochs": 9, "timestep": 17441, "ep_reward": 809.49658203125, "reward": 0.8254995346069336, "action": -0.06837737560272217}
{"mode": "train", "epochs": 9, "timestep": 17442, "ep_reward": 810.321044921875, "reward": 0.8244907855987549, "action": -0.6940256953239441}
{"mode": "train", "epochs": 9, "timestep": 17443, "ep_reward": 811.1154174804688, "reward": 0.7943980097770691, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 17444, "ep_reward": 811.8374633789062, "reward": 0.7220315933227539, "action": -0.9997797012329102}
{"mode": "train", "epochs": 9, "timestep": 17445, "ep_reward": 812.4619140625, "reward": 0.624433159828186, "action": -1.3437316417694092}
{"mode": "train", "epochs": 9, "timestep": 17446, "ep_reward": 812.9412231445312, "reward": 0.47927922010421753, "action": -0.8169217109680176}
{"mode": "train", "epochs": 9, "timestep": 17447, "ep_reward": 813.3087158203125, "reward": 0.3674977421760559, "action": -0.8530945777893066}
{"mode": "train", "epochs": 9, "timestep": 17448, "ep_reward": 813.5697631835938, "reward": 0.2610777020454407, "action": -0.797736406326294}
{"mode": "train", "epochs": 9, "timestep": 17449, "ep_reward": 813.7044067382812, "reward": 0.13461923599243164, "action": -1.0808148384094238}
{"mode": "train", "epochs": 9, "timestep": 17450, "ep_reward": 813.6926879882812, "reward": -0.011736631393432617, "action": -0.26374131441116333}
{"mode": "train", "epochs": 9, "timestep": 17451, "ep_reward": 813.818359375, "reward": 0.12568771839141846, "action": -0.9222530722618103}
{"mode": "train", "epochs": 9, "timestep": 17452, "ep_reward": 814.083984375, "reward": 0.2656400799751282, "action": -0.7802537083625793}
{"mode": "train", "epochs": 9, "timestep": 17453, "ep_reward": 814.4901123046875, "reward": 0.4061194062232971, "action": -0.7371772527694702}
{"mode": "train", "epochs": 9, "timestep": 17454, "ep_reward": 815.025634765625, "reward": 0.5355127453804016, "action": -1.3521771430969238}
{"mode": "train", "epochs": 9, "timestep": 17455, "ep_reward": 815.6648559570312, "reward": 0.6392149925231934, "action": -1.752146601676941}
{"mode": "train", "epochs": 9, "timestep": 17456, "ep_reward": 816.3829956054688, "reward": 0.7181523442268372, "action": -0.8533045053482056}
{"mode": "train", "epochs": 9, "timestep": 17457, "ep_reward": 817.1676025390625, "reward": 0.7845795154571533, "action": -0.5182775259017944}
{"mode": "train", "epochs": 9, "timestep": 17458, "ep_reward": 818.0004272460938, "reward": 0.8328187465667725, "action": -0.5801985263824463}
{"mode": "train", "epochs": 9, "timestep": 17459, "ep_reward": 818.8621826171875, "reward": 0.8617402911186218, "action": -0.9448938369750977}
{"mode": "train", "epochs": 9, "timestep": 17460, "ep_reward": 819.7333984375, "reward": 0.8712214231491089, "action": -0.7593172788619995}
{"mode": "train", "epochs": 9, "timestep": 17461, "ep_reward": 820.5994873046875, "reward": 0.8660892844200134, "action": -1.8016263246536255}
{"mode": "train", "epochs": 9, "timestep": 17462, "ep_reward": 821.433349609375, "reward": 0.8338426351547241, "action": -0.9810141921043396}
{"mode": "train", "epochs": 9, "timestep": 17463, "ep_reward": 822.2194213867188, "reward": 0.7860971093177795, "action": -1.0779411792755127}
{"mode": "train", "epochs": 9, "timestep": 17464, "ep_reward": 822.92822265625, "reward": 0.7087965607643127, "action": -0.2875722050666809}
{"mode": "train", "epochs": 9, "timestep": 17465, "ep_reward": 823.5347900390625, "reward": 0.6065579652786255, "action": -0.6267367601394653}
{"mode": "train", "epochs": 9, "timestep": 17466, "ep_reward": 823.996337890625, "reward": 0.46153247356414795, "action": -1.5721461772918701}
{"mode": "train", "epochs": 9, "timestep": 17467, "ep_reward": 824.3201904296875, "reward": 0.32385802268981934, "action": -0.5019131898880005}
{"mode": "train", "epochs": 9, "timestep": 17468, "ep_reward": 824.5289916992188, "reward": 0.2087727189064026, "action": -0.34742504358291626}
{"mode": "train", "epochs": 9, "timestep": 17469, "ep_reward": 824.6024169921875, "reward": 0.07343745231628418, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 17470, "ep_reward": 824.6469116210938, "reward": 0.04448014497756958, "action": -0.4417816996574402}
{"mode": "train", "epochs": 9, "timestep": 17471, "ep_reward": 824.8348388671875, "reward": 0.18795204162597656, "action": -1.0875236988067627}
{"mode": "train", "epochs": 9, "timestep": 17472, "ep_reward": 825.1607666015625, "reward": 0.3259230852127075, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 17473, "ep_reward": 825.60888671875, "reward": 0.44812071323394775, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 17474, "ep_reward": 826.1676635742188, "reward": 0.5587529540061951, "action": -0.1080356240272522}
{"mode": "train", "epochs": 9, "timestep": 17475, "ep_reward": 826.83837890625, "reward": 0.670714795589447, "action": -1.3799831867218018}
{"mode": "train", "epochs": 9, "timestep": 17476, "ep_reward": 827.5822143554688, "reward": 0.7438104152679443, "action": -1.360534429550171}
{"mode": "train", "epochs": 9, "timestep": 17477, "ep_reward": 828.377197265625, "reward": 0.7950121760368347, "action": -0.06542980670928955}
{"mode": "train", "epochs": 9, "timestep": 17478, "ep_reward": 829.2144165039062, "reward": 0.8372106552124023, "action": 0.06636601686477661}
{"mode": "train", "epochs": 9, "timestep": 17479, "ep_reward": 830.0751953125, "reward": 0.8607696294784546, "action": -1.411352276802063}
{"mode": "train", "epochs": 9, "timestep": 17480, "ep_reward": 830.9291381835938, "reward": 0.8539648056030273, "action": -0.3044598698616028}
{"mode": "train", "epochs": 9, "timestep": 17481, "ep_reward": 831.7674560546875, "reward": 0.8382931351661682, "action": -1.4836899042129517}
{"mode": "train", "epochs": 9, "timestep": 17482, "ep_reward": 832.5570678710938, "reward": 0.7896213531494141, "action": 0.07023173570632935}
{"mode": "train", "epochs": 9, "timestep": 17483, "ep_reward": 833.2871704101562, "reward": 0.7300726175308228, "action": -0.5109515190124512}
{"mode": "train", "epochs": 9, "timestep": 17484, "ep_reward": 833.9197387695312, "reward": 0.6325739622116089, "action": -0.8226960897445679}
{"mode": "train", "epochs": 9, "timestep": 17485, "ep_reward": 834.4126586914062, "reward": 0.4929152727127075, "action": -1.3241634368896484}
{"mode": "train", "epochs": 9, "timestep": 17486, "ep_reward": 834.7557373046875, "reward": 0.34307175874710083, "action": -1.1114938259124756}
{"mode": "train", "epochs": 9, "timestep": 17487, "ep_reward": 834.9874267578125, "reward": 0.2316664457321167, "action": -1.4049394130706787}
{"mode": "train", "epochs": 9, "timestep": 17488, "ep_reward": 835.0877685546875, "reward": 0.10033273696899414, "action": -1.2560302019119263}
{"mode": "train", "epochs": 9, "timestep": 17489, "ep_reward": 835.1040649414062, "reward": 0.016293704509735107, "action": -0.5084408521652222}
{"mode": "train", "epochs": 9, "timestep": 17490, "ep_reward": 835.26318359375, "reward": 0.1590975522994995, "action": -0.3891327381134033}
{"mode": "train", "epochs": 9, "timestep": 17491, "ep_reward": 835.5694580078125, "reward": 0.3062906265258789, "action": -1.4167938232421875}
{"mode": "train", "epochs": 9, "timestep": 17492, "ep_reward": 836.0055541992188, "reward": 0.436123788356781, "action": -1.3154330253601074}
{"mode": "train", "epochs": 9, "timestep": 17493, "ep_reward": 836.56103515625, "reward": 0.5555016994476318, "action": -1.192962646484375}
{"mode": "train", "epochs": 9, "timestep": 17494, "ep_reward": 837.2182006835938, "reward": 0.6571686267852783, "action": -1.697601318359375}
{"mode": "train", "epochs": 9, "timestep": 17495, "ep_reward": 837.949951171875, "reward": 0.7317527532577515, "action": -1.2016472816467285}
{"mode": "train", "epochs": 9, "timestep": 17496, "ep_reward": 838.73974609375, "reward": 0.7897679805755615, "action": -0.5017694234848022}
{"mode": "train", "epochs": 9, "timestep": 17497, "ep_reward": 839.572998046875, "reward": 0.833281934261322, "action": -0.7003982663154602}
{"mode": "train", "epochs": 9, "timestep": 17498, "ep_reward": 840.4288330078125, "reward": 0.8558378219604492, "action": -1.2304434776306152}
{"mode": "train", "epochs": 9, "timestep": 17499, "ep_reward": 841.2849731445312, "reward": 0.8561497330665588, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 17500, "ep_reward": 842.1157836914062, "reward": 0.8307892680168152, "action": -0.6287478804588318}
{"mode": "train", "epochs": 9, "timestep": 17501, "ep_reward": 842.9114379882812, "reward": 0.7956489324569702, "action": -1.3037045001983643}
{"mode": "train", "epochs": 9, "timestep": 17502, "ep_reward": 843.6375122070312, "reward": 0.7260556817054749, "action": -0.4684147834777832}
{"mode": "train", "epochs": 9, "timestep": 17503, "ep_reward": 844.26953125, "reward": 0.6320483684539795, "action": -1.0449285507202148}
{"mode": "train", "epochs": 9, "timestep": 17504, "ep_reward": 844.7603149414062, "reward": 0.4907718896865845, "action": -1.755803108215332}
{"mode": "train", "epochs": 9, "timestep": 17505, "ep_reward": 845.1163330078125, "reward": 0.3560182452201843, "action": -0.8420356512069702}
{"mode": "train", "epochs": 9, "timestep": 17506, "ep_reward": 845.363525390625, "reward": 0.24720263481140137, "action": -1.1429260969161987}
{"mode": "train", "epochs": 9, "timestep": 17507, "ep_reward": 845.4818115234375, "reward": 0.11829209327697754, "action": -1.8528270721435547}
{"mode": "train", "epochs": 9, "timestep": 17508, "ep_reward": 845.4781494140625, "reward": -0.003653883934020996, "action": -1.1250022649765015}
{"mode": "train", "epochs": 9, "timestep": 17509, "ep_reward": 845.6197509765625, "reward": 0.14160913228988647, "action": -1.7630479335784912}
{"mode": "train", "epochs": 9, "timestep": 17510, "ep_reward": 845.8912353515625, "reward": 0.2715136408805847, "action": -0.4666471481323242}
{"mode": "train", "epochs": 9, "timestep": 17511, "ep_reward": 846.308349609375, "reward": 0.41713738441467285, "action": -1.3050559759140015}
{"mode": "train", "epochs": 9, "timestep": 17512, "ep_reward": 846.84765625, "reward": 0.5393062829971313, "action": -1.368517518043518}
{"mode": "train", "epochs": 9, "timestep": 17513, "ep_reward": 847.4896850585938, "reward": 0.6419998407363892, "action": -1.9397425651550293}
{"mode": "train", "epochs": 9, "timestep": 17514, "ep_reward": 848.2067260742188, "reward": 0.7170554399490356, "action": 0.12860143184661865}
{"mode": "train", "epochs": 9, "timestep": 17515, "ep_reward": 848.9967651367188, "reward": 0.7900550961494446, "action": -1.3777724504470825}
{"mode": "train", "epochs": 9, "timestep": 17516, "ep_reward": 849.8231811523438, "reward": 0.8264276385307312, "action": -0.4674636125564575}
{"mode": "train", "epochs": 9, "timestep": 17517, "ep_reward": 850.6751708984375, "reward": 0.852003812789917, "action": -0.0787421464920044}
{"mode": "train", "epochs": 9, "timestep": 17518, "ep_reward": 851.5380859375, "reward": 0.8629298210144043, "action": -1.158606767654419}
{"mode": "train", "epochs": 9, "timestep": 17519, "ep_reward": 852.3848876953125, "reward": 0.8467807769775391, "action": -0.6250779628753662}
{"mode": "train", "epochs": 9, "timestep": 17520, "ep_reward": 853.2001342773438, "reward": 0.8152371644973755, "action": -1.0646106004714966}
{"mode": "train", "epochs": 9, "timestep": 17521, "ep_reward": 853.9547119140625, "reward": 0.7546063661575317, "action": -0.5237688422203064}
{"mode": "train", "epochs": 9, "timestep": 17522, "ep_reward": 854.6236572265625, "reward": 0.6689561605453491, "action": -0.9548720717430115}
{"mode": "train", "epochs": 9, "timestep": 17523, "ep_reward": 855.1644897460938, "reward": 0.5408467054367065, "action": -1.5574564933776855}
{"mode": "train", "epochs": 9, "timestep": 17524, "ep_reward": 855.5410766601562, "reward": 0.37656331062316895, "action": -1.0451997518539429}
{"mode": "train", "epochs": 9, "timestep": 17525, "ep_reward": 855.8131713867188, "reward": 0.27208101749420166, "action": -0.6764048337936401}
{"mode": "train", "epochs": 9, "timestep": 17526, "ep_reward": 855.9606323242188, "reward": 0.14744478464126587, "action": -1.5149357318878174}
{"mode": "train", "epochs": 9, "timestep": 17527, "ep_reward": 855.963623046875, "reward": 0.0029948949813842773, "action": -1.077906847000122}
{"mode": "train", "epochs": 9, "timestep": 17528, "ep_reward": 856.0760498046875, "reward": 0.11243999004364014, "action": -1.2605628967285156}
{"mode": "train", "epochs": 9, "timestep": 17529, "ep_reward": 856.3238525390625, "reward": 0.24783188104629517, "action": -0.7927463054656982}
{"mode": "train", "epochs": 9, "timestep": 17530, "ep_reward": 856.7135009765625, "reward": 0.3896259069442749, "action": -0.5659246444702148}
{"mode": "train", "epochs": 9, "timestep": 17531, "ep_reward": 857.23681640625, "reward": 0.5233416557312012, "action": -0.5623174905776978}
{"mode": "train", "epochs": 9, "timestep": 17532, "ep_reward": 857.8744506835938, "reward": 0.6376245021820068, "action": -0.7407046556472778}
{"mode": "train", "epochs": 9, "timestep": 17533, "ep_reward": 858.6015625, "reward": 0.727125346660614, "action": -0.9413557052612305}
{"mode": "train", "epochs": 9, "timestep": 17534, "ep_reward": 859.3941650390625, "reward": 0.7925944328308105, "action": -0.48978477716445923}
{"mode": "train", "epochs": 9, "timestep": 17535, "ep_reward": 860.2362060546875, "reward": 0.8420660495758057, "action": -0.5450763702392578}
{"mode": "train", "epochs": 9, "timestep": 17536, "ep_reward": 861.1098022460938, "reward": 0.8735675811767578, "action": -0.6115537285804749}
{"mode": "train", "epochs": 9, "timestep": 17537, "ep_reward": 861.99951171875, "reward": 0.889707624912262, "action": -0.7222578525543213}
{"mode": "train", "epochs": 9, "timestep": 17538, "ep_reward": 862.8909301757812, "reward": 0.8914137482643127, "action": -1.3630108833312988}
{"mode": "train", "epochs": 9, "timestep": 17539, "ep_reward": 863.7649536132812, "reward": 0.8740091919898987, "action": -0.5918794274330139}
{"mode": "train", "epochs": 9, "timestep": 17540, "ep_reward": 864.6110229492188, "reward": 0.8460482358932495, "action": -0.5652368068695068}
{"mode": "train", "epochs": 9, "timestep": 17541, "ep_reward": 865.4089965820312, "reward": 0.7979925870895386, "action": -0.38964152336120605}
{"mode": "train", "epochs": 9, "timestep": 17542, "ep_reward": 866.1353149414062, "reward": 0.7263107299804688, "action": 0.1470886468887329}
{"mode": "train", "epochs": 9, "timestep": 17543, "ep_reward": 866.7661743164062, "reward": 0.6308382749557495, "action": -0.5137430429458618}
{"mode": "train", "epochs": 9, "timestep": 17544, "ep_reward": 867.2590942382812, "reward": 0.4929434061050415, "action": -1.0697078704833984}
{"mode": "train", "epochs": 9, "timestep": 17545, "ep_reward": 867.576416015625, "reward": 0.31731438636779785, "action": -1.3460509777069092}
{"mode": "train", "epochs": 9, "timestep": 17546, "ep_reward": 867.7774658203125, "reward": 0.20105397701263428, "action": -0.9831368923187256}
{"mode": "train", "epochs": 9, "timestep": 17547, "ep_reward": 867.8422241210938, "reward": 0.06477326154708862, "action": -0.6770385503768921}
{"mode": "train", "epochs": 9, "timestep": 17548, "ep_reward": 867.895751953125, "reward": 0.053501248359680176, "action": -0.8422576785087585}
{"mode": "train", "epochs": 9, "timestep": 17549, "ep_reward": 868.0879516601562, "reward": 0.19217050075531006, "action": -1.709992527961731}
{"mode": "train", "epochs": 9, "timestep": 17550, "ep_reward": 868.4113159179688, "reward": 0.3233944773674011, "action": -1.197969675064087}
{"mode": "train", "epochs": 9, "timestep": 17551, "ep_reward": 868.8682861328125, "reward": 0.4569661617279053, "action": -0.48249542713165283}
{"mode": "train", "epochs": 9, "timestep": 17552, "ep_reward": 869.4517211914062, "reward": 0.5834529399871826, "action": -1.5768952369689941}
{"mode": "train", "epochs": 9, "timestep": 17553, "ep_reward": 870.1270751953125, "reward": 0.6753425598144531, "action": -1.727829933166504}
{"mode": "train", "epochs": 9, "timestep": 17554, "ep_reward": 870.8707885742188, "reward": 0.7437114715576172, "action": -1.3640894889831543}
{"mode": "train", "epochs": 9, "timestep": 17555, "ep_reward": 871.6646118164062, "reward": 0.7938524484634399, "action": -0.6259331703186035}
{"mode": "train", "epochs": 9, "timestep": 17556, "ep_reward": 872.4943237304688, "reward": 0.8297266364097595, "action": -0.5843443870544434}
{"mode": "train", "epochs": 9, "timestep": 17557, "ep_reward": 873.34033203125, "reward": 0.845977783203125, "action": -0.7916320562362671}
{"mode": "train", "epochs": 9, "timestep": 17558, "ep_reward": 874.1814575195312, "reward": 0.8411473631858826, "action": -1.0068880319595337}
{"mode": "train", "epochs": 9, "timestep": 17559, "ep_reward": 874.9949951171875, "reward": 0.8135573863983154, "action": -0.3247406482696533}
{"mode": "train", "epochs": 9, "timestep": 17560, "ep_reward": 875.763427734375, "reward": 0.7684311270713806, "action": -1.4285436868667603}
{"mode": "train", "epochs": 9, "timestep": 17561, "ep_reward": 876.4443359375, "reward": 0.6809166669845581, "action": -0.604687511920929}
{"mode": "train", "epochs": 9, "timestep": 17562, "ep_reward": 877.0098876953125, "reward": 0.5655800104141235, "action": -0.9510486125946045}
{"mode": "train", "epochs": 9, "timestep": 17563, "ep_reward": 877.41357421875, "reward": 0.4036714434623718, "action": -1.515289545059204}
{"mode": "train", "epochs": 9, "timestep": 17564, "ep_reward": 877.7152099609375, "reward": 0.30160993337631226, "action": -0.7274646162986755}
{"mode": "train", "epochs": 9, "timestep": 17565, "ep_reward": 877.8975219726562, "reward": 0.1823415756225586, "action": -0.9746298789978027}
{"mode": "train", "epochs": 9, "timestep": 17566, "ep_reward": 877.940673828125, "reward": 0.04313671588897705, "action": -0.6019960641860962}
{"mode": "train", "epochs": 9, "timestep": 17567, "ep_reward": 878.015625, "reward": 0.07495903968811035, "action": -0.6239118576049805}
{"mode": "train", "epochs": 9, "timestep": 17568, "ep_reward": 878.2327270507812, "reward": 0.2171211838722229, "action": -1.1542176008224487}
{"mode": "train", "epochs": 9, "timestep": 17569, "ep_reward": 878.5868530273438, "reward": 0.35413968563079834, "action": -1.0788400173187256}
{"mode": "train", "epochs": 9, "timestep": 17570, "ep_reward": 879.0720825195312, "reward": 0.4852328896522522, "action": -1.0107530355453491}
{"mode": "train", "epochs": 9, "timestep": 17571, "ep_reward": 879.6732177734375, "reward": 0.6011061668395996, "action": -1.1376073360443115}
{"mode": "train", "epochs": 9, "timestep": 17572, "ep_reward": 880.3675537109375, "reward": 0.6943142414093018, "action": -0.8764789700508118}
{"mode": "train", "epochs": 9, "timestep": 17573, "ep_reward": 881.1351318359375, "reward": 0.7675485014915466, "action": -1.0636341571807861}
{"mode": "train", "epochs": 9, "timestep": 17574, "ep_reward": 881.9526977539062, "reward": 0.8175579309463501, "action": -1.265326738357544}
{"mode": "train", "epochs": 9, "timestep": 17575, "ep_reward": 882.799560546875, "reward": 0.8468747138977051, "action": -1.663484811782837}
{"mode": "train", "epochs": 9, "timestep": 17576, "ep_reward": 883.6552734375, "reward": 0.8556907176971436, "action": -0.37044042348861694}
{"mode": "train", "epochs": 9, "timestep": 17577, "ep_reward": 884.513671875, "reward": 0.8584176301956177, "action": 0.20976442098617554}
{"mode": "train", "epochs": 9, "timestep": 17578, "ep_reward": 885.3622436523438, "reward": 0.8485685586929321, "action": -0.6041555404663086}
{"mode": "train", "epochs": 9, "timestep": 17579, "ep_reward": 886.1739501953125, "reward": 0.8117085099220276, "action": -0.1891605257987976}
{"mode": "train", "epochs": 9, "timestep": 17580, "ep_reward": 886.9288940429688, "reward": 0.7549225687980652, "action": -1.3731675148010254}
{"mode": "train", "epochs": 9, "timestep": 17581, "ep_reward": 887.583251953125, "reward": 0.6543700695037842, "action": -0.5484110116958618}
{"mode": "train", "epochs": 9, "timestep": 17582, "ep_reward": 888.1092529296875, "reward": 0.5259944796562195, "action": -1.121042251586914}
{"mode": "train", "epochs": 9, "timestep": 17583, "ep_reward": 888.46826171875, "reward": 0.3590157628059387, "action": -0.9564449191093445}
{"mode": "train", "epochs": 9, "timestep": 17584, "ep_reward": 888.7191162109375, "reward": 0.2508609890937805, "action": -0.8495378494262695}
{"mode": "train", "epochs": 9, "timestep": 17585, "ep_reward": 888.8416137695312, "reward": 0.12249171733856201, "action": -1.9923052787780762}
{"mode": "train", "epochs": 9, "timestep": 17586, "ep_reward": 888.833251953125, "reward": -0.008367776870727539, "action": -0.7349540591239929}
{"mode": "train", "epochs": 9, "timestep": 17587, "ep_reward": 888.9708862304688, "reward": 0.13761812448501587, "action": -0.7724704742431641}
{"mode": "train", "epochs": 9, "timestep": 17588, "ep_reward": 889.2506713867188, "reward": 0.27975815534591675, "action": -0.029186666011810303}
{"mode": "train", "epochs": 9, "timestep": 17589, "ep_reward": 889.6787719726562, "reward": 0.42810267210006714, "action": -1.317915678024292}
{"mode": "train", "epochs": 9, "timestep": 17590, "ep_reward": 890.2264404296875, "reward": 0.5476707220077515, "action": -0.42695969343185425}
{"mode": "train", "epochs": 9, "timestep": 17591, "ep_reward": 890.8850708007812, "reward": 0.6586242914199829, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 17592, "ep_reward": 891.6168823242188, "reward": 0.7317930459976196, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 17593, "ep_reward": 892.40283203125, "reward": 0.7859234809875488, "action": -0.7039047479629517}
{"mode": "train", "epochs": 9, "timestep": 17594, "ep_reward": 893.2353515625, "reward": 0.8325024247169495, "action": -1.3369172811508179}
{"mode": "train", "epochs": 9, "timestep": 17595, "ep_reward": 894.0907592773438, "reward": 0.8553873300552368, "action": -0.8587965965270996}
{"mode": "train", "epochs": 9, "timestep": 17596, "ep_reward": 894.9563598632812, "reward": 0.8655747175216675, "action": -1.3978304862976074}
{"mode": "train", "epochs": 9, "timestep": 17597, "ep_reward": 895.810546875, "reward": 0.8542163968086243, "action": -1.2087689638137817}
{"mode": "train", "epochs": 9, "timestep": 17598, "ep_reward": 896.6356201171875, "reward": 0.825076162815094, "action": -0.2021973729133606}
{"mode": "train", "epochs": 9, "timestep": 17599, "ep_reward": 897.4183959960938, "reward": 0.7827630639076233, "action": -1.020350456237793}
{"mode": "train", "epochs": 9, "timestep": 17600, "ep_reward": 898.1221923828125, "reward": 0.7037989497184753, "action": -1.3797388076782227}
{"mode": "train", "epochs": 9, "timestep": 17601, "ep_reward": 898.7061157226562, "reward": 0.5839245319366455, "action": 0.04428303241729736}
{"mode": "train", "epochs": 9, "timestep": 17602, "ep_reward": 899.1494140625, "reward": 0.44332098960876465, "action": -1.108520746231079}
{"mode": "train", "epochs": 9, "timestep": 17603, "ep_reward": 899.4627685546875, "reward": 0.31334352493286133, "action": -1.1976242065429688}
{"mode": "train", "epochs": 9, "timestep": 17604, "ep_reward": 899.6589965820312, "reward": 0.19620966911315918, "action": -1.6076927185058594}
{"mode": "train", "epochs": 9, "timestep": 17605, "ep_reward": 899.71826171875, "reward": 0.05927950143814087, "action": -0.6968433856964111}
{"mode": "train", "epochs": 9, "timestep": 17606, "ep_reward": 899.7771606445312, "reward": 0.058921098709106445, "action": -1.5274665355682373}
{"mode": "train", "epochs": 9, "timestep": 17607, "ep_reward": 899.9732055664062, "reward": 0.1960722804069519, "action": -1.1931860446929932}
{"mode": "train", "epochs": 9, "timestep": 17608, "ep_reward": 900.30712890625, "reward": 0.33390897512435913, "action": -1.4271290302276611}
{"mode": "train", "epochs": 9, "timestep": 17609, "ep_reward": 900.7704467773438, "reward": 0.46329134702682495, "action": -1.0007704496383667}
{"mode": "train", "epochs": 9, "timestep": 17610, "ep_reward": 901.353515625, "reward": 0.5830559134483337, "action": -0.5025930404663086}
{"mode": "train", "epochs": 9, "timestep": 17611, "ep_reward": 902.0397338867188, "reward": 0.6861883401870728, "action": -0.19630217552185059}
{"mode": "train", "epochs": 9, "timestep": 17612, "ep_reward": 902.8072509765625, "reward": 0.7674954533576965, "action": -0.9545326828956604}
{"mode": "train", "epochs": 9, "timestep": 17613, "ep_reward": 903.6263427734375, "reward": 0.8190793991088867, "action": -0.39468032121658325}
{"mode": "train", "epochs": 9, "timestep": 17614, "ep_reward": 904.4827270507812, "reward": 0.8563560247421265, "action": -1.4636675119400024}
{"mode": "train", "epochs": 9, "timestep": 17615, "ep_reward": 905.350830078125, "reward": 0.8681020736694336, "action": -0.9343341588973999}
{"mode": "train", "epochs": 9, "timestep": 17616, "ep_reward": 906.2191772460938, "reward": 0.8683696985244751, "action": -0.9967711567878723}
{"mode": "train", "epochs": 9, "timestep": 17617, "ep_reward": 907.0702514648438, "reward": 0.8510885238647461, "action": -1.1092891693115234}
{"mode": "train", "epochs": 9, "timestep": 17618, "ep_reward": 907.8828125, "reward": 0.8125314712524414, "action": -1.416508436203003}
{"mode": "train", "epochs": 9, "timestep": 17619, "ep_reward": 908.6276245117188, "reward": 0.7448033094406128, "action": -1.2985469102859497}
{"mode": "train", "epochs": 9, "timestep": 17620, "ep_reward": 909.2720336914062, "reward": 0.6444151401519775, "action": -1.6945836544036865}
{"mode": "train", "epochs": 9, "timestep": 17621, "ep_reward": 909.7691650390625, "reward": 0.49713820219039917, "action": -0.8840036988258362}
{"mode": "train", "epochs": 9, "timestep": 17622, "ep_reward": 910.1298217773438, "reward": 0.3606335520744324, "action": -1.1532082557678223}
{"mode": "train", "epochs": 9, "timestep": 17623, "ep_reward": 910.382568359375, "reward": 0.25272274017333984, "action": -1.6124749183654785}
{"mode": "train", "epochs": 9, "timestep": 17624, "ep_reward": 910.5076293945312, "reward": 0.1250544786453247, "action": -0.02061474323272705}
{"mode": "train", "epochs": 9, "timestep": 17625, "ep_reward": 910.49658203125, "reward": -0.011027812957763672, "action": -1.0921826362609863}
{"mode": "train", "epochs": 9, "timestep": 17626, "ep_reward": 910.6317138671875, "reward": 0.13513708114624023, "action": -1.937406063079834}
{"mode": "train", "epochs": 9, "timestep": 17627, "ep_reward": 910.894287109375, "reward": 0.2626020312309265, "action": -1.3178188800811768}
{"mode": "train", "epochs": 9, "timestep": 17628, "ep_reward": 911.29296875, "reward": 0.3986891508102417, "action": -0.2600111961364746}
{"mode": "train", "epochs": 9, "timestep": 17629, "ep_reward": 911.8291625976562, "reward": 0.5361673831939697, "action": -0.4034426212310791}
{"mode": "train", "epochs": 9, "timestep": 17630, "ep_reward": 912.4789428710938, "reward": 0.6497995257377625, "action": -1.4754966497421265}
{"mode": "train", "epochs": 9, "timestep": 17631, "ep_reward": 913.2075805664062, "reward": 0.7286428213119507, "action": -0.7690486907958984}
{"mode": "train", "epochs": 9, "timestep": 17632, "ep_reward": 914.0000610351562, "reward": 0.7924591302871704, "action": -1.0595182180404663}
{"mode": "train", "epochs": 9, "timestep": 17633, "ep_reward": 914.8329467773438, "reward": 0.832858681678772, "action": -0.8735937476158142}
{"mode": "train", "epochs": 9, "timestep": 17634, "ep_reward": 915.6895751953125, "reward": 0.8566405773162842, "action": -0.0502239465713501}
{"mode": "train", "epochs": 9, "timestep": 17635, "ep_reward": 916.5599975585938, "reward": 0.8704089522361755, "action": -0.5615564584732056}
{"mode": "train", "epochs": 9, "timestep": 17636, "ep_reward": 917.4234619140625, "reward": 0.8634427189826965, "action": -0.18687444925308228}
{"mode": "train", "epochs": 9, "timestep": 17637, "ep_reward": 918.2657470703125, "reward": 0.84227055311203, "action": -0.563779354095459}
{"mode": "train", "epochs": 9, "timestep": 17638, "ep_reward": 919.062744140625, "reward": 0.7970019578933716, "action": -1.5158202648162842}
{"mode": "train", "epochs": 9, "timestep": 17639, "ep_reward": 919.7774047851562, "reward": 0.7146629095077515, "action": -0.7608708143234253}
{"mode": "train", "epochs": 9, "timestep": 17640, "ep_reward": 920.3831176757812, "reward": 0.6057425737380981, "action": -1.5934233665466309}
{"mode": "train", "epochs": 9, "timestep": 17641, "ep_reward": 920.8280029296875, "reward": 0.4448578357696533, "action": -0.9282010793685913}
{"mode": "train", "epochs": 9, "timestep": 17642, "ep_reward": 921.1437377929688, "reward": 0.315751850605011, "action": -1.1060391664505005}
{"mode": "train", "epochs": 9, "timestep": 17643, "ep_reward": 921.3429565429688, "reward": 0.19920390844345093, "action": -0.41625726222991943}
{"mode": "train", "epochs": 9, "timestep": 17644, "ep_reward": 921.405517578125, "reward": 0.06257963180541992, "action": -0.5953050851821899}
{"mode": "train", "epochs": 9, "timestep": 17645, "ep_reward": 921.461181640625, "reward": 0.05564957857131958, "action": -1.3541936874389648}
{"mode": "train", "epochs": 9, "timestep": 17646, "ep_reward": 921.6543579101562, "reward": 0.19317054748535156, "action": -1.528937816619873}
{"mode": "train", "epochs": 9, "timestep": 17647, "ep_reward": 921.9812622070312, "reward": 0.3268805146217346, "action": -0.9363210797309875}
{"mode": "train", "epochs": 9, "timestep": 17648, "ep_reward": 922.4444580078125, "reward": 0.4631817936897278, "action": -0.5531247854232788}
{"mode": "train", "epochs": 9, "timestep": 17649, "ep_reward": 923.0322875976562, "reward": 0.5878288745880127, "action": -1.0253933668136597}
{"mode": "train", "epochs": 9, "timestep": 17650, "ep_reward": 923.7171020507812, "reward": 0.684798538684845, "action": -1.0576584339141846}
{"mode": "train", "epochs": 9, "timestep": 17651, "ep_reward": 924.4757080078125, "reward": 0.7585818767547607, "action": -0.669353187084198}
{"mode": "train", "epochs": 9, "timestep": 17652, "ep_reward": 925.289794921875, "reward": 0.8140791654586792, "action": -1.0289002656936646}
{"mode": "train", "epochs": 9, "timestep": 17653, "ep_reward": 926.136474609375, "reward": 0.8466602563858032, "action": -1.188942551612854}
{"mode": "train", "epochs": 9, "timestep": 17654, "ep_reward": 926.9970092773438, "reward": 0.860562801361084, "action": -0.8243350982666016}
{"mode": "train", "epochs": 9, "timestep": 17655, "ep_reward": 927.8577270507812, "reward": 0.8607094883918762, "action": -0.6128811836242676}
{"mode": "train", "epochs": 9, "timestep": 17656, "ep_reward": 928.70263671875, "reward": 0.8448878526687622, "action": -0.8545443415641785}
{"mode": "train", "epochs": 9, "timestep": 17657, "ep_reward": 929.5087890625, "reward": 0.8061428666114807, "action": -1.552982211112976}
{"mode": "train", "epochs": 9, "timestep": 17658, "ep_reward": 930.242431640625, "reward": 0.7336182594299316, "action": -0.5116276144981384}
{"mode": "train", "epochs": 9, "timestep": 17659, "ep_reward": 930.8817138671875, "reward": 0.6392983198165894, "action": -0.8738496899604797}
{"mode": "train", "epochs": 9, "timestep": 17660, "ep_reward": 931.3836059570312, "reward": 0.5019153952598572, "action": -1.4028209447860718}
{"mode": "train", "epochs": 9, "timestep": 17661, "ep_reward": 931.7373657226562, "reward": 0.3537576198577881, "action": -0.8877707719802856}
{"mode": "train", "epochs": 9, "timestep": 17662, "ep_reward": 931.98193359375, "reward": 0.24456095695495605, "action": -0.21459215879440308}
{"mode": "train", "epochs": 9, "timestep": 17663, "ep_reward": 932.0972290039062, "reward": 0.11528325080871582, "action": -0.7498102784156799}
{"mode": "train", "epochs": 9, "timestep": 17664, "ep_reward": 932.09716796875, "reward": -7.605552673339844e-05, "action": -1.07106351852417}
{"mode": "train", "epochs": 9, "timestep": 17665, "ep_reward": 932.241943359375, "reward": 0.14480549097061157, "action": -1.3756401538848877}
{"mode": "train", "epochs": 9, "timestep": 17666, "ep_reward": 932.521484375, "reward": 0.2795647978782654, "action": -1.0143446922302246}
{"mode": "train", "epochs": 9, "timestep": 17667, "ep_reward": 932.9389038085938, "reward": 0.417416512966156, "action": -1.1104276180267334}
{"mode": "train", "epochs": 9, "timestep": 17668, "ep_reward": 933.4808959960938, "reward": 0.5419764518737793, "action": -0.7530984878540039}
{"mode": "train", "epochs": 9, "timestep": 17669, "ep_reward": 934.131591796875, "reward": 0.6507023572921753, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 17670, "ep_reward": 934.85546875, "reward": 0.7238879203796387, "action": -0.4584581255912781}
{"mode": "train", "epochs": 9, "timestep": 17671, "ep_reward": 935.6460571289062, "reward": 0.7905887961387634, "action": -0.6265636086463928}
{"mode": "train", "epochs": 9, "timestep": 17672, "ep_reward": 936.4798583984375, "reward": 0.8338102102279663, "action": -0.9208467602729797}
{"mode": "train", "epochs": 9, "timestep": 17673, "ep_reward": 937.33544921875, "reward": 0.8555728197097778, "action": -1.5054510831832886}
{"mode": "train", "epochs": 9, "timestep": 17674, "ep_reward": 938.1904907226562, "reward": 0.8550217151641846, "action": -0.8370199203491211}
{"mode": "train", "epochs": 9, "timestep": 17675, "ep_reward": 939.0323486328125, "reward": 0.8418824672698975, "action": -1.5734612941741943}
{"mode": "train", "epochs": 9, "timestep": 17676, "ep_reward": 939.83251953125, "reward": 0.8001478314399719, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 17677, "ep_reward": 940.5577392578125, "reward": 0.7252423763275146, "action": -0.4156801104545593}
{"mode": "train", "epochs": 9, "timestep": 17678, "ep_reward": 941.1912231445312, "reward": 0.6334835290908813, "action": 0.11889493465423584}
{"mode": "train", "epochs": 9, "timestep": 17679, "ep_reward": 941.7025756835938, "reward": 0.5113758444786072, "action": -1.7866206169128418}
{"mode": "train", "epochs": 9, "timestep": 17680, "ep_reward": 942.0662231445312, "reward": 0.36365675926208496, "action": -1.4266691207885742}
{"mode": "train", "epochs": 9, "timestep": 17681, "ep_reward": 942.3226928710938, "reward": 0.25644242763519287, "action": -1.4435127973556519}
{"mode": "train", "epochs": 9, "timestep": 17682, "ep_reward": 942.4519653320312, "reward": 0.129277765750885, "action": -1.1395381689071655}
{"mode": "train", "epochs": 9, "timestep": 17683, "ep_reward": 942.4359741210938, "reward": -0.01596355438232422, "action": -1.3820029497146606}
{"mode": "train", "epochs": 9, "timestep": 17684, "ep_reward": 942.5669555664062, "reward": 0.13100749254226685, "action": -1.3154419660568237}
{"mode": "train", "epochs": 9, "timestep": 17685, "ep_reward": 942.8331909179688, "reward": 0.266227126121521, "action": -0.7088210582733154}
{"mode": "train", "epochs": 9, "timestep": 17686, "ep_reward": 943.2413940429688, "reward": 0.4082317352294922, "action": -1.5476479530334473}
{"mode": "train", "epochs": 9, "timestep": 17687, "ep_reward": 943.77001953125, "reward": 0.5286056995391846, "action": -0.1857086420059204}
{"mode": "train", "epochs": 9, "timestep": 17688, "ep_reward": 944.4160766601562, "reward": 0.6460763216018677, "action": -0.5861032009124756}
{"mode": "train", "epochs": 9, "timestep": 17689, "ep_reward": 945.1507568359375, "reward": 0.7347027659416199, "action": -0.2714362144470215}
{"mode": "train", "epochs": 9, "timestep": 17690, "ep_reward": 945.953857421875, "reward": 0.8030967712402344, "action": -0.8001217246055603}
{"mode": "train", "epochs": 9, "timestep": 17691, "ep_reward": 946.8002319335938, "reward": 0.8463557362556458, "action": -1.5990798473358154}
{"mode": "train", "epochs": 9, "timestep": 17692, "ep_reward": 947.6666870117188, "reward": 0.8664721250534058, "action": -1.7856676578521729}
{"mode": "train", "epochs": 9, "timestep": 17693, "ep_reward": 948.5367431640625, "reward": 0.8700460195541382, "action": -0.7470601797103882}
{"mode": "train", "epochs": 9, "timestep": 17694, "ep_reward": 949.4029541015625, "reward": 0.8662031888961792, "action": -1.2722489833831787}
{"mode": "train", "epochs": 9, "timestep": 17695, "ep_reward": 950.2429809570312, "reward": 0.8400527238845825, "action": -1.4012386798858643}
{"mode": "train", "epochs": 9, "timestep": 17696, "ep_reward": 951.0333251953125, "reward": 0.7903572916984558, "action": -0.7565054893493652}
{"mode": "train", "epochs": 9, "timestep": 17697, "ep_reward": 951.7525634765625, "reward": 0.7192336320877075, "action": -0.45587337017059326}
{"mode": "train", "epochs": 9, "timestep": 17698, "ep_reward": 952.3709106445312, "reward": 0.6183211803436279, "action": -1.2326363325119019}
{"mode": "train", "epochs": 9, "timestep": 17699, "ep_reward": 952.8385620117188, "reward": 0.467628538608551, "action": -1.5181806087493896}
{"mode": "train", "epochs": 9, "timestep": 17700, "ep_reward": 953.1702270507812, "reward": 0.33166372776031494, "action": -0.7601805329322815}
{"mode": "train", "epochs": 9, "timestep": 17701, "ep_reward": 953.3883056640625, "reward": 0.21806448698043823, "action": -0.7207721471786499}
{"mode": "train", "epochs": 9, "timestep": 17702, "ep_reward": 953.4727783203125, "reward": 0.08444982767105103, "action": -0.8176662921905518}
{"mode": "train", "epochs": 9, "timestep": 17703, "ep_reward": 953.5059814453125, "reward": 0.03322875499725342, "action": -0.9940987229347229}
{"mode": "train", "epochs": 9, "timestep": 17704, "ep_reward": 953.6798095703125, "reward": 0.1738365888595581, "action": -0.5943447351455688}
{"mode": "train", "epochs": 9, "timestep": 17705, "ep_reward": 953.9984741210938, "reward": 0.31868988275527954, "action": -1.823047161102295}
{"mode": "train", "epochs": 9, "timestep": 17706, "ep_reward": 954.44189453125, "reward": 0.4434020519256592, "action": -1.1025360822677612}
{"mode": "train", "epochs": 9, "timestep": 17707, "ep_reward": 955.0064697265625, "reward": 0.5645883679389954, "action": -1.5054683685302734}
{"mode": "train", "epochs": 9, "timestep": 17708, "ep_reward": 955.6675415039062, "reward": 0.6610649228096008, "action": -1.5469515323638916}
{"mode": "train", "epochs": 9, "timestep": 17709, "ep_reward": 956.402587890625, "reward": 0.7350177764892578, "action": -1.3562427759170532}
{"mode": "train", "epochs": 9, "timestep": 17710, "ep_reward": 957.1912841796875, "reward": 0.7887259125709534, "action": -0.7225722074508667}
{"mode": "train", "epochs": 9, "timestep": 17711, "ep_reward": 958.0184326171875, "reward": 0.8271211385726929, "action": -0.6931543350219727}
{"mode": "train", "epochs": 9, "timestep": 17712, "ep_reward": 958.8642578125, "reward": 0.8458479642868042, "action": -0.7188674211502075}
{"mode": "train", "epochs": 9, "timestep": 17713, "ep_reward": 959.7096557617188, "reward": 0.8453876376152039, "action": -0.9232497215270996}
{"mode": "train", "epochs": 9, "timestep": 17714, "ep_reward": 960.5326538085938, "reward": 0.8230227828025818, "action": -0.9026258587837219}
{"mode": "train", "epochs": 9, "timestep": 17715, "ep_reward": 961.3098754882812, "reward": 0.777223527431488, "action": -0.9244412183761597}
{"mode": "train", "epochs": 9, "timestep": 17716, "ep_reward": 962.0115966796875, "reward": 0.7017094492912292, "action": -1.774112343788147}
{"mode": "train", "epochs": 9, "timestep": 17717, "ep_reward": 962.589599609375, "reward": 0.5780164003372192, "action": -1.0920873880386353}
{"mode": "train", "epochs": 9, "timestep": 17718, "ep_reward": 963.008056640625, "reward": 0.4184800386428833, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 17719, "ep_reward": 963.3275756835938, "reward": 0.3194984793663025, "action": -0.0499112606048584}
{"mode": "train", "epochs": 9, "timestep": 17720, "ep_reward": 963.5311279296875, "reward": 0.20355689525604248, "action": -0.3862130641937256}
{"mode": "train", "epochs": 9, "timestep": 17721, "ep_reward": 963.5985717773438, "reward": 0.06743490695953369, "action": -1.772416114807129}
{"mode": "train", "epochs": 9, "timestep": 17722, "ep_reward": 963.6491088867188, "reward": 0.05055433511734009, "action": -1.4754276275634766}
{"mode": "train", "epochs": 9, "timestep": 17723, "ep_reward": 963.8379516601562, "reward": 0.1888243556022644, "action": -1.2944903373718262}
{"mode": "train", "epochs": 9, "timestep": 17724, "ep_reward": 964.163330078125, "reward": 0.3253694176673889, "action": -1.0894849300384521}
{"mode": "train", "epochs": 9, "timestep": 17725, "ep_reward": 964.6228637695312, "reward": 0.45951908826828003, "action": -1.023004412651062}
{"mode": "train", "epochs": 9, "timestep": 17726, "ep_reward": 965.2023315429688, "reward": 0.5794835090637207, "action": -0.19426393508911133}
{"mode": "train", "epochs": 9, "timestep": 17727, "ep_reward": 965.8889770507812, "reward": 0.6866482496261597, "action": -0.33514493703842163}
{"mode": "train", "epochs": 9, "timestep": 17728, "ep_reward": 966.65625, "reward": 0.7672730088233948, "action": -0.6895274519920349}
{"mode": "train", "epochs": 9, "timestep": 17729, "ep_reward": 967.4784545898438, "reward": 0.8221960663795471, "action": -1.4554705619812012}
{"mode": "train", "epochs": 9, "timestep": 17730, "ep_reward": 968.33056640625, "reward": 0.8521344661712646, "action": -1.3739113807678223}
{"mode": "train", "epochs": 9, "timestep": 17731, "ep_reward": 969.1971435546875, "reward": 0.8665809631347656, "action": -1.5295205116271973}
{"mode": "train", "epochs": 9, "timestep": 17732, "ep_reward": 970.0609130859375, "reward": 0.8637747764587402, "action": -0.9402682781219482}
{"mode": "train", "epochs": 9, "timestep": 17733, "ep_reward": 970.909423828125, "reward": 0.8485163450241089, "action": -1.1141074895858765}
{"mode": "train", "epochs": 9, "timestep": 17734, "ep_reward": 971.7206420898438, "reward": 0.8112468123435974, "action": -1.0669288635253906}
{"mode": "train", "epochs": 9, "timestep": 17735, "ep_reward": 972.4694213867188, "reward": 0.7487651705741882, "action": -0.28369855880737305}
{"mode": "train", "epochs": 9, "timestep": 17736, "ep_reward": 973.13330078125, "reward": 0.6638673543930054, "action": -1.1695595979690552}
{"mode": "train", "epochs": 9, "timestep": 17737, "ep_reward": 973.6639404296875, "reward": 0.5306111574172974, "action": -1.181132197380066}
{"mode": "train", "epochs": 9, "timestep": 17738, "ep_reward": 974.0350341796875, "reward": 0.3711215853691101, "action": -1.325130820274353}
{"mode": "train", "epochs": 9, "timestep": 17739, "ep_reward": 974.3004150390625, "reward": 0.2654028534889221, "action": -1.6097443103790283}
{"mode": "train", "epochs": 9, "timestep": 17740, "ep_reward": 974.4403076171875, "reward": 0.1398841142654419, "action": -0.4313547611236572}
{"mode": "train", "epochs": 9, "timestep": 17741, "ep_reward": 974.434326171875, "reward": -0.0059812068939208984, "action": -1.8134512901306152}
{"mode": "train", "epochs": 9, "timestep": 17742, "ep_reward": 974.5547485351562, "reward": 0.1204146146774292, "action": -1.0178792476654053}
{"mode": "train", "epochs": 9, "timestep": 17743, "ep_reward": 974.813720703125, "reward": 0.2589486837387085, "action": -1.508131504058838}
{"mode": "train", "epochs": 9, "timestep": 17744, "ep_reward": 975.2047729492188, "reward": 0.39106887578964233, "action": -1.020665168762207}
{"mode": "train", "epochs": 9, "timestep": 17745, "ep_reward": 975.7245483398438, "reward": 0.519780158996582, "action": -1.4590122699737549}
{"mode": "train", "epochs": 9, "timestep": 17746, "ep_reward": 976.3497924804688, "reward": 0.6252321004867554, "action": -0.23749351501464844}
{"mode": "train", "epochs": 9, "timestep": 17747, "ep_reward": 977.071044921875, "reward": 0.7212554216384888, "action": -1.0656814575195312}
{"mode": "train", "epochs": 9, "timestep": 17748, "ep_reward": 977.8558959960938, "reward": 0.7848379611968994, "action": -0.21013283729553223}
{"mode": "train", "epochs": 9, "timestep": 17749, "ep_reward": 978.6910400390625, "reward": 0.835133969783783, "action": -0.1530342698097229}
{"mode": "train", "epochs": 9, "timestep": 17750, "ep_reward": 979.557861328125, "reward": 0.8667916059494019, "action": -0.03641027212142944}
{"mode": "train", "epochs": 9, "timestep": 17751, "ep_reward": 980.4409790039062, "reward": 0.8830933570861816, "action": -0.5113013982772827}
{"mode": "train", "epochs": 9, "timestep": 17752, "ep_reward": 981.3217163085938, "reward": 0.8807403445243835, "action": -1.4673707485198975}
{"mode": "train", "epochs": 9, "timestep": 17753, "ep_reward": 982.1763916015625, "reward": 0.8546712398529053, "action": -0.8217268586158752}
{"mode": "train", "epochs": 9, "timestep": 17754, "ep_reward": 982.9905395507812, "reward": 0.8141354918479919, "action": -1.6261913776397705}
{"mode": "train", "epochs": 9, "timestep": 17755, "ep_reward": 983.730224609375, "reward": 0.7396838665008545, "action": -1.6471755504608154}
{"mode": "train", "epochs": 9, "timestep": 17756, "ep_reward": 984.3599853515625, "reward": 0.6297780275344849, "action": -1.308201551437378}
{"mode": "train", "epochs": 9, "timestep": 17757, "ep_reward": 984.8421630859375, "reward": 0.48219799995422363, "action": -1.272202491760254}
{"mode": "train", "epochs": 9, "timestep": 17758, "ep_reward": 985.1856079101562, "reward": 0.3434227705001831, "action": -1.1390104293823242}
{"mode": "train", "epochs": 9, "timestep": 17759, "ep_reward": 985.4177856445312, "reward": 0.23215168714523315, "action": -0.9278373718261719}
{"mode": "train", "epochs": 9, "timestep": 17760, "ep_reward": 985.5186157226562, "reward": 0.10083198547363281, "action": -1.078798532485962}
{"mode": "train", "epochs": 9, "timestep": 17761, "ep_reward": 985.534423828125, "reward": 0.01579129695892334, "action": -0.5402975082397461}
{"mode": "train", "epochs": 9, "timestep": 17762, "ep_reward": 985.6930541992188, "reward": 0.15862822532653809, "action": -0.930584192276001}
{"mode": "train", "epochs": 9, "timestep": 17763, "ep_reward": 985.9922485351562, "reward": 0.2991834878921509, "action": -1.1943153142929077}
{"mode": "train", "epochs": 9, "timestep": 17764, "ep_reward": 986.4253540039062, "reward": 0.4330991506576538, "action": -0.311642587184906}
{"mode": "train", "epochs": 9, "timestep": 17765, "ep_reward": 986.98974609375, "reward": 0.5643712282180786, "action": -1.0972832441329956}
{"mode": "train", "epochs": 9, "timestep": 17766, "ep_reward": 987.6552124023438, "reward": 0.6654869318008423, "action": -1.5018107891082764}
{"mode": "train", "epochs": 9, "timestep": 17767, "ep_reward": 988.3960571289062, "reward": 0.7408335208892822, "action": -1.3095368146896362}
{"mode": "train", "epochs": 9, "timestep": 17768, "ep_reward": 989.1932373046875, "reward": 0.7972051501274109, "action": -0.6113463044166565}
{"mode": "train", "epochs": 9, "timestep": 17769, "ep_reward": 990.033203125, "reward": 0.8399691581726074, "action": -0.9009252190589905}
{"mode": "train", "epochs": 9, "timestep": 17770, "ep_reward": 990.8953857421875, "reward": 0.8621702194213867, "action": -0.940665602684021}
{"mode": "train", "epochs": 9, "timestep": 17771, "ep_reward": 991.7628784179688, "reward": 0.867470383644104, "action": -1.8000450134277344}
{"mode": "train", "epochs": 9, "timestep": 17772, "ep_reward": 992.6112670898438, "reward": 0.8484035134315491, "action": -0.6459943652153015}
{"mode": "train", "epochs": 9, "timestep": 17773, "ep_reward": 993.4307861328125, "reward": 0.8195044994354248, "action": -1.0396255254745483}
{"mode": "train", "epochs": 9, "timestep": 17774, "ep_reward": 994.1932373046875, "reward": 0.7624495029449463, "action": -1.453108549118042}
{"mode": "train", "epochs": 9, "timestep": 17775, "ep_reward": 994.862060546875, "reward": 0.6688534021377563, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 17776, "ep_reward": 995.388916015625, "reward": 0.5268806219100952, "action": -1.1145051717758179}
{"mode": "train", "epochs": 9, "timestep": 17777, "ep_reward": 995.7713623046875, "reward": 0.3824576139450073, "action": -1.4026777744293213}
{"mode": "train", "epochs": 9, "timestep": 17778, "ep_reward": 996.0506591796875, "reward": 0.27928876876831055, "action": -0.6738170385360718}
{"mode": "train", "epochs": 9, "timestep": 17779, "ep_reward": 996.2066650390625, "reward": 0.156030535697937, "action": -0.5760742425918579}
{"mode": "train", "epochs": 9, "timestep": 17780, "ep_reward": 996.2194213867188, "reward": 0.012759685516357422, "action": -0.6101455092430115}
{"mode": "train", "epochs": 9, "timestep": 17781, "ep_reward": 996.322998046875, "reward": 0.10359984636306763, "action": -1.2319772243499756}
{"mode": "train", "epochs": 9, "timestep": 17782, "ep_reward": 996.5621337890625, "reward": 0.23912841081619263, "action": -0.4825384020805359}
{"mode": "train", "epochs": 9, "timestep": 17783, "ep_reward": 996.9470825195312, "reward": 0.38493913412094116, "action": -0.8855552077293396}
{"mode": "train", "epochs": 9, "timestep": 17784, "ep_reward": 997.462158203125, "reward": 0.5150859951972961, "action": -0.9760293960571289}
{"mode": "train", "epochs": 9, "timestep": 17785, "ep_reward": 998.0885620117188, "reward": 0.6264067888259888, "action": -0.9845991134643555}
{"mode": "train", "epochs": 9, "timestep": 17786, "ep_reward": 998.8043823242188, "reward": 0.7158225774765015, "action": -1.183483362197876}
{"mode": "train", "epochs": 9, "timestep": 17787, "ep_reward": 999.5855102539062, "reward": 0.7811170816421509, "action": -1.8221791982650757}
{"mode": "train", "epochs": 9, "timestep": 17788, "ep_reward": 1000.4064331054688, "reward": 0.820946216583252, "action": -0.5509887933731079}
{"mode": "train", "epochs": 9, "timestep": 17789, "ep_reward": 1001.2599487304688, "reward": 0.8535382747650146, "action": -1.9388902187347412}
{"mode": "train", "epochs": 9, "timestep": 17790, "ep_reward": 1002.1170654296875, "reward": 0.857086181640625, "action": -1.8738336563110352}
{"mode": "train", "epochs": 9, "timestep": 17791, "ep_reward": 1002.9602661132812, "reward": 0.8432048559188843, "action": -1.8543989658355713}
{"mode": "train", "epochs": 9, "timestep": 17792, "ep_reward": 1003.7683715820312, "reward": 0.8080883622169495, "action": -0.1850009560585022}
{"mode": "train", "epochs": 9, "timestep": 17793, "ep_reward": 1004.53271484375, "reward": 0.7643424868583679, "action": -1.3316690921783447}
{"mode": "train", "epochs": 9, "timestep": 17794, "ep_reward": 1005.2100219726562, "reward": 0.6773253679275513, "action": -1.369175672531128}
{"mode": "train", "epochs": 9, "timestep": 17795, "ep_reward": 1005.7600708007812, "reward": 0.5500747561454773, "action": -0.6169908046722412}
{"mode": "train", "epochs": 9, "timestep": 17796, "ep_reward": 1006.1589965820312, "reward": 0.3989328145980835, "action": -0.9470925331115723}
{"mode": "train", "epochs": 9, "timestep": 17797, "ep_reward": 1006.458251953125, "reward": 0.2992306351661682, "action": -1.1526315212249756}
{"mode": "train", "epochs": 9, "timestep": 17798, "ep_reward": 1006.6378784179688, "reward": 0.17960089445114136, "action": -0.7494751214981079}
{"mode": "train", "epochs": 9, "timestep": 17799, "ep_reward": 1006.6777954101562, "reward": 0.039899468421936035, "action": -0.9498657584190369}
{"mode": "train", "epochs": 9, "timestep": 17800, "ep_reward": 1006.7557983398438, "reward": 0.07800382375717163, "action": -1.2132002115249634}
{"mode": "train", "epochs": 9, "timestep": 17801, "ep_reward": 1006.9686889648438, "reward": 0.2128722071647644, "action": -1.4767042398452759}
{"mode": "train", "epochs": 9, "timestep": 17802, "ep_reward": 1007.3158569335938, "reward": 0.3471512794494629, "action": -1.833540916442871}
{"mode": "train", "epochs": 9, "timestep": 17803, "ep_reward": 1007.7869262695312, "reward": 0.4710724949836731, "action": -0.7409811019897461}
{"mode": "train", "epochs": 9, "timestep": 17804, "ep_reward": 1008.379638671875, "reward": 0.5927121639251709, "action": -1.253458023071289}
{"mode": "train", "epochs": 9, "timestep": 17805, "ep_reward": 1009.06494140625, "reward": 0.6853179931640625, "action": -1.811164379119873}
{"mode": "train", "epochs": 9, "timestep": 17806, "ep_reward": 1009.8139038085938, "reward": 0.7489707469940186, "action": -1.1515953540802002}
{"mode": "train", "epochs": 9, "timestep": 17807, "ep_reward": 1010.6107788085938, "reward": 0.796889066696167, "action": -0.7187941074371338}
{"mode": "train", "epochs": 9, "timestep": 17808, "ep_reward": 1011.43798828125, "reward": 0.8272069096565247, "action": 0.033629417419433594}
{"mode": "train", "epochs": 9, "timestep": 17809, "ep_reward": 1012.281982421875, "reward": 0.8439980149269104, "action": -0.8526309728622437}
{"mode": "train", "epochs": 9, "timestep": 17810, "ep_reward": 1013.1146240234375, "reward": 0.8326244354248047, "action": -1.147709846496582}
{"mode": "train", "epochs": 9, "timestep": 17811, "ep_reward": 1013.9105834960938, "reward": 0.7959619760513306, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 17812, "ep_reward": 1014.6322021484375, "reward": 0.7215991616249084, "action": -0.9336262345314026}
{"mode": "train", "epochs": 9, "timestep": 17813, "ep_reward": 1015.2551879882812, "reward": 0.6230101585388184, "action": -0.6301873922348022}
{"mode": "train", "epochs": 9, "timestep": 17814, "ep_reward": 1015.7426147460938, "reward": 0.4874405264854431, "action": -1.3669136762619019}
{"mode": "train", "epochs": 9, "timestep": 17815, "ep_reward": 1016.1053466796875, "reward": 0.3627336025238037, "action": -0.6380784511566162}
{"mode": "train", "epochs": 9, "timestep": 17816, "ep_reward": 1016.3605346679688, "reward": 0.2551892399787903, "action": -1.538059115409851}
{"mode": "train", "epochs": 9, "timestep": 17817, "ep_reward": 1016.4883422851562, "reward": 0.12782984972000122, "action": -1.1517324447631836}
{"mode": "train", "epochs": 9, "timestep": 17818, "ep_reward": 1016.4739990234375, "reward": -0.014345884323120117, "action": -1.5675764083862305}
{"mode": "train", "epochs": 9, "timestep": 17819, "ep_reward": 1016.6065063476562, "reward": 0.1325281858444214, "action": -0.6776564717292786}
{"mode": "train", "epochs": 9, "timestep": 17820, "ep_reward": 1016.8822021484375, "reward": 0.27572083473205566, "action": -0.13285821676254272}
{"mode": "train", "epochs": 9, "timestep": 17821, "ep_reward": 1017.3050537109375, "reward": 0.4228448271751404, "action": -1.3272336721420288}
{"mode": "train", "epochs": 9, "timestep": 17822, "ep_reward": 1017.847900390625, "reward": 0.5428174734115601, "action": -1.3409841060638428}
{"mode": "train", "epochs": 9, "timestep": 17823, "ep_reward": 1018.493408203125, "reward": 0.6454823017120361, "action": -0.9495767951011658}
{"mode": "train", "epochs": 9, "timestep": 17824, "ep_reward": 1019.2244873046875, "reward": 0.7310768365859985, "action": -1.0846703052520752}
{"mode": "train", "epochs": 9, "timestep": 17825, "ep_reward": 1020.0181274414062, "reward": 0.793636679649353, "action": -0.966200590133667}
{"mode": "train", "epochs": 9, "timestep": 17826, "ep_reward": 1020.8557739257812, "reward": 0.8376230001449585, "action": -0.7616175413131714}
{"mode": "train", "epochs": 9, "timestep": 17827, "ep_reward": 1021.7216186523438, "reward": 0.8658413887023926, "action": -0.7461908459663391}
{"mode": "train", "epochs": 9, "timestep": 17828, "ep_reward": 1022.6001586914062, "reward": 0.8785114884376526, "action": 0.036043643951416016}
{"mode": "train", "epochs": 9, "timestep": 17829, "ep_reward": 1023.4827880859375, "reward": 0.8826084733009338, "action": -0.5262115001678467}
{"mode": "train", "epochs": 9, "timestep": 17830, "ep_reward": 1024.349853515625, "reward": 0.867011547088623, "action": -1.0410174131393433}
{"mode": "train", "epochs": 9, "timestep": 17831, "ep_reward": 1025.1788330078125, "reward": 0.8289507627487183, "action": -1.4947803020477295}
{"mode": "train", "epochs": 9, "timestep": 17832, "ep_reward": 1025.941162109375, "reward": 0.7623344659805298, "action": -1.618272066116333}
{"mode": "train", "epochs": 9, "timestep": 17833, "ep_reward": 1026.60302734375, "reward": 0.6618148684501648, "action": -0.020689964294433594}
{"mode": "train", "epochs": 9, "timestep": 17834, "ep_reward": 1027.1468505859375, "reward": 0.5438178777694702, "action": -1.7494158744812012}
{"mode": "train", "epochs": 9, "timestep": 17835, "ep_reward": 1027.513671875, "reward": 0.3668771982192993, "action": -1.4924650192260742}
{"mode": "train", "epochs": 9, "timestep": 17836, "ep_reward": 1027.7740478515625, "reward": 0.26036709547042847, "action": -1.298931360244751}
{"mode": "train", "epochs": 9, "timestep": 17837, "ep_reward": 1027.907958984375, "reward": 0.13392144441604614, "action": -0.2784830331802368}
{"mode": "train", "epochs": 9, "timestep": 17838, "ep_reward": 1027.895263671875, "reward": -0.012650251388549805, "action": -0.6663291454315186}
{"mode": "train", "epochs": 9, "timestep": 17839, "ep_reward": 1028.021728515625, "reward": 0.12652581930160522, "action": -0.3749297857284546}
{"mode": "train", "epochs": 9, "timestep": 17840, "ep_reward": 1028.2950439453125, "reward": 0.27328407764434814, "action": -0.6226847171783447}
{"mode": "train", "epochs": 9, "timestep": 17841, "ep_reward": 1028.708984375, "reward": 0.413984477519989, "action": -1.8471553325653076}
{"mode": "train", "epochs": 9, "timestep": 17842, "ep_reward": 1029.2384033203125, "reward": 0.5293881297111511, "action": -0.590510368347168}
{"mode": "train", "epochs": 9, "timestep": 17843, "ep_reward": 1029.8807373046875, "reward": 0.6423245072364807, "action": -0.7518718242645264}
{"mode": "train", "epochs": 9, "timestep": 17844, "ep_reward": 1030.6112060546875, "reward": 0.7305132150650024, "action": -1.1763439178466797}
{"mode": "train", "epochs": 9, "timestep": 17845, "ep_reward": 1031.4039306640625, "reward": 0.7926938533782959, "action": -0.8461505770683289}
{"mode": "train", "epochs": 9, "timestep": 17846, "ep_reward": 1032.2420654296875, "reward": 0.8381955623626709, "action": -1.1787060499191284}
{"mode": "train", "epochs": 9, "timestep": 17847, "ep_reward": 1033.10546875, "reward": 0.8634336590766907, "action": -1.7842977046966553}
{"mode": "train", "epochs": 9, "timestep": 17848, "ep_reward": 1033.9737548828125, "reward": 0.8682633638381958, "action": -0.37552452087402344}
{"mode": "train", "epochs": 9, "timestep": 17849, "ep_reward": 1034.8424072265625, "reward": 0.8687114715576172, "action": -1.6154981851577759}
{"mode": "train", "epochs": 9, "timestep": 17850, "ep_reward": 1035.6834716796875, "reward": 0.8410327434539795, "action": -1.306792974472046}
{"mode": "train", "epochs": 9, "timestep": 17851, "ep_reward": 1036.4774169921875, "reward": 0.7939056158065796, "action": -0.07981294393539429}
{"mode": "train", "epochs": 9, "timestep": 17852, "ep_reward": 1037.210205078125, "reward": 0.7328295707702637, "action": -0.7446932196617126}
{"mode": "train", "epochs": 9, "timestep": 17853, "ep_reward": 1037.8427734375, "reward": 0.632559061050415, "action": -1.1694154739379883}
{"mode": "train", "epochs": 9, "timestep": 17854, "ep_reward": 1038.3302001953125, "reward": 0.4874052405357361, "action": -1.78358793258667}
{"mode": "train", "epochs": 9, "timestep": 17855, "ep_reward": 1038.6717529296875, "reward": 0.3415289521217346, "action": -1.1231282949447632}
{"mode": "train", "epochs": 9, "timestep": 17856, "ep_reward": 1038.901611328125, "reward": 0.22979813814163208, "action": -1.484360933303833}
{"mode": "train", "epochs": 9, "timestep": 17857, "ep_reward": 1038.999755859375, "reward": 0.09819388389587402, "action": -1.039055585861206}
{"mode": "train", "epochs": 9, "timestep": 17858, "ep_reward": 1039.0184326171875, "reward": 0.018647491931915283, "action": -0.4831126928329468}
{"mode": "train", "epochs": 9, "timestep": 17859, "ep_reward": 1039.1795654296875, "reward": 0.16111552715301514, "action": -0.8551006317138672}
{"mode": "train", "epochs": 9, "timestep": 17860, "ep_reward": 1039.4822998046875, "reward": 0.30273187160491943, "action": -0.4836069345474243}
{"mode": "train", "epochs": 9, "timestep": 17861, "ep_reward": 1039.927001953125, "reward": 0.44472581148147583, "action": -0.6598210334777832}
{"mode": "train", "epochs": 9, "timestep": 17862, "ep_reward": 1040.496826171875, "reward": 0.5698345899581909, "action": -1.5447622537612915}
{"mode": "train", "epochs": 9, "timestep": 17863, "ep_reward": 1041.162353515625, "reward": 0.6655070185661316, "action": -1.1030566692352295}
{"mode": "train", "epochs": 9, "timestep": 17864, "ep_reward": 1041.9071044921875, "reward": 0.7447947859764099, "action": -0.7981122732162476}
{"mode": "train", "epochs": 9, "timestep": 17865, "ep_reward": 1042.7125244140625, "reward": 0.8053756356239319, "action": -0.9792400598526001}
{"mode": "train", "epochs": 9, "timestep": 17866, "ep_reward": 1043.557373046875, "reward": 0.8448551893234253, "action": -0.04448270797729492}
{"mode": "train", "epochs": 9, "timestep": 17867, "ep_reward": 1044.4322509765625, "reward": 0.8748376369476318, "action": -0.6712576150894165}
{"mode": "train", "epochs": 9, "timestep": 17868, "ep_reward": 1045.3165283203125, "reward": 0.8843216300010681, "action": -1.4248145818710327}
{"mode": "train", "epochs": 9, "timestep": 17869, "ep_reward": 1046.189697265625, "reward": 0.8732225298881531, "action": -0.3905767798423767}
{"mode": "train", "epochs": 9, "timestep": 17870, "ep_reward": 1047.043701171875, "reward": 0.8540577292442322, "action": -1.671489953994751}
{"mode": "train", "epochs": 9, "timestep": 17871, "ep_reward": 1047.846923828125, "reward": 0.803176760673523, "action": -1.0593582391738892}
{"mode": "train", "epochs": 9, "timestep": 17872, "ep_reward": 1048.577880859375, "reward": 0.7309225797653198, "action": -0.7988287210464478}
{"mode": "train", "epochs": 9, "timestep": 17873, "ep_reward": 1049.206298828125, "reward": 0.6284241676330566, "action": -0.5629839301109314}
{"mode": "train", "epochs": 9, "timestep": 17874, "ep_reward": 1049.697265625, "reward": 0.4909723401069641, "action": -1.2045925855636597}
{"mode": "train", "epochs": 9, "timestep": 17875, "ep_reward": 1050.0343017578125, "reward": 0.3369942903518677, "action": -0.9751248955726624}
{"mode": "train", "epochs": 9, "timestep": 17876, "ep_reward": 1050.2586669921875, "reward": 0.22431570291519165, "action": -1.668518304824829}
{"mode": "train", "epochs": 9, "timestep": 17877, "ep_reward": 1050.3505859375, "reward": 0.09187465906143188, "action": -0.8806169033050537}
{"mode": "train", "epochs": 9, "timestep": 17878, "ep_reward": 1050.3758544921875, "reward": 0.025265812873840332, "action": -1.685304880142212}
{"mode": "train", "epochs": 9, "timestep": 17879, "ep_reward": 1050.5428466796875, "reward": 0.16695493459701538, "action": -1.235751986503601}
{"mode": "train", "epochs": 9, "timestep": 17880, "ep_reward": 1050.8468017578125, "reward": 0.30390244722366333, "action": -1.1197612285614014}
{"mode": "train", "epochs": 9, "timestep": 17881, "ep_reward": 1051.2857666015625, "reward": 0.43898850679397583, "action": -0.4712277054786682}
{"mode": "train", "epochs": 9, "timestep": 17882, "ep_reward": 1051.853759765625, "reward": 0.5679336786270142, "action": -0.8623058795928955}
{"mode": "train", "epochs": 9, "timestep": 17883, "ep_reward": 1052.5245361328125, "reward": 0.6707184314727783, "action": -1.3485995531082153}
{"mode": "train", "epochs": 9, "timestep": 17884, "ep_reward": 1053.2703857421875, "reward": 0.7458386421203613, "action": -1.9336614608764648}
{"mode": "train", "epochs": 9, "timestep": 17885, "ep_reward": 1054.0650634765625, "reward": 0.7946661114692688, "action": -1.3403644561767578}
{"mode": "train", "epochs": 9, "timestep": 17886, "ep_reward": 1054.8946533203125, "reward": 0.8296489715576172, "action": -0.9155414700508118}
{"mode": "train", "epochs": 9, "timestep": 17887, "ep_reward": 1055.7442626953125, "reward": 0.8496497273445129, "action": -1.257401943206787}
{"mode": "train", "epochs": 9, "timestep": 17888, "ep_reward": 1056.592529296875, "reward": 0.8483233451843262, "action": -1.5653645992279053}
{"mode": "train", "epochs": 9, "timestep": 17889, "ep_reward": 1057.4168701171875, "reward": 0.8243021965026855, "action": -1.478519082069397}
{"mode": "train", "epochs": 9, "timestep": 17890, "ep_reward": 1058.193603515625, "reward": 0.7767583131790161, "action": -1.3063938617706299}
{"mode": "train", "epochs": 9, "timestep": 17891, "ep_reward": 1058.89404296875, "reward": 0.7003999948501587, "action": -0.9779958128929138}
{"mode": "train", "epochs": 9, "timestep": 17892, "ep_reward": 1059.4844970703125, "reward": 0.5904870629310608, "action": -1.1304551362991333}
{"mode": "train", "epochs": 9, "timestep": 17893, "ep_reward": 1059.919677734375, "reward": 0.4352148771286011, "action": 0.44332611560821533}
{"mode": "train", "epochs": 9, "timestep": 17894, "ep_reward": 1060.2528076171875, "reward": 0.3330870270729065, "action": -1.150184988975525}
{"mode": "train", "epochs": 9, "timestep": 17895, "ep_reward": 1060.47265625, "reward": 0.21984702348709106, "action": -0.24837076663970947}
{"mode": "train", "epochs": 9, "timestep": 17896, "ep_reward": 1060.5592041015625, "reward": 0.08651798963546753, "action": -0.433541476726532}
{"mode": "train", "epochs": 9, "timestep": 17897, "ep_reward": 1060.5902099609375, "reward": 0.03103095293045044, "action": -1.3766121864318848}
{"mode": "train", "epochs": 9, "timestep": 17898, "ep_reward": 1060.76220703125, "reward": 0.1719667911529541, "action": -0.747728705406189}
{"mode": "train", "epochs": 9, "timestep": 17899, "ep_reward": 1061.0772705078125, "reward": 0.31503504514694214, "action": -1.1125929355621338}
{"mode": "train", "epochs": 9, "timestep": 17900, "ep_reward": 1061.5260009765625, "reward": 0.44871383905410767, "action": -0.18678462505340576}
{"mode": "train", "epochs": 9, "timestep": 17901, "ep_reward": 1062.10498046875, "reward": 0.5790137052536011, "action": -1.0936691761016846}
{"mode": "train", "epochs": 9, "timestep": 17902, "ep_reward": 1062.782470703125, "reward": 0.677532434463501, "action": -0.4278327226638794}
{"mode": "train", "epochs": 9, "timestep": 17903, "ep_reward": 1063.54296875, "reward": 0.7604374885559082, "action": -0.06308072805404663}
{"mode": "train", "epochs": 9, "timestep": 17904, "ep_reward": 1064.3670654296875, "reward": 0.8241525888442993, "action": -0.6233574151992798}
{"mode": "train", "epochs": 9, "timestep": 17905, "ep_reward": 1065.2310791015625, "reward": 0.8640152215957642, "action": -0.7259583473205566}
{"mode": "train", "epochs": 9, "timestep": 17906, "ep_reward": 1066.118896484375, "reward": 0.8878291249275208, "action": -0.5389126539230347}
{"mode": "train", "epochs": 9, "timestep": 17907, "ep_reward": 1067.0186767578125, "reward": 0.8997493386268616, "action": -0.9649932980537415}
{"mode": "train", "epochs": 9, "timestep": 17908, "ep_reward": 1067.914794921875, "reward": 0.8960720896720886, "action": -0.5004486441612244}
{"mode": "train", "epochs": 9, "timestep": 17909, "ep_reward": 1068.7972412109375, "reward": 0.8824304342269897, "action": -1.311532974243164}
{"mode": "train", "epochs": 9, "timestep": 17910, "ep_reward": 1069.643310546875, "reward": 0.8460536003112793, "action": -1.0386278629302979}
{"mode": "train", "epochs": 9, "timestep": 17911, "ep_reward": 1070.4337158203125, "reward": 0.7903831005096436, "action": -0.6594182252883911}
{"mode": "train", "epochs": 9, "timestep": 17912, "ep_reward": 1071.14501953125, "reward": 0.7112902402877808, "action": -0.9243837594985962}
{"mode": "train", "epochs": 9, "timestep": 17913, "ep_reward": 1071.74072265625, "reward": 0.5956463813781738, "action": -1.365836501121521}
{"mode": "train", "epochs": 9, "timestep": 17914, "ep_reward": 1072.1751708984375, "reward": 0.4344189167022705, "action": -0.6251108646392822}
{"mode": "train", "epochs": 9, "timestep": 17915, "ep_reward": 1072.468994140625, "reward": 0.2938075065612793, "action": -2.0}
{"mode": "train", "epochs": 9, "timestep": 17916, "ep_reward": 1072.642333984375, "reward": 0.1733912229537964, "action": 0.7398936748504639}
{"mode": "train", "epochs": 9, "timestep": 17917, "ep_reward": 1072.675048828125, "reward": 0.03272944688796997, "action": -0.9917526245117188}
{"mode": "train", "epochs": 9, "timestep": 17918, "ep_reward": 1072.760009765625, "reward": 0.08495008945465088, "action": -0.5328185558319092}
{"mode": "train", "epochs": 9, "timestep": 17919, "ep_reward": 1072.988525390625, "reward": 0.22851461172103882, "action": -1.3665204048156738}
{"mode": "train", "epochs": 9, "timestep": 17920, "ep_reward": 1073.3509521484375, "reward": 0.3624580502510071, "action": -0.7727892994880676}
{"mode": "train", "epochs": 9, "timestep": 17921, "ep_reward": 1073.847412109375, "reward": 0.4964481592178345, "action": -0.9372963309288025}
{"mode": "train", "epochs": 9, "timestep": 17922, "ep_reward": 1074.4586181640625, "reward": 0.6111658811569214, "action": -1.6469762325286865}
{"mode": "train", "epochs": 9, "timestep": 17923, "ep_reward": 1075.1558837890625, "reward": 0.6973246335983276, "action": -0.7847453951835632}
{"mode": "train", "epochs": 9, "timestep": 17924, "ep_reward": 1075.9261474609375, "reward": 0.7703241109848022, "action": -1.5357515811920166}
{"mode": "train", "epochs": 9, "timestep": 17925, "ep_reward": 1076.7413330078125, "reward": 0.8151483535766602, "action": -0.504056990146637}
{"mode": "train", "epochs": 9, "timestep": 17926, "ep_reward": 1077.591552734375, "reward": 0.8501657843589783, "action": -1.1306670904159546}
{"mode": "train", "epochs": 9, "timestep": 17927, "ep_reward": 1078.453857421875, "reward": 0.8622828722000122, "action": -0.6763594150543213}
{"mode": "train", "epochs": 9, "timestep": 17928, "ep_reward": 1079.3153076171875, "reward": 0.8615022897720337, "action": 0.02814316749572754}
{"mode": "train", "epochs": 9, "timestep": 17929, "ep_reward": 1080.16455078125, "reward": 0.8493039608001709, "action": -1.6861180067062378}
{"mode": "train", "epochs": 9, "timestep": 17930, "ep_reward": 1080.9654541015625, "reward": 0.8008602261543274, "action": -1.2406070232391357}
{"mode": "train", "epochs": 9, "timestep": 17931, "ep_reward": 1081.6943359375, "reward": 0.72892826795578, "action": -0.8290707468986511}
{"mode": "train", "epochs": 9, "timestep": 17932, "ep_reward": 1082.322021484375, "reward": 0.6276730298995972, "action": -0.653731107711792}
{"mode": "train", "epochs": 9, "timestep": 17933, "ep_reward": 1082.811767578125, "reward": 0.48968613147735596, "action": -1.4005628824234009}
{"mode": "train", "epochs": 9, "timestep": 17934, "ep_reward": 1083.1566162109375, "reward": 0.34486639499664307, "action": -1.1234813928604126}
{"mode": "train", "epochs": 9, "timestep": 17935, "ep_reward": 1083.3905029296875, "reward": 0.2338826060295105, "action": -0.8892656564712524}
{"mode": "train", "epochs": 9, "timestep": 17936, "ep_reward": 1083.4932861328125, "reward": 0.10273635387420654, "action": -1.6969802379608154}
{"mode": "train", "epochs": 9, "timestep": 17937, "ep_reward": 1083.5067138671875, "reward": 0.01347041130065918, "action": -1.592641830444336}
{"mode": "train", "epochs": 9, "timestep": 17938, "ep_reward": 1083.6634521484375, "reward": 0.15674090385437012, "action": -0.8568172454833984}
{"mode": "train", "epochs": 9, "timestep": 17939, "ep_reward": 1083.961669921875, "reward": 0.29820936918258667, "action": -0.8900808095932007}
{"mode": "train", "epochs": 9, "timestep": 17940, "ep_reward": 1084.3973388671875, "reward": 0.4356468915939331, "action": -0.7942217588424683}
{"mode": "train", "epochs": 9, "timestep": 17941, "ep_reward": 1084.958251953125, "reward": 0.5609272122383118, "action": -0.6927130222320557}
{"mode": "train", "epochs": 9, "timestep": 17942, "ep_reward": 1085.6251220703125, "reward": 0.6668840646743774, "action": -1.2266024351119995}
{"mode": "train", "epochs": 9, "timestep": 17943, "ep_reward": 1086.3699951171875, "reward": 0.7448856830596924, "action": -0.9228992462158203}
{"mode": "train", "epochs": 9, "timestep": 17944, "ep_reward": 1087.1746826171875, "reward": 0.8046474456787109, "action": 0.11389970779418945}
{"mode": "train", "epochs": 9, "timestep": 17945, "ep_reward": 1088.0279541015625, "reward": 0.8533030152320862, "action": -1.716491937637329}
{"mode": "train", "epochs": 9, "timestep": 17946, "ep_reward": 1088.8980712890625, "reward": 0.8700920343399048, "action": -1.1509138345718384}
{"mode": "train", "epochs": 9, "timestep": 17947, "ep_reward": 1089.7745361328125, "reward": 0.8764467835426331, "action": -1.627909541130066}
{"mode": "train", "epochs": 9, "timestep": 17948, "ep_reward": 1090.6378173828125, "reward": 0.8632715940475464, "action": -1.085681676864624}
{"mode": "train", "epochs": 9, "timestep": 17949, "ep_reward": 1091.4742431640625, "reward": 0.8364313244819641, "action": -0.19588017463684082}
{"mode": "train", "epochs": 9, "timestep": 17950, "ep_reward": 1092.270751953125, "reward": 0.7965152263641357, "action": -0.9017395377159119}
{"mode": "train", "epochs": 9, "timestep": 17951, "ep_reward": 1092.993896484375, "reward": 0.7231533527374268, "action": -1.1273449659347534}
{"mode": "train", "epochs": 9, "timestep": 17952, "ep_reward": 1093.60693359375, "reward": 0.6129910945892334, "action": -0.8668288588523865}
{"mode": "train", "epochs": 9, "timestep": 17953, "ep_reward": 1094.072998046875, "reward": 0.4661157727241516, "action": -1.1664336919784546}
{"mode": "train", "epochs": 9, "timestep": 17954, "ep_reward": 1094.3994140625, "reward": 0.3263567090034485, "action": -0.6381160020828247}
{"mode": "train", "epochs": 9, "timestep": 17955, "ep_reward": 1094.611083984375, "reward": 0.21165186166763306, "action": -1.3003267049789429}
{"mode": "train", "epochs": 9, "timestep": 17956, "ep_reward": 1094.688232421875, "reward": 0.07712370157241821, "action": -0.33148646354675293}
{"mode": "train", "epochs": 9, "timestep": 17957, "ep_reward": 1094.7291259765625, "reward": 0.040944457054138184, "action": -0.4098341464996338}
{"mode": "train", "epochs": 9, "timestep": 17958, "ep_reward": 1094.913818359375, "reward": 0.18470609188079834, "action": -1.0696001052856445}
{"mode": "train", "epochs": 9, "timestep": 17959, "ep_reward": 1095.2369384765625, "reward": 0.3230783939361572, "action": -1.005792498588562}
{"mode": "train", "epochs": 9, "timestep": 17960, "ep_reward": 1095.6943359375, "reward": 0.45738887786865234, "action": -1.2343891859054565}
{"mode": "train", "epochs": 9, "timestep": 17961, "ep_reward": 1096.26904296875, "reward": 0.5747541189193726, "action": -1.6894718408584595}
{"mode": "train", "epochs": 9, "timestep": 17962, "ep_reward": 1096.9365234375, "reward": 0.6674745082855225, "action": -1.962418794631958}
{"mode": "train", "epochs": 9, "timestep": 17963, "ep_reward": 1097.6729736328125, "reward": 0.7363954782485962, "action": -0.5196380019187927}
{"mode": "train", "epochs": 9, "timestep": 17964, "ep_reward": 1098.470703125, "reward": 0.7976851463317871, "action": -0.6122550964355469}
{"mode": "train", "epochs": 9, "timestep": 17965, "ep_reward": 1099.3070068359375, "reward": 0.8363465070724487, "action": -1.5258691310882568}
{"mode": "train", "epochs": 9, "timestep": 17966, "ep_reward": 1100.155029296875, "reward": 0.848070502281189, "action": -1.3689435720443726}
{"mode": "train", "epochs": 9, "timestep": 17967, "ep_reward": 1100.997802734375, "reward": 0.8427655696868896, "action": -0.77106112241745}
{"mode": "train", "epochs": 9, "timestep": 17968, "ep_reward": 1101.8204345703125, "reward": 0.8226015567779541, "action": -1.6162149906158447}
{"mode": "train", "epochs": 9, "timestep": 17969, "ep_reward": 1102.5902099609375, "reward": 0.7698041200637817, "action": -0.9402174353599548}
{"mode": "train", "epochs": 9, "timestep": 17970, "ep_reward": 1103.283447265625, "reward": 0.6932932138442993, "action": -0.7069319486618042}
{"mode": "train", "epochs": 9, "timestep": 17971, "ep_reward": 1103.8662109375, "reward": 0.582819938659668, "action": -1.5302059650421143}
{"mode": "train", "epochs": 9, "timestep": 17972, "ep_reward": 1104.2838134765625, "reward": 0.41755974292755127, "action": -1.3038380146026611}
{"mode": "train", "epochs": 9, "timestep": 17973, "ep_reward": 1104.6038818359375, "reward": 0.3200981616973877, "action": -0.18153250217437744}
{"mode": "train", "epochs": 9, "timestep": 17974, "ep_reward": 1104.80810546875, "reward": 0.20426762104034424, "action": -0.4703710675239563}
{"mode": "train", "epochs": 9, "timestep": 17975, "ep_reward": 1104.87646484375, "reward": 0.06837379932403564, "action": -1.17609441280365}
{"mode": "train", "epochs": 9, "timestep": 17976, "ep_reward": 1104.92626953125, "reward": 0.049819767475128174, "action": -0.6690027713775635}
{"mode": "train", "epochs": 9, "timestep": 17977, "ep_reward": 1105.116943359375, "reward": 0.1906542181968689, "action": -0.9251052141189575}
{"mode": "train", "epochs": 9, "timestep": 17978, "ep_reward": 1105.4481201171875, "reward": 0.3312193751335144, "action": -1.2480169534683228}
{"mode": "train", "epochs": 9, "timestep": 17979, "ep_reward": 1105.9102783203125, "reward": 0.4621279239654541, "action": -1.3679276704788208}
{"mode": "train", "epochs": 9, "timestep": 17980, "ep_reward": 1106.4879150390625, "reward": 0.5775847434997559, "action": -1.191244125366211}
{"mode": "train", "epochs": 9, "timestep": 17981, "ep_reward": 1107.162841796875, "reward": 0.6749112606048584, "action": -0.7149658203125}
{"mode": "train", "epochs": 9, "timestep": 17982, "ep_reward": 1107.916748046875, "reward": 0.7539642453193665, "action": -1.5791444778442383}
{"mode": "train", "epochs": 9, "timestep": 17983, "ep_reward": 1108.71923828125, "reward": 0.8025035262107849, "action": -1.5979169607162476}
{"mode": "train", "epochs": 9, "timestep": 17984, "ep_reward": 1109.55078125, "reward": 0.8315591812133789, "action": -0.5174533128738403}
{"mode": "train", "epochs": 9, "timestep": 17985, "ep_reward": 1110.40234375, "reward": 0.8515403866767883, "action": -1.203957200050354}
{"mode": "train", "epochs": 9, "timestep": 17986, "ep_reward": 1111.2493896484375, "reward": 0.8470375537872314, "action": -0.8042261600494385}
{"mode": "train", "epochs": 9, "timestep": 17987, "ep_reward": 1112.0758056640625, "reward": 0.826400637626648, "action": -1.0374996662139893}
{"mode": "train", "epochs": 9, "timestep": 17988, "ep_reward": 1112.8560791015625, "reward": 0.7802529335021973, "action": -0.6350115537643433}
{"mode": "train", "epochs": 9, "timestep": 17989, "ep_reward": 1113.5657958984375, "reward": 0.7096933126449585, "action": -0.942302942276001}
{"mode": "train", "epochs": 9, "timestep": 17990, "ep_reward": 1114.166259765625, "reward": 0.6004090309143066, "action": -0.756558895111084}
{"mode": "train", "epochs": 9, "timestep": 17991, "ep_reward": 1114.618896484375, "reward": 0.4526599645614624, "action": -1.1963977813720703}
{"mode": "train", "epochs": 9, "timestep": 17992, "ep_reward": 1114.9481201171875, "reward": 0.32921868562698364, "action": -0.9112452268600464}
{"mode": "train", "epochs": 9, "timestep": 17993, "ep_reward": 1115.1632080078125, "reward": 0.21509653329849243, "action": -1.2844740152359009}
{"mode": "train", "epochs": 9, "timestep": 17994, "ep_reward": 1115.244384765625, "reward": 0.08112388849258423, "action": 0.19873285293579102}
{"mode": "train", "epochs": 9, "timestep": 17995, "ep_reward": 1115.281005859375, "reward": 0.03659772872924805, "action": -1.8326435089111328}
{"mode": "train", "epochs": 9, "timestep": 17996, "ep_reward": 1115.4578857421875, "reward": 0.17682230472564697, "action": -1.1701693534851074}
{"mode": "train", "epochs": 9, "timestep": 17997, "ep_reward": 1115.772705078125, "reward": 0.31480348110198975, "action": -0.6346350908279419}
{"mode": "train", "epochs": 9, "timestep": 17998, "ep_reward": 1116.2275390625, "reward": 0.4547756314277649, "action": -1.4027204513549805}
{"mode": "train", "epochs": 9, "timestep": 17999, "ep_reward": 1116.79833984375, "reward": 0.5707549452781677, "action": -1.306593418121338}
{"mode": "train", "epochs": 9, "timestep": 18000, "ep_reward": 1117.4666748046875, "reward": 0.6683657169342041, "action": -0.45573949813842773}
{"mode": "train", "epochs": 10, "timestep": 18001, "ep_reward": 0.9689611792564392, "reward": 0.9689611792564392, "action": -1.02801513671875}
{"mode": "train", "epochs": 10, "timestep": 18002, "ep_reward": 1.9354326725006104, "reward": 0.9664714932441711, "action": -0.6293457746505737}
{"mode": "train", "epochs": 10, "timestep": 18003, "ep_reward": 2.895443916320801, "reward": 0.96001136302948, "action": 0.18272626399993896}
{"mode": "train", "epochs": 10, "timestep": 18004, "ep_reward": 3.8417348861694336, "reward": 0.9462909698486328, "action": -0.6785508990287781}
{"mode": "train", "epochs": 10, "timestep": 18005, "ep_reward": 4.769697189331055, "reward": 0.9279623627662659, "action": -0.3973473906517029}
{"mode": "train", "epochs": 10, "timestep": 18006, "ep_reward": 5.6699957847595215, "reward": 0.900298535823822, "action": -0.2574387192726135}
{"mode": "train", "epochs": 10, "timestep": 18007, "ep_reward": 6.530489444732666, "reward": 0.8604934811592102, "action": -0.2521354854106903}
{"mode": "train", "epochs": 10, "timestep": 18008, "ep_reward": 7.336156845092773, "reward": 0.8056672811508179, "action": -1.381503701210022}
{"mode": "train", "epochs": 10, "timestep": 18009, "ep_reward": 8.07951831817627, "reward": 0.7433617115020752, "action": -0.6024534702301025}
{"mode": "train", "epochs": 10, "timestep": 18010, "ep_reward": 8.736577987670898, "reward": 0.6570594310760498, "action": -0.8523792028427124}
{"mode": "train", "epochs": 10, "timestep": 18011, "ep_reward": 9.2909574508667, "reward": 0.5543795824050903, "action": -0.7525050044059753}
{"mode": "train", "epochs": 10, "timestep": 18012, "ep_reward": 9.725168228149414, "reward": 0.43421101570129395, "action": -1.2764313220977783}
{"mode": "train", "epochs": 10, "timestep": 18013, "ep_reward": 10.035806655883789, "reward": 0.3106379508972168, "action": -0.6737077236175537}
{"mode": "train", "epochs": 10, "timestep": 18014, "ep_reward": 10.212814331054688, "reward": 0.1770075559616089, "action": -0.2620545029640198}
{"mode": "train", "epochs": 10, "timestep": 18015, "ep_reward": 10.397241592407227, "reward": 0.18442761898040771, "action": -0.4626612663269043}
{"mode": "train", "epochs": 10, "timestep": 18016, "ep_reward": 10.709214210510254, "reward": 0.31197285652160645, "action": -0.04405653476715088}
{"mode": "train", "epochs": 10, "timestep": 18017, "ep_reward": 11.142430305480957, "reward": 0.4332162141799927, "action": -0.554663360118866}
{"mode": "train", "epochs": 10, "timestep": 18018, "ep_reward": 11.693511009216309, "reward": 0.5510805249214172, "action": -0.998845100402832}
{"mode": "train", "epochs": 10, "timestep": 18019, "ep_reward": 12.350288391113281, "reward": 0.6567772626876831, "action": 1.2670838832855225}
{"mode": "train", "epochs": 10, "timestep": 18020, "ep_reward": 13.07933521270752, "reward": 0.7290470600128174, "action": 1.833046317100525}
{"mode": "train", "epochs": 10, "timestep": 18021, "ep_reward": 13.865486145019531, "reward": 0.7861505746841431, "action": 0.76014244556427}
{"mode": "train", "epochs": 10, "timestep": 18022, "ep_reward": 14.702624320983887, "reward": 0.8371384739875793, "action": 0.8578978180885315}
{"mode": "train", "epochs": 10, "timestep": 18023, "ep_reward": 15.577704429626465, "reward": 0.8750797510147095, "action": 0.5759536027908325}
{"mode": "train", "epochs": 10, "timestep": 18024, "ep_reward": 16.48051643371582, "reward": 0.9028120636940002, "action": 1.460318922996521}
{"mode": "train", "epochs": 10, "timestep": 18025, "ep_reward": 17.400371551513672, "reward": 0.9198556542396545, "action": 0.17792099714279175}
{"mode": "train", "epochs": 10, "timestep": 18026, "ep_reward": 18.33135986328125, "reward": 0.9309892654418945, "action": 1.7563588619232178}
{"mode": "train", "epochs": 10, "timestep": 18027, "ep_reward": 19.266006469726562, "reward": 0.9346460103988647, "action": 1.0179489850997925}
{"mode": "train", "epochs": 10, "timestep": 18028, "ep_reward": 20.198894500732422, "reward": 0.932887077331543, "action": 1.648266077041626}
{"mode": "train", "epochs": 10, "timestep": 18029, "ep_reward": 21.12547492980957, "reward": 0.926581084728241, "action": 0.4250395894050598}
{"mode": "train", "epochs": 10, "timestep": 18030, "ep_reward": 22.036500930786133, "reward": 0.9110254645347595, "action": 1.283969759941101}
{"mode": "train", "epochs": 10, "timestep": 18031, "ep_reward": 22.926057815551758, "reward": 0.8895564079284668, "action": 0.18197882175445557}
{"mode": "train", "epochs": 10, "timestep": 18032, "ep_reward": 23.779123306274414, "reward": 0.8530654907226562, "action": 0.6110064387321472}
{"mode": "train", "epochs": 10, "timestep": 18033, "ep_reward": 24.583843231201172, "reward": 0.8047196269035339, "action": 0.32783979177474976}
{"mode": "train", "epochs": 10, "timestep": 18034, "ep_reward": 25.322168350219727, "reward": 0.7383256554603577, "action": -0.9144593477249146}
{"mode": "train", "epochs": 10, "timestep": 18035, "ep_reward": 25.96284294128418, "reward": 0.6406753063201904, "action": -0.8249908089637756}
{"mode": "train", "epochs": 10, "timestep": 18036, "ep_reward": 26.481708526611328, "reward": 0.5188665390014648, "action": -0.3620404005050659}
{"mode": "train", "epochs": 10, "timestep": 18037, "ep_reward": 26.86292266845703, "reward": 0.38121497631073, "action": -0.46234071254730225}
{"mode": "train", "epochs": 10, "timestep": 18038, "ep_reward": 27.0918025970459, "reward": 0.22887980937957764, "action": -0.11594080924987793}
{"mode": "train", "epochs": 10, "timestep": 18039, "ep_reward": 27.18297004699707, "reward": 0.09116804599761963, "action": -0.8862894177436829}
{"mode": "train", "epochs": 10, "timestep": 18040, "ep_reward": 27.393203735351562, "reward": 0.21023410558700562, "action": -1.296001672744751}
{"mode": "train", "epochs": 10, "timestep": 18041, "ep_reward": 27.723079681396484, "reward": 0.3298766016960144, "action": -1.1882896423339844}
{"mode": "train", "epochs": 10, "timestep": 18042, "ep_reward": 28.173460006713867, "reward": 0.45037996768951416, "action": -1.0869934558868408}
{"mode": "train", "epochs": 10, "timestep": 18043, "ep_reward": 28.73740005493164, "reward": 0.5639407634735107, "action": -0.9727083444595337}
{"mode": "train", "epochs": 10, "timestep": 18044, "ep_reward": 29.401639938354492, "reward": 0.6642401218414307, "action": -0.8834295868873596}
{"mode": "train", "epochs": 10, "timestep": 18045, "ep_reward": 30.149099349975586, "reward": 0.7474595308303833, "action": -1.4975695610046387}
{"mode": "train", "epochs": 10, "timestep": 18046, "ep_reward": 30.957433700561523, "reward": 0.8083337545394897, "action": -1.08259916305542}
{"mode": "train", "epochs": 10, "timestep": 18047, "ep_reward": 31.814498901367188, "reward": 0.8570659756660461, "action": -1.4277511835098267}
{"mode": "train", "epochs": 10, "timestep": 18048, "ep_reward": 32.704872131347656, "reward": 0.890373170375824, "action": -1.3312169313430786}
{"mode": "train", "epochs": 10, "timestep": 18049, "ep_reward": 33.61860656738281, "reward": 0.9137341976165771, "action": -1.2516433000564575}
{"mode": "train", "epochs": 10, "timestep": 18050, "ep_reward": 34.54730224609375, "reward": 0.9286941885948181, "action": -0.49255692958831787}
{"mode": "train", "epochs": 10, "timestep": 18051, "ep_reward": 35.48716354370117, "reward": 0.9398604035377502, "action": -1.308407187461853}
{"mode": "train", "epochs": 10, "timestep": 18052, "ep_reward": 36.42631530761719, "reward": 0.9391514658927917, "action": -1.1596603393554688}
{"mode": "train", "epochs": 10, "timestep": 18053, "ep_reward": 37.35771560668945, "reward": 0.9314009547233582, "action": -1.0608114004135132}
{"mode": "train", "epochs": 10, "timestep": 18054, "ep_reward": 38.272483825683594, "reward": 0.9147672653198242, "action": -0.5533448457717896}
{"mode": "train", "epochs": 10, "timestep": 18055, "ep_reward": 39.162174224853516, "reward": 0.8896920680999756, "action": -0.05051112174987793}
{"mode": "train", "epochs": 10, "timestep": 18056, "ep_reward": 40.016075134277344, "reward": 0.8538990616798401, "action": -0.6318985223770142}
{"mode": "train", "epochs": 10, "timestep": 18057, "ep_reward": 40.81026840209961, "reward": 0.7941930890083313, "action": -1.667426347732544}
{"mode": "train", "epochs": 10, "timestep": 18058, "ep_reward": 41.50736618041992, "reward": 0.6970986127853394, "action": -1.2238467931747437}
{"mode": "train", "epochs": 10, "timestep": 18059, "ep_reward": 42.07667922973633, "reward": 0.5693115592002869, "action": -0.44049185514450073}
{"mode": "train", "epochs": 10, "timestep": 18060, "ep_reward": 42.492042541503906, "reward": 0.41536247730255127, "action": -1.0253862142562866}
{"mode": "train", "epochs": 10, "timestep": 18061, "ep_reward": 42.7440071105957, "reward": 0.2519630193710327, "action": -1.2843892574310303}
{"mode": "train", "epochs": 10, "timestep": 18062, "ep_reward": 42.86806106567383, "reward": 0.12405502796173096, "action": -0.7918812036514282}
{"mode": "train", "epochs": 10, "timestep": 18063, "ep_reward": 42.85819625854492, "reward": -0.009865045547485352, "action": -0.19080030918121338}
{"mode": "train", "epochs": 10, "timestep": 18064, "ep_reward": 42.99445343017578, "reward": 0.13625824451446533, "action": -1.0308058261871338}
{"mode": "train", "epochs": 10, "timestep": 18065, "ep_reward": 43.269569396972656, "reward": 0.2751166820526123, "action": -0.8920367956161499}
{"mode": "train", "epochs": 10, "timestep": 18066, "ep_reward": 43.683414459228516, "reward": 0.4138444662094116, "action": -1.909801959991455}
{"mode": "train", "epochs": 10, "timestep": 18067, "ep_reward": 44.212738037109375, "reward": 0.529325008392334, "action": -0.501323938369751}
{"mode": "train", "epochs": 10, "timestep": 18068, "ep_reward": 44.85605239868164, "reward": 0.6433159112930298, "action": -0.7121462821960449}
{"mode": "train", "epochs": 10, "timestep": 18069, "ep_reward": 45.586952209472656, "reward": 0.7309001684188843, "action": -0.6037236452102661}
{"mode": "train", "epochs": 10, "timestep": 18070, "ep_reward": 46.38327407836914, "reward": 0.7963221669197083, "action": -0.601909875869751}
{"mode": "train", "epochs": 10, "timestep": 18071, "ep_reward": 47.22416305541992, "reward": 0.8408902883529663, "action": -1.2250447273254395}
{"mode": "train", "epochs": 10, "timestep": 18072, "ep_reward": 48.08671951293945, "reward": 0.8625547289848328, "action": -0.69434654712677}
{"mode": "train", "epochs": 10, "timestep": 18073, "ep_reward": 48.959312438964844, "reward": 0.8725924491882324, "action": -0.9588636755943298}
{"mode": "train", "epochs": 10, "timestep": 18074, "ep_reward": 49.823734283447266, "reward": 0.864422619342804, "action": -0.7759002447128296}
{"mode": "train", "epochs": 10, "timestep": 18075, "ep_reward": 50.663673400878906, "reward": 0.8399378657341003, "action": -1.5028876066207886}
{"mode": "train", "epochs": 10, "timestep": 18076, "ep_reward": 51.45014953613281, "reward": 0.7864770293235779, "action": -0.9878413677215576}
{"mode": "train", "epochs": 10, "timestep": 18077, "ep_reward": 52.15943145751953, "reward": 0.7092834711074829, "action": -0.9585656523704529}
{"mode": "train", "epochs": 10, "timestep": 18078, "ep_reward": 52.75635528564453, "reward": 0.5969234704971313, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 18079, "ep_reward": 53.183677673339844, "reward": 0.42732155323028564, "action": -0.6889058351516724}
{"mode": "train", "epochs": 10, "timestep": 18080, "ep_reward": 53.49903869628906, "reward": 0.3153613805770874, "action": -1.3432159423828125}
{"mode": "train", "epochs": 10, "timestep": 18081, "ep_reward": 53.69781494140625, "reward": 0.19877475500106812, "action": -0.5304872393608093}
{"mode": "train", "epochs": 10, "timestep": 18082, "ep_reward": 53.75985336303711, "reward": 0.062036752700805664, "action": -1.0864771604537964}
{"mode": "train", "epochs": 10, "timestep": 18083, "ep_reward": 53.81609344482422, "reward": 0.05623960494995117, "action": -0.5756936073303223}
{"mode": "train", "epochs": 10, "timestep": 18084, "ep_reward": 54.014442443847656, "reward": 0.19834911823272705, "action": -1.5111267566680908}
{"mode": "train", "epochs": 10, "timestep": 18085, "ep_reward": 54.345794677734375, "reward": 0.3313511610031128, "action": -1.1235909461975098}
{"mode": "train", "epochs": 10, "timestep": 18086, "ep_reward": 54.810035705566406, "reward": 0.4642421007156372, "action": -1.9974782466888428}
{"mode": "train", "epochs": 10, "timestep": 18087, "ep_reward": 55.38256072998047, "reward": 0.5725248456001282, "action": 0.45828866958618164}
{"mode": "train", "epochs": 10, "timestep": 18088, "ep_reward": 56.07015609741211, "reward": 0.6875947713851929, "action": -1.0502580404281616}
{"mode": "train", "epochs": 10, "timestep": 18089, "ep_reward": 56.831085205078125, "reward": 0.7609286904335022, "action": -0.8023608922958374}
{"mode": "train", "epochs": 10, "timestep": 18090, "ep_reward": 57.64597702026367, "reward": 0.8148932456970215, "action": -1.1590700149536133}
{"mode": "train", "epochs": 10, "timestep": 18091, "ep_reward": 58.492279052734375, "reward": 0.8463013172149658, "action": -1.2919033765792847}
{"mode": "train", "epochs": 10, "timestep": 18092, "ep_reward": 59.35152053833008, "reward": 0.8592431545257568, "action": -1.532008171081543}
{"mode": "train", "epochs": 10, "timestep": 18093, "ep_reward": 60.20451736450195, "reward": 0.8529969453811646, "action": -0.6741331815719604}
{"mode": "train", "epochs": 10, "timestep": 18094, "ep_reward": 61.04002380371094, "reward": 0.8355070352554321, "action": -0.6495180130004883}
{"mode": "train", "epochs": 10, "timestep": 18095, "ep_reward": 61.8366813659668, "reward": 0.7966593503952026, "action": -0.5130818486213684}
{"mode": "train", "epochs": 10, "timestep": 18096, "ep_reward": 62.56964111328125, "reward": 0.7329598665237427, "action": -1.1209074258804321}
{"mode": "train", "epochs": 10, "timestep": 18097, "ep_reward": 63.19889450073242, "reward": 0.6292541027069092, "action": -0.23808473348617554}
{"mode": "train", "epochs": 10, "timestep": 18098, "ep_reward": 63.697296142578125, "reward": 0.4984012246131897, "action": -0.8934204578399658}
{"mode": "train", "epochs": 10, "timestep": 18099, "ep_reward": 64.04521942138672, "reward": 0.34792035818099976, "action": -1.7393826246261597}
{"mode": "train", "epochs": 10, "timestep": 18100, "ep_reward": 64.28294372558594, "reward": 0.23772132396697998, "action": -0.4158792495727539}
{"mode": "train", "epochs": 10, "timestep": 18101, "ep_reward": 64.39026641845703, "reward": 0.10732471942901611, "action": -0.6944518089294434}
{"mode": "train", "epochs": 10, "timestep": 18102, "ep_reward": 64.39892578125, "reward": 0.008656859397888184, "action": -1.39216947555542}
{"mode": "train", "epochs": 10, "timestep": 18103, "ep_reward": 64.55138397216797, "reward": 0.15246069431304932, "action": -1.2590689659118652}
{"mode": "train", "epochs": 10, "timestep": 18104, "ep_reward": 64.84014892578125, "reward": 0.2887634038925171, "action": -1.5026698112487793}
{"mode": "train", "epochs": 10, "timestep": 18105, "ep_reward": 65.26024627685547, "reward": 0.4200969338417053, "action": -0.4422633647918701}
{"mode": "train", "epochs": 10, "timestep": 18106, "ep_reward": 65.81248474121094, "reward": 0.5522365570068359, "action": -0.7374550104141235}
{"mode": "train", "epochs": 10, "timestep": 18107, "ep_reward": 66.47188568115234, "reward": 0.659401535987854, "action": -0.7434731721878052}
{"mode": "train", "epochs": 10, "timestep": 18108, "ep_reward": 67.21487426757812, "reward": 0.7429896593093872, "action": -1.178505778312683}
{"mode": "train", "epochs": 10, "timestep": 18109, "ep_reward": 68.01502227783203, "reward": 0.8001507520675659, "action": -1.3037934303283691}
{"mode": "train", "epochs": 10, "timestep": 18110, "ep_reward": 68.85184478759766, "reward": 0.8368211984634399, "action": -0.3932216763496399}
{"mode": "train", "epochs": 10, "timestep": 18111, "ep_reward": 69.7153549194336, "reward": 0.863507091999054, "action": -0.8728320002555847}
{"mode": "train", "epochs": 10, "timestep": 18112, "ep_reward": 70.5848159790039, "reward": 0.8694618940353394, "action": -1.7137101888656616}
{"mode": "train", "epochs": 10, "timestep": 18113, "ep_reward": 71.43634796142578, "reward": 0.8515292406082153, "action": -0.8773152232170105}
{"mode": "train", "epochs": 10, "timestep": 18114, "ep_reward": 72.25729370117188, "reward": 0.820949137210846, "action": -1.7548468112945557}
{"mode": "train", "epochs": 10, "timestep": 18115, "ep_reward": 73.01402282714844, "reward": 0.7567310333251953, "action": 0.40479254722595215}
{"mode": "train", "epochs": 10, "timestep": 18116, "ep_reward": 73.70000457763672, "reward": 0.6859793066978455, "action": -1.0877437591552734}
{"mode": "train", "epochs": 10, "timestep": 18117, "ep_reward": 74.26228332519531, "reward": 0.5622802376747131, "action": -0.9396746158599854}
{"mode": "train", "epochs": 10, "timestep": 18118, "ep_reward": 74.66122436523438, "reward": 0.39894336462020874, "action": -0.4210919737815857}
{"mode": "train", "epochs": 10, "timestep": 18119, "ep_reward": 74.94979095458984, "reward": 0.288565456867218, "action": -0.10206866264343262}
{"mode": "train", "epochs": 10, "timestep": 18120, "ep_reward": 75.11670684814453, "reward": 0.16691315174102783, "action": -0.8050898909568787}
{"mode": "train", "epochs": 10, "timestep": 18121, "ep_reward": 75.14203643798828, "reward": 0.02533257007598877, "action": -0.3759007453918457}
{"mode": "train", "epochs": 10, "timestep": 18122, "ep_reward": 75.23402404785156, "reward": 0.09198498725891113, "action": -0.6345851421356201}
{"mode": "train", "epochs": 10, "timestep": 18123, "ep_reward": 75.46846008300781, "reward": 0.23443341255187988, "action": -1.6596232652664185}
{"mode": "train", "epochs": 10, "timestep": 18124, "ep_reward": 75.83326721191406, "reward": 0.3648085594177246, "action": -1.057358741760254}
{"mode": "train", "epochs": 10, "timestep": 18125, "ep_reward": 76.32896423339844, "reward": 0.49569791555404663, "action": -1.1770925521850586}
{"mode": "train", "epochs": 10, "timestep": 18126, "ep_reward": 76.93721771240234, "reward": 0.6082538962364197, "action": -0.7547814249992371}
{"mode": "train", "epochs": 10, "timestep": 18127, "ep_reward": 77.64047241210938, "reward": 0.7032563090324402, "action": -1.6677281856536865}
{"mode": "train", "epochs": 10, "timestep": 18128, "ep_reward": 78.40654754638672, "reward": 0.7660728693008423, "action": -1.4970407485961914}
{"mode": "train", "epochs": 10, "timestep": 18129, "ep_reward": 79.21642303466797, "reward": 0.8098753094673157, "action": -1.2024847269058228}
{"mode": "train", "epochs": 10, "timestep": 18130, "ep_reward": 80.05314636230469, "reward": 0.8367247581481934, "action": -1.0487236976623535}
{"mode": "train", "epochs": 10, "timestep": 18131, "ep_reward": 80.89923095703125, "reward": 0.8460822701454163, "action": -0.7052636742591858}
{"mode": "train", "epochs": 10, "timestep": 18132, "ep_reward": 81.7386245727539, "reward": 0.8393915295600891, "action": -1.1561174392700195}
{"mode": "train", "epochs": 10, "timestep": 18133, "ep_reward": 82.54579162597656, "reward": 0.8071640729904175, "action": -1.4103213548660278}
{"mode": "train", "epochs": 10, "timestep": 18134, "ep_reward": 83.29158782958984, "reward": 0.7457956075668335, "action": -0.79902184009552}
{"mode": "train", "epochs": 10, "timestep": 18135, "ep_reward": 83.94962310791016, "reward": 0.6580383777618408, "action": -1.860586166381836}
{"mode": "train", "epochs": 10, "timestep": 18136, "ep_reward": 84.46517944335938, "reward": 0.5155583620071411, "action": -1.3989331722259521}
{"mode": "train", "epochs": 10, "timestep": 18137, "ep_reward": 84.84768676757812, "reward": 0.3825085163116455, "action": -0.8644473552703857}
{"mode": "train", "epochs": 10, "timestep": 18138, "ep_reward": 85.12687683105469, "reward": 0.2791863679885864, "action": -1.3086073398590088}
{"mode": "train", "epochs": 10, "timestep": 18139, "ep_reward": 85.28278350830078, "reward": 0.15590304136276245, "action": -1.4341955184936523}
{"mode": "train", "epochs": 10, "timestep": 18140, "ep_reward": 85.2954330444336, "reward": 0.012651026248931885, "action": -1.378794550895691}
{"mode": "train", "epochs": 10, "timestep": 18141, "ep_reward": 85.39912414550781, "reward": 0.10369116067886353, "action": -0.33139222860336304}
{"mode": "train", "epochs": 10, "timestep": 18142, "ep_reward": 85.64939880371094, "reward": 0.2502777576446533, "action": -1.3684989213943481}
{"mode": "train", "epochs": 10, "timestep": 18143, "ep_reward": 86.03246307373047, "reward": 0.3830667734146118, "action": -0.9697476625442505}
{"mode": "train", "epochs": 10, "timestep": 18144, "ep_reward": 86.54478454589844, "reward": 0.5123195648193359, "action": -1.4986599683761597}
{"mode": "train", "epochs": 10, "timestep": 18145, "ep_reward": 87.16326904296875, "reward": 0.6184868812561035, "action": -1.314178705215454}
{"mode": "train", "epochs": 10, "timestep": 18146, "ep_reward": 87.86936950683594, "reward": 0.7060997486114502, "action": -0.38372886180877686}
{"mode": "train", "epochs": 10, "timestep": 18147, "ep_reward": 88.64959716796875, "reward": 0.7802286148071289, "action": -0.9962292313575745}
{"mode": "train", "epochs": 10, "timestep": 18148, "ep_reward": 89.47652435302734, "reward": 0.8269240856170654, "action": -0.9170917272567749}
{"mode": "train", "epochs": 10, "timestep": 18149, "ep_reward": 90.3324203491211, "reward": 0.8558964729309082, "action": -0.9481003880500793}
{"mode": "train", "epochs": 10, "timestep": 18150, "ep_reward": 91.2002944946289, "reward": 0.867874264717102, "action": -1.2729426622390747}
{"mode": "train", "epochs": 10, "timestep": 18151, "ep_reward": 92.06099700927734, "reward": 0.8607020378112793, "action": -1.1838644742965698}
{"mode": "train", "epochs": 10, "timestep": 18152, "ep_reward": 92.89692687988281, "reward": 0.835931658744812, "action": -0.20256298780441284}
{"mode": "train", "epochs": 10, "timestep": 18153, "ep_reward": 93.69587707519531, "reward": 0.798949122428894, "action": -0.48022401332855225}
{"mode": "train", "epochs": 10, "timestep": 18154, "ep_reward": 94.4295654296875, "reward": 0.7336850762367249, "action": -1.1442737579345703}
{"mode": "train", "epochs": 10, "timestep": 18155, "ep_reward": 95.05757141113281, "reward": 0.6280069351196289, "action": -1.4950857162475586}
{"mode": "train", "epochs": 10, "timestep": 18156, "ep_reward": 95.53410339355469, "reward": 0.476532518863678, "action": -1.4702656269073486}
{"mode": "train", "epochs": 10, "timestep": 18157, "ep_reward": 95.87287902832031, "reward": 0.3387736678123474, "action": -1.0078840255737305}
{"mode": "train", "epochs": 10, "timestep": 18158, "ep_reward": 96.09934997558594, "reward": 0.2264714241027832, "action": -1.5849018096923828}
{"mode": "train", "epochs": 10, "timestep": 18159, "ep_reward": 96.19368743896484, "reward": 0.09433645009994507, "action": -1.1534069776535034}
{"mode": "train", "epochs": 10, "timestep": 18160, "ep_reward": 96.2162094116211, "reward": 0.02252352237701416, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 18161, "ep_reward": 96.38082122802734, "reward": 0.1646100878715515, "action": -1.3549996614456177}
{"mode": "train", "epochs": 10, "timestep": 18162, "ep_reward": 96.68086242675781, "reward": 0.3000428080558777, "action": -0.9962059259414673}
{"mode": "train", "epochs": 10, "timestep": 18163, "ep_reward": 97.1177749633789, "reward": 0.43690967559814453, "action": -1.5235978364944458}
{"mode": "train", "epochs": 10, "timestep": 18164, "ep_reward": 97.67186737060547, "reward": 0.5540890097618103, "action": -1.8746891021728516}
{"mode": "train", "epochs": 10, "timestep": 18165, "ep_reward": 98.32048034667969, "reward": 0.6486121416091919, "action": -0.7778986692428589}
{"mode": "train", "epochs": 10, "timestep": 18166, "ep_reward": 99.052978515625, "reward": 0.7324958443641663, "action": -1.0953094959259033}
{"mode": "train", "epochs": 10, "timestep": 18167, "ep_reward": 99.84236145019531, "reward": 0.7893820405006409, "action": -0.6975575685501099}
{"mode": "train", "epochs": 10, "timestep": 18168, "ep_reward": 100.67088317871094, "reward": 0.8285200595855713, "action": 0.003984689712524414}
{"mode": "train", "epochs": 10, "timestep": 18169, "ep_reward": 101.5248794555664, "reward": 0.8539937138557434, "action": -1.7116280794143677}
{"mode": "train", "epochs": 10, "timestep": 18170, "ep_reward": 102.37077331542969, "reward": 0.8458927869796753, "action": -1.2843122482299805}
{"mode": "train", "epochs": 10, "timestep": 18171, "ep_reward": 103.19222259521484, "reward": 0.8214466571807861, "action": -0.6284003257751465}
{"mode": "train", "epochs": 10, "timestep": 18172, "ep_reward": 103.97197723388672, "reward": 0.7797579765319824, "action": -0.4955822825431824}
{"mode": "train", "epochs": 10, "timestep": 18173, "ep_reward": 104.6833724975586, "reward": 0.7113977670669556, "action": 0.5311154127120972}
{"mode": "train", "epochs": 10, "timestep": 18174, "ep_reward": 105.30670166015625, "reward": 0.6233257055282593, "action": 0.4666569232940674}
{"mode": "train", "epochs": 10, "timestep": 18175, "ep_reward": 105.80735778808594, "reward": 0.5006586313247681, "action": -0.45303183794021606}
{"mode": "train", "epochs": 10, "timestep": 18176, "ep_reward": 106.14704132080078, "reward": 0.3396865725517273, "action": -1.0780539512634277}
{"mode": "train", "epochs": 10, "timestep": 18177, "ep_reward": 106.37470245361328, "reward": 0.2276620864868164, "action": -1.051442265510559}
{"mode": "train", "epochs": 10, "timestep": 18178, "ep_reward": 106.47039031982422, "reward": 0.09568971395492554, "action": -0.46131473779678345}
{"mode": "train", "epochs": 10, "timestep": 18179, "ep_reward": 106.49153900146484, "reward": 0.021150588989257812, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 18180, "ep_reward": 106.655029296875, "reward": 0.16348999738693237, "action": -0.8247414231300354}
{"mode": "train", "epochs": 10, "timestep": 18181, "ep_reward": 106.96048736572266, "reward": 0.30545902252197266, "action": -1.0725678205490112}
{"mode": "train", "epochs": 10, "timestep": 18182, "ep_reward": 107.40071868896484, "reward": 0.44022977352142334, "action": -1.0616469383239746}
{"mode": "train", "epochs": 10, "timestep": 18183, "ep_reward": 107.96273803710938, "reward": 0.5620207786560059, "action": -1.058504581451416}
{"mode": "train", "epochs": 10, "timestep": 18184, "ep_reward": 108.62676239013672, "reward": 0.664023756980896, "action": -0.4769572615623474}
{"mode": "train", "epochs": 10, "timestep": 18185, "ep_reward": 109.37581634521484, "reward": 0.749051570892334, "action": -0.6155540943145752}
{"mode": "train", "epochs": 10, "timestep": 18186, "ep_reward": 110.1856689453125, "reward": 0.8098497986793518, "action": -1.0404750108718872}
{"mode": "train", "epochs": 10, "timestep": 18187, "ep_reward": 111.03309631347656, "reward": 0.8474310636520386, "action": -0.7822047472000122}
{"mode": "train", "epochs": 10, "timestep": 18188, "ep_reward": 111.90349578857422, "reward": 0.8703964352607727, "action": -0.5395590662956238}
{"mode": "train", "epochs": 10, "timestep": 18189, "ep_reward": 112.78335571289062, "reward": 0.8798618316650391, "action": -0.8703626394271851}
{"mode": "train", "epochs": 10, "timestep": 18190, "ep_reward": 113.65461730957031, "reward": 0.8712618947029114, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 18191, "ep_reward": 114.48998260498047, "reward": 0.8353680372238159, "action": -0.2518928349018097}
{"mode": "train", "epochs": 10, "timestep": 18192, "ep_reward": 115.2833251953125, "reward": 0.7933452129364014, "action": 0.43624693155288696}
{"mode": "train", "epochs": 10, "timestep": 18193, "ep_reward": 116.0172119140625, "reward": 0.7338857650756836, "action": -0.35514217615127563}
{"mode": "train", "epochs": 10, "timestep": 18194, "ep_reward": 116.65330505371094, "reward": 0.6360947489738464, "action": -0.39226436614990234}
{"mode": "train", "epochs": 10, "timestep": 18195, "ep_reward": 117.15567016601562, "reward": 0.5023676156997681, "action": -1.2696431875228882}
{"mode": "train", "epochs": 10, "timestep": 18196, "ep_reward": 117.4870834350586, "reward": 0.33141541481018066, "action": -0.795250654220581}
{"mode": "train", "epochs": 10, "timestep": 18197, "ep_reward": 117.70488739013672, "reward": 0.2178053855895996, "action": -0.3202495574951172}
{"mode": "train", "epochs": 10, "timestep": 18198, "ep_reward": 117.78905487060547, "reward": 0.08416813611984253, "action": -0.07971459627151489}
{"mode": "train", "epochs": 10, "timestep": 18199, "ep_reward": 117.82267761230469, "reward": 0.03361976146697998, "action": -0.10751551389694214}
{"mode": "train", "epochs": 10, "timestep": 18200, "ep_reward": 118.00349426269531, "reward": 0.18081974983215332, "action": -1.4928128719329834}
{"mode": "train", "epochs": 10, "timestep": 18201, "ep_reward": 118.31683349609375, "reward": 0.31334030628204346, "action": -1.3159565925598145}
{"mode": "train", "epochs": 10, "timestep": 18202, "ep_reward": 118.7618637084961, "reward": 0.4450312852859497, "action": 0.38816511631011963}
{"mode": "train", "epochs": 10, "timestep": 18203, "ep_reward": 119.34443664550781, "reward": 0.5825698971748352, "action": -0.688449501991272}
{"mode": "train", "epochs": 10, "timestep": 18204, "ep_reward": 120.02875518798828, "reward": 0.6843201518058777, "action": -1.5166709423065186}
{"mode": "train", "epochs": 10, "timestep": 18205, "ep_reward": 120.7847671508789, "reward": 0.7560082674026489, "action": -0.7412174344062805}
{"mode": "train", "epochs": 10, "timestep": 18206, "ep_reward": 121.59931945800781, "reward": 0.8145530819892883, "action": -1.1487842798233032}
{"mode": "train", "epochs": 10, "timestep": 18207, "ep_reward": 122.4500503540039, "reward": 0.8507336378097534, "action": -1.509905457496643}
{"mode": "train", "epochs": 10, "timestep": 18208, "ep_reward": 123.31794738769531, "reward": 0.8678938746452332, "action": -1.073288083076477}
{"mode": "train", "epochs": 10, "timestep": 18209, "ep_reward": 124.19123840332031, "reward": 0.8732908368110657, "action": 0.4786776304244995}
{"mode": "train", "epochs": 10, "timestep": 18210, "ep_reward": 125.06730651855469, "reward": 0.8760703802108765, "action": -0.380526065826416}
{"mode": "train", "epochs": 10, "timestep": 18211, "ep_reward": 125.92298889160156, "reward": 0.8556797504425049, "action": -1.185090184211731}
{"mode": "train", "epochs": 10, "timestep": 18212, "ep_reward": 126.7315444946289, "reward": 0.8085526823997498, "action": -0.9219912886619568}
{"mode": "train", "epochs": 10, "timestep": 18213, "ep_reward": 127.46959686279297, "reward": 0.7380537986755371, "action": -0.30621254444122314}
{"mode": "train", "epochs": 10, "timestep": 18214, "ep_reward": 128.11260986328125, "reward": 0.6430089473724365, "action": -1.9434993267059326}
{"mode": "train", "epochs": 10, "timestep": 18215, "ep_reward": 128.60110473632812, "reward": 0.48848992586135864, "action": -1.2836782932281494}
{"mode": "train", "epochs": 10, "timestep": 18216, "ep_reward": 128.9374237060547, "reward": 0.3363136053085327, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 18217, "ep_reward": 129.16128540039062, "reward": 0.22385573387145996, "action": -0.9409742951393127}
{"mode": "train", "epochs": 10, "timestep": 18218, "ep_reward": 129.25242614746094, "reward": 0.0911332368850708, "action": -1.4144859313964844}
{"mode": "train", "epochs": 10, "timestep": 18219, "ep_reward": 129.2784423828125, "reward": 0.026017427444458008, "action": -1.4070745706558228}
{"mode": "train", "epochs": 10, "timestep": 18220, "ep_reward": 129.446044921875, "reward": 0.16760212182998657, "action": -0.8631462454795837}
{"mode": "train", "epochs": 10, "timestep": 18221, "ep_reward": 129.75527954101562, "reward": 0.30923640727996826, "action": -0.3292968273162842}
{"mode": "train", "epochs": 10, "timestep": 18222, "ep_reward": 130.2079315185547, "reward": 0.4526575207710266, "action": -0.884868860244751}
{"mode": "train", "epochs": 10, "timestep": 18223, "ep_reward": 130.7821807861328, "reward": 0.5742419958114624, "action": -0.9685047268867493}
{"mode": "train", "epochs": 10, "timestep": 18224, "ep_reward": 131.45709228515625, "reward": 0.6749162077903748, "action": -0.8793638944625854}
{"mode": "train", "epochs": 10, "timestep": 18225, "ep_reward": 132.21153259277344, "reward": 0.7544389367103577, "action": -0.5597211122512817}
{"mode": "train", "epochs": 10, "timestep": 18226, "ep_reward": 133.02696228027344, "reward": 0.8154274821281433, "action": -0.3072064518928528}
{"mode": "train", "epochs": 10, "timestep": 18227, "ep_reward": 133.8861541748047, "reward": 0.8591850399971008, "action": -0.7361031770706177}
{"mode": "train", "epochs": 10, "timestep": 18228, "ep_reward": 134.7694091796875, "reward": 0.8832573294639587, "action": -1.535658836364746}
{"mode": "train", "epochs": 10, "timestep": 18229, "ep_reward": 135.65701293945312, "reward": 0.8876055479049683, "action": -0.7520430088043213}
{"mode": "train", "epochs": 10, "timestep": 18230, "ep_reward": 136.54107666015625, "reward": 0.8840572834014893, "action": -1.5340793132781982}
{"mode": "train", "epochs": 10, "timestep": 18231, "ep_reward": 137.3997344970703, "reward": 0.8586533069610596, "action": -1.2005376815795898}
{"mode": "train", "epochs": 10, "timestep": 18232, "ep_reward": 138.21588134765625, "reward": 0.8161395788192749, "action": -1.3570373058319092}
{"mode": "train", "epochs": 10, "timestep": 18233, "ep_reward": 138.96217346191406, "reward": 0.7462928295135498, "action": -1.3805333375930786}
{"mode": "train", "epochs": 10, "timestep": 18234, "ep_reward": 139.604736328125, "reward": 0.6425583958625793, "action": -1.468965768814087}
{"mode": "train", "epochs": 10, "timestep": 18235, "ep_reward": 140.1014404296875, "reward": 0.49670320749282837, "action": -0.8776441216468811}
{"mode": "train", "epochs": 10, "timestep": 18236, "ep_reward": 140.45216369628906, "reward": 0.3507285714149475, "action": -1.3471882343292236}
{"mode": "train", "epochs": 10, "timestep": 18237, "ep_reward": 140.69313049316406, "reward": 0.24096429347991943, "action": -0.8563540577888489}
{"mode": "train", "epochs": 10, "timestep": 18238, "ep_reward": 140.80416870117188, "reward": 0.11104393005371094, "action": -1.4649957418441772}
{"mode": "train", "epochs": 10, "timestep": 18239, "ep_reward": 140.80874633789062, "reward": 0.004572272300720215, "action": -0.19934380054473877}
{"mode": "train", "epochs": 10, "timestep": 18240, "ep_reward": 140.95858764648438, "reward": 0.1498425006866455, "action": -0.27593308687210083}
{"mode": "train", "epochs": 10, "timestep": 18241, "ep_reward": 141.256591796875, "reward": 0.2980012893676758, "action": -1.4845563173294067}
{"mode": "train", "epochs": 10, "timestep": 18242, "ep_reward": 141.68377685546875, "reward": 0.42717820405960083, "action": -0.920872688293457}
{"mode": "train", "epochs": 10, "timestep": 18243, "ep_reward": 142.23580932617188, "reward": 0.5520336627960205, "action": -0.7238372564315796}
{"mode": "train", "epochs": 10, "timestep": 18244, "ep_reward": 142.8952178955078, "reward": 0.6594064235687256, "action": -0.8895256519317627}
{"mode": "train", "epochs": 10, "timestep": 18245, "ep_reward": 143.6375732421875, "reward": 0.7423537969589233, "action": -0.8395723700523376}
{"mode": "train", "epochs": 10, "timestep": 18246, "ep_reward": 144.44161987304688, "reward": 0.8040489554405212, "action": -0.3487730622291565}
{"mode": "train", "epochs": 10, "timestep": 18247, "ep_reward": 145.29180908203125, "reward": 0.8501884937286377, "action": -1.3146424293518066}
{"mode": "train", "epochs": 10, "timestep": 18248, "ep_reward": 146.1634979248047, "reward": 0.8716961741447449, "action": -0.8680953979492188}
{"mode": "train", "epochs": 10, "timestep": 18249, "ep_reward": 147.04547119140625, "reward": 0.8819702863693237, "action": -1.2441163063049316}
{"mode": "train", "epochs": 10, "timestep": 18250, "ep_reward": 147.92002868652344, "reward": 0.8745592832565308, "action": -0.5550789833068848}
{"mode": "train", "epochs": 10, "timestep": 18251, "ep_reward": 148.77655029296875, "reward": 0.856526792049408, "action": -1.1307889223098755}
{"mode": "train", "epochs": 10, "timestep": 18252, "ep_reward": 149.59046936035156, "reward": 0.813923716545105, "action": -1.0408813953399658}
{"mode": "train", "epochs": 10, "timestep": 18253, "ep_reward": 150.33712768554688, "reward": 0.7466565370559692, "action": -1.4048619270324707}
{"mode": "train", "epochs": 10, "timestep": 18254, "ep_reward": 150.97938537597656, "reward": 0.6422526836395264, "action": -1.7367995977401733}
{"mode": "train", "epochs": 10, "timestep": 18255, "ep_reward": 151.47146606445312, "reward": 0.49208682775497437, "action": -0.10725796222686768}
{"mode": "train", "epochs": 10, "timestep": 18256, "ep_reward": 151.82020568847656, "reward": 0.34873878955841064, "action": -0.4762653112411499}
{"mode": "train", "epochs": 10, "timestep": 18257, "ep_reward": 152.0586700439453, "reward": 0.23845750093460083, "action": -0.8572537302970886}
{"mode": "train", "epochs": 10, "timestep": 18258, "ep_reward": 152.16685485839844, "reward": 0.10817760229110718, "action": -1.1037715673446655}
{"mode": "train", "epochs": 10, "timestep": 18259, "ep_reward": 152.17462158203125, "reward": 0.0077634453773498535, "action": -0.6884537935256958}
{"mode": "train", "epochs": 10, "timestep": 18260, "ep_reward": 152.32618713378906, "reward": 0.1515703797340393, "action": -1.459839940071106}
{"mode": "train", "epochs": 10, "timestep": 18261, "ep_reward": 152.6115264892578, "reward": 0.2853434681892395, "action": -1.5743534564971924}
{"mode": "train", "epochs": 10, "timestep": 18262, "ep_reward": 153.02780151367188, "reward": 0.4162815809249878, "action": -0.9542494416236877}
{"mode": "train", "epochs": 10, "timestep": 18263, "ep_reward": 153.5710906982422, "reward": 0.5432865619659424, "action": -0.6613329648971558}
{"mode": "train", "epochs": 10, "timestep": 18264, "ep_reward": 154.22390747070312, "reward": 0.6528198719024658, "action": -1.1156072616577148}
{"mode": "train", "epochs": 10, "timestep": 18265, "ep_reward": 154.9574737548828, "reward": 0.7335680723190308, "action": -1.246364951133728}
{"mode": "train", "epochs": 10, "timestep": 18266, "ep_reward": 155.74806213378906, "reward": 0.7905937433242798, "action": -0.4280123710632324}
{"mode": "train", "epochs": 10, "timestep": 18267, "ep_reward": 156.5823516845703, "reward": 0.8342863917350769, "action": -0.23718583583831787}
{"mode": "train", "epochs": 10, "timestep": 18268, "ep_reward": 157.4427490234375, "reward": 0.8604024648666382, "action": -0.407179594039917}
{"mode": "train", "epochs": 10, "timestep": 18269, "ep_reward": 158.31065368652344, "reward": 0.8679088354110718, "action": -0.4279056787490845}
{"mode": "train", "epochs": 10, "timestep": 18270, "ep_reward": 159.169189453125, "reward": 0.858539879322052, "action": -0.6432042121887207}
{"mode": "train", "epochs": 10, "timestep": 18271, "ep_reward": 159.9978790283203, "reward": 0.8286948204040527, "action": -1.391061544418335}
{"mode": "train", "epochs": 10, "timestep": 18272, "ep_reward": 160.7659149169922, "reward": 0.768042802810669, "action": -1.7230989933013916}
{"mode": "train", "epochs": 10, "timestep": 18273, "ep_reward": 161.4375, "reward": 0.6715810298919678, "action": -1.4858089685440063}
{"mode": "train", "epochs": 10, "timestep": 18274, "ep_reward": 161.97499084472656, "reward": 0.5374888777732849, "action": -0.6844035387039185}
{"mode": "train", "epochs": 10, "timestep": 18275, "ep_reward": 162.3563995361328, "reward": 0.3814122676849365, "action": -0.8276653289794922}
{"mode": "train", "epochs": 10, "timestep": 18276, "ep_reward": 162.63424682617188, "reward": 0.2778412699699402, "action": -1.3611513376235962}
{"mode": "train", "epochs": 10, "timestep": 18277, "ep_reward": 162.78871154785156, "reward": 0.15445852279663086, "action": 0.07785308361053467}
{"mode": "train", "epochs": 10, "timestep": 18278, "ep_reward": 162.7996368408203, "reward": 0.010921180248260498, "action": -0.794134259223938}
{"mode": "train", "epochs": 10, "timestep": 18279, "ep_reward": 162.90496826171875, "reward": 0.10532718896865845, "action": -0.7170515060424805}
{"mode": "train", "epochs": 10, "timestep": 18280, "ep_reward": 163.15220642089844, "reward": 0.2472415566444397, "action": -1.0614081621170044}
{"mode": "train", "epochs": 10, "timestep": 18281, "ep_reward": 163.53688049316406, "reward": 0.38467609882354736, "action": -0.4475627541542053}
{"mode": "train", "epochs": 10, "timestep": 18282, "ep_reward": 164.05677795410156, "reward": 0.5198944807052612, "action": -0.9911937117576599}
{"mode": "train", "epochs": 10, "timestep": 18283, "ep_reward": 164.68692016601562, "reward": 0.6301395893096924, "action": -1.0750818252563477}
{"mode": "train", "epochs": 10, "timestep": 18284, "ep_reward": 165.40499877929688, "reward": 0.7180798053741455, "action": -1.241515874862671}
{"mode": "train", "epochs": 10, "timestep": 18285, "ep_reward": 166.1877899169922, "reward": 0.7827922105789185, "action": -1.5679049491882324}
{"mode": "train", "epochs": 10, "timestep": 18286, "ep_reward": 167.01266479492188, "reward": 0.8248758912086487, "action": -1.9341495037078857}
{"mode": "train", "epochs": 10, "timestep": 18287, "ep_reward": 167.8590545654297, "reward": 0.8463859558105469, "action": -0.8506578803062439}
{"mode": "train", "epochs": 10, "timestep": 18288, "ep_reward": 168.7191619873047, "reward": 0.860109806060791, "action": -1.1170718669891357}
{"mode": "train", "epochs": 10, "timestep": 18289, "ep_reward": 169.57333374023438, "reward": 0.854167103767395, "action": -1.1391819715499878}
{"mode": "train", "epochs": 10, "timestep": 18290, "ep_reward": 170.40216064453125, "reward": 0.8288275003433228, "action": -0.9690394401550293}
{"mode": "train", "epochs": 10, "timestep": 18291, "ep_reward": 171.18411254882812, "reward": 0.7819520235061646, "action": -0.9034040570259094}
{"mode": "train", "epochs": 10, "timestep": 18292, "ep_reward": 171.89109802246094, "reward": 0.7069869041442871, "action": -0.7087603807449341}
{"mode": "train", "epochs": 10, "timestep": 18293, "ep_reward": 172.49008178710938, "reward": 0.5989843010902405, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 18294, "ep_reward": 172.9206085205078, "reward": 0.43053287267684937, "action": -0.715482234954834}
{"mode": "train", "epochs": 10, "timestep": 18295, "ep_reward": 173.24252319335938, "reward": 0.32191377878189087, "action": -1.0116190910339355}
{"mode": "train", "epochs": 10, "timestep": 18296, "ep_reward": 173.44895935058594, "reward": 0.2064303755760193, "action": -1.2084457874298096}
{"mode": "train", "epochs": 10, "timestep": 18297, "ep_reward": 173.51995849609375, "reward": 0.07100093364715576, "action": -1.015663743019104}
{"mode": "train", "epochs": 10, "timestep": 18298, "ep_reward": 173.5670166015625, "reward": 0.047055840492248535, "action": -1.4224646091461182}
{"mode": "train", "epochs": 10, "timestep": 18299, "ep_reward": 173.75286865234375, "reward": 0.18585336208343506, "action": -0.7255380153656006}
{"mode": "train", "epochs": 10, "timestep": 18300, "ep_reward": 174.0821990966797, "reward": 0.32933735847473145, "action": -1.4497405290603638}
{"mode": "train", "epochs": 10, "timestep": 18301, "ep_reward": 174.54022216796875, "reward": 0.45803016424179077, "action": -1.092238187789917}
{"mode": "train", "epochs": 10, "timestep": 18302, "ep_reward": 175.11752319335938, "reward": 0.5772945880889893, "action": -0.6582306623458862}
{"mode": "train", "epochs": 10, "timestep": 18303, "ep_reward": 175.79771423339844, "reward": 0.6801919937133789, "action": -0.9264264702796936}
{"mode": "train", "epochs": 10, "timestep": 18304, "ep_reward": 176.55442810058594, "reward": 0.7567065954208374, "action": -0.7730373740196228}
{"mode": "train", "epochs": 10, "timestep": 18305, "ep_reward": 177.36705017089844, "reward": 0.812619149684906, "action": -1.5289355516433716}
{"mode": "train", "epochs": 10, "timestep": 18306, "ep_reward": 178.20973205566406, "reward": 0.8426826000213623, "action": -0.4367120862007141}
{"mode": "train", "epochs": 10, "timestep": 18307, "ep_reward": 179.0745086669922, "reward": 0.864780604839325, "action": -0.7527225017547607}
{"mode": "train", "epochs": 10, "timestep": 18308, "ep_reward": 179.94212341308594, "reward": 0.8676088452339172, "action": -0.9019192457199097}
{"mode": "train", "epochs": 10, "timestep": 18309, "ep_reward": 180.79429626464844, "reward": 0.8521757125854492, "action": -0.9094722270965576}
{"mode": "train", "epochs": 10, "timestep": 18310, "ep_reward": 181.61119079589844, "reward": 0.8168984055519104, "action": -0.9043452143669128}
{"mode": "train", "epochs": 10, "timestep": 18311, "ep_reward": 182.36822509765625, "reward": 0.7570314407348633, "action": -0.9669505953788757}
{"mode": "train", "epochs": 10, "timestep": 18312, "ep_reward": 183.03353881835938, "reward": 0.6653207540512085, "action": -0.44148051738739014}
{"mode": "train", "epochs": 10, "timestep": 18313, "ep_reward": 183.57675170898438, "reward": 0.5432056188583374, "action": -1.5263867378234863}
{"mode": "train", "epochs": 10, "timestep": 18314, "ep_reward": 183.94996643066406, "reward": 0.37321096658706665, "action": -1.9396967887878418}
{"mode": "train", "epochs": 10, "timestep": 18315, "ep_reward": 184.2180938720703, "reward": 0.2681339979171753, "action": -1.36443030834198}
{"mode": "train", "epochs": 10, "timestep": 18316, "ep_reward": 184.36106872558594, "reward": 0.14298218488693237, "action": -1.0748001337051392}
{"mode": "train", "epochs": 10, "timestep": 18317, "ep_reward": 184.3588409423828, "reward": -0.0022270679473876953, "action": -1.1684170961380005}
{"mode": "train", "epochs": 10, "timestep": 18318, "ep_reward": 184.47604370117188, "reward": 0.11719536781311035, "action": -0.7200654745101929}
{"mode": "train", "epochs": 10, "timestep": 18319, "ep_reward": 184.7354736328125, "reward": 0.2594375014305115, "action": -0.6816830039024353}
{"mode": "train", "epochs": 10, "timestep": 18320, "ep_reward": 185.13636779785156, "reward": 0.40089911222457886, "action": -1.0999654531478882}
{"mode": "train", "epochs": 10, "timestep": 18321, "ep_reward": 185.66293334960938, "reward": 0.526567816734314, "action": -0.36178267002105713}
{"mode": "train", "epochs": 10, "timestep": 18322, "ep_reward": 186.30508422851562, "reward": 0.6421557068824768, "action": -1.7913618087768555}
{"mode": "train", "epochs": 10, "timestep": 18323, "ep_reward": 187.02597045898438, "reward": 0.7208819389343262, "action": -0.31740790605545044}
{"mode": "train", "epochs": 10, "timestep": 18324, "ep_reward": 187.8187713623047, "reward": 0.7928050756454468, "action": -0.7253000736236572}
{"mode": "train", "epochs": 10, "timestep": 18325, "ep_reward": 188.65895080566406, "reward": 0.8401745557785034, "action": -0.5483080148696899}
{"mode": "train", "epochs": 10, "timestep": 18326, "ep_reward": 189.53048706054688, "reward": 0.8715294599533081, "action": -1.103613257408142}
{"mode": "train", "epochs": 10, "timestep": 18327, "ep_reward": 190.41387939453125, "reward": 0.883392333984375, "action": -1.679584264755249}
{"mode": "train", "epochs": 10, "timestep": 18328, "ep_reward": 191.2904052734375, "reward": 0.8765210509300232, "action": -0.31228435039520264}
{"mode": "train", "epochs": 10, "timestep": 18329, "ep_reward": 192.15528869628906, "reward": 0.8648878931999207, "action": -1.8305070400238037}
{"mode": "train", "epochs": 10, "timestep": 18330, "ep_reward": 192.97669982910156, "reward": 0.8214119672775269, "action": -0.8414785861968994}
{"mode": "train", "epochs": 10, "timestep": 18331, "ep_reward": 193.7391357421875, "reward": 0.7624377608299255, "action": -0.07494378089904785}
{"mode": "train", "epochs": 10, "timestep": 18332, "ep_reward": 194.42201232910156, "reward": 0.6828820705413818, "action": -0.33912837505340576}
{"mode": "train", "epochs": 10, "timestep": 18333, "ep_reward": 194.9886932373047, "reward": 0.5666860342025757, "action": -1.20382821559906}
{"mode": "train", "epochs": 10, "timestep": 18334, "ep_reward": 195.38827514648438, "reward": 0.39957618713378906, "action": -1.5251299142837524}
{"mode": "train", "epochs": 10, "timestep": 18335, "ep_reward": 195.66404724121094, "reward": 0.2757764458656311, "action": -1.4522546529769897}
{"mode": "train", "epochs": 10, "timestep": 18336, "ep_reward": 195.81605529785156, "reward": 0.1520116925239563, "action": -0.7789136171340942}
{"mode": "train", "epochs": 10, "timestep": 18337, "ep_reward": 195.82412719726562, "reward": 0.008073627948760986, "action": -1.369530200958252}
{"mode": "train", "epochs": 10, "timestep": 18338, "ep_reward": 195.93191528320312, "reward": 0.1077805757522583, "action": -1.3304880857467651}
{"mode": "train", "epochs": 10, "timestep": 18339, "ep_reward": 196.17404174804688, "reward": 0.24213021993637085, "action": -1.1000832319259644}
{"mode": "train", "epochs": 10, "timestep": 18340, "ep_reward": 196.55453491210938, "reward": 0.38049787282943726, "action": -1.0100622177124023}
{"mode": "train", "epochs": 10, "timestep": 18341, "ep_reward": 197.06503295898438, "reward": 0.5104906558990479, "action": -0.9859305024147034}
{"mode": "train", "epochs": 10, "timestep": 18342, "ep_reward": 197.6876983642578, "reward": 0.6226578950881958, "action": -0.669742226600647}
{"mode": "train", "epochs": 10, "timestep": 18343, "ep_reward": 198.40313720703125, "reward": 0.7154383659362793, "action": -0.7757368087768555}
{"mode": "train", "epochs": 10, "timestep": 18344, "ep_reward": 199.18670654296875, "reward": 0.7835753560066223, "action": -1.2394859790802002}
{"mode": "train", "epochs": 10, "timestep": 18345, "ep_reward": 200.0133056640625, "reward": 0.8266058564186096, "action": -0.7895776033401489}
{"mode": "train", "epochs": 10, "timestep": 18346, "ep_reward": 200.86843872070312, "reward": 0.8551324605941772, "action": -1.2666188478469849}
{"mode": "train", "epochs": 10, "timestep": 18347, "ep_reward": 201.73109436035156, "reward": 0.8626574277877808, "action": -0.7565898895263672}
{"mode": "train", "epochs": 10, "timestep": 18348, "ep_reward": 202.58865356445312, "reward": 0.8575612306594849, "action": -0.8954887986183167}
{"mode": "train", "epochs": 10, "timestep": 18349, "ep_reward": 203.42124938964844, "reward": 0.8325904607772827, "action": -0.8963409662246704}
{"mode": "train", "epochs": 10, "timestep": 18350, "ep_reward": 204.20631408691406, "reward": 0.7850692272186279, "action": -1.124361276626587}
{"mode": "train", "epochs": 10, "timestep": 18351, "ep_reward": 204.912841796875, "reward": 0.7065258622169495, "action": -0.5201472043991089}
{"mode": "train", "epochs": 10, "timestep": 18352, "ep_reward": 205.51300048828125, "reward": 0.600162148475647, "action": -0.5512855052947998}
{"mode": "train", "epochs": 10, "timestep": 18353, "ep_reward": 205.9676055908203, "reward": 0.45460957288742065, "action": -0.7113572359085083}
{"mode": "train", "epochs": 10, "timestep": 18354, "ep_reward": 206.28793334960938, "reward": 0.3203228712081909, "action": -1.906118631362915}
{"mode": "train", "epochs": 10, "timestep": 18355, "ep_reward": 206.49270629882812, "reward": 0.2047663927078247, "action": -0.9555172324180603}
{"mode": "train", "epochs": 10, "timestep": 18356, "ep_reward": 206.5615692138672, "reward": 0.06886857748031616, "action": -1.9108445644378662}
{"mode": "train", "epochs": 10, "timestep": 18357, "ep_reward": 206.6105499267578, "reward": 0.048986852169036865, "action": -1.8084337711334229}
{"mode": "train", "epochs": 10, "timestep": 18358, "ep_reward": 206.79812622070312, "reward": 0.18757504224777222, "action": -0.8910825252532959}
{"mode": "train", "epochs": 10, "timestep": 18359, "ep_reward": 207.12730407714844, "reward": 0.32917070388793945, "action": 0.16361689567565918}
{"mode": "train", "epochs": 10, "timestep": 18360, "ep_reward": 207.60443115234375, "reward": 0.4771197438240051, "action": -0.5603330135345459}
{"mode": "train", "epochs": 10, "timestep": 18361, "ep_reward": 208.2028045654297, "reward": 0.5983692407608032, "action": -1.7062857151031494}
{"mode": "train", "epochs": 10, "timestep": 18362, "ep_reward": 208.88995361328125, "reward": 0.6871474981307983, "action": -1.0262197256088257}
{"mode": "train", "epochs": 10, "timestep": 18363, "ep_reward": 209.65220642089844, "reward": 0.7622548937797546, "action": -1.038440227508545}
{"mode": "train", "epochs": 10, "timestep": 18364, "ep_reward": 210.46875, "reward": 0.816540002822876, "action": -1.035884976387024}
{"mode": "train", "epochs": 10, "timestep": 18365, "ep_reward": 211.32127380371094, "reward": 0.8525162935256958, "action": 0.33563822507858276}
{"mode": "train", "epochs": 10, "timestep": 18366, "ep_reward": 212.2042236328125, "reward": 0.8829531669616699, "action": -1.4180182218551636}
{"mode": "train", "epochs": 10, "timestep": 18367, "ep_reward": 213.0893096923828, "reward": 0.8850889801979065, "action": -0.6832313537597656}
{"mode": "train", "epochs": 10, "timestep": 18368, "ep_reward": 213.96791076660156, "reward": 0.8786022663116455, "action": -1.039116621017456}
{"mode": "train", "epochs": 10, "timestep": 18369, "ep_reward": 214.8209228515625, "reward": 0.8530174493789673, "action": -1.2244477272033691}
{"mode": "train", "epochs": 10, "timestep": 18370, "ep_reward": 215.6262664794922, "reward": 0.8053411841392517, "action": -0.5003103017807007}
{"mode": "train", "epochs": 10, "timestep": 18371, "ep_reward": 216.3653564453125, "reward": 0.7390914559364319, "action": -0.7075124979019165}
{"mode": "train", "epochs": 10, "timestep": 18372, "ep_reward": 217.00457763671875, "reward": 0.6392217874526978, "action": -1.5041860342025757}
{"mode": "train", "epochs": 10, "timestep": 18373, "ep_reward": 217.49493408203125, "reward": 0.4903610944747925, "action": -0.0784989595413208}
{"mode": "train", "epochs": 10, "timestep": 18374, "ep_reward": 217.83157348632812, "reward": 0.33663880825042725, "action": -1.033300757408142}
{"mode": "train", "epochs": 10, "timestep": 18375, "ep_reward": 218.05548095703125, "reward": 0.2239093780517578, "action": -1.6551916599273682}
{"mode": "train", "epochs": 10, "timestep": 18376, "ep_reward": 218.1469268798828, "reward": 0.09144800901412964, "action": -0.3483288288116455}
{"mode": "train", "epochs": 10, "timestep": 18377, "ep_reward": 218.172607421875, "reward": 0.025681734085083008, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 18378, "ep_reward": 218.33995056152344, "reward": 0.16734862327575684, "action": -1.3747704029083252}
{"mode": "train", "epochs": 10, "timestep": 18379, "ep_reward": 218.64242553710938, "reward": 0.3024769425392151, "action": -1.6627411842346191}
{"mode": "train", "epochs": 10, "timestep": 18380, "ep_reward": 219.07371520996094, "reward": 0.4312933087348938, "action": -0.8815349340438843}
{"mode": "train", "epochs": 10, "timestep": 18381, "ep_reward": 219.6308135986328, "reward": 0.5570983290672302, "action": -1.1908926963806152}
{"mode": "train", "epochs": 10, "timestep": 18382, "ep_reward": 220.28915405273438, "reward": 0.6583434343338013, "action": -0.2093418836593628}
{"mode": "train", "epochs": 10, "timestep": 18383, "ep_reward": 221.03521728515625, "reward": 0.7460687160491943, "action": -0.4830852746963501}
{"mode": "train", "epochs": 10, "timestep": 18384, "ep_reward": 221.842041015625, "reward": 0.8068243265151978, "action": -0.7298688292503357}
{"mode": "train", "epochs": 10, "timestep": 18385, "ep_reward": 222.68670654296875, "reward": 0.8446705341339111, "action": -1.566279411315918}
{"mode": "train", "epochs": 10, "timestep": 18386, "ep_reward": 223.54458618164062, "reward": 0.8578753471374512, "action": -0.7840955257415771}
{"mode": "train", "epochs": 10, "timestep": 18387, "ep_reward": 224.40536499023438, "reward": 0.8607852458953857, "action": -1.4267115592956543}
{"mode": "train", "epochs": 10, "timestep": 18388, "ep_reward": 225.245361328125, "reward": 0.8399893641471863, "action": -0.8956605792045593}
{"mode": "train", "epochs": 10, "timestep": 18389, "ep_reward": 226.04769897460938, "reward": 0.8023422956466675, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 18390, "ep_reward": 226.77320861816406, "reward": 0.7255126237869263, "action": -1.179714322090149}
{"mode": "train", "epochs": 10, "timestep": 18391, "ep_reward": 227.3946533203125, "reward": 0.6214505434036255, "action": -1.3440091609954834}
{"mode": "train", "epochs": 10, "timestep": 18392, "ep_reward": 227.86727905273438, "reward": 0.47262686491012573, "action": -1.334965467453003}
{"mode": "train", "epochs": 10, "timestep": 18393, "ep_reward": 228.21893310546875, "reward": 0.3516610264778137, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 18394, "ep_reward": 228.46107482910156, "reward": 0.24214410781860352, "action": -1.5458941459655762}
{"mode": "train", "epochs": 10, "timestep": 18395, "ep_reward": 228.5736846923828, "reward": 0.11261403560638428, "action": -0.9939253926277161}
{"mode": "train", "epochs": 10, "timestep": 18396, "ep_reward": 228.5764923095703, "reward": 0.002804875373840332, "action": -1.3539819717407227}
{"mode": "train", "epochs": 10, "timestep": 18397, "ep_reward": 228.7239227294922, "reward": 0.1474279761314392, "action": -0.7363553643226624}
{"mode": "train", "epochs": 10, "timestep": 18398, "ep_reward": 229.0140838623047, "reward": 0.29016274213790894, "action": -1.074511170387268}
{"mode": "train", "epochs": 10, "timestep": 18399, "ep_reward": 229.43960571289062, "reward": 0.4255242943763733, "action": -1.3253159523010254}
{"mode": "train", "epochs": 10, "timestep": 18400, "ep_reward": 229.98570251464844, "reward": 0.5461028814315796, "action": -1.2587827444076538}
{"mode": "train", "epochs": 10, "timestep": 18401, "ep_reward": 230.63461303710938, "reward": 0.6489042043685913, "action": -1.3855472803115845}
{"mode": "train", "epochs": 10, "timestep": 18402, "ep_reward": 231.36305236816406, "reward": 0.7284409999847412, "action": -1.419967532157898}
{"mode": "train", "epochs": 10, "timestep": 18403, "ep_reward": 232.14883422851562, "reward": 0.7857773900032043, "action": -1.5045174360275269}
{"mode": "train", "epochs": 10, "timestep": 18404, "ep_reward": 232.9707794189453, "reward": 0.8219506144523621, "action": -1.0641676187515259}
{"mode": "train", "epochs": 10, "timestep": 18405, "ep_reward": 233.81350708007812, "reward": 0.8427280187606812, "action": -1.9872503280639648}
{"mode": "train", "epochs": 10, "timestep": 18406, "ep_reward": 234.6498260498047, "reward": 0.8363169431686401, "action": -0.4397770166397095}
{"mode": "train", "epochs": 10, "timestep": 18407, "ep_reward": 235.4735565185547, "reward": 0.8237314224243164, "action": -0.6500067710876465}
{"mode": "train", "epochs": 10, "timestep": 18408, "ep_reward": 236.25973510742188, "reward": 0.7861767411231995, "action": 0.09571951627731323}
{"mode": "train", "epochs": 10, "timestep": 18409, "ep_reward": 236.98953247070312, "reward": 0.7298002243041992, "action": -1.4057377576828003}
{"mode": "train", "epochs": 10, "timestep": 18410, "ep_reward": 237.61219787597656, "reward": 0.6226702928543091, "action": -1.2416993379592896}
{"mode": "train", "epochs": 10, "timestep": 18411, "ep_reward": 238.0874481201172, "reward": 0.47525763511657715, "action": -1.0998340845108032}
{"mode": "train", "epochs": 10, "timestep": 18412, "ep_reward": 238.43643188476562, "reward": 0.3489863872528076, "action": -0.20953720808029175}
{"mode": "train", "epochs": 10, "timestep": 18413, "ep_reward": 238.67520141601562, "reward": 0.2387751340866089, "action": -0.4302937388420105}
{"mode": "train", "epochs": 10, "timestep": 18414, "ep_reward": 238.78375244140625, "reward": 0.10855704545974731, "action": -0.6569397449493408}
{"mode": "train", "epochs": 10, "timestep": 18415, "ep_reward": 238.79107666015625, "reward": 0.0073226094245910645, "action": -1.3142863512039185}
{"mode": "train", "epochs": 10, "timestep": 18416, "ep_reward": 238.94236755371094, "reward": 0.15128910541534424, "action": -1.2586708068847656}
{"mode": "train", "epochs": 10, "timestep": 18417, "ep_reward": 239.2300567626953, "reward": 0.28768616914749146, "action": -0.6495839357376099}
{"mode": "train", "epochs": 10, "timestep": 18418, "ep_reward": 239.65940856933594, "reward": 0.4293527603149414, "action": -0.37682318687438965}
{"mode": "train", "epochs": 10, "timestep": 18419, "ep_reward": 240.2196502685547, "reward": 0.5602365732192993, "action": -0.7122304439544678}
{"mode": "train", "epochs": 10, "timestep": 18420, "ep_reward": 240.88587951660156, "reward": 0.6662231087684631, "action": -0.17627084255218506}
{"mode": "train", "epochs": 10, "timestep": 18421, "ep_reward": 241.64016723632812, "reward": 0.7542864084243774, "action": -1.3124159574508667}
{"mode": "train", "epochs": 10, "timestep": 18422, "ep_reward": 242.4501495361328, "reward": 0.8099797964096069, "action": -0.9292500615119934}
{"mode": "train", "epochs": 10, "timestep": 18423, "ep_reward": 243.30093383789062, "reward": 0.8507917523384094, "action": -1.373703122138977}
{"mode": "train", "epochs": 10, "timestep": 18424, "ep_reward": 244.17291259765625, "reward": 0.871974766254425, "action": -1.3879451751708984}
{"mode": "train", "epochs": 10, "timestep": 18425, "ep_reward": 245.05142211914062, "reward": 0.8785133361816406, "action": -0.21552395820617676}
{"mode": "train", "epochs": 10, "timestep": 18426, "ep_reward": 245.93106079101562, "reward": 0.8796430230140686, "action": -0.9146357178688049}
{"mode": "train", "epochs": 10, "timestep": 18427, "ep_reward": 246.7903594970703, "reward": 0.8592960238456726, "action": -1.2198820114135742}
{"mode": "train", "epochs": 10, "timestep": 18428, "ep_reward": 247.60726928710938, "reward": 0.8169166445732117, "action": -0.2980668544769287}
{"mode": "train", "epochs": 10, "timestep": 18429, "ep_reward": 248.3665313720703, "reward": 0.7592669725418091, "action": -1.3203577995300293}
{"mode": "train", "epochs": 10, "timestep": 18430, "ep_reward": 249.02674865722656, "reward": 0.660212516784668, "action": -0.44446325302124023}
{"mode": "train", "epochs": 10, "timestep": 18431, "ep_reward": 249.56153869628906, "reward": 0.5347896218299866, "action": -0.8775692582130432}
{"mode": "train", "epochs": 10, "timestep": 18432, "ep_reward": 249.92596435546875, "reward": 0.36441975831985474, "action": -1.053086280822754}
{"mode": "train", "epochs": 10, "timestep": 18433, "ep_reward": 250.17843627929688, "reward": 0.25247615575790405, "action": -0.03094273805618286}
{"mode": "train", "epochs": 10, "timestep": 18434, "ep_reward": 250.30282592773438, "reward": 0.12438815832138062, "action": -1.7215116024017334}
{"mode": "train", "epochs": 10, "timestep": 18435, "ep_reward": 250.2923583984375, "reward": -0.010463118553161621, "action": -0.964656412601471}
{"mode": "train", "epochs": 10, "timestep": 18436, "ep_reward": 250.42807006835938, "reward": 0.13570404052734375, "action": -1.541001319885254}
{"mode": "train", "epochs": 10, "timestep": 18437, "ep_reward": 250.69630432128906, "reward": 0.2682328224182129, "action": -0.5193870067596436}
{"mode": "train", "epochs": 10, "timestep": 18438, "ep_reward": 251.10931396484375, "reward": 0.4130099415779114, "action": -0.670174241065979}
{"mode": "train", "epochs": 10, "timestep": 18439, "ep_reward": 251.65208435058594, "reward": 0.5427650213241577, "action": -1.1191306114196777}
{"mode": "train", "epochs": 10, "timestep": 18440, "ep_reward": 252.29977416992188, "reward": 0.6476935148239136, "action": -1.3205618858337402}
{"mode": "train", "epochs": 10, "timestep": 18441, "ep_reward": 253.0284881591797, "reward": 0.728718638420105, "action": -1.2777652740478516}
{"mode": "train", "epochs": 10, "timestep": 18442, "ep_reward": 253.8169708251953, "reward": 0.7884792685508728, "action": -1.784064769744873}
{"mode": "train", "epochs": 10, "timestep": 18443, "ep_reward": 254.64060974121094, "reward": 0.8236360549926758, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 18444, "ep_reward": 255.47914123535156, "reward": 0.8385337591171265, "action": -1.6356711387634277}
{"mode": "train", "epochs": 10, "timestep": 18445, "ep_reward": 256.31707763671875, "reward": 0.8379483222961426, "action": -0.793876588344574}
{"mode": "train", "epochs": 10, "timestep": 18446, "ep_reward": 257.14178466796875, "reward": 0.8247201442718506, "action": -1.2064321041107178}
{"mode": "train", "epochs": 10, "timestep": 18447, "ep_reward": 257.92578125, "reward": 0.7840058207511902, "action": -1.2943358421325684}
{"mode": "train", "epochs": 10, "timestep": 18448, "ep_reward": 258.638671875, "reward": 0.7128762006759644, "action": -1.2482221126556396}
{"mode": "train", "epochs": 10, "timestep": 18449, "ep_reward": 259.24395751953125, "reward": 0.6053004264831543, "action": -0.7912713885307312}
{"mode": "train", "epochs": 10, "timestep": 18450, "ep_reward": 259.70501708984375, "reward": 0.46106189489364624, "action": -1.3815785646438599}
{"mode": "train", "epochs": 10, "timestep": 18451, "ep_reward": 260.0540466308594, "reward": 0.3490368127822876, "action": -1.3247735500335693}
{"mode": "train", "epochs": 10, "timestep": 18452, "ep_reward": 260.2928161621094, "reward": 0.238764226436615, "action": -1.838614583015442}
{"mode": "train", "epochs": 10, "timestep": 18453, "ep_reward": 260.401611328125, "reward": 0.10879218578338623, "action": -0.48642146587371826}
{"mode": "train", "epochs": 10, "timestep": 18454, "ep_reward": 260.40869140625, "reward": 0.007064878940582275, "action": -1.373179316520691}
{"mode": "train", "epochs": 10, "timestep": 18455, "ep_reward": 260.55975341796875, "reward": 0.15106552839279175, "action": -1.2923160791397095}
{"mode": "train", "epochs": 10, "timestep": 18456, "ep_reward": 260.8468017578125, "reward": 0.2870537042617798, "action": -0.48504453897476196}
{"mode": "train", "epochs": 10, "timestep": 18457, "ep_reward": 261.277587890625, "reward": 0.43077611923217773, "action": -0.6133444905281067}
{"mode": "train", "epochs": 10, "timestep": 18458, "ep_reward": 261.8363342285156, "reward": 0.5587326288223267, "action": -0.6563390493392944}
{"mode": "train", "epochs": 10, "timestep": 18459, "ep_reward": 262.5018310546875, "reward": 0.6654931306838989, "action": -1.1494709253311157}
{"mode": "train", "epochs": 10, "timestep": 18460, "ep_reward": 263.2464294433594, "reward": 0.7445905208587646, "action": -1.7452529668807983}
{"mode": "train", "epochs": 10, "timestep": 18461, "ep_reward": 264.04400634765625, "reward": 0.7975842952728271, "action": -1.210587978363037}
{"mode": "train", "epochs": 10, "timestep": 18462, "ep_reward": 264.8805236816406, "reward": 0.8365297913551331, "action": -1.843809723854065}
{"mode": "train", "epochs": 10, "timestep": 18463, "ep_reward": 265.7331848144531, "reward": 0.8526614904403687, "action": -1.4205292463302612}
{"mode": "train", "epochs": 10, "timestep": 18464, "ep_reward": 266.58856201171875, "reward": 0.8553900718688965, "action": -1.1492209434509277}
{"mode": "train", "epochs": 10, "timestep": 18465, "ep_reward": 267.4306945800781, "reward": 0.8421207070350647, "action": -1.5452008247375488}
{"mode": "train", "epochs": 10, "timestep": 18466, "ep_reward": 268.23443603515625, "reward": 0.8037292957305908, "action": -0.6242092847824097}
{"mode": "train", "epochs": 10, "timestep": 18467, "ep_reward": 268.98272705078125, "reward": 0.7482796907424927, "action": -1.134237289428711}
{"mode": "train", "epochs": 10, "timestep": 18468, "ep_reward": 269.6375732421875, "reward": 0.6548417806625366, "action": -0.7043064832687378}
{"mode": "train", "epochs": 10, "timestep": 18469, "ep_reward": 270.1652526855469, "reward": 0.5276809930801392, "action": -1.1842328310012817}
{"mode": "train", "epochs": 10, "timestep": 18470, "ep_reward": 270.54296875, "reward": 0.37773019075393677, "action": -1.1598093509674072}
{"mode": "train", "epochs": 10, "timestep": 18471, "ep_reward": 270.81646728515625, "reward": 0.2734954357147217, "action": -0.8711115121841431}
{"mode": "train", "epochs": 10, "timestep": 18472, "ep_reward": 270.9657287597656, "reward": 0.14926385879516602, "action": 0.3627617359161377}
{"mode": "train", "epochs": 10, "timestep": 18473, "ep_reward": 270.9706726074219, "reward": 0.004934489727020264, "action": -1.0385690927505493}
{"mode": "train", "epochs": 10, "timestep": 18474, "ep_reward": 271.0812072753906, "reward": 0.11054223775863647, "action": -1.9838933944702148}
{"mode": "train", "epochs": 10, "timestep": 18475, "ep_reward": 271.3218688964844, "reward": 0.24066323041915894, "action": -0.41107988357543945}
{"mode": "train", "epochs": 10, "timestep": 18476, "ep_reward": 271.71002197265625, "reward": 0.3881537914276123, "action": -1.685354232788086}
{"mode": "train", "epochs": 10, "timestep": 18477, "ep_reward": 272.2191467285156, "reward": 0.5091309547424316, "action": -1.1941921710968018}
{"mode": "train", "epochs": 10, "timestep": 18478, "ep_reward": 272.83837890625, "reward": 0.619217038154602, "action": -1.2459245920181274}
{"mode": "train", "epochs": 10, "timestep": 18479, "ep_reward": 273.544921875, "reward": 0.70655357837677, "action": -0.4005323648452759}
{"mode": "train", "epochs": 10, "timestep": 18480, "ep_reward": 274.3236389160156, "reward": 0.7787045240402222, "action": -1.9695441722869873}
{"mode": "train", "epochs": 10, "timestep": 18481, "ep_reward": 275.1379089355469, "reward": 0.8142697215080261, "action": -1.2229869365692139}
{"mode": "train", "epochs": 10, "timestep": 18482, "ep_reward": 275.97528076171875, "reward": 0.8373579978942871, "action": -1.764913558959961}
{"mode": "train", "epochs": 10, "timestep": 18483, "ep_reward": 276.8116455078125, "reward": 0.8363732695579529, "action": -0.9356660842895508}
{"mode": "train", "epochs": 10, "timestep": 18484, "ep_reward": 277.6341247558594, "reward": 0.822475254535675, "action": -0.899773120880127}
{"mode": "train", "epochs": 10, "timestep": 18485, "ep_reward": 278.41961669921875, "reward": 0.7854903936386108, "action": -1.0513557195663452}
{"mode": "train", "epochs": 10, "timestep": 18486, "ep_reward": 279.1378173828125, "reward": 0.7182090282440186, "action": -1.4079692363739014}
{"mode": "train", "epochs": 10, "timestep": 18487, "ep_reward": 279.7481384277344, "reward": 0.61033034324646, "action": -0.4548587203025818}
{"mode": "train", "epochs": 10, "timestep": 18488, "ep_reward": 280.2211608886719, "reward": 0.47301942110061646, "action": -1.9023041725158691}
{"mode": "train", "epochs": 10, "timestep": 18489, "ep_reward": 280.5744934082031, "reward": 0.35333502292633057, "action": -1.1535139083862305}
{"mode": "train", "epochs": 10, "timestep": 18490, "ep_reward": 280.8185119628906, "reward": 0.24402213096618652, "action": -1.1582131385803223}
{"mode": "train", "epochs": 10, "timestep": 18491, "ep_reward": 280.93316650390625, "reward": 0.11466526985168457, "action": -1.4370927810668945}
{"mode": "train", "epochs": 10, "timestep": 18492, "ep_reward": 280.93365478515625, "reward": 0.0004931092262268066, "action": -1.0834258794784546}
{"mode": "train", "epochs": 10, "timestep": 18493, "ep_reward": 281.0789794921875, "reward": 0.14533346891403198, "action": -1.1113215684890747}
{"mode": "train", "epochs": 10, "timestep": 18494, "ep_reward": 281.36236572265625, "reward": 0.28338366746902466, "action": -1.0484164953231812}
{"mode": "train", "epochs": 10, "timestep": 18495, "ep_reward": 281.7823486328125, "reward": 0.4199710488319397, "action": -1.974313497543335}
{"mode": "train", "epochs": 10, "timestep": 18496, "ep_reward": 282.3164978027344, "reward": 0.534156858921051, "action": -0.654280424118042}
{"mode": "train", "epochs": 10, "timestep": 18497, "ep_reward": 282.9620666503906, "reward": 0.6455785036087036, "action": -0.6328970193862915}
{"mode": "train", "epochs": 10, "timestep": 18498, "ep_reward": 283.6949768066406, "reward": 0.7329127192497253, "action": -0.45900195837020874}
{"mode": "train", "epochs": 10, "timestep": 18499, "ep_reward": 284.4931945800781, "reward": 0.7982068657875061, "action": -0.47395581007003784}
{"mode": "train", "epochs": 10, "timestep": 18500, "ep_reward": 285.3353576660156, "reward": 0.8421756625175476, "action": -0.5238761901855469}
{"mode": "train", "epochs": 10, "timestep": 18501, "ep_reward": 286.2029724121094, "reward": 0.8676279187202454, "action": -0.8182555437088013}
{"mode": "train", "epochs": 10, "timestep": 18502, "ep_reward": 287.0775451660156, "reward": 0.8745692372322083, "action": -1.6774084568023682}
{"mode": "train", "epochs": 10, "timestep": 18503, "ep_reward": 287.9357604980469, "reward": 0.8582087159156799, "action": -1.673071265220642}
{"mode": "train", "epochs": 10, "timestep": 18504, "ep_reward": 288.7577209472656, "reward": 0.8219603300094604, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 18505, "ep_reward": 289.5142517089844, "reward": 0.7565306425094604, "action": -0.7603604197502136}
{"mode": "train", "epochs": 10, "timestep": 18506, "ep_reward": 290.1862487792969, "reward": 0.6719882488250732, "action": -0.988768994808197}
{"mode": "train", "epochs": 10, "timestep": 18507, "ep_reward": 290.7329406738281, "reward": 0.5466879606246948, "action": -0.5755373239517212}
{"mode": "train", "epochs": 10, "timestep": 18508, "ep_reward": 291.1217346191406, "reward": 0.3887866139411926, "action": -1.2081012725830078}
{"mode": "train", "epochs": 10, "timestep": 18509, "ep_reward": 291.40863037109375, "reward": 0.28690624237060547, "action": -1.1113826036453247}
{"mode": "train", "epochs": 10, "timestep": 18510, "ep_reward": 291.57366943359375, "reward": 0.16503679752349854, "action": -0.9204596877098083}
{"mode": "train", "epochs": 10, "timestep": 18511, "ep_reward": 291.5967102050781, "reward": 0.023039698600769043, "action": -1.584438681602478}
{"mode": "train", "epochs": 10, "timestep": 18512, "ep_reward": 291.69049072265625, "reward": 0.09377086162567139, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 18513, "ep_reward": 291.9166259765625, "reward": 0.22614312171936035, "action": -1.4978947639465332}
{"mode": "train", "epochs": 10, "timestep": 18514, "ep_reward": 292.27703857421875, "reward": 0.360403835773468, "action": -1.1309983730316162}
{"mode": "train", "epochs": 10, "timestep": 18515, "ep_reward": 292.7687072753906, "reward": 0.4916709065437317, "action": -1.0623446702957153}
{"mode": "train", "epochs": 10, "timestep": 18516, "ep_reward": 293.37493896484375, "reward": 0.6062246561050415, "action": -1.123511552810669}
{"mode": "train", "epochs": 10, "timestep": 18517, "ep_reward": 294.0723571777344, "reward": 0.697430431842804, "action": -1.2615386247634888}
{"mode": "train", "epochs": 10, "timestep": 18518, "ep_reward": 294.8360595703125, "reward": 0.7636992931365967, "action": -1.5655591487884521}
{"mode": "train", "epochs": 10, "timestep": 18519, "ep_reward": 295.6412353515625, "reward": 0.8051876425743103, "action": -0.6916868686676025}
{"mode": "train", "epochs": 10, "timestep": 18520, "ep_reward": 296.4755859375, "reward": 0.8343411684036255, "action": -0.44007962942123413}
{"mode": "train", "epochs": 10, "timestep": 18521, "ep_reward": 297.3216552734375, "reward": 0.8460559844970703, "action": -0.3433806300163269}
{"mode": "train", "epochs": 10, "timestep": 18522, "ep_reward": 298.160888671875, "reward": 0.8392385840415955, "action": -1.497098684310913}
{"mode": "train", "epochs": 10, "timestep": 18523, "ep_reward": 298.9608154296875, "reward": 0.7999250888824463, "action": -1.307049036026001}
{"mode": "train", "epochs": 10, "timestep": 18524, "ep_reward": 299.69561767578125, "reward": 0.7348111867904663, "action": -0.8218866586685181}
{"mode": "train", "epochs": 10, "timestep": 18525, "ep_reward": 300.33685302734375, "reward": 0.641240119934082, "action": -0.5662785768508911}
{"mode": "train", "epochs": 10, "timestep": 18526, "ep_reward": 300.84844970703125, "reward": 0.5116086006164551, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 18527, "ep_reward": 301.2183837890625, "reward": 0.36993205547332764, "action": -1.2396422624588013}
{"mode": "train", "epochs": 10, "timestep": 18528, "ep_reward": 301.48223876953125, "reward": 0.263869047164917, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 18529, "ep_reward": 301.620361328125, "reward": 0.13813740015029907, "action": -1.0824494361877441}
{"mode": "train", "epochs": 10, "timestep": 18530, "ep_reward": 301.6124267578125, "reward": -0.007925987243652344, "action": -1.9137053489685059}
{"mode": "train", "epochs": 10, "timestep": 18531, "ep_reward": 301.7345275878906, "reward": 0.12208676338195801, "action": -1.1902713775634766}
{"mode": "train", "epochs": 10, "timestep": 18532, "ep_reward": 301.9931640625, "reward": 0.25863081216812134, "action": -0.6334871053695679}
{"mode": "train", "epochs": 10, "timestep": 18533, "ep_reward": 302.3948669433594, "reward": 0.40169966220855713, "action": -1.088762879371643}
{"mode": "train", "epochs": 10, "timestep": 18534, "ep_reward": 302.9226989746094, "reward": 0.52784264087677, "action": -0.6338642835617065}
{"mode": "train", "epochs": 10, "timestep": 18535, "ep_reward": 303.5633239746094, "reward": 0.6406116485595703, "action": -0.9365965723991394}
{"mode": "train", "epochs": 10, "timestep": 18536, "ep_reward": 304.29058837890625, "reward": 0.7272680401802063, "action": -1.278436541557312}
{"mode": "train", "epochs": 10, "timestep": 18537, "ep_reward": 305.07928466796875, "reward": 0.7886950969696045, "action": -1.616222858428955}
{"mode": "train", "epochs": 10, "timestep": 18538, "ep_reward": 305.9069519042969, "reward": 0.8276774883270264, "action": -1.0498415231704712}
{"mode": "train", "epochs": 10, "timestep": 18539, "ep_reward": 306.7605895996094, "reward": 0.8536498546600342, "action": -1.7169705629348755}
{"mode": "train", "epochs": 10, "timestep": 18540, "ep_reward": 307.6175842285156, "reward": 0.8569921255111694, "action": -0.8300998210906982}
{"mode": "train", "epochs": 10, "timestep": 18541, "ep_reward": 308.4678649902344, "reward": 0.8502772450447083, "action": -1.4067857265472412}
{"mode": "train", "epochs": 10, "timestep": 18542, "ep_reward": 309.2862243652344, "reward": 0.818362295627594, "action": -0.6333486437797546}
{"mode": "train", "epochs": 10, "timestep": 18543, "ep_reward": 310.05584716796875, "reward": 0.7696190476417542, "action": -1.2000986337661743}
{"mode": "train", "epochs": 10, "timestep": 18544, "ep_reward": 310.7403869628906, "reward": 0.6845502853393555, "action": -0.7754995822906494}
{"mode": "train", "epochs": 10, "timestep": 18545, "ep_reward": 311.3075256347656, "reward": 0.5671525597572327, "action": -1.3078794479370117}
{"mode": "train", "epochs": 10, "timestep": 18546, "ep_reward": 311.7072448730469, "reward": 0.39971673488616943, "action": -1.115004301071167}
{"mode": "train", "epochs": 10, "timestep": 18547, "ep_reward": 312.0069885253906, "reward": 0.29974037408828735, "action": -0.6319208145141602}
{"mode": "train", "epochs": 10, "timestep": 18548, "ep_reward": 312.1871337890625, "reward": 0.1801546812057495, "action": -0.6357264518737793}
{"mode": "train", "epochs": 10, "timestep": 18549, "ep_reward": 312.22760009765625, "reward": 0.040481507778167725, "action": -1.3486355543136597}
{"mode": "train", "epochs": 10, "timestep": 18550, "ep_reward": 312.3050231933594, "reward": 0.07741796970367432, "action": -0.8885643482208252}
{"mode": "train", "epochs": 10, "timestep": 18551, "ep_reward": 312.5213928222656, "reward": 0.21635591983795166, "action": -1.1914842128753662}
{"mode": "train", "epochs": 10, "timestep": 18552, "ep_reward": 312.8749694824219, "reward": 0.3535647988319397, "action": -0.5751233100891113}
{"mode": "train", "epochs": 10, "timestep": 18553, "ep_reward": 313.365966796875, "reward": 0.491011381149292, "action": -0.7474815845489502}
{"mode": "train", "epochs": 10, "timestep": 18554, "ep_reward": 313.97467041015625, "reward": 0.6087127327919006, "action": -1.3396577835083008}
{"mode": "train", "epochs": 10, "timestep": 18555, "ep_reward": 314.67315673828125, "reward": 0.698487401008606, "action": -1.2599761486053467}
{"mode": "train", "epochs": 10, "timestep": 18556, "ep_reward": 315.440673828125, "reward": 0.767518937587738, "action": -0.2537434697151184}
{"mode": "train", "epochs": 10, "timestep": 18557, "ep_reward": 316.2652587890625, "reward": 0.8246002197265625, "action": -0.6499602794647217}
{"mode": "train", "epochs": 10, "timestep": 18558, "ep_reward": 317.1239929199219, "reward": 0.8587380647659302, "action": -1.1241720914840698}
{"mode": "train", "epochs": 10, "timestep": 18559, "ep_reward": 317.9967041015625, "reward": 0.8727260231971741, "action": -0.7235209941864014}
{"mode": "train", "epochs": 10, "timestep": 18560, "ep_reward": 318.871337890625, "reward": 0.8746477365493774, "action": -0.18654710054397583}
{"mode": "train", "epochs": 10, "timestep": 18561, "ep_reward": 319.73651123046875, "reward": 0.8651713132858276, "action": -1.216484546661377}
{"mode": "train", "epochs": 10, "timestep": 18562, "ep_reward": 320.5650939941406, "reward": 0.8285903334617615, "action": -1.5571551322937012}
{"mode": "train", "epochs": 10, "timestep": 18563, "ep_reward": 321.32928466796875, "reward": 0.764190673828125, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 18564, "ep_reward": 321.9908447265625, "reward": 0.6615743041038513, "action": -1.7131009101867676}
{"mode": "train", "epochs": 10, "timestep": 18565, "ep_reward": 322.51092529296875, "reward": 0.5200936794281006, "action": -1.632369041442871}
{"mode": "train", "epochs": 10, "timestep": 18566, "ep_reward": 322.8836669921875, "reward": 0.37274593114852905, "action": -1.3352423906326294}
{"mode": "train", "epochs": 10, "timestep": 18567, "ep_reward": 323.1511535644531, "reward": 0.2674911618232727, "action": -0.8846485614776611}
{"mode": "train", "epochs": 10, "timestep": 18568, "ep_reward": 323.2933654785156, "reward": 0.1422232985496521, "action": 0.0525897741317749}
{"mode": "train", "epochs": 10, "timestep": 18569, "ep_reward": 323.2901306152344, "reward": -0.003237009048461914, "action": -1.5201961994171143}
{"mode": "train", "epochs": 10, "timestep": 18570, "ep_reward": 323.4080505371094, "reward": 0.11792463064193726, "action": -1.5550129413604736}
{"mode": "train", "epochs": 10, "timestep": 18571, "ep_reward": 323.6576232910156, "reward": 0.24957942962646484, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 18572, "ep_reward": 324.0346374511719, "reward": 0.377022385597229, "action": -0.8467904329299927}
{"mode": "train", "epochs": 10, "timestep": 18573, "ep_reward": 324.54510498046875, "reward": 0.5104619264602661, "action": -1.025031328201294}
{"mode": "train", "epochs": 10, "timestep": 18574, "ep_reward": 325.16717529296875, "reward": 0.6220778226852417, "action": -1.5868899822235107}
{"mode": "train", "epochs": 10, "timestep": 18575, "ep_reward": 325.8716125488281, "reward": 0.7044309973716736, "action": -1.7957119941711426}
{"mode": "train", "epochs": 10, "timestep": 18576, "ep_reward": 326.633544921875, "reward": 0.7619434595108032, "action": -0.7676992416381836}
{"mode": "train", "epochs": 10, "timestep": 18577, "ep_reward": 327.4407653808594, "reward": 0.8072214722633362, "action": -0.43832719326019287}
{"mode": "train", "epochs": 10, "timestep": 18578, "ep_reward": 328.2745361328125, "reward": 0.8337587118148804, "action": -1.3966232538223267}
{"mode": "train", "epochs": 10, "timestep": 18579, "ep_reward": 329.1054992675781, "reward": 0.8309694528579712, "action": -0.41211867332458496}
{"mode": "train", "epochs": 10, "timestep": 18580, "ep_reward": 329.92169189453125, "reward": 0.816189706325531, "action": -1.1271926164627075}
{"mode": "train", "epochs": 10, "timestep": 18581, "ep_reward": 330.6915283203125, "reward": 0.7698356509208679, "action": -0.9281061887741089}
{"mode": "train", "epochs": 10, "timestep": 18582, "ep_reward": 331.3866882324219, "reward": 0.6951560974121094, "action": -0.9812895655632019}
{"mode": "train", "epochs": 10, "timestep": 18583, "ep_reward": 331.9692687988281, "reward": 0.5825795531272888, "action": -0.8044419884681702}
{"mode": "train", "epochs": 10, "timestep": 18584, "ep_reward": 332.3990478515625, "reward": 0.42977553606033325, "action": -0.7766884565353394}
{"mode": "train", "epochs": 10, "timestep": 18585, "ep_reward": 332.7253112792969, "reward": 0.3262682557106018, "action": -0.6915467977523804}
{"mode": "train", "epochs": 10, "timestep": 18586, "ep_reward": 332.93695068359375, "reward": 0.21163076162338257, "action": -0.7607401013374329}
{"mode": "train", "epochs": 10, "timestep": 18587, "ep_reward": 333.0139465332031, "reward": 0.0769888162612915, "action": -0.8721388578414917}
{"mode": "train", "epochs": 10, "timestep": 18588, "ep_reward": 333.054931640625, "reward": 0.04098480939865112, "action": -0.9475364685058594}
{"mode": "train", "epochs": 10, "timestep": 18589, "ep_reward": 333.2354431152344, "reward": 0.18051040172576904, "action": -0.9437394738197327}
{"mode": "train", "epochs": 10, "timestep": 18590, "ep_reward": 333.5567626953125, "reward": 0.3213309645652771, "action": -0.7431367635726929}
{"mode": "train", "epochs": 10, "timestep": 18591, "ep_reward": 334.0160827636719, "reward": 0.45931947231292725, "action": -0.2191096544265747}
{"mode": "train", "epochs": 10, "timestep": 18592, "ep_reward": 334.6037292480469, "reward": 0.5876413583755493, "action": -1.0314804315567017}
{"mode": "train", "epochs": 10, "timestep": 18593, "ep_reward": 335.2886962890625, "reward": 0.6849807500839233, "action": -1.4358701705932617}
{"mode": "train", "epochs": 10, "timestep": 18594, "ep_reward": 336.04547119140625, "reward": 0.7567631006240845, "action": -1.4189167022705078}
{"mode": "train", "epochs": 10, "timestep": 18595, "ep_reward": 336.8541259765625, "reward": 0.8086525201797485, "action": -0.5845588445663452}
{"mode": "train", "epochs": 10, "timestep": 18596, "ep_reward": 337.7030944824219, "reward": 0.8489559292793274, "action": -1.0454550981521606}
{"mode": "train", "epochs": 10, "timestep": 18597, "ep_reward": 338.5713195800781, "reward": 0.8682129383087158, "action": -1.2816619873046875}
{"mode": "train", "epochs": 10, "timestep": 18598, "ep_reward": 339.4411926269531, "reward": 0.8698703646659851, "action": -0.6909323930740356}
{"mode": "train", "epochs": 10, "timestep": 18599, "ep_reward": 340.3012390136719, "reward": 0.8600502014160156, "action": -1.0467296838760376}
{"mode": "train", "epochs": 10, "timestep": 18600, "ep_reward": 341.1297302246094, "reward": 0.8285043835639954, "action": -0.08856701850891113}
{"mode": "train", "epochs": 10, "timestep": 18601, "ep_reward": 341.9134521484375, "reward": 0.7837223410606384, "action": -1.5162303447723389}
{"mode": "train", "epochs": 10, "timestep": 18602, "ep_reward": 342.60919189453125, "reward": 0.6957355737686157, "action": -0.6226662993431091}
{"mode": "train", "epochs": 10, "timestep": 18603, "ep_reward": 343.19122314453125, "reward": 0.5820441842079163, "action": -0.57075035572052}
{"mode": "train", "epochs": 10, "timestep": 18604, "ep_reward": 343.621337890625, "reward": 0.4301223158836365, "action": -0.9964550137519836}
{"mode": "train", "epochs": 10, "timestep": 18605, "ep_reward": 343.9212951660156, "reward": 0.2999568581581116, "action": -0.957218587398529}
{"mode": "train", "epochs": 10, "timestep": 18606, "ep_reward": 344.1017150878906, "reward": 0.1804208755493164, "action": -0.9232298135757446}
{"mode": "train", "epochs": 10, "timestep": 18607, "ep_reward": 344.1426086425781, "reward": 0.04090738296508789, "action": -0.6626139283180237}
{"mode": "train", "epochs": 10, "timestep": 18608, "ep_reward": 344.2196960449219, "reward": 0.07709401845932007, "action": -0.8472158908843994}
{"mode": "train", "epochs": 10, "timestep": 18609, "ep_reward": 344.4360656738281, "reward": 0.2163761854171753, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 18610, "ep_reward": 344.7795715332031, "reward": 0.34349316358566284, "action": -0.9964300394058228}
{"mode": "train", "epochs": 10, "timestep": 18611, "ep_reward": 345.2574157714844, "reward": 0.47784996032714844, "action": -1.470785140991211}
{"mode": "train", "epochs": 10, "timestep": 18612, "ep_reward": 345.8475036621094, "reward": 0.5900818109512329, "action": -1.0074503421783447}
{"mode": "train", "epochs": 10, "timestep": 18613, "ep_reward": 346.53350830078125, "reward": 0.6859937906265259, "action": -0.9711921215057373}
{"mode": "train", "epochs": 10, "timestep": 18614, "ep_reward": 347.2917175292969, "reward": 0.758210301399231, "action": -1.155998706817627}
{"mode": "train", "epochs": 10, "timestep": 18615, "ep_reward": 348.09765625, "reward": 0.8059353828430176, "action": -1.264369249343872}
{"mode": "train", "epochs": 10, "timestep": 18616, "ep_reward": 348.9298095703125, "reward": 0.8321410417556763, "action": -1.3054291009902954}
{"mode": "train", "epochs": 10, "timestep": 18617, "ep_reward": 349.76837158203125, "reward": 0.8385517001152039, "action": -0.6098684072494507}
{"mode": "train", "epochs": 10, "timestep": 18618, "ep_reward": 350.5997619628906, "reward": 0.8313908576965332, "action": -0.8327865600585938}
{"mode": "train", "epochs": 10, "timestep": 18619, "ep_reward": 351.39984130859375, "reward": 0.8000801205635071, "action": -0.7091464400291443}
{"mode": "train", "epochs": 10, "timestep": 18620, "ep_reward": 352.1434020996094, "reward": 0.7435694932937622, "action": -1.8522305488586426}
{"mode": "train", "epochs": 10, "timestep": 18621, "ep_reward": 352.78326416015625, "reward": 0.6398552656173706, "action": -0.962597668170929}
{"mode": "train", "epochs": 10, "timestep": 18622, "ep_reward": 353.2883605957031, "reward": 0.5051068663597107, "action": -1.0140284299850464}
{"mode": "train", "epochs": 10, "timestep": 18623, "ep_reward": 353.66265869140625, "reward": 0.37428414821624756, "action": -0.9170888066291809}
{"mode": "train", "epochs": 10, "timestep": 18624, "ep_reward": 353.9319152832031, "reward": 0.2692670226097107, "action": -1.007287621498108}
{"mode": "train", "epochs": 10, "timestep": 18625, "ep_reward": 354.07623291015625, "reward": 0.14432156085968018, "action": -0.22693759202957153}
{"mode": "train", "epochs": 10, "timestep": 18626, "ep_reward": 354.07550048828125, "reward": -0.0007299184799194336, "action": -0.8912519216537476}
{"mode": "train", "epochs": 10, "timestep": 18627, "ep_reward": 354.19140625, "reward": 0.11590087413787842, "action": -0.4745985269546509}
{"mode": "train", "epochs": 10, "timestep": 18628, "ep_reward": 354.4525146484375, "reward": 0.2611141800880432, "action": -0.9421388506889343}
{"mode": "train", "epochs": 10, "timestep": 18629, "ep_reward": 354.8513488769531, "reward": 0.39883875846862793, "action": -1.3686295747756958}
{"mode": "train", "epochs": 10, "timestep": 18630, "ep_reward": 355.37286376953125, "reward": 0.5215046405792236, "action": -1.796547293663025}
{"mode": "train", "epochs": 10, "timestep": 18631, "ep_reward": 355.9958190917969, "reward": 0.6229455471038818, "action": -1.437221884727478}
{"mode": "train", "epochs": 10, "timestep": 18632, "ep_reward": 356.70379638671875, "reward": 0.7079730033874512, "action": -0.9409612417221069}
{"mode": "train", "epochs": 10, "timestep": 18633, "ep_reward": 357.4793701171875, "reward": 0.7755700349807739, "action": -0.7170091271400452}
{"mode": "train", "epochs": 10, "timestep": 18634, "ep_reward": 358.3028564453125, "reward": 0.8234738707542419, "action": -1.000166416168213}
{"mode": "train", "epochs": 10, "timestep": 18635, "ep_reward": 359.15234375, "reward": 0.849477231502533, "action": -0.9454777240753174}
{"mode": "train", "epochs": 10, "timestep": 18636, "ep_reward": 360.0105895996094, "reward": 0.8582597374916077, "action": -1.3353370428085327}
{"mode": "train", "epochs": 10, "timestep": 18637, "ep_reward": 360.85638427734375, "reward": 0.8457966446876526, "action": -0.04940342903137207}
{"mode": "train", "epochs": 10, "timestep": 18638, "ep_reward": 361.68157958984375, "reward": 0.82518470287323, "action": -1.9752894639968872}
{"mode": "train", "epochs": 10, "timestep": 18639, "ep_reward": 362.4432373046875, "reward": 0.7616519331932068, "action": -1.127431035041809}
{"mode": "train", "epochs": 10, "timestep": 18640, "ep_reward": 363.1177673339844, "reward": 0.6745320558547974, "action": -1.1406199932098389}
{"mode": "train", "epochs": 10, "timestep": 18641, "ep_reward": 363.6661682128906, "reward": 0.5484030246734619, "action": -0.6244632005691528}
{"mode": "train", "epochs": 10, "timestep": 18642, "ep_reward": 364.0586242675781, "reward": 0.39245760440826416, "action": -0.5945550203323364}
{"mode": "train", "epochs": 10, "timestep": 18643, "ep_reward": 364.3499450683594, "reward": 0.29132896661758423, "action": -0.8359974026679993}
{"mode": "train", "epochs": 10, "timestep": 18644, "ep_reward": 364.5201721191406, "reward": 0.1702219843864441, "action": -0.8408983945846558}
{"mode": "train", "epochs": 10, "timestep": 18645, "ep_reward": 364.5492858886719, "reward": 0.029119431972503662, "action": -0.8085288405418396}
{"mode": "train", "epochs": 10, "timestep": 18646, "ep_reward": 364.6376647949219, "reward": 0.08838462829589844, "action": -0.5745651125907898}
{"mode": "train", "epochs": 10, "timestep": 18647, "ep_reward": 364.8692626953125, "reward": 0.23159223794937134, "action": -0.8800004720687866}
{"mode": "train", "epochs": 10, "timestep": 18648, "ep_reward": 365.24072265625, "reward": 0.37146562337875366, "action": -0.13502073287963867}
{"mode": "train", "epochs": 10, "timestep": 18649, "ep_reward": 365.7518310546875, "reward": 0.5111071467399597, "action": -1.636834979057312}
{"mode": "train", "epochs": 10, "timestep": 18650, "ep_reward": 366.3677062988281, "reward": 0.615881085395813, "action": -0.5641800165176392}
{"mode": "train", "epochs": 10, "timestep": 18651, "ep_reward": 367.0795593261719, "reward": 0.7118681073188782, "action": -1.4459106922149658}
{"mode": "train", "epochs": 10, "timestep": 18652, "ep_reward": 367.8567810058594, "reward": 0.777219295501709, "action": -0.19335758686065674}
{"mode": "train", "epochs": 10, "timestep": 18653, "ep_reward": 368.6904296875, "reward": 0.8336519002914429, "action": -1.3237481117248535}
{"mode": "train", "epochs": 10, "timestep": 18654, "ep_reward": 369.5529479980469, "reward": 0.8625107407569885, "action": -1.2355217933654785}
{"mode": "train", "epochs": 10, "timestep": 18655, "ep_reward": 370.429931640625, "reward": 0.8769896626472473, "action": -0.628480076789856}
{"mode": "train", "epochs": 10, "timestep": 18656, "ep_reward": 371.3115234375, "reward": 0.881605327129364, "action": -0.9479206204414368}
{"mode": "train", "epochs": 10, "timestep": 18657, "ep_reward": 372.1799621582031, "reward": 0.8684452176094055, "action": -1.110395073890686}
{"mode": "train", "epochs": 10, "timestep": 18658, "ep_reward": 373.0159912109375, "reward": 0.8360347747802734, "action": -1.3433629274368286}
{"mode": "train", "epochs": 10, "timestep": 18659, "ep_reward": 373.79437255859375, "reward": 0.7783918380737305, "action": -1.3770806789398193}
{"mode": "train", "epochs": 10, "timestep": 18660, "ep_reward": 374.48443603515625, "reward": 0.690069854259491, "action": -0.648352861404419}
{"mode": "train", "epochs": 10, "timestep": 18661, "ep_reward": 375.0582275390625, "reward": 0.5737775564193726, "action": -1.8617030382156372}
{"mode": "train", "epochs": 10, "timestep": 18662, "ep_reward": 375.45684814453125, "reward": 0.39860785007476807, "action": -0.30074840784072876}
{"mode": "train", "epochs": 10, "timestep": 18663, "ep_reward": 375.748291015625, "reward": 0.2914329171180725, "action": -1.3435627222061157}
{"mode": "train", "epochs": 10, "timestep": 18664, "ep_reward": 375.918701171875, "reward": 0.17040801048278809, "action": -0.9989032745361328}
{"mode": "train", "epochs": 10, "timestep": 18665, "ep_reward": 375.9480895996094, "reward": 0.029384613037109375, "action": -0.4209635257720947}
{"mode": "train", "epochs": 10, "timestep": 18666, "ep_reward": 376.03619384765625, "reward": 0.08809411525726318, "action": -1.1878854036331177}
{"mode": "train", "epochs": 10, "timestep": 18667, "ep_reward": 376.2599182128906, "reward": 0.2237154245376587, "action": -0.039201319217681885}
{"mode": "train", "epochs": 10, "timestep": 18668, "ep_reward": 376.63525390625, "reward": 0.3753300905227661, "action": -1.2520405054092407}
{"mode": "train", "epochs": 10, "timestep": 18669, "ep_reward": 377.13702392578125, "reward": 0.5017701387405396, "action": -0.22761034965515137}
{"mode": "train", "epochs": 10, "timestep": 18670, "ep_reward": 377.76019287109375, "reward": 0.6231653094291687, "action": -1.1159409284591675}
{"mode": "train", "epochs": 10, "timestep": 18671, "ep_reward": 378.47271728515625, "reward": 0.7125118374824524, "action": -0.8542506098747253}
{"mode": "train", "epochs": 10, "timestep": 18672, "ep_reward": 379.2555236816406, "reward": 0.7828177213668823, "action": -1.1440443992614746}
{"mode": "train", "epochs": 10, "timestep": 18673, "ep_reward": 380.0859069824219, "reward": 0.8303956985473633, "action": -1.8463622331619263}
{"mode": "train", "epochs": 10, "timestep": 18674, "ep_reward": 380.9410705566406, "reward": 0.8551537394523621, "action": -1.2586078643798828}
{"mode": "train", "epochs": 10, "timestep": 18675, "ep_reward": 381.8100891113281, "reward": 0.8690185546875, "action": -1.4023634195327759}
{"mode": "train", "epochs": 10, "timestep": 18676, "ep_reward": 382.6758117675781, "reward": 0.8657169938087463, "action": -1.899887204170227}
{"mode": "train", "epochs": 10, "timestep": 18677, "ep_reward": 383.51617431640625, "reward": 0.8403635025024414, "action": -0.6079303026199341}
{"mode": "train", "epochs": 10, "timestep": 18678, "ep_reward": 384.3215026855469, "reward": 0.8053181171417236, "action": -1.2312835454940796}
{"mode": "train", "epochs": 10, "timestep": 18679, "ep_reward": 385.0592041015625, "reward": 0.7377148866653442, "action": -1.329527497291565}
{"mode": "train", "epochs": 10, "timestep": 18680, "ep_reward": 385.69384765625, "reward": 0.6346477270126343, "action": -1.0372155904769897}
{"mode": "train", "epochs": 10, "timestep": 18681, "ep_reward": 386.1882019042969, "reward": 0.4943498373031616, "action": -0.4093208909034729}
{"mode": "train", "epochs": 10, "timestep": 18682, "ep_reward": 386.5447692871094, "reward": 0.35656243562698364, "action": -1.4274358749389648}
{"mode": "train", "epochs": 10, "timestep": 18683, "ep_reward": 386.79278564453125, "reward": 0.24802041053771973, "action": -0.5405197143554688}
{"mode": "train", "epochs": 10, "timestep": 18684, "ep_reward": 386.912109375, "reward": 0.11932706832885742, "action": -0.9884129762649536}
{"mode": "train", "epochs": 10, "timestep": 18685, "ep_reward": 386.90753173828125, "reward": -0.004564642906188965, "action": -0.19117707014083862}
{"mode": "train", "epochs": 10, "timestep": 18686, "ep_reward": 387.0484313964844, "reward": 0.1409028172492981, "action": -0.7999812960624695}
{"mode": "train", "epochs": 10, "timestep": 18687, "ep_reward": 387.3312072753906, "reward": 0.28276264667510986, "action": -0.5054134130477905}
{"mode": "train", "epochs": 10, "timestep": 18688, "ep_reward": 387.7565612792969, "reward": 0.42536163330078125, "action": -1.4458870887756348}
{"mode": "train", "epochs": 10, "timestep": 18689, "ep_reward": 388.30084228515625, "reward": 0.5442860126495361, "action": -0.20506012439727783}
{"mode": "train", "epochs": 10, "timestep": 18690, "ep_reward": 388.95928955078125, "reward": 0.658461332321167, "action": -0.8295280933380127}
{"mode": "train", "epochs": 10, "timestep": 18691, "ep_reward": 389.7016296386719, "reward": 0.7423404455184937, "action": -1.6978055238723755}
{"mode": "train", "epochs": 10, "timestep": 18692, "ep_reward": 390.49884033203125, "reward": 0.797220766544342, "action": -0.9742772579193115}
{"mode": "train", "epochs": 10, "timestep": 18693, "ep_reward": 391.3387145996094, "reward": 0.8398603200912476, "action": -1.3506214618682861}
{"mode": "train", "epochs": 10, "timestep": 18694, "ep_reward": 392.2007751464844, "reward": 0.8620555996894836, "action": -1.9406545162200928}
{"mode": "train", "epochs": 10, "timestep": 18695, "ep_reward": 393.0644226074219, "reward": 0.8636611104011536, "action": -0.6114521622657776}
{"mode": "train", "epochs": 10, "timestep": 18696, "ep_reward": 393.9242248535156, "reward": 0.8597889542579651, "action": -0.6389646530151367}
{"mode": "train", "epochs": 10, "timestep": 18697, "ep_reward": 394.76177978515625, "reward": 0.8375557661056519, "action": -0.03562384843826294}
{"mode": "train", "epochs": 10, "timestep": 18698, "ep_reward": 395.56201171875, "reward": 0.8002245426177979, "action": -0.3708578944206238}
{"mode": "train", "epochs": 10, "timestep": 18699, "ep_reward": 396.29656982421875, "reward": 0.7345625162124634, "action": -1.3705729246139526}
{"mode": "train", "epochs": 10, "timestep": 18700, "ep_reward": 396.9214782714844, "reward": 0.6249186992645264, "action": -0.2739575505256653}
{"mode": "train", "epochs": 10, "timestep": 18701, "ep_reward": 397.41217041015625, "reward": 0.49069851636886597, "action": -1.5178852081298828}
{"mode": "train", "epochs": 10, "timestep": 18702, "ep_reward": 397.7469482421875, "reward": 0.3347868323326111, "action": -0.815569281578064}
{"mode": "train", "epochs": 10, "timestep": 18703, "ep_reward": 397.9686279296875, "reward": 0.22166931629180908, "action": -1.6554827690124512}
{"mode": "train", "epochs": 10, "timestep": 18704, "ep_reward": 398.0572509765625, "reward": 0.08861780166625977, "action": -1.9418138265609741}
{"mode": "train", "epochs": 10, "timestep": 18705, "ep_reward": 398.0859069824219, "reward": 0.028651535511016846, "action": -0.7496570348739624}
{"mode": "train", "epochs": 10, "timestep": 18706, "ep_reward": 398.2557067871094, "reward": 0.1697930097579956, "action": -0.9970885515213013}
{"mode": "train", "epochs": 10, "timestep": 18707, "ep_reward": 398.56549072265625, "reward": 0.30976974964141846, "action": -0.8657135367393494}
{"mode": "train", "epochs": 10, "timestep": 18708, "ep_reward": 399.01251220703125, "reward": 0.4470338225364685, "action": -1.2186511754989624}
{"mode": "train", "epochs": 10, "timestep": 18709, "ep_reward": 399.57867431640625, "reward": 0.5661509037017822, "action": -1.1484657526016235}
{"mode": "train", "epochs": 10, "timestep": 18710, "ep_reward": 400.2449951171875, "reward": 0.6663259267807007, "action": -0.9930139780044556}
{"mode": "train", "epochs": 10, "timestep": 18711, "ep_reward": 400.9905700683594, "reward": 0.7455817461013794, "action": -0.49456787109375}
{"mode": "train", "epochs": 10, "timestep": 18712, "ep_reward": 401.79754638671875, "reward": 0.8069850206375122, "action": -1.6717002391815186}
{"mode": "train", "epochs": 10, "timestep": 18713, "ep_reward": 402.6355895996094, "reward": 0.838034451007843, "action": -1.0641978979110718}
{"mode": "train", "epochs": 10, "timestep": 18714, "ep_reward": 403.49249267578125, "reward": 0.8569038510322571, "action": -0.9331103563308716}
{"mode": "train", "epochs": 10, "timestep": 18715, "ep_reward": 404.352294921875, "reward": 0.8597877025604248, "action": -0.4607875347137451}
{"mode": "train", "epochs": 10, "timestep": 18716, "ep_reward": 405.2014465332031, "reward": 0.8491509556770325, "action": -0.07854586839675903}
{"mode": "train", "epochs": 10, "timestep": 18717, "ep_reward": 406.0242004394531, "reward": 0.822748064994812, "action": -0.9573467373847961}
{"mode": "train", "epochs": 10, "timestep": 18718, "ep_reward": 406.78863525390625, "reward": 0.7644346952438354, "action": -1.4769458770751953}
{"mode": "train", "epochs": 10, "timestep": 18719, "ep_reward": 407.45751953125, "reward": 0.6688860654830933, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 18720, "ep_reward": 407.9831237792969, "reward": 0.5255976319313049, "action": -1.1840482950210571}
{"mode": "train", "epochs": 10, "timestep": 18721, "ep_reward": 408.3588562011719, "reward": 0.3757343292236328, "action": -0.6360491514205933}
{"mode": "train", "epochs": 10, "timestep": 18722, "ep_reward": 408.6299133300781, "reward": 0.2710508704185486, "action": -0.19744545221328735}
{"mode": "train", "epochs": 10, "timestep": 18723, "ep_reward": 408.7762145996094, "reward": 0.14629387855529785, "action": -0.9274811744689941}
{"mode": "train", "epochs": 10, "timestep": 18724, "ep_reward": 408.7777404785156, "reward": 0.001517176628112793, "action": -1.416621208190918}
{"mode": "train", "epochs": 10, "timestep": 18725, "ep_reward": 408.8914794921875, "reward": 0.11373847723007202, "action": -1.17904794216156}
{"mode": "train", "epochs": 10, "timestep": 18726, "ep_reward": 409.1416320800781, "reward": 0.2501598000526428, "action": -0.9634063243865967}
{"mode": "train", "epochs": 10, "timestep": 18727, "ep_reward": 409.5312805175781, "reward": 0.3896383047103882, "action": 0.14008855819702148}
{"mode": "train", "epochs": 10, "timestep": 18728, "ep_reward": 410.0626525878906, "reward": 0.5313687324523926, "action": -1.3968608379364014}
{"mode": "train", "epochs": 10, "timestep": 18729, "ep_reward": 410.6980285644531, "reward": 0.6353708505630493, "action": -1.301444411277771}
{"mode": "train", "epochs": 10, "timestep": 18730, "ep_reward": 411.4178771972656, "reward": 0.7198634147644043, "action": -1.0328609943389893}
{"mode": "train", "epochs": 10, "timestep": 18731, "ep_reward": 412.2033996582031, "reward": 0.7855138182640076, "action": -0.025543212890625}
{"mode": "train", "epochs": 10, "timestep": 18732, "ep_reward": 413.0427551269531, "reward": 0.8393490314483643, "action": -1.0128436088562012}
{"mode": "train", "epochs": 10, "timestep": 18733, "ep_reward": 413.9093017578125, "reward": 0.8665386438369751, "action": -1.3629748821258545}
{"mode": "train", "epochs": 10, "timestep": 18734, "ep_reward": 414.7850341796875, "reward": 0.8757288455963135, "action": -0.2715153098106384}
{"mode": "train", "epochs": 10, "timestep": 18735, "ep_reward": 415.6637268066406, "reward": 0.8787055015563965, "action": -0.8518954515457153}
{"mode": "train", "epochs": 10, "timestep": 18736, "ep_reward": 416.52471923828125, "reward": 0.8609974980354309, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 18737, "ep_reward": 417.3380432128906, "reward": 0.813317596912384, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 18738, "ep_reward": 418.07562255859375, "reward": 0.7375817894935608, "action": -1.3366243839263916}
{"mode": "train", "epochs": 10, "timestep": 18739, "ep_reward": 418.70928955078125, "reward": 0.6336532831192017, "action": -1.1482813358306885}
{"mode": "train", "epochs": 10, "timestep": 18740, "ep_reward": 419.2001953125, "reward": 0.490894079208374, "action": -1.160240650177002}
{"mode": "train", "epochs": 10, "timestep": 18741, "ep_reward": 419.5538330078125, "reward": 0.3536376357078552, "action": -0.817439079284668}
{"mode": "train", "epochs": 10, "timestep": 18742, "ep_reward": 419.798095703125, "reward": 0.24425196647644043, "action": -1.638714075088501}
{"mode": "train", "epochs": 10, "timestep": 18743, "ep_reward": 419.91326904296875, "reward": 0.11515957117080688, "action": 0.14086079597473145}
{"mode": "train", "epochs": 10, "timestep": 18744, "ep_reward": 419.91339111328125, "reward": 0.00012814998626708984, "action": -0.7031663060188293}
{"mode": "train", "epochs": 10, "timestep": 18745, "ep_reward": 420.0582580566406, "reward": 0.1448761224746704, "action": -1.6954717636108398}
{"mode": "train", "epochs": 10, "timestep": 18746, "ep_reward": 420.333984375, "reward": 0.2757134437561035, "action": 0.01687002182006836}
{"mode": "train", "epochs": 10, "timestep": 18747, "ep_reward": 420.7607421875, "reward": 0.42676037549972534, "action": -1.590362548828125}
{"mode": "train", "epochs": 10, "timestep": 18748, "ep_reward": 421.3049621582031, "reward": 0.5442215204238892, "action": -0.19389522075653076}
{"mode": "train", "epochs": 10, "timestep": 18749, "ep_reward": 421.9635009765625, "reward": 0.658545970916748, "action": -1.15535569190979}
{"mode": "train", "epochs": 10, "timestep": 18750, "ep_reward": 422.70245361328125, "reward": 0.7389483451843262, "action": -0.9741321802139282}
{"mode": "train", "epochs": 10, "timestep": 18751, "ep_reward": 423.5020446777344, "reward": 0.7995898723602295, "action": -0.11026936769485474}
{"mode": "train", "epochs": 10, "timestep": 18752, "ep_reward": 424.3497009277344, "reward": 0.8476440906524658, "action": -1.0147875547409058}
{"mode": "train", "epochs": 10, "timestep": 18753, "ep_reward": 425.22027587890625, "reward": 0.8705868721008301, "action": -1.048261046409607}
{"mode": "train", "epochs": 10, "timestep": 18754, "ep_reward": 426.09844970703125, "reward": 0.8781604766845703, "action": -0.6837259531021118}
{"mode": "train", "epochs": 10, "timestep": 18755, "ep_reward": 426.971923828125, "reward": 0.8734661936759949, "action": -1.455935001373291}
{"mode": "train", "epochs": 10, "timestep": 18756, "ep_reward": 427.81732177734375, "reward": 0.8453925251960754, "action": 0.2735077142715454}
{"mode": "train", "epochs": 10, "timestep": 18757, "ep_reward": 428.6303405761719, "reward": 0.813027024269104, "action": -0.32365310192108154}
{"mode": "train", "epochs": 10, "timestep": 18758, "ep_reward": 429.3819885253906, "reward": 0.7516345977783203, "action": -1.3656337261199951}
{"mode": "train", "epochs": 10, "timestep": 18759, "ep_reward": 430.0298156738281, "reward": 0.6478313207626343, "action": -0.7198026180267334}
{"mode": "train", "epochs": 10, "timestep": 18760, "ep_reward": 430.54364013671875, "reward": 0.5138192772865295, "action": -0.5064257383346558}
{"mode": "train", "epochs": 10, "timestep": 18761, "ep_reward": 430.890380859375, "reward": 0.34675514698028564, "action": -0.22604912519454956}
{"mode": "train", "epochs": 10, "timestep": 18762, "ep_reward": 431.1264953613281, "reward": 0.23610800504684448, "action": -0.3066573739051819}
{"mode": "train", "epochs": 10, "timestep": 18763, "ep_reward": 431.23193359375, "reward": 0.10543715953826904, "action": -0.7264262437820435}
{"mode": "train", "epochs": 10, "timestep": 18764, "ep_reward": 431.24273681640625, "reward": 0.010796666145324707, "action": -0.8004798889160156}
{"mode": "train", "epochs": 10, "timestep": 18765, "ep_reward": 431.39703369140625, "reward": 0.1542823314666748, "action": -1.029587984085083}
{"mode": "train", "epochs": 10, "timestep": 18766, "ep_reward": 431.6904296875, "reward": 0.29340994358062744, "action": -1.7990870475769043}
{"mode": "train", "epochs": 10, "timestep": 18767, "ep_reward": 432.1109313964844, "reward": 0.4205080270767212, "action": -0.7385746240615845}
{"mode": "train", "epochs": 10, "timestep": 18768, "ep_reward": 432.6601257324219, "reward": 0.5492008328437805, "action": -1.2773414850234985}
{"mode": "train", "epochs": 10, "timestep": 18769, "ep_reward": 433.31121826171875, "reward": 0.6510883569717407, "action": -1.4630556106567383}
{"mode": "train", "epochs": 10, "timestep": 18770, "ep_reward": 434.03985595703125, "reward": 0.7286353707313538, "action": -1.421098232269287}
{"mode": "train", "epochs": 10, "timestep": 18771, "ep_reward": 434.8243408203125, "reward": 0.7844942808151245, "action": 0.09909307956695557}
{"mode": "train", "epochs": 10, "timestep": 18772, "ep_reward": 435.6574401855469, "reward": 0.833102822303772, "action": -0.8114321231842041}
{"mode": "train", "epochs": 10, "timestep": 18773, "ep_reward": 436.510986328125, "reward": 0.8535310626029968, "action": -1.5189580917358398}
{"mode": "train", "epochs": 10, "timestep": 18774, "ep_reward": 437.36090087890625, "reward": 0.8499019742012024, "action": -1.385352373123169}
{"mode": "train", "epochs": 10, "timestep": 18775, "ep_reward": 438.1888732910156, "reward": 0.8279595375061035, "action": -0.5121487379074097}
{"mode": "train", "epochs": 10, "timestep": 18776, "ep_reward": 438.98046875, "reward": 0.7916027307510376, "action": -1.5792944431304932}
{"mode": "train", "epochs": 10, "timestep": 18777, "ep_reward": 439.6962585449219, "reward": 0.7157750129699707, "action": -1.3163529634475708}
{"mode": "train", "epochs": 10, "timestep": 18778, "ep_reward": 440.3022155761719, "reward": 0.605955958366394, "action": -0.622991144657135}
{"mode": "train", "epochs": 10, "timestep": 18779, "ep_reward": 440.7657775878906, "reward": 0.4635537266731262, "action": -0.4200482964515686}
{"mode": "train", "epochs": 10, "timestep": 18780, "ep_reward": 441.10870361328125, "reward": 0.34292072057724, "action": -1.3075587749481201}
{"mode": "train", "epochs": 10, "timestep": 18781, "ep_reward": 441.34027099609375, "reward": 0.23156636953353882, "action": -1.1187273263931274}
{"mode": "train", "epochs": 10, "timestep": 18782, "ep_reward": 441.4403076171875, "reward": 0.10005027055740356, "action": -1.841353178024292}
{"mode": "train", "epochs": 10, "timestep": 18783, "ep_reward": 441.4567565917969, "reward": 0.01644444465637207, "action": -0.8786424994468689}
{"mode": "train", "epochs": 10, "timestep": 18784, "ep_reward": 441.6158447265625, "reward": 0.15907371044158936, "action": -1.7539101839065552}
{"mode": "train", "epochs": 10, "timestep": 18785, "ep_reward": 441.9053039550781, "reward": 0.28945738077163696, "action": -0.7142965793609619}
{"mode": "train", "epochs": 10, "timestep": 18786, "ep_reward": 442.3364562988281, "reward": 0.4311475157737732, "action": -0.9588536620140076}
{"mode": "train", "epochs": 10, "timestep": 18787, "ep_reward": 442.8922119140625, "reward": 0.5557498931884766, "action": -0.8382057547569275}
{"mode": "train", "epochs": 10, "timestep": 18788, "ep_reward": 443.5533752441406, "reward": 0.661148190498352, "action": -0.5469446182250977}
{"mode": "train", "epochs": 10, "timestep": 18789, "ep_reward": 444.2992248535156, "reward": 0.745862603187561, "action": -0.8523815870285034}
{"mode": "train", "epochs": 10, "timestep": 18790, "ep_reward": 445.1039733886719, "reward": 0.8047374486923218, "action": -0.8183670043945312}
{"mode": "train", "epochs": 10, "timestep": 18791, "ep_reward": 445.947998046875, "reward": 0.8440355658531189, "action": -0.7417960166931152}
{"mode": "train", "epochs": 10, "timestep": 18792, "ep_reward": 446.814453125, "reward": 0.866447925567627, "action": -1.0564202070236206}
{"mode": "train", "epochs": 10, "timestep": 18793, "ep_reward": 447.68463134765625, "reward": 0.8701920509338379, "action": -1.11118483543396}
{"mode": "train", "epochs": 10, "timestep": 18794, "ep_reward": 448.5415954589844, "reward": 0.8569679260253906, "action": -0.6814407110214233}
{"mode": "train", "epochs": 10, "timestep": 18795, "ep_reward": 449.3702697753906, "reward": 0.8286686539649963, "action": -0.660205602645874}
{"mode": "train", "epochs": 10, "timestep": 18796, "ep_reward": 450.14813232421875, "reward": 0.7778677344322205, "action": -1.262798547744751}
{"mode": "train", "epochs": 10, "timestep": 18797, "ep_reward": 450.8394775390625, "reward": 0.691351592540741, "action": -1.4232310056686401}
{"mode": "train", "epochs": 10, "timestep": 18798, "ep_reward": 451.40435791015625, "reward": 0.5648893117904663, "action": -1.333797812461853}
{"mode": "train", "epochs": 10, "timestep": 18799, "ep_reward": 451.80029296875, "reward": 0.3959352970123291, "action": -1.133082628250122}
{"mode": "train", "epochs": 10, "timestep": 18800, "ep_reward": 452.092529296875, "reward": 0.29223644733428955, "action": -1.1283609867095947}
{"mode": "train", "epochs": 10, "timestep": 18801, "ep_reward": 452.2637939453125, "reward": 0.17126399278640747, "action": -1.3592561483383179}
{"mode": "train", "epochs": 10, "timestep": 18802, "ep_reward": 452.294189453125, "reward": 0.030408501625061035, "action": -0.7487796545028687}
{"mode": "train", "epochs": 10, "timestep": 18803, "ep_reward": 452.38134765625, "reward": 0.08717173337936401, "action": -0.5251806974411011}
{"mode": "train", "epochs": 10, "timestep": 18804, "ep_reward": 452.61224365234375, "reward": 0.23090589046478271, "action": -1.2558237314224243}
{"mode": "train", "epochs": 10, "timestep": 18805, "ep_reward": 452.9783020019531, "reward": 0.36604881286621094, "action": -1.2717676162719727}
{"mode": "train", "epochs": 10, "timestep": 18806, "ep_reward": 453.47210693359375, "reward": 0.4937925934791565, "action": -0.3917192220687866}
{"mode": "train", "epochs": 10, "timestep": 18807, "ep_reward": 454.0871887207031, "reward": 0.6150846481323242, "action": -0.6942180395126343}
{"mode": "train", "epochs": 10, "timestep": 18808, "ep_reward": 454.7970886230469, "reward": 0.709912896156311, "action": -0.8910674452781677}
{"mode": "train", "epochs": 10, "timestep": 18809, "ep_reward": 455.5771484375, "reward": 0.7800491452217102, "action": -1.068097710609436}
{"mode": "train", "epochs": 10, "timestep": 18810, "ep_reward": 456.4053649902344, "reward": 0.8282232880592346, "action": -0.8950943946838379}
{"mode": "train", "epochs": 10, "timestep": 18811, "ep_reward": 457.26519775390625, "reward": 0.8598325252532959, "action": -1.9917714595794678}
{"mode": "train", "epochs": 10, "timestep": 18812, "ep_reward": 458.13189697265625, "reward": 0.8666881918907166, "action": -1.4904056787490845}
{"mode": "train", "epochs": 10, "timestep": 18813, "ep_reward": 458.9933166503906, "reward": 0.8614319562911987, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 18814, "ep_reward": 459.8265075683594, "reward": 0.8331859707832336, "action": -0.8416500091552734}
{"mode": "train", "epochs": 10, "timestep": 18815, "ep_reward": 460.6195068359375, "reward": 0.7929946184158325, "action": -0.5917409658432007}
{"mode": "train", "epochs": 10, "timestep": 18816, "ep_reward": 461.3477783203125, "reward": 0.7282834053039551, "action": -1.746986746788025}
{"mode": "train", "epochs": 10, "timestep": 18817, "ep_reward": 461.96307373046875, "reward": 0.6152987480163574, "action": -0.6802957057952881}
{"mode": "train", "epochs": 10, "timestep": 18818, "ep_reward": 462.437255859375, "reward": 0.4741860628128052, "action": -1.1934473514556885}
{"mode": "train", "epochs": 10, "timestep": 18819, "ep_reward": 462.7818298339844, "reward": 0.34458428621292114, "action": -1.303910493850708}
{"mode": "train", "epochs": 10, "timestep": 18820, "ep_reward": 463.01544189453125, "reward": 0.23361825942993164, "action": -0.534947395324707}
{"mode": "train", "epochs": 10, "timestep": 18821, "ep_reward": 463.11798095703125, "reward": 0.1025272011756897, "action": -0.9390503168106079}
{"mode": "train", "epochs": 10, "timestep": 18822, "ep_reward": 463.1319274902344, "reward": 0.013934612274169922, "action": -0.85222327709198}
{"mode": "train", "epochs": 10, "timestep": 18823, "ep_reward": 463.2889709472656, "reward": 0.15703868865966797, "action": -0.8310056328773499}
{"mode": "train", "epochs": 10, "timestep": 18824, "ep_reward": 463.58782958984375, "reward": 0.2988726496696472, "action": -0.2947574853897095}
{"mode": "train", "epochs": 10, "timestep": 18825, "ep_reward": 464.03094482421875, "reward": 0.44311630725860596, "action": -1.6843583583831787}
{"mode": "train", "epochs": 10, "timestep": 18826, "ep_reward": 464.58782958984375, "reward": 0.5568854808807373, "action": -1.9656932353973389}
{"mode": "train", "epochs": 10, "timestep": 18827, "ep_reward": 465.2381896972656, "reward": 0.6503738164901733, "action": -1.2096372842788696}
{"mode": "train", "epochs": 10, "timestep": 18828, "ep_reward": 465.9691162109375, "reward": 0.7309376001358032, "action": -1.3737605810165405}
{"mode": "train", "epochs": 10, "timestep": 18829, "ep_reward": 466.7568054199219, "reward": 0.7876983880996704, "action": -0.5525026917457581}
{"mode": "train", "epochs": 10, "timestep": 18830, "ep_reward": 467.5880432128906, "reward": 0.8312263488769531, "action": -0.7818193435668945}
{"mode": "train", "epochs": 10, "timestep": 18831, "ep_reward": 468.44146728515625, "reward": 0.8534374237060547, "action": -0.792481005191803}
{"mode": "train", "epochs": 10, "timestep": 18832, "ep_reward": 469.29931640625, "reward": 0.8578360080718994, "action": -1.1765795946121216}
{"mode": "train", "epochs": 10, "timestep": 18833, "ep_reward": 470.139892578125, "reward": 0.8405867218971252, "action": -0.8448089361190796}
{"mode": "train", "epochs": 10, "timestep": 18834, "ep_reward": 470.945068359375, "reward": 0.8051730990409851, "action": 0.7884680032730103}
{"mode": "train", "epochs": 10, "timestep": 18835, "ep_reward": 471.7076110839844, "reward": 0.7625443339347839, "action": -1.1999183893203735}
{"mode": "train", "epochs": 10, "timestep": 18836, "ep_reward": 472.3769226074219, "reward": 0.6693204641342163, "action": -0.4182639718055725}
{"mode": "train", "epochs": 10, "timestep": 18837, "ep_reward": 472.9257507324219, "reward": 0.5488161444664001, "action": -0.7811151146888733}
{"mode": "train", "epochs": 10, "timestep": 18838, "ep_reward": 473.3096618652344, "reward": 0.3839104175567627, "action": -1.0860190391540527}
{"mode": "train", "epochs": 10, "timestep": 18839, "ep_reward": 473.5811462402344, "reward": 0.2714954614639282, "action": -1.1526319980621338}
{"mode": "train", "epochs": 10, "timestep": 18840, "ep_reward": 473.72808837890625, "reward": 0.14694178104400635, "action": -0.6023809909820557}
{"mode": "train", "epochs": 10, "timestep": 18841, "ep_reward": 473.7303466796875, "reward": 0.0022712349891662598, "action": -1.1290392875671387}
{"mode": "train", "epochs": 10, "timestep": 18842, "ep_reward": 473.8435363769531, "reward": 0.11318624019622803, "action": -0.06255567073822021}
{"mode": "train", "epochs": 10, "timestep": 18843, "ep_reward": 474.1069641113281, "reward": 0.2634321451187134, "action": -0.6113152503967285}
{"mode": "train", "epochs": 10, "timestep": 18844, "ep_reward": 474.5111389160156, "reward": 0.40417563915252686, "action": -0.9270772933959961}
{"mode": "train", "epochs": 10, "timestep": 18845, "ep_reward": 475.0417175292969, "reward": 0.5305866599082947, "action": 0.11569702625274658}
{"mode": "train", "epochs": 10, "timestep": 18846, "ep_reward": 475.69171142578125, "reward": 0.6499937772750854, "action": -1.518524408340454}
{"mode": "train", "epochs": 10, "timestep": 18847, "ep_reward": 476.42218017578125, "reward": 0.7304593920707703, "action": -0.9613122344017029}
{"mode": "train", "epochs": 10, "timestep": 18848, "ep_reward": 477.2185974121094, "reward": 0.7964060306549072, "action": -0.8700858354568481}
{"mode": "train", "epochs": 10, "timestep": 18849, "ep_reward": 478.0627746582031, "reward": 0.844169020652771, "action": -1.4865493774414062}
{"mode": "train", "epochs": 10, "timestep": 18850, "ep_reward": 478.9338684082031, "reward": 0.8710975646972656, "action": -0.8928040266036987}
{"mode": "train", "epochs": 10, "timestep": 18851, "ep_reward": 479.82232666015625, "reward": 0.8884711861610413, "action": -1.4363192319869995}
{"mode": "train", "epochs": 10, "timestep": 18852, "ep_reward": 480.7107238769531, "reward": 0.8884058594703674, "action": -0.8187652826309204}
{"mode": "train", "epochs": 10, "timestep": 18853, "ep_reward": 481.5897216796875, "reward": 0.8790034055709839, "action": -0.6804003715515137}
{"mode": "train", "epochs": 10, "timestep": 18854, "ep_reward": 482.44451904296875, "reward": 0.8548063039779663, "action": -0.2579692006111145}
{"mode": "train", "epochs": 10, "timestep": 18855, "ep_reward": 483.2598876953125, "reward": 0.8153642416000366, "action": -0.7673501372337341}
{"mode": "train", "epochs": 10, "timestep": 18856, "ep_reward": 484.007080078125, "reward": 0.7471795082092285, "action": -0.5459863543510437}
{"mode": "train", "epochs": 10, "timestep": 18857, "ep_reward": 484.6581115722656, "reward": 0.6510363817214966, "action": -0.22464972734451294}
{"mode": "train", "epochs": 10, "timestep": 18858, "ep_reward": 485.1824035644531, "reward": 0.5242840051651001, "action": -0.5171992778778076}
{"mode": "train", "epochs": 10, "timestep": 18859, "ep_reward": 485.5400085449219, "reward": 0.3575921654701233, "action": -0.6607141494750977}
{"mode": "train", "epochs": 10, "timestep": 18860, "ep_reward": 485.77099609375, "reward": 0.23098701238632202, "action": -0.7853097915649414}
{"mode": "train", "epochs": 10, "timestep": 18861, "ep_reward": 485.8704833984375, "reward": 0.09948879480361938, "action": -0.9158057570457458}
{"mode": "train", "epochs": 10, "timestep": 18862, "ep_reward": 485.88751220703125, "reward": 0.01703941822052002, "action": -1.9255099296569824}
{"mode": "train", "epochs": 10, "timestep": 18863, "ep_reward": 486.0473327636719, "reward": 0.1598178744316101, "action": -1.4121824502944946}
{"mode": "train", "epochs": 10, "timestep": 18864, "ep_reward": 486.3417663574219, "reward": 0.29443633556365967, "action": -1.0951489210128784}
{"mode": "train", "epochs": 10, "timestep": 18865, "ep_reward": 486.7724304199219, "reward": 0.430669367313385, "action": -0.33155912160873413}
{"mode": "train", "epochs": 10, "timestep": 18866, "ep_reward": 487.3348693847656, "reward": 0.562450647354126, "action": -0.6402451992034912}
{"mode": "train", "epochs": 10, "timestep": 18867, "ep_reward": 488.00341796875, "reward": 0.668533980846405, "action": -1.6638364791870117}
{"mode": "train", "epochs": 10, "timestep": 18868, "ep_reward": 488.7449951171875, "reward": 0.7415894269943237, "action": -1.0551313161849976}
{"mode": "train", "epochs": 10, "timestep": 18869, "ep_reward": 489.54461669921875, "reward": 0.7996296286582947, "action": -0.6825914978981018}
{"mode": "train", "epochs": 10, "timestep": 18870, "ep_reward": 490.38555908203125, "reward": 0.8409308791160583, "action": -0.7054046392440796}
{"mode": "train", "epochs": 10, "timestep": 18871, "ep_reward": 491.24957275390625, "reward": 0.8640020489692688, "action": -1.0993307828903198}
{"mode": "train", "epochs": 10, "timestep": 18872, "ep_reward": 492.11688232421875, "reward": 0.8672947883605957, "action": -1.7173206806182861}
{"mode": "train", "epochs": 10, "timestep": 18873, "ep_reward": 492.965087890625, "reward": 0.848207950592041, "action": -0.8041711449623108}
{"mode": "train", "epochs": 10, "timestep": 18874, "ep_reward": 493.7820739746094, "reward": 0.8169730305671692, "action": -0.8885147571563721}
{"mode": "train", "epochs": 10, "timestep": 18875, "ep_reward": 494.5425109863281, "reward": 0.7604328989982605, "action": -0.90058434009552}
{"mode": "train", "epochs": 10, "timestep": 18876, "ep_reward": 495.21539306640625, "reward": 0.6728857755661011, "action": -1.069144368171692}
{"mode": "train", "epochs": 10, "timestep": 18877, "ep_reward": 495.7606201171875, "reward": 0.5452244281768799, "action": -1.561227560043335}
{"mode": "train", "epochs": 10, "timestep": 18878, "ep_reward": 496.143310546875, "reward": 0.3826761841773987, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 18879, "ep_reward": 496.42303466796875, "reward": 0.27973031997680664, "action": -0.4945492744445801}
{"mode": "train", "epochs": 10, "timestep": 18880, "ep_reward": 496.5794372558594, "reward": 0.1563909649848938, "action": -1.6714210510253906}
{"mode": "train", "epochs": 10, "timestep": 18881, "ep_reward": 496.5927734375, "reward": 0.013330996036529541, "action": -0.9393301606178284}
{"mode": "train", "epochs": 10, "timestep": 18882, "ep_reward": 496.6958312988281, "reward": 0.10307210683822632, "action": -0.9551156163215637}
{"mode": "train", "epochs": 10, "timestep": 18883, "ep_reward": 496.9378356933594, "reward": 0.24200934171676636, "action": -0.6853154897689819}
{"mode": "train", "epochs": 10, "timestep": 18884, "ep_reward": 497.322509765625, "reward": 0.3846815824508667, "action": -0.5921862721443176}
{"mode": "train", "epochs": 10, "timestep": 18885, "ep_reward": 497.84063720703125, "reward": 0.5181236267089844, "action": -0.7600895166397095}
{"mode": "train", "epochs": 10, "timestep": 18886, "ep_reward": 498.4718017578125, "reward": 0.6311571598052979, "action": 0.1149362325668335}
{"mode": "train", "epochs": 10, "timestep": 18887, "ep_reward": 499.2020568847656, "reward": 0.7302650213241577, "action": -1.4507441520690918}
{"mode": "train", "epochs": 10, "timestep": 18888, "ep_reward": 499.9939270019531, "reward": 0.7918685674667358, "action": -0.33821403980255127}
{"mode": "train", "epochs": 10, "timestep": 18889, "ep_reward": 500.8380126953125, "reward": 0.8440994024276733, "action": -1.2258855104446411}
{"mode": "train", "epochs": 10, "timestep": 18890, "ep_reward": 501.7103271484375, "reward": 0.8723024725914001, "action": -0.7377182841300964}
{"mode": "train", "epochs": 10, "timestep": 18891, "ep_reward": 502.60028076171875, "reward": 0.8899561762809753, "action": -1.471380352973938}
{"mode": "train", "epochs": 10, "timestep": 18892, "ep_reward": 503.4891052246094, "reward": 0.8888260722160339, "action": -0.5838937163352966}
{"mode": "train", "epochs": 10, "timestep": 18893, "ep_reward": 504.3696594238281, "reward": 0.8805533647537231, "action": -0.25030601024627686}
{"mode": "train", "epochs": 10, "timestep": 18894, "ep_reward": 505.229248046875, "reward": 0.8595978617668152, "action": -0.524835467338562}
{"mode": "train", "epochs": 10, "timestep": 18895, "ep_reward": 506.0471496582031, "reward": 0.8179076910018921, "action": -0.3508210778236389}
{"mode": "train", "epochs": 10, "timestep": 18896, "ep_reward": 506.80181884765625, "reward": 0.7546796798706055, "action": -0.6435587406158447}
{"mode": "train", "epochs": 10, "timestep": 18897, "ep_reward": 507.46099853515625, "reward": 0.6591688394546509, "action": -0.6536617279052734}
{"mode": "train", "epochs": 10, "timestep": 18898, "ep_reward": 507.9894104003906, "reward": 0.5284009575843811, "action": 0.11142545938491821}
{"mode": "train", "epochs": 10, "timestep": 18899, "ep_reward": 508.3624267578125, "reward": 0.37300312519073486, "action": -1.0585923194885254}
{"mode": "train", "epochs": 10, "timestep": 18900, "ep_reward": 508.59759521484375, "reward": 0.2351609468460083, "action": -0.45760178565979004}
{"mode": "train", "epochs": 10, "timestep": 18901, "ep_reward": 508.70196533203125, "reward": 0.10436248779296875, "action": -0.4386826753616333}
{"mode": "train", "epochs": 10, "timestep": 18902, "ep_reward": 508.7138977050781, "reward": 0.011941313743591309, "action": -1.1999870538711548}
{"mode": "train", "epochs": 10, "timestep": 18903, "ep_reward": 508.8690490722656, "reward": 0.1551375389099121, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 18904, "ep_reward": 509.1513366699219, "reward": 0.2822933793067932, "action": -1.2449203729629517}
{"mode": "train", "epochs": 10, "timestep": 18905, "ep_reward": 509.5697021484375, "reward": 0.4183797240257263, "action": -0.7445999979972839}
{"mode": "train", "epochs": 10, "timestep": 18906, "ep_reward": 510.1174011230469, "reward": 0.547695517539978, "action": -0.7697572708129883}
{"mode": "train", "epochs": 10, "timestep": 18907, "ep_reward": 510.7726745605469, "reward": 0.6552624702453613, "action": -0.40167462825775146}
{"mode": "train", "epochs": 10, "timestep": 18908, "ep_reward": 511.5148620605469, "reward": 0.7421950101852417, "action": -1.3578845262527466}
{"mode": "train", "epochs": 10, "timestep": 18909, "ep_reward": 512.3114624023438, "reward": 0.7966221570968628, "action": -0.7126391530036926}
{"mode": "train", "epochs": 10, "timestep": 18910, "ep_reward": 513.1482543945312, "reward": 0.8367667198181152, "action": -1.1285227537155151}
{"mode": "train", "epochs": 10, "timestep": 18911, "ep_reward": 514.0031127929688, "reward": 0.854832112789154, "action": -0.6175307035446167}
{"mode": "train", "epochs": 10, "timestep": 18912, "ep_reward": 514.8629150390625, "reward": 0.8597872853279114, "action": -1.8324637413024902}
{"mode": "train", "epochs": 10, "timestep": 18913, "ep_reward": 515.6986694335938, "reward": 0.8357363939285278, "action": -0.6098229885101318}
{"mode": "train", "epochs": 10, "timestep": 18914, "ep_reward": 516.4998168945312, "reward": 0.8011302947998047, "action": -0.646949827671051}
{"mode": "train", "epochs": 10, "timestep": 18915, "ep_reward": 517.2400512695312, "reward": 0.7402184009552002, "action": -1.069763422012329}
{"mode": "train", "epochs": 10, "timestep": 18916, "ep_reward": 517.8817749023438, "reward": 0.6417461633682251, "action": -1.1054925918579102}
{"mode": "train", "epochs": 10, "timestep": 18917, "ep_reward": 518.3843994140625, "reward": 0.5026372671127319, "action": -0.5578821897506714}
{"mode": "train", "epochs": 10, "timestep": 18918, "ep_reward": 518.744873046875, "reward": 0.36045271158218384, "action": -0.5082637071609497}
{"mode": "train", "epochs": 10, "timestep": 18919, "ep_reward": 518.997314453125, "reward": 0.2524593472480774, "action": -1.4282623529434204}
{"mode": "train", "epochs": 10, "timestep": 18920, "ep_reward": 519.1220092773438, "reward": 0.12469470500946045, "action": -0.4147193431854248}
{"mode": "train", "epochs": 10, "timestep": 18921, "ep_reward": 519.1113891601562, "reward": -0.010589957237243652, "action": -0.7200820446014404}
{"mode": "train", "epochs": 10, "timestep": 18922, "ep_reward": 519.2470092773438, "reward": 0.13560158014297485, "action": -1.3578994274139404}
{"mode": "train", "epochs": 10, "timestep": 18923, "ep_reward": 519.5173950195312, "reward": 0.2703886032104492, "action": -0.7823625206947327}
{"mode": "train", "epochs": 10, "timestep": 18924, "ep_reward": 519.9288940429688, "reward": 0.41152048110961914, "action": -0.6054031848907471}
{"mode": "train", "epochs": 10, "timestep": 18925, "ep_reward": 520.47119140625, "reward": 0.542290210723877, "action": -0.8973243236541748}
{"mode": "train", "epochs": 10, "timestep": 18926, "ep_reward": 521.1207885742188, "reward": 0.6495762467384338, "action": -1.5654017925262451}
{"mode": "train", "epochs": 10, "timestep": 18927, "ep_reward": 521.8488159179688, "reward": 0.7280532121658325, "action": -0.6044704914093018}
{"mode": "train", "epochs": 10, "timestep": 18928, "ep_reward": 522.64306640625, "reward": 0.7942789793014526, "action": -0.6364939212799072}
{"mode": "train", "epochs": 10, "timestep": 18929, "ep_reward": 523.4823608398438, "reward": 0.8392994999885559, "action": -0.8734280467033386}
{"mode": "train", "epochs": 10, "timestep": 18930, "ep_reward": 524.3468017578125, "reward": 0.864426851272583, "action": -0.9129414558410645}
{"mode": "train", "epochs": 10, "timestep": 18931, "ep_reward": 525.2200317382812, "reward": 0.8732403516769409, "action": -1.1883163452148438}
{"mode": "train", "epochs": 10, "timestep": 18932, "ep_reward": 526.0839233398438, "reward": 0.8638725876808167, "action": -0.7935426831245422}
{"mode": "train", "epochs": 10, "timestep": 18933, "ep_reward": 526.9238891601562, "reward": 0.8399755358695984, "action": -1.0624504089355469}
{"mode": "train", "epochs": 10, "timestep": 18934, "ep_reward": 527.7157592773438, "reward": 0.7918896675109863, "action": -0.6585876941680908}
{"mode": "train", "epochs": 10, "timestep": 18935, "ep_reward": 528.436279296875, "reward": 0.7205089926719666, "action": -1.5234129428863525}
{"mode": "train", "epochs": 10, "timestep": 18936, "ep_reward": 529.0405883789062, "reward": 0.6042790412902832, "action": -0.7625942826271057}
{"mode": "train", "epochs": 10, "timestep": 18937, "ep_reward": 529.4973754882812, "reward": 0.45678532123565674, "action": -0.3455938696861267}
{"mode": "train", "epochs": 10, "timestep": 18938, "ep_reward": 529.8212890625, "reward": 0.32391655445098877, "action": -1.4888482093811035}
{"mode": "train", "epochs": 10, "timestep": 18939, "ep_reward": 530.0302124023438, "reward": 0.20891904830932617, "action": -1.110138177871704}
{"mode": "train", "epochs": 10, "timestep": 18940, "ep_reward": 530.1041259765625, "reward": 0.07393723726272583, "action": -0.07906180620193481}
{"mode": "train", "epochs": 10, "timestep": 18941, "ep_reward": 530.1482543945312, "reward": 0.044126033782958984, "action": -1.3218340873718262}
{"mode": "train", "epochs": 10, "timestep": 18942, "ep_reward": 530.33154296875, "reward": 0.1832866072654724, "action": -0.8569342494010925}
{"mode": "train", "epochs": 10, "timestep": 18943, "ep_reward": 530.65673828125, "reward": 0.32519781589508057, "action": -0.8812875747680664}
{"mode": "train", "epochs": 10, "timestep": 18944, "ep_reward": 531.1177978515625, "reward": 0.461087167263031, "action": -1.063999056816101}
{"mode": "train", "epochs": 10, "timestep": 18945, "ep_reward": 531.6976928710938, "reward": 0.5798954963684082, "action": -1.3825852870941162}
{"mode": "train", "epochs": 10, "timestep": 18946, "ep_reward": 532.3727416992188, "reward": 0.6750534772872925, "action": -0.4678881764411926}
{"mode": "train", "epochs": 10, "timestep": 18947, "ep_reward": 533.129638671875, "reward": 0.756878674030304, "action": -1.8536183834075928}
{"mode": "train", "epochs": 10, "timestep": 18948, "ep_reward": 533.9334716796875, "reward": 0.8038288950920105, "action": 0.1391751766204834}
{"mode": "train", "epochs": 10, "timestep": 18949, "ep_reward": 534.7827758789062, "reward": 0.8492928743362427, "action": -0.6849722862243652}
{"mode": "train", "epochs": 10, "timestep": 18950, "ep_reward": 535.65234375, "reward": 0.8695421814918518, "action": -1.0711948871612549}
{"mode": "train", "epochs": 10, "timestep": 18951, "ep_reward": 536.5230712890625, "reward": 0.8707208633422852, "action": -1.2507470846176147}
{"mode": "train", "epochs": 10, "timestep": 18952, "ep_reward": 537.376708984375, "reward": 0.8536381125450134, "action": -1.3837120532989502}
{"mode": "train", "epochs": 10, "timestep": 18953, "ep_reward": 538.19189453125, "reward": 0.8151810169219971, "action": -1.3105189800262451}
{"mode": "train", "epochs": 10, "timestep": 18954, "ep_reward": 538.9435424804688, "reward": 0.7516418099403381, "action": -0.3555402159690857}
{"mode": "train", "epochs": 10, "timestep": 18955, "ep_reward": 539.6109008789062, "reward": 0.6673724055290222, "action": -0.5119369029998779}
{"mode": "train", "epochs": 10, "timestep": 18956, "ep_reward": 540.1561889648438, "reward": 0.5452589988708496, "action": -1.2082340717315674}
{"mode": "train", "epochs": 10, "timestep": 18957, "ep_reward": 540.5322875976562, "reward": 0.376110315322876, "action": -1.5944647789001465}
{"mode": "train", "epochs": 10, "timestep": 18958, "ep_reward": 540.8038940429688, "reward": 0.2715851068496704, "action": -1.1694936752319336}
{"mode": "train", "epochs": 10, "timestep": 18959, "ep_reward": 540.9508666992188, "reward": 0.14700162410736084, "action": -1.0650885105133057}
{"mode": "train", "epochs": 10, "timestep": 18960, "ep_reward": 540.9532470703125, "reward": 0.002375483512878418, "action": -1.262931227684021}
{"mode": "train", "epochs": 10, "timestep": 18961, "ep_reward": 541.0662231445312, "reward": 0.11296051740646362, "action": -1.349745273590088}
{"mode": "train", "epochs": 10, "timestep": 18962, "ep_reward": 541.3134155273438, "reward": 0.24720025062561035, "action": -1.2124998569488525}
{"mode": "train", "epochs": 10, "timestep": 18963, "ep_reward": 541.6974487304688, "reward": 0.384033739566803, "action": -1.0651750564575195}
{"mode": "train", "epochs": 10, "timestep": 18964, "ep_reward": 542.2106323242188, "reward": 0.5131831765174866, "action": -0.46198010444641113}
{"mode": "train", "epochs": 10, "timestep": 18965, "ep_reward": 542.8411254882812, "reward": 0.6304847002029419, "action": -1.1992284059524536}
{"mode": "train", "epochs": 10, "timestep": 18966, "ep_reward": 543.5576171875, "reward": 0.7164632081985474, "action": -0.6515225172042847}
{"mode": "train", "epochs": 10, "timestep": 18967, "ep_reward": 544.3428344726562, "reward": 0.7851967811584473, "action": -1.0892542600631714}
{"mode": "train", "epochs": 10, "timestep": 18968, "ep_reward": 545.171630859375, "reward": 0.8287944793701172, "action": -0.7072744369506836}
{"mode": "train", "epochs": 10, "timestep": 18969, "ep_reward": 546.0289306640625, "reward": 0.8573297262191772, "action": -0.4561126232147217}
{"mode": "train", "epochs": 10, "timestep": 18970, "ep_reward": 546.8999633789062, "reward": 0.8710523843765259, "action": -1.13068687915802}
{"mode": "train", "epochs": 10, "timestep": 18971, "ep_reward": 547.7628173828125, "reward": 0.86286461353302, "action": -1.140699863433838}
{"mode": "train", "epochs": 10, "timestep": 18972, "ep_reward": 548.5992431640625, "reward": 0.8364123106002808, "action": -0.28207170963287354}
{"mode": "train", "epochs": 10, "timestep": 18973, "ep_reward": 549.395751953125, "reward": 0.7964972257614136, "action": -0.7275612950325012}
{"mode": "train", "epochs": 10, "timestep": 18974, "ep_reward": 550.1217651367188, "reward": 0.7260025143623352, "action": -0.3470710515975952}
{"mode": "train", "epochs": 10, "timestep": 18975, "ep_reward": 550.7494506835938, "reward": 0.6276969909667969, "action": -0.4901795983314514}
{"mode": "train", "epochs": 10, "timestep": 18976, "ep_reward": 551.2402954101562, "reward": 0.49081504344940186, "action": -1.1674137115478516}
{"mode": "train", "epochs": 10, "timestep": 18977, "ep_reward": 551.57421875, "reward": 0.3339359760284424, "action": -0.6023504734039307}
{"mode": "train", "epochs": 10, "timestep": 18978, "ep_reward": 551.7950439453125, "reward": 0.22079753875732422, "action": 0.2721313238143921}
{"mode": "train", "epochs": 10, "timestep": 18979, "ep_reward": 551.8826904296875, "reward": 0.0876457691192627, "action": 0.08577215671539307}
{"mode": "train", "epochs": 10, "timestep": 18980, "ep_reward": 551.9126586914062, "reward": 0.029950261116027832, "action": -0.42332321405410767}
{"mode": "train", "epochs": 10, "timestep": 18981, "ep_reward": 552.0858154296875, "reward": 0.1731783151626587, "action": -1.0883510112762451}
{"mode": "train", "epochs": 10, "timestep": 18982, "ep_reward": 552.3973999023438, "reward": 0.31157606840133667, "action": -0.9446368217468262}
{"mode": "train", "epochs": 10, "timestep": 18983, "ep_reward": 552.844970703125, "reward": 0.4475642442703247, "action": -1.5969877243041992}
{"mode": "train", "epochs": 10, "timestep": 18984, "ep_reward": 553.4073486328125, "reward": 0.562349796295166, "action": -1.2966430187225342}
{"mode": "train", "epochs": 10, "timestep": 18985, "ep_reward": 554.0690307617188, "reward": 0.6616559028625488, "action": -0.40541940927505493}
{"mode": "train", "epochs": 10, "timestep": 18986, "ep_reward": 554.8162231445312, "reward": 0.7471710443496704, "action": -0.5659158229827881}
{"mode": "train", "epochs": 10, "timestep": 18987, "ep_reward": 555.6237182617188, "reward": 0.807481050491333, "action": -1.2975890636444092}
{"mode": "train", "epochs": 10, "timestep": 18988, "ep_reward": 556.46484375, "reward": 0.8411443829536438, "action": -1.8532819747924805}
{"mode": "train", "epochs": 10, "timestep": 18989, "ep_reward": 557.3176879882812, "reward": 0.8528172969818115, "action": -0.7024500370025635}
{"mode": "train", "epochs": 10, "timestep": 18990, "ep_reward": 558.1748046875, "reward": 0.8571344017982483, "action": -0.6084983944892883}
{"mode": "train", "epochs": 10, "timestep": 18991, "ep_reward": 559.0189819335938, "reward": 0.8441553711891174, "action": -0.6388657093048096}
{"mode": "train", "epochs": 10, "timestep": 18992, "ep_reward": 559.8295288085938, "reward": 0.8105213642120361, "action": -0.3548869490623474}
{"mode": "train", "epochs": 10, "timestep": 18993, "ep_reward": 560.5848388671875, "reward": 0.7553377151489258, "action": -0.5633001327514648}
{"mode": "train", "epochs": 10, "timestep": 18994, "ep_reward": 561.2528076171875, "reward": 0.6679515838623047, "action": -1.0989086627960205}
{"mode": "train", "epochs": 10, "timestep": 18995, "ep_reward": 561.7894287109375, "reward": 0.5365996956825256, "action": -1.7642145156860352}
{"mode": "train", "epochs": 10, "timestep": 18996, "ep_reward": 562.1610107421875, "reward": 0.37159234285354614, "action": -0.5383826494216919}
{"mode": "train", "epochs": 10, "timestep": 18997, "ep_reward": 562.4270629882812, "reward": 0.2660224437713623, "action": -0.3908471465110779}
{"mode": "train", "epochs": 10, "timestep": 18998, "ep_reward": 562.5673828125, "reward": 0.14030253887176514, "action": -1.5576492547988892}
{"mode": "train", "epochs": 10, "timestep": 18999, "ep_reward": 562.5621948242188, "reward": -0.005175948143005371, "action": -0.9189871549606323}
{"mode": "train", "epochs": 10, "timestep": 19000, "ep_reward": 562.6820068359375, "reward": 0.11981165409088135, "action": -1.1037371158599854}
{"mode": "train", "epochs": 10, "timestep": 19001, "ep_reward": 562.9392700195312, "reward": 0.25724631547927856, "action": -1.5425405502319336}
{"mode": "train", "epochs": 10, "timestep": 19002, "ep_reward": 563.3284912109375, "reward": 0.3892296552658081, "action": -0.3781837821006775}
{"mode": "train", "epochs": 10, "timestep": 19003, "ep_reward": 563.8543090820312, "reward": 0.525813639163971, "action": -0.43551552295684814}
{"mode": "train", "epochs": 10, "timestep": 19004, "ep_reward": 564.4953002929688, "reward": 0.6410112977027893, "action": -1.2751660346984863}
{"mode": "train", "epochs": 10, "timestep": 19005, "ep_reward": 565.2196655273438, "reward": 0.7243952751159668, "action": -0.5903875231742859}
{"mode": "train", "epochs": 10, "timestep": 19006, "ep_reward": 566.0121459960938, "reward": 0.7925030589103699, "action": -0.28456586599349976}
{"mode": "train", "epochs": 10, "timestep": 19007, "ep_reward": 566.8544311523438, "reward": 0.8422756195068359, "action": -1.0232998132705688}
{"mode": "train", "epochs": 10, "timestep": 19008, "ep_reward": 567.7225341796875, "reward": 0.8680807948112488, "action": -1.5404596328735352}
{"mode": "train", "epochs": 10, "timestep": 19009, "ep_reward": 568.5969848632812, "reward": 0.8744778633117676, "action": -1.7685922384262085}
{"mode": "train", "epochs": 10, "timestep": 19010, "ep_reward": 569.4603881835938, "reward": 0.8633939027786255, "action": -1.178830862045288}
{"mode": "train", "epochs": 10, "timestep": 19011, "ep_reward": 570.2994995117188, "reward": 0.8391259908676147, "action": -1.081810474395752}
{"mode": "train", "epochs": 10, "timestep": 19012, "ep_reward": 571.09326171875, "reward": 0.7937822341918945, "action": -0.6173985600471497}
{"mode": "train", "epochs": 10, "timestep": 19013, "ep_reward": 571.8192138671875, "reward": 0.7259659171104431, "action": -1.6219983100891113}
{"mode": "train", "epochs": 10, "timestep": 19014, "ep_reward": 572.4310302734375, "reward": 0.6118202805519104, "action": -1.1411412954330444}
{"mode": "train", "epochs": 10, "timestep": 19015, "ep_reward": 572.8923950195312, "reward": 0.4613445997238159, "action": -1.182601809501648}
{"mode": "train", "epochs": 10, "timestep": 19016, "ep_reward": 573.2265625, "reward": 0.33416593074798584, "action": -1.20304274559021}
{"mode": "train", "epochs": 10, "timestep": 19017, "ep_reward": 573.447509765625, "reward": 0.22097563743591309, "action": -1.7066013813018799}
{"mode": "train", "epochs": 10, "timestep": 19018, "ep_reward": 573.5355224609375, "reward": 0.08803635835647583, "action": -0.6093189716339111}
{"mode": "train", "epochs": 10, "timestep": 19019, "ep_reward": 573.5648803710938, "reward": 0.02933824062347412, "action": -1.7306058406829834}
{"mode": "train", "epochs": 10, "timestep": 19020, "ep_reward": 573.7354736328125, "reward": 0.17056912183761597, "action": -0.46907323598861694}
{"mode": "train", "epochs": 10, "timestep": 19021, "ep_reward": 574.052490234375, "reward": 0.3169955611228943, "action": -1.344998836517334}
{"mode": "train", "epochs": 10, "timestep": 19022, "ep_reward": 574.499755859375, "reward": 0.44724005460739136, "action": -1.1943796873092651}
{"mode": "train", "epochs": 10, "timestep": 19023, "ep_reward": 575.0662841796875, "reward": 0.5665087699890137, "action": -1.4292242527008057}
{"mode": "train", "epochs": 10, "timestep": 19024, "ep_reward": 575.7299194335938, "reward": 0.6636316776275635, "action": -1.5857717990875244}
{"mode": "train", "epochs": 10, "timestep": 19025, "ep_reward": 576.4673461914062, "reward": 0.7374154329299927, "action": -1.7893719673156738}
{"mode": "train", "epochs": 10, "timestep": 19026, "ep_reward": 577.2552490234375, "reward": 0.7879139184951782, "action": -1.3919097185134888}
{"mode": "train", "epochs": 10, "timestep": 19027, "ep_reward": 578.0771484375, "reward": 0.8218971490859985, "action": 0.2068513035774231}
{"mode": "train", "epochs": 10, "timestep": 19028, "ep_reward": 578.9277954101562, "reward": 0.8506371378898621, "action": -1.0988543033599854}
{"mode": "train", "epochs": 10, "timestep": 19029, "ep_reward": 579.7766723632812, "reward": 0.8488529920578003, "action": -1.0075100660324097}
{"mode": "train", "epochs": 10, "timestep": 19030, "ep_reward": 580.6049194335938, "reward": 0.8282648324966431, "action": -1.4891183376312256}
{"mode": "train", "epochs": 10, "timestep": 19031, "ep_reward": 581.3843994140625, "reward": 0.7794725894927979, "action": -0.8860830664634705}
{"mode": "train", "epochs": 10, "timestep": 19032, "ep_reward": 582.0916748046875, "reward": 0.7072827219963074, "action": -1.6548101902008057}
{"mode": "train", "epochs": 10, "timestep": 19033, "ep_reward": 582.6802978515625, "reward": 0.5885943174362183, "action": -0.8098273277282715}
{"mode": "train", "epochs": 10, "timestep": 19034, "ep_reward": 583.1177978515625, "reward": 0.43751341104507446, "action": -1.3199620246887207}
{"mode": "train", "epochs": 10, "timestep": 19035, "ep_reward": 583.4481201171875, "reward": 0.33031517267227173, "action": -0.6787116527557373}
{"mode": "train", "epochs": 10, "timestep": 19036, "ep_reward": 583.6646118164062, "reward": 0.21647626161575317, "action": -0.45083385705947876}
{"mode": "train", "epochs": 10, "timestep": 19037, "ep_reward": 583.7472534179688, "reward": 0.0826345682144165, "action": 0.039466261863708496}
{"mode": "train", "epochs": 10, "timestep": 19038, "ep_reward": 583.7824096679688, "reward": 0.0351826548576355, "action": -0.7987769246101379}
{"mode": "train", "epochs": 10, "timestep": 19039, "ep_reward": 583.9578857421875, "reward": 0.17550498247146606, "action": -0.5501712560653687}
{"mode": "train", "epochs": 10, "timestep": 19040, "ep_reward": 584.2789916992188, "reward": 0.3210948705673218, "action": -0.7307502627372742}
{"mode": "train", "epochs": 10, "timestep": 19041, "ep_reward": 584.7374877929688, "reward": 0.458496630191803, "action": -0.8570999503135681}
{"mode": "train", "epochs": 10, "timestep": 19042, "ep_reward": 585.3170776367188, "reward": 0.5795970559120178, "action": -1.437612771987915}
{"mode": "train", "epochs": 10, "timestep": 19043, "ep_reward": 585.9916381835938, "reward": 0.6745322346687317, "action": -0.12505555152893066}
{"mode": "train", "epochs": 10, "timestep": 19044, "ep_reward": 586.752197265625, "reward": 0.7605446577072144, "action": -1.3028510808944702}
{"mode": "train", "epochs": 10, "timestep": 19045, "ep_reward": 587.565673828125, "reward": 0.8134918212890625, "action": -1.1065138578414917}
{"mode": "train", "epochs": 10, "timestep": 19046, "ep_reward": 588.4157104492188, "reward": 0.8500198125839233, "action": -0.8230370879173279}
{"mode": "train", "epochs": 10, "timestep": 19047, "ep_reward": 589.2881469726562, "reward": 0.8724460005760193, "action": -0.9422622919082642}
{"mode": "train", "epochs": 10, "timestep": 19048, "ep_reward": 590.1669311523438, "reward": 0.8787740468978882, "action": -0.596103310585022}
{"mode": "train", "epochs": 10, "timestep": 19049, "ep_reward": 591.0396728515625, "reward": 0.8727182149887085, "action": -1.088852047920227}
{"mode": "train", "epochs": 10, "timestep": 19050, "ep_reward": 591.8851318359375, "reward": 0.8454665541648865, "action": -1.7852412462234497}
{"mode": "train", "epochs": 10, "timestep": 19051, "ep_reward": 592.6749267578125, "reward": 0.789801299571991, "action": -0.36943262815475464}
{"mode": "train", "epochs": 10, "timestep": 19052, "ep_reward": 593.3955078125, "reward": 0.7205721139907837, "action": -1.0246316194534302}
{"mode": "train", "epochs": 10, "timestep": 19053, "ep_reward": 594.0060424804688, "reward": 0.6105213761329651, "action": -0.5611281394958496}
{"mode": "train", "epochs": 10, "timestep": 19054, "ep_reward": 594.4735107421875, "reward": 0.46748822927474976, "action": -0.7461035251617432}
{"mode": "train", "epochs": 10, "timestep": 19055, "ep_reward": 594.7968139648438, "reward": 0.3232730031013489, "action": -0.5106642246246338}
{"mode": "train", "epochs": 10, "timestep": 19056, "ep_reward": 595.0048828125, "reward": 0.20805424451828003, "action": -0.696773111820221}
{"mode": "train", "epochs": 10, "timestep": 19057, "ep_reward": 595.0775756835938, "reward": 0.07266241312026978, "action": -1.8681138753890991}
{"mode": "train", "epochs": 10, "timestep": 19058, "ep_reward": 595.122802734375, "reward": 0.045236825942993164, "action": -1.1577863693237305}
{"mode": "train", "epochs": 10, "timestep": 19059, "ep_reward": 595.3070678710938, "reward": 0.18426913022994995, "action": 0.22496700286865234}
{"mode": "train", "epochs": 10, "timestep": 19060, "ep_reward": 595.6465454101562, "reward": 0.3394869565963745, "action": -0.27616119384765625}
{"mode": "train", "epochs": 10, "timestep": 19061, "ep_reward": 596.1260375976562, "reward": 0.47949767112731934, "action": -0.8475097417831421}
{"mode": "train", "epochs": 10, "timestep": 19062, "ep_reward": 596.722900390625, "reward": 0.5968508720397949, "action": -1.5676480531692505}
{"mode": "train", "epochs": 10, "timestep": 19063, "ep_reward": 597.4103393554688, "reward": 0.6874479055404663, "action": -0.7382774353027344}
{"mode": "train", "epochs": 10, "timestep": 19064, "ep_reward": 598.176025390625, "reward": 0.7656675577163696, "action": -1.3783543109893799}
{"mode": "train", "epochs": 10, "timestep": 19065, "ep_reward": 598.9939575195312, "reward": 0.8179064393043518, "action": -0.5057417750358582}
{"mode": "train", "epochs": 10, "timestep": 19066, "ep_reward": 599.8536376953125, "reward": 0.8597010970115662, "action": -0.8326607942581177}
{"mode": "train", "epochs": 10, "timestep": 19067, "ep_reward": 600.736572265625, "reward": 0.8829615116119385, "action": -1.5710170269012451}
{"mode": "train", "epochs": 10, "timestep": 19068, "ep_reward": 601.62353515625, "reward": 0.8869398236274719, "action": -1.1221429109573364}
{"mode": "train", "epochs": 10, "timestep": 19069, "ep_reward": 602.5037841796875, "reward": 0.8802334666252136, "action": -1.701043963432312}
{"mode": "train", "epochs": 10, "timestep": 19070, "ep_reward": 603.3563842773438, "reward": 0.8525747060775757, "action": -0.8233224153518677}
{"mode": "train", "epochs": 10, "timestep": 19071, "ep_reward": 604.16845703125, "reward": 0.8120879530906677, "action": -1.74019193649292}
{"mode": "train", "epochs": 10, "timestep": 19072, "ep_reward": 604.9046630859375, "reward": 0.7362232208251953, "action": -1.029996633529663}
{"mode": "train", "epochs": 10, "timestep": 19073, "ep_reward": 605.5384521484375, "reward": 0.633812665939331, "action": -0.7758417725563049}
{"mode": "train", "epochs": 10, "timestep": 19074, "ep_reward": 606.0340576171875, "reward": 0.4955856204032898, "action": -0.753955602645874}
{"mode": "train", "epochs": 10, "timestep": 19075, "ep_reward": 606.3796997070312, "reward": 0.34565335512161255, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 19076, "ep_reward": 606.61474609375, "reward": 0.2350449562072754, "action": -0.8410161137580872}
{"mode": "train", "epochs": 10, "timestep": 19077, "ep_reward": 606.7189331054688, "reward": 0.10416442155838013, "action": -1.334151268005371}
{"mode": "train", "epochs": 10, "timestep": 19078, "ep_reward": 606.7310791015625, "reward": 0.012138903141021729, "action": -0.028941452503204346}
{"mode": "train", "epochs": 10, "timestep": 19079, "ep_reward": 606.890625, "reward": 0.15955334901809692, "action": -1.8818562030792236}
{"mode": "train", "epochs": 10, "timestep": 19080, "ep_reward": 607.1781005859375, "reward": 0.28746312856674194, "action": -0.7673337459564209}
{"mode": "train", "epochs": 10, "timestep": 19081, "ep_reward": 607.6063232421875, "reward": 0.4282257556915283, "action": -0.8509830236434937}
{"mode": "train", "epochs": 10, "timestep": 19082, "ep_reward": 608.16064453125, "reward": 0.5543255805969238, "action": -0.466727614402771}
{"mode": "train", "epochs": 10, "timestep": 19083, "ep_reward": 608.8245239257812, "reward": 0.6638765335083008, "action": -0.9929918646812439}
{"mode": "train", "epochs": 10, "timestep": 19084, "ep_reward": 609.56884765625, "reward": 0.7443133592605591, "action": -1.0992240905761719}
{"mode": "train", "epochs": 10, "timestep": 19085, "ep_reward": 610.3707275390625, "reward": 0.801888108253479, "action": -1.8918867111206055}
{"mode": "train", "epochs": 10, "timestep": 19086, "ep_reward": 611.2040405273438, "reward": 0.8333224654197693, "action": -1.4626610279083252}
{"mode": "train", "epochs": 10, "timestep": 19087, "ep_reward": 612.054931640625, "reward": 0.8509202003479004, "action": -1.7379119396209717}
{"mode": "train", "epochs": 10, "timestep": 19088, "ep_reward": 612.9034423828125, "reward": 0.8485236167907715, "action": -0.9127040505409241}
{"mode": "train", "epochs": 10, "timestep": 19089, "ep_reward": 613.73779296875, "reward": 0.8343228697776794, "action": -0.7920801639556885}
{"mode": "train", "epochs": 10, "timestep": 19090, "ep_reward": 614.5372314453125, "reward": 0.799407958984375, "action": -0.9824815392494202}
{"mode": "train", "epochs": 10, "timestep": 19091, "ep_reward": 615.2730712890625, "reward": 0.7358191609382629, "action": -0.7021051645278931}
{"mode": "train", "epochs": 10, "timestep": 19092, "ep_reward": 615.9153442382812, "reward": 0.6422574520111084, "action": -1.2782115936279297}
{"mode": "train", "epochs": 10, "timestep": 19093, "ep_reward": 616.41650390625, "reward": 0.5011762976646423, "action": -1.0832172632217407}
{"mode": "train", "epochs": 10, "timestep": 19094, "ep_reward": 616.780029296875, "reward": 0.36353516578674316, "action": -1.1361558437347412}
{"mode": "train", "epochs": 10, "timestep": 19095, "ep_reward": 617.036376953125, "reward": 0.2563614249229431, "action": -0.5308345556259155}
{"mode": "train", "epochs": 10, "timestep": 19096, "ep_reward": 617.1654663085938, "reward": 0.1291130781173706, "action": -0.6885581612586975}
{"mode": "train", "epochs": 10, "timestep": 19097, "ep_reward": 617.1497802734375, "reward": -0.01570272445678711, "action": -1.2249598503112793}
{"mode": "train", "epochs": 10, "timestep": 19098, "ep_reward": 617.2808837890625, "reward": 0.1310971975326538, "action": -1.847388744354248}
{"mode": "train", "epochs": 10, "timestep": 19099, "ep_reward": 617.5404663085938, "reward": 0.2595696449279785, "action": -1.4080278873443604}
{"mode": "train", "epochs": 10, "timestep": 19100, "ep_reward": 617.9349975585938, "reward": 0.39451438188552856, "action": -0.2361646294593811}
{"mode": "train", "epochs": 10, "timestep": 19101, "ep_reward": 618.4677124023438, "reward": 0.5327345132827759, "action": -0.991486132144928}
{"mode": "train", "epochs": 10, "timestep": 19102, "ep_reward": 619.1085815429688, "reward": 0.6408758759498596, "action": -0.6570236682891846}
{"mode": "train", "epochs": 10, "timestep": 19103, "ep_reward": 619.8379516601562, "reward": 0.729384183883667, "action": -0.43651068210601807}
{"mode": "train", "epochs": 10, "timestep": 19104, "ep_reward": 620.6342163085938, "reward": 0.7962521910667419, "action": -1.692371129989624}
{"mode": "train", "epochs": 10, "timestep": 19105, "ep_reward": 621.4654541015625, "reward": 0.8312569260597229, "action": -1.4386765956878662}
{"mode": "train", "epochs": 10, "timestep": 19106, "ep_reward": 622.3162841796875, "reward": 0.8508458733558655, "action": -0.9896728992462158}
{"mode": "train", "epochs": 10, "timestep": 19107, "ep_reward": 623.1732177734375, "reward": 0.8569629788398743, "action": -0.264165997505188}
{"mode": "train", "epochs": 10, "timestep": 19108, "ep_reward": 624.02490234375, "reward": 0.8516813516616821, "action": -0.6835262179374695}
{"mode": "train", "epochs": 10, "timestep": 19109, "ep_reward": 624.8482055664062, "reward": 0.82330322265625, "action": -0.800813615322113}
{"mode": "train", "epochs": 10, "timestep": 19110, "ep_reward": 625.6183471679688, "reward": 0.7701245546340942, "action": -1.927346110343933}
{"mode": "train", "epochs": 10, "timestep": 19111, "ep_reward": 626.2916259765625, "reward": 0.6733013391494751, "action": -1.4300402402877808}
{"mode": "train", "epochs": 10, "timestep": 19112, "ep_reward": 626.833251953125, "reward": 0.5416144132614136, "action": -0.9520402550697327}
{"mode": "train", "epochs": 10, "timestep": 19113, "ep_reward": 627.2206420898438, "reward": 0.38739103078842163, "action": -1.1989080905914307}
{"mode": "train", "epochs": 10, "timestep": 19114, "ep_reward": 627.5059204101562, "reward": 0.28525447845458984, "action": -0.6750256419181824}
{"mode": "train", "epochs": 10, "timestep": 19115, "ep_reward": 627.6688842773438, "reward": 0.16295814514160156, "action": -1.4285781383514404}
{"mode": "train", "epochs": 10, "timestep": 19116, "ep_reward": 627.689697265625, "reward": 0.020800411701202393, "action": -1.1909716129302979}
{"mode": "train", "epochs": 10, "timestep": 19117, "ep_reward": 627.7857055664062, "reward": 0.09602802991867065, "action": -1.5467839241027832}
{"mode": "train", "epochs": 10, "timestep": 19118, "ep_reward": 628.0137329101562, "reward": 0.2280481457710266, "action": -1.1898998022079468}
{"mode": "train", "epochs": 10, "timestep": 19119, "ep_reward": 628.3799438476562, "reward": 0.3661816120147705, "action": -0.5924427509307861}
{"mode": "train", "epochs": 10, "timestep": 19120, "ep_reward": 628.8828735351562, "reward": 0.5029065608978271, "action": -0.7500986456871033}
{"mode": "train", "epochs": 10, "timestep": 19121, "ep_reward": 629.5015869140625, "reward": 0.6187244653701782, "action": -1.8051695823669434}
{"mode": "train", "epochs": 10, "timestep": 19122, "ep_reward": 630.202880859375, "reward": 0.7012876272201538, "action": -0.8163476586341858}
{"mode": "train", "epochs": 10, "timestep": 19123, "ep_reward": 630.974853515625, "reward": 0.7719734907150269, "action": -0.8077356815338135}
{"mode": "train", "epochs": 10, "timestep": 19124, "ep_reward": 631.7955322265625, "reward": 0.8207049369812012, "action": -0.9869820475578308}
{"mode": "train", "epochs": 10, "timestep": 19125, "ep_reward": 632.6439819335938, "reward": 0.8484667539596558, "action": -0.48268187046051025}
{"mode": "train", "epochs": 10, "timestep": 19126, "ep_reward": 633.5068969726562, "reward": 0.862917423248291, "action": -0.904848039150238}
{"mode": "train", "epochs": 10, "timestep": 19127, "ep_reward": 634.3633422851562, "reward": 0.8564638495445251, "action": -1.4214286804199219}
{"mode": "train", "epochs": 10, "timestep": 19128, "ep_reward": 635.1895751953125, "reward": 0.8262088298797607, "action": -1.1654151678085327}
{"mode": "train", "epochs": 10, "timestep": 19129, "ep_reward": 635.9639282226562, "reward": 0.7743688225746155, "action": -1.016310453414917}
{"mode": "train", "epochs": 10, "timestep": 19130, "ep_reward": 636.6578369140625, "reward": 0.6939342021942139, "action": -1.7302696704864502}
{"mode": "train", "epochs": 10, "timestep": 19131, "ep_reward": 637.2243041992188, "reward": 0.5664941072463989, "action": 0.04906880855560303}
{"mode": "train", "epochs": 10, "timestep": 19132, "ep_reward": 637.64599609375, "reward": 0.42170441150665283, "action": -1.1492035388946533}
{"mode": "train", "epochs": 10, "timestep": 19133, "ep_reward": 637.9541015625, "reward": 0.30812156200408936, "action": 0.14405786991119385}
{"mode": "train", "epochs": 10, "timestep": 19134, "ep_reward": 638.1441040039062, "reward": 0.18998205661773682, "action": -1.2094475030899048}
{"mode": "train", "epochs": 10, "timestep": 19135, "ep_reward": 638.196044921875, "reward": 0.05191624164581299, "action": -1.3174041509628296}
{"mode": "train", "epochs": 10, "timestep": 19136, "ep_reward": 638.26220703125, "reward": 0.06615477800369263, "action": -1.5499167442321777}
{"mode": "train", "epochs": 10, "timestep": 19137, "ep_reward": 638.464599609375, "reward": 0.20236968994140625, "action": -0.820869505405426}
{"mode": "train", "epochs": 10, "timestep": 19138, "ep_reward": 638.8095092773438, "reward": 0.3448874354362488, "action": -1.2653502225875854}
{"mode": "train", "epochs": 10, "timestep": 19139, "ep_reward": 639.2843627929688, "reward": 0.4748356342315674, "action": -1.1358977556228638}
{"mode": "train", "epochs": 10, "timestep": 19140, "ep_reward": 639.8753662109375, "reward": 0.5910245180130005, "action": -1.5003483295440674}
{"mode": "train", "epochs": 10, "timestep": 19141, "ep_reward": 640.5576782226562, "reward": 0.6823177933692932, "action": -1.0241234302520752}
{"mode": "train", "epochs": 10, "timestep": 19142, "ep_reward": 641.313720703125, "reward": 0.7560158967971802, "action": -1.277090311050415}
{"mode": "train", "epochs": 10, "timestep": 19143, "ep_reward": 642.1188354492188, "reward": 0.8051210641860962, "action": -1.0602922439575195}
{"mode": "train", "epochs": 10, "timestep": 19144, "ep_reward": 642.9548950195312, "reward": 0.8360380530357361, "action": -1.5887231826782227}
{"mode": "train", "epochs": 10, "timestep": 19145, "ep_reward": 643.7982788085938, "reward": 0.8433772325515747, "action": -1.4130902290344238}
{"mode": "train", "epochs": 10, "timestep": 19146, "ep_reward": 644.6311645507812, "reward": 0.8328947424888611, "action": -1.031539797782898}
{"mode": "train", "epochs": 10, "timestep": 19147, "ep_reward": 645.4352416992188, "reward": 0.8040798306465149, "action": -0.5667197704315186}
{"mode": "train", "epochs": 10, "timestep": 19148, "ep_reward": 646.1893920898438, "reward": 0.7541297078132629, "action": -1.7634927034378052}
{"mode": "train", "epochs": 10, "timestep": 19149, "ep_reward": 646.8472900390625, "reward": 0.6579056978225708, "action": -1.0277920961380005}
{"mode": "train", "epochs": 10, "timestep": 19150, "ep_reward": 647.3768310546875, "reward": 0.5295584201812744, "action": -0.5890097618103027}
{"mode": "train", "epochs": 10, "timestep": 19151, "ep_reward": 647.7670288085938, "reward": 0.3901937007904053, "action": -1.9480199813842773}
{"mode": "train", "epochs": 10, "timestep": 19152, "ep_reward": 648.055908203125, "reward": 0.2888750433921814, "action": -0.03429973125457764}
{"mode": "train", "epochs": 10, "timestep": 19153, "ep_reward": 648.2230834960938, "reward": 0.16717272996902466, "action": -1.535074234008789}
{"mode": "train", "epochs": 10, "timestep": 19154, "ep_reward": 648.2487182617188, "reward": 0.025635480880737305, "action": -1.44194495677948}
{"mode": "train", "epochs": 10, "timestep": 19155, "ep_reward": 648.3402099609375, "reward": 0.09147655963897705, "action": -1.4569108486175537}
{"mode": "train", "epochs": 10, "timestep": 19156, "ep_reward": 648.5643920898438, "reward": 0.2241724133491516, "action": -0.7796722650527954}
{"mode": "train", "epochs": 10, "timestep": 19157, "ep_reward": 648.9317626953125, "reward": 0.36735856533050537, "action": -0.6052669882774353}
{"mode": "train", "epochs": 10, "timestep": 19158, "ep_reward": 649.4349975585938, "reward": 0.5032115578651428, "action": -0.8998526930809021}
{"mode": "train", "epochs": 10, "timestep": 19159, "ep_reward": 650.0524291992188, "reward": 0.6174170970916748, "action": -0.7247380018234253}
{"mode": "train", "epochs": 10, "timestep": 19160, "ep_reward": 650.7636108398438, "reward": 0.7112113237380981, "action": -1.4251350164413452}
{"mode": "train", "epochs": 10, "timestep": 19161, "ep_reward": 651.5392456054688, "reward": 0.7756329774856567, "action": -1.4108600616455078}
{"mode": "train", "epochs": 10, "timestep": 19162, "ep_reward": 652.3594970703125, "reward": 0.8202605247497559, "action": -1.100536584854126}
{"mode": "train", "epochs": 10, "timestep": 19163, "ep_reward": 653.208740234375, "reward": 0.8492555022239685, "action": -0.36666953563690186}
{"mode": "train", "epochs": 10, "timestep": 19164, "ep_reward": 654.0759887695312, "reward": 0.8672218918800354, "action": -0.6245496869087219}
{"mode": "train", "epochs": 10, "timestep": 19165, "ep_reward": 654.9424438476562, "reward": 0.86644446849823, "action": -1.1977248191833496}
{"mode": "train", "epochs": 10, "timestep": 19166, "ep_reward": 655.7854614257812, "reward": 0.8430222272872925, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 19167, "ep_reward": 656.5750122070312, "reward": 0.7895625829696655, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 19168, "ep_reward": 657.2801513671875, "reward": 0.70514976978302, "action": -0.6784058213233948}
{"mode": "train", "epochs": 10, "timestep": 19169, "ep_reward": 657.8792114257812, "reward": 0.5990545749664307, "action": -0.7750067114830017}
{"mode": "train", "epochs": 10, "timestep": 19170, "ep_reward": 658.3301391601562, "reward": 0.45092785358428955, "action": -1.0774610042572021}
{"mode": "train", "epochs": 10, "timestep": 19171, "ep_reward": 658.660888671875, "reward": 0.33074498176574707, "action": -1.026627540588379}
{"mode": "train", "epochs": 10, "timestep": 19172, "ep_reward": 658.8779296875, "reward": 0.21701180934906006, "action": -0.7380856871604919}
{"mode": "train", "epochs": 10, "timestep": 19173, "ep_reward": 658.961181640625, "reward": 0.0832526683807373, "action": -0.6795939207077026}
{"mode": "train", "epochs": 10, "timestep": 19174, "ep_reward": 658.9954833984375, "reward": 0.034296393394470215, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 19175, "ep_reward": 659.1703491210938, "reward": 0.17489075660705566, "action": -0.8658887147903442}
{"mode": "train", "epochs": 10, "timestep": 19176, "ep_reward": 659.4869384765625, "reward": 0.3165792226791382, "action": -0.8284086585044861}
{"mode": "train", "epochs": 10, "timestep": 19177, "ep_reward": 659.9406127929688, "reward": 0.4536817669868469, "action": -0.8674072623252869}
{"mode": "train", "epochs": 10, "timestep": 19178, "ep_reward": 660.5162963867188, "reward": 0.5756947994232178, "action": -1.0396695137023926}
{"mode": "train", "epochs": 10, "timestep": 19179, "ep_reward": 661.1915283203125, "reward": 0.6752233505249023, "action": -1.1574538946151733}
{"mode": "train", "epochs": 10, "timestep": 19180, "ep_reward": 661.9429321289062, "reward": 0.7513829469680786, "action": -0.8461014032363892}
{"mode": "train", "epochs": 10, "timestep": 19181, "ep_reward": 662.751953125, "reward": 0.8090298175811768, "action": -0.9993181824684143}
{"mode": "train", "epochs": 10, "timestep": 19182, "ep_reward": 663.59765625, "reward": 0.8457179069519043, "action": -1.8167228698730469}
{"mode": "train", "epochs": 10, "timestep": 19183, "ep_reward": 664.456298828125, "reward": 0.8586286306381226, "action": -1.0880924463272095}
{"mode": "train", "epochs": 10, "timestep": 19184, "ep_reward": 665.3173217773438, "reward": 0.8610484600067139, "action": -1.3752785921096802}
{"mode": "train", "epochs": 10, "timestep": 19185, "ep_reward": 666.1604614257812, "reward": 0.8431225419044495, "action": 0.32589030265808105}
{"mode": "train", "epochs": 10, "timestep": 19186, "ep_reward": 666.9813842773438, "reward": 0.8209086060523987, "action": -1.2180508375167847}
{"mode": "train", "epochs": 10, "timestep": 19187, "ep_reward": 667.7413940429688, "reward": 0.75999516248703, "action": -0.8138295412063599}
{"mode": "train", "epochs": 10, "timestep": 19188, "ep_reward": 668.4136352539062, "reward": 0.6722630262374878, "action": -1.407737135887146}
{"mode": "train", "epochs": 10, "timestep": 19189, "ep_reward": 668.9522705078125, "reward": 0.5386615991592407, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 19190, "ep_reward": 669.330810546875, "reward": 0.37853097915649414, "action": -0.3194054365158081}
{"mode": "train", "epochs": 10, "timestep": 19191, "ep_reward": 669.605224609375, "reward": 0.27441829442977905, "action": -0.13717150688171387}
{"mode": "train", "epochs": 10, "timestep": 19192, "ep_reward": 669.7554931640625, "reward": 0.15027529001235962, "action": -0.6555432677268982}
{"mode": "train", "epochs": 10, "timestep": 19193, "ep_reward": 669.7616577148438, "reward": 0.006137192249298096, "action": -0.8792791366577148}
{"mode": "train", "epochs": 10, "timestep": 19194, "ep_reward": 669.871337890625, "reward": 0.10967129468917847, "action": -0.8256603479385376}
{"mode": "train", "epochs": 10, "timestep": 19195, "ep_reward": 670.1217041015625, "reward": 0.25037163496017456, "action": -0.9471784234046936}
{"mode": "train", "epochs": 10, "timestep": 19196, "ep_reward": 670.5109252929688, "reward": 0.38921934366226196, "action": -1.1960790157318115}
{"mode": "train", "epochs": 10, "timestep": 19197, "ep_reward": 671.026123046875, "reward": 0.5152187347412109, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 19198, "ep_reward": 671.6417236328125, "reward": 0.6156028509140015, "action": -0.5667543411254883}
{"mode": "train", "epochs": 10, "timestep": 19199, "ep_reward": 672.3522338867188, "reward": 0.7105258107185364, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 19200, "ep_reward": 673.1201782226562, "reward": 0.7679736018180847, "action": -1.0293411016464233}
{"mode": "train", "epochs": 10, "timestep": 19201, "ep_reward": 673.93408203125, "reward": 0.8138939142227173, "action": -1.7228903770446777}
{"mode": "train", "epochs": 10, "timestep": 19202, "ep_reward": 674.7677612304688, "reward": 0.8336611986160278, "action": -0.25847285985946655}
{"mode": "train", "epochs": 10, "timestep": 19203, "ep_reward": 675.6153564453125, "reward": 0.8475863337516785, "action": -1.187442421913147}
{"mode": "train", "epochs": 10, "timestep": 19204, "ep_reward": 676.4489135742188, "reward": 0.8335735201835632, "action": -0.8003950119018555}
{"mode": "train", "epochs": 10, "timestep": 19205, "ep_reward": 677.250244140625, "reward": 0.8013414740562439, "action": -0.40588921308517456}
{"mode": "train", "epochs": 10, "timestep": 19206, "ep_reward": 677.9976196289062, "reward": 0.7473495006561279, "action": -1.3942168951034546}
{"mode": "train", "epochs": 10, "timestep": 19207, "ep_reward": 678.6473388671875, "reward": 0.6496954560279846, "action": -0.9915123581886292}
{"mode": "train", "epochs": 10, "timestep": 19208, "ep_reward": 679.163818359375, "reward": 0.5164684057235718, "action": -1.3979350328445435}
{"mode": "train", "epochs": 10, "timestep": 19209, "ep_reward": 679.5379638671875, "reward": 0.37415581941604614, "action": -0.8753893375396729}
{"mode": "train", "epochs": 10, "timestep": 19210, "ep_reward": 679.80712890625, "reward": 0.2691692113876343, "action": 0.06278955936431885}
{"mode": "train", "epochs": 10, "timestep": 19211, "ep_reward": 679.951171875, "reward": 0.1440671682357788, "action": -1.048014760017395}
{"mode": "train", "epochs": 10, "timestep": 19212, "ep_reward": 679.9501953125, "reward": -0.001002669334411621, "action": -1.298470377922058}
{"mode": "train", "epochs": 10, "timestep": 19213, "ep_reward": 680.0662841796875, "reward": 0.11609518527984619, "action": -0.48100388050079346}
{"mode": "train", "epochs": 10, "timestep": 19214, "ep_reward": 680.3275756835938, "reward": 0.2612898349761963, "action": -0.33241355419158936}
{"mode": "train", "epochs": 10, "timestep": 19215, "ep_reward": 680.7338256835938, "reward": 0.406247615814209, "action": -1.4984941482543945}
{"mode": "train", "epochs": 10, "timestep": 19216, "ep_reward": 681.260009765625, "reward": 0.5261930227279663, "action": -0.9308803677558899}
{"mode": "train", "epochs": 10, "timestep": 19217, "ep_reward": 681.8960571289062, "reward": 0.6360329389572144, "action": -0.7811640501022339}
{"mode": "train", "epochs": 10, "timestep": 19218, "ep_reward": 682.6216430664062, "reward": 0.7255656719207764, "action": -0.8493902087211609}
{"mode": "train", "epochs": 10, "timestep": 19219, "ep_reward": 683.4137573242188, "reward": 0.7921372652053833, "action": -1.8875302076339722}
{"mode": "train", "epochs": 10, "timestep": 19220, "ep_reward": 684.2440795898438, "reward": 0.8302993178367615, "action": -1.7784984111785889}
{"mode": "train", "epochs": 10, "timestep": 19221, "ep_reward": 685.096923828125, "reward": 0.8528458476066589, "action": -0.22453546524047852}
{"mode": "train", "epochs": 10, "timestep": 19222, "ep_reward": 685.9688720703125, "reward": 0.8719626665115356, "action": -1.160673975944519}
{"mode": "train", "epochs": 10, "timestep": 19223, "ep_reward": 686.8361206054688, "reward": 0.8672482967376709, "action": -1.0340471267700195}
{"mode": "train", "epochs": 10, "timestep": 19224, "ep_reward": 687.6823120117188, "reward": 0.8462038636207581, "action": -1.1850727796554565}
{"mode": "train", "epochs": 10, "timestep": 19225, "ep_reward": 688.4850463867188, "reward": 0.8027048110961914, "action": -1.077295184135437}
{"mode": "train", "epochs": 10, "timestep": 19226, "ep_reward": 689.218505859375, "reward": 0.7334333658218384, "action": -0.3414417505264282}
{"mode": "train", "epochs": 10, "timestep": 19227, "ep_reward": 689.8585205078125, "reward": 0.6400421857833862, "action": -1.2724121809005737}
{"mode": "train", "epochs": 10, "timestep": 19228, "ep_reward": 690.3547973632812, "reward": 0.49628251791000366, "action": 0.09209269285202026}
{"mode": "train", "epochs": 10, "timestep": 19229, "ep_reward": 690.70361328125, "reward": 0.3488160967826843, "action": -0.2684893012046814}
{"mode": "train", "epochs": 10, "timestep": 19230, "ep_reward": 690.9419555664062, "reward": 0.23836708068847656, "action": -1.8754749298095703}
{"mode": "train", "epochs": 10, "timestep": 19231, "ep_reward": 691.0502319335938, "reward": 0.10827076435089111, "action": -1.152137041091919}
{"mode": "train", "epochs": 10, "timestep": 19232, "ep_reward": 691.0578002929688, "reward": 0.007541179656982422, "action": -1.4926927089691162}
{"mode": "train", "epochs": 10, "timestep": 19233, "ep_reward": 691.2092895507812, "reward": 0.15149688720703125, "action": -1.3027269840240479}
{"mode": "train", "epochs": 10, "timestep": 19234, "ep_reward": 691.4966430664062, "reward": 0.28732550144195557, "action": -0.8906315565109253}
{"mode": "train", "epochs": 10, "timestep": 19235, "ep_reward": 691.9228515625, "reward": 0.4262038469314575, "action": -0.3621487021446228}
{"mode": "train", "epochs": 10, "timestep": 19236, "ep_reward": 692.4807739257812, "reward": 0.5578973293304443, "action": -1.0475597381591797}
{"mode": "train", "epochs": 10, "timestep": 19237, "ep_reward": 693.1416625976562, "reward": 0.6608827114105225, "action": 0.14211511611938477}
{"mode": "train", "epochs": 10, "timestep": 19238, "ep_reward": 693.89453125, "reward": 0.7528885006904602, "action": -0.3957592844963074}
{"mode": "train", "epochs": 10, "timestep": 19239, "ep_reward": 694.7105712890625, "reward": 0.8160647749900818, "action": -1.478135347366333}
{"mode": "train", "epochs": 10, "timestep": 19240, "ep_reward": 695.5618896484375, "reward": 0.8512938022613525, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 19241, "ep_reward": 696.4290771484375, "reward": 0.8672056198120117, "action": -0.20646101236343384}
{"mode": "train", "epochs": 10, "timestep": 19242, "ep_reward": 697.3115844726562, "reward": 0.8824909925460815, "action": -1.2988560199737549}
{"mode": "train", "epochs": 10, "timestep": 19243, "ep_reward": 698.1857299804688, "reward": 0.874161958694458, "action": -0.8851860761642456}
{"mode": "train", "epochs": 10, "timestep": 19244, "ep_reward": 699.0382690429688, "reward": 0.8525440692901611, "action": -1.6298120021820068}
{"mode": "train", "epochs": 10, "timestep": 19245, "ep_reward": 699.841796875, "reward": 0.803501307964325, "action": -1.3428311347961426}
{"mode": "train", "epochs": 10, "timestep": 19246, "ep_reward": 700.5713500976562, "reward": 0.7295615673065186, "action": -0.531669557094574}
{"mode": "train", "epochs": 10, "timestep": 19247, "ep_reward": 701.20263671875, "reward": 0.6312681436538696, "action": -1.6540801525115967}
{"mode": "train", "epochs": 10, "timestep": 19248, "ep_reward": 701.6810913085938, "reward": 0.47848373651504517, "action": -0.44685280323028564}
{"mode": "train", "epochs": 10, "timestep": 19249, "ep_reward": 702.021240234375, "reward": 0.34016019105911255, "action": -0.6409940719604492}
{"mode": "train", "epochs": 10, "timestep": 19250, "ep_reward": 702.2493896484375, "reward": 0.2281321883201599, "action": -1.336112141609192}
{"mode": "train", "epochs": 10, "timestep": 19251, "ep_reward": 702.3456420898438, "reward": 0.09624218940734863, "action": -0.9803202748298645}
{"mode": "train", "epochs": 10, "timestep": 19252, "ep_reward": 702.3663940429688, "reward": 0.020752787590026855, "action": 0.20032000541687012}
{"mode": "train", "epochs": 10, "timestep": 19253, "ep_reward": 702.537841796875, "reward": 0.17145848274230957, "action": -0.7839615345001221}
{"mode": "train", "epochs": 10, "timestep": 19254, "ep_reward": 702.8500366210938, "reward": 0.3121699094772339, "action": -0.7379194498062134}
{"mode": "train", "epochs": 10, "timestep": 19255, "ep_reward": 703.2991943359375, "reward": 0.4491690993309021, "action": -0.8857783079147339}
{"mode": "train", "epochs": 10, "timestep": 19256, "ep_reward": 703.8700561523438, "reward": 0.5708470344543457, "action": -1.1245471239089966}
{"mode": "train", "epochs": 10, "timestep": 19257, "ep_reward": 704.5406494140625, "reward": 0.6706002950668335, "action": -1.1931673288345337}
{"mode": "train", "epochs": 10, "timestep": 19258, "ep_reward": 705.2891845703125, "reward": 0.7485629916191101, "action": -0.0037841200828552246}
{"mode": "train", "epochs": 10, "timestep": 19259, "ep_reward": 706.1052856445312, "reward": 0.8160901665687561, "action": -0.25422990322113037}
{"mode": "train", "epochs": 10, "timestep": 19260, "ep_reward": 706.9666748046875, "reward": 0.8613666892051697, "action": -0.40667396783828735}
{"mode": "train", "epochs": 10, "timestep": 19261, "ep_reward": 707.8560791015625, "reward": 0.8894007205963135, "action": -0.7704076766967773}
{"mode": "train", "epochs": 10, "timestep": 19262, "ep_reward": 708.757568359375, "reward": 0.9014970064163208, "action": -1.4955835342407227}
{"mode": "train", "epochs": 10, "timestep": 19263, "ep_reward": 709.65380859375, "reward": 0.8962597250938416, "action": -0.5452330708503723}
{"mode": "train", "epochs": 10, "timestep": 19264, "ep_reward": 710.53857421875, "reward": 0.8847416043281555, "action": -1.1315804719924927}
{"mode": "train", "epochs": 10, "timestep": 19265, "ep_reward": 711.3912963867188, "reward": 0.8527398705482483, "action": -1.7373361587524414}
{"mode": "train", "epochs": 10, "timestep": 19266, "ep_reward": 712.1851806640625, "reward": 0.7938574552536011, "action": -1.3364272117614746}
{"mode": "train", "epochs": 10, "timestep": 19267, "ep_reward": 712.89501953125, "reward": 0.7098496556282043, "action": -0.7443360090255737}
{"mode": "train", "epochs": 10, "timestep": 19268, "ep_reward": 713.4928588867188, "reward": 0.5978119969367981, "action": -0.9924407005310059}
{"mode": "train", "epochs": 10, "timestep": 19269, "ep_reward": 713.936279296875, "reward": 0.44344258308410645, "action": -0.47240930795669556}
{"mode": "train", "epochs": 10, "timestep": 19270, "ep_reward": 714.2398071289062, "reward": 0.3035564422607422, "action": -1.0137815475463867}
{"mode": "train", "epochs": 10, "timestep": 19271, "ep_reward": 714.4244995117188, "reward": 0.1846880316734314, "action": -0.9216084480285645}
{"mode": "train", "epochs": 10, "timestep": 19272, "ep_reward": 714.4703369140625, "reward": 0.04583495855331421, "action": -0.6615263223648071}
{"mode": "train", "epochs": 10, "timestep": 19273, "ep_reward": 714.5426635742188, "reward": 0.07230424880981445, "action": -0.8765987157821655}
{"mode": "train", "epochs": 10, "timestep": 19274, "ep_reward": 714.7539672851562, "reward": 0.2113105058670044, "action": -0.35688549280166626}
{"mode": "train", "epochs": 10, "timestep": 19275, "ep_reward": 715.11279296875, "reward": 0.3588479161262512, "action": -0.00551152229309082}
{"mode": "train", "epochs": 10, "timestep": 19276, "ep_reward": 715.61376953125, "reward": 0.5009793043136597, "action": -1.5361511707305908}
{"mode": "train", "epochs": 10, "timestep": 19277, "ep_reward": 716.2218627929688, "reward": 0.6080647706985474, "action": -1.822066068649292}
{"mode": "train", "epochs": 10, "timestep": 19278, "ep_reward": 716.91552734375, "reward": 0.6936360597610474, "action": -0.8251801133155823}
{"mode": "train", "epochs": 10, "timestep": 19279, "ep_reward": 717.683837890625, "reward": 0.7682918310165405, "action": -1.3859262466430664}
{"mode": "train", "epochs": 10, "timestep": 19280, "ep_reward": 718.5008544921875, "reward": 0.8170095682144165, "action": -0.34071236848831177}
{"mode": "train", "epochs": 10, "timestep": 19281, "ep_reward": 719.3570556640625, "reward": 0.8562227487564087, "action": -0.7682900428771973}
{"mode": "train", "epochs": 10, "timestep": 19282, "ep_reward": 720.2320556640625, "reward": 0.8749701976776123, "action": -1.5547735691070557}
{"mode": "train", "epochs": 10, "timestep": 19283, "ep_reward": 721.1043090820312, "reward": 0.8722773194313049, "action": -0.13565528392791748}
{"mode": "train", "epochs": 10, "timestep": 19284, "ep_reward": 721.9697265625, "reward": 0.8654043078422546, "action": -0.417058527469635}
{"mode": "train", "epochs": 10, "timestep": 19285, "ep_reward": 722.808349609375, "reward": 0.8386449217796326, "action": -1.3561139106750488}
{"mode": "train", "epochs": 10, "timestep": 19286, "ep_reward": 723.5894165039062, "reward": 0.7810646295547485, "action": -1.244687795639038}
{"mode": "train", "epochs": 10, "timestep": 19287, "ep_reward": 724.2841796875, "reward": 0.694747805595398, "action": -1.3039932250976562}
{"mode": "train", "epochs": 10, "timestep": 19288, "ep_reward": 724.8545532226562, "reward": 0.5703877806663513, "action": -1.5749192237854004}
{"mode": "train", "epochs": 10, "timestep": 19289, "ep_reward": 725.2532348632812, "reward": 0.39869755506515503, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 19290, "ep_reward": 725.54443359375, "reward": 0.29117727279663086, "action": -0.820369303226471}
{"mode": "train", "epochs": 10, "timestep": 19291, "ep_reward": 725.7144775390625, "reward": 0.17006230354309082, "action": -0.6063470840454102}
{"mode": "train", "epochs": 10, "timestep": 19292, "ep_reward": 725.7433471679688, "reward": 0.028886497020721436, "action": -1.022656798362732}
{"mode": "train", "epochs": 10, "timestep": 19293, "ep_reward": 725.8318481445312, "reward": 0.08847713470458984, "action": -1.416577696800232}
{"mode": "train", "epochs": 10, "timestep": 19294, "ep_reward": 726.0534057617188, "reward": 0.2215699553489685, "action": -0.9362162351608276}
{"mode": "train", "epochs": 10, "timestep": 19295, "ep_reward": 726.4161376953125, "reward": 0.36275821924209595, "action": -1.251044750213623}
{"mode": "train", "epochs": 10, "timestep": 19296, "ep_reward": 726.9078369140625, "reward": 0.4917200207710266, "action": -0.4910823702812195}
{"mode": "train", "epochs": 10, "timestep": 19297, "ep_reward": 727.520263671875, "reward": 0.6124342679977417, "action": -1.1717450618743896}
{"mode": "train", "epochs": 10, "timestep": 19298, "ep_reward": 728.2228393554688, "reward": 0.7025825381278992, "action": -1.6155853271484375}
{"mode": "train", "epochs": 10, "timestep": 19299, "ep_reward": 728.9889526367188, "reward": 0.7661172151565552, "action": -1.5271704196929932}
{"mode": "train", "epochs": 10, "timestep": 19300, "ep_reward": 729.7987670898438, "reward": 0.8098263144493103, "action": -1.3468748331069946}
{"mode": "train", "epochs": 10, "timestep": 19301, "ep_reward": 730.6343994140625, "reward": 0.8356472253799438, "action": -1.067495584487915}
{"mode": "train", "epochs": 10, "timestep": 19302, "ep_reward": 731.4794921875, "reward": 0.8450794816017151, "action": -0.9168348908424377}
{"mode": "train", "epochs": 10, "timestep": 19303, "ep_reward": 732.3158569335938, "reward": 0.8363686203956604, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 19304, "ep_reward": 733.1109619140625, "reward": 0.7951237559318542, "action": -0.1687765121459961}
{"mode": "train", "epochs": 10, "timestep": 19305, "ep_reward": 733.8566284179688, "reward": 0.7456965446472168, "action": -0.8314013481140137}
{"mode": "train", "epochs": 10, "timestep": 19306, "ep_reward": 734.5137329101562, "reward": 0.6571166515350342, "action": -0.8685963749885559}
{"mode": "train", "epochs": 10, "timestep": 19307, "ep_reward": 735.042724609375, "reward": 0.5289708375930786, "action": -1.4070073366165161}
{"mode": "train", "epochs": 10, "timestep": 19308, "ep_reward": 735.4251098632812, "reward": 0.3824031949043274, "action": -0.5652018785476685}
{"mode": "train", "epochs": 10, "timestep": 19309, "ep_reward": 735.7042236328125, "reward": 0.279086709022522, "action": -0.8758501410484314}
{"mode": "train", "epochs": 10, "timestep": 19310, "ep_reward": 735.8599853515625, "reward": 0.15576940774917603, "action": -1.111596941947937}
{"mode": "train", "epochs": 10, "timestep": 19311, "ep_reward": 735.8724975585938, "reward": 0.012505590915679932, "action": -0.9268696904182434}
{"mode": "train", "epochs": 10, "timestep": 19312, "ep_reward": 735.9763793945312, "reward": 0.10385245084762573, "action": -0.7695168256759644}
{"mode": "train", "epochs": 10, "timestep": 19313, "ep_reward": 736.2214965820312, "reward": 0.24514317512512207, "action": -0.23199009895324707}
{"mode": "train", "epochs": 10, "timestep": 19314, "ep_reward": 736.6142578125, "reward": 0.3927374482154846, "action": -0.3938256502151489}
{"mode": "train", "epochs": 10, "timestep": 19315, "ep_reward": 737.140869140625, "reward": 0.5266261100769043, "action": -1.3843340873718262}
{"mode": "train", "epochs": 10, "timestep": 19316, "ep_reward": 737.7723999023438, "reward": 0.631515622138977, "action": -0.2708317041397095}
{"mode": "train", "epochs": 10, "timestep": 19317, "ep_reward": 738.4994506835938, "reward": 0.7270523309707642, "action": -1.2785415649414062}
{"mode": "train", "epochs": 10, "timestep": 19318, "ep_reward": 739.2904052734375, "reward": 0.7909539937973022, "action": -0.6048358678817749}
{"mode": "train", "epochs": 10, "timestep": 19319, "ep_reward": 740.132080078125, "reward": 0.8417012691497803, "action": -0.4335728883743286}
{"mode": "train", "epochs": 10, "timestep": 19320, "ep_reward": 741.0086059570312, "reward": 0.8765017986297607, "action": -1.5996408462524414}
{"mode": "train", "epochs": 10, "timestep": 19321, "ep_reward": 741.8970336914062, "reward": 0.8883998990058899, "action": -0.9863190650939941}
{"mode": "train", "epochs": 10, "timestep": 19322, "ep_reward": 742.788818359375, "reward": 0.8917824029922485, "action": -1.1112291812896729}
{"mode": "train", "epochs": 10, "timestep": 19323, "ep_reward": 743.669189453125, "reward": 0.8803976774215698, "action": -0.9406439065933228}
{"mode": "train", "epochs": 10, "timestep": 19324, "ep_reward": 744.5234375, "reward": 0.8542616367340088, "action": -1.2900714874267578}
{"mode": "train", "epochs": 10, "timestep": 19325, "ep_reward": 745.327880859375, "reward": 0.8044587969779968, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 19326, "ep_reward": 746.0471801757812, "reward": 0.7192925810813904, "action": -1.004620909690857}
{"mode": "train", "epochs": 10, "timestep": 19327, "ep_reward": 746.6561889648438, "reward": 0.6090335845947266, "action": -1.9211039543151855}
{"mode": "train", "epochs": 10, "timestep": 19328, "ep_reward": 747.1005249023438, "reward": 0.44430649280548096, "action": -0.7926969528198242}
{"mode": "train", "epochs": 10, "timestep": 19329, "ep_reward": 747.4208984375, "reward": 0.3203522562980652, "action": -1.0692483186721802}
{"mode": "train", "epochs": 10, "timestep": 19330, "ep_reward": 747.6255493164062, "reward": 0.20464521646499634, "action": -0.6983804702758789}
{"mode": "train", "epochs": 10, "timestep": 19331, "ep_reward": 747.6943969726562, "reward": 0.06887149810791016, "action": -0.9525961875915527}
{"mode": "train", "epochs": 10, "timestep": 19332, "ep_reward": 747.7437133789062, "reward": 0.04930239915847778, "action": -0.960310161113739}
{"mode": "train", "epochs": 10, "timestep": 19333, "ep_reward": 747.9314575195312, "reward": 0.18772274255752563, "action": -0.8542088270187378}
{"mode": "train", "epochs": 10, "timestep": 19334, "ep_reward": 748.2611694335938, "reward": 0.32971686124801636, "action": -1.0192477703094482}
{"mode": "train", "epochs": 10, "timestep": 19335, "ep_reward": 748.724853515625, "reward": 0.46366965770721436, "action": -1.155464768409729}
{"mode": "train", "epochs": 10, "timestep": 19336, "ep_reward": 749.30615234375, "reward": 0.5813043117523193, "action": -0.1494516134262085}
{"mode": "train", "epochs": 10, "timestep": 19337, "ep_reward": 749.9947509765625, "reward": 0.6886277794837952, "action": -0.6889498829841614}
{"mode": "train", "epochs": 10, "timestep": 19338, "ep_reward": 750.7607421875, "reward": 0.7660082578659058, "action": -0.9494025111198425}
{"mode": "train", "epochs": 10, "timestep": 19339, "ep_reward": 751.5803833007812, "reward": 0.8196243047714233, "action": -0.9728488922119141}
{"mode": "train", "epochs": 10, "timestep": 19340, "ep_reward": 752.4349975585938, "reward": 0.854585587978363, "action": -1.2828733921051025}
{"mode": "train", "epochs": 10, "timestep": 19341, "ep_reward": 753.305908203125, "reward": 0.8709211349487305, "action": -0.6871434450149536}
{"mode": "train", "epochs": 10, "timestep": 19342, "ep_reward": 754.1827392578125, "reward": 0.8768512010574341, "action": -0.2634335160255432}
{"mode": "train", "epochs": 10, "timestep": 19343, "ep_reward": 755.053466796875, "reward": 0.8707410097122192, "action": -1.387521743774414}
{"mode": "train", "epochs": 10, "timestep": 19344, "ep_reward": 755.8911743164062, "reward": 0.83769690990448, "action": -0.8944880962371826}
{"mode": "train", "epochs": 10, "timestep": 19345, "ep_reward": 756.6779174804688, "reward": 0.7867721915245056, "action": -0.818778395652771}
{"mode": "train", "epochs": 10, "timestep": 19346, "ep_reward": 757.3865966796875, "reward": 0.7086583375930786, "action": -1.5255508422851562}
{"mode": "train", "epochs": 10, "timestep": 19347, "ep_reward": 757.9730224609375, "reward": 0.5864381790161133, "action": -0.9606350064277649}
{"mode": "train", "epochs": 10, "timestep": 19348, "ep_reward": 758.4027709960938, "reward": 0.4297531843185425, "action": -1.0730953216552734}
{"mode": "train", "epochs": 10, "timestep": 19349, "ep_reward": 758.7078247070312, "reward": 0.30502617359161377, "action": -0.8376973867416382}
{"mode": "train", "epochs": 10, "timestep": 19350, "ep_reward": 758.8941040039062, "reward": 0.1862567663192749, "action": -1.7901663780212402}
{"mode": "train", "epochs": 10, "timestep": 19351, "ep_reward": 758.9417724609375, "reward": 0.047665178775787354, "action": -1.6950829029083252}
{"mode": "train", "epochs": 10, "timestep": 19352, "ep_reward": 759.011962890625, "reward": 0.07016432285308838, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 19353, "ep_reward": 759.2178955078125, "reward": 0.20593196153640747, "action": -0.6409931182861328}
{"mode": "train", "epochs": 10, "timestep": 19354, "ep_reward": 759.5685424804688, "reward": 0.3506668210029602, "action": -1.3561683893203735}
{"mode": "train", "epochs": 10, "timestep": 19355, "ep_reward": 760.04736328125, "reward": 0.4788389801979065, "action": -1.2938768863677979}
{"mode": "train", "epochs": 10, "timestep": 19356, "ep_reward": 760.64013671875, "reward": 0.5927451252937317, "action": -0.810694694519043}
{"mode": "train", "epochs": 10, "timestep": 19357, "ep_reward": 761.330810546875, "reward": 0.6906567811965942, "action": -1.3822959661483765}
{"mode": "train", "epochs": 10, "timestep": 19358, "ep_reward": 762.0904541015625, "reward": 0.7596300840377808, "action": -0.6153522729873657}
{"mode": "train", "epochs": 10, "timestep": 19359, "ep_reward": 762.9046020507812, "reward": 0.8141619563102722, "action": -1.5810428857803345}
{"mode": "train", "epochs": 10, "timestep": 19360, "ep_reward": 763.7448120117188, "reward": 0.8402346968650818, "action": -1.5135140419006348}
{"mode": "train", "epochs": 10, "timestep": 19361, "ep_reward": 764.5936889648438, "reward": 0.8488837480545044, "action": -1.8373980522155762}
{"mode": "train", "epochs": 10, "timestep": 19362, "ep_reward": 765.4295043945312, "reward": 0.8358265161514282, "action": -1.3198237419128418}
{"mode": "train", "epochs": 10, "timestep": 19363, "ep_reward": 766.2352294921875, "reward": 0.8057243824005127, "action": -0.9038299918174744}
{"mode": "train", "epochs": 10, "timestep": 19364, "ep_reward": 766.9889526367188, "reward": 0.7537381052970886, "action": -0.7479825019836426}
{"mode": "train", "epochs": 10, "timestep": 19365, "ep_reward": 767.6608276367188, "reward": 0.671857476234436, "action": -0.8885325193405151}
{"mode": "train", "epochs": 10, "timestep": 19366, "ep_reward": 768.2108154296875, "reward": 0.549971342086792, "action": -1.053924560546875}
{"mode": "train", "epochs": 10, "timestep": 19367, "ep_reward": 768.6082763671875, "reward": 0.3974807858467102, "action": -0.794923722743988}
{"mode": "train", "epochs": 10, "timestep": 19368, "ep_reward": 768.9058227539062, "reward": 0.297516405582428, "action": 0.40171873569488525}
{"mode": "train", "epochs": 10, "timestep": 19369, "ep_reward": 769.083251953125, "reward": 0.17744189500808716, "action": -1.2090296745300293}
{"mode": "train", "epochs": 10, "timestep": 19370, "ep_reward": 769.1207885742188, "reward": 0.037533342838287354, "action": -0.34269243478775024}
{"mode": "train", "epochs": 10, "timestep": 19371, "ep_reward": 769.2011108398438, "reward": 0.08032673597335815, "action": -1.1631267070770264}
{"mode": "train", "epochs": 10, "timestep": 19372, "ep_reward": 769.4171142578125, "reward": 0.21599042415618896, "action": -0.6773489713668823}
{"mode": "train", "epochs": 10, "timestep": 19373, "ep_reward": 769.7771606445312, "reward": 0.36006397008895874, "action": -1.0949660539627075}
{"mode": "train", "epochs": 10, "timestep": 19374, "ep_reward": 770.2676391601562, "reward": 0.4904692769050598, "action": -1.2165666818618774}
{"mode": "train", "epochs": 10, "timestep": 19375, "ep_reward": 770.8709716796875, "reward": 0.6033569574356079, "action": -0.6591805219650269}
{"mode": "train", "epochs": 10, "timestep": 19376, "ep_reward": 771.5717163085938, "reward": 0.7007310390472412, "action": -1.024261236190796}
{"mode": "train", "epochs": 10, "timestep": 19377, "ep_reward": 772.3427734375, "reward": 0.7710312604904175, "action": -1.4708629846572876}
{"mode": "train", "epochs": 10, "timestep": 19378, "ep_reward": 773.1590576171875, "reward": 0.8163063526153564, "action": -1.752753734588623}
{"mode": "train", "epochs": 10, "timestep": 19379, "ep_reward": 773.9996337890625, "reward": 0.8406063318252563, "action": -1.6448713541030884}
{"mode": "train", "epochs": 10, "timestep": 19380, "ep_reward": 774.84765625, "reward": 0.8480253219604492, "action": -1.615811824798584}
{"mode": "train", "epochs": 10, "timestep": 19381, "ep_reward": 775.6845703125, "reward": 0.8368911147117615, "action": -1.0134034156799316}
{"mode": "train", "epochs": 10, "timestep": 19382, "ep_reward": 776.4945678710938, "reward": 0.8099793195724487, "action": -0.5434051752090454}
{"mode": "train", "epochs": 10, "timestep": 19383, "ep_reward": 777.2573852539062, "reward": 0.762816846370697, "action": -1.1554661989212036}
{"mode": "train", "epochs": 10, "timestep": 19384, "ep_reward": 777.9354858398438, "reward": 0.6780784726142883, "action": -0.1956040859222412}
{"mode": "train", "epochs": 10, "timestep": 19385, "ep_reward": 778.5037841796875, "reward": 0.5683153867721558, "action": -0.7186828851699829}
{"mode": "train", "epochs": 10, "timestep": 19386, "ep_reward": 778.9149169921875, "reward": 0.41112643480300903, "action": -0.7802891135215759}
{"mode": "train", "epochs": 10, "timestep": 19387, "ep_reward": 779.2185668945312, "reward": 0.3036242723464966, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 19388, "ep_reward": 779.4035034179688, "reward": 0.18496239185333252, "action": -1.123643398284912}
{"mode": "train", "epochs": 10, "timestep": 19389, "ep_reward": 779.44970703125, "reward": 0.04620712995529175, "action": -0.17633163928985596}
{"mode": "train", "epochs": 10, "timestep": 19390, "ep_reward": 779.5216674804688, "reward": 0.07196295261383057, "action": -0.9024732708930969}
{"mode": "train", "epochs": 10, "timestep": 19391, "ep_reward": 779.7322387695312, "reward": 0.21055936813354492, "action": -1.1997390985488892}
{"mode": "train", "epochs": 10, "timestep": 19392, "ep_reward": 780.0800170898438, "reward": 0.3477649688720703, "action": -1.3736766576766968}
{"mode": "train", "epochs": 10, "timestep": 19393, "ep_reward": 780.556396484375, "reward": 0.4763783812522888, "action": -1.2332379817962646}
{"mode": "train", "epochs": 10, "timestep": 19394, "ep_reward": 781.1478271484375, "reward": 0.5914266705513, "action": -0.9212830662727356}
{"mode": "train", "epochs": 10, "timestep": 19395, "ep_reward": 781.8362426757812, "reward": 0.6884294152259827, "action": -0.31777024269104004}
{"mode": "train", "epochs": 10, "timestep": 19396, "ep_reward": 782.6036987304688, "reward": 0.7674418687820435, "action": -1.1566585302352905}
{"mode": "train", "epochs": 10, "timestep": 19397, "ep_reward": 783.4196166992188, "reward": 0.8159481287002563, "action": -0.9081013202667236}
{"mode": "train", "epochs": 10, "timestep": 19398, "ep_reward": 784.2671508789062, "reward": 0.8475098609924316, "action": -0.9087929725646973}
{"mode": "train", "epochs": 10, "timestep": 19399, "ep_reward": 785.1287231445312, "reward": 0.8615421056747437, "action": -0.32692933082580566}
{"mode": "train", "epochs": 10, "timestep": 19400, "ep_reward": 785.992431640625, "reward": 0.8636783957481384, "action": -0.23581010103225708}
{"mode": "train", "epochs": 10, "timestep": 19401, "ep_reward": 786.8417358398438, "reward": 0.8492828607559204, "action": -0.8237645030021667}
{"mode": "train", "epochs": 10, "timestep": 19402, "ep_reward": 787.6514282226562, "reward": 0.8097015619277954, "action": -0.10629260540008545}
{"mode": "train", "epochs": 10, "timestep": 19403, "ep_reward": 788.4043579101562, "reward": 0.7529090046882629, "action": -1.2268513441085815}
{"mode": "train", "epochs": 10, "timestep": 19404, "ep_reward": 789.0574951171875, "reward": 0.6531351208686829, "action": -1.334536075592041}
{"mode": "train", "epochs": 10, "timestep": 19405, "ep_reward": 789.5698852539062, "reward": 0.5123752951622009, "action": -1.4893118143081665}
{"mode": "train", "epochs": 10, "timestep": 19406, "ep_reward": 789.9251098632812, "reward": 0.35524171590805054, "action": -0.8308519721031189}
{"mode": "train", "epochs": 10, "timestep": 19407, "ep_reward": 790.1714477539062, "reward": 0.2463223934173584, "action": -0.6562596559524536}
{"mode": "train", "epochs": 10, "timestep": 19408, "ep_reward": 790.288818359375, "reward": 0.11738455295562744, "action": -0.6905319094657898}
{"mode": "train", "epochs": 10, "timestep": 19409, "ep_reward": 790.2864379882812, "reward": -0.002353072166442871, "action": -0.0035657882690429688}
{"mode": "train", "epochs": 10, "timestep": 19410, "ep_reward": 790.4315185546875, "reward": 0.14508056640625, "action": -0.9020189642906189}
{"mode": "train", "epochs": 10, "timestep": 19411, "ep_reward": 790.7166137695312, "reward": 0.2851223945617676, "action": -1.523301124572754}
{"mode": "train", "epochs": 10, "timestep": 19412, "ep_reward": 791.1320190429688, "reward": 0.41538769006729126, "action": -0.9415885806083679}
{"mode": "train", "epochs": 10, "timestep": 19413, "ep_reward": 791.6738891601562, "reward": 0.5418888330459595, "action": -1.3747093677520752}
{"mode": "train", "epochs": 10, "timestep": 19414, "ep_reward": 792.3181762695312, "reward": 0.6442631483078003, "action": -1.1794335842132568}
{"mode": "train", "epochs": 10, "timestep": 19415, "ep_reward": 793.044921875, "reward": 0.7267543077468872, "action": -1.3851982355117798}
{"mode": "train", "epochs": 10, "timestep": 19416, "ep_reward": 793.8299560546875, "reward": 0.7850251197814941, "action": -0.6425856351852417}
{"mode": "train", "epochs": 10, "timestep": 19417, "ep_reward": 794.6593017578125, "reward": 0.8293365240097046, "action": -1.0977144241333008}
{"mode": "train", "epochs": 10, "timestep": 19418, "ep_reward": 795.5097045898438, "reward": 0.8504164814949036, "action": -1.1184009313583374}
{"mode": "train", "epochs": 10, "timestep": 19419, "ep_reward": 796.36328125, "reward": 0.8535749316215515, "action": -0.38468611240386963}
{"mode": "train", "epochs": 10, "timestep": 19420, "ep_reward": 797.208251953125, "reward": 0.844954788684845, "action": -0.49740058183670044}
{"mode": "train", "epochs": 10, "timestep": 19421, "ep_reward": 798.0234985351562, "reward": 0.8152362704277039, "action": -0.6921851634979248}
{"mode": "train", "epochs": 10, "timestep": 19422, "ep_reward": 798.7828979492188, "reward": 0.75942462682724, "action": -0.5953888297080994}
{"mode": "train", "epochs": 10, "timestep": 19423, "ep_reward": 799.4573974609375, "reward": 0.6745032072067261, "action": -1.3472278118133545}
{"mode": "train", "epochs": 10, "timestep": 19424, "ep_reward": 800.0000610351562, "reward": 0.5426458716392517, "action": -1.318839192390442}
{"mode": "train", "epochs": 10, "timestep": 19425, "ep_reward": 800.379638671875, "reward": 0.3796035647392273, "action": -1.2848358154296875}
{"mode": "train", "epochs": 10, "timestep": 19426, "ep_reward": 800.6552734375, "reward": 0.27564817667007446, "action": -1.7411706447601318}
{"mode": "train", "epochs": 10, "timestep": 19427, "ep_reward": 800.8071899414062, "reward": 0.1518881916999817, "action": -1.1385239362716675}
{"mode": "train", "epochs": 10, "timestep": 19428, "ep_reward": 800.8152465820312, "reward": 0.008036673069000244, "action": -1.0174099206924438}
{"mode": "train", "epochs": 10, "timestep": 19429, "ep_reward": 800.923095703125, "reward": 0.10786890983581543, "action": -1.2727097272872925}
{"mode": "train", "epochs": 10, "timestep": 19430, "ep_reward": 801.1660766601562, "reward": 0.24296927452087402, "action": -0.8885590434074402}
{"mode": "train", "epochs": 10, "timestep": 19431, "ep_reward": 801.5496826171875, "reward": 0.3835828900337219, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 19432, "ep_reward": 802.0511474609375, "reward": 0.501489520072937, "action": -0.3526345491409302}
{"mode": "train", "epochs": 10, "timestep": 19433, "ep_reward": 802.67333984375, "reward": 0.6222045421600342, "action": -0.7071778774261475}
{"mode": "train", "epochs": 10, "timestep": 19434, "ep_reward": 803.3880004882812, "reward": 0.7146422863006592, "action": -0.5122910737991333}
{"mode": "train", "epochs": 10, "timestep": 19435, "ep_reward": 804.1732177734375, "reward": 0.7852444052696228, "action": -0.2696172595024109}
{"mode": "train", "epochs": 10, "timestep": 19436, "ep_reward": 805.0093994140625, "reward": 0.836193859577179, "action": -0.9482460618019104}
{"mode": "train", "epochs": 10, "timestep": 19437, "ep_reward": 805.872314453125, "reward": 0.8628901839256287, "action": -0.899736762046814}
{"mode": "train", "epochs": 10, "timestep": 19438, "ep_reward": 806.746337890625, "reward": 0.8740268349647522, "action": -1.1468859910964966}
{"mode": "train", "epochs": 10, "timestep": 19439, "ep_reward": 807.6137084960938, "reward": 0.867348313331604, "action": -1.687987208366394}
{"mode": "train", "epochs": 10, "timestep": 19440, "ep_reward": 808.4518432617188, "reward": 0.8381608128547668, "action": -0.8535261154174805}
{"mode": "train", "epochs": 10, "timestep": 19441, "ep_reward": 809.2462158203125, "reward": 0.7943756580352783, "action": -1.2754230499267578}
{"mode": "train", "epochs": 10, "timestep": 19442, "ep_reward": 809.9647216796875, "reward": 0.7185053825378418, "action": -0.0799056887626648}
{"mode": "train", "epochs": 10, "timestep": 19443, "ep_reward": 810.5877685546875, "reward": 0.6230378150939941, "action": -0.9141910076141357}
{"mode": "train", "epochs": 10, "timestep": 19444, "ep_reward": 811.0665283203125, "reward": 0.4787824749946594, "action": -1.4536397457122803}
{"mode": "train", "epochs": 10, "timestep": 19445, "ep_reward": 811.4019165039062, "reward": 0.33539658784866333, "action": -0.14822375774383545}
{"mode": "train", "epochs": 10, "timestep": 19446, "ep_reward": 811.6243896484375, "reward": 0.22245436906814575, "action": -1.0314266681671143}
{"mode": "train", "epochs": 10, "timestep": 19447, "ep_reward": 811.7139892578125, "reward": 0.0896264910697937, "action": -0.5356336832046509}
{"mode": "train", "epochs": 10, "timestep": 19448, "ep_reward": 811.7416381835938, "reward": 0.027627289295196533, "action": -1.8868153095245361}
{"mode": "train", "epochs": 10, "timestep": 19449, "ep_reward": 811.9107666015625, "reward": 0.16910213232040405, "action": -0.6560271382331848}
{"mode": "train", "epochs": 10, "timestep": 19450, "ep_reward": 812.2239379882812, "reward": 0.31317800283432007, "action": -1.5172967910766602}
{"mode": "train", "epochs": 10, "timestep": 19451, "ep_reward": 812.6658935546875, "reward": 0.44195765256881714, "action": -0.9274452924728394}
{"mode": "train", "epochs": 10, "timestep": 19452, "ep_reward": 813.2311401367188, "reward": 0.5652179718017578, "action": -1.084114909172058}
{"mode": "train", "epochs": 10, "timestep": 19453, "ep_reward": 813.897216796875, "reward": 0.6660626530647278, "action": -1.9460517168045044}
{"mode": "train", "epochs": 10, "timestep": 19454, "ep_reward": 814.6333618164062, "reward": 0.7361327409744263, "action": -0.9754853248596191}
{"mode": "train", "epochs": 10, "timestep": 19455, "ep_reward": 815.4277954101562, "reward": 0.7944127917289734, "action": -1.1223978996276855}
{"mode": "train", "epochs": 10, "timestep": 19456, "ep_reward": 816.2582397460938, "reward": 0.8304398655891418, "action": -1.364043951034546}
{"mode": "train", "epochs": 10, "timestep": 19457, "ep_reward": 817.1036987304688, "reward": 0.8454358577728271, "action": -1.0601551532745361}
{"mode": "train", "epochs": 10, "timestep": 19458, "ep_reward": 817.9481811523438, "reward": 0.8444629907608032, "action": -1.4671542644500732}
{"mode": "train", "epochs": 10, "timestep": 19459, "ep_reward": 818.767578125, "reward": 0.8194081783294678, "action": -0.8479509353637695}
{"mode": "train", "epochs": 10, "timestep": 19460, "ep_reward": 819.5437622070312, "reward": 0.7761935591697693, "action": -0.8050744533538818}
{"mode": "train", "epochs": 10, "timestep": 19461, "ep_reward": 820.2479858398438, "reward": 0.7042095065116882, "action": -0.6672555208206177}
{"mode": "train", "epochs": 10, "timestep": 19462, "ep_reward": 820.8462524414062, "reward": 0.598259449005127, "action": -1.5503947734832764}
{"mode": "train", "epochs": 10, "timestep": 19463, "ep_reward": 821.2838134765625, "reward": 0.4375828504562378, "action": -1.545135259628296}
{"mode": "train", "epochs": 10, "timestep": 19464, "ep_reward": 821.6139526367188, "reward": 0.33016377687454224, "action": -1.1818344593048096}
{"mode": "train", "epochs": 10, "timestep": 19465, "ep_reward": 821.830322265625, "reward": 0.21637171506881714, "action": -0.32228851318359375}
{"mode": "train", "epochs": 10, "timestep": 19466, "ep_reward": 821.9127197265625, "reward": 0.08240777254104614, "action": -1.2539016008377075}
{"mode": "train", "epochs": 10, "timestep": 19467, "ep_reward": 821.947998046875, "reward": 0.03528541326522827, "action": -1.0693904161453247}
{"mode": "train", "epochs": 10, "timestep": 19468, "ep_reward": 822.12353515625, "reward": 0.17553508281707764, "action": -1.2982177734375}
{"mode": "train", "epochs": 10, "timestep": 19469, "ep_reward": 822.4353637695312, "reward": 0.31183260679244995, "action": -1.2403290271759033}
{"mode": "train", "epochs": 10, "timestep": 19470, "ep_reward": 822.8804321289062, "reward": 0.4450870752334595, "action": -0.6842422485351562}
{"mode": "train", "epochs": 10, "timestep": 19471, "ep_reward": 823.4513549804688, "reward": 0.5708975195884705, "action": -1.2267311811447144}
{"mode": "train", "epochs": 10, "timestep": 19472, "ep_reward": 824.1206665039062, "reward": 0.6692966818809509, "action": -0.1578708291053772}
{"mode": "train", "epochs": 10, "timestep": 19473, "ep_reward": 824.8760375976562, "reward": 0.7553783059120178, "action": -0.8609919548034668}
{"mode": "train", "epochs": 10, "timestep": 19474, "ep_reward": 825.6875, "reward": 0.8114781379699707, "action": -0.5596814155578613}
{"mode": "train", "epochs": 10, "timestep": 19475, "ep_reward": 826.5381469726562, "reward": 0.8506277203559875, "action": -0.9600786566734314}
{"mode": "train", "epochs": 10, "timestep": 19476, "ep_reward": 827.4074096679688, "reward": 0.8692528009414673, "action": -1.3905785083770752}
{"mode": "train", "epochs": 10, "timestep": 19477, "ep_reward": 828.2760620117188, "reward": 0.8686806559562683, "action": -0.5188865661621094}
{"mode": "train", "epochs": 10, "timestep": 19478, "ep_reward": 829.1349487304688, "reward": 0.8588769435882568, "action": -0.9311456680297852}
{"mode": "train", "epochs": 10, "timestep": 19479, "ep_reward": 829.9617309570312, "reward": 0.8267727494239807, "action": -0.2915099859237671}
{"mode": "train", "epochs": 10, "timestep": 19480, "ep_reward": 830.7398071289062, "reward": 0.7780803442001343, "action": -1.3309534788131714}
{"mode": "train", "epochs": 10, "timestep": 19481, "ep_reward": 831.4293823242188, "reward": 0.6895908117294312, "action": -1.036024570465088}
{"mode": "train", "epochs": 10, "timestep": 19482, "ep_reward": 831.996826171875, "reward": 0.5674524903297424, "action": -0.03562682867050171}
{"mode": "train", "epochs": 10, "timestep": 19483, "ep_reward": 832.4168090820312, "reward": 0.4199875593185425, "action": -1.5143702030181885}
{"mode": "train", "epochs": 10, "timestep": 19484, "ep_reward": 832.7080078125, "reward": 0.29117757081985474, "action": -0.9848611950874329}
{"mode": "train", "epochs": 10, "timestep": 19485, "ep_reward": 832.8779296875, "reward": 0.16994476318359375, "action": -1.613438606262207}
{"mode": "train", "epochs": 10, "timestep": 19486, "ep_reward": 832.9068603515625, "reward": 0.02894526720046997, "action": -0.716892421245575}
{"mode": "train", "epochs": 10, "timestep": 19487, "ep_reward": 832.9953002929688, "reward": 0.08845287561416626, "action": -1.4167691469192505}
{"mode": "train", "epochs": 10, "timestep": 19488, "ep_reward": 833.2168579101562, "reward": 0.22157526016235352, "action": -0.677289605140686}
{"mode": "train", "epochs": 10, "timestep": 19489, "ep_reward": 833.5828857421875, "reward": 0.36601901054382324, "action": -0.5903592705726624}
{"mode": "train", "epochs": 10, "timestep": 19490, "ep_reward": 834.084716796875, "reward": 0.5018304586410522, "action": -1.9021496772766113}
{"mode": "train", "epochs": 10, "timestep": 19491, "ep_reward": 834.6900024414062, "reward": 0.6053041219711304, "action": -1.462378740310669}
{"mode": "train", "epochs": 10, "timestep": 19492, "ep_reward": 835.3839111328125, "reward": 0.6939082145690918, "action": -0.6904151439666748}
{"mode": "train", "epochs": 10, "timestep": 19493, "ep_reward": 836.1514892578125, "reward": 0.7675939202308655, "action": -0.8161875009536743}
{"mode": "train", "epochs": 10, "timestep": 19494, "ep_reward": 836.9691772460938, "reward": 0.8176630735397339, "action": -0.44353896379470825}
{"mode": "train", "epochs": 10, "timestep": 19495, "ep_reward": 837.8204345703125, "reward": 0.8512791395187378, "action": -0.13418656587600708}
{"mode": "train", "epochs": 10, "timestep": 19496, "ep_reward": 838.6901245117188, "reward": 0.8696925640106201, "action": -1.3685719966888428}
{"mode": "train", "epochs": 10, "timestep": 19497, "ep_reward": 839.5513916015625, "reward": 0.8612699508666992, "action": -0.6574152708053589}
{"mode": "train", "epochs": 10, "timestep": 19498, "ep_reward": 840.3923950195312, "reward": 0.840980052947998, "action": -0.8103589415550232}
{"mode": "train", "epochs": 10, "timestep": 19499, "ep_reward": 841.1904907226562, "reward": 0.7981157898902893, "action": -0.7590097188949585}
{"mode": "train", "epochs": 10, "timestep": 19500, "ep_reward": 841.9197387695312, "reward": 0.7292546033859253, "action": -0.7751975655555725}
{"mode": "train", "epochs": 10, "timestep": 19501, "ep_reward": 842.5469970703125, "reward": 0.627263069152832, "action": -0.8381907939910889}
{"mode": "train", "epochs": 10, "timestep": 19502, "ep_reward": 843.0325927734375, "reward": 0.48560309410095215, "action": -1.0592468976974487}
{"mode": "train", "epochs": 10, "timestep": 19503, "ep_reward": 843.3711547851562, "reward": 0.338537335395813, "action": -1.3269672393798828}
{"mode": "train", "epochs": 10, "timestep": 19504, "ep_reward": 843.5974731445312, "reward": 0.22631001472473145, "action": -1.2258331775665283}
{"mode": "train", "epochs": 10, "timestep": 19505, "ep_reward": 843.6915283203125, "reward": 0.09403800964355469, "action": -1.402888536453247}
{"mode": "train", "epochs": 10, "timestep": 19506, "ep_reward": 843.714599609375, "reward": 0.023044705390930176, "action": -0.18435633182525635}
{"mode": "train", "epochs": 10, "timestep": 19507, "ep_reward": 843.8836669921875, "reward": 0.1690937876701355, "action": -0.2669520378112793}
{"mode": "train", "epochs": 10, "timestep": 19508, "ep_reward": 844.2005615234375, "reward": 0.31691545248031616, "action": -1.7305691242218018}
{"mode": "train", "epochs": 10, "timestep": 19509, "ep_reward": 844.6423950195312, "reward": 0.44181638956069946, "action": -0.39543431997299194}
{"mode": "train", "epochs": 10, "timestep": 19510, "ep_reward": 845.212890625, "reward": 0.5704841017723083, "action": -1.5288676023483276}
{"mode": "train", "epochs": 10, "timestep": 19511, "ep_reward": 845.8790283203125, "reward": 0.6661232113838196, "action": -1.489084243774414}
{"mode": "train", "epochs": 10, "timestep": 19512, "ep_reward": 846.6204833984375, "reward": 0.7414348125457764, "action": -1.568006992340088}
{"mode": "train", "epochs": 10, "timestep": 19513, "ep_reward": 847.415771484375, "reward": 0.7953049540519714, "action": -1.3544297218322754}
{"mode": "train", "epochs": 10, "timestep": 19514, "ep_reward": 848.2473754882812, "reward": 0.8315806984901428, "action": -1.9313822984695435}
{"mode": "train", "epochs": 10, "timestep": 19515, "ep_reward": 849.0921630859375, "reward": 0.8448036313056946, "action": -0.5310196876525879}
{"mode": "train", "epochs": 10, "timestep": 19516, "ep_reward": 849.9444580078125, "reward": 0.8523053526878357, "action": -1.0954205989837646}
{"mode": "train", "epochs": 10, "timestep": 19517, "ep_reward": 850.7801513671875, "reward": 0.8357111215591431, "action": -1.4437919855117798}
{"mode": "train", "epochs": 10, "timestep": 19518, "ep_reward": 851.573486328125, "reward": 0.7933149933815002, "action": -1.6353089809417725}
{"mode": "train", "epochs": 10, "timestep": 19519, "ep_reward": 852.2932739257812, "reward": 0.7198166847229004, "action": -1.2961541414260864}
{"mode": "train", "epochs": 10, "timestep": 19520, "ep_reward": 852.9066772460938, "reward": 0.6133906841278076, "action": -0.9022448062896729}
{"mode": "train", "epochs": 10, "timestep": 19521, "ep_reward": 853.3764038085938, "reward": 0.46971309185028076, "action": -0.8275607824325562}
{"mode": "train", "epochs": 10, "timestep": 19522, "ep_reward": 853.7283325195312, "reward": 0.35190606117248535, "action": -1.5047707557678223}
{"mode": "train", "epochs": 10, "timestep": 19523, "ep_reward": 853.9706420898438, "reward": 0.2423250675201416, "action": -1.468099594116211}
{"mode": "train", "epochs": 10, "timestep": 19524, "ep_reward": 854.0833740234375, "reward": 0.1127549409866333, "action": -1.3714407682418823}
{"mode": "train", "epochs": 10, "timestep": 19525, "ep_reward": 854.0858764648438, "reward": 0.002473294734954834, "action": -1.8990201950073242}
{"mode": "train", "epochs": 10, "timestep": 19526, "ep_reward": 854.2330322265625, "reward": 0.14714807271957397, "action": -1.3804278373718262}
{"mode": "train", "epochs": 10, "timestep": 19527, "ep_reward": 854.5149536132812, "reward": 0.2819032669067383, "action": -1.0327004194259644}
{"mode": "train", "epochs": 10, "timestep": 19528, "ep_reward": 854.934326171875, "reward": 0.41936808824539185, "action": -1.482337474822998}
{"mode": "train", "epochs": 10, "timestep": 19529, "ep_reward": 855.4737548828125, "reward": 0.539432168006897, "action": -0.8765431642532349}
{"mode": "train", "epochs": 10, "timestep": 19530, "ep_reward": 856.1212768554688, "reward": 0.6474921703338623, "action": -0.6966345310211182}
{"mode": "train", "epochs": 10, "timestep": 19531, "ep_reward": 856.85498046875, "reward": 0.7336909770965576, "action": -0.8720560073852539}
{"mode": "train", "epochs": 10, "timestep": 19532, "ep_reward": 857.6497802734375, "reward": 0.7948131561279297, "action": -1.031693458557129}
{"mode": "train", "epochs": 10, "timestep": 19533, "ep_reward": 858.483642578125, "reward": 0.8338655233383179, "action": -0.7165300846099854}
{"mode": "train", "epochs": 10, "timestep": 19534, "ep_reward": 859.3408813476562, "reward": 0.8572537302970886, "action": -0.9433444738388062}
{"mode": "train", "epochs": 10, "timestep": 19535, "ep_reward": 860.2023315429688, "reward": 0.8614709973335266, "action": -1.1349899768829346}
{"mode": "train", "epochs": 10, "timestep": 19536, "ep_reward": 861.0486450195312, "reward": 0.8462952375411987, "action": -1.1052607297897339}
{"mode": "train", "epochs": 10, "timestep": 19537, "ep_reward": 861.859375, "reward": 0.8107085824012756, "action": -0.8923473954200745}
{"mode": "train", "epochs": 10, "timestep": 19538, "ep_reward": 862.6109619140625, "reward": 0.7515680193901062, "action": -1.8209760189056396}
{"mode": "train", "epochs": 10, "timestep": 19539, "ep_reward": 863.2596435546875, "reward": 0.6486775875091553, "action": -1.0782657861709595}
{"mode": "train", "epochs": 10, "timestep": 19540, "ep_reward": 863.7732543945312, "reward": 0.5135942697525024, "action": -0.4465116858482361}
{"mode": "train", "epochs": 10, "timestep": 19541, "ep_reward": 864.1450805664062, "reward": 0.37183743715286255, "action": -0.7387441396713257}
{"mode": "train", "epochs": 10, "timestep": 19542, "ep_reward": 864.411376953125, "reward": 0.2663267254829407, "action": -0.5805039405822754}
{"mode": "train", "epochs": 10, "timestep": 19543, "ep_reward": 864.5520629882812, "reward": 0.14067625999450684, "action": -1.5405077934265137}
{"mode": "train", "epochs": 10, "timestep": 19544, "ep_reward": 864.5473022460938, "reward": -0.004780769348144531, "action": -1.1502588987350464}
{"mode": "train", "epochs": 10, "timestep": 19545, "ep_reward": 864.666748046875, "reward": 0.11945921182632446, "action": -0.8927496671676636}
{"mode": "train", "epochs": 10, "timestep": 19546, "ep_reward": 864.9263916015625, "reward": 0.25963449478149414, "action": -0.4880605936050415}
{"mode": "train", "epochs": 10, "timestep": 19547, "ep_reward": 865.3301391601562, "reward": 0.403736412525177, "action": -1.3467020988464355}
{"mode": "train", "epochs": 10, "timestep": 19548, "ep_reward": 865.8562622070312, "reward": 0.5261105298995972, "action": -1.7364048957824707}
{"mode": "train", "epochs": 10, "timestep": 19549, "ep_reward": 866.4837646484375, "reward": 0.6274969577789307, "action": -0.9380331635475159}
{"mode": "train", "epochs": 10, "timestep": 19550, "ep_reward": 867.2003784179688, "reward": 0.716610312461853, "action": -0.5656521320343018}
{"mode": "train", "epochs": 10, "timestep": 19551, "ep_reward": 867.9865112304688, "reward": 0.7861075401306152, "action": -1.5105111598968506}
{"mode": "train", "epochs": 10, "timestep": 19552, "ep_reward": 868.8126220703125, "reward": 0.8261057138442993, "action": 0.4476332664489746}
{"mode": "train", "epochs": 10, "timestep": 19553, "ep_reward": 869.67724609375, "reward": 0.8646360635757446, "action": -0.16107779741287231}
{"mode": "train", "epochs": 10, "timestep": 19554, "ep_reward": 870.5580444335938, "reward": 0.8808185458183289, "action": -1.750488519668579}
{"mode": "train", "epochs": 10, "timestep": 19555, "ep_reward": 871.4270629882812, "reward": 0.8689965009689331, "action": -1.3076592683792114}
{"mode": "train", "epochs": 10, "timestep": 19556, "ep_reward": 872.270263671875, "reward": 0.8432233929634094, "action": -0.8009862899780273}
{"mode": "train", "epochs": 10, "timestep": 19557, "ep_reward": 873.0709228515625, "reward": 0.8006293177604675, "action": -1.776497721672058}
{"mode": "train", "epochs": 10, "timestep": 19558, "ep_reward": 873.7913208007812, "reward": 0.7204121351242065, "action": -0.8693817853927612}
{"mode": "train", "epochs": 10, "timestep": 19559, "ep_reward": 874.40625, "reward": 0.6149169206619263, "action": -0.5977398753166199}
{"mode": "train", "epochs": 10, "timestep": 19560, "ep_reward": 874.8798828125, "reward": 0.4736109972000122, "action": -1.0343949794769287}
{"mode": "train", "epochs": 10, "timestep": 19561, "ep_reward": 875.2146606445312, "reward": 0.3347738981246948, "action": -0.7082884907722473}
{"mode": "train", "epochs": 10, "timestep": 19562, "ep_reward": 875.4364013671875, "reward": 0.22176122665405273, "action": -0.9105544686317444}
{"mode": "train", "epochs": 10, "timestep": 19563, "ep_reward": 875.5252075195312, "reward": 0.08880484104156494, "action": -0.5146530270576477}
{"mode": "train", "epochs": 10, "timestep": 19564, "ep_reward": 875.5537719726562, "reward": 0.02856767177581787, "action": -1.5637871026992798}
{"mode": "train", "epochs": 10, "timestep": 19565, "ep_reward": 875.7236328125, "reward": 0.16988450288772583, "action": -0.02768009901046753}
{"mode": "train", "epochs": 10, "timestep": 19566, "ep_reward": 876.0453491210938, "reward": 0.3217269778251648, "action": -1.2067888975143433}
{"mode": "train", "epochs": 10, "timestep": 19567, "ep_reward": 876.4978637695312, "reward": 0.45252859592437744, "action": -1.3615163564682007}
{"mode": "train", "epochs": 10, "timestep": 19568, "ep_reward": 877.0667724609375, "reward": 0.5689128637313843, "action": -1.0438872575759888}
{"mode": "train", "epochs": 10, "timestep": 19569, "ep_reward": 877.7365112304688, "reward": 0.6697239279747009, "action": -1.3032419681549072}
{"mode": "train", "epochs": 10, "timestep": 19570, "ep_reward": 878.4824829101562, "reward": 0.7459762096405029, "action": -0.27863609790802}
{"mode": "train", "epochs": 10, "timestep": 19571, "ep_reward": 879.2926635742188, "reward": 0.8101797699928284, "action": -0.8397253751754761}
{"mode": "train", "epochs": 10, "timestep": 19572, "ep_reward": 880.1419677734375, "reward": 0.8493314385414124, "action": -0.47551411390304565}
{"mode": "train", "epochs": 10, "timestep": 19573, "ep_reward": 881.0164794921875, "reward": 0.8745330572128296, "action": -1.2948918342590332}
{"mode": "train", "epochs": 10, "timestep": 19574, "ep_reward": 881.8944091796875, "reward": 0.8779345750808716, "action": -1.8013572692871094}
{"mode": "train", "epochs": 10, "timestep": 19575, "ep_reward": 882.7559814453125, "reward": 0.8615485429763794, "action": -1.2463512420654297}
{"mode": "train", "epochs": 10, "timestep": 19576, "ep_reward": 883.5869750976562, "reward": 0.8309957981109619, "action": -1.030135154724121}
{"mode": "train", "epochs": 10, "timestep": 19577, "ep_reward": 884.3662109375, "reward": 0.7792313098907471, "action": -1.17624831199646}
{"mode": "train", "epochs": 10, "timestep": 19578, "ep_reward": 885.0625610351562, "reward": 0.6963777542114258, "action": -0.9246891736984253}
{"mode": "train", "epochs": 10, "timestep": 19579, "ep_reward": 885.6425170898438, "reward": 0.5799720287322998, "action": -0.6465904712677002}
{"mode": "train", "epochs": 10, "timestep": 19580, "ep_reward": 886.0693359375, "reward": 0.42682576179504395, "action": -0.8815716505050659}
{"mode": "train", "epochs": 10, "timestep": 19581, "ep_reward": 886.375244140625, "reward": 0.3059147000312805, "action": 0.08498477935791016}
{"mode": "train", "epochs": 10, "timestep": 19582, "ep_reward": 886.5626220703125, "reward": 0.18740153312683105, "action": -0.9504984021186829}
{"mode": "train", "epochs": 10, "timestep": 19583, "ep_reward": 886.6115112304688, "reward": 0.04886341094970703, "action": -1.4856085777282715}
{"mode": "train", "epochs": 10, "timestep": 19584, "ep_reward": 886.6807861328125, "reward": 0.0692717432975769, "action": -0.37198275327682495}
{"mode": "train", "epochs": 10, "timestep": 19585, "ep_reward": 886.895263671875, "reward": 0.21444934606552124, "action": -0.32773441076278687}
{"mode": "train", "epochs": 10, "timestep": 19586, "ep_reward": 887.2562866210938, "reward": 0.3610208034515381, "action": -0.6884194612503052}
{"mode": "train", "epochs": 10, "timestep": 19587, "ep_reward": 887.7507934570312, "reward": 0.49450254440307617, "action": -0.754418134689331}
{"mode": "train", "epochs": 10, "timestep": 19588, "ep_reward": 888.3617553710938, "reward": 0.6109638810157776, "action": -1.0034098625183105}
{"mode": "train", "epochs": 10, "timestep": 19589, "ep_reward": 889.0657958984375, "reward": 0.7040193676948547, "action": -1.666764497756958}
{"mode": "train", "epochs": 10, "timestep": 19590, "ep_reward": 889.8358764648438, "reward": 0.7700610160827637, "action": -1.460273265838623}
{"mode": "train", "epochs": 10, "timestep": 19591, "ep_reward": 890.6549072265625, "reward": 0.8190546035766602, "action": -1.649179458618164}
{"mode": "train", "epochs": 10, "timestep": 19592, "ep_reward": 891.5040283203125, "reward": 0.8491053581237793, "action": -1.0478460788726807}
{"mode": "train", "epochs": 10, "timestep": 19593, "ep_reward": 892.3720092773438, "reward": 0.8679589033126831, "action": -1.0429692268371582}
{"mode": "train", "epochs": 10, "timestep": 19594, "ep_reward": 893.2429809570312, "reward": 0.8709653615951538, "action": -1.768172264099121}
{"mode": "train", "epochs": 10, "timestep": 19595, "ep_reward": 894.0941772460938, "reward": 0.8511995077133179, "action": -0.06728476285934448}
{"mode": "train", "epochs": 10, "timestep": 19596, "ep_reward": 894.9214477539062, "reward": 0.8272768259048462, "action": -0.3109027147293091}
{"mode": "train", "epochs": 10, "timestep": 19597, "ep_reward": 895.7005004882812, "reward": 0.7790766358375549, "action": -0.44080060720443726}
{"mode": "train", "epochs": 10, "timestep": 19598, "ep_reward": 896.4027709960938, "reward": 0.7022432684898376, "action": -0.40789830684661865}
{"mode": "train", "epochs": 10, "timestep": 19599, "ep_reward": 896.9953002929688, "reward": 0.5925508737564087, "action": -1.2736340761184692}
{"mode": "train", "epochs": 10, "timestep": 19600, "ep_reward": 897.427490234375, "reward": 0.43216729164123535, "action": -0.5673459768295288}
{"mode": "train", "epochs": 10, "timestep": 19601, "ep_reward": 897.7266235351562, "reward": 0.2991405725479126, "action": -1.695387840270996}
{"mode": "train", "epochs": 10, "timestep": 19602, "ep_reward": 897.90625, "reward": 0.17963457107543945, "action": -0.5527981519699097}
{"mode": "train", "epochs": 10, "timestep": 19603, "ep_reward": 897.9461059570312, "reward": 0.03985995054244995, "action": -1.4297128915786743}
{"mode": "train", "epochs": 10, "timestep": 19604, "ep_reward": 898.0240478515625, "reward": 0.07794243097305298, "action": -1.3371174335479736}
{"mode": "train", "epochs": 10, "timestep": 19605, "ep_reward": 898.236572265625, "reward": 0.21253377199172974, "action": -0.40296030044555664}
{"mode": "train", "epochs": 10, "timestep": 19606, "ep_reward": 898.5967407226562, "reward": 0.3601810336112976, "action": -1.5839133262634277}
{"mode": "train", "epochs": 10, "timestep": 19607, "ep_reward": 899.081298828125, "reward": 0.4845876693725586, "action": -1.5712521076202393}
{"mode": "train", "epochs": 10, "timestep": 19608, "ep_reward": 899.67578125, "reward": 0.594456136226654, "action": -1.4890838861465454}
{"mode": "train", "epochs": 10, "timestep": 19609, "ep_reward": 900.3606567382812, "reward": 0.6848760843276978, "action": -0.7982462644577026}
{"mode": "train", "epochs": 10, "timestep": 19610, "ep_reward": 901.1201171875, "reward": 0.7594388723373413, "action": -1.019651174545288}
{"mode": "train", "epochs": 10, "timestep": 19611, "ep_reward": 901.92919921875, "reward": 0.809092104434967, "action": -1.120310664176941}
{"mode": "train", "epochs": 10, "timestep": 19612, "ep_reward": 902.766845703125, "reward": 0.837677001953125, "action": -0.4651915431022644}
{"mode": "train", "epochs": 10, "timestep": 19613, "ep_reward": 903.6199951171875, "reward": 0.8531451225280762, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 19614, "ep_reward": 904.4562377929688, "reward": 0.8362619876861572, "action": -0.7926687002182007}
{"mode": "train", "epochs": 10, "timestep": 19615, "ep_reward": 905.2652587890625, "reward": 0.8090384006500244, "action": -0.7269246578216553}
{"mode": "train", "epochs": 10, "timestep": 19616, "ep_reward": 906.0225219726562, "reward": 0.757282555103302, "action": -1.0103150606155396}
{"mode": "train", "epochs": 10, "timestep": 19617, "ep_reward": 906.6935424804688, "reward": 0.6710474491119385, "action": -0.26008814573287964}
{"mode": "train", "epochs": 10, "timestep": 19618, "ep_reward": 907.2504272460938, "reward": 0.5568914413452148, "action": -1.8101444244384766}
{"mode": "train", "epochs": 10, "timestep": 19619, "ep_reward": 907.6439819335938, "reward": 0.39355403184890747, "action": -1.2163833379745483}
{"mode": "train", "epochs": 10, "timestep": 19620, "ep_reward": 907.936767578125, "reward": 0.2927703857421875, "action": -0.6387314796447754}
{"mode": "train", "epochs": 10, "timestep": 19621, "ep_reward": 908.1087036132812, "reward": 0.17191362380981445, "action": -0.7190874814987183}
{"mode": "train", "epochs": 10, "timestep": 19622, "ep_reward": 908.1397705078125, "reward": 0.03109276294708252, "action": 0.24352359771728516}
{"mode": "train", "epochs": 10, "timestep": 19623, "ep_reward": 908.226318359375, "reward": 0.08654314279556274, "action": -0.642941951751709}
{"mode": "train", "epochs": 10, "timestep": 19624, "ep_reward": 908.4552001953125, "reward": 0.2288578748703003, "action": -0.8203108906745911}
{"mode": "train", "epochs": 10, "timestep": 19625, "ep_reward": 908.8247680664062, "reward": 0.3695926070213318, "action": -1.2515827417373657}
{"mode": "train", "epochs": 10, "timestep": 19626, "ep_reward": 909.3216552734375, "reward": 0.49685919284820557, "action": -0.3272056579589844}
{"mode": "train", "epochs": 10, "timestep": 19627, "ep_reward": 909.9398193359375, "reward": 0.6181879043579102, "action": -0.5842606425285339}
{"mode": "train", "epochs": 10, "timestep": 19628, "ep_reward": 910.6531982421875, "reward": 0.7133883237838745, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 19629, "ep_reward": 911.426513671875, "reward": 0.7733340263366699, "action": -1.2782946825027466}
{"mode": "train", "epochs": 10, "timestep": 19630, "ep_reward": 912.2474365234375, "reward": 0.8208945989608765, "action": -1.230426549911499}
{"mode": "train", "epochs": 10, "timestep": 19631, "ep_reward": 913.0980834960938, "reward": 0.8506669998168945, "action": -1.3240621089935303}
{"mode": "train", "epochs": 10, "timestep": 19632, "ep_reward": 913.9610595703125, "reward": 0.8629940748214722, "action": -0.19824272394180298}
{"mode": "train", "epochs": 10, "timestep": 19633, "ep_reward": 914.829345703125, "reward": 0.8682853579521179, "action": -1.49343740940094}
{"mode": "train", "epochs": 10, "timestep": 19634, "ep_reward": 915.674560546875, "reward": 0.8452044725418091, "action": -0.7099833488464355}
{"mode": "train", "epochs": 10, "timestep": 19635, "ep_reward": 916.4828491210938, "reward": 0.8082671165466309, "action": -1.5713043212890625}
{"mode": "train", "epochs": 10, "timestep": 19636, "ep_reward": 917.2190551757812, "reward": 0.7361811399459839, "action": -1.640343189239502}
{"mode": "train", "epochs": 10, "timestep": 19637, "ep_reward": 917.8468017578125, "reward": 0.6277247667312622, "action": -0.8263024091720581}
{"mode": "train", "epochs": 10, "timestep": 19638, "ep_reward": 918.3350219726562, "reward": 0.48821544647216797, "action": -1.4044567346572876}
{"mode": "train", "epochs": 10, "timestep": 19639, "ep_reward": 918.6869506835938, "reward": 0.35195237398147583, "action": -1.3071577548980713}
{"mode": "train", "epochs": 10, "timestep": 19640, "ep_reward": 918.9293823242188, "reward": 0.24245113134384155, "action": -0.6011826992034912}
{"mode": "train", "epochs": 10, "timestep": 19641, "ep_reward": 919.0421142578125, "reward": 0.11275434494018555, "action": -1.4668651819229126}
{"mode": "train", "epochs": 10, "timestep": 19642, "ep_reward": 919.0447998046875, "reward": 0.0026551485061645508, "action": -0.6387183666229248}
{"mode": "train", "epochs": 10, "timestep": 19643, "ep_reward": 919.1919555664062, "reward": 0.1471843719482422, "action": -1.1128097772598267}
{"mode": "train", "epochs": 10, "timestep": 19644, "ep_reward": 919.477294921875, "reward": 0.2853280305862427, "action": 0.17422902584075928}
{"mode": "train", "epochs": 10, "timestep": 19645, "ep_reward": 919.9138793945312, "reward": 0.43659740686416626, "action": -0.6739392876625061}
{"mode": "train", "epochs": 10, "timestep": 19646, "ep_reward": 920.4762573242188, "reward": 0.5623617768287659, "action": -0.12718039751052856}
{"mode": "train", "epochs": 10, "timestep": 19647, "ep_reward": 921.1498413085938, "reward": 0.6735950708389282, "action": -1.3801690340042114}
{"mode": "train", "epochs": 10, "timestep": 19648, "ep_reward": 921.8998413085938, "reward": 0.7499701976776123, "action": -0.1307937502861023}
{"mode": "train", "epochs": 10, "timestep": 19649, "ep_reward": 922.7169799804688, "reward": 0.817121684551239, "action": -1.5528017282485962}
{"mode": "train", "epochs": 10, "timestep": 19650, "ep_reward": 923.5709838867188, "reward": 0.8539742231369019, "action": -1.2851282358169556}
{"mode": "train", "epochs": 10, "timestep": 19651, "ep_reward": 924.44921875, "reward": 0.8782053589820862, "action": -0.9792729616165161}
{"mode": "train", "epochs": 10, "timestep": 19652, "ep_reward": 925.34033203125, "reward": 0.8911415934562683, "action": -0.18991518020629883}
{"mode": "train", "epochs": 10, "timestep": 19653, "ep_reward": 926.2372436523438, "reward": 0.8969031572341919, "action": -0.34474319219589233}
{"mode": "train", "epochs": 10, "timestep": 19654, "ep_reward": 927.1256103515625, "reward": 0.8883680105209351, "action": -0.8967446088790894}
{"mode": "train", "epochs": 10, "timestep": 19655, "ep_reward": 927.9861450195312, "reward": 0.8605405688285828, "action": -1.2789593935012817}
{"mode": "train", "epochs": 10, "timestep": 19656, "ep_reward": 928.7958374023438, "reward": 0.8096941709518433, "action": -1.3491677045822144}
{"mode": "train", "epochs": 10, "timestep": 19657, "ep_reward": 929.52734375, "reward": 0.7315356731414795, "action": 0.12550324201583862}
{"mode": "train", "epochs": 10, "timestep": 19658, "ep_reward": 930.1658325195312, "reward": 0.6385016441345215, "action": -0.20656132698059082}
{"mode": "train", "epochs": 10, "timestep": 19659, "ep_reward": 930.6737060546875, "reward": 0.5078514814376831, "action": -0.10632061958312988}
{"mode": "train", "epochs": 10, "timestep": 19660, "ep_reward": 931.0179443359375, "reward": 0.344261109828949, "action": -1.3215287923812866}
{"mode": "train", "epochs": 10, "timestep": 19661, "ep_reward": 931.2335815429688, "reward": 0.21561026573181152, "action": -1.1298408508300781}
{"mode": "train", "epochs": 10, "timestep": 19662, "ep_reward": 931.315185546875, "reward": 0.0816124677658081, "action": -1.154749870300293}
{"mode": "train", "epochs": 10, "timestep": 19663, "ep_reward": 931.351318359375, "reward": 0.03612041473388672, "action": -1.2237261533737183}
{"mode": "train", "epochs": 10, "timestep": 19664, "ep_reward": 931.5276489257812, "reward": 0.17635959386825562, "action": -0.7350047826766968}
{"mode": "train", "epochs": 10, "timestep": 19665, "ep_reward": 931.8473510742188, "reward": 0.3196728229522705, "action": -0.9246693849563599}
{"mode": "train", "epochs": 10, "timestep": 19666, "ep_reward": 932.3024291992188, "reward": 0.45507335662841797, "action": -1.7369916439056396}
{"mode": "train", "epochs": 10, "timestep": 19667, "ep_reward": 932.8696899414062, "reward": 0.5672721266746521, "action": -0.7831565737724304}
{"mode": "train", "epochs": 10, "timestep": 19668, "ep_reward": 933.5406494140625, "reward": 0.6709691882133484, "action": -0.34627723693847656}
{"mode": "train", "epochs": 10, "timestep": 19669, "ep_reward": 934.2957763671875, "reward": 0.7551038265228271, "action": -1.4421221017837524}
{"mode": "train", "epochs": 10, "timestep": 19670, "ep_reward": 935.102294921875, "reward": 0.8065180778503418, "action": -0.8509618639945984}
{"mode": "train", "epochs": 10, "timestep": 19671, "ep_reward": 935.9463500976562, "reward": 0.8440789580345154, "action": -1.2513035535812378}
{"mode": "train", "epochs": 10, "timestep": 19672, "ep_reward": 936.80712890625, "reward": 0.860794186592102, "action": -0.5602893233299255}
{"mode": "train", "epochs": 10, "timestep": 19673, "ep_reward": 937.6739501953125, "reward": 0.8668282628059387, "action": -0.22726565599441528}
{"mode": "train", "epochs": 10, "timestep": 19674, "ep_reward": 938.53271484375, "reward": 0.8587812781333923, "action": -1.8937010765075684}
{"mode": "train", "epochs": 10, "timestep": 19675, "ep_reward": 939.3492431640625, "reward": 0.816550612449646, "action": -1.1005216836929321}
{"mode": "train", "epochs": 10, "timestep": 19676, "ep_reward": 940.1052856445312, "reward": 0.7560485601425171, "action": -1.3868408203125}
{"mode": "train", "epochs": 10, "timestep": 19677, "ep_reward": 940.7652587890625, "reward": 0.6599985361099243, "action": -0.6070316433906555}
{"mode": "train", "epochs": 10, "timestep": 19678, "ep_reward": 941.300048828125, "reward": 0.5347797870635986, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 19679, "ep_reward": 941.676025390625, "reward": 0.3759562373161316, "action": -0.8964024186134338}
{"mode": "train", "epochs": 10, "timestep": 19680, "ep_reward": 941.9473266601562, "reward": 0.2713283896446228, "action": -0.4928077459335327}
{"mode": "train", "epochs": 10, "timestep": 19681, "ep_reward": 942.093994140625, "reward": 0.14667272567749023, "action": -0.2963097095489502}
{"mode": "train", "epochs": 10, "timestep": 19682, "ep_reward": 942.0958862304688, "reward": 0.001915276050567627, "action": -1.2340800762176514}
{"mode": "train", "epochs": 10, "timestep": 19683, "ep_reward": 942.2093505859375, "reward": 0.11345773935317993, "action": -0.8628451228141785}
{"mode": "train", "epochs": 10, "timestep": 19684, "ep_reward": 942.4631958007812, "reward": 0.2538611888885498, "action": -0.06132453680038452}
{"mode": "train", "epochs": 10, "timestep": 19685, "ep_reward": 942.8665771484375, "reward": 0.40335822105407715, "action": -0.010585427284240723}
{"mode": "train", "epochs": 10, "timestep": 19686, "ep_reward": 943.4068603515625, "reward": 0.5402712225914001, "action": -0.8598390817642212}
{"mode": "train", "epochs": 10, "timestep": 19687, "ep_reward": 944.054931640625, "reward": 0.6480439901351929, "action": -0.8738461136817932}
{"mode": "train", "epochs": 10, "timestep": 19688, "ep_reward": 944.7896728515625, "reward": 0.7347527146339417, "action": -0.6355654001235962}
{"mode": "train", "epochs": 10, "timestep": 19689, "ep_reward": 945.5921630859375, "reward": 0.8025107383728027, "action": -1.5008776187896729}
{"mode": "train", "epochs": 10, "timestep": 19690, "ep_reward": 946.4368286132812, "reward": 0.8446703553199768, "action": -0.7925814390182495}
{"mode": "train", "epochs": 10, "timestep": 19691, "ep_reward": 947.3135986328125, "reward": 0.8767856955528259, "action": -1.745197057723999}
{"mode": "train", "epochs": 10, "timestep": 19692, "ep_reward": 948.2017822265625, "reward": 0.8881908059120178, "action": -0.029977917671203613}
{"mode": "train", "epochs": 10, "timestep": 19693, "ep_reward": 949.1012573242188, "reward": 0.8994659185409546, "action": -0.40332090854644775}
{"mode": "train", "epochs": 10, "timestep": 19694, "ep_reward": 949.9963989257812, "reward": 0.8951417207717896, "action": -1.2359554767608643}
{"mode": "train", "epochs": 10, "timestep": 19695, "ep_reward": 950.8667602539062, "reward": 0.8703374862670898, "action": -1.2235782146453857}
{"mode": "train", "epochs": 10, "timestep": 19696, "ep_reward": 951.6939086914062, "reward": 0.8271634578704834, "action": -1.1358659267425537}
{"mode": "train", "epochs": 10, "timestep": 19697, "ep_reward": 952.4545288085938, "reward": 0.7606140971183777, "action": -0.9667755365371704}
{"mode": "train", "epochs": 10, "timestep": 19698, "ep_reward": 953.1195068359375, "reward": 0.6649751663208008, "action": -1.6261658668518066}
{"mode": "train", "epochs": 10, "timestep": 19699, "ep_reward": 953.6422119140625, "reward": 0.522689938545227, "action": -2.0}
{"mode": "train", "epochs": 10, "timestep": 19700, "ep_reward": 953.9961547851562, "reward": 0.3539584279060364, "action": -1.0329830646514893}
{"mode": "train", "epochs": 10, "timestep": 19701, "ep_reward": 954.2409057617188, "reward": 0.24476957321166992, "action": -0.9519785642623901}
{"mode": "train", "epochs": 10, "timestep": 19702, "ep_reward": 954.3563842773438, "reward": 0.11546981334686279, "action": -1.5746099948883057}
{"mode": "train", "epochs": 10, "timestep": 19703, "ep_reward": 954.3560180664062, "reward": -0.00038444995880126953, "action": -0.7913936376571655}
{"mode": "train", "epochs": 10, "timestep": 19704, "ep_reward": 954.5004272460938, "reward": 0.1444278359413147, "action": -1.7841473817825317}
{"mode": "train", "epochs": 10, "timestep": 19705, "ep_reward": 954.7744140625, "reward": 0.2739664316177368, "action": -1.7132165431976318}
{"mode": "train", "epochs": 10, "timestep": 19706, "ep_reward": 955.1787109375, "reward": 0.40430670976638794, "action": -1.0475490093231201}
{"mode": "train", "epochs": 10, "timestep": 19707, "ep_reward": 955.7108154296875, "reward": 0.5321071147918701, "action": -0.48187851905822754}
{"mode": "train", "epochs": 10, "timestep": 19708, "ep_reward": 956.3563232421875, "reward": 0.6455285549163818, "action": -1.7552621364593506}
{"mode": "train", "epochs": 10, "timestep": 19709, "ep_reward": 957.0774536132812, "reward": 0.7211395502090454, "action": -0.969457745552063}
{"mode": "train", "epochs": 10, "timestep": 19710, "ep_reward": 957.859619140625, "reward": 0.7821528911590576, "action": -0.8632662296295166}
{"mode": "train", "epochs": 10, "timestep": 19711, "ep_reward": 958.681640625, "reward": 0.8220287561416626, "action": -1.1590150594711304}
{"mode": "train", "epochs": 10, "timestep": 19712, "ep_reward": 959.520751953125, "reward": 0.8390947580337524, "action": -0.7445756196975708}
{"mode": "train", "epochs": 10, "timestep": 19713, "ep_reward": 960.3612060546875, "reward": 0.8404784202575684, "action": -1.2223840951919556}
{"mode": "train", "epochs": 10, "timestep": 19714, "ep_reward": 961.1778564453125, "reward": 0.8166643381118774, "action": -0.9154840707778931}
{"mode": "train", "epochs": 10, "timestep": 19715, "ep_reward": 961.94921875, "reward": 0.7713377475738525, "action": -0.8717211484909058}
{"mode": "train", "epochs": 10, "timestep": 19716, "ep_reward": 962.6456298828125, "reward": 0.6963839530944824, "action": -1.66361665725708}
{"mode": "train", "epochs": 10, "timestep": 19717, "ep_reward": 963.2191772460938, "reward": 0.5735452771186829, "action": -0.583594560623169}
{"mode": "train", "epochs": 10, "timestep": 19718, "ep_reward": 963.640869140625, "reward": 0.4217032194137573, "action": -0.3896063566207886}
{"mode": "train", "epochs": 10, "timestep": 19719, "ep_reward": 963.962158203125, "reward": 0.3212777376174927, "action": -0.9835869669914246}
{"mode": "train", "epochs": 10, "timestep": 19720, "ep_reward": 964.1678466796875, "reward": 0.20567089319229126, "action": -1.150718331336975}
{"mode": "train", "epochs": 10, "timestep": 19721, "ep_reward": 964.2378540039062, "reward": 0.07003259658813477, "action": -1.4648058414459229}
{"mode": "train", "epochs": 10, "timestep": 19722, "ep_reward": 964.2858276367188, "reward": 0.04800361394882202, "action": -1.2975513935089111}
{"mode": "train", "epochs": 10, "timestep": 19723, "ep_reward": 964.4724731445312, "reward": 0.18663352727890015, "action": -0.9953476786613464}
{"mode": "train", "epochs": 10, "timestep": 19724, "ep_reward": 964.7993774414062, "reward": 0.32687538862228394, "action": -0.9229028820991516}
{"mode": "train", "epochs": 10, "timestep": 19725, "ep_reward": 965.2617797851562, "reward": 0.46243083477020264, "action": -0.7579120397567749}
{"mode": "train", "epochs": 10, "timestep": 19726, "ep_reward": 965.846435546875, "reward": 0.584625244140625, "action": -0.6596937775611877}
{"mode": "train", "epochs": 10, "timestep": 19727, "ep_reward": 966.5325927734375, "reward": 0.6861346960067749, "action": -1.1852390766143799}
{"mode": "train", "epochs": 10, "timestep": 19728, "ep_reward": 967.2920532226562, "reward": 0.7594582438468933, "action": -0.6252661347389221}
{"mode": "train", "epochs": 10, "timestep": 19729, "ep_reward": 968.1087646484375, "reward": 0.8166855573654175, "action": -1.3990330696105957}
{"mode": "train", "epochs": 10, "timestep": 19730, "ep_reward": 968.9569702148438, "reward": 0.848224401473999, "action": -0.9625333547592163}
{"mode": "train", "epochs": 10, "timestep": 19731, "ep_reward": 969.82373046875, "reward": 0.8667678833007812, "action": -1.2635765075683594}
{"mode": "train", "epochs": 10, "timestep": 19732, "ep_reward": 970.6903686523438, "reward": 0.8666235208511353, "action": -1.857539176940918}
{"mode": "train", "epochs": 10, "timestep": 19733, "ep_reward": 971.5343017578125, "reward": 0.8439594507217407, "action": -0.7265152335166931}
{"mode": "train", "epochs": 10, "timestep": 19734, "ep_reward": 972.3448486328125, "reward": 0.810517430305481, "action": -1.1492209434509277}
{"mode": "train", "epochs": 10, "timestep": 19735, "ep_reward": 973.0921630859375, "reward": 0.7473194599151611, "action": -0.657928466796875}
{"mode": "train", "epochs": 10, "timestep": 19736, "ep_reward": 973.7496948242188, "reward": 0.6575478315353394, "action": -0.7747611999511719}
{"mode": "train", "epochs": 10, "timestep": 19737, "ep_reward": 974.2781982421875, "reward": 0.5285286903381348, "action": -1.4687426090240479}
{"mode": "train", "epochs": 10, "timestep": 19738, "ep_reward": 974.649169921875, "reward": 0.37097692489624023, "action": -0.3154911398887634}
{"mode": "train", "epochs": 10, "timestep": 19739, "ep_reward": 974.9143676757812, "reward": 0.26516926288604736, "action": -1.2353044748306274}
{"mode": "train", "epochs": 10, "timestep": 19740, "ep_reward": 975.0538940429688, "reward": 0.1395137906074524, "action": -0.6923098564147949}
{"mode": "train", "epochs": 10, "timestep": 19741, "ep_reward": 975.0476684570312, "reward": -0.006225109100341797, "action": -0.8536148071289062}
{"mode": "train", "epochs": 10, "timestep": 19742, "ep_reward": 975.1685180664062, "reward": 0.12083268165588379, "action": -0.30526256561279297}
{"mode": "train", "epochs": 10, "timestep": 19743, "ep_reward": 975.4368286132812, "reward": 0.26829981803894043, "action": -0.45614439249038696}
{"mode": "train", "epochs": 10, "timestep": 19744, "ep_reward": 975.8479614257812, "reward": 0.4111483693122864, "action": -1.3075588941574097}
{"mode": "train", "epochs": 10, "timestep": 19745, "ep_reward": 976.380615234375, "reward": 0.5326512455940247, "action": -0.7652919292449951}
{"mode": "train", "epochs": 10, "timestep": 19746, "ep_reward": 977.023681640625, "reward": 0.6430511474609375, "action": -0.5645278096199036}
{"mode": "train", "epochs": 10, "timestep": 19747, "ep_reward": 977.7568969726562, "reward": 0.733203649520874, "action": -1.2909175157546997}
{"mode": "train", "epochs": 10, "timestep": 19748, "ep_reward": 978.5518188476562, "reward": 0.794904887676239, "action": -1.0078341960906982}
{"mode": "train", "epochs": 10, "timestep": 19749, "ep_reward": 979.3921508789062, "reward": 0.8403537273406982, "action": -0.6990146636962891}
{"mode": "train", "epochs": 10, "timestep": 19750, "ep_reward": 980.263427734375, "reward": 0.8713012933731079, "action": -1.7463353872299194}
{"mode": "train", "epochs": 10, "timestep": 19751, "ep_reward": 981.1427001953125, "reward": 0.8793028593063354, "action": -1.5856785774230957}
{"mode": "train", "epochs": 10, "timestep": 19752, "ep_reward": 982.0167236328125, "reward": 0.8740458488464355, "action": -0.4195135235786438}
{"mode": "train", "epochs": 10, "timestep": 19753, "ep_reward": 982.8790893554688, "reward": 0.8623890280723572, "action": -0.44696182012557983}
{"mode": "train", "epochs": 10, "timestep": 19754, "ep_reward": 983.7115478515625, "reward": 0.8324852585792542, "action": -1.539258360862732}
{"mode": "train", "epochs": 10, "timestep": 19755, "ep_reward": 984.480712890625, "reward": 0.7691729068756104, "action": -1.0484620332717896}
{"mode": "train", "epochs": 10, "timestep": 19756, "ep_reward": 985.1607666015625, "reward": 0.6800434589385986, "action": -0.9048089981079102}
{"mode": "train", "epochs": 10, "timestep": 19757, "ep_reward": 985.716552734375, "reward": 0.555790901184082, "action": -0.666150689125061}
{"mode": "train", "epochs": 10, "timestep": 19758, "ep_reward": 986.111328125, "reward": 0.3947833180427551, "action": -0.557092547416687}
{"mode": "train", "epochs": 10, "timestep": 19759, "ep_reward": 986.388916015625, "reward": 0.27756673097610474, "action": -1.9301939010620117}
{"mode": "train", "epochs": 10, "timestep": 19760, "ep_reward": 986.5430908203125, "reward": 0.15419310331344604, "action": -1.0800974369049072}
{"mode": "train", "epochs": 10, "timestep": 19761, "ep_reward": 986.5536499023438, "reward": 0.010576426982879639, "action": -1.567582130432129}
{"mode": "train", "epochs": 10, "timestep": 19762, "ep_reward": 986.6592407226562, "reward": 0.10556995868682861, "action": 0.37208735942840576}
{"mode": "train", "epochs": 10, "timestep": 19763, "ep_reward": 986.920166015625, "reward": 0.26091063022613525, "action": -0.8088138103485107}
{"mode": "train", "epochs": 10, "timestep": 19764, "ep_reward": 987.3186645507812, "reward": 0.39850497245788574, "action": -0.762731671333313}
{"mode": "train", "epochs": 10, "timestep": 19765, "ep_reward": 987.8455810546875, "reward": 0.5269444584846497, "action": -1.1641167402267456}
{"mode": "train", "epochs": 10, "timestep": 19766, "ep_reward": 988.4794311523438, "reward": 0.6338648796081543, "action": -1.278210997581482}
{"mode": "train", "epochs": 10, "timestep": 19767, "ep_reward": 989.1990966796875, "reward": 0.7196910381317139, "action": -0.27762264013290405}
{"mode": "train", "epochs": 10, "timestep": 19768, "ep_reward": 989.9927368164062, "reward": 0.7936422228813171, "action": -1.184816598892212}
{"mode": "train", "epochs": 10, "timestep": 19769, "ep_reward": 990.83251953125, "reward": 0.8397711515426636, "action": -0.7668108940124512}
{"mode": "train", "epochs": 10, "timestep": 19770, "ep_reward": 991.705322265625, "reward": 0.872816264629364, "action": -1.4319838285446167}
{"mode": "train", "epochs": 10, "timestep": 19771, "ep_reward": 992.5917358398438, "reward": 0.8864187598228455, "action": -1.7776203155517578}
{"mode": "train", "epochs": 10, "timestep": 19772, "ep_reward": 993.475830078125, "reward": 0.8840752243995667, "action": -0.4392430782318115}
{"mode": "train", "epochs": 10, "timestep": 19773, "ep_reward": 994.3535766601562, "reward": 0.8777166604995728, "action": -0.9139595627784729}
{"mode": "train", "epochs": 10, "timestep": 19774, "ep_reward": 995.2046508789062, "reward": 0.8511046767234802, "action": -1.8344900608062744}
{"mode": "train", "epochs": 10, "timestep": 19775, "ep_reward": 995.9995727539062, "reward": 0.794941246509552, "action": -0.3914005160331726}
{"mode": "train", "epochs": 10, "timestep": 19776, "ep_reward": 996.7254028320312, "reward": 0.7258017063140869, "action": -0.04354369640350342}
{"mode": "train", "epochs": 10, "timestep": 19777, "ep_reward": 997.355224609375, "reward": 0.6297935247421265, "action": -1.189507007598877}
{"mode": "train", "epochs": 10, "timestep": 19778, "ep_reward": 997.83740234375, "reward": 0.4821985960006714, "action": -0.753484845161438}
{"mode": "train", "epochs": 10, "timestep": 19779, "ep_reward": 998.1635131835938, "reward": 0.3261268138885498, "action": -0.637036144733429}
{"mode": "train", "epochs": 10, "timestep": 19780, "ep_reward": 998.3748779296875, "reward": 0.21136856079101562, "action": -1.3574213981628418}
{"mode": "train", "epochs": 10, "timestep": 19781, "ep_reward": 998.45166015625, "reward": 0.07679980993270874, "action": -0.45441991090774536}
{"mode": "train", "epochs": 10, "timestep": 19782, "ep_reward": 998.4928588867188, "reward": 0.04118865728378296, "action": -1.231758952140808}
{"mode": "train", "epochs": 10, "timestep": 19783, "ep_reward": 998.673583984375, "reward": 0.1807042360305786, "action": -1.144395351409912}
{"mode": "train", "epochs": 10, "timestep": 19784, "ep_reward": 998.9925537109375, "reward": 0.31897467374801636, "action": -1.2892975807189941}
{"mode": "train", "epochs": 10, "timestep": 19785, "ep_reward": 999.4434814453125, "reward": 0.45095449686050415, "action": -0.5689643621444702}
{"mode": "train", "epochs": 10, "timestep": 19786, "ep_reward": 1000.0206909179688, "reward": 0.5772137641906738, "action": -0.7637401223182678}
{"mode": "train", "epochs": 10, "timestep": 19787, "ep_reward": 1000.6998291015625, "reward": 0.679162859916687, "action": -0.600688099861145}
{"mode": "train", "epochs": 10, "timestep": 19788, "ep_reward": 1001.458984375, "reward": 0.7591630816459656, "action": -1.191528558731079}
{"mode": "train", "epochs": 10, "timestep": 19789, "ep_reward": 1002.270751953125, "reward": 0.811779797077179, "action": -0.491915762424469}
{"mode": "train", "epochs": 10, "timestep": 19790, "ep_reward": 1003.1221923828125, "reward": 0.8514528274536133, "action": 0.2749367356300354}
{"mode": "train", "epochs": 10, "timestep": 19791, "ep_reward": 1004.002197265625, "reward": 0.8799959421157837, "action": -1.1052724123001099}
{"mode": "train", "epochs": 10, "timestep": 19792, "ep_reward": 1004.8847045898438, "reward": 0.8825225830078125, "action": -0.39825689792633057}
{"mode": "train", "epochs": 10, "timestep": 19793, "ep_reward": 1005.7606201171875, "reward": 0.8759213089942932, "action": -1.2051804065704346}
{"mode": "train", "epochs": 10, "timestep": 19794, "ep_reward": 1006.6065673828125, "reward": 0.8459606766700745, "action": -1.1778388023376465}
{"mode": "train", "epochs": 10, "timestep": 19795, "ep_reward": 1007.4011840820312, "reward": 0.7946390509605408, "action": -1.1911200284957886}
{"mode": "train", "epochs": 10, "timestep": 19796, "ep_reward": 1008.1163940429688, "reward": 0.7152082324028015, "action": -0.597628116607666}
{"mode": "train", "epochs": 10, "timestep": 19797, "ep_reward": 1008.7249145507812, "reward": 0.6085221767425537, "action": -0.27483266592025757}
{"mode": "train", "epochs": 10, "timestep": 19798, "ep_reward": 1009.19384765625, "reward": 0.4689229130744934, "action": -0.6037861108779907}
{"mode": "train", "epochs": 10, "timestep": 19799, "ep_reward": 1009.5116577148438, "reward": 0.31782907247543335, "action": -1.2460286617279053}
{"mode": "train", "epochs": 10, "timestep": 19800, "ep_reward": 1009.7133178710938, "reward": 0.20165234804153442, "action": -0.8460525870323181}
{"mode": "train", "epochs": 10, "timestep": 19801, "ep_reward": 1009.7786254882812, "reward": 0.06532788276672363, "action": -1.4848477840423584}
{"mode": "train", "epochs": 10, "timestep": 19802, "ep_reward": 1009.8314819335938, "reward": 0.05286753177642822, "action": -0.5380425453186035}
{"mode": "train", "epochs": 10, "timestep": 19803, "ep_reward": 1010.0267944335938, "reward": 0.1952837109565735, "action": -1.7844473123550415}
{"mode": "train", "epochs": 10, "timestep": 19804, "ep_reward": 1010.3517456054688, "reward": 0.3249497413635254, "action": -0.5388510227203369}
{"mode": "train", "epochs": 10, "timestep": 19805, "ep_reward": 1010.8175659179688, "reward": 0.4658045172691345, "action": -1.478191614151001}
{"mode": "train", "epochs": 10, "timestep": 19806, "ep_reward": 1011.39697265625, "reward": 0.5794308185577393, "action": -1.6444792747497559}
{"mode": "train", "epochs": 10, "timestep": 19807, "ep_reward": 1012.0684814453125, "reward": 0.6714940071105957, "action": -1.357637643814087}
{"mode": "train", "epochs": 10, "timestep": 19808, "ep_reward": 1012.81298828125, "reward": 0.7444940209388733, "action": -0.4140484929084778}
{"mode": "train", "epochs": 10, "timestep": 19809, "ep_reward": 1013.6168823242188, "reward": 0.8038817048072815, "action": -1.278321623802185}
{"mode": "train", "epochs": 10, "timestep": 19810, "ep_reward": 1014.4510498046875, "reward": 0.8341562151908875, "action": -0.9402291178703308}
{"mode": "train", "epochs": 10, "timestep": 19811, "ep_reward": 1015.2996215820312, "reward": 0.8485786318778992, "action": -1.5919625759124756}
{"mode": "train", "epochs": 10, "timestep": 19812, "ep_reward": 1016.1380004882812, "reward": 0.8383904695510864, "action": -0.40702199935913086}
{"mode": "train", "epochs": 10, "timestep": 19813, "ep_reward": 1016.9564819335938, "reward": 0.8184787631034851, "action": -1.116176962852478}
{"mode": "train", "epochs": 10, "timestep": 19814, "ep_reward": 1017.7238159179688, "reward": 0.7673398852348328, "action": -0.8756450414657593}
{"mode": "train", "epochs": 10, "timestep": 19815, "ep_reward": 1018.4120483398438, "reward": 0.6882296800613403, "action": -0.839581310749054}
{"mode": "train", "epochs": 10, "timestep": 19816, "ep_reward": 1018.9845581054688, "reward": 0.5725210905075073, "action": -1.1265655755996704}
{"mode": "train", "epochs": 10, "timestep": 19817, "ep_reward": 1019.3947143554688, "reward": 0.4101335406303406, "action": -1.2925232648849487}
{"mode": "train", "epochs": 10, "timestep": 19818, "ep_reward": 1019.7036743164062, "reward": 0.3089512586593628, "action": -1.4610297679901123}
{"mode": "train", "epochs": 10, "timestep": 19819, "ep_reward": 1019.8947143554688, "reward": 0.19106441736221313, "action": -1.4927380084991455}
{"mode": "train", "epochs": 10, "timestep": 19820, "ep_reward": 1019.947998046875, "reward": 0.05326133966445923, "action": -0.9711287617683411}
{"mode": "train", "epochs": 10, "timestep": 19821, "ep_reward": 1020.012939453125, "reward": 0.06491649150848389, "action": -1.3825511932373047}
{"mode": "train", "epochs": 10, "timestep": 19822, "ep_reward": 1020.2142333984375, "reward": 0.2012752890586853, "action": -0.9016736745834351}
{"mode": "train", "epochs": 10, "timestep": 19823, "ep_reward": 1020.5570678710938, "reward": 0.3428419828414917, "action": -0.7693625688552856}
{"mode": "train", "epochs": 10, "timestep": 19824, "ep_reward": 1021.035888671875, "reward": 0.47883141040802, "action": -1.5218065977096558}
{"mode": "train", "epochs": 10, "timestep": 19825, "ep_reward": 1021.6260375976562, "reward": 0.5901463031768799, "action": -0.4839026927947998}
{"mode": "train", "epochs": 10, "timestep": 19826, "ep_reward": 1022.3180541992188, "reward": 0.6920322179794312, "action": -1.3456614017486572}
{"mode": "train", "epochs": 10, "timestep": 19827, "ep_reward": 1023.0797729492188, "reward": 0.7617138624191284, "action": -0.24665981531143188}
{"mode": "train", "epochs": 10, "timestep": 19828, "ep_reward": 1023.8999633789062, "reward": 0.8201972842216492, "action": -0.7668497562408447}
{"mode": "train", "epochs": 10, "timestep": 19829, "ep_reward": 1024.754150390625, "reward": 0.8542372584342957, "action": -1.2893179655075073}
{"mode": "train", "epochs": 10, "timestep": 19830, "ep_reward": 1025.6214599609375, "reward": 0.8673206567764282, "action": -0.6826928853988647}
{"mode": "train", "epochs": 10, "timestep": 19831, "ep_reward": 1026.490966796875, "reward": 0.8695026636123657, "action": -0.5157160758972168}
{"mode": "train", "epochs": 10, "timestep": 19832, "ep_reward": 1027.3472900390625, "reward": 0.8563507199287415, "action": -1.664337396621704}
{"mode": "train", "epochs": 10, "timestep": 19833, "ep_reward": 1028.1605224609375, "reward": 0.8132644295692444, "action": 0.10856938362121582}
{"mode": "train", "epochs": 10, "timestep": 19834, "ep_reward": 1028.9237060546875, "reward": 0.7631546258926392, "action": -0.7419921159744263}
{"mode": "train", "epochs": 10, "timestep": 19835, "ep_reward": 1029.598876953125, "reward": 0.6751115918159485, "action": -0.7479698657989502}
{"mode": "train", "epochs": 10, "timestep": 19836, "ep_reward": 1030.1497802734375, "reward": 0.5509181618690491, "action": -0.67674720287323}
{"mode": "train", "epochs": 10, "timestep": 19837, "ep_reward": 1030.5379638671875, "reward": 0.3882162570953369, "action": -1.1837810277938843}
{"mode": "train", "epochs": 10, "timestep": 19838, "ep_reward": 1030.8084716796875, "reward": 0.2705078125, "action": -0.34640318155288696}
{"mode": "train", "epochs": 10, "timestep": 19839, "ep_reward": 1030.9541015625, "reward": 0.14568579196929932, "action": -0.5626007318496704}
{"mode": "train", "epochs": 10, "timestep": 19840, "ep_reward": 1030.9549560546875, "reward": 0.0008195042610168457, "action": -1.0869102478027344}
{"mode": "train", "epochs": 10, "timestep": 19841, "ep_reward": 1031.0694580078125, "reward": 0.11445289850234985, "action": -0.9633930325508118}
{"mode": "train", "epochs": 10, "timestep": 19842, "ep_reward": 1031.3231201171875, "reward": 0.2536163330078125, "action": -0.6390279531478882}
{"mode": "train", "epochs": 10, "timestep": 19843, "ep_reward": 1031.719482421875, "reward": 0.39634764194488525, "action": -1.1264489889144897}
{"mode": "train", "epochs": 10, "timestep": 19844, "ep_reward": 1032.2418212890625, "reward": 0.5223703384399414, "action": -1.1157962083816528}
{"mode": "train", "epochs": 10, "timestep": 19845, "ep_reward": 1032.872802734375, "reward": 0.6310111284255981, "action": -0.7857236862182617}
{"mode": "train", "epochs": 10, "timestep": 19846, "ep_reward": 1033.593994140625, "reward": 0.7212356925010681, "action": -0.5783867835998535}
{"mode": "train", "epochs": 10, "timestep": 19847, "ep_reward": 1034.384521484375, "reward": 0.7904807329177856, "action": -1.3697158098220825}
{"mode": "train", "epochs": 10, "timestep": 19848, "ep_reward": 1035.216796875, "reward": 0.8323248624801636, "action": -0.9038894772529602}
{"mode": "train", "epochs": 10, "timestep": 19849, "ep_reward": 1036.0775146484375, "reward": 0.8606675863265991, "action": -1.1340540647506714}
{"mode": "train", "epochs": 10, "timestep": 19850, "ep_reward": 1036.948486328125, "reward": 0.8709226250648499, "action": -1.4515794515609741}
{"mode": "train", "epochs": 10, "timestep": 19851, "ep_reward": 1037.8109130859375, "reward": 0.8624367117881775, "action": -1.6601030826568604}
{"mode": "train", "epochs": 10, "timestep": 19852, "ep_reward": 1038.64453125, "reward": 0.8335975408554077, "action": -0.8436480760574341}
{"mode": "train", "epochs": 10, "timestep": 19853, "ep_reward": 1039.4342041015625, "reward": 0.7896887063980103, "action": 0.46477264165878296}
{"mode": "train", "epochs": 10, "timestep": 19854, "ep_reward": 1040.16796875, "reward": 0.7337316274642944, "action": -0.09168839454650879}
{"mode": "train", "epochs": 10, "timestep": 19855, "ep_reward": 1040.809814453125, "reward": 0.6418299078941345, "action": -1.5374829769134521}
{"mode": "train", "epochs": 10, "timestep": 19856, "ep_reward": 1041.303466796875, "reward": 0.4936644434928894, "action": -0.7082397937774658}
{"mode": "train", "epochs": 10, "timestep": 19857, "ep_reward": 1041.645263671875, "reward": 0.34181857109069824, "action": -0.7736417651176453}
{"mode": "train", "epochs": 10, "timestep": 19858, "ep_reward": 1041.87548828125, "reward": 0.23020577430725098, "action": -0.6582467555999756}
{"mode": "train", "epochs": 10, "timestep": 19859, "ep_reward": 1041.9739990234375, "reward": 0.09854388236999512, "action": -1.0063451528549194}
{"mode": "train", "epochs": 10, "timestep": 19860, "ep_reward": 1041.9920654296875, "reward": 0.018118739128112793, "action": -1.654280185699463}
{"mode": "train", "epochs": 10, "timestep": 19861, "ep_reward": 1042.1527099609375, "reward": 0.16066819429397583, "action": -1.6469056606292725}
{"mode": "train", "epochs": 10, "timestep": 19862, "ep_reward": 1042.445068359375, "reward": 0.29237520694732666, "action": -1.0837593078613281}
{"mode": "train", "epochs": 10, "timestep": 19863, "ep_reward": 1042.8743896484375, "reward": 0.4292765259742737, "action": -0.46129709482192993}
{"mode": "train", "epochs": 10, "timestep": 19864, "ep_reward": 1043.434326171875, "reward": 0.5599220991134644, "action": -1.1771900653839111}
{"mode": "train", "epochs": 10, "timestep": 19865, "ep_reward": 1044.0953369140625, "reward": 0.6609954237937927, "action": -0.7189464569091797}
{"mode": "train", "epochs": 10, "timestep": 19866, "ep_reward": 1044.8392333984375, "reward": 0.7438881397247314, "action": -1.5100047588348389}
{"mode": "train", "epochs": 10, "timestep": 19867, "ep_reward": 1045.6361083984375, "reward": 0.7968910932540894, "action": -0.6593126654624939}
{"mode": "train", "epochs": 10, "timestep": 19868, "ep_reward": 1046.473876953125, "reward": 0.8377469778060913, "action": -0.8561134338378906}
{"mode": "train", "epochs": 10, "timestep": 19869, "ep_reward": 1047.332275390625, "reward": 0.858416736125946, "action": -0.9968122839927673}
{"mode": "train", "epochs": 10, "timestep": 19870, "ep_reward": 1048.193115234375, "reward": 0.8608376383781433, "action": -0.6551315784454346}
{"mode": "train", "epochs": 10, "timestep": 19871, "ep_reward": 1049.04150390625, "reward": 0.8484494686126709, "action": -1.7257336378097534}
{"mode": "train", "epochs": 10, "timestep": 19872, "ep_reward": 1049.846923828125, "reward": 0.8054540157318115, "action": -1.1726492643356323}
{"mode": "train", "epochs": 10, "timestep": 19873, "ep_reward": 1050.587646484375, "reward": 0.7407812476158142, "action": -1.020248532295227}
{"mode": "train", "epochs": 10, "timestep": 19874, "ep_reward": 1051.2320556640625, "reward": 0.6443761587142944, "action": -0.7817633748054504}
{"mode": "train", "epochs": 10, "timestep": 19875, "ep_reward": 1051.74365234375, "reward": 0.511629581451416, "action": -0.5901899337768555}
{"mode": "train", "epochs": 10, "timestep": 19876, "ep_reward": 1052.109619140625, "reward": 0.36592328548431396, "action": -0.35921788215637207}
{"mode": "train", "epochs": 10, "timestep": 19877, "ep_reward": 1052.3685302734375, "reward": 0.25896376371383667, "action": -1.7849631309509277}
{"mode": "train", "epochs": 10, "timestep": 19878, "ep_reward": 1052.5008544921875, "reward": 0.13237839937210083, "action": -0.46768903732299805}
{"mode": "train", "epochs": 10, "timestep": 19879, "ep_reward": 1052.4864501953125, "reward": -0.014423251152038574, "action": -0.8190957307815552}
{"mode": "train", "epochs": 10, "timestep": 19880, "ep_reward": 1052.6143798828125, "reward": 0.12795323133468628, "action": -1.4148406982421875}
{"mode": "train", "epochs": 10, "timestep": 19881, "ep_reward": 1052.876220703125, "reward": 0.2618136405944824, "action": -1.0563064813613892}
{"mode": "train", "epochs": 10, "timestep": 19882, "ep_reward": 1053.2763671875, "reward": 0.40012359619140625, "action": -0.6134439706802368}
{"mode": "train", "epochs": 10, "timestep": 19883, "ep_reward": 1053.8089599609375, "reward": 0.5325419902801514, "action": -0.4767264723777771}
{"mode": "train", "epochs": 10, "timestep": 19884, "ep_reward": 1054.455078125, "reward": 0.646091639995575, "action": -1.2198190689086914}
{"mode": "train", "epochs": 10, "timestep": 19885, "ep_reward": 1055.1837158203125, "reward": 0.7286454439163208, "action": -1.4471042156219482}
{"mode": "train", "epochs": 10, "timestep": 19886, "ep_reward": 1055.9713134765625, "reward": 0.787628173828125, "action": -1.1437020301818848}
{"mode": "train", "epochs": 10, "timestep": 19887, "ep_reward": 1056.80078125, "reward": 0.829454779624939, "action": -1.7252100706100464}
{"mode": "train", "epochs": 10, "timestep": 19888, "ep_reward": 1057.64892578125, "reward": 0.8481711149215698, "action": -0.6483480930328369}
{"mode": "train", "epochs": 10, "timestep": 19889, "ep_reward": 1058.5076904296875, "reward": 0.858814001083374, "action": -0.7600365877151489}
{"mode": "train", "epochs": 10, "timestep": 19890, "ep_reward": 1059.3585205078125, "reward": 0.8507843017578125, "action": -0.10466837882995605}
{"mode": "train", "epochs": 10, "timestep": 19891, "ep_reward": 1060.1881103515625, "reward": 0.8295875191688538, "action": -1.3765202760696411}
{"mode": "train", "epochs": 10, "timestep": 19892, "ep_reward": 1060.9613037109375, "reward": 0.7732429504394531, "action": -0.7189484238624573}
{"mode": "train", "epochs": 10, "timestep": 19893, "ep_reward": 1061.6552734375, "reward": 0.6939371824264526, "action": -1.3575853109359741}
{"mode": "train", "epochs": 10, "timestep": 19894, "ep_reward": 1062.2254638671875, "reward": 0.5701360702514648, "action": -1.0596176385879517}
{"mode": "train", "epochs": 10, "timestep": 19895, "ep_reward": 1062.6328125, "reward": 0.4074050188064575, "action": -1.382211446762085}
{"mode": "train", "epochs": 10, "timestep": 19896, "ep_reward": 1062.93212890625, "reward": 0.29932063817977905, "action": -1.476342797279358}
{"mode": "train", "epochs": 10, "timestep": 19897, "ep_reward": 1063.11181640625, "reward": 0.17970365285873413, "action": -1.2752830982208252}
{"mode": "train", "epochs": 10, "timestep": 19898, "ep_reward": 1063.1519775390625, "reward": 0.04010850191116333, "action": -0.8269557952880859}
{"mode": "train", "epochs": 10, "timestep": 19899, "ep_reward": 1063.229736328125, "reward": 0.07775336503982544, "action": -1.5688740015029907}
{"mode": "train", "epochs": 10, "timestep": 19900, "ep_reward": 1063.4420166015625, "reward": 0.2123405933380127, "action": -1.1741278171539307}
{"mode": "train", "epochs": 10, "timestep": 19901, "ep_reward": 1063.79248046875, "reward": 0.3504951596260071, "action": -1.6019482612609863}
{"mode": "train", "epochs": 10, "timestep": 19902, "ep_reward": 1064.2689208984375, "reward": 0.47648364305496216, "action": -1.4540903568267822}
{"mode": "train", "epochs": 10, "timestep": 19903, "ep_reward": 1064.8580322265625, "reward": 0.5890957117080688, "action": -1.3156651258468628}
{"mode": "train", "epochs": 10, "timestep": 19904, "ep_reward": 1065.539794921875, "reward": 0.6818199157714844, "action": -1.2303732633590698}
{"mode": "train", "epochs": 10, "timestep": 19905, "ep_reward": 1066.29150390625, "reward": 0.7517692446708679, "action": -1.471887230873108}
{"mode": "train", "epochs": 10, "timestep": 19906, "ep_reward": 1067.0880126953125, "reward": 0.7965047955513, "action": -1.3566360473632812}
{"mode": "train", "epochs": 10, "timestep": 19907, "ep_reward": 1067.9090576171875, "reward": 0.821091890335083, "action": -0.8101695775985718}
{"mode": "train", "epochs": 10, "timestep": 19908, "ep_reward": 1068.739013671875, "reward": 0.8299192786216736, "action": -1.4401962757110596}
{"mode": "train", "epochs": 10, "timestep": 19909, "ep_reward": 1069.550048828125, "reward": 0.8110130429267883, "action": -0.2748589515686035}
{"mode": "train", "epochs": 10, "timestep": 19910, "ep_reward": 1070.329345703125, "reward": 0.7792742252349854, "action": -1.8350589275360107}
{"mode": "train", "epochs": 10, "timestep": 19911, "ep_reward": 1071.030029296875, "reward": 0.7007150650024414, "action": -0.7290617227554321}
{"mode": "train", "epochs": 10, "timestep": 19912, "ep_reward": 1071.62744140625, "reward": 0.5974079370498657, "action": -1.1695177555084229}
{"mode": "train", "epochs": 10, "timestep": 19913, "ep_reward": 1072.0723876953125, "reward": 0.44489800930023193, "action": -0.7122697830200195}
{"mode": "train", "epochs": 10, "timestep": 19914, "ep_reward": 1072.4171142578125, "reward": 0.34472113847732544, "action": -1.9761335849761963}
{"mode": "train", "epochs": 10, "timestep": 19915, "ep_reward": 1072.65087890625, "reward": 0.23382025957107544, "action": -1.4731096029281616}
{"mode": "train", "epochs": 10, "timestep": 19916, "ep_reward": 1072.753662109375, "reward": 0.10278570652008057, "action": -1.5918192863464355}
{"mode": "train", "epochs": 10, "timestep": 19917, "ep_reward": 1072.7672119140625, "reward": 0.013530135154724121, "action": -1.0482933521270752}
{"mode": "train", "epochs": 10, "timestep": 19918, "ep_reward": 1072.923828125, "reward": 0.15662753582000732, "action": -1.4592679738998413}
{"mode": "train", "epochs": 10, "timestep": 19919, "ep_reward": 1073.21435546875, "reward": 0.2904992699623108, "action": -1.658226728439331}
{"mode": "train", "epochs": 10, "timestep": 19920, "ep_reward": 1073.634521484375, "reward": 0.42011624574661255, "action": -1.1882113218307495}
{"mode": "train", "epochs": 10, "timestep": 19921, "ep_reward": 1074.178466796875, "reward": 0.5439574122428894, "action": -0.9028508067131042}
{"mode": "train", "epochs": 10, "timestep": 19922, "ep_reward": 1074.8292236328125, "reward": 0.6507067084312439, "action": -0.9269348978996277}
{"mode": "train", "epochs": 10, "timestep": 19923, "ep_reward": 1075.5623779296875, "reward": 0.7331070899963379, "action": -1.3995802402496338}
{"mode": "train", "epochs": 10, "timestep": 19924, "ep_reward": 1076.35009765625, "reward": 0.7876715660095215, "action": -1.3610327243804932}
{"mode": "train", "epochs": 10, "timestep": 19925, "ep_reward": 1077.1717529296875, "reward": 0.8216981887817383, "action": -1.1948285102844238}
{"mode": "train", "epochs": 10, "timestep": 19926, "ep_reward": 1078.0091552734375, "reward": 0.8374519944190979, "action": -1.1501623392105103}
{"mode": "train", "epochs": 10, "timestep": 19927, "ep_reward": 1078.843017578125, "reward": 0.8338229656219482, "action": -0.9891713261604309}
{"mode": "train", "epochs": 10, "timestep": 19928, "ep_reward": 1079.6531982421875, "reward": 0.8102316856384277, "action": -0.44902127981185913}
{"mode": "train", "epochs": 10, "timestep": 19929, "ep_reward": 1080.4205322265625, "reward": 0.7673358917236328, "action": -1.029491901397705}
{"mode": "train", "epochs": 10, "timestep": 19930, "ep_reward": 1081.1082763671875, "reward": 0.6877968311309814, "action": -1.6169707775115967}
{"mode": "train", "epochs": 10, "timestep": 19931, "ep_reward": 1081.670166015625, "reward": 0.5619404315948486, "action": -0.6646870374679565}
{"mode": "train", "epochs": 10, "timestep": 19932, "ep_reward": 1082.0797119140625, "reward": 0.40953361988067627, "action": -0.44088155031204224}
{"mode": "train", "epochs": 10, "timestep": 19933, "ep_reward": 1082.3919677734375, "reward": 0.3122095465660095, "action": -0.8723285794258118}
{"mode": "train", "epochs": 10, "timestep": 19934, "ep_reward": 1082.5867919921875, "reward": 0.19476383924484253, "action": -1.7982325553894043}
{"mode": "train", "epochs": 10, "timestep": 19935, "ep_reward": 1082.6444091796875, "reward": 0.05758357048034668, "action": -1.1929928064346313}
{"mode": "train", "epochs": 10, "timestep": 19936, "ep_reward": 1082.705078125, "reward": 0.06064325571060181, "action": -1.0594594478607178}
{"mode": "train", "epochs": 10, "timestep": 19937, "ep_reward": 1082.902587890625, "reward": 0.19752466678619385, "action": -1.0491409301757812}
{"mode": "train", "epochs": 10, "timestep": 19938, "ep_reward": 1083.2398681640625, "reward": 0.33727216720581055, "action": -0.21408677101135254}
{"mode": "train", "epochs": 10, "timestep": 19939, "ep_reward": 1083.7203369140625, "reward": 0.4804403781890869, "action": -1.3715088367462158}
{"mode": "train", "epochs": 10, "timestep": 19940, "ep_reward": 1084.3133544921875, "reward": 0.5929722189903259, "action": -0.7989636659622192}
{"mode": "train", "epochs": 10, "timestep": 19941, "ep_reward": 1085.004638671875, "reward": 0.6913365125656128, "action": -1.2128987312316895}
{"mode": "train", "epochs": 10, "timestep": 19942, "ep_reward": 1085.767578125, "reward": 0.7629157304763794, "action": 0.034838199615478516}
{"mode": "train", "epochs": 10, "timestep": 19943, "ep_reward": 1086.5919189453125, "reward": 0.8243707418441772, "action": -1.4558095932006836}
{"mode": "train", "epochs": 10, "timestep": 19944, "ep_reward": 1087.4456787109375, "reward": 0.8537901639938354, "action": -0.7097809314727783}
{"mode": "train", "epochs": 10, "timestep": 19945, "ep_reward": 1088.31884765625, "reward": 0.87322998046875, "action": -1.2540117502212524}
{"mode": "train", "epochs": 10, "timestep": 19946, "ep_reward": 1089.191650390625, "reward": 0.8728232383728027, "action": -1.1767380237579346}
{"mode": "train", "epochs": 10, "timestep": 19947, "ep_reward": 1090.0482177734375, "reward": 0.8565731048583984, "action": -1.4726914167404175}
{"mode": "train", "epochs": 10, "timestep": 19948, "ep_reward": 1090.8662109375, "reward": 0.8179435729980469, "action": -0.6388757228851318}
{"mode": "train", "epochs": 10, "timestep": 19949, "ep_reward": 1091.6287841796875, "reward": 0.7625820636749268, "action": -1.915278673171997}
{"mode": "train", "epochs": 10, "timestep": 19950, "ep_reward": 1092.2901611328125, "reward": 0.6614357233047485, "action": -0.1539531946182251}
{"mode": "train", "epochs": 10, "timestep": 19951, "ep_reward": 1092.8336181640625, "reward": 0.5435075759887695, "action": -1.339684009552002}
{"mode": "train", "epochs": 10, "timestep": 19952, "ep_reward": 1093.211181640625, "reward": 0.37750929594039917, "action": -1.2449305057525635}
{"mode": "train", "epochs": 10, "timestep": 19953, "ep_reward": 1093.484375, "reward": 0.273250937461853, "action": -0.7032603025436401}
{"mode": "train", "epochs": 10, "timestep": 19954, "ep_reward": 1093.6331787109375, "reward": 0.1488109827041626, "action": -1.5185019969940186}
{"mode": "train", "epochs": 10, "timestep": 19955, "ep_reward": 1093.6376953125, "reward": 0.004530012607574463, "action": -1.2388447523117065}
{"mode": "train", "epochs": 10, "timestep": 19956, "ep_reward": 1093.748779296875, "reward": 0.11103856563568115, "action": -1.2721874713897705}
{"mode": "train", "epochs": 10, "timestep": 19957, "ep_reward": 1093.994873046875, "reward": 0.24613547325134277, "action": -1.5273586511611938}
{"mode": "train", "epochs": 10, "timestep": 19958, "ep_reward": 1094.3739013671875, "reward": 0.379059374332428, "action": 0.2872884273529053}
{"mode": "train", "epochs": 10, "timestep": 19959, "ep_reward": 1094.8984375, "reward": 0.5245434045791626, "action": -1.5329108238220215}
{"mode": "train", "epochs": 10, "timestep": 19960, "ep_reward": 1095.5267333984375, "reward": 0.62823885679245, "action": -1.670750379562378}
{"mode": "train", "epochs": 10, "timestep": 19961, "ep_reward": 1096.2366943359375, "reward": 0.7099887132644653, "action": -1.6638107299804688}
{"mode": "train", "epochs": 10, "timestep": 19962, "ep_reward": 1097.00732421875, "reward": 0.7705883383750916, "action": -0.5285162925720215}
{"mode": "train", "epochs": 10, "timestep": 19963, "ep_reward": 1097.828125, "reward": 0.8208099603652954, "action": -0.35853111743927}
{"mode": "train", "epochs": 10, "timestep": 19964, "ep_reward": 1098.6805419921875, "reward": 0.8524053692817688, "action": -0.7472254037857056}
{"mode": "train", "epochs": 10, "timestep": 19965, "ep_reward": 1099.5433349609375, "reward": 0.8628159761428833, "action": -1.1959643363952637}
{"mode": "train", "epochs": 10, "timestep": 19966, "ep_reward": 1100.3953857421875, "reward": 0.8520074486732483, "action": -1.2970911264419556}
{"mode": "train", "epochs": 10, "timestep": 19967, "ep_reward": 1101.2158203125, "reward": 0.8204749822616577, "action": -0.20908409357070923}
{"mode": "train", "epochs": 10, "timestep": 19968, "ep_reward": 1101.9918212890625, "reward": 0.7760616540908813, "action": -0.5259805917739868}
{"mode": "train", "epochs": 10, "timestep": 19969, "ep_reward": 1102.692138671875, "reward": 0.7003639340400696, "action": -1.0801782608032227}
{"mode": "train", "epochs": 10, "timestep": 19970, "ep_reward": 1103.2747802734375, "reward": 0.5826842784881592, "action": -0.9885338544845581}
{"mode": "train", "epochs": 10, "timestep": 19971, "ep_reward": 1103.699462890625, "reward": 0.42469263076782227, "action": -1.1466318368911743}
{"mode": "train", "epochs": 10, "timestep": 19972, "ep_reward": 1104.00537109375, "reward": 0.30589407682418823, "action": -0.8904305696487427}
{"mode": "train", "epochs": 10, "timestep": 19973, "ep_reward": 1104.1927490234375, "reward": 0.1873961091041565, "action": -1.1715079545974731}
{"mode": "train", "epochs": 10, "timestep": 19974, "ep_reward": 1104.24169921875, "reward": 0.048933982849121094, "action": -1.1569775342941284}
{"mode": "train", "epochs": 10, "timestep": 19975, "ep_reward": 1104.3109130859375, "reward": 0.06922179460525513, "action": -0.9271866083145142}
{"mode": "train", "epochs": 10, "timestep": 19976, "ep_reward": 1104.5184326171875, "reward": 0.20750653743743896, "action": -0.3367595672607422}
{"mode": "train", "epochs": 10, "timestep": 19977, "ep_reward": 1104.8739013671875, "reward": 0.3554757237434387, "action": -0.8585340976715088}
{"mode": "train", "epochs": 10, "timestep": 19978, "ep_reward": 1105.362060546875, "reward": 0.4881904125213623, "action": -1.8144090175628662}
{"mode": "train", "epochs": 10, "timestep": 19979, "ep_reward": 1105.956787109375, "reward": 0.5947083234786987, "action": -0.38639068603515625}
{"mode": "train", "epochs": 10, "timestep": 19980, "ep_reward": 1106.653564453125, "reward": 0.6968178153038025, "action": -0.9093065857887268}
{"mode": "train", "epochs": 10, "timestep": 19981, "ep_reward": 1107.423583984375, "reward": 0.7700198888778687, "action": -0.6923648118972778}
{"mode": "train", "epochs": 10, "timestep": 19982, "ep_reward": 1108.24755859375, "reward": 0.8239762187004089, "action": -1.5296599864959717}
{"mode": "train", "epochs": 10, "timestep": 19983, "ep_reward": 1109.1002197265625, "reward": 0.8526082038879395, "action": -0.12779676914215088}
{"mode": "train", "epochs": 10, "timestep": 19984, "ep_reward": 1109.976806640625, "reward": 0.8765534162521362, "action": -0.627028226852417}
{"mode": "train", "epochs": 10, "timestep": 19985, "ep_reward": 1110.85791015625, "reward": 0.8811565041542053, "action": -0.8264390826225281}
{"mode": "train", "epochs": 10, "timestep": 19986, "ep_reward": 1111.7269287109375, "reward": 0.8689943552017212, "action": -0.5271083116531372}
{"mode": "train", "epochs": 10, "timestep": 19987, "ep_reward": 1112.5689697265625, "reward": 0.8420990109443665, "action": -1.2705308198928833}
{"mode": "train", "epochs": 10, "timestep": 19988, "ep_reward": 1113.355712890625, "reward": 0.7867608070373535, "action": -0.9452073574066162}
{"mode": "train", "epochs": 10, "timestep": 19989, "ep_reward": 1114.0616455078125, "reward": 0.7059904336929321, "action": -1.9988574981689453}
{"mode": "train", "epochs": 10, "timestep": 19990, "ep_reward": 1114.637451171875, "reward": 0.5757701396942139, "action": -0.24327856302261353}
{"mode": "train", "epochs": 10, "timestep": 19991, "ep_reward": 1115.06494140625, "reward": 0.4275417923927307, "action": -1.1191290616989136}
{"mode": "train", "epochs": 10, "timestep": 19992, "ep_reward": 1115.364501953125, "reward": 0.29953134059906006, "action": -1.2776117324829102}
{"mode": "train", "epochs": 10, "timestep": 19993, "ep_reward": 1115.54443359375, "reward": 0.17996257543563843, "action": -0.907227635383606}
{"mode": "train", "epochs": 10, "timestep": 19994, "ep_reward": 1115.5848388671875, "reward": 0.04036903381347656, "action": -0.6095426082611084}
{"mode": "train", "epochs": 10, "timestep": 19995, "ep_reward": 1115.6624755859375, "reward": 0.07760262489318848, "action": -1.0724643468856812}
{"mode": "train", "epochs": 10, "timestep": 19996, "ep_reward": 1115.8765869140625, "reward": 0.21416640281677246, "action": -1.689725637435913}
{"mode": "train", "epochs": 10, "timestep": 19997, "ep_reward": 1116.22216796875, "reward": 0.3456171751022339, "action": -1.1226801872253418}
{"mode": "train", "epochs": 10, "timestep": 19998, "ep_reward": 1116.700439453125, "reward": 0.47825318574905396, "action": -0.943544864654541}
{"mode": "train", "epochs": 10, "timestep": 19999, "ep_reward": 1117.296875, "reward": 0.596383273601532, "action": -0.4194680452346802}
{"mode": "train", "epochs": 10, "timestep": 20000, "ep_reward": 1117.9940185546875, "reward": 0.6971084475517273, "action": -2.0}
{"mode": "train", "epochs": 11, "timestep": 20001, "ep_reward": 0.8841556906700134, "reward": 0.8841556906700134, "action": -0.9702194929122925}
{"mode": "train", "epochs": 11, "timestep": 20002, "ep_reward": 1.7673108577728271, "reward": 0.883155107498169, "action": -1.2056291103363037}
{"mode": "train", "epochs": 11, "timestep": 20003, "ep_reward": 2.64078426361084, "reward": 0.8734734654426575, "action": -0.1829252541065216}
{"mode": "train", "epochs": 11, "timestep": 20004, "ep_reward": 3.491253137588501, "reward": 0.8504688739776611, "action": -0.0984111800789833}
{"mode": "train", "epochs": 11, "timestep": 20005, "ep_reward": 4.303898811340332, "reward": 0.8126457929611206, "action": 1.2650941610336304}
{"mode": "train", "epochs": 11, "timestep": 20006, "ep_reward": 5.052753925323486, "reward": 0.7488552331924438, "action": -0.021819978952407837}
{"mode": "train", "epochs": 11, "timestep": 20007, "ep_reward": 5.724918842315674, "reward": 0.6721649169921875, "action": 0.20172253251075745}
{"mode": "train", "epochs": 11, "timestep": 20008, "ep_reward": 6.299411296844482, "reward": 0.5744922757148743, "action": 0.458996444940567}
{"mode": "train", "epochs": 11, "timestep": 20009, "ep_reward": 6.755224227905273, "reward": 0.4558129906654358, "action": 0.9042932987213135}
{"mode": "train", "epochs": 11, "timestep": 20010, "ep_reward": 7.071944713592529, "reward": 0.31672048568725586, "action": -0.6780188083648682}
{"mode": "train", "epochs": 11, "timestep": 20011, "ep_reward": 7.263509273529053, "reward": 0.1915643811225891, "action": -0.3664777874946594}
{"mode": "train", "epochs": 11, "timestep": 20012, "ep_reward": 7.485943794250488, "reward": 0.222434401512146, "action": -0.20765253901481628}
{"mode": "train", "epochs": 11, "timestep": 20013, "ep_reward": 7.825979709625244, "reward": 0.34003591537475586, "action": -1.2719042301177979}
{"mode": "train", "epochs": 11, "timestep": 20014, "ep_reward": 8.290067672729492, "reward": 0.46408820152282715, "action": -0.2870803475379944}
{"mode": "train", "epochs": 11, "timestep": 20015, "ep_reward": 8.85867691040039, "reward": 0.5686091184616089, "action": 0.5576797723770142}
{"mode": "train", "epochs": 11, "timestep": 20016, "ep_reward": 9.513195037841797, "reward": 0.6545177698135376, "action": 1.2888978719711304}
{"mode": "train", "epochs": 11, "timestep": 20017, "ep_reward": 10.236869812011719, "reward": 0.7236748933792114, "action": 0.6185423135757446}
{"mode": "train", "epochs": 11, "timestep": 20018, "ep_reward": 11.02096939086914, "reward": 0.7840995788574219, "action": 1.0181201696395874}
{"mode": "train", "epochs": 11, "timestep": 20019, "ep_reward": 11.850327491760254, "reward": 0.8293579816818237, "action": 0.3243313431739807}
{"mode": "train", "epochs": 11, "timestep": 20020, "ep_reward": 12.71493148803711, "reward": 0.8646038174629211, "action": 0.3905121088027954}
{"mode": "train", "epochs": 11, "timestep": 20021, "ep_reward": 13.601995468139648, "reward": 0.8870642185211182, "action": 0.18410038948059082}
{"mode": "train", "epochs": 11, "timestep": 20022, "ep_reward": 14.500107765197754, "reward": 0.8981125950813293, "action": 0.4600731134414673}
{"mode": "train", "epochs": 11, "timestep": 20023, "ep_reward": 15.398194313049316, "reward": 0.8980861306190491, "action": 0.7404893636703491}
{"mode": "train", "epochs": 11, "timestep": 20024, "ep_reward": 16.28646469116211, "reward": 0.8882703185081482, "action": 1.1373307704925537}
{"mode": "train", "epochs": 11, "timestep": 20025, "ep_reward": 17.15632438659668, "reward": 0.8698592185974121, "action": 1.0777008533477783}
{"mode": "train", "epochs": 11, "timestep": 20026, "ep_reward": 17.997676849365234, "reward": 0.841352641582489, "action": 0.8310415148735046}
{"mode": "train", "epochs": 11, "timestep": 20027, "ep_reward": 18.797517776489258, "reward": 0.7998415231704712, "action": 1.4102407693862915}
{"mode": "train", "epochs": 11, "timestep": 20028, "ep_reward": 19.54651641845703, "reward": 0.7489981651306152, "action": 1.3286378383636475}
{"mode": "train", "epochs": 11, "timestep": 20029, "ep_reward": 20.231689453125, "reward": 0.6851732730865479, "action": -1.0860118865966797}
{"mode": "train", "epochs": 11, "timestep": 20030, "ep_reward": 20.816328048706055, "reward": 0.5846387147903442, "action": -0.8473871350288391}
{"mode": "train", "epochs": 11, "timestep": 20031, "ep_reward": 21.280935287475586, "reward": 0.46460777521133423, "action": -1.1225382089614868}
{"mode": "train", "epochs": 11, "timestep": 20032, "ep_reward": 21.605188369750977, "reward": 0.32425230741500854, "action": -1.3061020374298096}
{"mode": "train", "epochs": 11, "timestep": 20033, "ep_reward": 21.775922775268555, "reward": 0.17073476314544678, "action": -0.7799841165542603}
{"mode": "train", "epochs": 11, "timestep": 20034, "ep_reward": 21.970991134643555, "reward": 0.19506865739822388, "action": 0.05373537540435791}
{"mode": "train", "epochs": 11, "timestep": 20035, "ep_reward": 22.29067611694336, "reward": 0.3196847438812256, "action": -0.6579102277755737}
{"mode": "train", "epochs": 11, "timestep": 20036, "ep_reward": 22.72661018371582, "reward": 0.43593400716781616, "action": -0.8399057388305664}
{"mode": "train", "epochs": 11, "timestep": 20037, "ep_reward": 23.271282196044922, "reward": 0.5446720123291016, "action": -1.210054636001587}
{"mode": "train", "epochs": 11, "timestep": 20038, "ep_reward": 23.910900115966797, "reward": 0.6396173238754272, "action": -0.8782482743263245}
{"mode": "train", "epochs": 11, "timestep": 20039, "ep_reward": 24.634424209594727, "reward": 0.723524808883667, "action": -1.5125436782836914}
{"mode": "train", "epochs": 11, "timestep": 20040, "ep_reward": 25.422393798828125, "reward": 0.7879694700241089, "action": -0.8441881537437439}
{"mode": "train", "epochs": 11, "timestep": 20041, "ep_reward": 26.26531982421875, "reward": 0.8429254293441772, "action": -0.4621391296386719}
{"mode": "train", "epochs": 11, "timestep": 20042, "ep_reward": 27.151578903198242, "reward": 0.8862588405609131, "action": -1.0776567459106445}
{"mode": "train", "epochs": 11, "timestep": 20043, "ep_reward": 28.067264556884766, "reward": 0.9156849980354309, "action": -1.1542860269546509}
{"mode": "train", "epochs": 11, "timestep": 20044, "ep_reward": 29.0042724609375, "reward": 0.9370077252388, "action": -1.472426414489746}
{"mode": "train", "epochs": 11, "timestep": 20045, "ep_reward": 29.956144332885742, "reward": 0.9518717527389526, "action": -0.8830958008766174}
{"mode": "train", "epochs": 11, "timestep": 20046, "ep_reward": 30.92007064819336, "reward": 0.9639272093772888, "action": -0.8347193598747253}
{"mode": "train", "epochs": 11, "timestep": 20047, "ep_reward": 31.89246368408203, "reward": 0.9723934531211853, "action": -0.29904377460479736}
{"mode": "train", "epochs": 11, "timestep": 20048, "ep_reward": 32.870849609375, "reward": 0.9783847332000732, "action": -0.3056367039680481}
{"mode": "train", "epochs": 11, "timestep": 20049, "ep_reward": 33.852149963378906, "reward": 0.9813004732131958, "action": -0.6803441047668457}
{"mode": "train", "epochs": 11, "timestep": 20050, "ep_reward": 34.83389663696289, "reward": 0.9817467927932739, "action": -1.0354390144348145}
{"mode": "train", "epochs": 11, "timestep": 20051, "ep_reward": 35.81455612182617, "reward": 0.9806612730026245, "action": -0.6144018769264221}
{"mode": "train", "epochs": 11, "timestep": 20052, "ep_reward": 36.7918586730957, "reward": 0.9773015975952148, "action": -1.0329723358154297}
{"mode": "train", "epochs": 11, "timestep": 20053, "ep_reward": 37.764163970947266, "reward": 0.9723055362701416, "action": -0.5897237062454224}
{"mode": "train", "epochs": 11, "timestep": 20054, "ep_reward": 38.7277717590332, "reward": 0.9636079668998718, "action": 0.18965044617652893}
{"mode": "train", "epochs": 11, "timestep": 20055, "ep_reward": 39.675537109375, "reward": 0.9477642774581909, "action": -0.1412498950958252}
{"mode": "train", "epochs": 11, "timestep": 20056, "ep_reward": 40.601016998291016, "reward": 0.925479531288147, "action": -0.3920331597328186}
{"mode": "train", "epochs": 11, "timestep": 20057, "ep_reward": 41.49605178833008, "reward": 0.8950336575508118, "action": -0.8119322061538696}
{"mode": "train", "epochs": 11, "timestep": 20058, "ep_reward": 42.351768493652344, "reward": 0.8557174801826477, "action": -1.0807228088378906}
{"mode": "train", "epochs": 11, "timestep": 20059, "ep_reward": 43.156944274902344, "reward": 0.805176317691803, "action": -0.291843980550766}
{"mode": "train", "epochs": 11, "timestep": 20060, "ep_reward": 43.88866424560547, "reward": 0.7317186594009399, "action": -0.5084601044654846}
{"mode": "train", "epochs": 11, "timestep": 20061, "ep_reward": 44.52830123901367, "reward": 0.6396374702453613, "action": -1.2154186964035034}
{"mode": "train", "epochs": 11, "timestep": 20062, "ep_reward": 45.0641975402832, "reward": 0.5358971953392029, "action": -0.9392799139022827}
{"mode": "train", "epochs": 11, "timestep": 20063, "ep_reward": 45.47789001464844, "reward": 0.41369158029556274, "action": 0.006443500518798828}
{"mode": "train", "epochs": 11, "timestep": 20064, "ep_reward": 45.745323181152344, "reward": 0.26743435859680176, "action": -1.860033631324768}
{"mode": "train", "epochs": 11, "timestep": 20065, "ep_reward": 45.89072799682617, "reward": 0.14540636539459229, "action": -2.0}
{"mode": "train", "epochs": 11, "timestep": 20066, "ep_reward": 46.102291107177734, "reward": 0.21156156063079834, "action": -1.1124420166015625}
{"mode": "train", "epochs": 11, "timestep": 20067, "ep_reward": 46.444828033447266, "reward": 0.3425362706184387, "action": -0.482284814119339}
{"mode": "train", "epochs": 11, "timestep": 20068, "ep_reward": 46.9071159362793, "reward": 0.4622892141342163, "action": -0.399998277425766}
{"mode": "train", "epochs": 11, "timestep": 20069, "ep_reward": 47.478694915771484, "reward": 0.571580171585083, "action": 0.27510589361190796}
{"mode": "train", "epochs": 11, "timestep": 20070, "ep_reward": 48.14048385620117, "reward": 0.661788284778595, "action": 1.6979680061340332}
{"mode": "train", "epochs": 11, "timestep": 20071, "ep_reward": 48.869998931884766, "reward": 0.7295156121253967, "action": 1.1821670532226562}
{"mode": "train", "epochs": 11, "timestep": 20072, "ep_reward": 49.658931732177734, "reward": 0.7889313101768494, "action": 0.4600179195404053}
{"mode": "train", "epochs": 11, "timestep": 20073, "ep_reward": 50.49757766723633, "reward": 0.8386470079421997, "action": 1.2075268030166626}
{"mode": "train", "epochs": 11, "timestep": 20074, "ep_reward": 51.37047576904297, "reward": 0.8728997111320496, "action": 0.7633208632469177}
{"mode": "train", "epochs": 11, "timestep": 20075, "ep_reward": 52.268829345703125, "reward": 0.8983525037765503, "action": 1.1342641115188599}
{"mode": "train", "epochs": 11, "timestep": 20076, "ep_reward": 53.18281555175781, "reward": 0.9139844179153442, "action": 1.593094825744629}
{"mode": "train", "epochs": 11, "timestep": 20077, "ep_reward": 54.1053466796875, "reward": 0.9225327968597412, "action": 0.7472329139709473}
{"mode": "train", "epochs": 11, "timestep": 20078, "ep_reward": 55.03004837036133, "reward": 0.9247010946273804, "action": 1.5388343334197998}
{"mode": "train", "epochs": 11, "timestep": 20079, "ep_reward": 55.95098114013672, "reward": 0.9209326505661011, "action": 0.6118425130844116}
{"mode": "train", "epochs": 11, "timestep": 20080, "ep_reward": 56.85963821411133, "reward": 0.908658504486084, "action": 1.2593780755996704}
{"mode": "train", "epochs": 11, "timestep": 20081, "ep_reward": 57.749267578125, "reward": 0.8896292448043823, "action": 1.2863425016403198}
{"mode": "train", "epochs": 11, "timestep": 20082, "ep_reward": 58.611427307128906, "reward": 0.8621608018875122, "action": 0.5935376882553101}
{"mode": "train", "epochs": 11, "timestep": 20083, "ep_reward": 59.4315071105957, "reward": 0.8200793862342834, "action": 1.055607795715332}
{"mode": "train", "epochs": 11, "timestep": 20084, "ep_reward": 60.19841003417969, "reward": 0.7669048309326172, "action": 1.1397333145141602}
{"mode": "train", "epochs": 11, "timestep": 20085, "ep_reward": 60.89851760864258, "reward": 0.7001074552536011, "action": -1.1443524360656738}
{"mode": "train", "epochs": 11, "timestep": 20086, "ep_reward": 61.4935302734375, "reward": 0.5950120687484741, "action": -0.4978368282318115}
{"mode": "train", "epochs": 11, "timestep": 20087, "ep_reward": 61.966835021972656, "reward": 0.4733065366744995, "action": -1.026120662689209}
{"mode": "train", "epochs": 11, "timestep": 20088, "ep_reward": 62.294132232666016, "reward": 0.3272988796234131, "action": -1.2246037721633911}
{"mode": "train", "epochs": 11, "timestep": 20089, "ep_reward": 62.460445404052734, "reward": 0.16631156206130981, "action": -1.3951857089996338}
{"mode": "train", "epochs": 11, "timestep": 20090, "ep_reward": 62.60676574707031, "reward": 0.14631909132003784, "action": -0.44404786825180054}
{"mode": "train", "epochs": 11, "timestep": 20091, "ep_reward": 62.880096435546875, "reward": 0.2733306884765625, "action": -1.237499475479126}
{"mode": "train", "epochs": 11, "timestep": 20092, "ep_reward": 63.27316665649414, "reward": 0.3930683732032776, "action": -0.8792563676834106}
{"mode": "train", "epochs": 11, "timestep": 20093, "ep_reward": 63.78540802001953, "reward": 0.5122395753860474, "action": -2.0}
{"mode": "train", "epochs": 11, "timestep": 20094, "ep_reward": 64.39480590820312, "reward": 0.6094003319740295, "action": -1.0453171730041504}
{"mode": "train", "epochs": 11, "timestep": 20095, "ep_reward": 65.09648132324219, "reward": 0.7016764879226685, "action": -0.3368067145347595}
{"mode": "train", "epochs": 11, "timestep": 20096, "ep_reward": 65.87786865234375, "reward": 0.7813893556594849, "action": -1.1473842859268188}
{"mode": "train", "epochs": 11, "timestep": 20097, "ep_reward": 66.71476745605469, "reward": 0.8368992209434509, "action": -0.7462825179100037}
{"mode": "train", "epochs": 11, "timestep": 20098, "ep_reward": 67.59542083740234, "reward": 0.8806524872779846, "action": -0.7435739636421204}
{"mode": "train", "epochs": 11, "timestep": 20099, "ep_reward": 68.50759887695312, "reward": 0.9121814966201782, "action": -0.5454638600349426}
{"mode": "train", "epochs": 11, "timestep": 20100, "ep_reward": 69.44258117675781, "reward": 0.9349852204322815, "action": -1.6141260862350464}
{"mode": "train", "epochs": 11, "timestep": 20101, "ep_reward": 70.38800048828125, "reward": 0.9454162120819092, "action": -1.293957233428955}
{"mode": "train", "epochs": 11, "timestep": 20102, "ep_reward": 71.33956909179688, "reward": 0.9515718817710876, "action": -1.7044321298599243}
{"mode": "train", "epochs": 11, "timestep": 20103, "ep_reward": 72.28978729248047, "reward": 0.950215756893158, "action": -0.7416614294052124}
{"mode": "train", "epochs": 11, "timestep": 20104, "ep_reward": 73.23725891113281, "reward": 0.947468638420105, "action": -0.9857838153839111}
{"mode": "train", "epochs": 11, "timestep": 20105, "ep_reward": 74.17357635498047, "reward": 0.9363155364990234, "action": -0.8748959302902222}
{"mode": "train", "epochs": 11, "timestep": 20106, "ep_reward": 75.09026336669922, "reward": 0.916684627532959, "action": -0.8867002725601196}
{"mode": "train", "epochs": 11, "timestep": 20107, "ep_reward": 75.97511291503906, "reward": 0.8848474025726318, "action": -0.34702837467193604}
{"mode": "train", "epochs": 11, "timestep": 20108, "ep_reward": 76.81626892089844, "reward": 0.8411560654640198, "action": -0.7182981371879578}
{"mode": "train", "epochs": 11, "timestep": 20109, "ep_reward": 77.5898666381836, "reward": 0.7736008167266846, "action": -0.5964127779006958}
{"mode": "train", "epochs": 11, "timestep": 20110, "ep_reward": 78.27005004882812, "reward": 0.6801832914352417, "action": -0.9541734457015991}
{"mode": "train", "epochs": 11, "timestep": 20111, "ep_reward": 78.81999206542969, "reward": 0.5499426126480103, "action": -1.0864166021347046}
{"mode": "train", "epochs": 11, "timestep": 20112, "ep_reward": 79.20199584960938, "reward": 0.3820047378540039, "action": -0.31427472829818726}
{"mode": "train", "epochs": 11, "timestep": 20113, "ep_reward": 79.42329406738281, "reward": 0.22130036354064941, "action": -0.5827734470367432}
{"mode": "train", "epochs": 11, "timestep": 20114, "ep_reward": 79.51140594482422, "reward": 0.08810937404632568, "action": -1.4882187843322754}
{"mode": "train", "epochs": 11, "timestep": 20115, "ep_reward": 79.54064178466797, "reward": 0.029237210750579834, "action": -1.2108525037765503}
{"mode": "train", "epochs": 11, "timestep": 20116, "ep_reward": 79.71080780029297, "reward": 0.17016446590423584, "action": -2.0}
{"mode": "train", "epochs": 11, "timestep": 20117, "ep_reward": 80.00851440429688, "reward": 0.29770398139953613, "action": -0.4515155553817749}
{"mode": "train", "epochs": 11, "timestep": 20118, "ep_reward": 80.45110321044922, "reward": 0.44259172677993774, "action": -0.22783499956130981}
{"mode": "train", "epochs": 11, "timestep": 20119, "ep_reward": 81.02494812011719, "reward": 0.5738427042961121, "action": -0.9380780458450317}
{"mode": "train", "epochs": 11, "timestep": 20120, "ep_reward": 81.69966125488281, "reward": 0.6747139692306519, "action": -1.230104684829712}
{"mode": "train", "epochs": 11, "timestep": 20121, "ep_reward": 82.44976806640625, "reward": 0.7501044869422913, "action": -1.3679680824279785}
{"mode": "train", "epochs": 11, "timestep": 20122, "ep_reward": 83.25288391113281, "reward": 0.803118109703064, "action": -0.8244579434394836}
{"mode": "train", "epochs": 11, "timestep": 20123, "ep_reward": 84.09435272216797, "reward": 0.8414710164070129, "action": -1.4118133783340454}
{"mode": "train", "epochs": 11, "timestep": 20124, "ep_reward": 84.95137023925781, "reward": 0.8570173978805542, "action": -1.1147412061691284}
{"mode": "train", "epochs": 11, "timestep": 20125, "ep_reward": 85.80941009521484, "reward": 0.8580429553985596, "action": -1.2416776418685913}
{"mode": "train", "epochs": 11, "timestep": 20126, "ep_reward": 86.64895629882812, "reward": 0.8395429253578186, "action": -1.586273431777954}
{"mode": "train", "epochs": 11, "timestep": 20127, "ep_reward": 87.44461059570312, "reward": 0.7956516146659851, "action": -1.022218108177185}
{"mode": "train", "epochs": 11, "timestep": 20128, "ep_reward": 88.17405700683594, "reward": 0.7294480800628662, "action": -1.3787648677825928}
{"mode": "train", "epochs": 11, "timestep": 20129, "ep_reward": 88.79816436767578, "reward": 0.6241046190261841, "action": -0.758791446685791}
{"mode": "train", "epochs": 11, "timestep": 20130, "ep_reward": 89.28349304199219, "reward": 0.48532670736312866, "action": -1.6884570121765137}
{"mode": "train", "epochs": 11, "timestep": 20131, "ep_reward": 89.63872528076172, "reward": 0.3552287220954895, "action": -0.5762455463409424}
{"mode": "train", "epochs": 11, "timestep": 20132, "ep_reward": 89.885009765625, "reward": 0.24628639221191406, "action": -0.546353816986084}
{"mode": "train", "epochs": 11, "timestep": 20133, "ep_reward": 90.0022964477539, "reward": 0.11728864908218384, "action": -1.073868989944458}
{"mode": "train", "epochs": 11, "timestep": 20134, "ep_reward": 89.99998474121094, "reward": -0.002308368682861328, "action": -0.529015839099884}
{"mode": "train", "epochs": 11, "timestep": 20135, "ep_reward": 90.14278411865234, "reward": 0.1427973508834839, "action": -1.4225232601165771}
{"mode": "train", "epochs": 11, "timestep": 20136, "ep_reward": 90.41976165771484, "reward": 0.27697569131851196, "action": -0.5086818933486938}
{"mode": "train", "epochs": 11, "timestep": 20137, "ep_reward": 90.84085845947266, "reward": 0.4210951328277588, "action": -1.4739195108413696}
{"mode": "train", "epochs": 11, "timestep": 20138, "ep_reward": 91.38153839111328, "reward": 0.5406813025474548, "action": -0.9531355500221252}
{"mode": "train", "epochs": 11, "timestep": 20139, "ep_reward": 92.02928924560547, "reward": 0.6477524042129517, "action": -0.8615855574607849}
{"mode": "train", "epochs": 11, "timestep": 20140, "ep_reward": 92.76204681396484, "reward": 0.7327609062194824, "action": -0.9023118019104004}
{"mode": "train", "epochs": 11, "timestep": 20141, "ep_reward": 93.55667114257812, "reward": 0.7946237921714783, "action": -0.8316829800605774}
{"mode": "train", "epochs": 11, "timestep": 20142, "ep_reward": 94.393310546875, "reward": 0.8366408944129944, "action": -0.7231675386428833}
{"mode": "train", "epochs": 11, "timestep": 20143, "ep_reward": 95.25475311279297, "reward": 0.8614429235458374, "action": -0.6910544633865356}
{"mode": "train", "epochs": 11, "timestep": 20144, "ep_reward": 96.124755859375, "reward": 0.8700004816055298, "action": 0.03394341468811035}
{"mode": "train", "epochs": 11, "timestep": 20145, "ep_reward": 96.99333190917969, "reward": 0.8685725927352905, "action": -0.13907349109649658}
{"mode": "train", "epochs": 11, "timestep": 20146, "ep_reward": 97.84225463867188, "reward": 0.8489221930503845, "action": -0.8825198411941528}
{"mode": "train", "epochs": 11, "timestep": 20147, "ep_reward": 98.64483642578125, "reward": 0.8025791645050049, "action": -0.31894683837890625}
{"mode": "train", "epochs": 11, "timestep": 20148, "ep_reward": 99.38134765625, "reward": 0.7365138530731201, "action": -0.7976405024528503}
{"mode": "train", "epochs": 11, "timestep": 20149, "ep_reward": 100.0151596069336, "reward": 0.6338106393814087, "action": -1.5023138523101807}
{"mode": "train", "epochs": 11, "timestep": 20150, "ep_reward": 100.49797058105469, "reward": 0.48281437158584595, "action": -1.6447327136993408}
{"mode": "train", "epochs": 11, "timestep": 20151, "ep_reward": 100.82833099365234, "reward": 0.33036404848098755, "action": -1.839977741241455}
{"mode": "train", "epochs": 11, "timestep": 20152, "ep_reward": 101.04499816894531, "reward": 0.21667015552520752, "action": -1.2224438190460205}
{"mode": "train", "epochs": 11, "timestep": 20153, "ep_reward": 101.12794494628906, "reward": 0.08294552564620972, "action": -0.31080079078674316}
{"mode": "train", "epochs": 11, "timestep": 20154, "ep_reward": 101.16283416748047, "reward": 0.03489041328430176, "action": -0.22180312871932983}
{"mode": "train", "epochs": 11, "timestep": 20155, "ep_reward": 101.34358978271484, "reward": 0.1807573437690735, "action": -1.2488752603530884}
{"mode": "train", "epochs": 11, "timestep": 20156, "ep_reward": 101.66015625, "reward": 0.31656503677368164, "action": -1.0785727500915527}
{"mode": "train", "epochs": 11, "timestep": 20157, "ep_reward": 102.11070251464844, "reward": 0.4505462646484375, "action": -1.2325706481933594}
{"mode": "train", "epochs": 11, "timestep": 20158, "ep_reward": 102.67969512939453, "reward": 0.5689929723739624, "action": -1.4705991744995117}
{"mode": "train", "epochs": 11, "timestep": 20159, "ep_reward": 103.34493255615234, "reward": 0.665238618850708, "action": -1.0470292568206787}
{"mode": "train", "epochs": 11, "timestep": 20160, "ep_reward": 104.08866882324219, "reward": 0.7437334060668945, "action": -1.2679109573364258}
{"mode": "train", "epochs": 11, "timestep": 20161, "ep_reward": 104.88661193847656, "reward": 0.7979437112808228, "action": -0.5080238580703735}
{"mode": "train", "epochs": 11, "timestep": 20162, "ep_reward": 105.72533416748047, "reward": 0.8387255072593689, "action": -0.6332983374595642}
{"mode": "train", "epochs": 11, "timestep": 20163, "ep_reward": 106.5850601196289, "reward": 0.8597286343574524, "action": -0.7591854333877563}
{"mode": "train", "epochs": 11, "timestep": 20164, "ep_reward": 107.44749450683594, "reward": 0.8624357581138611, "action": -1.594710350036621}
{"mode": "train", "epochs": 11, "timestep": 20165, "ep_reward": 108.28740692138672, "reward": 0.8399139642715454, "action": -0.7713529467582703}
{"mode": "train", "epochs": 11, "timestep": 20166, "ep_reward": 109.09089660644531, "reward": 0.8034898042678833, "action": -0.2408844232559204}
{"mode": "train", "epochs": 11, "timestep": 20167, "ep_reward": 109.83815002441406, "reward": 0.7472506761550903, "action": -0.8736652135848999}
{"mode": "train", "epochs": 11, "timestep": 20168, "ep_reward": 110.49108123779297, "reward": 0.6529291868209839, "action": -0.2820553183555603}
{"mode": "train", "epochs": 11, "timestep": 20169, "ep_reward": 111.02000427246094, "reward": 0.5289204120635986, "action": -1.818555474281311}
{"mode": "train", "epochs": 11, "timestep": 20170, "ep_reward": 111.3846435546875, "reward": 0.36463624238967896, "action": -1.3481664657592773}
{"mode": "train", "epochs": 11, "timestep": 20171, "ep_reward": 111.64229583740234, "reward": 0.2576492428779602, "action": -1.2363301515579224}
{"mode": "train", "epochs": 11, "timestep": 20172, "ep_reward": 111.77291870117188, "reward": 0.13062089681625366, "action": -1.3786940574645996}
{"mode": "train", "epochs": 11, "timestep": 20173, "ep_reward": 111.7566146850586, "reward": -0.016306161880493164, "action": -0.8091290593147278}
{"mode": "train", "epochs": 11, "timestep": 20174, "ep_reward": 111.8863296508789, "reward": 0.1297178864479065, "action": -0.09402871131896973}
{"mode": "train", "epochs": 11, "timestep": 20175, "ep_reward": 112.16634368896484, "reward": 0.2800148129463196, "action": 0.25609707832336426}
{"mode": "train", "epochs": 11, "timestep": 20176, "ep_reward": 112.59660339355469, "reward": 0.4302629232406616, "action": -0.16694146394729614}
{"mode": "train", "epochs": 11, "timestep": 20177, "ep_reward": 113.15744018554688, "reward": 0.5608365535736084, "action": -1.2206839323043823}
{"mode": "train", "epochs": 11, "timestep": 20178, "ep_reward": 113.81861114501953, "reward": 0.6611732244491577, "action": -1.2184083461761475}
{"mode": "train", "epochs": 11, "timestep": 20179, "ep_reward": 114.56072235107422, "reward": 0.742113471031189, "action": -1.2113420963287354}
{"mode": "train", "epochs": 11, "timestep": 20180, "ep_reward": 115.36449432373047, "reward": 0.8037742376327515, "action": -0.5312526822090149}
{"mode": "train", "epochs": 11, "timestep": 20181, "ep_reward": 116.21746063232422, "reward": 0.8529642224311829, "action": -0.9842041730880737}
{"mode": "train", "epochs": 11, "timestep": 20182, "ep_reward": 117.10032653808594, "reward": 0.8828643560409546, "action": -1.2883079051971436}
{"mode": "train", "epochs": 11, "timestep": 20183, "ep_reward": 117.99797821044922, "reward": 0.8976554274559021, "action": -1.1062883138656616}
{"mode": "train", "epochs": 11, "timestep": 20184, "ep_reward": 118.89970397949219, "reward": 0.9017252326011658, "action": -1.417024850845337}
{"mode": "train", "epochs": 11, "timestep": 20185, "ep_reward": 119.79078674316406, "reward": 0.8910865783691406, "action": -0.5546866655349731}
{"mode": "train", "epochs": 11, "timestep": 20186, "ep_reward": 120.66346740722656, "reward": 0.8726800084114075, "action": -0.8989914655685425}
{"mode": "train", "epochs": 11, "timestep": 20187, "ep_reward": 121.49760437011719, "reward": 0.8341373801231384, "action": -1.0529767274856567}
{"mode": "train", "epochs": 11, "timestep": 20188, "ep_reward": 122.26897430419922, "reward": 0.7713719010353088, "action": -0.6614586114883423}
{"mode": "train", "epochs": 11, "timestep": 20189, "ep_reward": 122.95258331298828, "reward": 0.6836111545562744, "action": -1.1197240352630615}
{"mode": "train", "epochs": 11, "timestep": 20190, "ep_reward": 123.50753021240234, "reward": 0.5549488067626953, "action": -1.1322611570358276}
{"mode": "train", "epochs": 11, "timestep": 20191, "ep_reward": 123.893310546875, "reward": 0.38577866554260254, "action": -1.0052809715270996}
{"mode": "train", "epochs": 11, "timestep": 20192, "ep_reward": 124.15509033203125, "reward": 0.26177978515625, "action": -0.8636945486068726}
{"mode": "train", "epochs": 11, "timestep": 20193, "ep_reward": 124.29045867919922, "reward": 0.13537049293518066, "action": -1.5527342557907104}
{"mode": "train", "epochs": 11, "timestep": 20194, "ep_reward": 124.27947998046875, "reward": -0.010975480079650879, "action": -1.750274658203125}
{"mode": "train", "epochs": 11, "timestep": 20195, "ep_reward": 124.40435791015625, "reward": 0.12487667798995972, "action": -0.6997009515762329}
{"mode": "train", "epochs": 11, "timestep": 20196, "ep_reward": 124.67180633544922, "reward": 0.26744550466537476, "action": -1.5796442031860352}
{"mode": "train", "epochs": 11, "timestep": 20197, "ep_reward": 125.06961059570312, "reward": 0.39780116081237793, "action": -0.561211347579956}
{"mode": "train", "epochs": 11, "timestep": 20198, "ep_reward": 125.60043334960938, "reward": 0.5308242440223694, "action": -0.9421661496162415}
{"mode": "train", "epochs": 11, "timestep": 20199, "ep_reward": 126.24029541015625, "reward": 0.6398648023605347, "action": -0.21532708406448364}
{"mode": "train", "epochs": 11, "timestep": 20200, "ep_reward": 126.97376251220703, "reward": 0.7334665060043335, "action": -1.2553833723068237}
{"mode": "train", "epochs": 11, "timestep": 20201, "ep_reward": 127.76798248291016, "reward": 0.7942163348197937, "action": -0.24449580907821655}
{"mode": "train", "epochs": 11, "timestep": 20202, "ep_reward": 128.61204528808594, "reward": 0.8440673351287842, "action": -1.3534860610961914}
{"mode": "train", "epochs": 11, "timestep": 20203, "ep_reward": 129.4794464111328, "reward": 0.867402970790863, "action": -0.40199708938598633}
{"mode": "train", "epochs": 11, "timestep": 20204, "ep_reward": 130.362548828125, "reward": 0.8831014633178711, "action": -1.6859509944915771}
{"mode": "train", "epochs": 11, "timestep": 20205, "ep_reward": 131.2363739013672, "reward": 0.873822808265686, "action": -1.7493791580200195}
{"mode": "train", "epochs": 11, "timestep": 20206, "ep_reward": 132.0831756591797, "reward": 0.8467949628829956, "action": -1.3870214223861694}
{"mode": "train", "epochs": 11, "timestep": 20207, "ep_reward": 132.88438415527344, "reward": 0.801205575466156, "action": -1.6086629629135132}
{"mode": "train", "epochs": 11, "timestep": 20208, "ep_reward": 133.6096954345703, "reward": 0.7253061532974243, "action": -0.07838791608810425}
{"mode": "train", "epochs": 11, "timestep": 20209, "ep_reward": 134.2430877685547, "reward": 0.6333962678909302, "action": -1.071534276008606}
{"mode": "train", "epochs": 11, "timestep": 20210, "ep_reward": 134.733642578125, "reward": 0.4905616044998169, "action": -1.393712043762207}
{"mode": "train", "epochs": 11, "timestep": 20211, "ep_reward": 135.07958984375, "reward": 0.34595155715942383, "action": -0.8103967905044556}
{"mode": "train", "epochs": 11, "timestep": 20212, "ep_reward": 135.31468200683594, "reward": 0.2350904941558838, "action": -1.2859108448028564}
{"mode": "train", "epochs": 11, "timestep": 20213, "ep_reward": 135.4190673828125, "reward": 0.10438287258148193, "action": -0.4414534568786621}
{"mode": "train", "epochs": 11, "timestep": 20214, "ep_reward": 135.43104553222656, "reward": 0.011972963809967041, "action": -0.7893942594528198}
{"mode": "train", "epochs": 11, "timestep": 20215, "ep_reward": 135.58627319335938, "reward": 0.15522277355194092, "action": -1.5515049695968628}
{"mode": "train", "epochs": 11, "timestep": 20216, "ep_reward": 135.8743438720703, "reward": 0.28806865215301514, "action": -0.5280424356460571}
{"mode": "train", "epochs": 11, "timestep": 20217, "ep_reward": 136.30609130859375, "reward": 0.43175196647644043, "action": -0.10669523477554321}
{"mode": "train", "epochs": 11, "timestep": 20218, "ep_reward": 136.87156677246094, "reward": 0.565467894077301, "action": -1.0035970211029053}
{"mode": "train", "epochs": 11, "timestep": 20219, "ep_reward": 137.53897094726562, "reward": 0.6673998832702637, "action": -1.2865060567855835}
{"mode": "train", "epochs": 11, "timestep": 20220, "ep_reward": 138.28369140625, "reward": 0.7447140216827393, "action": -1.0718485116958618}
{"mode": "train", "epochs": 11, "timestep": 20221, "ep_reward": 139.08676147460938, "reward": 0.8030662536621094, "action": -1.1821935176849365}
{"mode": "train", "epochs": 11, "timestep": 20222, "ep_reward": 139.92799377441406, "reward": 0.8412378430366516, "action": -0.8863306641578674}
{"mode": "train", "epochs": 11, "timestep": 20223, "ep_reward": 140.79263305664062, "reward": 0.8646405935287476, "action": -1.3949973583221436}
{"mode": "train", "epochs": 11, "timestep": 20224, "ep_reward": 141.6604766845703, "reward": 0.8678508996963501, "action": -0.7594307661056519}
{"mode": "train", "epochs": 11, "timestep": 20225, "ep_reward": 142.52037048339844, "reward": 0.8598943948745728, "action": -0.78362637758255}
{"mode": "train", "epochs": 11, "timestep": 20226, "ep_reward": 143.3536834716797, "reward": 0.8333095908164978, "action": -1.090856671333313}
{"mode": "train", "epochs": 11, "timestep": 20227, "ep_reward": 144.1348876953125, "reward": 0.7812085747718811, "action": -0.6853662133216858}
{"mode": "train", "epochs": 11, "timestep": 20228, "ep_reward": 144.83958435058594, "reward": 0.7047003507614136, "action": -1.413083553314209}
{"mode": "train", "epochs": 11, "timestep": 20229, "ep_reward": 145.42323303222656, "reward": 0.5836522579193115, "action": -1.0698678493499756}
{"mode": "train", "epochs": 11, "timestep": 20230, "ep_reward": 145.8479461669922, "reward": 0.42471379041671753, "action": -1.0868679285049438}
{"mode": "train", "epochs": 11, "timestep": 20231, "ep_reward": 146.15509033203125, "reward": 0.30714428424835205, "action": -0.6488116979598999}
{"mode": "train", "epochs": 11, "timestep": 20232, "ep_reward": 146.34402465820312, "reward": 0.18893426656723022, "action": -0.36617058515548706}
{"mode": "train", "epochs": 11, "timestep": 20233, "ep_reward": 146.39453125, "reward": 0.05051201581954956, "action": -1.8005166053771973}
{"mode": "train", "epochs": 11, "timestep": 20234, "ep_reward": 146.46188354492188, "reward": 0.06734907627105713, "action": -2.0}
{"mode": "train", "epochs": 11, "timestep": 20235, "ep_reward": 146.66539001464844, "reward": 0.2035096287727356, "action": -0.587449312210083}
{"mode": "train", "epochs": 11, "timestep": 20236, "ep_reward": 147.01429748535156, "reward": 0.3489089608192444, "action": -1.203547716140747}
{"mode": "train", "epochs": 11, "timestep": 20237, "ep_reward": 147.49330139160156, "reward": 0.4790053367614746, "action": -0.45512521266937256}
{"mode": "train", "epochs": 11, "timestep": 20238, "ep_reward": 148.09518432617188, "reward": 0.6018761396408081, "action": -1.460394024848938}
{"mode": "train", "epochs": 11, "timestep": 20239, "ep_reward": 148.78701782226562, "reward": 0.69183349609375, "action": -1.4575241804122925}
{"mode": "train", "epochs": 11, "timestep": 20240, "ep_reward": 149.5474853515625, "reward": 0.7604655027389526, "action": -1.3558080196380615}
{"mode": "train", "epochs": 11, "timestep": 20241, "ep_reward": 150.3568878173828, "reward": 0.8094085454940796, "action": -0.4469190239906311}
{"mode": "train", "epochs": 11, "timestep": 20242, "ep_reward": 151.203857421875, "reward": 0.8469631671905518, "action": -0.7318239212036133}
{"mode": "train", "epochs": 11, "timestep": 20243, "ep_reward": 152.06777954101562, "reward": 0.863917350769043, "action": -1.9054288864135742}
{"mode": "train", "epochs": 11, "timestep": 20244, "ep_reward": 152.92185974121094, "reward": 0.8540812730789185, "action": -0.9004881381988525}
{"mode": "train", "epochs": 11, "timestep": 20245, "ep_reward": 153.75588989257812, "reward": 0.8340314626693726, "action": -1.3522534370422363}
{"mode": "train", "epochs": 11, "timestep": 20246, "ep_reward": 154.54293823242188, "reward": 0.7870429754257202, "action": -0.8672443628311157}
{"mode": "train", "epochs": 11, "timestep": 20247, "ep_reward": 155.25938415527344, "reward": 0.7164527177810669, "action": -1.2932898998260498}
{"mode": "train", "epochs": 11, "timestep": 20248, "ep_reward": 155.86453247070312, "reward": 0.6051479578018188, "action": -1.517970085144043}
{"mode": "train", "epochs": 11, "timestep": 20249, "ep_reward": 156.31182861328125, "reward": 0.4472993016242981, "action": -0.6629079580307007}
{"mode": "train", "epochs": 11, "timestep": 20250, "ep_reward": 156.64622497558594, "reward": 0.3343920111656189, "action": -0.8628658652305603}
{"mode": "train", "epochs": 11, "timestep": 20251, "ep_reward": 156.8674774169922, "reward": 0.22125446796417236, "action": -1.3755772113800049}
{"mode": "train", "epochs": 11, "timestep": 20252, "ep_reward": 156.95574951171875, "reward": 0.0882686972618103, "action": -0.7808683514595032}
{"mode": "train", "epochs": 11, "timestep": 20253, "ep_reward": 156.98486328125, "reward": 0.029109835624694824, "action": -1.5862724781036377}
{"mode": "train", "epochs": 11, "timestep": 20254, "ep_reward": 157.15521240234375, "reward": 0.1703529953956604, "action": -0.3642733693122864}
{"mode": "train", "epochs": 11, "timestep": 20255, "ep_reward": 157.47317504882812, "reward": 0.3179646134376526, "action": -1.8489296436309814}
{"mode": "train", "epochs": 11, "timestep": 20256, "ep_reward": 157.91526794433594, "reward": 0.44209033250808716, "action": -0.6559820175170898}
{"mode": "train", "epochs": 11, "timestep": 20257, "ep_reward": 158.483642578125, "reward": 0.5683779120445251, "action": -1.145333170890808}
{"mode": "train", "epochs": 11, "timestep": 20258, "ep_reward": 159.15191650390625, "reward": 0.6682714223861694, "action": -0.15222179889678955}
{"mode": "train", "epochs": 11, "timestep": 20259, "ep_reward": 159.90716552734375, "reward": 0.7552445530891418, "action": -0.7735385894775391}
{"mode": "train", "epochs": 11, "timestep": 20260, "ep_reward": 160.72032165527344, "reward": 0.813148558139801, "action": -1.7956221103668213}
{"mode": "train", "epochs": 11, "timestep": 20261, "ep_reward": 161.56393432617188, "reward": 0.8436172008514404, "action": -1.0218851566314697}
{"mode": "train", "epochs": 11, "timestep": 20262, "ep_reward": 162.42799377441406, "reward": 0.8640621304512024, "action": -0.7769694328308105}
{"mode": "train", "epochs": 11, "timestep": 20263, "ep_reward": 163.29830932617188, "reward": 0.870319128036499, "action": -1.3864936828613281}
{"mode": "train", "epochs": 11, "timestep": 20264, "ep_reward": 164.15310668945312, "reward": 0.8548007011413574, "action": -1.1225115060806274}
{"mode": "train", "epochs": 11, "timestep": 20265, "ep_reward": 164.97511291503906, "reward": 0.822008490562439, "action": -0.47727102041244507}
{"mode": "train", "epochs": 11, "timestep": 20266, "ep_reward": 165.74691772460938, "reward": 0.7717991471290588, "action": -1.4277417659759521}
{"mode": "train", "epochs": 11, "timestep": 20267, "ep_reward": 166.42828369140625, "reward": 0.6813678741455078, "action": -1.2685235738754272}
{"mode": "train", "epochs": 11, "timestep": 20268, "ep_reward": 166.9823455810547, "reward": 0.5540686249732971, "action": -0.8742761611938477}
{"mode": "train", "epochs": 11, "timestep": 20269, "ep_reward": 167.37200927734375, "reward": 0.38967037200927734, "action": -0.8732995390892029}
{"mode": "train", "epochs": 11, "timestep": 20270, "ep_reward": 167.6591033935547, "reward": 0.2870931029319763, "action": -0.6988386511802673}
{"mode": "train", "epochs": 11, "timestep": 20271, "ep_reward": 167.8243408203125, "reward": 0.16523903608322144, "action": -0.46296608448028564}
{"mode": "train", "epochs": 11, "timestep": 20272, "ep_reward": 167.84767150878906, "reward": 0.023337066173553467, "action": -0.8383935689926147}
{"mode": "train", "epochs": 11, "timestep": 20273, "ep_reward": 167.9414825439453, "reward": 0.0938144326210022, "action": -0.7620672583580017}
{"mode": "train", "epochs": 11, "timestep": 20274, "ep_reward": 168.17620849609375, "reward": 0.23472654819488525, "action": -1.7054991722106934}
{"mode": "train", "epochs": 11, "timestep": 20275, "ep_reward": 168.5409698486328, "reward": 0.36476558446884155, "action": -1.1917868852615356}
{"mode": "train", "epochs": 11, "timestep": 20276, "ep_reward": 169.0352783203125, "reward": 0.494303822517395, "action": -1.0423256158828735}
{"mode": "train", "epochs": 11, "timestep": 20277, "ep_reward": 169.64389038085938, "reward": 0.6086161732673645, "action": -0.8081369996070862}
{"mode": "train", "epochs": 11, "timestep": 20278, "ep_reward": 170.34669494628906, "reward": 0.7028010487556458, "action": -1.921633243560791}
{"mode": "train", "epochs": 11, "timestep": 20279, "ep_reward": 171.1096649169922, "reward": 0.7629735469818115, "action": -0.11611813306808472}
{"mode": "train", "epochs": 11, "timestep": 20280, "ep_reward": 171.92868041992188, "reward": 0.8190081715583801, "action": -1.0298655033111572}
{"mode": "train", "epochs": 11, "timestep": 20281, "ep_reward": 172.7749481201172, "reward": 0.8462706804275513, "action": -0.9318966269493103}
{"mode": "train", "epochs": 11, "timestep": 20282, "ep_reward": 173.63148498535156, "reward": 0.8565312623977661, "action": -0.3780362606048584}
{"mode": "train", "epochs": 11, "timestep": 20283, "ep_reward": 174.48529052734375, "reward": 0.8538129329681396, "action": -1.5454938411712646}
{"mode": "train", "epochs": 11, "timestep": 20284, "ep_reward": 175.3063201904297, "reward": 0.8210288286209106, "action": -1.0394028425216675}
{"mode": "train", "epochs": 11, "timestep": 20285, "ep_reward": 176.0748291015625, "reward": 0.7685053944587708, "action": -0.8609758615493774}
{"mode": "train", "epochs": 11, "timestep": 20286, "ep_reward": 176.7623748779297, "reward": 0.6875443458557129, "action": -1.5202665328979492}
{"mode": "train", "epochs": 11, "timestep": 20287, "ep_reward": 177.32278442382812, "reward": 0.5604019165039062, "action": -0.6993244886398315}
{"mode": "train", "epochs": 11, "timestep": 20288, "ep_reward": 177.7240447998047, "reward": 0.4012550711631775, "action": -1.5028328895568848}
{"mode": "train", "epochs": 11, "timestep": 20289, "ep_reward": 178.02407836914062, "reward": 0.3000349998474121, "action": -0.25452369451522827}
{"mode": "train", "epochs": 11, "timestep": 20290, "ep_reward": 178.20449829101562, "reward": 0.18041932582855225, "action": -1.144496202468872}
{"mode": "train", "epochs": 11, "timestep": 20291, "ep_reward": 178.2454376220703, "reward": 0.040936291217803955, "action": -0.6559823155403137}
{"mode": "train", "epochs": 11, "timestep": 20292, "ep_reward": 178.322509765625, "reward": 0.07707172632217407, "action": -0.8255209922790527}
{"mode": "train", "epochs": 11, "timestep": 20293, "ep_reward": 178.53924560546875, "reward": 0.21674036979675293, "action": -1.4517848491668701}
{"mode": "train", "epochs": 11, "timestep": 20294, "ep_reward": 178.8898162841797, "reward": 0.35057491064071655, "action": -0.9359345436096191}
{"mode": "train", "epochs": 11, "timestep": 20295, "ep_reward": 179.37411499023438, "reward": 0.48430144786834717, "action": -1.165235161781311}
{"mode": "train", "epochs": 11, "timestep": 20296, "ep_reward": 179.97293090820312, "reward": 0.5988084673881531, "action": -0.6574932336807251}
{"mode": "train", "epochs": 11, "timestep": 20297, "ep_reward": 180.669921875, "reward": 0.6969875693321228, "action": -1.4321832656860352}
{"mode": "train", "epochs": 11, "timestep": 20298, "ep_reward": 181.43406677246094, "reward": 0.7641454935073853, "action": -0.5024774074554443}
{"mode": "train", "epochs": 11, "timestep": 20299, "ep_reward": 182.25262451171875, "reward": 0.8185528516769409, "action": -1.8719568252563477}
{"mode": "train", "epochs": 11, "timestep": 20300, "ep_reward": 183.09414672851562, "reward": 0.841526210308075, "action": -0.6754857301712036}
{"mode": "train", "epochs": 11, "timestep": 20301, "ep_reward": 183.95138549804688, "reward": 0.8572395443916321, "action": -1.4025752544403076}
{"mode": "train", "epochs": 11, "timestep": 20302, "ep_reward": 184.80020141601562, "reward": 0.8488094806671143, "action": -0.8616626858711243}
{"mode": "train", "epochs": 11, "timestep": 20303, "ep_reward": 185.62567138671875, "reward": 0.8254682421684265, "action": -1.3630976676940918}
{"mode": "train", "epochs": 11, "timestep": 20304, "ep_reward": 186.39907836914062, "reward": 0.7734082341194153, "action": -0.9540160298347473}
{"mode": "train", "epochs": 11, "timestep": 20305, "ep_reward": 187.094482421875, "reward": 0.6954072713851929, "action": -0.8391658663749695}
{"mode": "train", "epochs": 11, "timestep": 20306, "ep_reward": 187.67665100097656, "reward": 0.5821671485900879, "action": -1.4248275756835938}
{"mode": "train", "epochs": 11, "timestep": 20307, "ep_reward": 188.09454345703125, "reward": 0.41789573431015015, "action": -1.0290952920913696}
{"mode": "train", "epochs": 11, "timestep": 20308, "ep_reward": 188.4092559814453, "reward": 0.31470823287963867, "action": -0.9284393787384033}
{"mode": "train", "epochs": 11, "timestep": 20309, "ep_reward": 188.6070098876953, "reward": 0.19775933027267456, "action": -1.7296528816223145}
{"mode": "train", "epochs": 11, "timestep": 20310, "ep_reward": 188.6681365966797, "reward": 0.0611194372177124, "action": -0.41925889253616333}
{"mode": "train", "epochs": 11, "timestep": 20311, "ep_reward": 188.72531127929688, "reward": 0.05717223882675171, "action": -1.0845545530319214}
{"mode": "train", "epochs": 11, "timestep": 20312, "ep_reward": 188.91986083984375, "reward": 0.19454264640808105, "action": -0.8696744441986084}
{"mode": "train", "epochs": 11, "timestep": 20313, "ep_reward": 189.25628662109375, "reward": 0.33643215894699097, "action": -0.9091025590896606}
{"mode": "train", "epochs": 11, "timestep": 20314, "ep_reward": 189.7275390625, "reward": 0.47124719619750977, "action": -1.147871971130371}
{"mode": "train", "epochs": 11, "timestep": 20315, "ep_reward": 190.31512451171875, "reward": 0.5875903367996216, "action": -1.9793577194213867}
{"mode": "train", "epochs": 11, "timestep": 20316, "ep_reward": 190.9900665283203, "reward": 0.6749359369277954, "action": -0.3629283905029297}
{"mode": "train", "epochs": 11, "timestep": 20317, "ep_reward": 191.7469482421875, "reward": 0.756875216960907, "action": -1.5914925336837769}
{"mode": "train", "epochs": 11, "timestep": 20318, "ep_reward": 192.55126953125, "reward": 0.804328203201294, "action": -0.648200273513794}
{"mode": "train", "epochs": 11, "timestep": 20319, "ep_reward": 193.39186096191406, "reward": 0.8405920267105103, "action": -1.4860188961029053}
{"mode": "train", "epochs": 11, "timestep": 20320, "ep_reward": 194.2429962158203, "reward": 0.8511425256729126, "action": -0.4776013493537903}
{"mode": "train", "epochs": 11, "timestep": 20321, "ep_reward": 195.09559631347656, "reward": 0.8526057600975037, "action": -0.9392305016517639}
{"mode": "train", "epochs": 11, "timestep": 20322, "ep_reward": 195.92636108398438, "reward": 0.8307640552520752, "action": -1.128830909729004}
{"mode": "train", "epochs": 11, "timestep": 20323, "ep_reward": 196.71047973632812, "reward": 0.784113883972168, "action": -1.4810785055160522}
{"mode": "train", "epochs": 11, "timestep": 20324, "ep_reward": 197.41461181640625, "reward": 0.7041376829147339, "action": -0.3840423822402954}
{"mode": "train", "epochs": 11, "timestep": 20325, "ep_reward": 198.01597595214844, "reward": 0.6013709902763367, "action": -0.4738706946372986}
{"mode": "train", "epochs": 11, "timestep": 20326, "ep_reward": 198.47434997558594, "reward": 0.458376407623291, "action": -0.6766992807388306}
{"mode": "train", "epochs": 11, "timestep": 20327, "ep_reward": 198.8041229248047, "reward": 0.32976698875427246, "action": -0.5416038036346436}
{"mode": "train", "epochs": 11, "timestep": 20328, "ep_reward": 199.01980590820312, "reward": 0.2156902551651001, "action": -1.4439823627471924}
{"mode": "train", "epochs": 11, "timestep": 20329, "ep_reward": 199.10162353515625, "reward": 0.08181607723236084, "action": -0.7958876490592957}
{"mode": "train", "epochs": 11, "timestep": 20330, "ep_reward": 199.13754272460938, "reward": 0.03592634201049805, "action": -1.3412147760391235}
{"mode": "train", "epochs": 11, "timestep": 20331, "ep_reward": 199.313720703125, "reward": 0.17618364095687866, "action": -0.8977358937263489}
{"mode": "train", "epochs": 11, "timestep": 20332, "ep_reward": 199.6312255859375, "reward": 0.31751203536987305, "action": -0.6711666584014893}
{"mode": "train", "epochs": 11, "timestep": 20333, "ep_reward": 200.08766174316406, "reward": 0.4564394950866699, "action": -1.0971622467041016}
{"mode": "train", "epochs": 11, "timestep": 20334, "ep_reward": 200.6631317138672, "reward": 0.5754720568656921, "action": -0.9635636806488037}
{"mode": "train", "epochs": 11, "timestep": 20335, "ep_reward": 201.33897399902344, "reward": 0.6758451461791992, "action": -0.7323840856552124}
{"mode": "train", "epochs": 11, "timestep": 20336, "ep_reward": 202.0946502685547, "reward": 0.7556810975074768, "action": -1.637845516204834}
{"mode": "train", "epochs": 11, "timestep": 20337, "ep_reward": 202.90040588378906, "reward": 0.8057620525360107, "action": -0.898940920829773}
{"mode": "train", "epochs": 11, "timestep": 20338, "ep_reward": 203.7438507080078, "reward": 0.8434470891952515, "action": -2.0}
{"mode": "train", "epochs": 11, "timestep": 20339, "ep_reward": 204.5984344482422, "reward": 0.8545911312103271, "action": -0.4266309142112732}
{"mode": "train", "epochs": 11, "timestep": 20340, "ep_reward": 205.46070861816406, "reward": 0.8622753620147705, "action": -0.6732063293457031}
{"mode": "train", "epochs": 11, "timestep": 20341, "ep_reward": 206.3108367919922, "reward": 0.850134551525116, "action": -1.8079288005828857}
{"mode": "train", "epochs": 11, "timestep": 20342, "ep_reward": 207.11785888671875, "reward": 0.8070281744003296, "action": -1.088696002960205}
{"mode": "train", "epochs": 11, "timestep": 20343, "ep_reward": 207.86203002929688, "reward": 0.744165301322937, "action": -0.5017834901809692}
{"mode": "train", "epochs": 11, "timestep": 20344, "ep_reward": 208.517822265625, "reward": 0.6557900309562683, "action": -1.3136236667633057}
{"mode": "train", "epochs": 11, "timestep": 20345, "ep_reward": 209.03616333007812, "reward": 0.518337607383728, "action": -1.2312002182006836}
{"mode": "train", "epochs": 11, "timestep": 20346, "ep_reward": 209.40589904785156, "reward": 0.3697403073310852, "action": -1.1729371547698975}
{"mode": "train", "epochs": 11, "timestep": 20347, "ep_reward": 209.66952514648438, "reward": 0.26362311840057373, "action": -2.0}
{"mode": "train", "epochs": 11, "timestep": 20348, "ep_reward": 209.8073272705078, "reward": 0.137806236743927, "action": -1.3471729755401611}
{"mode": "train", "epochs": 11, "timestep": 20349, "ep_reward": 209.7992706298828, "reward": -0.008056879043579102, "action": -0.6053555011749268}
{"mode": "train", "epochs": 11, "timestep": 20350, "ep_reward": 209.9216766357422, "reward": 0.12241262197494507, "action": -1.0114058256149292}
{"mode": "train", "epochs": 11, "timestep": 20351, "ep_reward": 210.18289184570312, "reward": 0.261208176612854, "action": -0.2184109091758728}
{"mode": "train", "epochs": 11, "timestep": 20352, "ep_reward": 210.59164428710938, "reward": 0.4087539315223694, "action": -1.1426514387130737}
{"mode": "train", "epochs": 11, "timestep": 20353, "ep_reward": 211.1244354248047, "reward": 0.5327873229980469, "action": -1.404532790184021}
{"mode": "train", "epochs": 11, "timestep": 20354, "ep_reward": 211.76095581054688, "reward": 0.6365166902542114, "action": -1.1393804550170898}
{"mode": "train", "epochs": 11, "timestep": 20355, "ep_reward": 212.48309326171875, "reward": 0.72213214635849, "action": -0.5820944309234619}
{"mode": "train", "epochs": 11, "timestep": 20356, "ep_reward": 213.2739715576172, "reward": 0.7908848524093628, "action": -0.7450970411300659}
{"mode": "train", "epochs": 11, "timestep": 20357, "ep_reward": 214.11134338378906, "reward": 0.83737713098526, "action": 0.22915279865264893}
{"mode": "train", "epochs": 11, "timestep": 20358, "ep_reward": 214.985107421875, "reward": 0.8737715482711792, "action": -1.3689427375793457}
{"mode": "train", "epochs": 11, "timestep": 20359, "ep_reward": 215.86720275878906, "reward": 0.8820921778678894, "action": -0.5097870826721191}
{"mode": "train", "epochs": 11, "timestep": 20360, "ep_reward": 216.7500762939453, "reward": 0.8828729391098022, "action": -0.6749333143234253}
{"mode": "train", "epochs": 11, "timestep": 20361, "ep_reward": 217.61717224121094, "reward": 0.8670985102653503, "action": -1.655409574508667}
{"mode": "train", "epochs": 11, "timestep": 20362, "ep_reward": 218.44161987304688, "reward": 0.8244537115097046, "action": -0.09920036792755127}
{"mode": "train", "epochs": 11, "timestep": 20363, "ep_reward": 219.21473693847656, "reward": 0.7731142044067383, "action": -1.0452396869659424}
{"mode": "train", "epochs": 11, "timestep": 20364, "ep_reward": 219.8980712890625, "reward": 0.6833341717720032, "action": -1.428558111190796}
{"mode": "train", "epochs": 11, "timestep": 20365, "ep_reward": 220.4496307373047, "reward": 0.5515568852424622, "action": -0.6715190410614014}
{"mode": "train", "epochs": 11, "timestep": 20366, "ep_reward": 220.83860778808594, "reward": 0.3889732360839844, "action": -1.9164693355560303}
{"mode": "train", "epochs": 11, "timestep": 20367, "ep_reward": 221.10977172851562, "reward": 0.27116745710372925, "action": -1.203758955001831}
{"mode": "train", "epochs": 11, "timestep": 20368, "ep_reward": 221.25624084472656, "reward": 0.14647585153579712, "action": -1.3242754936218262}
{"mode": "train", "epochs": 11, "timestep": 20369, "ep_reward": 221.25814819335938, "reward": 0.0019124150276184082, "action": 0.06686007976531982}
{"mode": "train", "epochs": 11, "timestep": 20370, "ep_reward": 221.37171936035156, "reward": 0.11356431245803833, "action": -0.5680431723594666}
{"mode": "train", "epochs": 11, "timestep": 20371, "ep_reward": 221.62921142578125, "reward": 0.2574892044067383, "action": -1.435784101486206}
{"mode": "train", "epochs": 11, "timestep": 20372, "ep_reward": 222.01890563964844, "reward": 0.38969922065734863, "action": -0.780994713306427}
{"mode": "train", "epochs": 11, "timestep": 20373, "ep_reward": 222.53976440429688, "reward": 0.5208511352539062, "action": -0.7452044486999512}
{"mode": "train", "epochs": 11, "timestep": 20374, "ep_reward": 223.17335510253906, "reward": 0.6335926055908203, "action": -1.4037857055664062}
{"mode": "train", "epochs": 11, "timestep": 20375, "ep_reward": 223.89077758789062, "reward": 0.7174237966537476, "action": -0.3466196656227112}
{"mode": "train", "epochs": 11, "timestep": 20376, "ep_reward": 224.68028259277344, "reward": 0.7895033359527588, "action": -0.8853131532669067}
{"mode": "train", "epochs": 11, "timestep": 20377, "ep_reward": 225.51588439941406, "reward": 0.8356055021286011, "action": -0.43753963708877563}
{"mode": "train", "epochs": 11, "timestep": 20378, "ep_reward": 226.38352966308594, "reward": 0.8676459193229675, "action": -0.7152340412139893}
{"mode": "train", "epochs": 11, "timestep": 20379, "ep_reward": 227.26531982421875, "reward": 0.8817923069000244, "action": -0.14662623405456543}
{"mode": "train", "epochs": 11, "timestep": 20380, "ep_reward": 228.1512908935547, "reward": 0.8859764933586121, "action": -0.6610240936279297}
{"mode": "train", "epochs": 11, "timestep": 20381, "ep_reward": 229.0226593017578, "reward": 0.8713745474815369, "action": -0.765256941318512}
{"mode": "train", "epochs": 11, "timestep": 20382, "ep_reward": 229.86135864257812, "reward": 0.8386989831924438, "action": -0.9756885766983032}
{"mode": "train", "epochs": 11, "timestep": 20383, "ep_reward": 230.64352416992188, "reward": 0.7821677923202515, "action": -0.3667595386505127}
{"mode": "train", "epochs": 11, "timestep": 20384, "ep_reward": 231.347900390625, "reward": 0.7043771147727966, "action": -0.9335361123085022}
{"mode": "train", "epochs": 11, "timestep": 20385, "ep_reward": 231.934326171875, "reward": 0.5864286422729492, "action": -1.350590705871582}
{"mode": "train", "epochs": 11, "timestep": 20386, "ep_reward": 232.35696411132812, "reward": 0.42263883352279663, "action": -1.52018404006958}
{"mode": "train", "epochs": 11, "timestep": 20387, "ep_reward": 232.6459197998047, "reward": 0.2889587879180908, "action": -0.6852880716323853}
{"mode": "train", "epochs": 11, "timestep": 20388, "ep_reward": 232.8132781982422, "reward": 0.1673603057861328, "action": -1.203208327293396}
{"mode": "train", "epochs": 11, "timestep": 20389, "ep_reward": 232.8391571044922, "reward": 0.025873184204101562, "action": -0.8003407716751099}
{"mode": "train", "epochs": 11, "timestep": 20390, "ep_reward": 232.93057250976562, "reward": 0.09142029285430908, "action": -0.9172936677932739}
{"mode": "train", "epochs": 11, "timestep": 20391, "ep_reward": 233.16107177734375, "reward": 0.23049676418304443, "action": -0.5400984883308411}
{"mode": "train", "epochs": 11, "timestep": 20392, "ep_reward": 233.53634643554688, "reward": 0.3752674460411072, "action": -0.421750545501709}
{"mode": "train", "epochs": 11, "timestep": 20393, "ep_reward": 234.04754638671875, "reward": 0.5111982822418213, "action": -2.0}
{"mode": "train", "epochs": 11, "timestep": 20394, "ep_reward": 234.65951538085938, "reward": 0.6119731664657593, "action": -1.8763819932937622}
{"mode": "train", "epochs": 11, "timestep": 20395, "ep_reward": 235.3550262451172, "reward": 0.6955040693283081, "action": -1.08000648021698}
{"mode": "train", "epochs": 11, "timestep": 20396, "ep_reward": 236.12071228027344, "reward": 0.7656797170639038, "action": -1.3638986349105835}
{"mode": "train", "epochs": 11, "timestep": 20397, "ep_reward": 236.93243408203125, "reward": 0.8117262721061707, "action": -1.1131082773208618}
{"mode": "train", "epochs": 11, "timestep": 20398, "ep_reward": 237.77293395996094, "reward": 0.8405065536499023, "action": -1.5972687005996704}
{"mode": "train", "epochs": 11, "timestep": 20399, "ep_reward": 238.61959838867188, "reward": 0.8466671705245972, "action": -1.0419106483459473}
{"mode": "train", "epochs": 11, "timestep": 20400, "ep_reward": 239.45835876464844, "reward": 0.838758647441864, "action": -1.6377742290496826}
{"mode": "train", "epochs": 11, "timestep": 20401, "ep_reward": 240.26199340820312, "reward": 0.8036325573921204, "action": -0.5290864706039429}
{"mode": "train", "epochs": 11, "timestep": 20402, "ep_reward": 241.01556396484375, "reward": 0.7535645961761475, "action": -0.9781204462051392}
{"mode": "train", "epochs": 11, "timestep": 20403, "ep_reward": 241.6824188232422, "reward": 0.6668577194213867, "action": -1.4526010751724243}
{"mode": "train", "epochs": 11, "timestep": 20404, "ep_reward": 242.21661376953125, "reward": 0.5341966152191162, "action": -0.13650602102279663}
{"mode": "train", "epochs": 11, "timestep": 20405, "ep_reward": 242.6071319580078, "reward": 0.390521764755249, "action": -0.43471503257751465}
{"mode": "train", "epochs": 11, "timestep": 20406, "ep_reward": 242.89608764648438, "reward": 0.2889556884765625, "action": -0.8241002559661865}
{"mode": "train", "epochs": 11, "timestep": 20407, "ep_reward": 243.0635223388672, "reward": 0.16743284463882446, "action": -0.6892719268798828}
{"mode": "train", "epochs": 11, "timestep": 20408, "ep_reward": 243.0894012451172, "reward": 0.02588355541229248, "action": -0.8319881558418274}
{"mode": "train", "epochs": 11, "timestep": 20409, "ep_reward": 243.1808319091797, "reward": 0.09142786264419556, "action": -0.7182638645172119}
{"mode": "train", "epochs": 11, "timestep": 20410, "ep_reward": 243.41378784179688, "reward": 0.23295408487319946, "action": -0.8188803791999817}
{"mode": "train", "epochs": 11, "timestep": 20411, "ep_reward": 243.78758239746094, "reward": 0.37379777431488037, "action": -0.7849199771881104}
{"mode": "train", "epochs": 11, "timestep": 20412, "ep_reward": 244.29364013671875, "reward": 0.5060502886772156, "action": -0.8236362934112549}
{"mode": "train", "epochs": 11, "timestep": 20413, "ep_reward": 244.91397094726562, "reward": 0.6203265190124512, "action": -1.460009217262268}
{"mode": "train", "epochs": 11, "timestep": 20414, "ep_reward": 245.62062072753906, "reward": 0.7066442966461182, "action": -1.387598991394043}
{"mode": "train", "epochs": 11, "timestep": 20415, "ep_reward": 246.39332580566406, "reward": 0.7727057337760925, "action": -0.9489648342132568}
{"mode": "train", "epochs": 11, "timestep": 20416, "ep_reward": 247.2158203125, "reward": 0.822501540184021, "action": -0.45103567838668823}
{"mode": "train", "epochs": 11, "timestep": 20417, "ep_reward": 248.07357788085938, "reward": 0.8577592372894287, "action": -0.5540093183517456}
{"mode": "train", "epochs": 11, "timestep": 20418, "ep_reward": 248.94874572753906, "reward": 0.8751740455627441, "action": -2.0}
{"mode": "train", "epochs": 11, "timestep": 20419, "ep_reward": 249.81407165527344, "reward": 0.8653296828269958, "action": -1.0381641387939453}
{"mode": "train", "epochs": 11, "timestep": 20420, "ep_reward": 250.6600799560547, "reward": 0.8460026979446411, "action": 0.1598529815673828}
{"mode": "train", "epochs": 11, "timestep": 20421, "ep_reward": 251.4778289794922, "reward": 0.8177531361579895, "action": -1.9221312999725342}
{"mode": "train", "epochs": 11, "timestep": 20422, "ep_reward": 252.22190856933594, "reward": 0.7440855503082275, "action": -1.4359986782073975}
{"mode": "train", "epochs": 11, "timestep": 20423, "ep_reward": 252.8627471923828, "reward": 0.6408424377441406, "action": -0.6960523128509521}
{"mode": "train", "epochs": 11, "timestep": 20424, "ep_reward": 253.36988830566406, "reward": 0.5071355700492859, "action": -1.216928482055664}
{"mode": "train", "epochs": 11, "timestep": 20425, "ep_reward": 253.7277069091797, "reward": 0.3578197956085205, "action": -1.3172144889831543}
{"mode": "train", "epochs": 11, "timestep": 20426, "ep_reward": 253.9771270751953, "reward": 0.24941593408584595, "action": -1.3278484344482422}
{"mode": "train", "epochs": 11, "timestep": 20427, "ep_reward": 254.09823608398438, "reward": 0.1211158037185669, "action": -0.3633471131324768}
{"mode": "train", "epochs": 11, "timestep": 20428, "ep_reward": 254.0916748046875, "reward": -0.006556987762451172, "action": -0.8700162768363953}
{"mode": "train", "epochs": 11, "timestep": 20429, "ep_reward": 254.23086547851562, "reward": 0.1391923427581787, "action": -0.9458785057067871}
{"mode": "train", "epochs": 11, "timestep": 20430, "ep_reward": 254.50990295410156, "reward": 0.2790437936782837, "action": -1.6988836526870728}
{"mode": "train", "epochs": 11, "timestep": 20431, "ep_reward": 254.917724609375, "reward": 0.4078226089477539, "action": -1.3058406114578247}
{"mode": "train", "epochs": 11, "timestep": 20432, "ep_reward": 255.44918823242188, "reward": 0.5314704775810242, "action": -0.9207517504692078}
{"mode": "train", "epochs": 11, "timestep": 20433, "ep_reward": 256.08953857421875, "reward": 0.6403356790542603, "action": -2.0}
{"mode": "train", "epochs": 11, "timestep": 20434, "ep_reward": 256.8046875, "reward": 0.7151342630386353, "action": -0.8691178560256958}
{"mode": "train", "epochs": 11, "timestep": 20435, "ep_reward": 257.5839538574219, "reward": 0.7792563438415527, "action": -0.167932391166687}
{"mode": "train", "epochs": 11, "timestep": 20436, "ep_reward": 258.41143798828125, "reward": 0.8274813294410706, "action": -0.31914830207824707}
{"mode": "train", "epochs": 11, "timestep": 20437, "ep_reward": 259.2653503417969, "reward": 0.8539270162582397, "action": -1.5499553680419922}
{"mode": "train", "epochs": 11, "timestep": 20438, "ep_reward": 260.1170349121094, "reward": 0.8516891002655029, "action": -1.048890233039856}
{"mode": "train", "epochs": 11, "timestep": 20439, "ep_reward": 260.9519348144531, "reward": 0.8349094390869141, "action": -0.9636058211326599}
{"mode": "train", "epochs": 11, "timestep": 20440, "ep_reward": 261.748779296875, "reward": 0.7968488335609436, "action": -1.2182989120483398}
{"mode": "train", "epochs": 11, "timestep": 20441, "ep_reward": 262.4773864746094, "reward": 0.7286040782928467, "action": -1.0336695909500122}
{"mode": "train", "epochs": 11, "timestep": 20442, "ep_reward": 263.1051330566406, "reward": 0.6277505159378052, "action": -0.5702375173568726}
{"mode": "train", "epochs": 11, "timestep": 20443, "ep_reward": 263.5981140136719, "reward": 0.4929945468902588, "action": -0.3148532509803772}
{"mode": "train", "epochs": 11, "timestep": 20444, "ep_reward": 263.95452880859375, "reward": 0.35640978813171387, "action": -1.2448128461837769}
{"mode": "train", "epochs": 11, "timestep": 20445, "ep_reward": 264.2022705078125, "reward": 0.24773484468460083, "action": -1.1399946212768555}
{"mode": "train", "epochs": 11, "timestep": 20446, "ep_reward": 264.3213195800781, "reward": 0.11904948949813843, "action": -1.101870059967041}
{"mode": "train", "epochs": 11, "timestep": 20447, "ep_reward": 264.31689453125, "reward": -0.004435062408447266, "action": -1.650385856628418}
{"mode": "train", "epochs": 11, "timestep": 20448, "ep_reward": 264.4580078125, "reward": 0.1411139965057373, "action": -1.2039203643798828}
{"mode": "train", "epochs": 11, "timestep": 20449, "ep_reward": 264.73590087890625, "reward": 0.2778785824775696, "action": -1.323757529258728}
{"mode": "train", "epochs": 11, "timestep": 20450, "ep_reward": 265.147705078125, "reward": 0.41181671619415283, "action": -0.4047664403915405}
{"mode": "train", "epochs": 11, "timestep": 20451, "ep_reward": 265.6929626464844, "reward": 0.5452526807785034, "action": -0.02662181854248047}
{"mode": "train", "epochs": 11, "timestep": 20452, "ep_reward": 266.35400390625, "reward": 0.6610300540924072, "action": -1.4488438367843628}
{"mode": "train", "epochs": 11, "timestep": 20453, "ep_reward": 267.092529296875, "reward": 0.7385349273681641, "action": -0.6472017765045166}
{"mode": "train", "epochs": 11, "timestep": 20454, "ep_reward": 267.89501953125, "reward": 0.8024896383285522, "action": -1.322991967201233}
{"mode": "train", "epochs": 11, "timestep": 20455, "ep_reward": 268.7359313964844, "reward": 0.8409112691879272, "action": -0.9917815327644348}
{"mode": "train", "epochs": 11, "timestep": 20456, "ep_reward": 269.6011962890625, "reward": 0.8652796745300293, "action": -0.5169156193733215}
{"mode": "train", "epochs": 11, "timestep": 20457, "ep_reward": 270.4788513183594, "reward": 0.8776533603668213, "action": -1.5464205741882324}
{"mode": "train", "epochs": 11, "timestep": 20458, "ep_reward": 271.3450012207031, "reward": 0.8661459684371948, "action": -0.9840075969696045}
{"mode": "train", "epochs": 11, "timestep": 20459, "ep_reward": 272.1865234375, "reward": 0.8415316343307495, "action": -1.346387267112732}
{"mode": "train", "epochs": 11, "timestep": 20460, "ep_reward": 272.9780578613281, "reward": 0.7915468215942383, "action": -1.4480876922607422}
{"mode": "train", "epochs": 11, "timestep": 20461, "ep_reward": 273.689453125, "reward": 0.7113989591598511, "action": -1.5835292339324951}
{"mode": "train", "epochs": 11, "timestep": 20462, "ep_reward": 274.28173828125, "reward": 0.5922987461090088, "action": -0.6942394971847534}
{"mode": "train", "epochs": 11, "timestep": 20463, "ep_reward": 274.72454833984375, "reward": 0.44280946254730225, "action": -1.18577241897583}
{"mode": "train", "epochs": 11, "timestep": 20464, "ep_reward": 275.0464782714844, "reward": 0.321926474571228, "action": -0.34178656339645386}
{"mode": "train", "epochs": 11, "timestep": 20465, "ep_reward": 275.2527770996094, "reward": 0.20628464221954346, "action": -1.7188305854797363}
{"mode": "train", "epochs": 11, "timestep": 20466, "ep_reward": 275.3235778808594, "reward": 0.0708124041557312, "action": -1.754232406616211}
{"mode": "train", "epochs": 11, "timestep": 20467, "ep_reward": 275.3708190917969, "reward": 0.04723155498504639, "action": -0.4515542984008789}
{"mode": "train", "epochs": 11, "timestep": 20468, "ep_reward": 275.5615539550781, "reward": 0.1907367706298828, "action": 0.15960729122161865}
{"mode": "train", "epochs": 11, "timestep": 20469, "ep_reward": 275.9053649902344, "reward": 0.34382331371307373, "action": -2.0}
{"mode": "train", "epochs": 11, "timestep": 20470, "ep_reward": 276.3684387207031, "reward": 0.4630882740020752, "action": -1.8747773170471191}
{"mode": "train", "epochs": 11, "timestep": 20471, "ep_reward": 276.94085693359375, "reward": 0.5724160671234131, "action": -1.753572940826416}
{"mode": "train", "epochs": 11, "timestep": 20472, "ep_reward": 277.6058044433594, "reward": 0.6649410724639893, "action": -1.0621228218078613}
{"mode": "train", "epochs": 11, "timestep": 20473, "ep_reward": 278.3486022949219, "reward": 0.7427868843078613, "action": -0.9828553795814514}
{"mode": "train", "epochs": 11, "timestep": 20474, "ep_reward": 279.1473083496094, "reward": 0.7986913919448853, "action": -0.7569206357002258}
{"mode": "train", "epochs": 11, "timestep": 20475, "ep_reward": 279.9831237792969, "reward": 0.8358193635940552, "action": -1.118796944618225}
{"mode": "train", "epochs": 11, "timestep": 20476, "ep_reward": 280.8340148925781, "reward": 0.8509038090705872, "action": -1.110216736793518}
{"mode": "train", "epochs": 11, "timestep": 20477, "ep_reward": 281.6819152832031, "reward": 0.847900927066803, "action": -0.8334967494010925}
{"mode": "train", "epochs": 11, "timestep": 20478, "ep_reward": 282.5096740722656, "reward": 0.8277682065963745, "action": -1.0942176580429077}
{"mode": "train", "epochs": 11, "timestep": 20479, "ep_reward": 283.2916564941406, "reward": 0.7819936275482178, "action": -0.5370521545410156}
{"mode": "train", "epochs": 11, "timestep": 20480, "ep_reward": 284.0053405761719, "reward": 0.7136809825897217, "action": -1.170044183731079}
{"mode": "train", "epochs": 11, "timestep": 20481, "ep_reward": 284.6080322265625, "reward": 0.6026843786239624, "action": -1.763370394706726}
{"mode": "train", "epochs": 11, "timestep": 20482, "ep_reward": 285.0479431152344, "reward": 0.4399137496948242, "action": -0.27683329582214355}
{"mode": "train", "epochs": 11, "timestep": 20483, "ep_reward": 285.3785400390625, "reward": 0.3306000828742981, "action": -0.802906334400177}
{"mode": "train", "epochs": 11, "timestep": 20484, "ep_reward": 285.5951843261719, "reward": 0.21665459871292114, "action": -1.7230644226074219}
{"mode": "train", "epochs": 11, "timestep": 20485, "ep_reward": 285.67816162109375, "reward": 0.08297044038772583, "action": -1.0530424118041992}
{"mode": "train", "epochs": 11, "timestep": 20486, "ep_reward": 285.712890625, "reward": 0.03471881151199341, "action": -1.1532517671585083}
{"mode": "train", "epochs": 11, "timestep": 20487, "ep_reward": 285.8879699707031, "reward": 0.17509299516677856, "action": -1.0485650300979614}
{"mode": "train", "epochs": 11, "timestep": 20488, "ep_reward": 286.2025451660156, "reward": 0.3145650625228882, "action": -0.25142067670822144}
{"mode": "train", "epochs": 11, "timestep": 20489, "ep_reward": 286.661376953125, "reward": 0.45882952213287354, "action": -1.5287787914276123}
{"mode": "train", "epochs": 11, "timestep": 20490, "ep_reward": 287.2340087890625, "reward": 0.5726180076599121, "action": -1.0067546367645264}
{"mode": "train", "epochs": 11, "timestep": 20491, "ep_reward": 287.9071044921875, "reward": 0.6731100082397461, "action": -0.24287772178649902}
{"mode": "train", "epochs": 11, "timestep": 20492, "ep_reward": 288.6651611328125, "reward": 0.7580516934394836, "action": -1.5278676748275757}
{"mode": "train", "epochs": 11, "timestep": 20493, "ep_reward": 289.4739685058594, "reward": 0.8088201284408569, "action": -1.4799330234527588}
{"mode": "train", "epochs": 11, "timestep": 20494, "ep_reward": 290.3157653808594, "reward": 0.8417997360229492, "action": -0.6164990663528442}
{"mode": "train", "epochs": 11, "timestep": 20495, "ep_reward": 291.1805725097656, "reward": 0.8648086786270142, "action": -1.6694200038909912}
{"mode": "train", "epochs": 11, "timestep": 20496, "ep_reward": 292.0433044433594, "reward": 0.8627222180366516, "action": -0.1660967469215393}
{"mode": "train", "epochs": 11, "timestep": 20497, "ep_reward": 292.8997497558594, "reward": 0.8564512729644775, "action": -0.5815788507461548}
{"mode": "train", "epochs": 11, "timestep": 20498, "ep_reward": 293.7275695800781, "reward": 0.8278292417526245, "action": -0.9309075474739075}
{"mode": "train", "epochs": 11, "timestep": 20499, "ep_reward": 294.5003662109375, "reward": 0.7727935314178467, "action": -1.2823400497436523}
{"mode": "train", "epochs": 11, "timestep": 20500, "ep_reward": 295.1841735839844, "reward": 0.6838066577911377, "action": -0.974822461605072}
{"mode": "train", "epochs": 11, "timestep": 20501, "ep_reward": 295.7452087402344, "reward": 0.5610387325286865, "action": -0.1563934087753296}
{"mode": "train", "epochs": 11, "timestep": 20502, "ep_reward": 296.1553649902344, "reward": 0.4101411700248718, "action": -0.25245392322540283}
{"mode": "train", "epochs": 11, "timestep": 20503, "ep_reward": 296.4441223144531, "reward": 0.28874820470809937, "action": -0.36363333463668823}
{"mode": "train", "epochs": 11, "timestep": 20504, "ep_reward": 296.6112976074219, "reward": 0.1671798825263977, "action": -0.04960399866104126}
{"mode": "train", "epochs": 11, "timestep": 20505, "ep_reward": 296.6368408203125, "reward": 0.025533676147460938, "action": -1.0625439882278442}
{"mode": "train", "epochs": 11, "timestep": 20506, "ep_reward": 296.7284240722656, "reward": 0.09159314632415771, "action": -1.638266921043396}
{"mode": "train", "epochs": 11, "timestep": 20507, "ep_reward": 296.95263671875, "reward": 0.22421163320541382, "action": -1.4374232292175293}
{"mode": "train", "epochs": 11, "timestep": 20508, "ep_reward": 297.31195068359375, "reward": 0.3593045473098755, "action": -0.09282797574996948}
{"mode": "train", "epochs": 11, "timestep": 20509, "ep_reward": 297.814697265625, "reward": 0.5027607679367065, "action": -1.3716703653335571}
{"mode": "train", "epochs": 11, "timestep": 20510, "ep_reward": 298.42657470703125, "reward": 0.6118780374526978, "action": -1.5366597175598145}
{"mode": "train", "epochs": 11, "timestep": 20511, "ep_reward": 299.1249694824219, "reward": 0.6983895897865295, "action": -0.942716658115387}
{"mode": "train", "epochs": 11, "timestep": 20512, "ep_reward": 299.8935852050781, "reward": 0.7686159610748291, "action": 0.030780494213104248}
{"mode": "train", "epochs": 11, "timestep": 20513, "ep_reward": 300.7189636230469, "reward": 0.8253704905509949, "action": -1.6444377899169922}
{"mode": "train", "epochs": 11, "timestep": 20514, "ep_reward": 301.566650390625, "reward": 0.8477017879486084, "action": -0.6705182790756226}
{"mode": "train", "epochs": 11, "timestep": 20515, "ep_reward": 302.4278259277344, "reward": 0.8611679077148438, "action": -0.880511999130249}
{"mode": "train", "epochs": 11, "timestep": 20516, "ep_reward": 303.2832946777344, "reward": 0.8554830551147461, "action": -1.0700241327285767}
{"mode": "train", "epochs": 11, "timestep": 20517, "ep_reward": 304.11236572265625, "reward": 0.8290724754333496, "action": -0.9755944609642029}
{"mode": "train", "epochs": 11, "timestep": 20518, "ep_reward": 304.892822265625, "reward": 0.7804480791091919, "action": -0.4658586382865906}
{"mode": "train", "epochs": 11, "timestep": 20519, "ep_reward": 305.60174560546875, "reward": 0.7089164853096008, "action": 1.2380876541137695}
{"mode": "train", "epochs": 11, "timestep": 20520, "ep_reward": 306.2290344238281, "reward": 0.6272802352905273, "action": 0.8032013177871704}
{"mode": "train", "epochs": 11, "timestep": 20521, "ep_reward": 306.73834228515625, "reward": 0.5093156099319458, "action": 1.0093215703964233}
{"mode": "train", "epochs": 11, "timestep": 20522, "ep_reward": 307.10284423828125, "reward": 0.3645097613334656, "action": -0.7261446118354797}
{"mode": "train", "epochs": 11, "timestep": 20523, "ep_reward": 307.32489013671875, "reward": 0.22203433513641357, "action": -1.766456961631775}
{"mode": "train", "epochs": 11, "timestep": 20524, "ep_reward": 307.41412353515625, "reward": 0.08923995494842529, "action": -1.0233087539672852}
{"mode": "train", "epochs": 11, "timestep": 20525, "ep_reward": 307.44232177734375, "reward": 0.02818828821182251, "action": -0.5706496238708496}
{"mode": "train", "epochs": 11, "timestep": 20526, "ep_reward": 307.6119079589844, "reward": 0.1695880889892578, "action": -0.4209582209587097}
{"mode": "train", "epochs": 11, "timestep": 20527, "ep_reward": 307.9285583496094, "reward": 0.3166389465332031, "action": -0.6921546459197998}
{"mode": "train", "epochs": 11, "timestep": 20528, "ep_reward": 308.38299560546875, "reward": 0.45443660020828247, "action": -1.3268766403198242}
{"mode": "train", "epochs": 11, "timestep": 20529, "ep_reward": 308.9538879394531, "reward": 0.5708892345428467, "action": -0.8588933944702148}
{"mode": "train", "epochs": 11, "timestep": 20530, "ep_reward": 309.6271667480469, "reward": 0.6732820272445679, "action": -0.8545541167259216}
{"mode": "train", "epochs": 11, "timestep": 20531, "ep_reward": 310.3804016113281, "reward": 0.753234326839447, "action": 0.11414659023284912}
{"mode": "train", "epochs": 11, "timestep": 20532, "ep_reward": 311.2002258300781, "reward": 0.8198119401931763, "action": 1.3704938888549805}
{"mode": "train", "epochs": 11, "timestep": 20533, "ep_reward": 312.0755615234375, "reward": 0.8753426671028137, "action": 2.0}
{"mode": "train", "epochs": 11, "timestep": 20534, "ep_reward": 312.99237060546875, "reward": 0.9167962670326233, "action": 1.5412886142730713}
{"mode": "train", "epochs": 11, "timestep": 20535, "ep_reward": 313.933837890625, "reward": 0.9414765238761902, "action": 1.0420323610305786}
{"mode": "train", "epochs": 11, "timestep": 20536, "ep_reward": 314.88818359375, "reward": 0.9543426036834717, "action": 0.47506463527679443}
{"mode": "train", "epochs": 11, "timestep": 20537, "ep_reward": 315.84619140625, "reward": 0.9580188393592834, "action": 0.8110466003417969}
{"mode": "train", "epochs": 11, "timestep": 20538, "ep_reward": 316.8042297363281, "reward": 0.9580381512641907, "action": 1.3969331979751587}
{"mode": "train", "epochs": 11, "timestep": 20539, "ep_reward": 317.7604064941406, "reward": 0.956183135509491, "action": 0.34583914279937744}
{"mode": "train", "epochs": 11, "timestep": 20540, "ep_reward": 318.7043762207031, "reward": 0.9439656138420105, "action": 1.2418570518493652}
{"mode": "train", "epochs": 11, "timestep": 20541, "ep_reward": 319.63470458984375, "reward": 0.9303256869316101, "action": 0.4664313793182373}
{"mode": "train", "epochs": 11, "timestep": 20542, "ep_reward": 320.5392150878906, "reward": 0.9045041799545288, "action": 1.2213850021362305}
{"mode": "train", "epochs": 11, "timestep": 20543, "ep_reward": 321.4124755859375, "reward": 0.8732641339302063, "action": 1.459637999534607}
{"mode": "train", "epochs": 11, "timestep": 20544, "ep_reward": 322.2444763183594, "reward": 0.8320004343986511, "action": 1.5984231233596802}
{"mode": "train", "epochs": 11, "timestep": 20545, "ep_reward": 323.0226135253906, "reward": 0.7781491875648499, "action": 0.4880985617637634}
{"mode": "train", "epochs": 11, "timestep": 20546, "ep_reward": 323.7191162109375, "reward": 0.6965138912200928, "action": 0.9275760650634766}
{"mode": "train", "epochs": 11, "timestep": 20547, "ep_reward": 324.31707763671875, "reward": 0.5979674458503723, "action": 1.4027175903320312}
{"mode": "train", "epochs": 11, "timestep": 20548, "ep_reward": 324.8030700683594, "reward": 0.48598712682724, "action": 1.378556251525879}
{"mode": "train", "epochs": 11, "timestep": 20549, "ep_reward": 325.1631774902344, "reward": 0.3601110577583313, "action": 0.9011041522026062}
{"mode": "train", "epochs": 11, "timestep": 20550, "ep_reward": 325.3838806152344, "reward": 0.22070199251174927, "action": 1.0023093223571777}
{"mode": "train", "epochs": 11, "timestep": 20551, "ep_reward": 325.47357177734375, "reward": 0.0896841287612915, "action": -0.12219655513763428}
{"mode": "train", "epochs": 11, "timestep": 20552, "ep_reward": 325.6896667480469, "reward": 0.2161027193069458, "action": 1.4594768285751343}
{"mode": "train", "epochs": 11, "timestep": 20553, "ep_reward": 326.0508728027344, "reward": 0.3612011671066284, "action": 2.0}
{"mode": "train", "epochs": 11, "timestep": 20554, "ep_reward": 326.5523986816406, "reward": 0.5015318393707275, "action": 0.7416136264801025}
{"mode": "train", "epochs": 11, "timestep": 20555, "ep_reward": 327.1653137207031, "reward": 0.6129282712936401, "action": 0.7970219850540161}
{"mode": "train", "epochs": 11, "timestep": 20556, "ep_reward": 327.8717041015625, "reward": 0.7063870429992676, "action": 0.7327132225036621}
{"mode": "train", "epochs": 11, "timestep": 20557, "ep_reward": 328.6508483886719, "reward": 0.7791471481323242, "action": 1.2133281230926514}
{"mode": "train", "epochs": 11, "timestep": 20558, "ep_reward": 329.48455810546875, "reward": 0.8337098956108093, "action": 1.1979008913040161}
{"mode": "train", "epochs": 11, "timestep": 20559, "ep_reward": 330.3522644042969, "reward": 0.8677120804786682, "action": 1.2547659873962402}
{"mode": "train", "epochs": 11, "timestep": 20560, "ep_reward": 331.23504638671875, "reward": 0.8827846646308899, "action": 0.0026526451110839844}
{"mode": "train", "epochs": 11, "timestep": 20561, "ep_reward": 332.1166687011719, "reward": 0.8816084861755371, "action": -0.06743818521499634}
{"mode": "train", "epochs": 11, "timestep": 20562, "ep_reward": 332.9840393066406, "reward": 0.8673567175865173, "action": 0.9630056619644165}
{"mode": "train", "epochs": 11, "timestep": 20563, "ep_reward": 333.8184814453125, "reward": 0.8344386219978333, "action": -0.7137398719787598}
{"mode": "train", "epochs": 11, "timestep": 20564, "ep_reward": 334.6106262207031, "reward": 0.7921375036239624, "action": -0.09644977748394012}
{"mode": "train", "epochs": 11, "timestep": 20565, "ep_reward": 335.3414611816406, "reward": 0.730827808380127, "action": 0.2065032422542572}
{"mode": "train", "epochs": 11, "timestep": 20566, "ep_reward": 335.99017333984375, "reward": 0.6487138867378235, "action": -0.30386728048324585}
{"mode": "train", "epochs": 11, "timestep": 20567, "ep_reward": 336.54302978515625, "reward": 0.5528438091278076, "action": -1.2114207744598389}
{"mode": "train", "epochs": 11, "timestep": 20568, "ep_reward": 336.9967041015625, "reward": 0.4536781311035156, "action": -0.5073528289794922}
{"mode": "train", "epochs": 11, "timestep": 20569, "ep_reward": 337.3365478515625, "reward": 0.3398336172103882, "action": -0.11435231566429138}
{"mode": "train", "epochs": 11, "timestep": 20570, "ep_reward": 337.5549011230469, "reward": 0.2183469533920288, "action": -1.1336122751235962}
{"mode": "train", "epochs": 11, "timestep": 20571, "ep_reward": 337.8121337890625, "reward": 0.25723105669021606, "action": -0.837199866771698}
{"mode": "train", "epochs": 11, "timestep": 20572, "ep_reward": 338.1813659667969, "reward": 0.36922508478164673, "action": -0.9141910672187805}
{"mode": "train", "epochs": 11, "timestep": 20573, "ep_reward": 338.6583251953125, "reward": 0.47696685791015625, "action": 0.4370790123939514}
{"mode": "train", "epochs": 11, "timestep": 20574, "ep_reward": 339.2243957519531, "reward": 0.5660788416862488, "action": 0.9794373512268066}
{"mode": "train", "epochs": 11, "timestep": 20575, "ep_reward": 339.8673095703125, "reward": 0.6429238319396973, "action": 1.462430715560913}
{"mode": "train", "epochs": 11, "timestep": 20576, "ep_reward": 340.5747985839844, "reward": 0.707480788230896, "action": 0.9541183114051819}
{"mode": "train", "epochs": 11, "timestep": 20577, "ep_reward": 341.3387756347656, "reward": 0.763982355594635, "action": 1.4132895469665527}
{"mode": "train", "epochs": 11, "timestep": 20578, "ep_reward": 342.1458435058594, "reward": 0.8070709109306335, "action": 1.0016708374023438}
{"mode": "train", "epochs": 11, "timestep": 20579, "ep_reward": 342.9865417480469, "reward": 0.8407009243965149, "action": 1.494758129119873}
{"mode": "train", "epochs": 11, "timestep": 20580, "ep_reward": 343.8497009277344, "reward": 0.8631526827812195, "action": 0.42108750343322754}
{"mode": "train", "epochs": 11, "timestep": 20581, "ep_reward": 344.7266845703125, "reward": 0.8769924640655518, "action": 1.3705488443374634}
{"mode": "train", "epochs": 11, "timestep": 20582, "ep_reward": 345.6072082519531, "reward": 0.8805323839187622, "action": 0.6559256911277771}
{"mode": "train", "epochs": 11, "timestep": 20583, "ep_reward": 346.4814147949219, "reward": 0.874209463596344, "action": 1.0886855125427246}
{"mode": "train", "epochs": 11, "timestep": 20584, "ep_reward": 347.33984375, "reward": 0.8584140539169312, "action": 0.9763621091842651}
{"mode": "train", "epochs": 11, "timestep": 20585, "ep_reward": 348.17169189453125, "reward": 0.8318630456924438, "action": 0.8210467100143433}
{"mode": "train", "epochs": 11, "timestep": 20586, "ep_reward": 348.9642333984375, "reward": 0.7925432920455933, "action": 1.4938430786132812}
{"mode": "train", "epochs": 11, "timestep": 20587, "ep_reward": 349.7090148925781, "reward": 0.7447724342346191, "action": -0.034967780113220215}
{"mode": "train", "epochs": 11, "timestep": 20588, "ep_reward": 350.3816223144531, "reward": 0.6726123094558716, "action": 0.8248735666275024}
{"mode": "train", "epochs": 11, "timestep": 20589, "ep_reward": 350.9727783203125, "reward": 0.5911651849746704, "action": 1.0019844770431519}
{"mode": "train", "epochs": 11, "timestep": 20590, "ep_reward": 351.4723205566406, "reward": 0.499553918838501, "action": 0.914374828338623}
{"mode": "train", "epochs": 11, "timestep": 20591, "ep_reward": 351.87158203125, "reward": 0.3992513418197632, "action": 0.5040397644042969}
{"mode": "train", "epochs": 11, "timestep": 20592, "ep_reward": 352.1625061035156, "reward": 0.29093432426452637, "action": 0.29160863161087036}
{"mode": "train", "epochs": 11, "timestep": 20593, "ep_reward": 352.39105224609375, "reward": 0.22855275869369507, "action": 0.20187675952911377}
{"mode": "train", "epochs": 11, "timestep": 20594, "ep_reward": 352.7215881347656, "reward": 0.3305218815803528, "action": 0.5717145204544067}
{"mode": "train", "epochs": 11, "timestep": 20595, "ep_reward": 353.1558532714844, "reward": 0.4342610239982605, "action": 1.1871037483215332}
{"mode": "train", "epochs": 11, "timestep": 20596, "ep_reward": 353.6910095214844, "reward": 0.5351428985595703, "action": 1.0628987550735474}
{"mode": "train", "epochs": 11, "timestep": 20597, "ep_reward": 354.3126220703125, "reward": 0.6216181516647339, "action": 0.5332052111625671}
{"mode": "train", "epochs": 11, "timestep": 20598, "ep_reward": 355.00201416015625, "reward": 0.6894052028656006, "action": 0.6605170965194702}
{"mode": "train", "epochs": 11, "timestep": 20599, "ep_reward": 355.7432556152344, "reward": 0.7412443161010742, "action": 0.9417766332626343}
{"mode": "train", "epochs": 11, "timestep": 20600, "ep_reward": 356.51898193359375, "reward": 0.7757266759872437, "action": 0.9964545369148254}
{"mode": "train", "epochs": 11, "timestep": 20601, "ep_reward": 357.30999755859375, "reward": 0.791001558303833, "action": 1.0274027585983276}
{"mode": "train", "epochs": 11, "timestep": 20602, "ep_reward": 358.0966796875, "reward": 0.7866832613945007, "action": 0.7885069847106934}
{"mode": "train", "epochs": 11, "timestep": 20603, "ep_reward": 358.86004638671875, "reward": 0.7633528113365173, "action": 0.4184001684188843}
{"mode": "train", "epochs": 11, "timestep": 20604, "ep_reward": 359.5829162597656, "reward": 0.7228666543960571, "action": 0.6263881921768188}
{"mode": "train", "epochs": 11, "timestep": 20605, "ep_reward": 360.2462463378906, "reward": 0.6633217334747314, "action": 0.21838609874248505}
{"mode": "train", "epochs": 11, "timestep": 20606, "ep_reward": 360.8352966308594, "reward": 0.589065432548523, "action": 1.564910650253296}
{"mode": "train", "epochs": 11, "timestep": 20607, "ep_reward": 361.3224792480469, "reward": 0.4871861934661865, "action": -0.056290075182914734}
{"mode": "train", "epochs": 11, "timestep": 20608, "ep_reward": 361.70904541015625, "reward": 0.3865622282028198, "action": -0.008642368018627167}
{"mode": "train", "epochs": 11, "timestep": 20609, "ep_reward": 361.9899597167969, "reward": 0.2809191942214966, "action": 0.3732181489467621}
{"mode": "train", "epochs": 11, "timestep": 20610, "ep_reward": 362.2587890625, "reward": 0.2688300609588623, "action": -0.7135869860649109}
{"mode": "train", "epochs": 11, "timestep": 20611, "ep_reward": 362.6285705566406, "reward": 0.36978715658187866, "action": -1.0293059349060059}
{"mode": "train", "epochs": 11, "timestep": 20612, "ep_reward": 363.0975646972656, "reward": 0.4689944386482239, "action": -0.33622390031814575}
{"mode": "train", "epochs": 11, "timestep": 20613, "ep_reward": 363.6524658203125, "reward": 0.5549036264419556, "action": 1.427384853363037}
{"mode": "train", "epochs": 11, "timestep": 20614, "ep_reward": 364.2746276855469, "reward": 0.6221542358398438, "action": 1.4000800848007202}
{"mode": "train", "epochs": 11, "timestep": 20615, "ep_reward": 364.9572448730469, "reward": 0.6826026439666748, "action": 1.1535285711288452}
{"mode": "train", "epochs": 11, "timestep": 20616, "ep_reward": 365.6922302246094, "reward": 0.7349778413772583, "action": 1.7637379169464111}
{"mode": "train", "epochs": 11, "timestep": 20617, "ep_reward": 366.46771240234375, "reward": 0.7754836678504944, "action": 1.1257755756378174}
{"mode": "train", "epochs": 11, "timestep": 20618, "ep_reward": 367.2761535644531, "reward": 0.8084458708763123, "action": 0.48314929008483887}
{"mode": "train", "epochs": 11, "timestep": 20619, "ep_reward": 368.10723876953125, "reward": 0.8310879468917847, "action": 0.6994431018829346}
{"mode": "train", "epochs": 11, "timestep": 20620, "ep_reward": 368.9483947753906, "reward": 0.8411580324172974, "action": 1.2483142614364624}
{"mode": "train", "epochs": 11, "timestep": 20621, "ep_reward": 369.7890930175781, "reward": 0.8407074213027954, "action": 1.0259729623794556}
{"mode": "train", "epochs": 11, "timestep": 20622, "ep_reward": 370.6190490722656, "reward": 0.8299419283866882, "action": 0.9959586262702942}
{"mode": "train", "epochs": 11, "timestep": 20623, "ep_reward": 371.42718505859375, "reward": 0.8081234693527222, "action": 1.4743632078170776}
{"mode": "train", "epochs": 11, "timestep": 20624, "ep_reward": 372.20465087890625, "reward": 0.7774724364280701, "action": -0.12671661376953125}
{"mode": "train", "epochs": 11, "timestep": 20625, "ep_reward": 372.93072509765625, "reward": 0.7260754108428955, "action": 0.940590500831604}
{"mode": "train", "epochs": 11, "timestep": 20626, "ep_reward": 373.5967102050781, "reward": 0.6659794449806213, "action": 0.7507604360580444}
{"mode": "train", "epochs": 11, "timestep": 20627, "ep_reward": 374.1888732910156, "reward": 0.5921506881713867, "action": 0.1901140809059143}
{"mode": "train", "epochs": 11, "timestep": 20628, "ep_reward": 374.6903991699219, "reward": 0.5015183091163635, "action": 1.2230360507965088}
{"mode": "train", "epochs": 11, "timestep": 20629, "ep_reward": 375.1031494140625, "reward": 0.41274815797805786, "action": 0.4072480797767639}
{"mode": "train", "epochs": 11, "timestep": 20630, "ep_reward": 375.4161682128906, "reward": 0.3130149245262146, "action": 1.743220567703247}
{"mode": "train", "epochs": 11, "timestep": 20631, "ep_reward": 375.6782531738281, "reward": 0.26208823919296265, "action": -0.05575072765350342}
{"mode": "train", "epochs": 11, "timestep": 20632, "ep_reward": 376.0284423828125, "reward": 0.35017919540405273, "action": 0.7221811413764954}
{"mode": "train", "epochs": 11, "timestep": 20633, "ep_reward": 376.47100830078125, "reward": 0.44256335496902466, "action": 1.0496679544448853}
{"mode": "train", "epochs": 11, "timestep": 20634, "ep_reward": 377.0009460449219, "reward": 0.5299419164657593, "action": 0.7616671323776245}
{"mode": "train", "epochs": 11, "timestep": 20635, "ep_reward": 377.60516357421875, "reward": 0.6042221188545227, "action": 0.4957047700881958}
{"mode": "train", "epochs": 11, "timestep": 20636, "ep_reward": 378.26898193359375, "reward": 0.6638181209564209, "action": 1.395948052406311}
{"mode": "train", "epochs": 11, "timestep": 20637, "ep_reward": 378.9793395996094, "reward": 0.7103580236434937, "action": 0.6560612916946411}
{"mode": "train", "epochs": 11, "timestep": 20638, "ep_reward": 379.71612548828125, "reward": 0.736796498298645, "action": 0.5871795415878296}
{"mode": "train", "epochs": 11, "timestep": 20639, "ep_reward": 380.4623107910156, "reward": 0.7461918592453003, "action": 1.5845885276794434}
{"mode": "train", "epochs": 11, "timestep": 20640, "ep_reward": 381.19818115234375, "reward": 0.735866367816925, "action": 1.0018768310546875}
{"mode": "train", "epochs": 11, "timestep": 20641, "ep_reward": 381.9042053222656, "reward": 0.7060378789901733, "action": 0.22898828983306885}
{"mode": "train", "epochs": 11, "timestep": 20642, "ep_reward": 382.5657958984375, "reward": 0.6615966558456421, "action": 1.636540174484253}
{"mode": "train", "epochs": 11, "timestep": 20643, "ep_reward": 383.15777587890625, "reward": 0.5919879674911499, "action": 0.46832647919654846}
{"mode": "train", "epochs": 11, "timestep": 20644, "ep_reward": 383.6705322265625, "reward": 0.5127663612365723, "action": 0.7111659049987793}
{"mode": "train", "epochs": 11, "timestep": 20645, "ep_reward": 384.09027099609375, "reward": 0.4197530150413513, "action": 0.606715202331543}
{"mode": "train", "epochs": 11, "timestep": 20646, "ep_reward": 384.4100341796875, "reward": 0.3197762966156006, "action": -0.1285550594329834}
{"mode": "train", "epochs": 11, "timestep": 20647, "ep_reward": 384.68927001953125, "reward": 0.2792316675186157, "action": 0.4620928168296814}
{"mode": "train", "epochs": 11, "timestep": 20648, "ep_reward": 385.0522155761719, "reward": 0.36294180154800415, "action": 0.9181556105613708}
{"mode": "train", "epochs": 11, "timestep": 20649, "ep_reward": 385.4967346191406, "reward": 0.4445042610168457, "action": 0.7120524644851685}
{"mode": "train", "epochs": 11, "timestep": 20650, "ep_reward": 386.02227783203125, "reward": 0.525530219078064, "action": 1.5481607913970947}
{"mode": "train", "epochs": 11, "timestep": 20651, "ep_reward": 386.61895751953125, "reward": 0.5966660976409912, "action": 1.1025564670562744}
{"mode": "train", "epochs": 11, "timestep": 20652, "ep_reward": 387.28289794921875, "reward": 0.6639479398727417, "action": 0.7000830173492432}
{"mode": "train", "epochs": 11, "timestep": 20653, "ep_reward": 388.00604248046875, "reward": 0.7231392860412598, "action": 1.0908138751983643}
{"mode": "train", "epochs": 11, "timestep": 20654, "ep_reward": 388.7751770019531, "reward": 0.7691253423690796, "action": 0.942236065864563}
{"mode": "train", "epochs": 11, "timestep": 20655, "ep_reward": 389.57952880859375, "reward": 0.804351270198822, "action": 1.0819541215896606}
{"mode": "train", "epochs": 11, "timestep": 20656, "ep_reward": 390.40771484375, "reward": 0.8281870484352112, "action": 0.7319355010986328}
{"mode": "train", "epochs": 11, "timestep": 20657, "ep_reward": 391.2491455078125, "reward": 0.8414455652236938, "action": 0.3995956778526306}
{"mode": "train", "epochs": 11, "timestep": 20658, "ep_reward": 392.091796875, "reward": 0.842650830745697, "action": 0.2687540650367737}
{"mode": "train", "epochs": 11, "timestep": 20659, "ep_reward": 392.92236328125, "reward": 0.8305671215057373, "action": -0.11525553464889526}
{"mode": "train", "epochs": 11, "timestep": 20660, "ep_reward": 393.7250671386719, "reward": 0.8026955127716064, "action": 1.4181582927703857}
{"mode": "train", "epochs": 11, "timestep": 20661, "ep_reward": 394.4925842285156, "reward": 0.767525851726532, "action": 0.5747112035751343}
{"mode": "train", "epochs": 11, "timestep": 20662, "ep_reward": 395.2084045410156, "reward": 0.7158063650131226, "action": 0.9123572111129761}
{"mode": "train", "epochs": 11, "timestep": 20663, "ep_reward": 395.86102294921875, "reward": 0.652621865272522, "action": 1.3000717163085938}
{"mode": "train", "epochs": 11, "timestep": 20664, "ep_reward": 396.4422302246094, "reward": 0.5811975002288818, "action": 0.7960638999938965}
{"mode": "train", "epochs": 11, "timestep": 20665, "ep_reward": 396.9385070800781, "reward": 0.49628788232803345, "action": 1.2528002262115479}
{"mode": "train", "epochs": 11, "timestep": 20666, "ep_reward": 397.3482360839844, "reward": 0.40974223613739014, "action": 0.665058434009552}
{"mode": "train", "epochs": 11, "timestep": 20667, "ep_reward": 397.66400146484375, "reward": 0.3157660961151123, "action": 0.30631744861602783}
{"mode": "train", "epochs": 11, "timestep": 20668, "ep_reward": 397.930419921875, "reward": 0.2664188742637634, "action": 0.42812567949295044}
{"mode": "train", "epochs": 11, "timestep": 20669, "ep_reward": 398.288818359375, "reward": 0.35840386152267456, "action": 1.2743735313415527}
{"mode": "train", "epochs": 11, "timestep": 20670, "ep_reward": 398.741943359375, "reward": 0.4531126618385315, "action": 1.7200829982757568}
{"mode": "train", "epochs": 11, "timestep": 20671, "ep_reward": 399.28271484375, "reward": 0.5407750606536865, "action": 1.1445491313934326}
{"mode": "train", "epochs": 11, "timestep": 20672, "ep_reward": 399.89398193359375, "reward": 0.6112600564956665, "action": 0.6553508043289185}
{"mode": "train", "epochs": 11, "timestep": 20673, "ep_reward": 400.5588684082031, "reward": 0.6648790836334229, "action": 2.0}
{"mode": "train", "epochs": 11, "timestep": 20674, "ep_reward": 401.2638244628906, "reward": 0.7049410939216614, "action": 0.3668806552886963}
{"mode": "train", "epochs": 11, "timestep": 20675, "ep_reward": 401.9870910644531, "reward": 0.723255455493927, "action": 0.76146000623703}
{"mode": "train", "epochs": 11, "timestep": 20676, "ep_reward": 402.7125549316406, "reward": 0.7254738807678223, "action": 1.104848027229309}
{"mode": "train", "epochs": 11, "timestep": 20677, "ep_reward": 403.42169189453125, "reward": 0.70912766456604, "action": 0.8714370727539062}
{"mode": "train", "epochs": 11, "timestep": 20678, "ep_reward": 404.0964660644531, "reward": 0.6747668981552124, "action": 1.1400833129882812}
{"mode": "train", "epochs": 11, "timestep": 20679, "ep_reward": 404.7175598144531, "reward": 0.6211028099060059, "action": 0.3424607515335083}
{"mode": "train", "epochs": 11, "timestep": 20680, "ep_reward": 405.27349853515625, "reward": 0.5559251308441162, "action": 0.6164921522140503}
{"mode": "train", "epochs": 11, "timestep": 20681, "ep_reward": 405.7499694824219, "reward": 0.47646546363830566, "action": 0.5880770683288574}
{"mode": "train", "epochs": 11, "timestep": 20682, "ep_reward": 406.1374816894531, "reward": 0.3874973654747009, "action": 1.0543575286865234}
{"mode": "train", "epochs": 11, "timestep": 20683, "ep_reward": 406.4256286621094, "reward": 0.28813838958740234, "action": 1.0079900026321411}
{"mode": "train", "epochs": 11, "timestep": 20684, "ep_reward": 406.7449951171875, "reward": 0.31935882568359375, "action": 1.1413569450378418}
{"mode": "train", "epochs": 11, "timestep": 20685, "ep_reward": 407.14349365234375, "reward": 0.3985065221786499, "action": 1.1039972305297852}
{"mode": "train", "epochs": 11, "timestep": 20686, "ep_reward": 407.622314453125, "reward": 0.4788227677345276, "action": 0.31596291065216064}
{"mode": "train", "epochs": 11, "timestep": 20687, "ep_reward": 408.1831970214844, "reward": 0.5608805418014526, "action": 0.6864941120147705}
{"mode": "train", "epochs": 11, "timestep": 20688, "ep_reward": 408.815673828125, "reward": 0.6324632167816162, "action": 1.8681721687316895}
{"mode": "train", "epochs": 11, "timestep": 20689, "ep_reward": 409.5054016113281, "reward": 0.6897376775741577, "action": 0.3381826877593994}
{"mode": "train", "epochs": 11, "timestep": 20690, "ep_reward": 410.2498779296875, "reward": 0.7444672584533691, "action": 1.0980998277664185}
{"mode": "train", "epochs": 11, "timestep": 20691, "ep_reward": 411.0338134765625, "reward": 0.7839215397834778, "action": 1.2110170125961304}
{"mode": "train", "epochs": 11, "timestep": 20692, "ep_reward": 411.8463134765625, "reward": 0.8125049471855164, "action": 0.34839189052581787}
{"mode": "train", "epochs": 11, "timestep": 20693, "ep_reward": 412.67724609375, "reward": 0.8309372663497925, "action": 0.39610689878463745}
{"mode": "train", "epochs": 11, "timestep": 20694, "ep_reward": 413.5133361816406, "reward": 0.8360874056816101, "action": 1.571886658668518}
{"mode": "train", "epochs": 11, "timestep": 20695, "ep_reward": 414.3447265625, "reward": 0.8313807845115662, "action": 0.8653563857078552}
{"mode": "train", "epochs": 11, "timestep": 20696, "ep_reward": 415.16021728515625, "reward": 0.8154920339584351, "action": 0.9565165638923645}
{"mode": "train", "epochs": 11, "timestep": 20697, "ep_reward": 415.9484558105469, "reward": 0.7882466316223145, "action": 1.1265147924423218}
{"mode": "train", "epochs": 11, "timestep": 20698, "ep_reward": 416.6985778808594, "reward": 0.7501189708709717, "action": 0.5121047496795654}
{"mode": "train", "epochs": 11, "timestep": 20699, "ep_reward": 417.3943176269531, "reward": 0.6957262754440308, "action": 2.0}
{"mode": "train", "epochs": 11, "timestep": 20700, "ep_reward": 418.0343322753906, "reward": 0.6400133371353149, "action": 0.49654310941696167}
{"mode": "train", "epochs": 11, "timestep": 20701, "ep_reward": 418.5978698730469, "reward": 0.5635489821434021, "action": 1.123003363609314}
{"mode": "train", "epochs": 11, "timestep": 20702, "ep_reward": 419.0809020996094, "reward": 0.48303306102752686, "action": 1.0942292213439941}
{"mode": "train", "epochs": 11, "timestep": 20703, "ep_reward": 419.47869873046875, "reward": 0.3978113532066345, "action": 0.9587365984916687}
{"mode": "train", "epochs": 11, "timestep": 20704, "ep_reward": 419.7894592285156, "reward": 0.3107597231864929, "action": 1.181736707687378}
{"mode": "train", "epochs": 11, "timestep": 20705, "ep_reward": 420.08587646484375, "reward": 0.2964087724685669, "action": 1.0901079177856445}
{"mode": "train", "epochs": 11, "timestep": 20706, "ep_reward": 420.47088623046875, "reward": 0.38500142097473145, "action": 1.151444911956787}
{"mode": "train", "epochs": 11, "timestep": 20707, "ep_reward": 420.9398193359375, "reward": 0.46894586086273193, "action": 0.8001148700714111}
{"mode": "train", "epochs": 11, "timestep": 20708, "ep_reward": 421.4823303222656, "reward": 0.5425118207931519, "action": 1.0105502605438232}
{"mode": "train", "epochs": 11, "timestep": 20709, "ep_reward": 422.08819580078125, "reward": 0.6058651208877563, "action": 0.8497291803359985}
{"mode": "train", "epochs": 11, "timestep": 20710, "ep_reward": 422.7427978515625, "reward": 0.6546051502227783, "action": 0.4589150547981262}
{"mode": "train", "epochs": 11, "timestep": 20711, "ep_reward": 423.43035888671875, "reward": 0.6875573396682739, "action": 1.7887792587280273}
{"mode": "train", "epochs": 11, "timestep": 20712, "ep_reward": 424.13543701171875, "reward": 0.7050912380218506, "action": 0.19378943741321564}
{"mode": "train", "epochs": 11, "timestep": 20713, "ep_reward": 424.8400573730469, "reward": 0.7046135663986206, "action": -0.9581046104431152}
{"mode": "train", "epochs": 11, "timestep": 20714, "ep_reward": 425.5340576171875, "reward": 0.6940079927444458, "action": 0.07500430941581726}
{"mode": "train", "epochs": 11, "timestep": 20715, "ep_reward": 426.2037658691406, "reward": 0.6697031855583191, "action": 0.19007916748523712}
{"mode": "train", "epochs": 11, "timestep": 20716, "ep_reward": 426.8353576660156, "reward": 0.6315872073173523, "action": 0.2570158541202545}
{"mode": "train", "epochs": 11, "timestep": 20717, "ep_reward": 427.4155578613281, "reward": 0.5802057385444641, "action": 0.17612212896347046}
{"mode": "train", "epochs": 11, "timestep": 20718, "ep_reward": 427.9333801269531, "reward": 0.5178323984146118, "action": 1.2522566318511963}
{"mode": "train", "epochs": 11, "timestep": 20719, "ep_reward": 428.37054443359375, "reward": 0.4371792674064636, "action": 1.1977169513702393}
{"mode": "train", "epochs": 11, "timestep": 20720, "ep_reward": 428.717529296875, "reward": 0.3469884991645813, "action": 1.1515085697174072}
{"mode": "train", "epochs": 11, "timestep": 20721, "ep_reward": 429.01373291015625, "reward": 0.2962159514427185, "action": -0.07806050777435303}
{"mode": "train", "epochs": 11, "timestep": 20722, "ep_reward": 429.38934326171875, "reward": 0.3756224513053894, "action": 1.676073670387268}
{"mode": "train", "epochs": 11, "timestep": 20723, "ep_reward": 429.8345642089844, "reward": 0.4452148675918579, "action": 1.035576343536377}
{"mode": "train", "epochs": 11, "timestep": 20724, "ep_reward": 430.3534240722656, "reward": 0.5188473463058472, "action": 0.4465234577655792}
{"mode": "train", "epochs": 11, "timestep": 20725, "ep_reward": 430.9445495605469, "reward": 0.591134786605835, "action": 1.292398452758789}
{"mode": "train", "epochs": 11, "timestep": 20726, "ep_reward": 431.5959777832031, "reward": 0.6514313817024231, "action": 1.1303625106811523}
{"mode": "train", "epochs": 11, "timestep": 20727, "ep_reward": 432.30035400390625, "reward": 0.7043688297271729, "action": 1.062596082687378}
{"mode": "train", "epochs": 11, "timestep": 20728, "ep_reward": 433.0479736328125, "reward": 0.747632622718811, "action": 1.6937463283538818}
{"mode": "train", "epochs": 11, "timestep": 20729, "ep_reward": 433.8276062011719, "reward": 0.7796400785446167, "action": 0.4754696488380432}
{"mode": "train", "epochs": 11, "timestep": 20730, "ep_reward": 434.6313171386719, "reward": 0.8037158846855164, "action": 1.1518921852111816}
{"mode": "train", "epochs": 11, "timestep": 20731, "ep_reward": 435.44683837890625, "reward": 0.8155174851417542, "action": 0.09501367807388306}
{"mode": "train", "epochs": 11, "timestep": 20732, "ep_reward": 436.2619934082031, "reward": 0.8151604533195496, "action": 0.49203699827194214}
{"mode": "train", "epochs": 11, "timestep": 20733, "ep_reward": 437.0634460449219, "reward": 0.8014506697654724, "action": 1.3921740055084229}
{"mode": "train", "epochs": 11, "timestep": 20734, "ep_reward": 437.8420715332031, "reward": 0.7786365747451782, "action": 1.127959966659546}
{"mode": "train", "epochs": 11, "timestep": 20735, "ep_reward": 438.5864562988281, "reward": 0.7443755269050598, "action": 1.1996142864227295}
{"mode": "train", "epochs": 11, "timestep": 20736, "ep_reward": 439.2859191894531, "reward": 0.6994692087173462, "action": 1.044203758239746}
{"mode": "train", "epochs": 11, "timestep": 20737, "ep_reward": 439.92864990234375, "reward": 0.6427344679832458, "action": 1.4994593858718872}
{"mode": "train", "epochs": 11, "timestep": 20738, "ep_reward": 440.5085754394531, "reward": 0.5799369812011719, "action": 1.0316519737243652}
{"mode": "train", "epochs": 11, "timestep": 20739, "ep_reward": 441.0148620605469, "reward": 0.5062803030014038, "action": 1.692702293395996}
{"mode": "train", "epochs": 11, "timestep": 20740, "ep_reward": 441.4492492675781, "reward": 0.4343879818916321, "action": 0.6136430501937866}
{"mode": "train", "epochs": 11, "timestep": 20741, "ep_reward": 441.80096435546875, "reward": 0.35172539949417114, "action": 2.0}
{"mode": "train", "epochs": 11, "timestep": 20742, "ep_reward": 442.0897216796875, "reward": 0.2887471318244934, "action": 1.02271568775177}
{"mode": "train", "epochs": 11, "timestep": 20743, "ep_reward": 442.45758056640625, "reward": 0.36785370111465454, "action": 1.3999948501586914}
{"mode": "train", "epochs": 11, "timestep": 20744, "ep_reward": 442.9024658203125, "reward": 0.44489818811416626, "action": 0.512627124786377}
{"mode": "train", "epochs": 11, "timestep": 20745, "ep_reward": 443.4131164550781, "reward": 0.5106394290924072, "action": 0.06538349390029907}
{"mode": "train", "epochs": 11, "timestep": 20746, "ep_reward": 443.9803466796875, "reward": 0.5672398805618286, "action": 0.9352611899375916}
{"mode": "train", "epochs": 11, "timestep": 20747, "ep_reward": 444.59722900390625, "reward": 0.6168727874755859, "action": 1.204424262046814}
{"mode": "train", "epochs": 11, "timestep": 20748, "ep_reward": 445.2498779296875, "reward": 0.6526450514793396, "action": 0.5641122460365295}
{"mode": "train", "epochs": 11, "timestep": 20749, "ep_reward": 445.92205810546875, "reward": 0.6721689701080322, "action": -0.4663645625114441}
{"mode": "train", "epochs": 11, "timestep": 20750, "ep_reward": 446.60107421875, "reward": 0.6790270209312439, "action": -1.0034117698669434}
{"mode": "train", "epochs": 11, "timestep": 20751, "ep_reward": 447.27801513671875, "reward": 0.6769494414329529, "action": -0.9863293170928955}
{"mode": "train", "epochs": 11, "timestep": 20752, "ep_reward": 447.9445495605469, "reward": 0.6665384769439697, "action": -0.7951972484588623}
{"mode": "train", "epochs": 11, "timestep": 20753, "ep_reward": 448.5916442871094, "reward": 0.6470972299575806, "action": -1.1215208768844604}
{"mode": "train", "epochs": 11, "timestep": 20754, "ep_reward": 449.2124938964844, "reward": 0.6208479404449463, "action": 0.906290590763092}
{"mode": "train", "epochs": 11, "timestep": 20755, "ep_reward": 449.78863525390625, "reward": 0.5761428475379944, "action": 1.0615557432174683}
{"mode": "train", "epochs": 11, "timestep": 20756, "ep_reward": 450.3052978515625, "reward": 0.5166661143302917, "action": 0.6519699096679688}
{"mode": "train", "epochs": 11, "timestep": 20757, "ep_reward": 450.7537536621094, "reward": 0.44844532012939453, "action": 0.7026398181915283}
{"mode": "train", "epochs": 11, "timestep": 20758, "ep_reward": 451.1261901855469, "reward": 0.37243950366973877, "action": 1.1717456579208374}
{"mode": "train", "epochs": 11, "timestep": 20759, "ep_reward": 451.4321594238281, "reward": 0.3059656023979187, "action": 0.7799595594406128}
{"mode": "train", "epochs": 11, "timestep": 20760, "ep_reward": 451.8054504394531, "reward": 0.37328046560287476, "action": 0.8927891850471497}
{"mode": "train", "epochs": 11, "timestep": 20761, "ep_reward": 452.2468566894531, "reward": 0.4414132237434387, "action": 1.575624942779541}
{"mode": "train", "epochs": 11, "timestep": 20762, "ep_reward": 452.7526550292969, "reward": 0.5057929158210754, "action": 1.4998250007629395}
{"mode": "train", "epochs": 11, "timestep": 20763, "ep_reward": 453.3216247558594, "reward": 0.5689824819564819, "action": 1.442101240158081}
{"mode": "train", "epochs": 11, "timestep": 20764, "ep_reward": 453.9499206542969, "reward": 0.628286600112915, "action": 0.8702471852302551}
{"mode": "train", "epochs": 11, "timestep": 20765, "ep_reward": 454.63287353515625, "reward": 0.6829450130462646, "action": 0.7899459004402161}
{"mode": "train", "epochs": 11, "timestep": 20766, "ep_reward": 455.3606872558594, "reward": 0.727824866771698, "action": 0.7313179969787598}
{"mode": "train", "epochs": 11, "timestep": 20767, "ep_reward": 456.12237548828125, "reward": 0.7616732120513916, "action": 0.6624000072479248}
{"mode": "train", "epochs": 11, "timestep": 20768, "ep_reward": 456.90618896484375, "reward": 0.7838097810745239, "action": 1.1338950395584106}
{"mode": "train", "epochs": 11, "timestep": 20769, "ep_reward": 457.70062255859375, "reward": 0.7944256663322449, "action": 0.9439469575881958}
{"mode": "train", "epochs": 11, "timestep": 20770, "ep_reward": 458.4950256347656, "reward": 0.7943919897079468, "action": 1.377642035484314}
{"mode": "train", "epochs": 11, "timestep": 20771, "ep_reward": 459.2797546386719, "reward": 0.7847203612327576, "action": 1.1681264638900757}
{"mode": "train", "epochs": 11, "timestep": 20772, "ep_reward": 460.0444641113281, "reward": 0.7647215723991394, "action": 0.6033046841621399}
{"mode": "train", "epochs": 11, "timestep": 20773, "ep_reward": 460.7757263183594, "reward": 0.7312591075897217, "action": 0.6638708114624023}
{"mode": "train", "epochs": 11, "timestep": 20774, "ep_reward": 461.46112060546875, "reward": 0.6853845119476318, "action": 0.3674551248550415}
{"mode": "train", "epochs": 11, "timestep": 20775, "ep_reward": 462.0860290527344, "reward": 0.6248974800109863, "action": 1.7887758016586304}
{"mode": "train", "epochs": 11, "timestep": 20776, "ep_reward": 462.65087890625, "reward": 0.5648497343063354, "action": 1.0470958948135376}
{"mode": "train", "epochs": 11, "timestep": 20777, "ep_reward": 463.14434814453125, "reward": 0.4934651851654053, "action": 1.3698779344558716}
{"mode": "train", "epochs": 11, "timestep": 20778, "ep_reward": 463.5656433105469, "reward": 0.42129313945770264, "action": 0.784268856048584}
{"mode": "train", "epochs": 11, "timestep": 20779, "ep_reward": 463.90911865234375, "reward": 0.34346747398376465, "action": 1.7154808044433594}
{"mode": "train", "epochs": 11, "timestep": 20780, "ep_reward": 464.2185363769531, "reward": 0.30941498279571533, "action": 0.4620305597782135}
{"mode": "train", "epochs": 11, "timestep": 20781, "ep_reward": 464.60186767578125, "reward": 0.3833457827568054, "action": 0.6089450120925903}
{"mode": "train", "epochs": 11, "timestep": 20782, "ep_reward": 465.0572204589844, "reward": 0.4553385376930237, "action": 1.4853310585021973}
{"mode": "train", "epochs": 11, "timestep": 20783, "ep_reward": 465.5816650390625, "reward": 0.5244468450546265, "action": 0.063443124294281}
{"mode": "train", "epochs": 11, "timestep": 20784, "ep_reward": 466.15948486328125, "reward": 0.5778119564056396, "action": 0.3139383792877197}
{"mode": "train", "epochs": 11, "timestep": 20785, "ep_reward": 466.7820129394531, "reward": 0.6225346326828003, "action": -1.5026990175247192}
{"mode": "train", "epochs": 11, "timestep": 20786, "ep_reward": 467.4364318847656, "reward": 0.6544299125671387, "action": -0.7623351812362671}
{"mode": "train", "epochs": 11, "timestep": 20787, "ep_reward": 468.1170349121094, "reward": 0.6806039810180664, "action": -0.2907358407974243}
{"mode": "train", "epochs": 11, "timestep": 20788, "ep_reward": 468.8141784667969, "reward": 0.6971489191055298, "action": -0.597568154335022}
{"mode": "train", "epochs": 11, "timestep": 20789, "ep_reward": 469.51678466796875, "reward": 0.702598512172699, "action": -0.9023290276527405}
{"mode": "train", "epochs": 11, "timestep": 20790, "ep_reward": 470.21502685546875, "reward": 0.6982319355010986, "action": -1.3288042545318604}
{"mode": "train", "epochs": 11, "timestep": 20791, "ep_reward": 470.9010925292969, "reward": 0.6860682964324951, "action": -0.7491111159324646}
{"mode": "train", "epochs": 11, "timestep": 20792, "ep_reward": 471.5648498535156, "reward": 0.6637560725212097, "action": 0.012010037899017334}
{"mode": "train", "epochs": 11, "timestep": 20793, "ep_reward": 472.19268798828125, "reward": 0.6278478503227234, "action": 0.825069785118103}
{"mode": "train", "epochs": 11, "timestep": 20794, "ep_reward": 472.7674865722656, "reward": 0.5747994184494019, "action": 0.7577181458473206}
{"mode": "train", "epochs": 11, "timestep": 20795, "ep_reward": 473.2757568359375, "reward": 0.508285403251648, "action": 1.7245306968688965}
{"mode": "train", "epochs": 11, "timestep": 20796, "ep_reward": 473.6979675292969, "reward": 0.42222458124160767, "action": 0.8300198316574097}
{"mode": "train", "epochs": 11, "timestep": 20797, "ep_reward": 474.03155517578125, "reward": 0.33357447385787964, "action": 0.6017134189605713}
{"mode": "train", "epochs": 11, "timestep": 20798, "ep_reward": 474.341064453125, "reward": 0.3095237612724304, "action": 1.3990859985351562}
{"mode": "train", "epochs": 11, "timestep": 20799, "ep_reward": 474.72137451171875, "reward": 0.38030028343200684, "action": 2.0}
{"mode": "train", "epochs": 11, "timestep": 20800, "ep_reward": 475.1718444824219, "reward": 0.4504792094230652, "action": 0.05433100461959839}
{"mode": "train", "epochs": 11, "timestep": 20801, "ep_reward": 475.7037658691406, "reward": 0.5319138169288635, "action": 2.0}
{"mode": "train", "epochs": 11, "timestep": 20802, "ep_reward": 476.3005065917969, "reward": 0.596734881401062, "action": 0.12170815467834473}
{"mode": "train", "epochs": 11, "timestep": 20803, "ep_reward": 476.9656677246094, "reward": 0.6651533842086792, "action": 0.9024478197097778}
{"mode": "train", "epochs": 11, "timestep": 20804, "ep_reward": 477.68408203125, "reward": 0.7184062600135803, "action": 0.15770810842514038}
{"mode": "train", "epochs": 11, "timestep": 20805, "ep_reward": 478.4463195800781, "reward": 0.7622500061988831, "action": 1.0921508073806763}
{"mode": "train", "epochs": 11, "timestep": 20806, "ep_reward": 479.2373352050781, "reward": 0.7910239100456238, "action": 1.022753357887268}
{"mode": "train", "epochs": 11, "timestep": 20807, "ep_reward": 480.0465087890625, "reward": 0.8091800808906555, "action": 1.4925228357315063}
{"mode": "train", "epochs": 11, "timestep": 20808, "ep_reward": 480.86383056640625, "reward": 0.8173178434371948, "action": 0.27692466974258423}
{"mode": "train", "epochs": 11, "timestep": 20809, "ep_reward": 481.6776123046875, "reward": 0.8137882351875305, "action": 1.3807406425476074}
{"mode": "train", "epochs": 11, "timestep": 20810, "ep_reward": 482.47796630859375, "reward": 0.8003507256507874, "action": 1.2009626626968384}
{"mode": "train", "epochs": 11, "timestep": 20811, "ep_reward": 483.25439453125, "reward": 0.7764378190040588, "action": 0.6645467281341553}
{"mode": "train", "epochs": 11, "timestep": 20812, "ep_reward": 483.99310302734375, "reward": 0.7386994957923889, "action": 1.1115237474441528}
{"mode": "train", "epochs": 11, "timestep": 20813, "ep_reward": 484.6841125488281, "reward": 0.6909949779510498, "action": 0.9803650379180908}
{"mode": "train", "epochs": 11, "timestep": 20814, "ep_reward": 485.3155517578125, "reward": 0.631424605846405, "action": 0.4904024004936218}
{"mode": "train", "epochs": 11, "timestep": 20815, "ep_reward": 485.872802734375, "reward": 0.5572453737258911, "action": 0.6717446446418762}
{"mode": "train", "epochs": 11, "timestep": 20816, "ep_reward": 486.3478698730469, "reward": 0.4750775694847107, "action": 0.7754703760147095}
{"mode": "train", "epochs": 11, "timestep": 20817, "ep_reward": 486.73638916015625, "reward": 0.3885173797607422, "action": 1.1439777612686157}
{"mode": "train", "epochs": 11, "timestep": 20818, "ep_reward": 487.04156494140625, "reward": 0.305178165435791, "action": 1.7960388660430908}
{"mode": "train", "epochs": 11, "timestep": 20819, "ep_reward": 487.3561706542969, "reward": 0.31460583209991455, "action": 0.7726298570632935}
{"mode": "train", "epochs": 11, "timestep": 20820, "ep_reward": 487.7535400390625, "reward": 0.3973560929298401, "action": 0.2677256464958191}
{"mode": "train", "epochs": 11, "timestep": 20821, "ep_reward": 488.2270812988281, "reward": 0.4735560417175293, "action": 0.8973821997642517}
{"mode": "train", "epochs": 11, "timestep": 20822, "ep_reward": 488.7734375, "reward": 0.5463635921478271, "action": 1.08194899559021}
{"mode": "train", "epochs": 11, "timestep": 20823, "ep_reward": 489.38177490234375, "reward": 0.6083266735076904, "action": 0.9394336938858032}
{"mode": "train", "epochs": 11, "timestep": 20824, "ep_reward": 490.03717041015625, "reward": 0.6553820371627808, "action": -0.18255515396595}
{"mode": "train", "epochs": 11, "timestep": 20825, "ep_reward": 490.7233581542969, "reward": 0.6861854791641235, "action": -0.07094337046146393}
{"mode": "train", "epochs": 11, "timestep": 20826, "ep_reward": 491.4284973144531, "reward": 0.7051293253898621, "action": 0.1862686276435852}
{"mode": "train", "epochs": 11, "timestep": 20827, "ep_reward": 492.13934326171875, "reward": 0.7108323574066162, "action": -0.3522077202796936}
{"mode": "train", "epochs": 11, "timestep": 20828, "ep_reward": 492.84326171875, "reward": 0.7039177417755127, "action": -0.4530971050262451}
{"mode": "train", "epochs": 11, "timestep": 20829, "ep_reward": 493.52880859375, "reward": 0.6855366230010986, "action": 0.22715431451797485}
{"mode": "train", "epochs": 11, "timestep": 20830, "ep_reward": 494.1812438964844, "reward": 0.6524314284324646, "action": 0.6985833048820496}
{"mode": "train", "epochs": 11, "timestep": 20831, "ep_reward": 494.7839660644531, "reward": 0.6027237176895142, "action": 0.5182283520698547}
{"mode": "train", "epochs": 11, "timestep": 20832, "ep_reward": 495.3238220214844, "reward": 0.5398600697517395, "action": 1.0379700660705566}
{"mode": "train", "epochs": 11, "timestep": 20833, "ep_reward": 495.7847595214844, "reward": 0.46093249320983887, "action": 1.5169116258621216}
{"mode": "train", "epochs": 11, "timestep": 20834, "ep_reward": 496.1514587402344, "reward": 0.3666902780532837, "action": 2.0}
{"mode": "train", "epochs": 11, "timestep": 20835, "ep_reward": 496.4154357910156, "reward": 0.2639668583869934, "action": 1.1732715368270874}
{"mode": "train", "epochs": 11, "timestep": 20836, "ep_reward": 496.756103515625, "reward": 0.3406657576560974, "action": 1.9797680377960205}
{"mode": "train", "epochs": 11, "timestep": 20837, "ep_reward": 497.1718444824219, "reward": 0.4157264828681946, "action": 1.0151680707931519}
{"mode": "train", "epochs": 11, "timestep": 20838, "ep_reward": 497.6705627441406, "reward": 0.49870842695236206, "action": 1.1779205799102783}
{"mode": "train", "epochs": 11, "timestep": 20839, "ep_reward": 498.2474365234375, "reward": 0.576887845993042, "action": 1.191613793373108}
{"mode": "train", "epochs": 11, "timestep": 20840, "ep_reward": 498.895751953125, "reward": 0.6483135223388672, "action": 1.2245413064956665}
{"mode": "train", "epochs": 11, "timestep": 20841, "ep_reward": 499.60614013671875, "reward": 0.7104001045227051, "action": 1.6557797193527222}
{"mode": "train", "epochs": 11, "timestep": 20842, "ep_reward": 500.3667907714844, "reward": 0.7606521844863892, "action": 1.1483497619628906}
{"mode": "train", "epochs": 11, "timestep": 20843, "ep_reward": 501.169677734375, "reward": 0.8028724789619446, "action": 0.4931338429450989}
{"mode": "train", "epochs": 11, "timestep": 20844, "ep_reward": 502.0047607421875, "reward": 0.8350931406021118, "action": 1.2185211181640625}
{"mode": "train", "epochs": 11, "timestep": 20845, "ep_reward": 502.8590393066406, "reward": 0.8542839884757996, "action": 1.4803907871246338}
{"mode": "train", "epochs": 11, "timestep": 20846, "ep_reward": 503.7232360839844, "reward": 0.8642104864120483, "action": 1.0368396043777466}
{"mode": "train", "epochs": 11, "timestep": 20847, "ep_reward": 504.5884094238281, "reward": 0.8651785850524902, "action": 0.6151915788650513}
{"mode": "train", "epochs": 11, "timestep": 20848, "ep_reward": 505.44342041015625, "reward": 0.8550117015838623, "action": 1.3846893310546875}
{"mode": "train", "epochs": 11, "timestep": 20849, "ep_reward": 506.2794494628906, "reward": 0.8360150456428528, "action": 1.601593017578125}
{"mode": "train", "epochs": 11, "timestep": 20850, "ep_reward": 507.087890625, "reward": 0.8084564208984375, "action": 0.9507143497467041}
{"mode": "train", "epochs": 11, "timestep": 20851, "ep_reward": 507.85491943359375, "reward": 0.7670326828956604, "action": 1.5662977695465088}
{"mode": "train", "epochs": 11, "timestep": 20852, "ep_reward": 508.5722961425781, "reward": 0.7173880338668823, "action": 0.7748332023620605}
{"mode": "train", "epochs": 11, "timestep": 20853, "ep_reward": 509.2227783203125, "reward": 0.6504763960838318, "action": 0.4746631383895874}
{"mode": "train", "epochs": 11, "timestep": 20854, "ep_reward": 509.79046630859375, "reward": 0.5676786303520203, "action": 0.7986653447151184}
{"mode": "train", "epochs": 11, "timestep": 20855, "ep_reward": 510.2668762207031, "reward": 0.47641968727111816, "action": 1.3982150554656982}
{"mode": "train", "epochs": 11, "timestep": 20856, "ep_reward": 510.6525573730469, "reward": 0.3856862187385559, "action": 0.5871728658676147}
{"mode": "train", "epochs": 11, "timestep": 20857, "ep_reward": 510.938232421875, "reward": 0.28566884994506836, "action": 0.6607711315155029}
{"mode": "train", "epochs": 11, "timestep": 20858, "ep_reward": 511.2115783691406, "reward": 0.27335721254348755, "action": 1.462148666381836}
{"mode": "train", "epochs": 11, "timestep": 20859, "ep_reward": 511.58709716796875, "reward": 0.37551504373550415, "action": 0.6634021997451782}
{"mode": "train", "epochs": 11, "timestep": 20860, "ep_reward": 512.0538330078125, "reward": 0.4667356610298157, "action": 1.0628944635391235}
{"mode": "train", "epochs": 11, "timestep": 20861, "ep_reward": 512.6061401367188, "reward": 0.5523269176483154, "action": 0.6167969107627869}
{"mode": "train", "epochs": 11, "timestep": 20862, "ep_reward": 513.2293090820312, "reward": 0.6231679916381836, "action": 0.4495716094970703}
{"mode": "train", "epochs": 11, "timestep": 20863, "ep_reward": 513.908935546875, "reward": 0.6796404719352722, "action": -0.40797296166419983}
{"mode": "train", "epochs": 11, "timestep": 20864, "ep_reward": 514.6288452148438, "reward": 0.7199032306671143, "action": -0.15331979095935822}
{"mode": "train", "epochs": 11, "timestep": 20865, "ep_reward": 515.376953125, "reward": 0.7481304407119751, "action": -0.0946694165468216}
{"mode": "train", "epochs": 11, "timestep": 20866, "ep_reward": 516.1395874023438, "reward": 0.7626380920410156, "action": -0.7391917109489441}
{"mode": "train", "epochs": 11, "timestep": 20867, "ep_reward": 516.9038696289062, "reward": 0.7643126845359802, "action": -0.9353721141815186}
{"mode": "train", "epochs": 11, "timestep": 20868, "ep_reward": 517.6589965820312, "reward": 0.755124568939209, "action": -0.13878613710403442}
{"mode": "train", "epochs": 11, "timestep": 20869, "ep_reward": 518.3907470703125, "reward": 0.7317479848861694, "action": 0.5107412338256836}
{"mode": "train", "epochs": 11, "timestep": 20870, "ep_reward": 519.0812377929688, "reward": 0.690491795539856, "action": 0.566108226776123}
{"mode": "train", "epochs": 11, "timestep": 20871, "ep_reward": 519.7130737304688, "reward": 0.6318100690841675, "action": 0.9847604036331177}
{"mode": "train", "epochs": 11, "timestep": 20872, "ep_reward": 520.2664184570312, "reward": 0.5533387660980225, "action": 0.9712194800376892}
{"mode": "train", "epochs": 11, "timestep": 20873, "ep_reward": 520.7255249023438, "reward": 0.4591195583343506, "action": 0.8354846239089966}
{"mode": "train", "epochs": 11, "timestep": 20874, "ep_reward": 521.0801391601562, "reward": 0.3546239137649536, "action": 0.499968558549881}
{"mode": "train", "epochs": 11, "timestep": 20875, "ep_reward": 521.3282470703125, "reward": 0.2481364607810974, "action": 1.3095901012420654}
{"mode": "train", "epochs": 11, "timestep": 20876, "ep_reward": 521.6373291015625, "reward": 0.3090754747390747, "action": 1.4278316497802734}
{"mode": "train", "epochs": 11, "timestep": 20877, "ep_reward": 522.0322265625, "reward": 0.39489632844924927, "action": 1.2461116313934326}
{"mode": "train", "epochs": 11, "timestep": 20878, "ep_reward": 522.5154418945312, "reward": 0.48322105407714844, "action": 0.2515623867511749}
{"mode": "train", "epochs": 11, "timestep": 20879, "ep_reward": 523.0900268554688, "reward": 0.5746033787727356, "action": 1.0371103286743164}
{"mode": "train", "epochs": 11, "timestep": 20880, "ep_reward": 523.7412109375, "reward": 0.6511653661727905, "action": 1.5040242671966553}
{"mode": "train", "epochs": 11, "timestep": 20881, "ep_reward": 524.4564819335938, "reward": 0.7152740955352783, "action": 1.1693674325942993}
{"mode": "train", "epochs": 11, "timestep": 20882, "ep_reward": 525.2271118164062, "reward": 0.7706283330917358, "action": 1.0230481624603271}
{"mode": "train", "epochs": 11, "timestep": 20883, "ep_reward": 526.0419311523438, "reward": 0.8148193359375, "action": 1.5002484321594238}
{"mode": "train", "epochs": 11, "timestep": 20884, "ep_reward": 526.8886108398438, "reward": 0.8467026948928833, "action": 0.32591676712036133}
{"mode": "train", "epochs": 11, "timestep": 20885, "ep_reward": 527.7592163085938, "reward": 0.8706285357475281, "action": 0.8520464897155762}
{"mode": "train", "epochs": 11, "timestep": 20886, "ep_reward": 528.6416625976562, "reward": 0.8824353814125061, "action": 0.45790332555770874}
{"mode": "train", "epochs": 11, "timestep": 20887, "ep_reward": 529.5254516601562, "reward": 0.8837977647781372, "action": 0.8169275522232056}
{"mode": "train", "epochs": 11, "timestep": 20888, "ep_reward": 530.4003295898438, "reward": 0.8749004602432251, "action": 0.2745763063430786}
{"mode": "train", "epochs": 11, "timestep": 20889, "ep_reward": 531.2535400390625, "reward": 0.8532370328903198, "action": 1.4872827529907227}
{"mode": "train", "epochs": 11, "timestep": 20890, "ep_reward": 532.0778198242188, "reward": 0.8242816925048828, "action": 1.7063239812850952}
{"mode": "train", "epochs": 11, "timestep": 20891, "ep_reward": 532.864501953125, "reward": 0.7866588234901428, "action": 0.8551536798477173}
{"mode": "train", "epochs": 11, "timestep": 20892, "ep_reward": 533.5969848632812, "reward": 0.7324955463409424, "action": 0.5509943962097168}
{"mode": "train", "epochs": 11, "timestep": 20893, "ep_reward": 534.2584838867188, "reward": 0.6614881753921509, "action": 1.1174384355545044}
{"mode": "train", "epochs": 11, "timestep": 20894, "ep_reward": 534.8397216796875, "reward": 0.5812592506408691, "action": 0.4562251567840576}
{"mode": "train", "epochs": 11, "timestep": 20895, "ep_reward": 535.32275390625, "reward": 0.4830394387245178, "action": 1.7678149938583374}
{"mode": "train", "epochs": 11, "timestep": 20896, "ep_reward": 535.7142333984375, "reward": 0.39148402214050293, "action": 1.2671921253204346}
{"mode": "train", "epochs": 11, "timestep": 20897, "ep_reward": 536.0088500976562, "reward": 0.2945953607559204, "action": 1.090284824371338}
{"mode": "train", "epochs": 11, "timestep": 20898, "ep_reward": 536.2614135742188, "reward": 0.252562940120697, "action": 0.974232017993927}
{"mode": "train", "epochs": 11, "timestep": 20899, "ep_reward": 536.6148681640625, "reward": 0.3534337282180786, "action": 0.7739887237548828}
{"mode": "train", "epochs": 11, "timestep": 20900, "ep_reward": 537.0641479492188, "reward": 0.4492802023887634, "action": 1.111173391342163}
{"mode": "train", "epochs": 11, "timestep": 20901, "ep_reward": 537.6036376953125, "reward": 0.5394754409790039, "action": 1.1065059900283813}
{"mode": "train", "epochs": 11, "timestep": 20902, "ep_reward": 538.220458984375, "reward": 0.6167949438095093, "action": -0.6227477788925171}
{"mode": "train", "epochs": 11, "timestep": 20903, "ep_reward": 538.8934326171875, "reward": 0.6729579567909241, "action": 0.3876943588256836}
{"mode": "train", "epochs": 11, "timestep": 20904, "ep_reward": 539.6141357421875, "reward": 0.7207300662994385, "action": -0.3811294138431549}
{"mode": "train", "epochs": 11, "timestep": 20905, "ep_reward": 540.3663330078125, "reward": 0.752190113067627, "action": -0.21304404735565186}
{"mode": "train", "epochs": 11, "timestep": 20906, "ep_reward": 541.1370849609375, "reward": 0.7707635760307312, "action": -0.40284013748168945}
{"mode": "train", "epochs": 11, "timestep": 20907, "ep_reward": 541.9130249023438, "reward": 0.775927722454071, "action": 0.4436100125312805}
{"mode": "train", "epochs": 11, "timestep": 20908, "ep_reward": 542.6786499023438, "reward": 0.765611469745636, "action": -0.3467274010181427}
{"mode": "train", "epochs": 11, "timestep": 20909, "ep_reward": 543.4202880859375, "reward": 0.7416635751724243, "action": 1.0020885467529297}
{"mode": "train", "epochs": 11, "timestep": 20910, "ep_reward": 544.1167602539062, "reward": 0.6964420676231384, "action": 0.509278416633606}
{"mode": "train", "epochs": 11, "timestep": 20911, "ep_reward": 544.751708984375, "reward": 0.6349660754203796, "action": 0.8129315376281738}
{"mode": "train", "epochs": 11, "timestep": 20912, "ep_reward": 545.3060302734375, "reward": 0.5543073415756226, "action": 1.439292311668396}
{"mode": "train", "epochs": 11, "timestep": 20913, "ep_reward": 545.7578735351562, "reward": 0.45184361934661865, "action": 0.14800786972045898}
{"mode": "train", "epochs": 11, "timestep": 20914, "ep_reward": 546.1077880859375, "reward": 0.3498882055282593, "action": -0.11194401979446411}
{"mode": "train", "epochs": 11, "timestep": 20915, "ep_reward": 546.355712890625, "reward": 0.24794119596481323, "action": 1.3281207084655762}
{"mode": "train", "epochs": 11, "timestep": 20916, "ep_reward": 546.6617431640625, "reward": 0.30604565143585205, "action": 0.1297411322593689}
{"mode": "train", "epochs": 11, "timestep": 20917, "ep_reward": 547.0631103515625, "reward": 0.4013557434082031, "action": 0.9423828125}
{"mode": "train", "epochs": 11, "timestep": 20918, "ep_reward": 547.552001953125, "reward": 0.4889214038848877, "action": 0.9462500810623169}
{"mode": "train", "epochs": 11, "timestep": 20919, "ep_reward": 548.1243286132812, "reward": 0.572356104850769, "action": 1.4703984260559082}
{"mode": "train", "epochs": 11, "timestep": 20920, "ep_reward": 548.7696533203125, "reward": 0.6453503370285034, "action": 1.3137354850769043}
{"mode": "train", "epochs": 11, "timestep": 20921, "ep_reward": 549.4802856445312, "reward": 0.7106122970581055, "action": 0.880413293838501}
{"mode": "train", "epochs": 11, "timestep": 20922, "ep_reward": 550.2471923828125, "reward": 0.7669020891189575, "action": 1.5451353788375854}
{"mode": "train", "epochs": 11, "timestep": 20923, "ep_reward": 551.0562133789062, "reward": 0.8089985847473145, "action": 0.7534734606742859}
{"mode": "train", "epochs": 11, "timestep": 20924, "ep_reward": 551.8991088867188, "reward": 0.8428735733032227, "action": 0.9722564816474915}
{"mode": "train", "epochs": 11, "timestep": 20925, "ep_reward": 552.7638549804688, "reward": 0.8647279739379883, "action": 1.8813062906265259}
{"mode": "train", "epochs": 11, "timestep": 20926, "ep_reward": 553.6406860351562, "reward": 0.8768355846405029, "action": 0.9382436871528625}
{"mode": "train", "epochs": 11, "timestep": 20927, "ep_reward": 554.5218505859375, "reward": 0.8811855912208557, "action": 1.3572537899017334}
{"mode": "train", "epochs": 11, "timestep": 20928, "ep_reward": 555.3987426757812, "reward": 0.8769130706787109, "action": 1.1565749645233154}
{"mode": "train", "epochs": 11, "timestep": 20929, "ep_reward": 556.2623901367188, "reward": 0.8636192083358765, "action": 0.772506594657898}
{"mode": "train", "epochs": 11, "timestep": 20930, "ep_reward": 557.1011352539062, "reward": 0.8387680649757385, "action": 1.3380577564239502}
{"mode": "train", "epochs": 11, "timestep": 20931, "ep_reward": 557.906005859375, "reward": 0.8048622608184814, "action": 1.5118577480316162}
{"mode": "train", "epochs": 11, "timestep": 20932, "ep_reward": 558.6670532226562, "reward": 0.7610527276992798, "action": 1.0269221067428589}
{"mode": "train", "epochs": 11, "timestep": 20933, "ep_reward": 559.3692016601562, "reward": 0.7021657228469849, "action": 1.156579852104187}
{"mode": "train", "epochs": 11, "timestep": 20934, "ep_reward": 560.0005493164062, "reward": 0.6313744783401489, "action": 0.5681471824645996}
{"mode": "train", "epochs": 11, "timestep": 20935, "ep_reward": 560.54345703125, "reward": 0.542896032333374, "action": 1.743441104888916}
{"mode": "train", "epochs": 11, "timestep": 20936, "ep_reward": 561.0003051757812, "reward": 0.45684880018234253, "action": 0.44296568632125854}
{"mode": "train", "epochs": 11, "timestep": 20937, "ep_reward": 561.3533935546875, "reward": 0.3530924916267395, "action": 0.7738893032073975}
{"mode": "train", "epochs": 11, "timestep": 20938, "ep_reward": 561.6051635742188, "reward": 0.2517988085746765, "action": 0.5650608539581299}
{"mode": "train", "epochs": 11, "timestep": 20939, "ep_reward": 561.8953247070312, "reward": 0.29018688201904297, "action": 1.5866894721984863}
{"mode": "train", "epochs": 11, "timestep": 20940, "ep_reward": 562.2915649414062, "reward": 0.39622437953948975, "action": -0.5850419402122498}
{"mode": "train", "epochs": 11, "timestep": 20941, "ep_reward": 562.773193359375, "reward": 0.48161011934280396, "action": 0.05518600344657898}
{"mode": "train", "epochs": 11, "timestep": 20942, "ep_reward": 563.33935546875, "reward": 0.5661662817001343, "action": 0.053217485547065735}
{"mode": "train", "epochs": 11, "timestep": 20943, "ep_reward": 563.9798583984375, "reward": 0.6405224800109863, "action": -0.5580915212631226}
{"mode": "train", "epochs": 11, "timestep": 20944, "ep_reward": 564.6797485351562, "reward": 0.6998986601829529, "action": -0.6792211532592773}
{"mode": "train", "epochs": 11, "timestep": 20945, "ep_reward": 565.4268188476562, "reward": 0.7470775842666626, "action": 0.11134830117225647}
{"mode": "train", "epochs": 11, "timestep": 20946, "ep_reward": 566.2100830078125, "reward": 0.7832627296447754, "action": -0.2596777081489563}
{"mode": "train", "epochs": 11, "timestep": 20947, "ep_reward": 567.0140380859375, "reward": 0.8039566278457642, "action": -0.967107892036438}
{"mode": "train", "epochs": 11, "timestep": 20948, "ep_reward": 567.8258666992188, "reward": 0.8117989301681519, "action": -0.6447643041610718}
{"mode": "train", "epochs": 11, "timestep": 20949, "ep_reward": 568.6338500976562, "reward": 0.8080063462257385, "action": 0.754881739616394}
{"mode": "train", "epochs": 11, "timestep": 20950, "ep_reward": 569.4205932617188, "reward": 0.7867187261581421, "action": 0.11707957088947296}
{"mode": "train", "epochs": 11, "timestep": 20951, "ep_reward": 570.1702880859375, "reward": 0.7496975660324097, "action": -0.16148406267166138}
{"mode": "train", "epochs": 11, "timestep": 20952, "ep_reward": 570.8682250976562, "reward": 0.6979422569274902, "action": 0.6900752782821655}
{"mode": "train", "epochs": 11, "timestep": 20953, "ep_reward": 571.4921264648438, "reward": 0.6239181756973267, "action": -0.47651857137680054}
{"mode": "train", "epochs": 11, "timestep": 20954, "ep_reward": 572.0350341796875, "reward": 0.5429224967956543, "action": 1.5692620277404785}
{"mode": "train", "epochs": 11, "timestep": 20955, "ep_reward": 572.46484375, "reward": 0.42981261014938354, "action": 0.8553414940834045}
{"mode": "train", "epochs": 11, "timestep": 20956, "ep_reward": 572.775390625, "reward": 0.31052547693252563, "action": 0.714617133140564}
{"mode": "train", "epochs": 11, "timestep": 20957, "ep_reward": 572.982421875, "reward": 0.20701032876968384, "action": 0.7542333602905273}
{"mode": "train", "epochs": 11, "timestep": 20958, "ep_reward": 573.2861328125, "reward": 0.3037302494049072, "action": -0.1464563012123108}
{"mode": "train", "epochs": 11, "timestep": 20959, "ep_reward": 573.6961059570312, "reward": 0.40994584560394287, "action": -0.7947209477424622}
{"mode": "train", "epochs": 11, "timestep": 20960, "ep_reward": 574.2122192382812, "reward": 0.5160998702049255, "action": 1.0291216373443604}
{"mode": "train", "epochs": 11, "timestep": 20961, "ep_reward": 574.8115844726562, "reward": 0.5993438363075256, "action": 1.0709969997406006}
{"mode": "train", "epochs": 11, "timestep": 20962, "ep_reward": 575.4852905273438, "reward": 0.6736826300621033, "action": 0.3110313415527344}
{"mode": "train", "epochs": 11, "timestep": 20963, "ep_reward": 576.225830078125, "reward": 0.7405411005020142, "action": 0.39555823802948}
{"mode": "train", "epochs": 11, "timestep": 20964, "ep_reward": 577.0182495117188, "reward": 0.7923895716667175, "action": 1.3650585412979126}
{"mode": "train", "epochs": 11, "timestep": 20965, "ep_reward": 577.846435546875, "reward": 0.8282070159912109, "action": 0.4986289143562317}
{"mode": "train", "epochs": 11, "timestep": 20966, "ep_reward": 578.7015380859375, "reward": 0.8551319241523743, "action": 0.9474833011627197}
{"mode": "train", "epochs": 11, "timestep": 20967, "ep_reward": 579.5713500976562, "reward": 0.8698387145996094, "action": 1.2915372848510742}
{"mode": "train", "epochs": 11, "timestep": 20968, "ep_reward": 580.4463500976562, "reward": 0.8749915361404419, "action": 1.014716625213623}
{"mode": "train", "epochs": 11, "timestep": 20969, "ep_reward": 581.3172607421875, "reward": 0.8709261417388916, "action": 1.1455718278884888}
{"mode": "train", "epochs": 11, "timestep": 20970, "ep_reward": 582.174560546875, "reward": 0.857319712638855, "action": 2.0}
{"mode": "train", "epochs": 11, "timestep": 20971, "ep_reward": 583.01220703125, "reward": 0.8376215100288391, "action": 1.410153865814209}
{"mode": "train", "epochs": 11, "timestep": 20972, "ep_reward": 583.8193359375, "reward": 0.8071075081825256, "action": 0.884449303150177}
{"mode": "train", "epochs": 11, "timestep": 20973, "ep_reward": 584.5819091796875, "reward": 0.7625607252120972, "action": 0.6972947120666504}
{"mode": "train", "epochs": 11, "timestep": 20974, "ep_reward": 585.2847900390625, "reward": 0.7029014825820923, "action": 1.8612420558929443}
{"mode": "train", "epochs": 11, "timestep": 20975, "ep_reward": 585.9243774414062, "reward": 0.6395743489265442, "action": 0.728746235370636}
{"mode": "train", "epochs": 11, "timestep": 20976, "ep_reward": 586.4807739257812, "reward": 0.556383490562439, "action": 1.1434173583984375}
{"mode": "train", "epochs": 11, "timestep": 20977, "ep_reward": 586.9480590820312, "reward": 0.46729201078414917, "action": 1.0179780721664429}
{"mode": "train", "epochs": 11, "timestep": 20978, "ep_reward": 587.3201293945312, "reward": 0.37204086780548096, "action": 0.6074200868606567}
{"mode": "train", "epochs": 11, "timestep": 20979, "ep_reward": 587.591552734375, "reward": 0.2714534401893616, "action": 1.5072733163833618}
{"mode": "train", "epochs": 11, "timestep": 20980, "ep_reward": 587.8807983398438, "reward": 0.2892674207687378, "action": 0.11718094348907471}
{"mode": "train", "epochs": 11, "timestep": 20981, "ep_reward": 588.2617797851562, "reward": 0.3810010552406311, "action": 0.6133919358253479}
{"mode": "train", "epochs": 11, "timestep": 20982, "ep_reward": 588.7353515625, "reward": 0.47359800338745117, "action": -0.020457416772842407}
{"mode": "train", "epochs": 11, "timestep": 20983, "ep_reward": 589.2904052734375, "reward": 0.5550739765167236, "action": -0.21291561424732208}
{"mode": "train", "epochs": 11, "timestep": 20984, "ep_reward": 589.9169921875, "reward": 0.6265976428985596, "action": -0.07241718471050262}
{"mode": "train", "epochs": 11, "timestep": 20985, "ep_reward": 590.6044921875, "reward": 0.6875176429748535, "action": 0.0437522828578949}
{"mode": "train", "epochs": 11, "timestep": 20986, "ep_reward": 591.3397216796875, "reward": 0.7352501153945923, "action": -1.2666279077529907}
{"mode": "train", "epochs": 11, "timestep": 20987, "ep_reward": 592.106689453125, "reward": 0.766986608505249, "action": -0.6317389607429504}
{"mode": "train", "epochs": 11, "timestep": 20988, "ep_reward": 592.895751953125, "reward": 0.7890567779541016, "action": -1.1989637613296509}
{"mode": "train", "epochs": 11, "timestep": 20989, "ep_reward": 593.6953125, "reward": 0.7995865345001221, "action": -0.3727991580963135}
{"mode": "train", "epochs": 11, "timestep": 20990, "ep_reward": 594.4937133789062, "reward": 0.798395037651062, "action": -1.0256807804107666}
{"mode": "train", "epochs": 11, "timestep": 20991, "ep_reward": 595.2796630859375, "reward": 0.7859588861465454, "action": -1.227142095565796}
{"mode": "train", "epochs": 11, "timestep": 20992, "ep_reward": 596.043212890625, "reward": 0.7635428309440613, "action": 0.059859465807676315}
{"mode": "train", "epochs": 11, "timestep": 20993, "ep_reward": 596.7667846679688, "reward": 0.7235493659973145, "action": -0.589909553527832}
{"mode": "train", "epochs": 11, "timestep": 20994, "ep_reward": 597.4390258789062, "reward": 0.6722270250320435, "action": 0.18883037567138672}
{"mode": "train", "epochs": 11, "timestep": 20995, "ep_reward": 598.0410766601562, "reward": 0.6020219326019287, "action": 0.4296128451824188}
{"mode": "train", "epochs": 11, "timestep": 20996, "ep_reward": 598.5562133789062, "reward": 0.5151486992835999, "action": 0.22735315561294556}
{"mode": "train", "epochs": 11, "timestep": 20997, "ep_reward": 598.9743041992188, "reward": 0.41809791326522827, "action": 0.34871625900268555}
{"mode": "train", "epochs": 11, "timestep": 20998, "ep_reward": 599.287109375, "reward": 0.31280517578125, "action": 0.20596343278884888}
{"mode": "train", "epochs": 11, "timestep": 20999, "ep_reward": 599.540283203125, "reward": 0.2531977891921997, "action": 1.1275320053100586}
{"mode": "train", "epochs": 11, "timestep": 21000, "ep_reward": 599.8792724609375, "reward": 0.33897286653518677, "action": 1.2022777795791626}
{"mode": "train", "epochs": 11, "timestep": 21001, "ep_reward": 600.3062133789062, "reward": 0.4269407391548157, "action": -0.9565410017967224}
{"mode": "train", "epochs": 11, "timestep": 21002, "ep_reward": 600.8344116210938, "reward": 0.5281704664230347, "action": 0.8330767154693604}
{"mode": "train", "epochs": 11, "timestep": 21003, "ep_reward": 601.4415893554688, "reward": 0.6071548461914062, "action": 0.5227276682853699}
{"mode": "train", "epochs": 11, "timestep": 21004, "ep_reward": 602.1201782226562, "reward": 0.6785624027252197, "action": 0.40192699432373047}
{"mode": "train", "epochs": 11, "timestep": 21005, "ep_reward": 602.8583374023438, "reward": 0.7381486892700195, "action": 0.29626744985580444}
{"mode": "train", "epochs": 11, "timestep": 21006, "ep_reward": 603.6426391601562, "reward": 0.7842714786529541, "action": 1.2416789531707764}
{"mode": "train", "epochs": 11, "timestep": 21007, "ep_reward": 604.457763671875, "reward": 0.8151068687438965, "action": 0.8310924768447876}
{"mode": "train", "epochs": 11, "timestep": 21008, "ep_reward": 605.2937622070312, "reward": 0.8359987735748291, "action": 0.3521791696548462}
{"mode": "train", "epochs": 11, "timestep": 21009, "ep_reward": 606.1389770507812, "reward": 0.8452291488647461, "action": 0.520608127117157}
{"mode": "train", "epochs": 11, "timestep": 21010, "ep_reward": 606.980712890625, "reward": 0.841727614402771, "action": 1.6251461505889893}
{"mode": "train", "epochs": 11, "timestep": 21011, "ep_reward": 607.8103637695312, "reward": 0.8296438455581665, "action": 0.640837550163269}
{"mode": "train", "epochs": 11, "timestep": 21012, "ep_reward": 608.61474609375, "reward": 0.8044025897979736, "action": 1.4275574684143066}
{"mode": "train", "epochs": 11, "timestep": 21013, "ep_reward": 609.3853759765625, "reward": 0.7706589102745056, "action": -0.08461672067642212}
{"mode": "train", "epochs": 11, "timestep": 21014, "ep_reward": 610.101318359375, "reward": 0.7159494161605835, "action": 0.8049355745315552}
{"mode": "train", "epochs": 11, "timestep": 21015, "ep_reward": 610.7528076171875, "reward": 0.6514967083930969, "action": 0.580365777015686}
{"mode": "train", "epochs": 11, "timestep": 21016, "ep_reward": 611.3251342773438, "reward": 0.5723477602005005, "action": 1.362639307975769}
{"mode": "train", "epochs": 11, "timestep": 21017, "ep_reward": 611.8154296875, "reward": 0.4902917742729187, "action": 1.2608163356781006}
{"mode": "train", "epochs": 11, "timestep": 21018, "ep_reward": 612.2180786132812, "reward": 0.40265023708343506, "action": 1.2958897352218628}
{"mode": "train", "epochs": 11, "timestep": 21019, "ep_reward": 612.5330810546875, "reward": 0.3150039315223694, "action": 1.3990428447723389}
{"mode": "train", "epochs": 11, "timestep": 21020, "ep_reward": 612.8114013671875, "reward": 0.2783384323120117, "action": 0.0058969855308532715}
{"mode": "train", "epochs": 11, "timestep": 21021, "ep_reward": 613.1751708984375, "reward": 0.36376839876174927, "action": 1.1160976886749268}
{"mode": "train", "epochs": 11, "timestep": 21022, "ep_reward": 613.6296997070312, "reward": 0.4545177221298218, "action": -0.09593768417835236}
{"mode": "train", "epochs": 11, "timestep": 21023, "ep_reward": 614.160888671875, "reward": 0.5311588048934937, "action": -0.41329532861709595}
{"mode": "train", "epochs": 11, "timestep": 21024, "ep_reward": 614.760009765625, "reward": 0.5991478562355042, "action": 0.2187749445438385}
{"mode": "train", "epochs": 11, "timestep": 21025, "ep_reward": 615.4202270507812, "reward": 0.6602240204811096, "action": -0.6128689050674438}
{"mode": "train", "epochs": 11, "timestep": 21026, "ep_reward": 616.1263427734375, "reward": 0.7061247229576111, "action": -0.48652657866477966}
{"mode": "train", "epochs": 11, "timestep": 21027, "ep_reward": 616.8673095703125, "reward": 0.7409692406654358, "action": -0.7808859944343567}
{"mode": "train", "epochs": 11, "timestep": 21028, "ep_reward": 617.6309204101562, "reward": 0.7635834217071533, "action": -0.30831378698349}
{"mode": "train", "epochs": 11, "timestep": 21029, "ep_reward": 618.4053344726562, "reward": 0.7744040489196777, "action": -0.604483962059021}
{"mode": "train", "epochs": 11, "timestep": 21030, "ep_reward": 619.1778564453125, "reward": 0.772552490234375, "action": -0.42534857988357544}
{"mode": "train", "epochs": 11, "timestep": 21031, "ep_reward": 619.9356689453125, "reward": 0.757828950881958, "action": -0.26771438121795654}
{"mode": "train", "epochs": 11, "timestep": 21032, "ep_reward": 620.6648559570312, "reward": 0.7291942834854126, "action": 0.3375089466571808}
{"mode": "train", "epochs": 11, "timestep": 21033, "ep_reward": 621.3477783203125, "reward": 0.6829108595848083, "action": 1.1283752918243408}
{"mode": "train", "epochs": 11, "timestep": 21034, "ep_reward": 621.9620971679688, "reward": 0.6143355369567871, "action": 0.5717834234237671}
{"mode": "train", "epochs": 11, "timestep": 21035, "ep_reward": 622.4940185546875, "reward": 0.5319458246231079, "action": 0.40045928955078125}
{"mode": "train", "epochs": 11, "timestep": 21036, "ep_reward": 622.931884765625, "reward": 0.43787258863449097, "action": 1.432702898979187}
{"mode": "train", "epochs": 11, "timestep": 21037, "ep_reward": 623.2556762695312, "reward": 0.32379239797592163, "action": 1.1388425827026367}
{"mode": "train", "epochs": 11, "timestep": 21038, "ep_reward": 623.4907836914062, "reward": 0.23508083820343018, "action": 1.405775785446167}
{"mode": "train", "epochs": 11, "timestep": 21039, "ep_reward": 623.8121337890625, "reward": 0.32133710384368896, "action": 1.222922921180725}
{"mode": "train", "epochs": 11, "timestep": 21040, "ep_reward": 624.2249145507812, "reward": 0.41275179386138916, "action": 0.04203540086746216}
{"mode": "train", "epochs": 11, "timestep": 21041, "ep_reward": 624.7369384765625, "reward": 0.5120196342468262, "action": 0.654872715473175}
{"mode": "train", "epochs": 11, "timestep": 21042, "ep_reward": 625.3358154296875, "reward": 0.5988675355911255, "action": 0.9643738865852356}
{"mode": "train", "epochs": 11, "timestep": 21043, "ep_reward": 626.0098266601562, "reward": 0.6739884614944458, "action": 0.7629101276397705}
{"mode": "train", "epochs": 11, "timestep": 21044, "ep_reward": 626.7485961914062, "reward": 0.7387493848800659, "action": 0.7371317148208618}
{"mode": "train", "epochs": 11, "timestep": 21045, "ep_reward": 627.5391845703125, "reward": 0.7906122803688049, "action": 1.2039885520935059}
{"mode": "train", "epochs": 11, "timestep": 21046, "ep_reward": 628.3677368164062, "reward": 0.828560471534729, "action": 0.7594125270843506}
{"mode": "train", "epochs": 11, "timestep": 21047, "ep_reward": 629.2243041992188, "reward": 0.8565868139266968, "action": 1.032830834388733}
{"mode": "train", "epochs": 11, "timestep": 21048, "ep_reward": 630.09765625, "reward": 0.8733664751052856, "action": 0.7002302408218384}
{"mode": "train", "epochs": 11, "timestep": 21049, "ep_reward": 630.9779052734375, "reward": 0.8802740573883057, "action": 0.8032813668251038}
{"mode": "train", "epochs": 11, "timestep": 21050, "ep_reward": 631.8546752929688, "reward": 0.8767580389976501, "action": 1.7319139242172241}
{"mode": "train", "epochs": 11, "timestep": 21051, "ep_reward": 632.720703125, "reward": 0.866030216217041, "action": 0.6142037510871887}
{"mode": "train", "epochs": 11, "timestep": 21052, "ep_reward": 633.5635986328125, "reward": 0.8429028987884521, "action": 1.054308295249939}
{"mode": "train", "epochs": 11, "timestep": 21053, "ep_reward": 634.3729248046875, "reward": 0.8093317151069641, "action": 2.0}
{"mode": "train", "epochs": 11, "timestep": 21054, "ep_reward": 635.14306640625, "reward": 0.7701542973518372, "action": 0.9236235618591309}
{"mode": "train", "epochs": 11, "timestep": 21055, "ep_reward": 635.8565063476562, "reward": 0.7134119272232056, "action": 1.2059745788574219}
{"mode": "train", "epochs": 11, "timestep": 21056, "ep_reward": 636.502197265625, "reward": 0.6456996202468872, "action": -0.10500001907348633}
{"mode": "train", "epochs": 11, "timestep": 21057, "ep_reward": 637.05517578125, "reward": 0.552959144115448, "action": 2.0}
{"mode": "train", "epochs": 11, "timestep": 21058, "ep_reward": 637.524658203125, "reward": 0.46951019763946533, "action": 1.6621190309524536}
{"mode": "train", "epochs": 11, "timestep": 21059, "ep_reward": 637.9049072265625, "reward": 0.3802276849746704, "action": 0.11848366260528564}
{"mode": "train", "epochs": 11, "timestep": 21060, "ep_reward": 638.1786499023438, "reward": 0.27371716499328613, "action": -0.878978431224823}
{"mode": "train", "epochs": 11, "timestep": 21061, "ep_reward": 638.4424438476562, "reward": 0.2638165354728699, "action": -1.0986219644546509}
{"mode": "train", "epochs": 11, "timestep": 21062, "ep_reward": 638.7974243164062, "reward": 0.35498666763305664, "action": -1.010872721672058}
{"mode": "train", "epochs": 11, "timestep": 21063, "ep_reward": 639.2460327148438, "reward": 0.4485952854156494, "action": -0.5823960304260254}
{"mode": "train", "epochs": 11, "timestep": 21064, "ep_reward": 639.7884521484375, "reward": 0.5424486398696899, "action": -1.2536534070968628}
{"mode": "train", "epochs": 11, "timestep": 21065, "ep_reward": 640.4124145507812, "reward": 0.6239484548568726, "action": -0.9463528394699097}
{"mode": "train", "epochs": 11, "timestep": 21066, "ep_reward": 641.110107421875, "reward": 0.6976938247680664, "action": -1.9777426719665527}
{"mode": "train", "epochs": 11, "timestep": 21067, "ep_reward": 641.8649291992188, "reward": 0.7548173069953918, "action": -0.5755992531776428}
{"mode": "train", "epochs": 11, "timestep": 21068, "ep_reward": 642.6728515625, "reward": 0.8079164028167725, "action": -0.6070911288261414}
{"mode": "train", "epochs": 11, "timestep": 21069, "ep_reward": 643.5202026367188, "reward": 0.8473622798919678, "action": -0.08549195528030396}
{"mode": "train", "epochs": 11, "timestep": 21070, "ep_reward": 644.3953247070312, "reward": 0.8751077055931091, "action": -1.1670653820037842}
{"mode": "train", "epochs": 11, "timestep": 21071, "ep_reward": 645.2847900390625, "reward": 0.8894819617271423, "action": -2.0}
{"mode": "train", "epochs": 11, "timestep": 21072, "ep_reward": 646.1810302734375, "reward": 0.8962544798851013, "action": -0.5186700224876404}
{"mode": "train", "epochs": 11, "timestep": 21073, "ep_reward": 647.0758666992188, "reward": 0.8948532938957214, "action": -1.805354356765747}
{"mode": "train", "epochs": 11, "timestep": 21074, "ep_reward": 647.962646484375, "reward": 0.8868055939674377, "action": -0.7587432861328125}
{"mode": "train", "epochs": 11, "timestep": 21075, "ep_reward": 648.8307495117188, "reward": 0.8681329488754272, "action": -0.6599361896514893}
{"mode": "train", "epochs": 11, "timestep": 21076, "ep_reward": 649.66845703125, "reward": 0.8377219438552856, "action": -0.6202002763748169}
{"mode": "train", "epochs": 11, "timestep": 21077, "ep_reward": 650.4624633789062, "reward": 0.7939941883087158, "action": 0.006194651126861572}
{"mode": "train", "epochs": 11, "timestep": 21078, "ep_reward": 651.1930541992188, "reward": 0.7305625677108765, "action": 0.11084040999412537}
{"mode": "train", "epochs": 11, "timestep": 21079, "ep_reward": 651.8404541015625, "reward": 0.6473987102508545, "action": 0.46337729692459106}
{"mode": "train", "epochs": 11, "timestep": 21080, "ep_reward": 652.3816528320312, "reward": 0.5412111282348633, "action": 0.9540473222732544}
{"mode": "train", "epochs": 11, "timestep": 21081, "ep_reward": 652.792236328125, "reward": 0.41060972213745117, "action": 0.4367976784706116}
{"mode": "train", "epochs": 11, "timestep": 21082, "ep_reward": 653.0645141601562, "reward": 0.27226001024246216, "action": -0.36258167028427124}
{"mode": "train", "epochs": 11, "timestep": 21083, "ep_reward": 653.2059326171875, "reward": 0.14139395952224731, "action": 0.5392528772354126}
{"mode": "train", "epochs": 11, "timestep": 21084, "ep_reward": 653.4509887695312, "reward": 0.24504101276397705, "action": -0.1459524780511856}
{"mode": "train", "epochs": 11, "timestep": 21085, "ep_reward": 653.8178100585938, "reward": 0.36683785915374756, "action": -0.843185305595398}
{"mode": "train", "epochs": 11, "timestep": 21086, "ep_reward": 654.308349609375, "reward": 0.4905276298522949, "action": 0.2426484227180481}
{"mode": "train", "epochs": 11, "timestep": 21087, "ep_reward": 654.9014892578125, "reward": 0.5931553840637207, "action": -0.1933186650276184}
{"mode": "train", "epochs": 11, "timestep": 21088, "ep_reward": 655.586669921875, "reward": 0.6851823329925537, "action": 1.5579783916473389}
{"mode": "train", "epochs": 11, "timestep": 21089, "ep_reward": 656.3372802734375, "reward": 0.7506141662597656, "action": 1.2625631093978882}
{"mode": "train", "epochs": 11, "timestep": 21090, "ep_reward": 657.1432495117188, "reward": 0.8059956431388855, "action": 0.3942776918411255}
{"mode": "train", "epochs": 11, "timestep": 21091, "ep_reward": 657.9957885742188, "reward": 0.8525497913360596, "action": 1.0749807357788086}
{"mode": "train", "epochs": 11, "timestep": 21092, "ep_reward": 658.8799438476562, "reward": 0.8841565251350403, "action": 1.1326911449432373}
{"mode": "train", "epochs": 11, "timestep": 21093, "ep_reward": 659.7862548828125, "reward": 0.9063085913658142, "action": 0.9650536179542542}
{"mode": "train", "epochs": 11, "timestep": 21094, "ep_reward": 660.7069702148438, "reward": 0.9206969738006592, "action": 1.0262395143508911}
{"mode": "train", "epochs": 11, "timestep": 21095, "ep_reward": 661.634765625, "reward": 0.9277763962745667, "action": 0.9526777267456055}
{"mode": "train", "epochs": 11, "timestep": 21096, "ep_reward": 662.5629272460938, "reward": 0.9281437397003174, "action": 0.9033469557762146}
{"mode": "train", "epochs": 11, "timestep": 21097, "ep_reward": 663.4844970703125, "reward": 0.9215426445007324, "action": 1.1284152269363403}
{"mode": "train", "epochs": 11, "timestep": 21098, "ep_reward": 664.3927001953125, "reward": 0.9081761240959167, "action": 1.1246825456619263}
{"mode": "train", "epochs": 11, "timestep": 21099, "ep_reward": 665.2796630859375, "reward": 0.8869755268096924, "action": 0.8045017123222351}
{"mode": "train", "epochs": 11, "timestep": 21100, "ep_reward": 666.1343383789062, "reward": 0.8547055721282959, "action": 0.6035386323928833}
{"mode": "train", "epochs": 11, "timestep": 21101, "ep_reward": 666.94287109375, "reward": 0.8085274696350098, "action": 1.8652024269104004}
{"mode": "train", "epochs": 11, "timestep": 21102, "ep_reward": 667.700439453125, "reward": 0.7575432658195496, "action": 1.260605812072754}
{"mode": "train", "epochs": 11, "timestep": 21103, "ep_reward": 668.3899536132812, "reward": 0.6895037889480591, "action": 1.0747747421264648}
{"mode": "train", "epochs": 11, "timestep": 21104, "ep_reward": 668.9955444335938, "reward": 0.605610728263855, "action": 0.7286882400512695}
{"mode": "train", "epochs": 11, "timestep": 21105, "ep_reward": 669.5, "reward": 0.5044711232185364, "action": 0.7785483598709106}
{"mode": "train", "epochs": 11, "timestep": 21106, "ep_reward": 669.8930053710938, "reward": 0.39302492141723633, "action": 0.3822947144508362}
{"mode": "train", "epochs": 11, "timestep": 21107, "ep_reward": 670.164306640625, "reward": 0.2713031768798828, "action": 0.5981230735778809}
{"mode": "train", "epochs": 11, "timestep": 21108, "ep_reward": 670.3487548828125, "reward": 0.18447226285934448, "action": 1.6045596599578857}
{"mode": "train", "epochs": 11, "timestep": 21109, "ep_reward": 670.6560668945312, "reward": 0.3073166608810425, "action": 0.43939363956451416}
{"mode": "train", "epochs": 11, "timestep": 21110, "ep_reward": 671.072509765625, "reward": 0.416420042514801, "action": 1.6435847282409668}
{"mode": "train", "epochs": 11, "timestep": 21111, "ep_reward": 671.6004638671875, "reward": 0.5279356241226196, "action": 0.831720769405365}
{"mode": "train", "epochs": 11, "timestep": 21112, "ep_reward": 672.2193603515625, "reward": 0.618868350982666, "action": 0.9995524883270264}
{"mode": "train", "epochs": 11, "timestep": 21113, "ep_reward": 672.9136352539062, "reward": 0.6942758560180664, "action": 1.7205641269683838}
{"mode": "train", "epochs": 11, "timestep": 21114, "ep_reward": 673.6665649414062, "reward": 0.7529264688491821, "action": -0.1512942612171173}
{"mode": "train", "epochs": 11, "timestep": 21115, "ep_reward": 674.4530639648438, "reward": 0.7865151166915894, "action": -0.05773290991783142}
{"mode": "train", "epochs": 11, "timestep": 21116, "ep_reward": 675.2588500976562, "reward": 0.8057897686958313, "action": -0.30357491970062256}
{"mode": "train", "epochs": 11, "timestep": 21117, "ep_reward": 676.069580078125, "reward": 0.8107547163963318, "action": -1.0693039894104004}
{"mode": "train", "epochs": 11, "timestep": 21118, "ep_reward": 676.8738403320312, "reward": 0.804276704788208, "action": -0.05716906487941742}
{"mode": "train", "epochs": 11, "timestep": 21119, "ep_reward": 677.656982421875, "reward": 0.7831537127494812, "action": 0.3629908263683319}
{"mode": "train", "epochs": 11, "timestep": 21120, "ep_reward": 678.4013061523438, "reward": 0.7443405985832214, "action": 0.9278312921524048}
{"mode": "train", "epochs": 11, "timestep": 21121, "ep_reward": 679.0850830078125, "reward": 0.6837557554244995, "action": 1.0627846717834473}
{"mode": "train", "epochs": 11, "timestep": 21122, "ep_reward": 679.6865844726562, "reward": 0.6014729738235474, "action": 0.920677900314331}
{"mode": "train", "epochs": 11, "timestep": 21123, "ep_reward": 680.1875, "reward": 0.5008889436721802, "action": 0.87098628282547}
{"mode": "train", "epochs": 11, "timestep": 21124, "ep_reward": 680.5728759765625, "reward": 0.38539355993270874, "action": 0.9660219550132751}
{"mode": "train", "epochs": 11, "timestep": 21125, "ep_reward": 680.83203125, "reward": 0.2591499090194702, "action": 0.40995195508003235}
{"mode": "train", "epochs": 11, "timestep": 21126, "ep_reward": 681.0662841796875, "reward": 0.23423123359680176, "action": -0.08637407422065735}
{"mode": "train", "epochs": 11, "timestep": 21127, "ep_reward": 681.4067993164062, "reward": 0.3405299782752991, "action": -0.8045405149459839}
{"mode": "train", "epochs": 11, "timestep": 21128, "ep_reward": 681.8577880859375, "reward": 0.45096540451049805, "action": 0.8935394287109375}
{"mode": "train", "epochs": 11, "timestep": 21129, "ep_reward": 682.3990478515625, "reward": 0.5412678718566895, "action": 1.6031336784362793}
{"mode": "train", "epochs": 11, "timestep": 21130, "ep_reward": 683.0193481445312, "reward": 0.6202841997146606, "action": 0.4825019836425781}
{"mode": "train", "epochs": 11, "timestep": 21131, "ep_reward": 683.716796875, "reward": 0.6974561214447021, "action": 0.08549469709396362}
{"mode": "train", "epochs": 11, "timestep": 21132, "ep_reward": 684.4793090820312, "reward": 0.7625182867050171, "action": -0.24489480257034302}
{"mode": "train", "epochs": 11, "timestep": 21133, "ep_reward": 685.2920532226562, "reward": 0.8127235174179077, "action": 1.1364022493362427}
{"mode": "train", "epochs": 11, "timestep": 21134, "ep_reward": 686.1362915039062, "reward": 0.8442594408988953, "action": -0.1612473726272583}
{"mode": "train", "epochs": 11, "timestep": 21135, "ep_reward": 687.0026245117188, "reward": 0.8663447499275208, "action": 0.0736382007598877}
{"mode": "train", "epochs": 11, "timestep": 21136, "ep_reward": 687.8767700195312, "reward": 0.8741526007652283, "action": 0.7932529449462891}
{"mode": "train", "epochs": 11, "timestep": 21137, "ep_reward": 688.7471313476562, "reward": 0.870364248752594, "action": 0.7237507700920105}
{"mode": "train", "epochs": 11, "timestep": 21138, "ep_reward": 689.6027221679688, "reward": 0.8555681109428406, "action": 1.6325228214263916}
{"mode": "train", "epochs": 11, "timestep": 21139, "ep_reward": 690.43603515625, "reward": 0.8333356380462646, "action": 1.4294575452804565}
{"mode": "train", "epochs": 11, "timestep": 21140, "ep_reward": 691.2368774414062, "reward": 0.8008668422698975, "action": 1.2321932315826416}
{"mode": "train", "epochs": 11, "timestep": 21141, "ep_reward": 691.9932861328125, "reward": 0.7564252614974976, "action": 0.7749626636505127}
{"mode": "train", "epochs": 11, "timestep": 21142, "ep_reward": 692.6893310546875, "reward": 0.6960664391517639, "action": 1.9686038494110107}
{"mode": "train", "epochs": 11, "timestep": 21143, "ep_reward": 693.3221435546875, "reward": 0.6327944397926331, "action": 1.2481825351715088}
{"mode": "train", "epochs": 11, "timestep": 21144, "ep_reward": 693.8766479492188, "reward": 0.5544813871383667, "action": 1.0563167333602905}
{"mode": "train", "epochs": 11, "timestep": 21145, "ep_reward": 694.3426513671875, "reward": 0.46599531173706055, "action": 1.514157772064209}
{"mode": "train", "epochs": 11, "timestep": 21146, "ep_reward": 694.7207641601562, "reward": 0.37810975313186646, "action": 0.9776750206947327}
{"mode": "train", "epochs": 11, "timestep": 21147, "ep_reward": 695.006103515625, "reward": 0.2853128910064697, "action": 1.5142459869384766}
{"mode": "train", "epochs": 11, "timestep": 21148, "ep_reward": 695.3028564453125, "reward": 0.29675543308258057, "action": 0.3657223582267761}
{"mode": "train", "epochs": 11, "timestep": 21149, "ep_reward": 695.6887817382812, "reward": 0.3859531283378601, "action": -0.2015831619501114}
{"mode": "train", "epochs": 11, "timestep": 21150, "ep_reward": 696.1580200195312, "reward": 0.4692431092262268, "action": -0.1674952507019043}
{"mode": "train", "epochs": 11, "timestep": 21151, "ep_reward": 696.7060546875, "reward": 0.548038125038147, "action": -1.0453224182128906}
{"mode": "train", "epochs": 11, "timestep": 21152, "ep_reward": 697.321044921875, "reward": 0.6149981021881104, "action": -0.38923466205596924}
{"mode": "train", "epochs": 11, "timestep": 21153, "ep_reward": 697.9976806640625, "reward": 0.6766438484191895, "action": -1.1439634561538696}
{"mode": "train", "epochs": 11, "timestep": 21154, "ep_reward": 698.72216796875, "reward": 0.7244613170623779, "action": -1.1331695318222046}
{"mode": "train", "epochs": 11, "timestep": 21155, "ep_reward": 699.4844970703125, "reward": 0.7623502016067505, "action": -1.1384212970733643}
{"mode": "train", "epochs": 11, "timestep": 21156, "ep_reward": 700.2744140625, "reward": 0.789905846118927, "action": -1.0717799663543701}
{"mode": "train", "epochs": 11, "timestep": 21157, "ep_reward": 701.08154296875, "reward": 0.8071272373199463, "action": -0.9570395350456238}
{"mode": "train", "epochs": 11, "timestep": 21158, "ep_reward": 701.8953247070312, "reward": 0.8137621879577637, "action": -0.36884239315986633}
{"mode": "train", "epochs": 11, "timestep": 21159, "ep_reward": 702.703369140625, "reward": 0.8080270290374756, "action": -0.29394274950027466}
{"mode": "train", "epochs": 11, "timestep": 21160, "ep_reward": 703.4917602539062, "reward": 0.788361668586731, "action": -1.3526188135147095}
{"mode": "train", "epochs": 11, "timestep": 21161, "ep_reward": 704.2517700195312, "reward": 0.7599843740463257, "action": 0.03689735382795334}
{"mode": "train", "epochs": 11, "timestep": 21162, "ep_reward": 704.9645385742188, "reward": 0.7127426862716675, "action": 0.09301944077014923}
{"mode": "train", "epochs": 11, "timestep": 21163, "ep_reward": 705.6134643554688, "reward": 0.6489054560661316, "action": 0.570583701133728}
{"mode": "train", "epochs": 11, "timestep": 21164, "ep_reward": 706.178466796875, "reward": 0.5649949312210083, "action": 1.180999994277954}
{"mode": "train", "epochs": 11, "timestep": 21165, "ep_reward": 706.637451171875, "reward": 0.4589860439300537, "action": 0.5777443647384644}
{"mode": "train", "epochs": 11, "timestep": 21166, "ep_reward": 706.9832153320312, "reward": 0.3457896113395691, "action": 0.617301881313324}
{"mode": "train", "epochs": 11, "timestep": 21167, "ep_reward": 707.2096557617188, "reward": 0.22645336389541626, "action": 1.2145228385925293}
{"mode": "train", "epochs": 11, "timestep": 21168, "ep_reward": 707.486572265625, "reward": 0.2769455909729004, "action": -0.877679705619812}
{"mode": "train", "epochs": 11, "timestep": 21169, "ep_reward": 707.8748779296875, "reward": 0.3882966637611389, "action": 0.3040007948875427}
{"mode": "train", "epochs": 11, "timestep": 21170, "ep_reward": 708.360595703125, "reward": 0.48572486639022827, "action": -0.03262460231781006}
{"mode": "train", "epochs": 11, "timestep": 21171, "ep_reward": 708.9393310546875, "reward": 0.5787383913993835, "action": 1.570988416671753}
{"mode": "train", "epochs": 11, "timestep": 21172, "ep_reward": 709.5908813476562, "reward": 0.6515611410140991, "action": 0.5052580833435059}
{"mode": "train", "epochs": 11, "timestep": 21173, "ep_reward": 710.3117065429688, "reward": 0.7208224534988403, "action": 1.2499101161956787}
{"mode": "train", "epochs": 11, "timestep": 21174, "ep_reward": 711.08544921875, "reward": 0.7737170457839966, "action": 1.168760895729065}
{"mode": "train", "epochs": 11, "timestep": 21175, "ep_reward": 711.9012451171875, "reward": 0.8157732486724854, "action": 0.8170814514160156}
{"mode": "train", "epochs": 11, "timestep": 21176, "ep_reward": 712.748779296875, "reward": 0.8475198745727539, "action": 0.996317982673645}
{"mode": "train", "epochs": 11, "timestep": 21177, "ep_reward": 713.6166381835938, "reward": 0.8678750991821289, "action": 0.7173173427581787}
{"mode": "train", "epochs": 11, "timestep": 21178, "ep_reward": 714.4945678710938, "reward": 0.8779492378234863, "action": 2.0}
{"mode": "train", "epochs": 11, "timestep": 21179, "ep_reward": 715.3742065429688, "reward": 0.8796247243881226, "action": 1.7610245943069458}
{"mode": "train", "epochs": 11, "timestep": 21180, "ep_reward": 716.2488403320312, "reward": 0.874655544757843, "action": 1.0554718971252441}
{"mode": "train", "epochs": 11, "timestep": 21181, "ep_reward": 717.1090087890625, "reward": 0.8601605892181396, "action": 0.742345929145813}
{"mode": "train", "epochs": 11, "timestep": 21182, "ep_reward": 717.9429931640625, "reward": 0.8339756727218628, "action": 0.40993642807006836}
{"mode": "train", "epochs": 11, "timestep": 21183, "ep_reward": 718.7362060546875, "reward": 0.7931932210922241, "action": 0.9791248440742493}
{"mode": "train", "epochs": 11, "timestep": 21184, "ep_reward": 719.4776000976562, "reward": 0.7413731813430786, "action": 1.103253722190857}
{"mode": "train", "epochs": 11, "timestep": 21185, "ep_reward": 720.1546630859375, "reward": 0.6770545244216919, "action": 0.8978487253189087}
{"mode": "train", "epochs": 11, "timestep": 21186, "ep_reward": 720.7526245117188, "reward": 0.5979447364807129, "action": 0.9769360423088074}
{"mode": "train", "epochs": 11, "timestep": 21187, "ep_reward": 721.2604370117188, "reward": 0.507807731628418, "action": 1.175267219543457}
{"mode": "train", "epochs": 11, "timestep": 21188, "ep_reward": 721.6724853515625, "reward": 0.41205787658691406, "action": 0.7488367557525635}
{"mode": "train", "epochs": 11, "timestep": 21189, "ep_reward": 721.9812622070312, "reward": 0.308756947517395, "action": 0.4187576472759247}
{"mode": "train", "epochs": 11, "timestep": 21190, "ep_reward": 722.20654296875, "reward": 0.22529983520507812, "action": -0.16852407157421112}
{"mode": "train", "epochs": 11, "timestep": 21191, "ep_reward": 722.5286254882812, "reward": 0.3220577836036682, "action": 0.2160286009311676}
{"mode": "train", "epochs": 11, "timestep": 21192, "ep_reward": 722.9508056640625, "reward": 0.4222102761268616, "action": -0.6264323592185974}
{"mode": "train", "epochs": 11, "timestep": 21193, "ep_reward": 723.4630126953125, "reward": 0.5122312307357788, "action": -0.5124245882034302}
{"mode": "train", "epochs": 11, "timestep": 21194, "ep_reward": 724.0596313476562, "reward": 0.5966233611106873, "action": -1.6746900081634521}
{"mode": "train", "epochs": 11, "timestep": 21195, "ep_reward": 724.7246704101562, "reward": 0.6650623083114624, "action": -1.78102445602417}
{"mode": "train", "epochs": 11, "timestep": 21196, "ep_reward": 725.449462890625, "reward": 0.7248218059539795, "action": -0.9455854892730713}
{"mode": "train", "epochs": 11, "timestep": 21197, "ep_reward": 726.2279663085938, "reward": 0.7785118222236633, "action": -0.6968268752098083}
{"mode": "train", "epochs": 11, "timestep": 21198, "ep_reward": 727.0484619140625, "reward": 0.820522665977478, "action": -1.6975359916687012}
{"mode": "train", "epochs": 11, "timestep": 21199, "ep_reward": 727.8970947265625, "reward": 0.8486154079437256, "action": -1.2479796409606934}
{"mode": "train", "epochs": 11, "timestep": 21200, "ep_reward": 728.765869140625, "reward": 0.8688007593154907, "action": -0.7095202803611755}
{"mode": "train", "epochs": 11, "timestep": 21201, "ep_reward": 729.6455078125, "reward": 0.8796398043632507, "action": -1.4609646797180176}
{"mode": "train", "epochs": 11, "timestep": 21202, "ep_reward": 730.5267944335938, "reward": 0.8812720775604248, "action": -0.7833020687103271}
{"mode": "train", "epochs": 11, "timestep": 21203, "ep_reward": 731.400146484375, "reward": 0.8733744025230408, "action": -0.4195657968521118}
{"mode": "train", "epochs": 11, "timestep": 21204, "ep_reward": 732.2533569335938, "reward": 0.8531982898712158, "action": -2.0}
{"mode": "train", "epochs": 11, "timestep": 21205, "ep_reward": 733.0816650390625, "reward": 0.8282961845397949, "action": 0.289353609085083}
{"mode": "train", "epochs": 11, "timestep": 21206, "ep_reward": 733.86279296875, "reward": 0.7811412811279297, "action": 0.20707686245441437}
{"mode": "train", "epochs": 11, "timestep": 21207, "ep_reward": 734.5786743164062, "reward": 0.7159056663513184, "action": 0.5534504652023315}
{"mode": "train", "epochs": 11, "timestep": 21208, "ep_reward": 735.2067260742188, "reward": 0.6280743479728699, "action": 0.6778662204742432}
{"mode": "train", "epochs": 11, "timestep": 21209, "ep_reward": 735.7250366210938, "reward": 0.518307089805603, "action": 1.4430047273635864}
{"mode": "train", "epochs": 11, "timestep": 21210, "ep_reward": 736.10595703125, "reward": 0.3809278607368469, "action": -0.4580632150173187}
{"mode": "train", "epochs": 11, "timestep": 21211, "ep_reward": 736.36083984375, "reward": 0.2548542022705078, "action": -0.4237872362136841}
{"mode": "train", "epochs": 11, "timestep": 21212, "ep_reward": 736.531005859375, "reward": 0.17015743255615234, "action": -0.14938995242118835}
{"mode": "train", "epochs": 11, "timestep": 21213, "ep_reward": 736.8168334960938, "reward": 0.2858300805091858, "action": -0.9143413305282593}
{"mode": "train", "epochs": 11, "timestep": 21214, "ep_reward": 737.2251586914062, "reward": 0.40834611654281616, "action": -0.6304416060447693}
{"mode": "train", "epochs": 11, "timestep": 21215, "ep_reward": 737.7457885742188, "reward": 0.5206207036972046, "action": 0.2971958518028259}
{"mode": "train", "epochs": 11, "timestep": 21216, "ep_reward": 738.3600463867188, "reward": 0.6142326593399048, "action": -0.1894792914390564}
{"mode": "train", "epochs": 11, "timestep": 21217, "ep_reward": 739.057861328125, "reward": 0.6977862119674683, "action": 0.9081521034240723}
{"mode": "train", "epochs": 11, "timestep": 21218, "ep_reward": 739.8177490234375, "reward": 0.7598817348480225, "action": 0.45844316482543945}
{"mode": "train", "epochs": 11, "timestep": 21219, "ep_reward": 740.6284790039062, "reward": 0.8107149004936218, "action": 0.9027042388916016}
{"mode": "train", "epochs": 11, "timestep": 21220, "ep_reward": 741.47509765625, "reward": 0.8466327786445618, "action": 1.4977643489837646}
{"mode": "train", "epochs": 11, "timestep": 21221, "ep_reward": 742.3458862304688, "reward": 0.8707593679428101, "action": 0.39008718729019165}
{"mode": "train", "epochs": 11, "timestep": 21222, "ep_reward": 743.2327270507812, "reward": 0.8868283629417419, "action": 1.294960618019104}
{"mode": "train", "epochs": 11, "timestep": 21223, "ep_reward": 744.125244140625, "reward": 0.8925440907478333, "action": 0.502505898475647}
{"mode": "train", "epochs": 11, "timestep": 21224, "ep_reward": 745.0139770507812, "reward": 0.8887315988540649, "action": 1.1578598022460938}
{"mode": "train", "epochs": 11, "timestep": 21225, "ep_reward": 745.89013671875, "reward": 0.8761779069900513, "action": 0.7829784750938416}
{"mode": "train", "epochs": 11, "timestep": 21226, "ep_reward": 746.7427978515625, "reward": 0.8526455760002136, "action": 1.0743221044540405}
{"mode": "train", "epochs": 11, "timestep": 21227, "ep_reward": 747.5616455078125, "reward": 0.8188781142234802, "action": 1.2240612506866455}
{"mode": "train", "epochs": 11, "timestep": 21228, "ep_reward": 748.3358154296875, "reward": 0.7741501331329346, "action": 0.4399632215499878}
{"mode": "train", "epochs": 11, "timestep": 21229, "ep_reward": 749.0463256835938, "reward": 0.7104804515838623, "action": 1.0499911308288574}
{"mode": "train", "epochs": 11, "timestep": 21230, "ep_reward": 749.6825561523438, "reward": 0.6362273693084717, "action": 1.3304072618484497}
{"mode": "train", "epochs": 11, "timestep": 21231, "ep_reward": 750.2348022460938, "reward": 0.5522705316543579, "action": 0.5546563863754272}
{"mode": "train", "epochs": 11, "timestep": 21232, "ep_reward": 750.6852416992188, "reward": 0.4504671096801758, "action": 0.7004137635231018}
{"mode": "train", "epochs": 11, "timestep": 21233, "ep_reward": 751.0282592773438, "reward": 0.3430215120315552, "action": 0.8343839645385742}
{"mode": "train", "epochs": 11, "timestep": 21234, "ep_reward": 751.2645263671875, "reward": 0.2362382411956787, "action": 1.576406478881836}
{"mode": "train", "epochs": 11, "timestep": 21235, "ep_reward": 751.5466918945312, "reward": 0.28219491243362427, "action": -0.5083242654800415}
{"mode": "train", "epochs": 11, "timestep": 21236, "ep_reward": 751.9232788085938, "reward": 0.3765876889228821, "action": -1.1675763130187988}
{"mode": "train", "epochs": 11, "timestep": 21237, "ep_reward": 752.3893432617188, "reward": 0.4660419225692749, "action": -0.1546648144721985}
{"mode": "train", "epochs": 11, "timestep": 21238, "ep_reward": 752.9486083984375, "reward": 0.5592828989028931, "action": -1.2315850257873535}
{"mode": "train", "epochs": 11, "timestep": 21239, "ep_reward": 753.5850219726562, "reward": 0.6364278793334961, "action": -0.48392045497894287}
{"mode": "train", "epochs": 11, "timestep": 21240, "ep_reward": 754.2930297851562, "reward": 0.7079956531524658, "action": -0.7267533540725708}
{"mode": "train", "epochs": 11, "timestep": 21241, "ep_reward": 755.05810546875, "reward": 0.7650469541549683, "action": -1.3003852367401123}
{"mode": "train", "epochs": 11, "timestep": 21242, "ep_reward": 755.86572265625, "reward": 0.8076357841491699, "action": -0.8572394847869873}
{"mode": "train", "epochs": 11, "timestep": 21243, "ep_reward": 756.706298828125, "reward": 0.8405569791793823, "action": -0.45057934522628784}
{"mode": "train", "epochs": 11, "timestep": 21244, "ep_reward": 757.5686645507812, "reward": 0.8623909950256348, "action": -0.65012526512146}
{"mode": "train", "epochs": 11, "timestep": 21245, "ep_reward": 758.44091796875, "reward": 0.8722553253173828, "action": -0.2600213885307312}
{"mode": "train", "epochs": 11, "timestep": 21246, "ep_reward": 759.3110961914062, "reward": 0.8701828718185425, "action": -1.8987500667572021}
{"mode": "train", "epochs": 11, "timestep": 21247, "ep_reward": 760.171875, "reward": 0.8607556819915771, "action": -0.7314357161521912}
{"mode": "train", "epochs": 11, "timestep": 21248, "ep_reward": 761.0111694335938, "reward": 0.8392797708511353, "action": -1.5712194442749023}
{"mode": "train", "epochs": 11, "timestep": 21249, "ep_reward": 761.8213500976562, "reward": 0.8101882338523865, "action": -0.22088882327079773}
{"mode": "train", "epochs": 11, "timestep": 21250, "ep_reward": 762.583740234375, "reward": 0.7623897790908813, "action": -0.690158486366272}
{"mode": "train", "epochs": 11, "timestep": 21251, "ep_reward": 763.2857055664062, "reward": 0.7019834518432617, "action": -0.17407828569412231}
{"mode": "train", "epochs": 11, "timestep": 21252, "ep_reward": 763.9078979492188, "reward": 0.6221696138381958, "action": 0.9696376323699951}
{"mode": "train", "epochs": 11, "timestep": 21253, "ep_reward": 764.4220581054688, "reward": 0.514145016670227, "action": 1.6101281642913818}
{"mode": "train", "epochs": 11, "timestep": 21254, "ep_reward": 764.8021850585938, "reward": 0.3801504969596863, "action": -0.2093142867088318}
{"mode": "train", "epochs": 11, "timestep": 21255, "ep_reward": 765.05810546875, "reward": 0.2559483051300049, "action": 0.5455825328826904}
{"mode": "train", "epochs": 11, "timestep": 21256, "ep_reward": 765.2452392578125, "reward": 0.18710529804229736, "action": -0.4215282201766968}
{"mode": "train", "epochs": 11, "timestep": 21257, "ep_reward": 765.5493774414062, "reward": 0.30413109064102173, "action": -0.5952690839767456}
{"mode": "train", "epochs": 11, "timestep": 21258, "ep_reward": 765.9708251953125, "reward": 0.4214250445365906, "action": -0.9362329840660095}
{"mode": "train", "epochs": 11, "timestep": 21259, "ep_reward": 766.504638671875, "reward": 0.533837080001831, "action": 0.4398675560951233}
{"mode": "train", "epochs": 11, "timestep": 21260, "ep_reward": 767.1280517578125, "reward": 0.6234046220779419, "action": 0.4561552405357361}
{"mode": "train", "epochs": 11, "timestep": 21261, "ep_reward": 767.8286743164062, "reward": 0.7006500959396362, "action": 0.17157137393951416}
{"mode": "train", "epochs": 11, "timestep": 21262, "ep_reward": 768.5936279296875, "reward": 0.7649444341659546, "action": 1.5721502304077148}
{"mode": "train", "epochs": 11, "timestep": 21263, "ep_reward": 769.4031372070312, "reward": 0.8094841241836548, "action": 0.9566277861595154}
{"mode": "train", "epochs": 11, "timestep": 21264, "ep_reward": 770.2486572265625, "reward": 0.8455283641815186, "action": 1.4313759803771973}
{"mode": "train", "epochs": 11, "timestep": 21265, "ep_reward": 771.1187133789062, "reward": 0.87005615234375, "action": 0.4920690655708313}
{"mode": "train", "epochs": 11, "timestep": 21266, "ep_reward": 772.0048828125, "reward": 0.8861438035964966, "action": 1.8847057819366455}
{"mode": "train", "epochs": 11, "timestep": 21267, "ep_reward": 772.8975830078125, "reward": 0.8926984071731567, "action": 0.24505078792572021}
{"mode": "train", "epochs": 11, "timestep": 21268, "ep_reward": 773.787841796875, "reward": 0.8902590274810791, "action": 1.1191844940185547}
{"mode": "train", "epochs": 11, "timestep": 21269, "ep_reward": 774.66650390625, "reward": 0.8786675930023193, "action": 1.6134939193725586}
{"mode": "train", "epochs": 11, "timestep": 21270, "ep_reward": 775.5264282226562, "reward": 0.8599222898483276, "action": 0.9671944379806519}
{"mode": "train", "epochs": 11, "timestep": 21271, "ep_reward": 776.3556518554688, "reward": 0.8292087316513062, "action": 1.3798428773880005}
{"mode": "train", "epochs": 11, "timestep": 21272, "ep_reward": 777.1447143554688, "reward": 0.7890501618385315, "action": 1.4613425731658936}
{"mode": "train", "epochs": 11, "timestep": 21273, "ep_reward": 777.8826904296875, "reward": 0.737963080406189, "action": 0.9587108492851257}
{"mode": "train", "epochs": 11, "timestep": 21274, "ep_reward": 778.5534057617188, "reward": 0.6706972122192383, "action": 0.42707693576812744}
{"mode": "train", "epochs": 11, "timestep": 21275, "ep_reward": 779.137939453125, "reward": 0.5845158696174622, "action": 1.3385875225067139}
{"mode": "train", "epochs": 11, "timestep": 21276, "ep_reward": 779.6326293945312, "reward": 0.4947032928466797, "action": 1.3656575679779053}
{"mode": "train", "epochs": 11, "timestep": 21277, "ep_reward": 780.0316772460938, "reward": 0.39905446767807007, "action": 0.9798457622528076}
{"mode": "train", "epochs": 11, "timestep": 21278, "ep_reward": 780.3292236328125, "reward": 0.29757410287857056, "action": 0.29788047075271606}
{"mode": "train", "epochs": 11, "timestep": 21279, "ep_reward": 780.5634765625, "reward": 0.2342485785484314, "action": -0.16672928631305695}
{"mode": "train", "epochs": 11, "timestep": 21280, "ep_reward": 780.89501953125, "reward": 0.33154767751693726, "action": -0.09494459629058838}
{"mode": "train", "epochs": 11, "timestep": 21281, "ep_reward": 781.32470703125, "reward": 0.429704487323761, "action": -0.38802120089530945}
{"mode": "train", "epochs": 11, "timestep": 21282, "ep_reward": 781.8464965820312, "reward": 0.5217734575271606, "action": -0.9569388628005981}
{"mode": "train", "epochs": 11, "timestep": 21283, "ep_reward": 782.4496459960938, "reward": 0.6031632423400879, "action": -0.117550790309906}
{"mode": "train", "epochs": 11, "timestep": 21284, "ep_reward": 783.1295776367188, "reward": 0.6799278259277344, "action": -0.5684183835983276}
{"mode": "train", "epochs": 11, "timestep": 21285, "ep_reward": 783.8702392578125, "reward": 0.7406778335571289, "action": -1.3501309156417847}
{"mode": "train", "epochs": 11, "timestep": 21286, "ep_reward": 784.6563110351562, "reward": 0.7860616445541382, "action": -0.2936556339263916}
{"mode": "train", "epochs": 11, "timestep": 21287, "ep_reward": 785.4794311523438, "reward": 0.8230974674224854, "action": -0.6003167629241943}
{"mode": "train", "epochs": 11, "timestep": 21288, "ep_reward": 786.3255615234375, "reward": 0.8461475372314453, "action": -0.8627772331237793}
{"mode": "train", "epochs": 11, "timestep": 21289, "ep_reward": 787.1829223632812, "reward": 0.8573375940322876, "action": -1.152160882949829}
{"mode": "train", "epochs": 11, "timestep": 21290, "ep_reward": 788.0411987304688, "reward": 0.8582701683044434, "action": -1.6856112480163574}
{"mode": "train", "epochs": 11, "timestep": 21291, "ep_reward": 788.892333984375, "reward": 0.8511244058609009, "action": -1.2760347127914429}
{"mode": "train", "epochs": 11, "timestep": 21292, "ep_reward": 789.726806640625, "reward": 0.8344959616661072, "action": -0.11657357215881348}
{"mode": "train", "epochs": 11, "timestep": 21293, "ep_reward": 790.5288696289062, "reward": 0.8020344972610474, "action": -0.1080595850944519}
{"mode": "train", "epochs": 11, "timestep": 21294, "ep_reward": 791.2825927734375, "reward": 0.7537018060684204, "action": 0.7644882202148438}
{"mode": "train", "epochs": 11, "timestep": 21295, "ep_reward": 791.9640502929688, "reward": 0.6814862489700317, "action": -1.2697267532348633}
{"mode": "train", "epochs": 11, "timestep": 21296, "ep_reward": 792.5718994140625, "reward": 0.6078345775604248, "action": 0.5676007866859436}
{"mode": "train", "epochs": 11, "timestep": 21297, "ep_reward": 793.0761108398438, "reward": 0.5042136907577515, "action": -0.21040800213813782}
{"mode": "train", "epochs": 11, "timestep": 21298, "ep_reward": 793.4710693359375, "reward": 0.39496541023254395, "action": -0.5665374994277954}
{"mode": "train", "epochs": 11, "timestep": 21299, "ep_reward": 793.7554931640625, "reward": 0.2844383716583252, "action": -0.06251873075962067}
{"mode": "train", "epochs": 11, "timestep": 21300, "ep_reward": 793.9742431640625, "reward": 0.21874147653579712, "action": -0.37809494137763977}
{"mode": "train", "epochs": 11, "timestep": 21301, "ep_reward": 794.29931640625, "reward": 0.3251017928123474, "action": 0.09619995951652527}
{"mode": "train", "epochs": 11, "timestep": 21302, "ep_reward": 794.7260131835938, "reward": 0.4266940951347351, "action": -1.458207368850708}
{"mode": "train", "epochs": 11, "timestep": 21303, "ep_reward": 795.2603149414062, "reward": 0.5343253016471863, "action": 0.8761206865310669}
{"mode": "train", "epochs": 11, "timestep": 21304, "ep_reward": 795.8742065429688, "reward": 0.613872766494751, "action": 0.7239937782287598}
{"mode": "train", "epochs": 11, "timestep": 21305, "ep_reward": 796.5590209960938, "reward": 0.6848316192626953, "action": 0.731726348400116}
{"mode": "train", "epochs": 11, "timestep": 21306, "ep_reward": 797.3029174804688, "reward": 0.7438672780990601, "action": 1.0258084535598755}
{"mode": "train", "epochs": 11, "timestep": 21307, "ep_reward": 798.0924072265625, "reward": 0.7894933223724365, "action": 0.7451270818710327}
{"mode": "train", "epochs": 11, "timestep": 21308, "ep_reward": 798.9165649414062, "reward": 0.8241727948188782, "action": 0.547407865524292}
{"mode": "train", "epochs": 11, "timestep": 21309, "ep_reward": 799.7635498046875, "reward": 0.847000002861023, "action": 0.3636508584022522}
{"mode": "train", "epochs": 11, "timestep": 21310, "ep_reward": 800.6209716796875, "reward": 0.8574413657188416, "action": 1.3301455974578857}
{"mode": "train", "epochs": 11, "timestep": 21311, "ep_reward": 801.4781494140625, "reward": 0.8571861386299133, "action": 1.037817120552063}
{"mode": "train", "epochs": 11, "timestep": 21312, "ep_reward": 802.3251953125, "reward": 0.8470498919487, "action": 1.0369590520858765}
{"mode": "train", "epochs": 11, "timestep": 21313, "ep_reward": 803.1514282226562, "reward": 0.8262141942977905, "action": 2.0}
{"mode": "train", "epochs": 11, "timestep": 21314, "ep_reward": 803.9508666992188, "reward": 0.7994149923324585, "action": 0.6458508968353271}
{"mode": "train", "epochs": 11, "timestep": 21315, "ep_reward": 804.7067260742188, "reward": 0.7558754682540894, "action": 0.5360467433929443}
{"mode": "train", "epochs": 11, "timestep": 21316, "ep_reward": 805.4041137695312, "reward": 0.6974108219146729, "action": 0.14864188432693481}
{"mode": "train", "epochs": 11, "timestep": 21317, "ep_reward": 806.0248413085938, "reward": 0.6206983923912048, "action": 1.5869719982147217}
{"mode": "train", "epochs": 11, "timestep": 21318, "ep_reward": 806.5684814453125, "reward": 0.5436295866966248, "action": 1.3591233491897583}
{"mode": "train", "epochs": 11, "timestep": 21319, "ep_reward": 807.0263671875, "reward": 0.4579124450683594, "action": 0.4123949110507965}
{"mode": "train", "epochs": 11, "timestep": 21320, "ep_reward": 807.3844604492188, "reward": 0.35809624195098877, "action": 1.0594162940979004}
{"mode": "train", "epochs": 11, "timestep": 21321, "ep_reward": 807.6491088867188, "reward": 0.2646310329437256, "action": 0.05675323307514191}
{"mode": "train", "epochs": 11, "timestep": 21322, "ep_reward": 807.948974609375, "reward": 0.2998451590538025, "action": -1.2715981006622314}
{"mode": "train", "epochs": 11, "timestep": 21323, "ep_reward": 808.3330688476562, "reward": 0.38406801223754883, "action": -0.6742238402366638}
{"mode": "train", "epochs": 11, "timestep": 21324, "ep_reward": 808.806640625, "reward": 0.4735758900642395, "action": -0.9111039042472839}
{"mode": "train", "epochs": 11, "timestep": 21325, "ep_reward": 809.3642578125, "reward": 0.5575925707817078, "action": -0.6253716945648193}
{"mode": "train", "epochs": 11, "timestep": 21326, "ep_reward": 810.0003662109375, "reward": 0.6361289024353027, "action": 0.3845561742782593}
{"mode": "train", "epochs": 11, "timestep": 21327, "ep_reward": 810.7085571289062, "reward": 0.7081873416900635, "action": -0.27891790866851807}
{"mode": "train", "epochs": 11, "timestep": 21328, "ep_reward": 811.4700317382812, "reward": 0.7614693641662598, "action": -1.6109590530395508}
{"mode": "train", "epochs": 11, "timestep": 21329, "ep_reward": 812.26806640625, "reward": 0.7980316877365112, "action": -0.7679733037948608}
{"mode": "train", "epochs": 11, "timestep": 21330, "ep_reward": 813.094482421875, "reward": 0.8264339566230774, "action": -0.9192156791687012}
{"mode": "train", "epochs": 11, "timestep": 21331, "ep_reward": 813.9376220703125, "reward": 0.8431426882743835, "action": -0.803058385848999}
{"mode": "train", "epochs": 11, "timestep": 21332, "ep_reward": 814.7864990234375, "reward": 0.8488485813140869, "action": -1.4858582019805908}
{"mode": "train", "epochs": 11, "timestep": 21333, "ep_reward": 815.6316528320312, "reward": 0.8451825380325317, "action": -0.4540572762489319}
{"mode": "train", "epochs": 11, "timestep": 21334, "ep_reward": 816.4608154296875, "reward": 0.8291832208633423, "action": -0.9276684522628784}
{"mode": "train", "epochs": 11, "timestep": 21335, "ep_reward": 817.262939453125, "reward": 0.8021323680877686, "action": -1.1133924722671509}
{"mode": "train", "epochs": 11, "timestep": 21336, "ep_reward": 818.027099609375, "reward": 0.7641514539718628, "action": -0.02228546142578125}
{"mode": "train", "epochs": 11, "timestep": 21337, "ep_reward": 818.7333984375, "reward": 0.7062689065933228, "action": -0.9730284214019775}
{"mode": "train", "epochs": 11, "timestep": 21338, "ep_reward": 819.3732299804688, "reward": 0.639853835105896, "action": -0.5279173254966736}
{"mode": "train", "epochs": 11, "timestep": 21339, "ep_reward": 819.9305419921875, "reward": 0.5573385953903198, "action": -1.4016389846801758}
{"mode": "train", "epochs": 11, "timestep": 21340, "ep_reward": 820.4039306640625, "reward": 0.4733846187591553, "action": -0.16516049206256866}
{"mode": "train", "epochs": 11, "timestep": 21341, "ep_reward": 820.7755737304688, "reward": 0.37161785364151, "action": -0.3526759743690491}
{"mode": "train", "epochs": 11, "timestep": 21342, "ep_reward": 821.0443725585938, "reward": 0.26880156993865967, "action": -0.324481338262558}
{"mode": "train", "epochs": 11, "timestep": 21343, "ep_reward": 821.3284301757812, "reward": 0.28403282165527344, "action": 0.05963265895843506}
{"mode": "train", "epochs": 11, "timestep": 21344, "ep_reward": 821.7064208984375, "reward": 0.3779734969139099, "action": -0.8377771973609924}
{"mode": "train", "epochs": 11, "timestep": 21345, "ep_reward": 822.1823120117188, "reward": 0.47591620683670044, "action": -0.4047620892524719}
{"mode": "train", "epochs": 11, "timestep": 21346, "ep_reward": 822.74462890625, "reward": 0.5623043775558472, "action": 1.3979535102844238}
{"mode": "train", "epochs": 11, "timestep": 21347, "ep_reward": 823.3740234375, "reward": 0.6293880939483643, "action": 0.4178493618965149}
{"mode": "train", "epochs": 11, "timestep": 21348, "ep_reward": 824.0670166015625, "reward": 0.6930097341537476, "action": 0.6810564994812012}
{"mode": "train", "epochs": 11, "timestep": 21349, "ep_reward": 824.8104248046875, "reward": 0.7433940172195435, "action": 0.8130355477333069}
{"mode": "train", "epochs": 11, "timestep": 21350, "ep_reward": 825.5917358398438, "reward": 0.7812805771827698, "action": 1.4641141891479492}
{"mode": "train", "epochs": 11, "timestep": 21351, "ep_reward": 826.3987426757812, "reward": 0.8069790005683899, "action": 0.9931139945983887}
{"mode": "train", "epochs": 11, "timestep": 21352, "ep_reward": 827.2221069335938, "reward": 0.8233641386032104, "action": 1.138458490371704}
{"mode": "train", "epochs": 11, "timestep": 21353, "ep_reward": 828.0513305664062, "reward": 0.8292011022567749, "action": 1.2070293426513672}
{"mode": "train", "epochs": 11, "timestep": 21354, "ep_reward": 828.8763427734375, "reward": 0.8250188827514648, "action": 1.5077743530273438}
{"mode": "train", "epochs": 11, "timestep": 21355, "ep_reward": 829.6882934570312, "reward": 0.8119704127311707, "action": 0.05670386552810669}
{"mode": "train", "epochs": 11, "timestep": 21356, "ep_reward": 830.4712524414062, "reward": 0.782942533493042, "action": 1.0792700052261353}
{"mode": "train", "epochs": 11, "timestep": 21357, "ep_reward": 831.2155151367188, "reward": 0.7442641258239746, "action": 1.6542454957962036}
{"mode": "train", "epochs": 11, "timestep": 21358, "ep_reward": 831.9136352539062, "reward": 0.6980987787246704, "action": 0.8231654167175293}
{"mode": "train", "epochs": 11, "timestep": 21359, "ep_reward": 832.5497436523438, "reward": 0.6360799670219421, "action": 1.128965139389038}
{"mode": "train", "epochs": 11, "timestep": 21360, "ep_reward": 833.1154174804688, "reward": 0.5656470656394958, "action": 0.9191599488258362}
{"mode": "train", "epochs": 11, "timestep": 21361, "ep_reward": 833.6007080078125, "reward": 0.4853140711784363, "action": 1.5084643363952637}
{"mode": "train", "epochs": 11, "timestep": 21362, "ep_reward": 834.0069580078125, "reward": 0.4062618017196655, "action": 1.1390557289123535}
{"mode": "train", "epochs": 11, "timestep": 21363, "ep_reward": 834.3311767578125, "reward": 0.3242160677909851, "action": 0.10833403468132019}
{"mode": "train", "epochs": 11, "timestep": 21364, "ep_reward": 834.6236572265625, "reward": 0.29245221614837646, "action": -1.7463984489440918}
{"mode": "train", "epochs": 11, "timestep": 21365, "ep_reward": 834.9891357421875, "reward": 0.3654925227165222, "action": -0.8495528697967529}
{"mode": "train", "epochs": 11, "timestep": 21366, "ep_reward": 835.4362182617188, "reward": 0.44710439443588257, "action": -1.7988730669021606}
{"mode": "train", "epochs": 11, "timestep": 21367, "ep_reward": 835.957763671875, "reward": 0.5215442776679993, "action": -1.5296962261199951}
{"mode": "train", "epochs": 11, "timestep": 21368, "ep_reward": 836.5527954101562, "reward": 0.5950261354446411, "action": -1.2807936668395996}
{"mode": "train", "epochs": 11, "timestep": 21369, "ep_reward": 837.21630859375, "reward": 0.6634829044342041, "action": -1.5369725227355957}
{"mode": "train", "epochs": 11, "timestep": 21370, "ep_reward": 837.9381103515625, "reward": 0.7217767238616943, "action": -0.9867612719535828}
{"mode": "train", "epochs": 11, "timestep": 21371, "ep_reward": 838.7103881835938, "reward": 0.7722798585891724, "action": -1.4626500606536865}
{"mode": "train", "epochs": 11, "timestep": 21372, "ep_reward": 839.5205078125, "reward": 0.8101072311401367, "action": -0.6427433490753174}
{"mode": "train", "epochs": 11, "timestep": 21373, "ep_reward": 840.359619140625, "reward": 0.8390811085700989, "action": -2.0}
{"mode": "train", "epochs": 11, "timestep": 21374, "ep_reward": 841.2153930664062, "reward": 0.8557811975479126, "action": -2.0}
{"mode": "train", "epochs": 11, "timestep": 21375, "ep_reward": 842.0811767578125, "reward": 0.8658133745193481, "action": -0.4942851960659027}
{"mode": "train", "epochs": 11, "timestep": 21376, "ep_reward": 842.947998046875, "reward": 0.8667999505996704, "action": -1.9539109468460083}
{"mode": "train", "epochs": 11, "timestep": 21377, "ep_reward": 843.8082275390625, "reward": 0.8602392673492432, "action": -0.09222090244293213}
{"mode": "train", "epochs": 11, "timestep": 21378, "ep_reward": 844.64794921875, "reward": 0.8397282361984253, "action": -0.9059764742851257}
{"mode": "train", "epochs": 11, "timestep": 21379, "ep_reward": 845.4566040039062, "reward": 0.8086735010147095, "action": -1.1083061695098877}
{"mode": "train", "epochs": 11, "timestep": 21380, "ep_reward": 846.2230834960938, "reward": 0.7664961814880371, "action": 0.6225171089172363}
{"mode": "train", "epochs": 11, "timestep": 21381, "ep_reward": 846.9214477539062, "reward": 0.6983911991119385, "action": 0.6996612548828125}
{"mode": "train", "epochs": 11, "timestep": 21382, "ep_reward": 847.5302124023438, "reward": 0.6087871789932251, "action": 0.6638374924659729}
{"mode": "train", "epochs": 11, "timestep": 21383, "ep_reward": 848.0297241210938, "reward": 0.4994971752166748, "action": 0.6854564547538757}
{"mode": "train", "epochs": 11, "timestep": 21384, "ep_reward": 848.4033813476562, "reward": 0.37367165088653564, "action": 0.6320052742958069}
{"mode": "train", "epochs": 11, "timestep": 21385, "ep_reward": 848.6417846679688, "reward": 0.23840844631195068, "action": 1.4548711776733398}
{"mode": "train", "epochs": 11, "timestep": 21386, "ep_reward": 848.8255615234375, "reward": 0.18380272388458252, "action": 0.62172931432724}
{"mode": "train", "epochs": 11, "timestep": 21387, "ep_reward": 849.1214599609375, "reward": 0.29587626457214355, "action": 0.020479649305343628}
{"mode": "train", "epochs": 11, "timestep": 21388, "ep_reward": 849.5364990234375, "reward": 0.41502541303634644, "action": -0.8729771375656128}
{"mode": "train", "epochs": 11, "timestep": 21389, "ep_reward": 850.0719604492188, "reward": 0.5354458093643188, "action": 0.8277788758277893}
{"mode": "train", "epochs": 11, "timestep": 21390, "ep_reward": 850.700439453125, "reward": 0.628481388092041, "action": 1.1611523628234863}
{"mode": "train", "epochs": 11, "timestep": 21391, "ep_reward": 851.4075317382812, "reward": 0.7070826888084412, "action": 0.7669764757156372}
{"mode": "train", "epochs": 11, "timestep": 21392, "ep_reward": 852.182373046875, "reward": 0.7748315930366516, "action": 0.8609462380409241}
{"mode": "train", "epochs": 11, "timestep": 21393, "ep_reward": 853.0101318359375, "reward": 0.8277616500854492, "action": 1.5907917022705078}
{"mode": "train", "epochs": 11, "timestep": 21394, "ep_reward": 853.875732421875, "reward": 0.8656076192855835, "action": 0.7697138786315918}
{"mode": "train", "epochs": 11, "timestep": 21395, "ep_reward": 854.7722778320312, "reward": 0.8965240716934204, "action": 1.1970689296722412}
{"mode": "train", "epochs": 11, "timestep": 21396, "ep_reward": 855.6893920898438, "reward": 0.9171439409255981, "action": 0.5135039687156677}
{"mode": "train", "epochs": 11, "timestep": 21397, "ep_reward": 856.62060546875, "reward": 0.9311857223510742, "action": 1.002387523651123}
{"mode": "train", "epochs": 11, "timestep": 21398, "ep_reward": 857.5581665039062, "reward": 0.9375348091125488, "action": 0.939689576625824}
{"mode": "train", "epochs": 11, "timestep": 21399, "ep_reward": 858.4960327148438, "reward": 0.9378799200057983, "action": 1.0182660818099976}
{"mode": "train", "epochs": 11, "timestep": 21400, "ep_reward": 859.4282836914062, "reward": 0.9322208762168884, "action": 1.649188756942749}
{"mode": "train", "epochs": 11, "timestep": 21401, "ep_reward": 860.3505249023438, "reward": 0.922256588935852, "action": 1.06373131275177}
{"mode": "train", "epochs": 11, "timestep": 21402, "ep_reward": 861.2550048828125, "reward": 0.9044579863548279, "action": 1.715792179107666}
{"mode": "train", "epochs": 11, "timestep": 21403, "ep_reward": 862.1365966796875, "reward": 0.8815614581108093, "action": 1.2940465211868286}
{"mode": "train", "epochs": 11, "timestep": 21404, "ep_reward": 862.9849243164062, "reward": 0.8483402729034424, "action": -0.023926496505737305}
{"mode": "train", "epochs": 11, "timestep": 21405, "ep_reward": 863.779541015625, "reward": 0.7945895195007324, "action": 0.3269944190979004}
{"mode": "train", "epochs": 11, "timestep": 21406, "ep_reward": 864.5047607421875, "reward": 0.7252480387687683, "action": 1.4312564134597778}
{"mode": "train", "epochs": 11, "timestep": 21407, "ep_reward": 865.1533813476562, "reward": 0.648635983467102, "action": 0.6842265129089355}
{"mode": "train", "epochs": 11, "timestep": 21408, "ep_reward": 865.7032470703125, "reward": 0.5498939752578735, "action": 1.0297261476516724}
{"mode": "train", "epochs": 11, "timestep": 21409, "ep_reward": 866.1447143554688, "reward": 0.44145137071609497, "action": 0.5398200750350952}
{"mode": "train", "epochs": 11, "timestep": 21410, "ep_reward": 866.4635009765625, "reward": 0.3188167214393616, "action": 1.3724652528762817}
{"mode": "train", "epochs": 11, "timestep": 21411, "ep_reward": 866.669189453125, "reward": 0.20569437742233276, "action": 0.4292950928211212}
{"mode": "train", "epochs": 11, "timestep": 21412, "ep_reward": 866.9044799804688, "reward": 0.23529893159866333, "action": -0.27359285950660706}
{"mode": "train", "epochs": 11, "timestep": 21413, "ep_reward": 867.2493896484375, "reward": 0.3448861837387085, "action": -1.2025489807128906}
{"mode": "train", "epochs": 11, "timestep": 21414, "ep_reward": 867.695556640625, "reward": 0.44615596532821655, "action": -0.11663585901260376}
{"mode": "train", "epochs": 11, "timestep": 21415, "ep_reward": 868.2481689453125, "reward": 0.5526044964790344, "action": -1.0466111898422241}
{"mode": "train", "epochs": 11, "timestep": 21416, "ep_reward": 868.8890380859375, "reward": 0.6408878564834595, "action": -1.189513087272644}
{"mode": "train", "epochs": 11, "timestep": 21417, "ep_reward": 869.6056518554688, "reward": 0.7166385054588318, "action": -0.40723589062690735}
{"mode": "train", "epochs": 11, "timestep": 21418, "ep_reward": 870.3892211914062, "reward": 0.7835686802864075, "action": -0.992241382598877}
{"mode": "train", "epochs": 11, "timestep": 21419, "ep_reward": 871.2221069335938, "reward": 0.832865834236145, "action": -1.2305374145507812}
{"mode": "train", "epochs": 11, "timestep": 21420, "ep_reward": 872.0916137695312, "reward": 0.869522213935852, "action": -0.8428075313568115}
{"mode": "train", "epochs": 11, "timestep": 21421, "ep_reward": 872.98876953125, "reward": 0.897168755531311, "action": -1.575271725654602}
{"mode": "train", "epochs": 11, "timestep": 21422, "ep_reward": 873.9035034179688, "reward": 0.9147205948829651, "action": -1.1553518772125244}
{"mode": "train", "epochs": 11, "timestep": 21423, "ep_reward": 874.829833984375, "reward": 0.9263001680374146, "action": -1.4876521825790405}
{"mode": "train", "epochs": 11, "timestep": 21424, "ep_reward": 875.7616577148438, "reward": 0.9318076372146606, "action": -0.4226773977279663}
{"mode": "train", "epochs": 11, "timestep": 21425, "ep_reward": 876.6924438476562, "reward": 0.9307922124862671, "action": 0.0047743916511535645}
{"mode": "train", "epochs": 11, "timestep": 21426, "ep_reward": 877.6128540039062, "reward": 0.9203812479972839, "action": -0.47117936611175537}
{"mode": "train", "epochs": 11, "timestep": 21427, "ep_reward": 878.5139770507812, "reward": 0.9011205434799194, "action": -1.1881470680236816}
{"mode": "train", "epochs": 11, "timestep": 21428, "ep_reward": 879.388916015625, "reward": 0.874940037727356, "action": -1.177186131477356}
{"mode": "train", "epochs": 11, "timestep": 21429, "ep_reward": 880.2277221679688, "reward": 0.8388304114341736, "action": 0.07092386484146118}
{"mode": "train", "epochs": 11, "timestep": 21430, "ep_reward": 881.0092163085938, "reward": 0.7814980745315552, "action": -0.022787868976593018}
{"mode": "train", "epochs": 11, "timestep": 21431, "ep_reward": 881.7150268554688, "reward": 0.7058053016662598, "action": -0.2034963071346283}
{"mode": "train", "epochs": 11, "timestep": 21432, "ep_reward": 882.3267822265625, "reward": 0.6117526292800903, "action": -0.24079997837543488}
{"mode": "train", "epochs": 11, "timestep": 21433, "ep_reward": 882.8261108398438, "reward": 0.4993457794189453, "action": -0.3888886570930481}
{"mode": "train", "epochs": 11, "timestep": 21434, "ep_reward": 883.2001342773438, "reward": 0.3740085959434509, "action": 0.10869845747947693}
{"mode": "train", "epochs": 11, "timestep": 21435, "ep_reward": 883.4339599609375, "reward": 0.23382598161697388, "action": -0.661902129650116}
{"mode": "train", "epochs": 11, "timestep": 21436, "ep_reward": 883.580078125, "reward": 0.14611709117889404, "action": -0.5647777318954468}
{"mode": "train", "epochs": 11, "timestep": 21437, "ep_reward": 883.8515014648438, "reward": 0.27139413356781006, "action": -0.5944458246231079}
{"mode": "train", "epochs": 11, "timestep": 21438, "ep_reward": 884.2477416992188, "reward": 0.3962441086769104, "action": -1.0552961826324463}
{"mode": "train", "epochs": 11, "timestep": 21439, "ep_reward": 884.7655639648438, "reward": 0.5178099870681763, "action": -1.1953473091125488}
{"mode": "train", "epochs": 11, "timestep": 21440, "ep_reward": 885.3909301757812, "reward": 0.6253893375396729, "action": 1.0466442108154297}
{"mode": "train", "epochs": 11, "timestep": 21441, "ep_reward": 886.091796875, "reward": 0.7008646726608276, "action": 0.919008195400238}
{"mode": "train", "epochs": 11, "timestep": 21442, "ep_reward": 886.8565063476562, "reward": 0.7647104263305664, "action": 0.32640939950942993}
{"mode": "train", "epochs": 11, "timestep": 21443, "ep_reward": 887.6741333007812, "reward": 0.8176131844520569, "action": 1.1202549934387207}
{"mode": "train", "epochs": 11, "timestep": 21444, "ep_reward": 888.5281982421875, "reward": 0.8540568351745605, "action": 1.4200154542922974}
{"mode": "train", "epochs": 11, "timestep": 21445, "ep_reward": 889.4078979492188, "reward": 0.8797117471694946, "action": 1.0423295497894287}
{"mode": "train", "epochs": 11, "timestep": 21446, "ep_reward": 890.3051147460938, "reward": 0.8972448706626892, "action": 1.6172618865966797}
{"mode": "train", "epochs": 11, "timestep": 21447, "ep_reward": 891.2115478515625, "reward": 0.9064573645591736, "action": 1.374540090560913}
{"mode": "train", "epochs": 11, "timestep": 21448, "ep_reward": 892.1205444335938, "reward": 0.9090182781219482, "action": 2.0}
{"mode": "train", "epochs": 11, "timestep": 21449, "ep_reward": 893.0267944335938, "reward": 0.9062421321868896, "action": 0.9268419742584229}
{"mode": "train", "epochs": 11, "timestep": 21450, "ep_reward": 893.9219970703125, "reward": 0.8952220678329468, "action": 0.01238173246383667}
{"mode": "train", "epochs": 11, "timestep": 21451, "ep_reward": 894.7930908203125, "reward": 0.871120810508728, "action": 1.0361721515655518}
{"mode": "train", "epochs": 11, "timestep": 21452, "ep_reward": 895.6317138671875, "reward": 0.8386340141296387, "action": 0.9169813394546509}
{"mode": "train", "epochs": 11, "timestep": 21453, "ep_reward": 896.4251708984375, "reward": 0.7934384346008301, "action": 0.9409769177436829}
{"mode": "train", "epochs": 11, "timestep": 21454, "ep_reward": 897.1597290039062, "reward": 0.7345336675643921, "action": 0.8688017129898071}
{"mode": "train", "epochs": 11, "timestep": 21455, "ep_reward": 897.8198852539062, "reward": 0.6601475477218628, "action": 0.9800260663032532}
{"mode": "train", "epochs": 11, "timestep": 21456, "ep_reward": 898.39208984375, "reward": 0.5722148418426514, "action": 0.36192578077316284}
{"mode": "train", "epochs": 11, "timestep": 21457, "ep_reward": 898.8569946289062, "reward": 0.4649108648300171, "action": -0.14614415168762207}
{"mode": "train", "epochs": 11, "timestep": 21458, "ep_reward": 899.19775390625, "reward": 0.34073710441589355, "action": 0.7041056156158447}
{"mode": "train", "epochs": 11, "timestep": 21459, "ep_reward": 899.4202880859375, "reward": 0.22250640392303467, "action": 1.0848720073699951}
{"mode": "train", "epochs": 11, "timestep": 21460, "ep_reward": 899.6581420898438, "reward": 0.2378373146057129, "action": 0.5142108798027039}
{"mode": "train", "epochs": 11, "timestep": 21461, "ep_reward": 900.0082397460938, "reward": 0.3500959873199463, "action": -0.44997888803482056}
{"mode": "train", "epochs": 11, "timestep": 21462, "ep_reward": 900.4603271484375, "reward": 0.45207417011260986, "action": 0.066181480884552}
{"mode": "train", "epochs": 11, "timestep": 21463, "ep_reward": 901.0131225585938, "reward": 0.552809476852417, "action": -0.06445199251174927}
{"mode": "train", "epochs": 11, "timestep": 21464, "ep_reward": 901.6544189453125, "reward": 0.6412805318832397, "action": -1.5768671035766602}
{"mode": "train", "epochs": 11, "timestep": 21465, "ep_reward": 902.3627319335938, "reward": 0.7082825899124146, "action": -0.05072146654129028}
{"mode": "train", "epochs": 11, "timestep": 21466, "ep_reward": 903.1343994140625, "reward": 0.7716666460037231, "action": -0.8243529796600342}
{"mode": "train", "epochs": 11, "timestep": 21467, "ep_reward": 903.9512939453125, "reward": 0.8168908357620239, "action": -0.7784143686294556}
{"mode": "train", "epochs": 11, "timestep": 21468, "ep_reward": 904.8010864257812, "reward": 0.8497934937477112, "action": -1.9075480699539185}
{"mode": "train", "epochs": 11, "timestep": 21469, "ep_reward": 905.6715087890625, "reward": 0.870442807674408, "action": -1.1073148250579834}
{"mode": "train", "epochs": 11, "timestep": 21470, "ep_reward": 906.5556640625, "reward": 0.8841800689697266, "action": -1.150195598602295}
{"mode": "train", "epochs": 11, "timestep": 21471, "ep_reward": 907.4447631835938, "reward": 0.8890834450721741, "action": -1.0412653684616089}
{"mode": "train", "epochs": 11, "timestep": 21472, "ep_reward": 908.3300170898438, "reward": 0.8852686882019043, "action": -0.698432981967926}
{"mode": "train", "epochs": 11, "timestep": 21473, "ep_reward": 909.2012329101562, "reward": 0.8711877465248108, "action": -0.6849277019500732}
{"mode": "train", "epochs": 11, "timestep": 21474, "ep_reward": 910.047119140625, "reward": 0.8458767533302307, "action": -0.3232395350933075}
{"mode": "train", "epochs": 11, "timestep": 21475, "ep_reward": 910.85302734375, "reward": 0.8059291839599609, "action": -0.46239426732063293}
{"mode": "train", "epochs": 11, "timestep": 21476, "ep_reward": 911.6045532226562, "reward": 0.7515078783035278, "action": 0.20718073844909668}
{"mode": "train", "epochs": 11, "timestep": 21477, "ep_reward": 912.2796020507812, "reward": 0.6750210523605347, "action": 0.7252892851829529}
{"mode": "train", "epochs": 11, "timestep": 21478, "ep_reward": 912.8532104492188, "reward": 0.5736029744148254, "action": 0.07719798386096954}
{"mode": "train", "epochs": 11, "timestep": 21479, "ep_reward": 913.3128051757812, "reward": 0.4596223831176758, "action": -0.41005608439445496}
{"mode": "train", "epochs": 11, "timestep": 21480, "ep_reward": 913.65234375, "reward": 0.33955180644989014, "action": -0.15692564845085144}
{"mode": "train", "epochs": 11, "timestep": 21481, "ep_reward": 913.8646850585938, "reward": 0.2123243808746338, "action": 0.17069262266159058}
{"mode": "train", "epochs": 11, "timestep": 21482, "ep_reward": 914.083740234375, "reward": 0.21902936697006226, "action": -0.8065441250801086}
{"mode": "train", "epochs": 11, "timestep": 21483, "ep_reward": 914.4240112304688, "reward": 0.340289831161499, "action": -0.6580512523651123}
{"mode": "train", "epochs": 11, "timestep": 21484, "ep_reward": 914.8803100585938, "reward": 0.4563007950782776, "action": -0.24884849786758423}
{"mode": "train", "epochs": 11, "timestep": 21485, "ep_reward": 915.4403076171875, "reward": 0.5600224733352661, "action": -0.5623576641082764}
{"mode": "train", "epochs": 11, "timestep": 21486, "ep_reward": 916.0931396484375, "reward": 0.6528220176696777, "action": 1.7583436965942383}
{"mode": "train", "epochs": 11, "timestep": 21487, "ep_reward": 916.8104248046875, "reward": 0.717259407043457, "action": 1.4744538068771362}
{"mode": "train", "epochs": 11, "timestep": 21488, "ep_reward": 917.583740234375, "reward": 0.773343026638031, "action": 0.8148601651191711}
{"mode": "train", "epochs": 11, "timestep": 21489, "ep_reward": 918.404541015625, "reward": 0.8208114504814148, "action": 0.8317818641662598}
{"mode": "train", "epochs": 11, "timestep": 21490, "ep_reward": 919.26025390625, "reward": 0.8557125329971313, "action": 1.713008999824524}
{"mode": "train", "epochs": 11, "timestep": 21491, "ep_reward": 920.1387329101562, "reward": 0.878467857837677, "action": 0.9282999634742737}
{"mode": "train", "epochs": 11, "timestep": 21492, "ep_reward": 921.0328369140625, "reward": 0.8941243886947632, "action": 1.229141116142273}
{"mode": "train", "epochs": 11, "timestep": 21493, "ep_reward": 921.9337768554688, "reward": 0.9009652733802795, "action": 1.0550470352172852}
{"mode": "train", "epochs": 11, "timestep": 21494, "ep_reward": 922.83349609375, "reward": 0.8997496366500854, "action": 1.49449622631073}
{"mode": "train", "epochs": 11, "timestep": 21495, "ep_reward": 923.7249755859375, "reward": 0.8914696574211121, "action": 0.9236283898353577}
{"mode": "train", "epochs": 11, "timestep": 21496, "ep_reward": 924.5985717773438, "reward": 0.8735958337783813, "action": 0.7797737121582031}
{"mode": "train", "epochs": 11, "timestep": 21497, "ep_reward": 925.4430541992188, "reward": 0.8444796204566956, "action": 1.5654549598693848}
{"mode": "train", "epochs": 11, "timestep": 21498, "ep_reward": 926.2508544921875, "reward": 0.8078176975250244, "action": 1.8565208911895752}
{"mode": "train", "epochs": 11, "timestep": 21499, "ep_reward": 927.0134887695312, "reward": 0.7626553773880005, "action": 1.1147606372833252}
{"mode": "train", "epochs": 11, "timestep": 21500, "ep_reward": 927.71435546875, "reward": 0.7008676528930664, "action": 1.0834966897964478}
{"mode": "train", "epochs": 11, "timestep": 21501, "ep_reward": 928.3397827148438, "reward": 0.6254453659057617, "action": 0.46224337816238403}
{"mode": "train", "epochs": 11, "timestep": 21502, "ep_reward": 928.8707275390625, "reward": 0.5309280753135681, "action": 1.3436627388000488}
{"mode": "train", "epochs": 11, "timestep": 21503, "ep_reward": 929.3057861328125, "reward": 0.4350872039794922, "action": 0.6520650386810303}
{"mode": "train", "epochs": 11, "timestep": 21504, "ep_reward": 929.6329345703125, "reward": 0.3271440863609314, "action": 0.6821725368499756}
{"mode": "train", "epochs": 11, "timestep": 21505, "ep_reward": 929.8523559570312, "reward": 0.2194303274154663, "action": -0.1509409099817276}
{"mode": "train", "epochs": 11, "timestep": 21506, "ep_reward": 930.1392211914062, "reward": 0.2868545651435852, "action": -0.12160739302635193}
{"mode": "train", "epochs": 11, "timestep": 21507, "ep_reward": 930.527587890625, "reward": 0.3883609175682068, "action": -1.364168643951416}
{"mode": "train", "epochs": 11, "timestep": 21508, "ep_reward": 931.00634765625, "reward": 0.478762149810791, "action": -0.12946343421936035}
{"mode": "train", "epochs": 11, "timestep": 21509, "ep_reward": 931.5807495117188, "reward": 0.5744071006774902, "action": 0.18439066410064697}
{"mode": "train", "epochs": 11, "timestep": 21510, "ep_reward": 932.2411499023438, "reward": 0.6603964567184448, "action": -1.4150464534759521}
{"mode": "train", "epochs": 11, "timestep": 21511, "ep_reward": 932.96484375, "reward": 0.7237199544906616, "action": -1.4892903566360474}
{"mode": "train", "epochs": 11, "timestep": 21512, "ep_reward": 933.7410888671875, "reward": 0.7762666940689087, "action": -1.3400088548660278}
{"mode": "train", "epochs": 11, "timestep": 21513, "ep_reward": 934.5599975585938, "reward": 0.8189095854759216, "action": -0.35497158765792847}
{"mode": "train", "epochs": 11, "timestep": 21514, "ep_reward": 935.4129028320312, "reward": 0.8529238700866699, "action": -1.5831977128982544}
{"mode": "train", "epochs": 11, "timestep": 21515, "ep_reward": 936.2861328125, "reward": 0.8732496500015259, "action": -0.2639985680580139}
{"mode": "train", "epochs": 11, "timestep": 21516, "ep_reward": 937.1715698242188, "reward": 0.8854074478149414, "action": -1.2550973892211914}
{"mode": "train", "epochs": 11, "timestep": 21517, "ep_reward": 938.058837890625, "reward": 0.8872607350349426, "action": -0.46076321601867676}
{"mode": "train", "epochs": 11, "timestep": 21518, "ep_reward": 938.9376220703125, "reward": 0.8787963390350342, "action": -0.8288591504096985}
{"mode": "train", "epochs": 11, "timestep": 21519, "ep_reward": 939.7977294921875, "reward": 0.8601317405700684, "action": -0.7110213041305542}
{"mode": "train", "epochs": 11, "timestep": 21520, "ep_reward": 940.6273803710938, "reward": 0.8296367526054382, "action": -0.41378253698349}
{"mode": "train", "epochs": 11, "timestep": 21521, "ep_reward": 941.4115600585938, "reward": 0.7841931581497192, "action": 0.3707183301448822}
{"mode": "train", "epochs": 11, "timestep": 21522, "ep_reward": 942.1283569335938, "reward": 0.7168228030204773, "action": 0.2976619005203247}
{"mode": "train", "epochs": 11, "timestep": 21523, "ep_reward": 942.7581787109375, "reward": 0.6298315525054932, "action": 0.09433946758508682}
{"mode": "train", "epochs": 11, "timestep": 21524, "ep_reward": 943.2837524414062, "reward": 0.5255893468856812, "action": -1.1158803701400757}
{"mode": "train", "epochs": 11, "timestep": 21525, "ep_reward": 943.7048950195312, "reward": 0.4211180806159973, "action": -0.27848029136657715}
{"mode": "train", "epochs": 11, "timestep": 21526, "ep_reward": 944.0057373046875, "reward": 0.30082446336746216, "action": -0.7942726612091064}
{"mode": "train", "epochs": 11, "timestep": 21527, "ep_reward": 944.1919555664062, "reward": 0.186226487159729, "action": -1.5550620555877686}
{"mode": "train", "epochs": 11, "timestep": 21528, "ep_reward": 944.4798583984375, "reward": 0.2879191040992737, "action": 0.21590843796730042}
{"mode": "train", "epochs": 11, "timestep": 21529, "ep_reward": 944.8707275390625, "reward": 0.3908432722091675, "action": -0.8253998160362244}
{"mode": "train", "epochs": 11, "timestep": 21530, "ep_reward": 945.3694458007812, "reward": 0.4987436532974243, "action": -0.08597078919410706}
{"mode": "train", "epochs": 11, "timestep": 21531, "ep_reward": 945.9602661132812, "reward": 0.5907905101776123, "action": 1.0319876670837402}
{"mode": "train", "epochs": 11, "timestep": 21532, "ep_reward": 946.6249389648438, "reward": 0.6646455526351929, "action": 1.4771876335144043}
{"mode": "train", "epochs": 11, "timestep": 21533, "ep_reward": 947.3510131835938, "reward": 0.7260992527008057, "action": 0.39814889430999756}
{"mode": "train", "epochs": 11, "timestep": 21534, "ep_reward": 948.1322021484375, "reward": 0.7811886072158813, "action": 1.067216157913208}
{"mode": "train", "epochs": 11, "timestep": 21535, "ep_reward": 948.9527587890625, "reward": 0.8205441236495972, "action": 0.9509761333465576}
{"mode": "train", "epochs": 11, "timestep": 21536, "ep_reward": 949.8015747070312, "reward": 0.8487993478775024, "action": 2.0}
{"mode": "train", "epochs": 11, "timestep": 21537, "ep_reward": 950.667724609375, "reward": 0.8661787509918213, "action": 0.5255275964736938}
{"mode": "train", "epochs": 11, "timestep": 21538, "ep_reward": 951.5437622070312, "reward": 0.8760435581207275, "action": 1.4774448871612549}
{"mode": "train", "epochs": 11, "timestep": 21539, "ep_reward": 952.420166015625, "reward": 0.8764020204544067, "action": 0.4112502932548523}
{"mode": "train", "epochs": 11, "timestep": 21540, "ep_reward": 953.2859497070312, "reward": 0.8658075928688049, "action": 0.8593586087226868}
{"mode": "train", "epochs": 11, "timestep": 21541, "ep_reward": 954.1305541992188, "reward": 0.8445876836776733, "action": 1.4310191869735718}
{"mode": "train", "epochs": 11, "timestep": 21542, "ep_reward": 954.9453125, "reward": 0.8147833943367004, "action": 1.384718656539917}
{"mode": "train", "epochs": 11, "timestep": 21543, "ep_reward": 955.7195434570312, "reward": 0.7742398977279663, "action": 1.0967332124710083}
{"mode": "train", "epochs": 11, "timestep": 21544, "ep_reward": 956.4395751953125, "reward": 0.7200244665145874, "action": 1.4247815608978271}
{"mode": "train", "epochs": 11, "timestep": 21545, "ep_reward": 957.095458984375, "reward": 0.6558741331100464, "action": 1.1845500469207764}
{"mode": "train", "epochs": 11, "timestep": 21546, "ep_reward": 957.6741333007812, "reward": 0.5786914825439453, "action": 0.8484160304069519}
{"mode": "train", "epochs": 11, "timestep": 21547, "ep_reward": 958.1625366210938, "reward": 0.48840808868408203, "action": 0.879091739654541}
{"mode": "train", "epochs": 11, "timestep": 21548, "ep_reward": 958.5540161132812, "reward": 0.39145660400390625, "action": 0.5415608882904053}
{"mode": "train", "epochs": 11, "timestep": 21549, "ep_reward": 958.8424682617188, "reward": 0.2884548306465149, "action": 0.1025768518447876}
{"mode": "train", "epochs": 11, "timestep": 21550, "ep_reward": 959.09716796875, "reward": 0.2546713948249817, "action": -0.3089478611946106}
{"mode": "train", "epochs": 11, "timestep": 21551, "ep_reward": 959.4464721679688, "reward": 0.3493090271949768, "action": -0.14947277307510376}
{"mode": "train", "epochs": 11, "timestep": 21552, "ep_reward": 959.8914184570312, "reward": 0.4449765086174011, "action": -1.7388720512390137}
{"mode": "train", "epochs": 11, "timestep": 21553, "ep_reward": 960.4176025390625, "reward": 0.5262017846107483, "action": -0.6608365178108215}
{"mode": "train", "epochs": 11, "timestep": 21554, "ep_reward": 961.0279541015625, "reward": 0.6103562116622925, "action": -0.9717692136764526}
{"mode": "train", "epochs": 11, "timestep": 21555, "ep_reward": 961.7106323242188, "reward": 0.6826557517051697, "action": -0.8220473527908325}
{"mode": "train", "epochs": 11, "timestep": 21556, "ep_reward": 962.4549560546875, "reward": 0.7443436980247498, "action": -0.8396084904670715}
{"mode": "train", "epochs": 11, "timestep": 21557, "ep_reward": 963.2483520507812, "reward": 0.7934105396270752, "action": -0.6283330917358398}
{"mode": "train", "epochs": 11, "timestep": 21558, "ep_reward": 964.0787963867188, "reward": 0.8304250240325928, "action": -1.6746656894683838}
{"mode": "train", "epochs": 11, "timestep": 21559, "ep_reward": 964.932861328125, "reward": 0.8540894985198975, "action": -0.9900264739990234}
{"mode": "train", "epochs": 11, "timestep": 21560, "ep_reward": 965.802490234375, "reward": 0.8696108460426331, "action": -1.7398879528045654}
{"mode": "train", "epochs": 11, "timestep": 21561, "ep_reward": 966.6786499023438, "reward": 0.8761535882949829, "action": -0.9279168248176575}
{"mode": "train", "epochs": 11, "timestep": 21562, "ep_reward": 967.552734375, "reward": 0.8740867376327515, "action": -0.8010479211807251}
{"mode": "train", "epochs": 11, "timestep": 21563, "ep_reward": 968.4144287109375, "reward": 0.8616713285446167, "action": -0.4308432340621948}
{"mode": "train", "epochs": 11, "timestep": 21564, "ep_reward": 969.2509155273438, "reward": 0.8365076780319214, "action": 0.7666071057319641}
{"mode": "train", "epochs": 11, "timestep": 21565, "ep_reward": 970.04150390625, "reward": 0.79056316614151, "action": 0.8653820753097534}
{"mode": "train", "epochs": 11, "timestep": 21566, "ep_reward": 970.7645874023438, "reward": 0.7230921983718872, "action": 0.13513338565826416}
{"mode": "train", "epochs": 11, "timestep": 21567, "ep_reward": 971.4043579101562, "reward": 0.6397755146026611, "action": 1.4675462245941162}
{"mode": "train", "epochs": 11, "timestep": 21568, "ep_reward": 971.927490234375, "reward": 0.5231069326400757, "action": 0.31261542439460754}
{"mode": "train", "epochs": 11, "timestep": 21569, "ep_reward": 972.325927734375, "reward": 0.39840954542160034, "action": 1.21933913230896}
{"mode": "train", "epochs": 11, "timestep": 21570, "ep_reward": 972.5762329101562, "reward": 0.250305712223053, "action": -0.04344841092824936}
{"mode": "train", "epochs": 11, "timestep": 21571, "ep_reward": 972.7217407226562, "reward": 0.14549994468688965, "action": 0.11407485604286194}
{"mode": "train", "epochs": 11, "timestep": 21572, "ep_reward": 972.9849853515625, "reward": 0.26323050260543823, "action": -1.2021489143371582}
{"mode": "train", "epochs": 11, "timestep": 21573, "ep_reward": 973.3794555664062, "reward": 0.39444124698638916, "action": -1.5398144721984863}
{"mode": "train", "epochs": 11, "timestep": 21574, "ep_reward": 973.8987426757812, "reward": 0.5192983150482178, "action": 0.4125245213508606}
{"mode": "train", "epochs": 11, "timestep": 21575, "ep_reward": 974.5126953125, "reward": 0.6139237880706787, "action": 1.8192460536956787}
{"mode": "train", "epochs": 11, "timestep": 21576, "ep_reward": 975.2003173828125, "reward": 0.687606930732727, "action": 0.5692721605300903}
{"mode": "train", "epochs": 11, "timestep": 21577, "ep_reward": 975.958251953125, "reward": 0.7579367160797119, "action": 1.0022262334823608}
{"mode": "train", "epochs": 11, "timestep": 21578, "ep_reward": 976.77001953125, "reward": 0.8117849826812744, "action": 0.43809235095977783}
{"mode": "train", "epochs": 11, "timestep": 21579, "ep_reward": 977.6248779296875, "reward": 0.854874312877655, "action": 1.5927999019622803}
{"mode": "train", "epochs": 11, "timestep": 21580, "ep_reward": 978.5076293945312, "reward": 0.8827505111694336, "action": 1.3181203603744507}
{"mode": "train", "epochs": 11, "timestep": 21581, "ep_reward": 979.410888671875, "reward": 0.9032849073410034, "action": 0.07028573751449585}
{"mode": "train", "epochs": 11, "timestep": 21582, "ep_reward": 980.32763671875, "reward": 0.9167265295982361, "action": 0.4026268720626831}
{"mode": "train", "epochs": 11, "timestep": 21583, "ep_reward": 981.2474975585938, "reward": 0.9198650121688843, "action": 1.0626474618911743}
{"mode": "train", "epochs": 11, "timestep": 21584, "ep_reward": 982.1627197265625, "reward": 0.9152191281318665, "action": 0.946986198425293}
{"mode": "train", "epochs": 11, "timestep": 21585, "ep_reward": 983.0654907226562, "reward": 0.9027557969093323, "action": 0.9886078834533691}
{"mode": "train", "epochs": 11, "timestep": 21586, "ep_reward": 983.9472045898438, "reward": 0.8817377090454102, "action": 0.9845731854438782}
{"mode": "train", "epochs": 11, "timestep": 21587, "ep_reward": 984.7979125976562, "reward": 0.8507153391838074, "action": 0.9898102879524231}
{"mode": "train", "epochs": 11, "timestep": 21588, "ep_reward": 985.6058959960938, "reward": 0.8079677820205688, "action": 1.3388309478759766}
{"mode": "train", "epochs": 11, "timestep": 21589, "ep_reward": 986.3604736328125, "reward": 0.7545681595802307, "action": 1.2317452430725098}
{"mode": "train", "epochs": 11, "timestep": 21590, "ep_reward": 987.0474853515625, "reward": 0.6869986057281494, "action": 0.9716042876243591}
{"mode": "train", "epochs": 11, "timestep": 21591, "ep_reward": 987.6505126953125, "reward": 0.6030067205429077, "action": 1.0108281373977661}
{"mode": "train", "epochs": 11, "timestep": 21592, "ep_reward": 988.1567993164062, "reward": 0.5062757730484009, "action": 0.24034756422042847}
{"mode": "train", "epochs": 11, "timestep": 21593, "ep_reward": 988.5472412109375, "reward": 0.3904455900192261, "action": 1.0482367277145386}
{"mode": "train", "epochs": 11, "timestep": 21594, "ep_reward": 988.8258056640625, "reward": 0.27856284379959106, "action": 1.6775825023651123}
{"mode": "train", "epochs": 11, "timestep": 21595, "ep_reward": 989.0293579101562, "reward": 0.20357972383499146, "action": 0.025805920362472534}
{"mode": "train", "epochs": 11, "timestep": 21596, "ep_reward": 989.3372802734375, "reward": 0.30792635679244995, "action": -0.6252518892288208}
{"mode": "train", "epochs": 11, "timestep": 21597, "ep_reward": 989.7451171875, "reward": 0.4078218340873718, "action": 0.5610625147819519}
{"mode": "train", "epochs": 11, "timestep": 21598, "ep_reward": 990.2592163085938, "reward": 0.514123797416687, "action": -0.5334982872009277}
{"mode": "train", "epochs": 11, "timestep": 21599, "ep_reward": 990.8616333007812, "reward": 0.6024297475814819, "action": -0.8706104755401611}
{"mode": "train", "epochs": 11, "timestep": 21600, "ep_reward": 991.539794921875, "reward": 0.6781529188156128, "action": -0.896410346031189}
{"mode": "train", "epochs": 11, "timestep": 21601, "ep_reward": 992.28173828125, "reward": 0.7419540882110596, "action": -1.1879056692123413}
{"mode": "train", "epochs": 11, "timestep": 21602, "ep_reward": 993.0740356445312, "reward": 0.7922807931900024, "action": -0.35502856969833374}
{"mode": "train", "epochs": 11, "timestep": 21603, "ep_reward": 993.9074096679688, "reward": 0.8333677053451538, "action": -0.396048903465271}
{"mode": "train", "epochs": 11, "timestep": 21604, "ep_reward": 994.76806640625, "reward": 0.8606268167495728, "action": -1.9377272129058838}
{"mode": "train", "epochs": 11, "timestep": 21605, "ep_reward": 995.6434936523438, "reward": 0.8754397034645081, "action": -1.349696397781372}
{"mode": "train", "epochs": 11, "timestep": 21606, "ep_reward": 996.52685546875, "reward": 0.8833417296409607, "action": -0.8248519897460938}
{"mode": "train", "epochs": 11, "timestep": 21607, "ep_reward": 997.4090576171875, "reward": 0.8822126388549805, "action": -0.9614696502685547}
{"mode": "train", "epochs": 11, "timestep": 21608, "ep_reward": 998.2805786132812, "reward": 0.8715051412582397, "action": -0.6534814834594727}
{"mode": "train", "epochs": 11, "timestep": 21609, "ep_reward": 999.1299438476562, "reward": 0.8493771553039551, "action": -0.8389208316802979}
{"mode": "train", "epochs": 11, "timestep": 21610, "ep_reward": 999.94580078125, "reward": 0.8158687949180603, "action": -1.1104133129119873}
{"mode": "train", "epochs": 11, "timestep": 21611, "ep_reward": 1000.7171630859375, "reward": 0.7713592648506165, "action": -0.10857118666172028}
{"mode": "train", "epochs": 11, "timestep": 21612, "ep_reward": 1001.4230346679688, "reward": 0.7058935165405273, "action": 1.1440759897232056}
{"mode": "train", "epochs": 11, "timestep": 21613, "ep_reward": 1002.03369140625, "reward": 0.6106568574905396, "action": 0.4094509184360504}
{"mode": "train", "epochs": 11, "timestep": 21614, "ep_reward": 1002.5343627929688, "reward": 0.5006959438323975, "action": 0.14583393931388855}
{"mode": "train", "epochs": 11, "timestep": 21615, "ep_reward": 1002.91259765625, "reward": 0.3782438635826111, "action": -1.3373390436172485}
{"mode": "train", "epochs": 11, "timestep": 21616, "ep_reward": 1003.1805419921875, "reward": 0.26794278621673584, "action": -0.6809240579605103}
{"mode": "train", "epochs": 11, "timestep": 21617, "ep_reward": 1003.378173828125, "reward": 0.19765537977218628, "action": 0.7838526964187622}
{"mode": "train", "epochs": 11, "timestep": 21618, "ep_reward": 1003.6776123046875, "reward": 0.2994658350944519, "action": -0.740992546081543}
{"mode": "train", "epochs": 11, "timestep": 21619, "ep_reward": 1004.0938720703125, "reward": 0.4162400960922241, "action": -0.9316422939300537}
{"mode": "train", "epochs": 11, "timestep": 21620, "ep_reward": 1004.620849609375, "reward": 0.5269864797592163, "action": 0.1298254430294037}
{"mode": "train", "epochs": 11, "timestep": 21621, "ep_reward": 1005.23828125, "reward": 0.617457389831543, "action": 1.739452600479126}
{"mode": "train", "epochs": 11, "timestep": 21622, "ep_reward": 1005.9247436523438, "reward": 0.6864362955093384, "action": 2.0}
{"mode": "train", "epochs": 11, "timestep": 21623, "ep_reward": 1006.669921875, "reward": 0.7452077865600586, "action": 0.299277126789093}
{"mode": "train", "epochs": 11, "timestep": 21624, "ep_reward": 1007.47119140625, "reward": 0.8012581467628479, "action": 1.5872997045516968}
{"mode": "train", "epochs": 11, "timestep": 21625, "ep_reward": 1008.3104248046875, "reward": 0.8392487168312073, "action": 0.3442046046257019}
{"mode": "train", "epochs": 11, "timestep": 21626, "ep_reward": 1009.1805419921875, "reward": 0.8701184391975403, "action": 1.3931668996810913}
{"mode": "train", "epochs": 11, "timestep": 21627, "ep_reward": 1010.0686645507812, "reward": 0.8881179094314575, "action": 0.5621773600578308}
{"mode": "train", "epochs": 11, "timestep": 21628, "ep_reward": 1010.966552734375, "reward": 0.897866427898407, "action": 1.4599982500076294}
{"mode": "train", "epochs": 11, "timestep": 21629, "ep_reward": 1011.8655395507812, "reward": 0.8989791870117188, "action": 0.6428964138031006}
{"mode": "train", "epochs": 11, "timestep": 21630, "ep_reward": 1012.75634765625, "reward": 0.8907912969589233, "action": 1.8666893243789673}
{"mode": "train", "epochs": 11, "timestep": 21631, "ep_reward": 1013.6331787109375, "reward": 0.8768287301063538, "action": 1.4631733894348145}
{"mode": "train", "epochs": 11, "timestep": 21632, "ep_reward": 1014.4871826171875, "reward": 0.8540282249450684, "action": 1.1134259700775146}
{"mode": "train", "epochs": 11, "timestep": 21633, "ep_reward": 1015.3070068359375, "reward": 0.8198233842849731, "action": 1.1563382148742676}
{"mode": "train", "epochs": 11, "timestep": 21634, "ep_reward": 1016.0809936523438, "reward": 0.7739698886871338, "action": 0.9645853638648987}
{"mode": "train", "epochs": 11, "timestep": 21635, "ep_reward": 1016.794677734375, "reward": 0.7136541604995728, "action": 0.8373539447784424}
{"mode": "train", "epochs": 11, "timestep": 21636, "ep_reward": 1017.4324951171875, "reward": 0.6377997398376465, "action": 2.0}
{"mode": "train", "epochs": 11, "timestep": 21637, "ep_reward": 1017.9931640625, "reward": 0.56064373254776, "action": 1.0645639896392822}
{"mode": "train", "epochs": 11, "timestep": 21638, "ep_reward": 1018.4595947265625, "reward": 0.46645092964172363, "action": 0.45951369404792786}
{"mode": "train", "epochs": 11, "timestep": 21639, "ep_reward": 1018.818603515625, "reward": 0.3589811325073242, "action": 1.2529067993164062}
{"mode": "train", "epochs": 11, "timestep": 21640, "ep_reward": 1019.0778198242188, "reward": 0.2592155933380127, "action": -0.3152737021446228}
{"mode": "train", "epochs": 11, "timestep": 21641, "ep_reward": 1019.3399047851562, "reward": 0.26209110021591187, "action": -1.035768985748291}
{"mode": "train", "epochs": 11, "timestep": 21642, "ep_reward": 1019.6951904296875, "reward": 0.35529792308807373, "action": -1.1192134618759155}
{"mode": "train", "epochs": 11, "timestep": 21643, "ep_reward": 1020.14453125, "reward": 0.4493643641471863, "action": -1.2932438850402832}
{"mode": "train", "epochs": 11, "timestep": 21644, "ep_reward": 1020.6842651367188, "reward": 0.5397584438323975, "action": -0.670169472694397}
{"mode": "train", "epochs": 11, "timestep": 21645, "ep_reward": 1021.3121948242188, "reward": 0.6279284358024597, "action": -0.7535474300384521}
{"mode": "train", "epochs": 11, "timestep": 21646, "ep_reward": 1022.0160522460938, "reward": 0.703880786895752, "action": -1.0251295566558838}
{"mode": "train", "epochs": 11, "timestep": 21647, "ep_reward": 1022.781494140625, "reward": 0.7654269337654114, "action": -0.9372417330741882}
{"mode": "train", "epochs": 11, "timestep": 21648, "ep_reward": 1023.5962524414062, "reward": 0.8147428035736084, "action": -1.1860315799713135}
{"mode": "train", "epochs": 11, "timestep": 21649, "ep_reward": 1024.4473876953125, "reward": 0.851109504699707, "action": -2.0}
{"mode": "train", "epochs": 11, "timestep": 21650, "ep_reward": 1025.323486328125, "reward": 0.8760817646980286, "action": -1.1149441003799438}
{"mode": "train", "epochs": 11, "timestep": 21651, "ep_reward": 1026.2186279296875, "reward": 0.8951740264892578, "action": 0.359649121761322}
{"mode": "train", "epochs": 11, "timestep": 21652, "ep_reward": 1027.1240234375, "reward": 0.9054341316223145, "action": -0.551094651222229}
{"mode": "train", "epochs": 11, "timestep": 21653, "ep_reward": 1028.0281982421875, "reward": 0.9041714668273926, "action": -0.36826151609420776}
{"mode": "train", "epochs": 11, "timestep": 21654, "ep_reward": 1028.920654296875, "reward": 0.8924369812011719, "action": -1.3392494916915894}
{"mode": "train", "epochs": 11, "timestep": 21655, "ep_reward": 1029.794189453125, "reward": 0.8735039830207825, "action": -0.2970007061958313}
{"mode": "train", "epochs": 11, "timestep": 21656, "ep_reward": 1030.63427734375, "reward": 0.840042769908905, "action": -0.29751768708229065}
{"mode": "train", "epochs": 11, "timestep": 21657, "ep_reward": 1031.42626953125, "reward": 0.7919409275054932, "action": -0.20806798338890076}
{"mode": "train", "epochs": 11, "timestep": 21658, "ep_reward": 1032.15283203125, "reward": 0.7265658974647522, "action": -0.6114020347595215}
{"mode": "train", "epochs": 11, "timestep": 21659, "ep_reward": 1032.7998046875, "reward": 0.6469645500183105, "action": -0.47076207399368286}
{"mode": "train", "epochs": 11, "timestep": 21660, "ep_reward": 1033.349609375, "reward": 0.5497678518295288, "action": -0.9043185710906982}
{"mode": "train", "epochs": 11, "timestep": 21661, "ep_reward": 1033.79345703125, "reward": 0.4439038038253784, "action": 0.6396324038505554}
{"mode": "train", "epochs": 11, "timestep": 21662, "ep_reward": 1034.1038818359375, "reward": 0.3104422688484192, "action": -0.2739986479282379}
{"mode": "train", "epochs": 11, "timestep": 21663, "ep_reward": 1034.2872314453125, "reward": 0.18333721160888672, "action": -0.1928831934928894}
{"mode": "train", "epochs": 11, "timestep": 21664, "ep_reward": 1034.5294189453125, "reward": 0.24215036630630493, "action": -0.9682574272155762}
{"mode": "train", "epochs": 11, "timestep": 21665, "ep_reward": 1034.89404296875, "reward": 0.3646790385246277, "action": -0.8781875371932983}
{"mode": "train", "epochs": 11, "timestep": 21666, "ep_reward": 1035.374755859375, "reward": 0.48066943883895874, "action": 0.41027963161468506}
{"mode": "train", "epochs": 11, "timestep": 21667, "ep_reward": 1035.9512939453125, "reward": 0.5765164494514465, "action": 0.5259188413619995}
{"mode": "train", "epochs": 11, "timestep": 21668, "ep_reward": 1036.6121826171875, "reward": 0.660886287689209, "action": 0.5557820796966553}
{"mode": "train", "epochs": 11, "timestep": 21669, "ep_reward": 1037.3441162109375, "reward": 0.7319895029067993, "action": 0.6733089089393616}
{"mode": "train", "epochs": 11, "timestep": 21670, "ep_reward": 1038.1324462890625, "reward": 0.7883610725402832, "action": 1.877642273902893}
{"mode": "train", "epochs": 11, "timestep": 21671, "ep_reward": 1038.960205078125, "reward": 0.8277432918548584, "action": 2.0}
{"mode": "train", "epochs": 11, "timestep": 21672, "ep_reward": 1039.818603515625, "reward": 0.8584161996841431, "action": 0.25559884309768677}
{"mode": "train", "epochs": 11, "timestep": 21673, "ep_reward": 1040.70263671875, "reward": 0.8840277791023254, "action": 0.8670741319656372}
{"mode": "train", "epochs": 11, "timestep": 21674, "ep_reward": 1041.6002197265625, "reward": 0.8975862860679626, "action": 0.9341640472412109}
{"mode": "train", "epochs": 11, "timestep": 21675, "ep_reward": 1042.502197265625, "reward": 0.9020060300827026, "action": 1.7473045587539673}
{"mode": "train", "epochs": 11, "timestep": 21676, "ep_reward": 1043.40185546875, "reward": 0.8996313810348511, "action": 0.5064547657966614}
{"mode": "train", "epochs": 11, "timestep": 21677, "ep_reward": 1044.289306640625, "reward": 0.8874118328094482, "action": 0.3348528742790222}
{"mode": "train", "epochs": 11, "timestep": 21678, "ep_reward": 1045.152587890625, "reward": 0.8632894158363342, "action": 0.8446592688560486}
{"mode": "train", "epochs": 11, "timestep": 21679, "ep_reward": 1045.9814453125, "reward": 0.828860878944397, "action": 0.32223135232925415}
{"mode": "train", "epochs": 11, "timestep": 21680, "ep_reward": 1046.7591552734375, "reward": 0.7777342796325684, "action": 1.694562554359436}
{"mode": "train", "epochs": 11, "timestep": 21681, "ep_reward": 1047.4808349609375, "reward": 0.7216355800628662, "action": -0.6489512920379639}
{"mode": "train", "epochs": 11, "timestep": 21682, "ep_reward": 1048.1123046875, "reward": 0.6315133571624756, "action": 1.0973116159439087}
{"mode": "train", "epochs": 11, "timestep": 21683, "ep_reward": 1048.6517333984375, "reward": 0.539383053779602, "action": 1.915233850479126}
{"mode": "train", "epochs": 11, "timestep": 21684, "ep_reward": 1049.0986328125, "reward": 0.4468846321105957, "action": 0.6101279854774475}
{"mode": "train", "epochs": 11, "timestep": 21685, "ep_reward": 1049.433837890625, "reward": 0.33524084091186523, "action": 1.0886938571929932}
{"mode": "train", "epochs": 11, "timestep": 21686, "ep_reward": 1049.6624755859375, "reward": 0.22868722677230835, "action": 0.24999794363975525}
{"mode": "train", "epochs": 11, "timestep": 21687, "ep_reward": 1049.928955078125, "reward": 0.2665165662765503, "action": -2.0}
{"mode": "train", "epochs": 11, "timestep": 21688, "ep_reward": 1050.2840576171875, "reward": 0.35505789518356323, "action": 0.4819251298904419}
{"mode": "train", "epochs": 11, "timestep": 21689, "ep_reward": 1050.7503662109375, "reward": 0.4663689136505127, "action": -0.7365004420280457}
{"mode": "train", "epochs": 11, "timestep": 21690, "ep_reward": 1051.310791015625, "reward": 0.5604063868522644, "action": -0.48254886269569397}
{"mode": "train", "epochs": 11, "timestep": 21691, "ep_reward": 1051.9578857421875, "reward": 0.6470518112182617, "action": -0.9064257740974426}
{"mode": "train", "epochs": 11, "timestep": 21692, "ep_reward": 1052.676513671875, "reward": 0.7186168432235718, "action": -0.6174095869064331}
{"mode": "train", "epochs": 11, "timestep": 21693, "ep_reward": 1053.4552001953125, "reward": 0.7786454558372498, "action": -1.056949496269226}
{"mode": "train", "epochs": 11, "timestep": 21694, "ep_reward": 1054.2786865234375, "reward": 0.8234883546829224, "action": -1.0849895477294922}
{"mode": "train", "epochs": 11, "timestep": 21695, "ep_reward": 1055.1356201171875, "reward": 0.8568888306617737, "action": -0.6853159666061401}
{"mode": "train", "epochs": 11, "timestep": 21696, "ep_reward": 1056.0159912109375, "reward": 0.8804308772087097, "action": -1.0388838052749634}
{"mode": "train", "epochs": 11, "timestep": 21697, "ep_reward": 1056.909423828125, "reward": 0.8934169411659241, "action": -0.7499535083770752}
{"mode": "train", "epochs": 11, "timestep": 21698, "ep_reward": 1057.8067626953125, "reward": 0.8973331451416016, "action": -1.2060359716415405}
{"mode": "train", "epochs": 11, "timestep": 21699, "ep_reward": 1058.6995849609375, "reward": 0.8927679061889648, "action": -1.1879018545150757}
{"mode": "train", "epochs": 11, "timestep": 21700, "ep_reward": 1059.5794677734375, "reward": 0.879938006401062, "action": -0.7420026063919067}
{"mode": "train", "epochs": 11, "timestep": 21701, "ep_reward": 1060.4354248046875, "reward": 0.8559569716453552, "action": -1.579869270324707}
{"mode": "train", "epochs": 11, "timestep": 21702, "ep_reward": 1061.26025390625, "reward": 0.8248676061630249, "action": -1.0085664987564087}
{"mode": "train", "epochs": 11, "timestep": 21703, "ep_reward": 1062.0401611328125, "reward": 0.7799076437950134, "action": -0.16591110825538635}
{"mode": "train", "epochs": 11, "timestep": 21704, "ep_reward": 1062.7548828125, "reward": 0.7147253751754761, "action": -0.47901755571365356}
{"mode": "train", "epochs": 11, "timestep": 21705, "ep_reward": 1063.3896484375, "reward": 0.6347665786743164, "action": 0.4748646318912506}
{"mode": "train", "epochs": 11, "timestep": 21706, "ep_reward": 1063.918212890625, "reward": 0.5286237001419067, "action": 0.8385838270187378}
{"mode": "train", "epochs": 11, "timestep": 21707, "ep_reward": 1064.31884765625, "reward": 0.4006810188293457, "action": 0.687325119972229}
{"mode": "train", "epochs": 11, "timestep": 21708, "ep_reward": 1064.58056640625, "reward": 0.26170414686203003, "action": 0.2276085615158081}
{"mode": "train", "epochs": 11, "timestep": 21709, "ep_reward": 1064.7318115234375, "reward": 0.15128785371780396, "action": -1.7504595518112183}
{"mode": "train", "epochs": 11, "timestep": 21710, "ep_reward": 1065.015625, "reward": 0.28386348485946655, "action": 0.35460352897644043}
{"mode": "train", "epochs": 11, "timestep": 21711, "ep_reward": 1065.40966796875, "reward": 0.3940742611885071, "action": -1.2952756881713867}
{"mode": "train", "epochs": 11, "timestep": 21712, "ep_reward": 1065.923828125, "reward": 0.5142149925231934, "action": 0.021547816693782806}
{"mode": "train", "epochs": 11, "timestep": 21713, "ep_reward": 1066.5343017578125, "reward": 0.6105304956436157, "action": 0.14395642280578613}
{"mode": "train", "epochs": 11, "timestep": 21714, "ep_reward": 1067.226806640625, "reward": 0.6925058960914612, "action": 0.5015432238578796}
{"mode": "train", "epochs": 11, "timestep": 21715, "ep_reward": 1067.9844970703125, "reward": 0.757653534412384, "action": 0.4364585280418396}
{"mode": "train", "epochs": 11, "timestep": 21716, "ep_reward": 1068.793212890625, "reward": 0.808752179145813, "action": 0.43070071935653687}
{"mode": "train", "epochs": 11, "timestep": 21717, "ep_reward": 1069.63916015625, "reward": 0.8459088802337646, "action": 0.7724872827529907}
{"mode": "train", "epochs": 11, "timestep": 21718, "ep_reward": 1070.5089111328125, "reward": 0.8698093891143799, "action": 0.8327920436859131}
{"mode": "train", "epochs": 11, "timestep": 21719, "ep_reward": 1071.391845703125, "reward": 0.8829925656318665, "action": 1.0286939144134521}
{"mode": "train", "epochs": 11, "timestep": 21720, "ep_reward": 1072.2784423828125, "reward": 0.8865927457809448, "action": 0.26913124322891235}
{"mode": "train", "epochs": 11, "timestep": 21721, "ep_reward": 1073.15771484375, "reward": 0.8793191313743591, "action": 0.31879109144210815}
{"mode": "train", "epochs": 11, "timestep": 21722, "ep_reward": 1074.017578125, "reward": 0.8598778247833252, "action": 0.5924346446990967}
{"mode": "train", "epochs": 11, "timestep": 21723, "ep_reward": 1074.84619140625, "reward": 0.8285942077636719, "action": 0.7010354995727539}
{"mode": "train", "epochs": 11, "timestep": 21724, "ep_reward": 1075.630615234375, "reward": 0.7844051122665405, "action": 1.218618631362915}
{"mode": "train", "epochs": 11, "timestep": 21725, "ep_reward": 1076.3603515625, "reward": 0.7296801805496216, "action": 2.0}
{"mode": "train", "epochs": 11, "timestep": 21726, "ep_reward": 1077.029541015625, "reward": 0.6691781282424927, "action": 1.145653486251831}
{"mode": "train", "epochs": 11, "timestep": 21727, "ep_reward": 1077.62060546875, "reward": 0.5911033749580383, "action": 0.8257321119308472}
{"mode": "train", "epochs": 11, "timestep": 21728, "ep_reward": 1078.11962890625, "reward": 0.4989657998085022, "action": 1.0480918884277344}
{"mode": "train", "epochs": 11, "timestep": 21729, "ep_reward": 1078.5208740234375, "reward": 0.40129101276397705, "action": 0.9867990016937256}
{"mode": "train", "epochs": 11, "timestep": 21730, "ep_reward": 1078.821533203125, "reward": 0.3006766438484192, "action": 0.030756115913391113}
{"mode": "train", "epochs": 11, "timestep": 21731, "ep_reward": 1079.054931640625, "reward": 0.2333926558494568, "action": -0.5044078826904297}
{"mode": "train", "epochs": 11, "timestep": 21732, "ep_reward": 1079.3831787109375, "reward": 0.328278124332428, "action": -0.9921683073043823}
{"mode": "train", "epochs": 11, "timestep": 21733, "ep_reward": 1079.8043212890625, "reward": 0.421087384223938, "action": -0.578028678894043}
{"mode": "train", "epochs": 11, "timestep": 21734, "ep_reward": 1080.3197021484375, "reward": 0.5153319239616394, "action": -1.4915348291397095}
{"mode": "train", "epochs": 11, "timestep": 21735, "ep_reward": 1080.916748046875, "reward": 0.5970304012298584, "action": -0.7355514764785767}
{"mode": "train", "epochs": 11, "timestep": 21736, "ep_reward": 1081.59228515625, "reward": 0.6755765676498413, "action": -0.25034016370773315}
{"mode": "train", "epochs": 11, "timestep": 21737, "ep_reward": 1082.336181640625, "reward": 0.7439150810241699, "action": -0.9804155826568604}
{"mode": "train", "epochs": 11, "timestep": 21738, "ep_reward": 1083.130859375, "reward": 0.7946609854698181, "action": -1.0435254573822021}
{"mode": "train", "epochs": 11, "timestep": 21739, "ep_reward": 1083.964111328125, "reward": 0.8332409858703613, "action": -0.9215627908706665}
{"mode": "train", "epochs": 11, "timestep": 21740, "ep_reward": 1084.8250732421875, "reward": 0.8610195517539978, "action": -0.3463558554649353}
{"mode": "train", "epochs": 11, "timestep": 21741, "ep_reward": 1085.7034912109375, "reward": 0.8783998489379883, "action": -0.8584291338920593}
{"mode": "train", "epochs": 11, "timestep": 21742, "ep_reward": 1086.587890625, "reward": 0.8843634724617004, "action": -1.111275553703308}
{"mode": "train", "epochs": 11, "timestep": 21743, "ep_reward": 1087.468994140625, "reward": 0.8811423182487488, "action": -0.8565655946731567}
{"mode": "train", "epochs": 11, "timestep": 21744, "ep_reward": 1088.3370361328125, "reward": 0.8680776357650757, "action": -0.3106766939163208}
{"mode": "train", "epochs": 11, "timestep": 21745, "ep_reward": 1089.178955078125, "reward": 0.8418750762939453, "action": 0.32127436995506287}
{"mode": "train", "epochs": 11, "timestep": 21746, "ep_reward": 1089.9766845703125, "reward": 0.7977721095085144, "action": 0.44832929968833923}
{"mode": "train", "epochs": 11, "timestep": 21747, "ep_reward": 1090.710693359375, "reward": 0.7340681552886963, "action": 0.637082576751709}
{"mode": "train", "epochs": 11, "timestep": 21748, "ep_reward": 1091.358642578125, "reward": 0.6479685306549072, "action": -0.20531678199768066}
{"mode": "train", "epochs": 11, "timestep": 21749, "ep_reward": 1091.9080810546875, "reward": 0.5494903326034546, "action": 0.9211271405220032}
{"mode": "train", "epochs": 11, "timestep": 21750, "ep_reward": 1092.3302001953125, "reward": 0.4221256375312805, "action": -0.036870598793029785}
{"mode": "train", "epochs": 11, "timestep": 21751, "ep_reward": 1092.623046875, "reward": 0.29288607835769653, "action": 0.071938157081604}
{"mode": "train", "epochs": 11, "timestep": 21752, "ep_reward": 1092.7822265625, "reward": 0.15912294387817383, "action": 0.36387619376182556}
{"mode": "train", "epochs": 11, "timestep": 21753, "ep_reward": 1093.0250244140625, "reward": 0.2427583932876587, "action": -0.32746368646621704}
{"mode": "train", "epochs": 11, "timestep": 21754, "ep_reward": 1093.3890380859375, "reward": 0.36398738622665405, "action": -0.22101221978664398}
{"mode": "train", "epochs": 11, "timestep": 21755, "ep_reward": 1093.869140625, "reward": 0.4801188111305237, "action": 0.7985008955001831}
{"mode": "train", "epochs": 11, "timestep": 21756, "ep_reward": 1094.447998046875, "reward": 0.5788325071334839, "action": 0.4652091860771179}
{"mode": "train", "epochs": 11, "timestep": 21757, "ep_reward": 1095.1170654296875, "reward": 0.6690677404403687, "action": 0.7009934782981873}
{"mode": "train", "epochs": 11, "timestep": 21758, "ep_reward": 1095.8603515625, "reward": 0.7432839870452881, "action": 0.7560938596725464}
{"mode": "train", "epochs": 11, "timestep": 21759, "ep_reward": 1096.6630859375, "reward": 0.8027331233024597, "action": 0.3464111089706421}
{"mode": "train", "epochs": 11, "timestep": 21760, "ep_reward": 1097.5130615234375, "reward": 0.8499734401702881, "action": 0.49549221992492676}
{"mode": "train", "epochs": 11, "timestep": 21761, "ep_reward": 1098.3963623046875, "reward": 0.8832707405090332, "action": 0.9291789531707764}
{"mode": "train", "epochs": 11, "timestep": 21762, "ep_reward": 1099.301025390625, "reward": 0.904685378074646, "action": 1.0913727283477783}
{"mode": "train", "epochs": 11, "timestep": 21763, "ep_reward": 1100.218505859375, "reward": 0.9175032377243042, "action": 1.1078497171401978}
{"mode": "train", "epochs": 11, "timestep": 21764, "ep_reward": 1101.1417236328125, "reward": 0.9231727719306946, "action": 1.0147053003311157}
{"mode": "train", "epochs": 11, "timestep": 21765, "ep_reward": 1102.063720703125, "reward": 0.9220193028450012, "action": 0.6248456239700317}
{"mode": "train", "epochs": 11, "timestep": 21766, "ep_reward": 1102.9764404296875, "reward": 0.9127553701400757, "action": 0.42916423082351685}
{"mode": "train", "epochs": 11, "timestep": 21767, "ep_reward": 1103.8699951171875, "reward": 0.8935520648956299, "action": 1.3337479829788208}
{"mode": "train", "epochs": 11, "timestep": 21768, "ep_reward": 1104.7376708984375, "reward": 0.8676817417144775, "action": 1.5764317512512207}
{"mode": "train", "epochs": 11, "timestep": 21769, "ep_reward": 1105.5711669921875, "reward": 0.8335378766059875, "action": 1.812929630279541}
{"mode": "train", "epochs": 11, "timestep": 21770, "ep_reward": 1106.3619384765625, "reward": 0.790789783000946, "action": 1.0116856098175049}
{"mode": "train", "epochs": 11, "timestep": 21771, "ep_reward": 1107.092529296875, "reward": 0.7306413054466248, "action": 0.5882327556610107}
{"mode": "train", "epochs": 11, "timestep": 21772, "ep_reward": 1107.744140625, "reward": 0.6516638994216919, "action": 1.0695630311965942}
{"mode": "train", "epochs": 11, "timestep": 21773, "ep_reward": 1108.3057861328125, "reward": 0.5615983605384827, "action": 2.0}
{"mode": "train", "epochs": 11, "timestep": 21774, "ep_reward": 1108.7769775390625, "reward": 0.471221923828125, "action": 0.695266842842102}
{"mode": "train", "epochs": 11, "timestep": 21775, "ep_reward": 1109.1378173828125, "reward": 0.3608623743057251, "action": 0.2276645302772522}
{"mode": "train", "epochs": 11, "timestep": 21776, "ep_reward": 1109.3795166015625, "reward": 0.24163907766342163, "action": 0.6547017693519592}
{"mode": "train", "epochs": 11, "timestep": 21777, "ep_reward": 1109.6168212890625, "reward": 0.23727887868881226, "action": 0.07588326930999756}
{"mode": "train", "epochs": 11, "timestep": 21778, "ep_reward": 1109.9608154296875, "reward": 0.3439983129501343, "action": -0.6998697519302368}
{"mode": "train", "epochs": 11, "timestep": 21779, "ep_reward": 1110.4044189453125, "reward": 0.44360828399658203, "action": -0.3372343182563782}
{"mode": "train", "epochs": 11, "timestep": 21780, "ep_reward": 1110.946533203125, "reward": 0.5421550273895264, "action": -0.27669569849967957}
{"mode": "train", "epochs": 11, "timestep": 21781, "ep_reward": 1111.578125, "reward": 0.631565272808075, "action": -1.0119881629943848}
{"mode": "train", "epochs": 11, "timestep": 21782, "ep_reward": 1112.2822265625, "reward": 0.7041016221046448, "action": -0.127444326877594}
{"mode": "train", "epochs": 11, "timestep": 21783, "ep_reward": 1113.050537109375, "reward": 0.768361508846283, "action": -1.0848740339279175}
{"mode": "train", "epochs": 11, "timestep": 21784, "ep_reward": 1113.8646240234375, "reward": 0.8140603303909302, "action": -0.717332661151886}
{"mode": "train", "epochs": 11, "timestep": 21785, "ep_reward": 1114.7137451171875, "reward": 0.8491119742393494, "action": -0.8928390145301819}
{"mode": "train", "epochs": 11, "timestep": 21786, "ep_reward": 1115.5860595703125, "reward": 0.8723000288009644, "action": -0.14205187559127808}
{"mode": "train", "epochs": 11, "timestep": 21787, "ep_reward": 1116.4710693359375, "reward": 0.8849750757217407, "action": -1.8029725551605225}
{"mode": "train", "epochs": 11, "timestep": 21788, "ep_reward": 1117.35888671875, "reward": 0.8878607749938965, "action": -0.2833501696586609}
{"mode": "train", "epochs": 11, "timestep": 21789, "ep_reward": 1118.239501953125, "reward": 0.8806519508361816, "action": -1.1744089126586914}
{"mode": "train", "epochs": 11, "timestep": 21790, "ep_reward": 1119.1041259765625, "reward": 0.8646196126937866, "action": 0.13715997338294983}
{"mode": "train", "epochs": 11, "timestep": 21791, "ep_reward": 1119.9365234375, "reward": 0.832404613494873, "action": 0.04785241186618805}
{"mode": "train", "epochs": 11, "timestep": 21792, "ep_reward": 1120.720703125, "reward": 0.7841981053352356, "action": 0.9582942724227905}
{"mode": "train", "epochs": 11, "timestep": 21793, "ep_reward": 1121.4315185546875, "reward": 0.7107588648796082, "action": 0.1754000186920166}
{"mode": "train", "epochs": 11, "timestep": 21794, "ep_reward": 1122.052978515625, "reward": 0.6214847564697266, "action": 1.020857334136963}
{"mode": "train", "epochs": 11, "timestep": 21795, "ep_reward": 1122.556396484375, "reward": 0.5033932328224182, "action": 0.8056620359420776}
{"mode": "train", "epochs": 11, "timestep": 21796, "ep_reward": 1122.9244384765625, "reward": 0.3680610656738281, "action": 1.446332573890686}
{"mode": "train", "epochs": 11, "timestep": 21797, "ep_reward": 1123.1357421875, "reward": 0.21130818128585815, "action": 1.241148829460144}
{"mode": "train", "epochs": 11, "timestep": 21798, "ep_reward": 1123.2762451171875, "reward": 0.14046931266784668, "action": 0.7045374512672424}
{"mode": "train", "epochs": 11, "timestep": 21799, "ep_reward": 1123.5362548828125, "reward": 0.25995969772338867, "action": -0.8574079275131226}
{"mode": "train", "epochs": 11, "timestep": 21800, "ep_reward": 1123.933837890625, "reward": 0.3975631594657898, "action": -0.6873562335968018}
{"mode": "train", "epochs": 11, "timestep": 21801, "ep_reward": 1124.4580078125, "reward": 0.5241349935531616, "action": 0.0022149384021759033}
{"mode": "train", "epochs": 11, "timestep": 21802, "ep_reward": 1125.087890625, "reward": 0.6298294067382812, "action": 1.3092142343521118}
{"mode": "train", "epochs": 11, "timestep": 21803, "ep_reward": 1125.7978515625, "reward": 0.7100006341934204, "action": 2.0}
{"mode": "train", "epochs": 11, "timestep": 21804, "ep_reward": 1126.570556640625, "reward": 0.7727185487747192, "action": 1.2437114715576172}
{"mode": "train", "epochs": 11, "timestep": 21805, "ep_reward": 1127.398681640625, "reward": 0.8280923366546631, "action": -0.07060688734054565}
{"mode": "train", "epochs": 11, "timestep": 21806, "ep_reward": 1128.275390625, "reward": 0.8767654299736023, "action": 0.6468634009361267}
{"mode": "train", "epochs": 11, "timestep": 21807, "ep_reward": 1129.1845703125, "reward": 0.9091238379478455, "action": 0.4522576332092285}
{"mode": "train", "epochs": 11, "timestep": 21808, "ep_reward": 1130.1170654296875, "reward": 0.9324966669082642, "action": 1.049980878829956}
{"mode": "train", "epochs": 11, "timestep": 21809, "ep_reward": 1131.06396484375, "reward": 0.94696044921875, "action": 1.9476826190948486}
{"mode": "train", "epochs": 11, "timestep": 21810, "ep_reward": 1132.0198974609375, "reward": 0.9559005498886108, "action": 0.3483954071998596}
{"mode": "train", "epochs": 11, "timestep": 21811, "ep_reward": 1132.9827880859375, "reward": 0.9628625512123108, "action": 1.2727510929107666}
{"mode": "train", "epochs": 11, "timestep": 21812, "ep_reward": 1133.9481201171875, "reward": 0.9653324484825134, "action": 1.0526765584945679}
{"mode": "train", "epochs": 11, "timestep": 21813, "ep_reward": 1134.9129638671875, "reward": 0.9648184180259705, "action": 1.0253664255142212}
{"mode": "train", "epochs": 11, "timestep": 21814, "ep_reward": 1135.8739013671875, "reward": 0.9609792828559875, "action": 1.3346834182739258}
{"mode": "train", "epochs": 11, "timestep": 21815, "ep_reward": 1136.828125, "reward": 0.9541828036308289, "action": 1.6081293821334839}
{"mode": "train", "epochs": 11, "timestep": 21816, "ep_reward": 1137.772705078125, "reward": 0.9446091651916504, "action": 1.288567304611206}
{"mode": "train", "epochs": 11, "timestep": 21817, "ep_reward": 1138.7025146484375, "reward": 0.9298303723335266, "action": 1.1262588500976562}
{"mode": "train", "epochs": 11, "timestep": 21818, "ep_reward": 1139.61083984375, "reward": 0.9083407521247864, "action": 0.012840569019317627}
{"mode": "train", "epochs": 11, "timestep": 21819, "ep_reward": 1140.48291015625, "reward": 0.8720214366912842, "action": 0.9389927983283997}
{"mode": "train", "epochs": 11, "timestep": 21820, "ep_reward": 1141.3106689453125, "reward": 0.8277384042739868, "action": 0.7963449954986572}
{"mode": "train", "epochs": 11, "timestep": 21821, "ep_reward": 1142.078857421875, "reward": 0.7681417465209961, "action": 0.7266025543212891}
{"mode": "train", "epochs": 11, "timestep": 21822, "ep_reward": 1142.7696533203125, "reward": 0.6907874941825867, "action": 1.654733419418335}
{"mode": "train", "epochs": 11, "timestep": 21823, "ep_reward": 1143.3753662109375, "reward": 0.6057066917419434, "action": 0.8471035361289978}
{"mode": "train", "epochs": 11, "timestep": 21824, "ep_reward": 1143.8726806640625, "reward": 0.4973168969154358, "action": 1.9114246368408203}
{"mode": "train", "epochs": 11, "timestep": 21825, "ep_reward": 1144.263671875, "reward": 0.39094263315200806, "action": 0.4108254909515381}
{"mode": "train", "epochs": 11, "timestep": 21826, "ep_reward": 1144.5250244140625, "reward": 0.2614050507545471, "action": 0.6735312938690186}
{"mode": "train", "epochs": 11, "timestep": 21827, "ep_reward": 1144.6719970703125, "reward": 0.1470022201538086, "action": -1.070689082145691}
{"mode": "train", "epochs": 11, "timestep": 21828, "ep_reward": 1144.9254150390625, "reward": 0.253420352935791, "action": -0.4495094418525696}
{"mode": "train", "epochs": 11, "timestep": 21829, "ep_reward": 1145.2955322265625, "reward": 0.37007540464401245, "action": 0.13429370522499084}
{"mode": "train", "epochs": 11, "timestep": 21830, "ep_reward": 1145.7847900390625, "reward": 0.4892734885215759, "action": -0.5389838814735413}
{"mode": "train", "epochs": 11, "timestep": 21831, "ep_reward": 1146.377197265625, "reward": 0.5924654006958008, "action": -0.726887047290802}
{"mode": "train", "epochs": 11, "timestep": 21832, "ep_reward": 1147.0587158203125, "reward": 0.6815099716186523, "action": 0.14201533794403076}
{"mode": "train", "epochs": 11, "timestep": 21833, "ep_reward": 1147.8197021484375, "reward": 0.7609277367591858, "action": -1.2450265884399414}
{"mode": "train", "epochs": 11, "timestep": 21834, "ep_reward": 1148.635498046875, "reward": 0.815848171710968, "action": -0.8846078515052795}
{"mode": "train", "epochs": 11, "timestep": 21835, "ep_reward": 1149.49560546875, "reward": 0.8600928783416748, "action": -1.1604458093643188}
{"mode": "train", "epochs": 11, "timestep": 21836, "ep_reward": 1150.3876953125, "reward": 0.8920857310295105, "action": -1.1200307607650757}
{"mode": "train", "epochs": 11, "timestep": 21837, "ep_reward": 1151.3028564453125, "reward": 0.9151871204376221, "action": -1.7330106496810913}
{"mode": "train", "epochs": 11, "timestep": 21838, "ep_reward": 1152.233154296875, "reward": 0.9303506016731262, "action": -0.31504642963409424}
{"mode": "train", "epochs": 11, "timestep": 21839, "ep_reward": 1153.174560546875, "reward": 0.9414337277412415, "action": -0.6650086045265198}
{"mode": "train", "epochs": 11, "timestep": 21840, "ep_reward": 1154.1197509765625, "reward": 0.9452083110809326, "action": -0.8109798431396484}
{"mode": "train", "epochs": 11, "timestep": 21841, "ep_reward": 1155.0626220703125, "reward": 0.9428728222846985, "action": -1.8691143989562988}
{"mode": "train", "epochs": 11, "timestep": 21842, "ep_reward": 1156.0, "reward": 0.9373500943183899, "action": 0.10359352827072144}
{"mode": "train", "epochs": 11, "timestep": 21843, "ep_reward": 1156.9215087890625, "reward": 0.9215654134750366, "action": -1.4803225994110107}
{"mode": "train", "epochs": 11, "timestep": 21844, "ep_reward": 1157.82373046875, "reward": 0.9022203683853149, "action": -0.738898515701294}
{"mode": "train", "epochs": 11, "timestep": 21845, "ep_reward": 1158.6949462890625, "reward": 0.8712255954742432, "action": -1.7324378490447998}
{"mode": "train", "epochs": 11, "timestep": 21846, "ep_reward": 1159.530029296875, "reward": 0.8351049423217773, "action": -0.9538947343826294}
{"mode": "train", "epochs": 11, "timestep": 21847, "ep_reward": 1160.3126220703125, "reward": 0.7826027274131775, "action": -0.5742989182472229}
{"mode": "train", "epochs": 11, "timestep": 21848, "ep_reward": 1161.0242919921875, "reward": 0.711639404296875, "action": 0.013311490416526794}
{"mode": "train", "epochs": 11, "timestep": 21849, "ep_reward": 1161.640869140625, "reward": 0.6166115403175354, "action": 0.46207863092422485}
{"mode": "train", "epochs": 11, "timestep": 21850, "ep_reward": 1162.136962890625, "reward": 0.4960572123527527, "action": -0.4336884021759033}
{"mode": "train", "epochs": 11, "timestep": 21851, "ep_reward": 1162.506103515625, "reward": 0.3690938353538513, "action": -0.5350360870361328}
{"mode": "train", "epochs": 11, "timestep": 21852, "ep_reward": 1162.7420654296875, "reward": 0.23599743843078613, "action": -0.8124431371688843}
{"mode": "train", "epochs": 11, "timestep": 21853, "ep_reward": 1162.8865966796875, "reward": 0.1445663571357727, "action": -0.29783880710601807}
{"mode": "train", "epochs": 11, "timestep": 21854, "ep_reward": 1163.1536865234375, "reward": 0.2670443058013916, "action": -0.18104606866836548}
{"mode": "train", "epochs": 11, "timestep": 21855, "ep_reward": 1163.54248046875, "reward": 0.38876479864120483, "action": -0.944040834903717}
{"mode": "train", "epochs": 11, "timestep": 21856, "ep_reward": 1164.0540771484375, "reward": 0.5115653276443481, "action": -0.39779993891716003}
{"mode": "train", "epochs": 11, "timestep": 21857, "ep_reward": 1164.6700439453125, "reward": 0.6160095930099487, "action": -0.6107456088066101}
{"mode": "train", "epochs": 11, "timestep": 21858, "ep_reward": 1165.3753662109375, "reward": 0.7053546905517578, "action": 0.7068500518798828}
{"mode": "train", "epochs": 11, "timestep": 21859, "ep_reward": 1166.144775390625, "reward": 0.7694234251976013, "action": 1.5152080059051514}
{"mode": "train", "epochs": 11, "timestep": 21860, "ep_reward": 1166.96142578125, "reward": 0.8166616559028625, "action": 1.6978291273117065}
{"mode": "train", "epochs": 11, "timestep": 21861, "ep_reward": 1167.8145751953125, "reward": 0.8531550765037537, "action": 0.832118034362793}
{"mode": "train", "epochs": 11, "timestep": 21862, "ep_reward": 1168.6971435546875, "reward": 0.8826117515563965, "action": 1.3032358884811401}
{"mode": "train", "epochs": 11, "timestep": 21863, "ep_reward": 1169.5986328125, "reward": 0.9015095233917236, "action": 1.1760673522949219}
{"mode": "train", "epochs": 11, "timestep": 21864, "ep_reward": 1170.511474609375, "reward": 0.9128136038780212, "action": 1.5438363552093506}
{"mode": "train", "epochs": 11, "timestep": 21865, "ep_reward": 1171.4288330078125, "reward": 0.9173247814178467, "action": 0.9137133359909058}
{"mode": "train", "epochs": 11, "timestep": 21866, "ep_reward": 1172.3436279296875, "reward": 0.9147791862487793, "action": 1.6851893663406372}
{"mode": "train", "epochs": 11, "timestep": 21867, "ep_reward": 1173.250244140625, "reward": 0.9066423177719116, "action": 0.02500075101852417}
{"mode": "train", "epochs": 11, "timestep": 21868, "ep_reward": 1174.1363525390625, "reward": 0.8860974311828613, "action": 0.1499391794204712}
{"mode": "train", "epochs": 11, "timestep": 21869, "ep_reward": 1174.9891357421875, "reward": 0.8527445793151855, "action": 2.0}
{"mode": "train", "epochs": 11, "timestep": 21870, "ep_reward": 1175.80615234375, "reward": 0.8170661926269531, "action": 0.1528719663619995}
{"mode": "train", "epochs": 11, "timestep": 21871, "ep_reward": 1176.5638427734375, "reward": 0.7577433586120605, "action": 1.1676616668701172}
{"mode": "train", "epochs": 11, "timestep": 21872, "ep_reward": 1177.25341796875, "reward": 0.6896264553070068, "action": 0.11902660131454468}
{"mode": "train", "epochs": 11, "timestep": 21873, "ep_reward": 1177.8497314453125, "reward": 0.5962939858436584, "action": 0.9350659251213074}
{"mode": "train", "epochs": 11, "timestep": 21874, "ep_reward": 1178.3448486328125, "reward": 0.49511080980300903, "action": 1.6213864088058472}
{"mode": "train", "epochs": 11, "timestep": 21875, "ep_reward": 1178.73779296875, "reward": 0.392958402633667, "action": 0.9916326999664307}
{"mode": "train", "epochs": 11, "timestep": 21876, "ep_reward": 1179.018798828125, "reward": 0.28095853328704834, "action": 1.2242400646209717}
{"mode": "train", "epochs": 11, "timestep": 21877, "ep_reward": 1179.21875, "reward": 0.19992178678512573, "action": 0.11000999808311462}
{"mode": "train", "epochs": 11, "timestep": 21878, "ep_reward": 1179.5245361328125, "reward": 0.3058304190635681, "action": 0.8664420247077942}
{"mode": "train", "epochs": 11, "timestep": 21879, "ep_reward": 1179.942138671875, "reward": 0.41762202978134155, "action": -1.2370916604995728}
{"mode": "train", "epochs": 11, "timestep": 21880, "ep_reward": 1180.4498291015625, "reward": 0.507737398147583, "action": -0.7820541858673096}
{"mode": "train", "epochs": 11, "timestep": 21881, "ep_reward": 1181.0460205078125, "reward": 0.596152126789093, "action": -0.719589114189148}
{"mode": "train", "epochs": 11, "timestep": 21882, "ep_reward": 1181.7210693359375, "reward": 0.675067663192749, "action": -0.4606623649597168}
{"mode": "train", "epochs": 11, "timestep": 21883, "ep_reward": 1182.4637451171875, "reward": 0.7427065372467041, "action": -0.7310991287231445}
{"mode": "train", "epochs": 11, "timestep": 21884, "ep_reward": 1183.2587890625, "reward": 0.7950625419616699, "action": -1.1141839027404785}
{"mode": "train", "epochs": 11, "timestep": 21885, "ep_reward": 1184.09228515625, "reward": 0.8335204124450684, "action": -1.0628740787506104}
{"mode": "train", "epochs": 11, "timestep": 21886, "ep_reward": 1184.9534912109375, "reward": 0.8611489534378052, "action": -1.7543575763702393}
{"mode": "train", "epochs": 11, "timestep": 21887, "ep_reward": 1185.83203125, "reward": 0.8785847425460815, "action": -0.35215872526168823}
{"mode": "train", "epochs": 11, "timestep": 21888, "ep_reward": 1186.7203369140625, "reward": 0.8882887363433838, "action": -0.9675838947296143}
{"mode": "train", "epochs": 11, "timestep": 21889, "ep_reward": 1187.6080322265625, "reward": 0.8876954913139343, "action": -0.6939270496368408}
{"mode": "train", "epochs": 11, "timestep": 21890, "ep_reward": 1188.485107421875, "reward": 0.8770264983177185, "action": -1.0218137502670288}
{"mode": "train", "epochs": 11, "timestep": 21891, "ep_reward": 1189.341796875, "reward": 0.856735348701477, "action": -1.5744602680206299}
{"mode": "train", "epochs": 11, "timestep": 21892, "ep_reward": 1190.1705322265625, "reward": 0.828780472278595, "action": 0.17565253376960754}
{"mode": "train", "epochs": 11, "timestep": 21893, "ep_reward": 1190.9503173828125, "reward": 0.7797831892967224, "action": 0.5339939594268799}
{"mode": "train", "epochs": 11, "timestep": 21894, "ep_reward": 1191.65966796875, "reward": 0.7093755602836609, "action": 1.1227052211761475}
{"mode": "train", "epochs": 11, "timestep": 21895, "ep_reward": 1192.271484375, "reward": 0.6117743849754333, "action": 1.6584043502807617}
{"mode": "train", "epochs": 11, "timestep": 21896, "ep_reward": 1192.7557373046875, "reward": 0.4842420220375061, "action": 0.42157962918281555}
{"mode": "train", "epochs": 11, "timestep": 21897, "ep_reward": 1193.106201171875, "reward": 0.35044169425964355, "action": -0.9989601373672485}
{"mode": "train", "epochs": 11, "timestep": 21898, "ep_reward": 1193.3341064453125, "reward": 0.22786813974380493, "action": -0.16078771650791168}
{"mode": "train", "epochs": 11, "timestep": 21899, "ep_reward": 1193.5145263671875, "reward": 0.18039417266845703, "action": -1.445448875427246}
{"mode": "train", "epochs": 11, "timestep": 21900, "ep_reward": 1193.8248291015625, "reward": 0.31036096811294556, "action": -0.5405266284942627}
{"mode": "train", "epochs": 11, "timestep": 21901, "ep_reward": 1194.252685546875, "reward": 0.42786645889282227, "action": -0.7069617509841919}
{"mode": "train", "epochs": 11, "timestep": 21902, "ep_reward": 1194.7916259765625, "reward": 0.538953423500061, "action": -0.1643521785736084}
{"mode": "train", "epochs": 11, "timestep": 21903, "ep_reward": 1195.4244384765625, "reward": 0.6328386664390564, "action": 1.1587098836898804}
{"mode": "train", "epochs": 11, "timestep": 21904, "ep_reward": 1196.1292724609375, "reward": 0.70481938123703, "action": 0.40198153257369995}
{"mode": "train", "epochs": 11, "timestep": 21905, "ep_reward": 1196.8978271484375, "reward": 0.7684937715530396, "action": 0.8718530535697937}
{"mode": "train", "epochs": 11, "timestep": 21906, "ep_reward": 1197.713623046875, "reward": 0.815828800201416, "action": 1.7432799339294434}
{"mode": "train", "epochs": 11, "timestep": 21907, "ep_reward": 1198.562744140625, "reward": 0.8491336703300476, "action": 0.39683496952056885}
{"mode": "train", "epochs": 11, "timestep": 21908, "ep_reward": 1199.4385986328125, "reward": 0.8758280873298645, "action": 1.3846696615219116}
{"mode": "train", "epochs": 11, "timestep": 21909, "ep_reward": 1200.3291015625, "reward": 0.8904756307601929, "action": 1.371874213218689}
{"mode": "train", "epochs": 11, "timestep": 21910, "ep_reward": 1201.2265625, "reward": 0.8974201083183289, "action": 1.0829344987869263}
{"mode": "train", "epochs": 11, "timestep": 21911, "ep_reward": 1202.1229248046875, "reward": 0.8963669538497925, "action": 1.6306977272033691}
{"mode": "train", "epochs": 11, "timestep": 21912, "ep_reward": 1203.011474609375, "reward": 0.8885250091552734, "action": 0.49511128664016724}
{"mode": "train", "epochs": 11, "timestep": 21913, "ep_reward": 1203.880615234375, "reward": 0.8691282868385315, "action": 1.5850062370300293}
{"mode": "train", "epochs": 11, "timestep": 21914, "ep_reward": 1204.7237548828125, "reward": 0.843146800994873, "action": 1.1212760210037231}
{"mode": "train", "epochs": 11, "timestep": 21915, "ep_reward": 1205.5284423828125, "reward": 0.8047475814819336, "action": 1.8772510290145874}
{"mode": "train", "epochs": 11, "timestep": 21916, "ep_reward": 1206.2880859375, "reward": 0.7596885561943054, "action": 0.43063271045684814}
{"mode": "train", "epochs": 11, "timestep": 21917, "ep_reward": 1206.980224609375, "reward": 0.6921724081039429, "action": 1.0146774053573608}
{"mode": "train", "epochs": 11, "timestep": 21918, "ep_reward": 1207.5941162109375, "reward": 0.6139416694641113, "action": 1.9152164459228516}
{"mode": "train", "epochs": 11, "timestep": 21919, "ep_reward": 1208.1273193359375, "reward": 0.5331641435623169, "action": 1.702121376991272}
{"mode": "train", "epochs": 11, "timestep": 21920, "ep_reward": 1208.5716552734375, "reward": 0.4443504214286804, "action": -1.1683378219604492}
{"mode": "train", "epochs": 11, "timestep": 21921, "ep_reward": 1208.89013671875, "reward": 0.31847506761550903, "action": -0.15757280588150024}
{"mode": "train", "epochs": 11, "timestep": 21922, "ep_reward": 1209.088623046875, "reward": 0.19851738214492798, "action": -0.861039400100708}
{"mode": "train", "epochs": 11, "timestep": 21923, "ep_reward": 1209.3687744140625, "reward": 0.28018516302108765, "action": -1.5981827974319458}
{"mode": "train", "epochs": 11, "timestep": 21924, "ep_reward": 1209.7440185546875, "reward": 0.3751833438873291, "action": -0.6127265691757202}
{"mode": "train", "epochs": 11, "timestep": 21925, "ep_reward": 1210.2235107421875, "reward": 0.47948408126831055, "action": -1.1279507875442505}
{"mode": "train", "epochs": 11, "timestep": 21926, "ep_reward": 1210.797119140625, "reward": 0.5736429691314697, "action": -1.2550170421600342}
{"mode": "train", "epochs": 11, "timestep": 21927, "ep_reward": 1211.455078125, "reward": 0.6579941511154175, "action": -0.4394826292991638}
{"mode": "train", "epochs": 11, "timestep": 21928, "ep_reward": 1212.190673828125, "reward": 0.7355393171310425, "action": -0.9242628216743469}
{"mode": "train", "epochs": 11, "timestep": 21929, "ep_reward": 1212.9859619140625, "reward": 0.795276403427124, "action": -1.524742841720581}
{"mode": "train", "epochs": 11, "timestep": 21930, "ep_reward": 1213.82568359375, "reward": 0.8396809101104736, "action": -1.0052976608276367}
{"mode": "train", "epochs": 11, "timestep": 21931, "ep_reward": 1214.7012939453125, "reward": 0.8755552172660828, "action": -0.848494291305542}
{"mode": "train", "epochs": 11, "timestep": 21932, "ep_reward": 1215.6026611328125, "reward": 0.9014177918434143, "action": -1.953050136566162}
{"mode": "train", "epochs": 11, "timestep": 21933, "ep_reward": 1216.52001953125, "reward": 0.9173023104667664, "action": -0.9774149656295776}
{"mode": "train", "epochs": 11, "timestep": 21934, "ep_reward": 1217.4486083984375, "reward": 0.9285902380943298, "action": -0.7257844805717468}
{"mode": "train", "epochs": 11, "timestep": 21935, "ep_reward": 1218.381591796875, "reward": 0.9330111145973206, "action": -0.5640386343002319}
{"mode": "train", "epochs": 11, "timestep": 21936, "ep_reward": 1219.3115234375, "reward": 0.9299180507659912, "action": -1.580169916152954}
{"mode": "train", "epochs": 11, "timestep": 21937, "ep_reward": 1220.2332763671875, "reward": 0.921798825263977, "action": -1.3523423671722412}
{"mode": "train", "epochs": 11, "timestep": 21938, "ep_reward": 1221.140625, "reward": 0.9073441624641418, "action": -0.8875219821929932}
{"mode": "train", "epochs": 11, "timestep": 21939, "ep_reward": 1222.0240478515625, "reward": 0.8834787607192993, "action": -0.795657753944397}
{"mode": "train", "epochs": 11, "timestep": 21940, "ep_reward": 1222.872802734375, "reward": 0.8487162590026855, "action": 0.4280543029308319}
{"mode": "train", "epochs": 11, "timestep": 21941, "ep_reward": 1223.6651611328125, "reward": 0.792346715927124, "action": -0.2801191210746765}
{"mode": "train", "epochs": 11, "timestep": 21942, "ep_reward": 1224.3868408203125, "reward": 0.7217147350311279, "action": 1.3080755472183228}
{"mode": "train", "epochs": 11, "timestep": 21943, "ep_reward": 1225.002197265625, "reward": 0.6153559684753418, "action": -0.2164456844329834}
{"mode": "train", "epochs": 11, "timestep": 21944, "ep_reward": 1225.5030517578125, "reward": 0.5008418560028076, "action": -0.14874577522277832}
{"mode": "train", "epochs": 11, "timestep": 21945, "ep_reward": 1225.87255859375, "reward": 0.3694577217102051, "action": 0.6140636205673218}
{"mode": "train", "epochs": 11, "timestep": 21946, "ep_reward": 1226.0899658203125, "reward": 0.21740293502807617, "action": -0.06834001839160919}
{"mode": "train", "epochs": 11, "timestep": 21947, "ep_reward": 1226.2091064453125, "reward": 0.11918371915817261, "action": -1.17628812789917}
{"mode": "train", "epochs": 11, "timestep": 21948, "ep_reward": 1226.46630859375, "reward": 0.25724828243255615, "action": -0.20027074217796326}
{"mode": "train", "epochs": 11, "timestep": 21949, "ep_reward": 1226.8497314453125, "reward": 0.38346391916275024, "action": -1.8338367938995361}
{"mode": "train", "epochs": 11, "timestep": 21950, "ep_reward": 1227.367919921875, "reward": 0.5182138085365295, "action": -0.524906575679779}
{"mode": "train", "epochs": 11, "timestep": 21951, "ep_reward": 1227.9923095703125, "reward": 0.6243555545806885, "action": 0.1405400037765503}
{"mode": "train", "epochs": 11, "timestep": 21952, "ep_reward": 1228.701171875, "reward": 0.70887291431427, "action": 1.7073967456817627}
{"mode": "train", "epochs": 11, "timestep": 21953, "ep_reward": 1229.4705810546875, "reward": 0.7693692445755005, "action": 0.8048363924026489}
{"mode": "train", "epochs": 11, "timestep": 21954, "ep_reward": 1230.2933349609375, "reward": 0.822758674621582, "action": 0.9875034689903259}
{"mode": "train", "epochs": 11, "timestep": 21955, "ep_reward": 1231.1558837890625, "reward": 0.8625997304916382, "action": 1.2258193492889404}
{"mode": "train", "epochs": 11, "timestep": 21956, "ep_reward": 1232.0469970703125, "reward": 0.8911431431770325, "action": 1.1130468845367432}
{"mode": "train", "epochs": 11, "timestep": 21957, "ep_reward": 1232.9583740234375, "reward": 0.9113455414772034, "action": 0.6900742053985596}
{"mode": "train", "epochs": 11, "timestep": 21958, "ep_reward": 1233.8824462890625, "reward": 0.9240143299102783, "action": 1.5101954936981201}
{"mode": "train", "epochs": 11, "timestep": 21959, "ep_reward": 1234.811767578125, "reward": 0.9293051362037659, "action": 1.2974319458007812}
{"mode": "train", "epochs": 11, "timestep": 21960, "ep_reward": 1235.740966796875, "reward": 0.9292120337486267, "action": 0.6093758344650269}
{"mode": "train", "epochs": 11, "timestep": 21961, "ep_reward": 1236.6627197265625, "reward": 0.9217102527618408, "action": 1.0095984935760498}
{"mode": "train", "epochs": 11, "timestep": 21962, "ep_reward": 1237.5699462890625, "reward": 0.9072215557098389, "action": 0.3303372263908386}
{"mode": "train", "epochs": 11, "timestep": 21963, "ep_reward": 1238.451171875, "reward": 0.8812735676765442, "action": 0.6016976237297058}
{"mode": "train", "epochs": 11, "timestep": 21964, "ep_reward": 1239.2955322265625, "reward": 0.8444124460220337, "action": 0.8092362284660339}
{"mode": "train", "epochs": 11, "timestep": 21965, "ep_reward": 1240.0908203125, "reward": 0.7953479290008545, "action": 0.7475554347038269}
{"mode": "train", "epochs": 11, "timestep": 21966, "ep_reward": 1240.821533203125, "reward": 0.7306852340698242, "action": 1.4843170642852783}
{"mode": "train", "epochs": 11, "timestep": 21967, "ep_reward": 1241.478515625, "reward": 0.6569539308547974, "action": 0.4205026626586914}
{"mode": "train", "epochs": 11, "timestep": 21968, "ep_reward": 1242.0367431640625, "reward": 0.5581728219985962, "action": 1.112011194229126}
{"mode": "train", "epochs": 11, "timestep": 21969, "ep_reward": 1242.489501953125, "reward": 0.45277535915374756, "action": 0.040238797664642334}
{"mode": "train", "epochs": 11, "timestep": 21970, "ep_reward": 1242.8150634765625, "reward": 0.32553631067276, "action": 1.4175708293914795}
{"mode": "train", "epochs": 11, "timestep": 21971, "ep_reward": 1243.028076171875, "reward": 0.2130281925201416, "action": -0.9824494123458862}
{"mode": "train", "epochs": 11, "timestep": 21972, "ep_reward": 1243.2457275390625, "reward": 0.2176607847213745, "action": -0.3733311891555786}
{"mode": "train", "epochs": 11, "timestep": 21973, "ep_reward": 1243.5758056640625, "reward": 0.33006536960601807, "action": -0.731949508190155}
{"mode": "train", "epochs": 11, "timestep": 21974, "ep_reward": 1244.0150146484375, "reward": 0.4391622543334961, "action": -0.8951735496520996}
{"mode": "train", "epochs": 11, "timestep": 21975, "ep_reward": 1244.5572509765625, "reward": 0.5422966480255127, "action": -0.22289207577705383}
{"mode": "train", "epochs": 11, "timestep": 21976, "ep_reward": 1245.1982421875, "reward": 0.6409945487976074, "action": -0.664018988609314}
{"mode": "train", "epochs": 11, "timestep": 21977, "ep_reward": 1245.919921875, "reward": 0.721657395362854, "action": -0.4246506690979004}
{"mode": "train", "epochs": 11, "timestep": 21978, "ep_reward": 1246.70849609375, "reward": 0.7885386943817139, "action": -1.1383119821548462}
{"mode": "train", "epochs": 11, "timestep": 21979, "ep_reward": 1247.545654296875, "reward": 0.8372116684913635, "action": -0.9269039034843445}
{"mode": "train", "epochs": 11, "timestep": 21980, "ep_reward": 1248.420654296875, "reward": 0.8750468492507935, "action": -0.8381028771400452}
{"mode": "train", "epochs": 11, "timestep": 21981, "ep_reward": 1249.3232421875, "reward": 0.9025776386260986, "action": -0.9770792722702026}
{"mode": "train", "epochs": 11, "timestep": 21982, "ep_reward": 1250.2440185546875, "reward": 0.9207722544670105, "action": -1.6110343933105469}
{"mode": "train", "epochs": 11, "timestep": 21983, "ep_reward": 1251.175537109375, "reward": 0.9315344095230103, "action": -0.8723938465118408}
{"mode": "train", "epochs": 11, "timestep": 21984, "ep_reward": 1252.11279296875, "reward": 0.9372103214263916, "action": -0.6439478993415833}
{"mode": "train", "epochs": 11, "timestep": 21985, "ep_reward": 1253.0489501953125, "reward": 0.9361703395843506, "action": -1.3443142175674438}
{"mode": "train", "epochs": 11, "timestep": 21986, "ep_reward": 1253.9786376953125, "reward": 0.9296993017196655, "action": -1.5808238983154297}
{"mode": "train", "epochs": 11, "timestep": 21987, "ep_reward": 1254.8970947265625, "reward": 0.9184918403625488, "action": -0.2471001148223877}
{"mode": "train", "epochs": 11, "timestep": 21988, "ep_reward": 1255.7928466796875, "reward": 0.8957651853561401, "action": -0.9763915538787842}
{"mode": "train", "epochs": 11, "timestep": 21989, "ep_reward": 1256.658203125, "reward": 0.8653268218040466, "action": 0.1573222428560257}
{"mode": "train", "epochs": 11, "timestep": 21990, "ep_reward": 1257.4739990234375, "reward": 0.8158555030822754, "action": -0.3257949948310852}
{"mode": "train", "epochs": 11, "timestep": 21991, "ep_reward": 1258.22607421875, "reward": 0.7520425319671631, "action": 0.19831925630569458}
{"mode": "train", "epochs": 11, "timestep": 21992, "ep_reward": 1258.890380859375, "reward": 0.6643607020378113, "action": 1.3849108219146729}
{"mode": "train", "epochs": 11, "timestep": 21993, "ep_reward": 1259.4312744140625, "reward": 0.5409414768218994, "action": 0.8733834624290466}
{"mode": "train", "epochs": 11, "timestep": 21994, "ep_reward": 1259.8294677734375, "reward": 0.3981780409812927, "action": 0.2437727153301239}
{"mode": "train", "epochs": 11, "timestep": 21995, "ep_reward": 1260.076904296875, "reward": 0.24745941162109375, "action": 0.07865280658006668}
{"mode": "train", "epochs": 11, "timestep": 21996, "ep_reward": 1260.17138671875, "reward": 0.09442323446273804, "action": -0.9849545359611511}
{"mode": "train", "epochs": 11, "timestep": 21997, "ep_reward": 1260.3734130859375, "reward": 0.2019779086112976, "action": -1.0286329984664917}
{"mode": "train", "epochs": 11, "timestep": 21998, "ep_reward": 1260.7154541015625, "reward": 0.3420169949531555, "action": -0.532323956489563}
{"mode": "train", "epochs": 11, "timestep": 21999, "ep_reward": 1261.18603515625, "reward": 0.47063368558883667, "action": -0.5033102631568909}
{"mode": "train", "epochs": 11, "timestep": 22000, "ep_reward": 1261.7730712890625, "reward": 0.5869902968406677, "action": 0.10277649760246277}
{"mode": "train", "epochs": 12, "timestep": 22001, "ep_reward": 0.8733848333358765, "reward": 0.8733848333358765, "action": 1.7957632541656494}
{"mode": "train", "epochs": 12, "timestep": 22002, "ep_reward": 1.7366050481796265, "reward": 0.86322021484375, "action": 1.423836588859558}
{"mode": "train", "epochs": 12, "timestep": 22003, "ep_reward": 2.5806896686553955, "reward": 0.8440845608711243, "action": 1.0763230323791504}
{"mode": "train", "epochs": 12, "timestep": 22004, "ep_reward": 3.3943099975585938, "reward": 0.8136204481124878, "action": 1.0678343772888184}
{"mode": "train", "epochs": 12, "timestep": 22005, "ep_reward": 4.165688991546631, "reward": 0.7713788747787476, "action": -0.02064722776412964}
{"mode": "train", "epochs": 12, "timestep": 22006, "ep_reward": 4.873665809631348, "reward": 0.7079769372940063, "action": 0.7430216670036316}
{"mode": "train", "epochs": 12, "timestep": 22007, "ep_reward": 5.507454872131348, "reward": 0.6337890625, "action": 0.31161975860595703}
{"mode": "train", "epochs": 12, "timestep": 22008, "ep_reward": 6.0490522384643555, "reward": 0.5415974259376526, "action": 0.06106007099151611}
{"mode": "train", "epochs": 12, "timestep": 22009, "ep_reward": 6.482877731323242, "reward": 0.43382537364959717, "action": -1.1391081809997559}
{"mode": "train", "epochs": 12, "timestep": 22010, "ep_reward": 6.784815788269043, "reward": 0.30193793773651123, "action": -0.8103573322296143}
{"mode": "train", "epochs": 12, "timestep": 22011, "ep_reward": 6.9521989822387695, "reward": 0.16738301515579224, "action": -0.022155821323394775}
{"mode": "train", "epochs": 12, "timestep": 22012, "ep_reward": 7.227060317993164, "reward": 0.27486157417297363, "action": -1.0916303396224976}
{"mode": "train", "epochs": 12, "timestep": 22013, "ep_reward": 7.6045966148376465, "reward": 0.37753623723983765, "action": 0.3837530016899109}
{"mode": "train", "epochs": 12, "timestep": 22014, "ep_reward": 8.096490859985352, "reward": 0.49189430475234985, "action": -1.2849149703979492}
{"mode": "train", "epochs": 12, "timestep": 22015, "ep_reward": 8.680231094360352, "reward": 0.5837407112121582, "action": -0.9363275766372681}
{"mode": "train", "epochs": 12, "timestep": 22016, "ep_reward": 9.349220275878906, "reward": 0.6689896583557129, "action": 0.5697221159934998}
{"mode": "train", "epochs": 12, "timestep": 22017, "ep_reward": 10.098999977111816, "reward": 0.7497798800468445, "action": -0.4723206162452698}
{"mode": "train", "epochs": 12, "timestep": 22018, "ep_reward": 10.905948638916016, "reward": 0.8069488406181335, "action": -0.6630837917327881}
{"mode": "train", "epochs": 12, "timestep": 22019, "ep_reward": 11.755210876464844, "reward": 0.8492622971534729, "action": -0.7593818306922913}
{"mode": "train", "epochs": 12, "timestep": 22020, "ep_reward": 12.634325981140137, "reward": 0.8791151642799377, "action": -1.0953933000564575}
{"mode": "train", "epochs": 12, "timestep": 22021, "ep_reward": 13.532370567321777, "reward": 0.8980449438095093, "action": -1.7345504760742188}
{"mode": "train", "epochs": 12, "timestep": 22022, "ep_reward": 14.441092491149902, "reward": 0.9087223410606384, "action": -1.3883044719696045}
{"mode": "train", "epochs": 12, "timestep": 22023, "ep_reward": 15.35444164276123, "reward": 0.9133487939834595, "action": -1.0249648094177246}
{"mode": "train", "epochs": 12, "timestep": 22024, "ep_reward": 16.265260696411133, "reward": 0.9108191728591919, "action": -0.8629512190818787}
{"mode": "train", "epochs": 12, "timestep": 22025, "ep_reward": 17.16524314880371, "reward": 0.8999818563461304, "action": -0.9259448647499084}
{"mode": "train", "epochs": 12, "timestep": 22026, "ep_reward": 18.04555892944336, "reward": 0.8803165555000305, "action": 0.022687971591949463}
{"mode": "train", "epochs": 12, "timestep": 22027, "ep_reward": 18.89095687866211, "reward": 0.8453973531723022, "action": -0.41610267758369446}
{"mode": "train", "epochs": 12, "timestep": 22028, "ep_reward": 19.688587188720703, "reward": 0.797630250453949, "action": 0.30405139923095703}
{"mode": "train", "epochs": 12, "timestep": 22029, "ep_reward": 20.41631317138672, "reward": 0.7277258634567261, "action": 0.8436501622200012}
{"mode": "train", "epochs": 12, "timestep": 22030, "ep_reward": 21.047685623168945, "reward": 0.6313716173171997, "action": -0.4685046672821045}
{"mode": "train", "epochs": 12, "timestep": 22031, "ep_reward": 21.574377059936523, "reward": 0.5266908407211304, "action": 0.41440629959106445}
{"mode": "train", "epochs": 12, "timestep": 22032, "ep_reward": 21.970407485961914, "reward": 0.3960305452346802, "action": 0.0832739919424057}
{"mode": "train", "epochs": 12, "timestep": 22033, "ep_reward": 22.22808265686035, "reward": 0.25767529010772705, "action": -0.3171558976173401}
{"mode": "train", "epochs": 12, "timestep": 22034, "ep_reward": 22.35409927368164, "reward": 0.12601572275161743, "action": 0.28105291724205017}
{"mode": "train", "epochs": 12, "timestep": 22035, "ep_reward": 22.59734535217285, "reward": 0.24324536323547363, "action": -0.22195205092430115}
{"mode": "train", "epochs": 12, "timestep": 22036, "ep_reward": 22.96527862548828, "reward": 0.36793410778045654, "action": -1.0726500749588013}
{"mode": "train", "epochs": 12, "timestep": 22037, "ep_reward": 23.460573196411133, "reward": 0.4952939748764038, "action": -1.0979344844818115}
{"mode": "train", "epochs": 12, "timestep": 22038, "ep_reward": 24.06881332397461, "reward": 0.6082393527030945, "action": 1.5711876153945923}
{"mode": "train", "epochs": 12, "timestep": 22039, "ep_reward": 24.75439453125, "reward": 0.6855820417404175, "action": 1.1309514045715332}
{"mode": "train", "epochs": 12, "timestep": 22040, "ep_reward": 25.508668899536133, "reward": 0.7542747259140015, "action": 1.5619659423828125}
{"mode": "train", "epochs": 12, "timestep": 22041, "ep_reward": 26.316598892211914, "reward": 0.8079292178153992, "action": 1.486806035041809}
{"mode": "train", "epochs": 12, "timestep": 22042, "ep_reward": 27.167551040649414, "reward": 0.8509526252746582, "action": 0.5841292142868042}
{"mode": "train", "epochs": 12, "timestep": 22043, "ep_reward": 28.054201126098633, "reward": 0.886650800704956, "action": 0.8420727849006653}
{"mode": "train", "epochs": 12, "timestep": 22044, "ep_reward": 28.965171813964844, "reward": 0.9109713435173035, "action": 0.3913920521736145}
{"mode": "train", "epochs": 12, "timestep": 22045, "ep_reward": 29.892372131347656, "reward": 0.9272006154060364, "action": 0.49577850103378296}
{"mode": "train", "epochs": 12, "timestep": 22046, "ep_reward": 30.82699203491211, "reward": 0.9346200823783875, "action": 1.9990460872650146}
{"mode": "train", "epochs": 12, "timestep": 22047, "ep_reward": 31.76325225830078, "reward": 0.9362607002258301, "action": 1.5843126773834229}
{"mode": "train", "epochs": 12, "timestep": 22048, "ep_reward": 32.696964263916016, "reward": 0.9337132573127747, "action": 1.2958630323410034}
{"mode": "train", "epochs": 12, "timestep": 22049, "ep_reward": 33.62275695800781, "reward": 0.9257926940917969, "action": 0.7741382718086243}
{"mode": "train", "epochs": 12, "timestep": 22050, "ep_reward": 34.532649993896484, "reward": 0.9098923802375793, "action": 1.0627223253250122}
{"mode": "train", "epochs": 12, "timestep": 22051, "ep_reward": 35.419105529785156, "reward": 0.8864550590515137, "action": 0.9387480020523071}
{"mode": "train", "epochs": 12, "timestep": 22052, "ep_reward": 36.27153396606445, "reward": 0.8524301052093506, "action": 2.0}
{"mode": "train", "epochs": 12, "timestep": 22053, "ep_reward": 37.08539581298828, "reward": 0.8138617277145386, "action": 1.3318102359771729}
{"mode": "train", "epochs": 12, "timestep": 22054, "ep_reward": 37.84530258178711, "reward": 0.7599077224731445, "action": 1.568270206451416}
{"mode": "train", "epochs": 12, "timestep": 22055, "ep_reward": 38.539939880371094, "reward": 0.6946392059326172, "action": 0.9888944029808044}
{"mode": "train", "epochs": 12, "timestep": 22056, "ep_reward": 39.15050506591797, "reward": 0.6105648279190063, "action": 0.5942879319190979}
{"mode": "train", "epochs": 12, "timestep": 22057, "ep_reward": 39.658485412597656, "reward": 0.5079820156097412, "action": 1.4092540740966797}
{"mode": "train", "epochs": 12, "timestep": 22058, "ep_reward": 40.06242370605469, "reward": 0.40393829345703125, "action": -0.7765397429466248}
{"mode": "train", "epochs": 12, "timestep": 22059, "ep_reward": 40.329917907714844, "reward": 0.2674948573112488, "action": -1.3892788887023926}
{"mode": "train", "epochs": 12, "timestep": 22060, "ep_reward": 40.4848518371582, "reward": 0.15493285655975342, "action": -1.3042246103286743}
{"mode": "train", "epochs": 12, "timestep": 22061, "ep_reward": 40.74519729614258, "reward": 0.26034408807754517, "action": -0.9561011791229248}
{"mode": "train", "epochs": 12, "timestep": 22062, "ep_reward": 41.11892318725586, "reward": 0.373727023601532, "action": 0.26800304651260376}
{"mode": "train", "epochs": 12, "timestep": 22063, "ep_reward": 41.61540603637695, "reward": 0.49648356437683105, "action": 0.27441728115081787}
{"mode": "train", "epochs": 12, "timestep": 22064, "ep_reward": 42.22257614135742, "reward": 0.6071717739105225, "action": 0.22695153951644897}
{"mode": "train", "epochs": 12, "timestep": 22065, "ep_reward": 42.92327117919922, "reward": 0.7006943225860596, "action": -1.255820393562317}
{"mode": "train", "epochs": 12, "timestep": 22066, "ep_reward": 43.69093704223633, "reward": 0.7676647901535034, "action": 0.3257264494895935}
{"mode": "train", "epochs": 12, "timestep": 22067, "ep_reward": 44.51978302001953, "reward": 0.8288469910621643, "action": -1.4667174816131592}
{"mode": "train", "epochs": 12, "timestep": 22068, "ep_reward": 45.386714935302734, "reward": 0.8669313192367554, "action": -1.514953374862671}
{"mode": "train", "epochs": 12, "timestep": 22069, "ep_reward": 46.2823371887207, "reward": 0.8956224322319031, "action": -1.3576281070709229}
{"mode": "train", "epochs": 12, "timestep": 22070, "ep_reward": 47.19940948486328, "reward": 0.917073667049408, "action": -0.58931565284729}
{"mode": "train", "epochs": 12, "timestep": 22071, "ep_reward": 48.1319694519043, "reward": 0.9325588941574097, "action": -1.4262200593948364}
{"mode": "train", "epochs": 12, "timestep": 22072, "ep_reward": 49.07245635986328, "reward": 0.9404858350753784, "action": -1.601149320602417}
{"mode": "train", "epochs": 12, "timestep": 22073, "ep_reward": 50.01654815673828, "reward": 0.9440926313400269, "action": -0.06641358137130737}
{"mode": "train", "epochs": 12, "timestep": 22074, "ep_reward": 50.95813751220703, "reward": 0.9415885806083679, "action": 0.09526413679122925}
{"mode": "train", "epochs": 12, "timestep": 22075, "ep_reward": 51.88833999633789, "reward": 0.9302034378051758, "action": -1.2615374326705933}
{"mode": "train", "epochs": 12, "timestep": 22076, "ep_reward": 52.80255126953125, "reward": 0.9142119884490967, "action": -0.9766377210617065}
{"mode": "train", "epochs": 12, "timestep": 22077, "ep_reward": 53.692142486572266, "reward": 0.8895922899246216, "action": -1.3759218454360962}
{"mode": "train", "epochs": 12, "timestep": 22078, "ep_reward": 54.54970169067383, "reward": 0.8575589656829834, "action": -0.9708811044692993}
{"mode": "train", "epochs": 12, "timestep": 22079, "ep_reward": 55.36188888549805, "reward": 0.8121854066848755, "action": -0.513994574546814}
{"mode": "train", "epochs": 12, "timestep": 22080, "ep_reward": 56.110843658447266, "reward": 0.7489544153213501, "action": 0.11051646620035172}
{"mode": "train", "epochs": 12, "timestep": 22081, "ep_reward": 56.77262496948242, "reward": 0.6617823839187622, "action": 0.05318315699696541}
{"mode": "train", "epochs": 12, "timestep": 22082, "ep_reward": 57.326576232910156, "reward": 0.5539513826370239, "action": -1.0459926128387451}
{"mode": "train", "epochs": 12, "timestep": 22083, "ep_reward": 57.768104553222656, "reward": 0.4415273070335388, "action": -0.7468687295913696}
{"mode": "train", "epochs": 12, "timestep": 22084, "ep_reward": 58.084327697753906, "reward": 0.3162238597869873, "action": -0.7535668611526489}
{"mode": "train", "epochs": 12, "timestep": 22085, "ep_reward": 58.27290725708008, "reward": 0.1885785460472107, "action": -0.1424926519393921}
{"mode": "train", "epochs": 12, "timestep": 22086, "ep_reward": 58.47637939453125, "reward": 0.20347237586975098, "action": -0.64151531457901}
{"mode": "train", "epochs": 12, "timestep": 22087, "ep_reward": 58.80488204956055, "reward": 0.32850122451782227, "action": -1.1698850393295288}
{"mode": "train", "epochs": 12, "timestep": 22088, "ep_reward": 59.25933074951172, "reward": 0.4544471502304077, "action": -1.417952299118042}
{"mode": "train", "epochs": 12, "timestep": 22089, "ep_reward": 59.829673767089844, "reward": 0.5703411102294922, "action": -0.11143969744443893}
{"mode": "train", "epochs": 12, "timestep": 22090, "ep_reward": 60.48969268798828, "reward": 0.6600193977355957, "action": 0.583548367023468}
{"mode": "train", "epochs": 12, "timestep": 22091, "ep_reward": 61.220272064208984, "reward": 0.7305776476860046, "action": 1.519957423210144}
{"mode": "train", "epochs": 12, "timestep": 22092, "ep_reward": 62.00379180908203, "reward": 0.7835180759429932, "action": 1.523666262626648}
{"mode": "train", "epochs": 12, "timestep": 22093, "ep_reward": 62.82971954345703, "reward": 0.8259263634681702, "action": 1.2901917695999146}
{"mode": "train", "epochs": 12, "timestep": 22094, "ep_reward": 63.688819885253906, "reward": 0.8590989112854004, "action": -0.3056154251098633}
{"mode": "train", "epochs": 12, "timestep": 22095, "ep_reward": 64.57340240478516, "reward": 0.8845821619033813, "action": 0.774875819683075}
{"mode": "train", "epochs": 12, "timestep": 22096, "ep_reward": 65.46944427490234, "reward": 0.896044135093689, "action": 1.6053380966186523}
{"mode": "train", "epochs": 12, "timestep": 22097, "ep_reward": 66.36859130859375, "reward": 0.8991435766220093, "action": 1.2520767450332642}
{"mode": "train", "epochs": 12, "timestep": 22098, "ep_reward": 67.26353454589844, "reward": 0.8949452638626099, "action": 0.618316113948822}
{"mode": "train", "epochs": 12, "timestep": 22099, "ep_reward": 68.14415740966797, "reward": 0.8806223273277283, "action": 1.246834635734558}
{"mode": "train", "epochs": 12, "timestep": 22100, "ep_reward": 69.00222778320312, "reward": 0.8580711483955383, "action": 1.0564497709274292}
{"mode": "train", "epochs": 12, "timestep": 22101, "ep_reward": 69.82666015625, "reward": 0.8244320154190063, "action": 1.054257869720459}
{"mode": "train", "epochs": 12, "timestep": 22102, "ep_reward": 70.60533905029297, "reward": 0.7786811590194702, "action": 1.128961205482483}
{"mode": "train", "epochs": 12, "timestep": 22103, "ep_reward": 71.32559967041016, "reward": 0.7202618718147278, "action": 0.7550837993621826}
{"mode": "train", "epochs": 12, "timestep": 22104, "ep_reward": 71.97034454345703, "reward": 0.6447464227676392, "action": 1.2208667993545532}
{"mode": "train", "epochs": 12, "timestep": 22105, "ep_reward": 72.53010559082031, "reward": 0.5597620606422424, "action": 1.3138689994812012}
{"mode": "train", "epochs": 12, "timestep": 22106, "ep_reward": 72.99614715576172, "reward": 0.46603924036026, "action": -1.0048904418945312}
{"mode": "train", "epochs": 12, "timestep": 22107, "ep_reward": 73.33443450927734, "reward": 0.3382853865623474, "action": -1.118959665298462}
{"mode": "train", "epochs": 12, "timestep": 22108, "ep_reward": 73.53473663330078, "reward": 0.20029866695404053, "action": -0.1774314045906067}
{"mode": "train", "epochs": 12, "timestep": 22109, "ep_reward": 73.77745056152344, "reward": 0.2427128553390503, "action": -1.4551753997802734}
{"mode": "train", "epochs": 12, "timestep": 22110, "ep_reward": 74.12024688720703, "reward": 0.3427996039390564, "action": -0.7277885675430298}
{"mode": "train", "epochs": 12, "timestep": 22111, "ep_reward": 74.57144165039062, "reward": 0.4511967897415161, "action": -0.9854663610458374}
{"mode": "train", "epochs": 12, "timestep": 22112, "ep_reward": 75.12374114990234, "reward": 0.552302896976471, "action": -0.9070942401885986}
{"mode": "train", "epochs": 12, "timestep": 22113, "ep_reward": 75.76834869384766, "reward": 0.6446101665496826, "action": -0.4511928856372833}
{"mode": "train", "epochs": 12, "timestep": 22114, "ep_reward": 76.49507141113281, "reward": 0.7267223000526428, "action": -0.8214903473854065}
{"mode": "train", "epochs": 12, "timestep": 22115, "ep_reward": 77.2860336303711, "reward": 0.7909619808197021, "action": -1.2291430234909058}
{"mode": "train", "epochs": 12, "timestep": 22116, "ep_reward": 78.1255874633789, "reward": 0.8395522832870483, "action": -0.502128005027771}
{"mode": "train", "epochs": 12, "timestep": 22117, "ep_reward": 79.00480651855469, "reward": 0.8792210817337036, "action": -0.8926395177841187}
{"mode": "train", "epochs": 12, "timestep": 22118, "ep_reward": 79.9111328125, "reward": 0.9063242673873901, "action": -0.9623239040374756}
{"mode": "train", "epochs": 12, "timestep": 22119, "ep_reward": 80.83584594726562, "reward": 0.9247151613235474, "action": -0.08070898056030273}
{"mode": "train", "epochs": 12, "timestep": 22120, "ep_reward": 81.7719955444336, "reward": 0.9361525774002075, "action": -1.619041085243225}
{"mode": "train", "epochs": 12, "timestep": 22121, "ep_reward": 82.71199035644531, "reward": 0.9399982690811157, "action": -1.3959380388259888}
{"mode": "train", "epochs": 12, "timestep": 22122, "ep_reward": 83.65147399902344, "reward": 0.9394850730895996, "action": -0.7028300166130066}
{"mode": "train", "epochs": 12, "timestep": 22123, "ep_reward": 84.58417510986328, "reward": 0.9327015280723572, "action": -0.5145288705825806}
{"mode": "train", "epochs": 12, "timestep": 22124, "ep_reward": 85.50211334228516, "reward": 0.917941689491272, "action": -1.4201773405075073}
{"mode": "train", "epochs": 12, "timestep": 22125, "ep_reward": 86.40035247802734, "reward": 0.8982424139976501, "action": -0.2943998873233795}
{"mode": "train", "epochs": 12, "timestep": 22126, "ep_reward": 87.26488494873047, "reward": 0.8645289540290833, "action": -0.22736769914627075}
{"mode": "train", "epochs": 12, "timestep": 22127, "ep_reward": 88.08130645751953, "reward": 0.8164216876029968, "action": -0.5843632221221924}
{"mode": "train", "epochs": 12, "timestep": 22128, "ep_reward": 88.83580017089844, "reward": 0.7544964551925659, "action": 0.5136809349060059}
{"mode": "train", "epochs": 12, "timestep": 22129, "ep_reward": 89.50003814697266, "reward": 0.6642358303070068, "action": 0.14720824360847473}
{"mode": "train", "epochs": 12, "timestep": 22130, "ep_reward": 90.05477142333984, "reward": 0.5547361373901367, "action": -0.25887244939804077}
{"mode": "train", "epochs": 12, "timestep": 22131, "ep_reward": 90.4854965209961, "reward": 0.43072617053985596, "action": -0.04195454716682434}
{"mode": "train", "epochs": 12, "timestep": 22132, "ep_reward": 90.77638244628906, "reward": 0.2908822298049927, "action": -1.8890697956085205}
{"mode": "train", "epochs": 12, "timestep": 22133, "ep_reward": 90.9505615234375, "reward": 0.17417585849761963, "action": -0.26141154766082764}
{"mode": "train", "epochs": 12, "timestep": 22134, "ep_reward": 91.15259552001953, "reward": 0.20203369855880737, "action": -0.9298717379570007}
{"mode": "train", "epochs": 12, "timestep": 22135, "ep_reward": 91.48436737060547, "reward": 0.33177071809768677, "action": -0.48211848735809326}
{"mode": "train", "epochs": 12, "timestep": 22136, "ep_reward": 91.93722534179688, "reward": 0.4528545141220093, "action": -0.886486291885376}
{"mode": "train", "epochs": 12, "timestep": 22137, "ep_reward": 92.50477600097656, "reward": 0.5675479769706726, "action": 0.5586261749267578}
{"mode": "train", "epochs": 12, "timestep": 22138, "ep_reward": 93.1611328125, "reward": 0.6563529968261719, "action": 1.467583417892456}
{"mode": "train", "epochs": 12, "timestep": 22139, "ep_reward": 93.88764953613281, "reward": 0.7265153527259827, "action": 1.2539622783660889}
{"mode": "train", "epochs": 12, "timestep": 22140, "ep_reward": 94.67383575439453, "reward": 0.7861886024475098, "action": 0.5019336938858032}
{"mode": "train", "epochs": 12, "timestep": 22141, "ep_reward": 95.51036071777344, "reward": 0.836527407169342, "action": 1.1607515811920166}
{"mode": "train", "epochs": 12, "timestep": 22142, "ep_reward": 96.38195037841797, "reward": 0.8715860843658447, "action": 1.17437744140625}
{"mode": "train", "epochs": 12, "timestep": 22143, "ep_reward": 97.27877807617188, "reward": 0.8968306183815002, "action": 1.450093150138855}
{"mode": "train", "epochs": 12, "timestep": 22144, "ep_reward": 98.1923599243164, "reward": 0.9135825037956238, "action": 0.9563725590705872}
{"mode": "train", "epochs": 12, "timestep": 22145, "ep_reward": 99.11629486083984, "reward": 0.9239380359649658, "action": 0.9526298642158508}
{"mode": "train", "epochs": 12, "timestep": 22146, "ep_reward": 100.04350280761719, "reward": 0.927209198474884, "action": 0.5824328660964966}
{"mode": "train", "epochs": 12, "timestep": 22147, "ep_reward": 100.96629333496094, "reward": 0.9227939248085022, "action": 1.2851990461349487}
{"mode": "train", "epochs": 12, "timestep": 22148, "ep_reward": 101.87841033935547, "reward": 0.9121199250221252, "action": 1.154338002204895}
{"mode": "train", "epochs": 12, "timestep": 22149, "ep_reward": 102.77218627929688, "reward": 0.8937721252441406, "action": 1.5939464569091797}
{"mode": "train", "epochs": 12, "timestep": 22150, "ep_reward": 103.64115142822266, "reward": 0.8689686059951782, "action": 1.166378140449524}
{"mode": "train", "epochs": 12, "timestep": 22151, "ep_reward": 104.473876953125, "reward": 0.8327265381813049, "action": 1.373546838760376}
{"mode": "train", "epochs": 12, "timestep": 22152, "ep_reward": 105.260009765625, "reward": 0.7861294746398926, "action": 0.7337741255760193}
{"mode": "train", "epochs": 12, "timestep": 22153, "ep_reward": 105.9814682006836, "reward": 0.721459150314331, "action": -0.04216885566711426}
{"mode": "train", "epochs": 12, "timestep": 22154, "ep_reward": 106.6142807006836, "reward": 0.6328102946281433, "action": 1.010698676109314}
{"mode": "train", "epochs": 12, "timestep": 22155, "ep_reward": 107.15131378173828, "reward": 0.5370293855667114, "action": -0.45535069704055786}
{"mode": "train", "epochs": 12, "timestep": 22156, "ep_reward": 107.5625, "reward": 0.41118359565734863, "action": -0.5402639508247375}
{"mode": "train", "epochs": 12, "timestep": 22157, "ep_reward": 107.83413696289062, "reward": 0.27163875102996826, "action": -0.3685188889503479}
{"mode": "train", "epochs": 12, "timestep": 22158, "ep_reward": 107.96392822265625, "reward": 0.12979024648666382, "action": -1.1593888998031616}
{"mode": "train", "epochs": 12, "timestep": 22159, "ep_reward": 108.19832611083984, "reward": 0.23439675569534302, "action": -1.4487758874893188}
{"mode": "train", "epochs": 12, "timestep": 22160, "ep_reward": 108.54313659667969, "reward": 0.3448074460029602, "action": 0.12993428111076355}
{"mode": "train", "epochs": 12, "timestep": 22161, "ep_reward": 109.01400756835938, "reward": 0.47087472677230835, "action": -0.09005323052406311}
{"mode": "train", "epochs": 12, "timestep": 22162, "ep_reward": 109.59813690185547, "reward": 0.5841317176818848, "action": 0.007802903652191162}
{"mode": "train", "epochs": 12, "timestep": 22163, "ep_reward": 110.28085327148438, "reward": 0.6827198266983032, "action": -1.0903676748275757}
{"mode": "train", "epochs": 12, "timestep": 22164, "ep_reward": 111.03712463378906, "reward": 0.7562739253044128, "action": -1.3252252340316772}
{"mode": "train", "epochs": 12, "timestep": 22165, "ep_reward": 111.85138702392578, "reward": 0.8142625093460083, "action": -1.087570071220398}
{"mode": "train", "epochs": 12, "timestep": 22166, "ep_reward": 112.71224212646484, "reward": 0.8608547449111938, "action": -0.8014275431632996}
{"mode": "train", "epochs": 12, "timestep": 22167, "ep_reward": 113.60942840576172, "reward": 0.8971894383430481, "action": -0.8042639493942261}
{"mode": "train", "epochs": 12, "timestep": 22168, "ep_reward": 114.53305053710938, "reward": 0.9236209988594055, "action": -1.0554100275039673}
{"mode": "train", "epochs": 12, "timestep": 22169, "ep_reward": 115.47486114501953, "reward": 0.9418073296546936, "action": -0.8994529247283936}
{"mode": "train", "epochs": 12, "timestep": 22170, "ep_reward": 116.4295883178711, "reward": 0.9547298550605774, "action": -0.34665679931640625}
{"mode": "train", "epochs": 12, "timestep": 22171, "ep_reward": 117.39292907714844, "reward": 0.9633442163467407, "action": -0.7719447016716003}
{"mode": "train", "epochs": 12, "timestep": 22172, "ep_reward": 118.36006164550781, "reward": 0.9671289324760437, "action": -0.4906402826309204}
{"mode": "train", "epochs": 12, "timestep": 22173, "ep_reward": 119.32708740234375, "reward": 0.9670281410217285, "action": -1.0134245157241821}
{"mode": "train", "epochs": 12, "timestep": 22174, "ep_reward": 120.29070281982422, "reward": 0.9636180400848389, "action": -1.1767096519470215}
{"mode": "train", "epochs": 12, "timestep": 22175, "ep_reward": 121.24794006347656, "reward": 0.9572362899780273, "action": -0.5116268396377563}
{"mode": "train", "epochs": 12, "timestep": 22176, "ep_reward": 122.1928939819336, "reward": 0.9449506402015686, "action": -1.0653423070907593}
{"mode": "train", "epochs": 12, "timestep": 22177, "ep_reward": 123.12127685546875, "reward": 0.9283844232559204, "action": -1.0841035842895508}
{"mode": "train", "epochs": 12, "timestep": 22178, "ep_reward": 124.02644348144531, "reward": 0.9051674008369446, "action": -1.0522122383117676}
{"mode": "train", "epochs": 12, "timestep": 22179, "ep_reward": 124.89957427978516, "reward": 0.8731329441070557, "action": -0.6426522135734558}
{"mode": "train", "epochs": 12, "timestep": 22180, "ep_reward": 125.72655487060547, "reward": 0.8269805908203125, "action": -1.0428907871246338}
{"mode": "train", "epochs": 12, "timestep": 22181, "ep_reward": 126.49556732177734, "reward": 0.769011378288269, "action": -0.9838818311691284}
{"mode": "train", "epochs": 12, "timestep": 22182, "ep_reward": 127.19012451171875, "reward": 0.6945549845695496, "action": 0.05346101522445679}
{"mode": "train", "epochs": 12, "timestep": 22183, "ep_reward": 127.78125762939453, "reward": 0.5911306738853455, "action": -0.6806536912918091}
{"mode": "train", "epochs": 12, "timestep": 22184, "ep_reward": 128.2573699951172, "reward": 0.4761127829551697, "action": -1.3883204460144043}
{"mode": "train", "epochs": 12, "timestep": 22185, "ep_reward": 128.6151580810547, "reward": 0.35779237747192383, "action": -1.2968111038208008}
{"mode": "train", "epochs": 12, "timestep": 22186, "ep_reward": 128.85011291503906, "reward": 0.2349492907524109, "action": -1.1909167766571045}
{"mode": "train", "epochs": 12, "timestep": 22187, "ep_reward": 129.00967407226562, "reward": 0.1595563292503357, "action": -1.0396783351898193}
{"mode": "train", "epochs": 12, "timestep": 22188, "ep_reward": 129.29571533203125, "reward": 0.2860413193702698, "action": -1.7211062908172607}
{"mode": "train", "epochs": 12, "timestep": 22189, "ep_reward": 129.71153259277344, "reward": 0.41581422090530396, "action": 0.052862703800201416}
{"mode": "train", "epochs": 12, "timestep": 22190, "ep_reward": 130.232421875, "reward": 0.5208877325057983, "action": -0.6242775917053223}
{"mode": "train", "epochs": 12, "timestep": 22191, "ep_reward": 130.85293579101562, "reward": 0.620507001876831, "action": 0.7837963700294495}
{"mode": "train", "epochs": 12, "timestep": 22192, "ep_reward": 131.5489044189453, "reward": 0.6959696412086487, "action": 1.6986103057861328}
{"mode": "train", "epochs": 12, "timestep": 22193, "ep_reward": 132.30355834960938, "reward": 0.7546569108963013, "action": 1.0675077438354492}
{"mode": "train", "epochs": 12, "timestep": 22194, "ep_reward": 133.10906982421875, "reward": 0.8055076599121094, "action": 1.2902073860168457}
{"mode": "train", "epochs": 12, "timestep": 22195, "ep_reward": 133.95291137695312, "reward": 0.8438406586647034, "action": 1.5482518672943115}
{"mode": "train", "epochs": 12, "timestep": 22196, "ep_reward": 134.8245849609375, "reward": 0.8716669678688049, "action": 0.9700868129730225}
{"mode": "train", "epochs": 12, "timestep": 22197, "ep_reward": 135.71640014648438, "reward": 0.891817569732666, "action": 0.7380330562591553}
{"mode": "train", "epochs": 12, "timestep": 22198, "ep_reward": 136.6191864013672, "reward": 0.9027910232543945, "action": 1.2720791101455688}
{"mode": "train", "epochs": 12, "timestep": 22199, "ep_reward": 137.5244598388672, "reward": 0.9052689075469971, "action": 0.9746678471565247}
{"mode": "train", "epochs": 12, "timestep": 22200, "ep_reward": 138.4241943359375, "reward": 0.8997374773025513, "action": 1.0348702669143677}
{"mode": "train", "epochs": 12, "timestep": 22201, "ep_reward": 139.30990600585938, "reward": 0.8857173919677734, "action": 1.0865273475646973}
{"mode": "train", "epochs": 12, "timestep": 22202, "ep_reward": 140.17237854003906, "reward": 0.8624693155288696, "action": 1.6003079414367676}
{"mode": "train", "epochs": 12, "timestep": 22203, "ep_reward": 141.004150390625, "reward": 0.8317643404006958, "action": 0.7453336715698242}
{"mode": "train", "epochs": 12, "timestep": 22204, "ep_reward": 141.7894287109375, "reward": 0.7852762341499329, "action": 1.237328290939331}
{"mode": "train", "epochs": 12, "timestep": 22205, "ep_reward": 142.51771545410156, "reward": 0.728282630443573, "action": 0.4803171157836914}
{"mode": "train", "epochs": 12, "timestep": 22206, "ep_reward": 143.1686248779297, "reward": 0.6509032845497131, "action": 0.99425208568573}
{"mode": "train", "epochs": 12, "timestep": 22207, "ep_reward": 143.731689453125, "reward": 0.5630648136138916, "action": 0.18718136847019196}
{"mode": "train", "epochs": 12, "timestep": 22208, "ep_reward": 144.18606567382812, "reward": 0.45437031984329224, "action": -0.010597825050354004}
{"mode": "train", "epochs": 12, "timestep": 22209, "ep_reward": 144.51895141601562, "reward": 0.3328831195831299, "action": -0.9811714291572571}
{"mode": "train", "epochs": 12, "timestep": 22210, "ep_reward": 144.71255493164062, "reward": 0.19359880685806274, "action": -0.5530822277069092}
{"mode": "train", "epochs": 12, "timestep": 22211, "ep_reward": 144.9449462890625, "reward": 0.2323877215385437, "action": 0.12740135192871094}
{"mode": "train", "epochs": 12, "timestep": 22212, "ep_reward": 145.2938690185547, "reward": 0.3489265441894531, "action": -1.4568555355072021}
{"mode": "train", "epochs": 12, "timestep": 22213, "ep_reward": 145.74365234375, "reward": 0.4497833847999573, "action": -1.1779011487960815}
{"mode": "train", "epochs": 12, "timestep": 22214, "ep_reward": 146.29354858398438, "reward": 0.5498981475830078, "action": -0.7154016494750977}
{"mode": "train", "epochs": 12, "timestep": 22215, "ep_reward": 146.93798828125, "reward": 0.6444411277770996, "action": -1.6048755645751953}
{"mode": "train", "epochs": 12, "timestep": 22216, "ep_reward": 147.65744018554688, "reward": 0.7194452285766602, "action": -1.3852970600128174}
{"mode": "train", "epochs": 12, "timestep": 22217, "ep_reward": 148.44093322753906, "reward": 0.7834912538528442, "action": -1.005081295967102}
{"mode": "train", "epochs": 12, "timestep": 22218, "ep_reward": 149.2775421142578, "reward": 0.8366157412528992, "action": -0.9912933111190796}
{"mode": "train", "epochs": 12, "timestep": 22219, "ep_reward": 150.15467834472656, "reward": 0.877133309841156, "action": -2.0}
{"mode": "train", "epochs": 12, "timestep": 22220, "ep_reward": 151.05877685546875, "reward": 0.9041022658348083, "action": -1.8309731483459473}
{"mode": "train", "epochs": 12, "timestep": 22221, "ep_reward": 151.98416137695312, "reward": 0.9253817200660706, "action": -0.8265767693519592}
{"mode": "train", "epochs": 12, "timestep": 22222, "ep_reward": 152.92759704589844, "reward": 0.9434384703636169, "action": -0.9303297400474548}
{"mode": "train", "epochs": 12, "timestep": 22223, "ep_reward": 153.88304138183594, "reward": 0.955450713634491, "action": -1.1583826541900635}
{"mode": "train", "epochs": 12, "timestep": 22224, "ep_reward": 154.84591674804688, "reward": 0.9628769755363464, "action": -1.1741243600845337}
{"mode": "train", "epochs": 12, "timestep": 22225, "ep_reward": 155.8130645751953, "reward": 0.9671419858932495, "action": -0.4276565909385681}
{"mode": "train", "epochs": 12, "timestep": 22226, "ep_reward": 156.78094482421875, "reward": 0.9678784608840942, "action": -2.0}
{"mode": "train", "epochs": 12, "timestep": 22227, "ep_reward": 157.74781799316406, "reward": 0.9668772220611572, "action": -0.8874742388725281}
{"mode": "train", "epochs": 12, "timestep": 22228, "ep_reward": 158.71023559570312, "reward": 0.9624192118644714, "action": -1.2307647466659546}
{"mode": "train", "epochs": 12, "timestep": 22229, "ep_reward": 159.66517639160156, "reward": 0.9549352526664734, "action": -1.773720145225525}
{"mode": "train", "epochs": 12, "timestep": 22230, "ep_reward": 160.61061096191406, "reward": 0.9454341530799866, "action": -1.4765734672546387}
{"mode": "train", "epochs": 12, "timestep": 22231, "ep_reward": 161.54185485839844, "reward": 0.9312425851821899, "action": -0.9267752766609192}
{"mode": "train", "epochs": 12, "timestep": 22232, "ep_reward": 162.45077514648438, "reward": 0.908927321434021, "action": -1.2657606601715088}
{"mode": "train", "epochs": 12, "timestep": 22233, "ep_reward": 163.33062744140625, "reward": 0.8798589706420898, "action": -0.8855293989181519}
{"mode": "train", "epochs": 12, "timestep": 22234, "ep_reward": 164.1688690185547, "reward": 0.8382356762886047, "action": -0.8497136235237122}
{"mode": "train", "epochs": 12, "timestep": 22235, "ep_reward": 164.9515380859375, "reward": 0.782676100730896, "action": 0.03700333833694458}
{"mode": "train", "epochs": 12, "timestep": 22236, "ep_reward": 165.65390014648438, "reward": 0.7023664712905884, "action": -0.5373623967170715}
{"mode": "train", "epochs": 12, "timestep": 22237, "ep_reward": 166.26058959960938, "reward": 0.6066889762878418, "action": -1.0685726404190063}
{"mode": "train", "epochs": 12, "timestep": 22238, "ep_reward": 166.75979614257812, "reward": 0.4992082118988037, "action": -0.8113028407096863}
{"mode": "train", "epochs": 12, "timestep": 22239, "ep_reward": 167.13565063476562, "reward": 0.37584763765335083, "action": -0.9928591847419739}
{"mode": "train", "epochs": 12, "timestep": 22240, "ep_reward": 167.38412475585938, "reward": 0.24846923351287842, "action": -0.9436988234519958}
{"mode": "train", "epochs": 12, "timestep": 22241, "ep_reward": 167.5198974609375, "reward": 0.13576912879943848, "action": -0.7362325191497803}
{"mode": "train", "epochs": 12, "timestep": 22242, "ep_reward": 167.78131103515625, "reward": 0.2614102363586426, "action": -1.1167662143707275}
{"mode": "train", "epochs": 12, "timestep": 22243, "ep_reward": 168.17105102539062, "reward": 0.38974231481552124, "action": -1.0646613836288452}
{"mode": "train", "epochs": 12, "timestep": 22244, "ep_reward": 168.6804962158203, "reward": 0.5094403028488159, "action": -0.08319348096847534}
{"mode": "train", "epochs": 12, "timestep": 22245, "ep_reward": 169.28875732421875, "reward": 0.6082683205604553, "action": 1.1345891952514648}
{"mode": "train", "epochs": 12, "timestep": 22246, "ep_reward": 169.97459411621094, "reward": 0.6858352422714233, "action": 0.839894711971283}
{"mode": "train", "epochs": 12, "timestep": 22247, "ep_reward": 170.7277069091797, "reward": 0.7531059980392456, "action": 0.7219766974449158}
{"mode": "train", "epochs": 12, "timestep": 22248, "ep_reward": 171.53500366210938, "reward": 0.8072989583015442, "action": 1.5286850929260254}
{"mode": "train", "epochs": 12, "timestep": 22249, "ep_reward": 172.38096618652344, "reward": 0.845961332321167, "action": 1.1487913131713867}
{"mode": "train", "epochs": 12, "timestep": 22250, "ep_reward": 173.25694274902344, "reward": 0.8759796023368835, "action": 1.144134521484375}
{"mode": "train", "epochs": 12, "timestep": 22251, "ep_reward": 174.15350341796875, "reward": 0.8965544104576111, "action": 1.4672760963439941}
{"mode": "train", "epochs": 12, "timestep": 22252, "ep_reward": 175.06236267089844, "reward": 0.9088635444641113, "action": 0.8839627504348755}
{"mode": "train", "epochs": 12, "timestep": 22253, "ep_reward": 175.97645568847656, "reward": 0.9140999913215637, "action": 1.354409098625183}
{"mode": "train", "epochs": 12, "timestep": 22254, "ep_reward": 176.88865661621094, "reward": 0.9122058153152466, "action": 1.0307737588882446}
{"mode": "train", "epochs": 12, "timestep": 22255, "ep_reward": 177.7914276123047, "reward": 0.9027642607688904, "action": 0.23406267166137695}
{"mode": "train", "epochs": 12, "timestep": 22256, "ep_reward": 178.6730499267578, "reward": 0.8816213011741638, "action": 1.699237585067749}
{"mode": "train", "epochs": 12, "timestep": 22257, "ep_reward": 179.5286865234375, "reward": 0.8556420803070068, "action": 0.8713608980178833}
{"mode": "train", "epochs": 12, "timestep": 22258, "ep_reward": 180.34429931640625, "reward": 0.8156113028526306, "action": 0.7817691564559937}
{"mode": "train", "epochs": 12, "timestep": 22259, "ep_reward": 181.10569763183594, "reward": 0.7614008188247681, "action": 1.0066572427749634}
{"mode": "train", "epochs": 12, "timestep": 22260, "ep_reward": 181.79969787597656, "reward": 0.6939963102340698, "action": 0.5967810153961182}
{"mode": "train", "epochs": 12, "timestep": 22261, "ep_reward": 182.407470703125, "reward": 0.6077671051025391, "action": 0.13746213912963867}
{"mode": "train", "epochs": 12, "timestep": 22262, "ep_reward": 182.9083709716797, "reward": 0.5008999109268188, "action": 1.8554887771606445}
{"mode": "train", "epochs": 12, "timestep": 22263, "ep_reward": 183.31097412109375, "reward": 0.4025971293449402, "action": 0.549243152141571}
{"mode": "train", "epochs": 12, "timestep": 22264, "ep_reward": 183.5971221923828, "reward": 0.2861427068710327, "action": -0.746070384979248}
{"mode": "train", "epochs": 12, "timestep": 22265, "ep_reward": 183.77586364746094, "reward": 0.1787455677986145, "action": -0.14638429880142212}
{"mode": "train", "epochs": 12, "timestep": 22266, "ep_reward": 184.06387329101562, "reward": 0.28800874948501587, "action": -0.8669993281364441}
{"mode": "train", "epochs": 12, "timestep": 22267, "ep_reward": 184.45654296875, "reward": 0.3926636576652527, "action": -0.3279876708984375}
{"mode": "train", "epochs": 12, "timestep": 22268, "ep_reward": 184.95668029785156, "reward": 0.5001423954963684, "action": -0.8320220112800598}
{"mode": "train", "epochs": 12, "timestep": 22269, "ep_reward": 185.552001953125, "reward": 0.5953155755996704, "action": -1.7729899883270264}
{"mode": "train", "epochs": 12, "timestep": 22270, "ep_reward": 186.22552490234375, "reward": 0.6735289096832275, "action": -1.0942511558532715}
{"mode": "train", "epochs": 12, "timestep": 22271, "ep_reward": 186.97093200683594, "reward": 0.7454040050506592, "action": -0.512413740158081}
{"mode": "train", "epochs": 12, "timestep": 22272, "ep_reward": 187.77743530273438, "reward": 0.8064978122711182, "action": -1.8746740818023682}
{"mode": "train", "epochs": 12, "timestep": 22273, "ep_reward": 188.62545776367188, "reward": 0.8480205535888672, "action": -1.1283409595489502}
{"mode": "train", "epochs": 12, "timestep": 22274, "ep_reward": 189.50840759277344, "reward": 0.8829560279846191, "action": -0.42226773500442505}
{"mode": "train", "epochs": 12, "timestep": 22275, "ep_reward": 190.41830444335938, "reward": 0.9098963141441345, "action": -0.3671923279762268}
{"mode": "train", "epochs": 12, "timestep": 22276, "ep_reward": 191.34532165527344, "reward": 0.92701655626297, "action": -0.062476933002471924}
{"mode": "train", "epochs": 12, "timestep": 22277, "ep_reward": 192.28057861328125, "reward": 0.9352595210075378, "action": -1.4889647960662842}
{"mode": "train", "epochs": 12, "timestep": 22278, "ep_reward": 193.21701049804688, "reward": 0.936436653137207, "action": -0.5837491750717163}
{"mode": "train", "epochs": 12, "timestep": 22279, "ep_reward": 194.14808654785156, "reward": 0.9310694336891174, "action": -0.6964815258979797}
{"mode": "train", "epochs": 12, "timestep": 22280, "ep_reward": 195.06642150878906, "reward": 0.918340265750885, "action": -0.5161290168762207}
{"mode": "train", "epochs": 12, "timestep": 22281, "ep_reward": 195.96278381347656, "reward": 0.8963664770126343, "action": -0.05812901258468628}
{"mode": "train", "epochs": 12, "timestep": 22282, "ep_reward": 196.8237762451172, "reward": 0.8609901666641235, "action": -0.06066739559173584}
{"mode": "train", "epochs": 12, "timestep": 22283, "ep_reward": 197.63429260253906, "reward": 0.8105190992355347, "action": 1.0800557136535645}
{"mode": "train", "epochs": 12, "timestep": 22284, "ep_reward": 198.36660766601562, "reward": 0.7323137521743774, "action": -0.2350209802389145}
{"mode": "train", "epochs": 12, "timestep": 22285, "ep_reward": 199.0087127685547, "reward": 0.642102837562561, "action": -0.48446160554885864}
{"mode": "train", "epochs": 12, "timestep": 22286, "ep_reward": 199.54359436035156, "reward": 0.5348864793777466, "action": -0.23048703372478485}
{"mode": "train", "epochs": 12, "timestep": 22287, "ep_reward": 199.95167541503906, "reward": 0.408083975315094, "action": 0.3682728409767151}
{"mode": "train", "epochs": 12, "timestep": 22288, "ep_reward": 200.212890625, "reward": 0.261211097240448, "action": -0.3848079741001129}
{"mode": "train", "epochs": 12, "timestep": 22289, "ep_reward": 200.33370971679688, "reward": 0.12081563472747803, "action": -0.24784165620803833}
{"mode": "train", "epochs": 12, "timestep": 22290, "ep_reward": 200.5469512939453, "reward": 0.21324723958969116, "action": -1.1269042491912842}
{"mode": "train", "epochs": 12, "timestep": 22291, "ep_reward": 200.89736938476562, "reward": 0.35041534900665283, "action": -0.2878705859184265}
{"mode": "train", "epochs": 12, "timestep": 22292, "ep_reward": 201.37030029296875, "reward": 0.47293001413345337, "action": -1.3034045696258545}
{"mode": "train", "epochs": 12, "timestep": 22293, "ep_reward": 201.96311950683594, "reward": 0.5928242206573486, "action": 1.0005172491073608}
{"mode": "train", "epochs": 12, "timestep": 22294, "ep_reward": 202.6408233642578, "reward": 0.6777040362358093, "action": 0.8238124847412109}
{"mode": "train", "epochs": 12, "timestep": 22295, "ep_reward": 203.3913116455078, "reward": 0.7504916191101074, "action": 1.056262493133545}
{"mode": "train", "epochs": 12, "timestep": 22296, "ep_reward": 204.1992645263672, "reward": 0.8079540729522705, "action": 0.323972225189209}
{"mode": "train", "epochs": 12, "timestep": 22297, "ep_reward": 205.0546417236328, "reward": 0.8553779125213623, "action": 1.1068323850631714}
{"mode": "train", "epochs": 12, "timestep": 22298, "ep_reward": 205.94189453125, "reward": 0.8872482776641846, "action": 1.350063443183899}
{"mode": "train", "epochs": 12, "timestep": 22299, "ep_reward": 206.8514862060547, "reward": 0.9095844626426697, "action": 0.747281014919281}
{"mode": "train", "epochs": 12, "timestep": 22300, "ep_reward": 207.77670288085938, "reward": 0.9252195954322815, "action": 1.7151789665222168}
{"mode": "train", "epochs": 12, "timestep": 22301, "ep_reward": 208.7100067138672, "reward": 0.9333097338676453, "action": 1.5184389352798462}
{"mode": "train", "epochs": 12, "timestep": 22302, "ep_reward": 209.64688110351562, "reward": 0.9368816614151001, "action": 1.3078969717025757}
{"mode": "train", "epochs": 12, "timestep": 22303, "ep_reward": 210.5823516845703, "reward": 0.9354680776596069, "action": 1.5960087776184082}
{"mode": "train", "epochs": 12, "timestep": 22304, "ep_reward": 211.51187133789062, "reward": 0.929512083530426, "action": 1.3424065113067627}
{"mode": "train", "epochs": 12, "timestep": 22305, "ep_reward": 212.4297332763672, "reward": 0.9178565740585327, "action": 0.28084802627563477}
{"mode": "train", "epochs": 12, "timestep": 22306, "ep_reward": 213.32467651367188, "reward": 0.8949456810951233, "action": 1.7830049991607666}
{"mode": "train", "epochs": 12, "timestep": 22307, "ep_reward": 214.19337463378906, "reward": 0.8686975836753845, "action": 0.9600438475608826}
{"mode": "train", "epochs": 12, "timestep": 22308, "ep_reward": 215.0220489501953, "reward": 0.8286811113357544, "action": 1.0908634662628174}
{"mode": "train", "epochs": 12, "timestep": 22309, "ep_reward": 215.79856872558594, "reward": 0.7765201926231384, "action": 1.1323211193084717}
{"mode": "train", "epochs": 12, "timestep": 22310, "ep_reward": 216.50900268554688, "reward": 0.7104318141937256, "action": 0.501413106918335}
{"mode": "train", "epochs": 12, "timestep": 22311, "ep_reward": 217.13180541992188, "reward": 0.6228040456771851, "action": 1.1397470235824585}
{"mode": "train", "epochs": 12, "timestep": 22312, "ep_reward": 217.6575469970703, "reward": 0.5257347822189331, "action": 1.350459098815918}
{"mode": "train", "epochs": 12, "timestep": 22313, "ep_reward": 218.07814025878906, "reward": 0.42060011625289917, "action": 0.7805501818656921}
{"mode": "train", "epochs": 12, "timestep": 22314, "ep_reward": 218.3814697265625, "reward": 0.3033221960067749, "action": 0.813213050365448}
{"mode": "train", "epochs": 12, "timestep": 22315, "ep_reward": 218.568115234375, "reward": 0.18665188550949097, "action": -0.21583500504493713}
{"mode": "train", "epochs": 12, "timestep": 22316, "ep_reward": 218.82875061035156, "reward": 0.2606382369995117, "action": -1.221815586090088}
{"mode": "train", "epochs": 12, "timestep": 22317, "ep_reward": 219.19078063964844, "reward": 0.3620326519012451, "action": -0.9908437728881836}
{"mode": "train", "epochs": 12, "timestep": 22318, "ep_reward": 219.65701293945312, "reward": 0.4662396311759949, "action": -0.43736037611961365}
{"mode": "train", "epochs": 12, "timestep": 22319, "ep_reward": 220.2266082763672, "reward": 0.5696016550064087, "action": -1.4757030010223389}
{"mode": "train", "epochs": 12, "timestep": 22320, "ep_reward": 220.8808135986328, "reward": 0.6542023420333862, "action": -0.9869084358215332}
{"mode": "train", "epochs": 12, "timestep": 22321, "ep_reward": 221.61151123046875, "reward": 0.7307020425796509, "action": -0.9376736283302307}
{"mode": "train", "epochs": 12, "timestep": 22322, "ep_reward": 222.40493774414062, "reward": 0.7934318780899048, "action": -1.6200592517852783}
{"mode": "train", "epochs": 12, "timestep": 22323, "ep_reward": 223.24478149414062, "reward": 0.8398452401161194, "action": -0.6459581255912781}
{"mode": "train", "epochs": 12, "timestep": 22324, "ep_reward": 224.12417602539062, "reward": 0.8793978691101074, "action": -1.0644850730895996}
{"mode": "train", "epochs": 12, "timestep": 22325, "ep_reward": 225.03079223632812, "reward": 0.906612753868103, "action": -1.6423230171203613}
{"mode": "train", "epochs": 12, "timestep": 22326, "ep_reward": 225.95567321777344, "reward": 0.9248824715614319, "action": -0.40845656394958496}
{"mode": "train", "epochs": 12, "timestep": 22327, "ep_reward": 226.89439392089844, "reward": 0.9387165904045105, "action": -1.4903855323791504}
{"mode": "train", "epochs": 12, "timestep": 22328, "ep_reward": 227.83950805664062, "reward": 0.9451215863227844, "action": -2.0}
{"mode": "train", "epochs": 12, "timestep": 22329, "ep_reward": 228.7875213623047, "reward": 0.9480164647102356, "action": -0.9704635143280029}
{"mode": "train", "epochs": 12, "timestep": 22330, "ep_reward": 229.73423767089844, "reward": 0.9467104077339172, "action": -1.5691750049591064}
{"mode": "train", "epochs": 12, "timestep": 22331, "ep_reward": 230.67575073242188, "reward": 0.9415124654769897, "action": -1.6918387413024902}
{"mode": "train", "epochs": 12, "timestep": 22332, "ep_reward": 231.60829162597656, "reward": 0.9325398206710815, "action": -1.3676735162734985}
{"mode": "train", "epochs": 12, "timestep": 22333, "ep_reward": 232.5260772705078, "reward": 0.9177843332290649, "action": -1.01466703414917}
{"mode": "train", "epochs": 12, "timestep": 22334, "ep_reward": 233.42088317871094, "reward": 0.8948124647140503, "action": -0.2960749864578247}
{"mode": "train", "epochs": 12, "timestep": 22335, "ep_reward": 234.27908325195312, "reward": 0.8582057952880859, "action": -0.7332062721252441}
{"mode": "train", "epochs": 12, "timestep": 22336, "ep_reward": 235.0895233154297, "reward": 0.8104374408721924, "action": 0.21466052532196045}
{"mode": "train", "epochs": 12, "timestep": 22337, "ep_reward": 235.82875061035156, "reward": 0.7392306327819824, "action": -0.45864999294281006}
{"mode": "train", "epochs": 12, "timestep": 22338, "ep_reward": 236.4822235107422, "reward": 0.6534655094146729, "action": -0.6964703798294067}
{"mode": "train", "epochs": 12, "timestep": 22339, "ep_reward": 237.03379821777344, "reward": 0.5515681505203247, "action": -1.031567931175232}
{"mode": "train", "epochs": 12, "timestep": 22340, "ep_reward": 237.47244262695312, "reward": 0.43863946199417114, "action": -0.44644200801849365}
{"mode": "train", "epochs": 12, "timestep": 22341, "ep_reward": 237.78123474121094, "reward": 0.3087959289550781, "action": -1.2656830549240112}
{"mode": "train", "epochs": 12, "timestep": 22342, "ep_reward": 237.96888732910156, "reward": 0.1876508593559265, "action": -0.8257904052734375}
{"mode": "train", "epochs": 12, "timestep": 22343, "ep_reward": 238.18304443359375, "reward": 0.21415692567825317, "action": -1.4786468744277954}
{"mode": "train", "epochs": 12, "timestep": 22344, "ep_reward": 238.5269012451172, "reward": 0.34385472536087036, "action": -1.2735416889190674}
{"mode": "train", "epochs": 12, "timestep": 22345, "ep_reward": 238.99205017089844, "reward": 0.4651501178741455, "action": -0.09004765003919601}
{"mode": "train", "epochs": 12, "timestep": 22346, "ep_reward": 239.55809020996094, "reward": 0.566033124923706, "action": 0.6276319026947021}
{"mode": "train", "epochs": 12, "timestep": 22347, "ep_reward": 240.20846557617188, "reward": 0.6503725647926331, "action": 1.2807033061981201}
{"mode": "train", "epochs": 12, "timestep": 22348, "ep_reward": 240.9275360107422, "reward": 0.7190752029418945, "action": 0.35758036375045776}
{"mode": "train", "epochs": 12, "timestep": 22349, "ep_reward": 241.7078094482422, "reward": 0.7802659273147583, "action": 0.8890727162361145}
{"mode": "train", "epochs": 12, "timestep": 22350, "ep_reward": 242.5328826904297, "reward": 0.8250719308853149, "action": 0.8211252689361572}
{"mode": "train", "epochs": 12, "timestep": 22351, "ep_reward": 243.39080810546875, "reward": 0.8579198122024536, "action": 1.7339863777160645}
{"mode": "train", "epochs": 12, "timestep": 22352, "ep_reward": 244.26962280273438, "reward": 0.8788142204284668, "action": 1.5210613012313843}
{"mode": "train", "epochs": 12, "timestep": 22353, "ep_reward": 245.16213989257812, "reward": 0.8925217390060425, "action": 1.4487605094909668}
{"mode": "train", "epochs": 12, "timestep": 22354, "ep_reward": 246.06118774414062, "reward": 0.8990423679351807, "action": 0.8420946598052979}
{"mode": "train", "epochs": 12, "timestep": 22355, "ep_reward": 246.9585418701172, "reward": 0.8973472118377686, "action": 1.3410946130752563}
{"mode": "train", "epochs": 12, "timestep": 22356, "ep_reward": 247.8465118408203, "reward": 0.8879662752151489, "action": 0.5286792516708374}
{"mode": "train", "epochs": 12, "timestep": 22357, "ep_reward": 248.7137451171875, "reward": 0.8672321438789368, "action": 0.6774527430534363}
{"mode": "train", "epochs": 12, "timestep": 22358, "ep_reward": 249.54859924316406, "reward": 0.8348603844642639, "action": 2.0}
{"mode": "train", "epochs": 12, "timestep": 22359, "ep_reward": 250.34677124023438, "reward": 0.7981725931167603, "action": 0.7237504720687866}
{"mode": "train", "epochs": 12, "timestep": 22360, "ep_reward": 251.0891571044922, "reward": 0.7423901557922363, "action": 1.2273645401000977}
{"mode": "train", "epochs": 12, "timestep": 22361, "ep_reward": 251.76515197753906, "reward": 0.6759991645812988, "action": 1.0174952745437622}
{"mode": "train", "epochs": 12, "timestep": 22362, "ep_reward": 252.35984802246094, "reward": 0.5946918725967407, "action": 0.8949278593063354}
{"mode": "train", "epochs": 12, "timestep": 22363, "ep_reward": 252.8600311279297, "reward": 0.5001757144927979, "action": 0.7924697399139404}
{"mode": "train", "epochs": 12, "timestep": 22364, "ep_reward": 253.25587463378906, "reward": 0.3958396911621094, "action": 0.11453258991241455}
{"mode": "train", "epochs": 12, "timestep": 22365, "ep_reward": 253.53500366210938, "reward": 0.27913498878479004, "action": 0.11897459626197815}
{"mode": "train", "epochs": 12, "timestep": 22366, "ep_reward": 253.74986267089844, "reward": 0.21486419439315796, "action": -0.12660402059555054}
{"mode": "train", "epochs": 12, "timestep": 22367, "ep_reward": 254.06858825683594, "reward": 0.31873083114624023, "action": 0.12066929787397385}
{"mode": "train", "epochs": 12, "timestep": 22368, "ep_reward": 254.4934539794922, "reward": 0.4248597025871277, "action": -0.5433622002601624}
{"mode": "train", "epochs": 12, "timestep": 22369, "ep_reward": 255.01461791992188, "reward": 0.5211632251739502, "action": -0.535666286945343}
{"mode": "train", "epochs": 12, "timestep": 22370, "ep_reward": 255.6245880126953, "reward": 0.6099734902381897, "action": -0.3267444372177124}
{"mode": "train", "epochs": 12, "timestep": 22371, "ep_reward": 256.3132019042969, "reward": 0.6886162757873535, "action": -1.2394013404846191}
{"mode": "train", "epochs": 12, "timestep": 22372, "ep_reward": 257.06243896484375, "reward": 0.7492241859436035, "action": -0.9083513021469116}
{"mode": "train", "epochs": 12, "timestep": 22373, "ep_reward": 257.862060546875, "reward": 0.7996227145195007, "action": -0.4923921227455139}
{"mode": "train", "epochs": 12, "timestep": 22374, "ep_reward": 258.7007141113281, "reward": 0.8386492729187012, "action": -1.3433104753494263}
{"mode": "train", "epochs": 12, "timestep": 22375, "ep_reward": 259.5644836425781, "reward": 0.8637599945068359, "action": -1.3316020965576172}
{"mode": "train", "epochs": 12, "timestep": 22376, "ep_reward": 260.4443664550781, "reward": 0.8798912167549133, "action": -1.354170322418213}
{"mode": "train", "epochs": 12, "timestep": 22377, "ep_reward": 261.33203125, "reward": 0.8876561522483826, "action": -1.5857164859771729}
{"mode": "train", "epochs": 12, "timestep": 22378, "ep_reward": 262.2200012207031, "reward": 0.8879695534706116, "action": -1.1290748119354248}
{"mode": "train", "epochs": 12, "timestep": 22379, "ep_reward": 263.0999755859375, "reward": 0.8799628615379333, "action": -0.5912948846817017}
{"mode": "train", "epochs": 12, "timestep": 22380, "ep_reward": 263.960693359375, "reward": 0.8607205152511597, "action": -1.0342168807983398}
{"mode": "train", "epochs": 12, "timestep": 22381, "ep_reward": 264.79229736328125, "reward": 0.8315891027450562, "action": -1.154313564300537}
{"mode": "train", "epochs": 12, "timestep": 22382, "ep_reward": 265.5838928222656, "reward": 0.7915817499160767, "action": 0.41807466745376587}
{"mode": "train", "epochs": 12, "timestep": 22383, "ep_reward": 266.31103515625, "reward": 0.727157473564148, "action": 0.2591181695461273}
{"mode": "train", "epochs": 12, "timestep": 22384, "ep_reward": 266.954833984375, "reward": 0.6438117027282715, "action": 0.5525405406951904}
{"mode": "train", "epochs": 12, "timestep": 22385, "ep_reward": 267.4927062988281, "reward": 0.5378715991973877, "action": -0.28706881403923035}
{"mode": "train", "epochs": 12, "timestep": 22386, "ep_reward": 267.9169006347656, "reward": 0.42420363426208496, "action": 0.5730525851249695}
{"mode": "train", "epochs": 12, "timestep": 22387, "ep_reward": 268.2070617675781, "reward": 0.2901749014854431, "action": -0.45351165533065796}
{"mode": "train", "epochs": 12, "timestep": 22388, "ep_reward": 268.372802734375, "reward": 0.1657428741455078, "action": -0.31920504570007324}
{"mode": "train", "epochs": 12, "timestep": 22389, "ep_reward": 268.63482666015625, "reward": 0.26202404499053955, "action": -1.2992396354675293}
{"mode": "train", "epochs": 12, "timestep": 22390, "ep_reward": 269.02117919921875, "reward": 0.3863542675971985, "action": -0.05996274948120117}
{"mode": "train", "epochs": 12, "timestep": 22391, "ep_reward": 269.5144958496094, "reward": 0.49330341815948486, "action": -0.011448858305811882}
{"mode": "train", "epochs": 12, "timestep": 22392, "ep_reward": 270.10546875, "reward": 0.5909733772277832, "action": 1.399259328842163}
{"mode": "train", "epochs": 12, "timestep": 22393, "ep_reward": 270.77313232421875, "reward": 0.6676576137542725, "action": 0.26508820056915283}
{"mode": "train", "epochs": 12, "timestep": 22394, "ep_reward": 271.512939453125, "reward": 0.7398190498352051, "action": 0.6022650003433228}
{"mode": "train", "epochs": 12, "timestep": 22395, "ep_reward": 272.3082580566406, "reward": 0.7953126430511475, "action": 1.1008464097976685}
{"mode": "train", "epochs": 12, "timestep": 22396, "ep_reward": 273.1440734863281, "reward": 0.8358297348022461, "action": 0.7719327211380005}
{"mode": "train", "epochs": 12, "timestep": 22397, "ep_reward": 274.0100402832031, "reward": 0.8659603595733643, "action": 1.1633636951446533}
{"mode": "train", "epochs": 12, "timestep": 22398, "ep_reward": 274.894775390625, "reward": 0.8847339153289795, "action": 1.8986148834228516}
{"mode": "train", "epochs": 12, "timestep": 22399, "ep_reward": 275.78985595703125, "reward": 0.895087480545044, "action": 1.2598885297775269}
{"mode": "train", "epochs": 12, "timestep": 22400, "ep_reward": 276.6886901855469, "reward": 0.8988358974456787, "action": 0.9762530326843262}
{"mode": "train", "epochs": 12, "timestep": 22401, "ep_reward": 277.5829162597656, "reward": 0.8942215442657471, "action": 1.3167688846588135}
{"mode": "train", "epochs": 12, "timestep": 22402, "ep_reward": 278.4646911621094, "reward": 0.8817847967147827, "action": 1.1370691061019897}
{"mode": "train", "epochs": 12, "timestep": 22403, "ep_reward": 279.32470703125, "reward": 0.8600145578384399, "action": 1.1831578016281128}
{"mode": "train", "epochs": 12, "timestep": 22404, "ep_reward": 280.1529541015625, "reward": 0.8282415270805359, "action": 0.8792933225631714}
{"mode": "train", "epochs": 12, "timestep": 22405, "ep_reward": 280.9359130859375, "reward": 0.7829679846763611, "action": 1.0261502265930176}
{"mode": "train", "epochs": 12, "timestep": 22406, "ep_reward": 281.6608581542969, "reward": 0.7249324917793274, "action": 1.2201943397521973}
{"mode": "train", "epochs": 12, "timestep": 22407, "ep_reward": 282.3156433105469, "reward": 0.6547774076461792, "action": 0.9414911270141602}
{"mode": "train", "epochs": 12, "timestep": 22408, "ep_reward": 282.8848876953125, "reward": 0.569239616394043, "action": 0.8158066868782043}
{"mode": "train", "epochs": 12, "timestep": 22409, "ep_reward": 283.3558654785156, "reward": 0.4709886908531189, "action": -0.3412092626094818}
{"mode": "train", "epochs": 12, "timestep": 22410, "ep_reward": 283.7065734863281, "reward": 0.3507067561149597, "action": -0.9102438688278198}
{"mode": "train", "epochs": 12, "timestep": 22411, "ep_reward": 283.9228820800781, "reward": 0.21631479263305664, "action": -1.6078917980194092}
{"mode": "train", "epochs": 12, "timestep": 22412, "ep_reward": 284.14666748046875, "reward": 0.2237842082977295, "action": -0.22404909133911133}
{"mode": "train", "epochs": 12, "timestep": 22413, "ep_reward": 284.4837646484375, "reward": 0.33709603548049927, "action": -0.715148389339447}
{"mode": "train", "epochs": 12, "timestep": 22414, "ep_reward": 284.9290466308594, "reward": 0.44527143239974976, "action": -1.3779619932174683}
{"mode": "train", "epochs": 12, "timestep": 22415, "ep_reward": 285.4723205566406, "reward": 0.5432730317115784, "action": -1.1200319528579712}
{"mode": "train", "epochs": 12, "timestep": 22416, "ep_reward": 286.1076354980469, "reward": 0.6353281736373901, "action": -1.3837049007415771}
{"mode": "train", "epochs": 12, "timestep": 22417, "ep_reward": 286.8211364746094, "reward": 0.713516116142273, "action": -0.6179125308990479}
{"mode": "train", "epochs": 12, "timestep": 22418, "ep_reward": 287.604248046875, "reward": 0.7831261157989502, "action": -0.7122859954833984}
{"mode": "train", "epochs": 12, "timestep": 22419, "ep_reward": 288.44122314453125, "reward": 0.8369901180267334, "action": -1.513822317123413}
{"mode": "train", "epochs": 12, "timestep": 22420, "ep_reward": 289.31591796875, "reward": 0.8746946454048157, "action": -1.4721063375473022}
{"mode": "train", "epochs": 12, "timestep": 22421, "ep_reward": 290.2193908691406, "reward": 0.9034826159477234, "action": -1.4131073951721191}
{"mode": "train", "epochs": 12, "timestep": 22422, "ep_reward": 291.14434814453125, "reward": 0.9249721765518188, "action": -1.3099348545074463}
{"mode": "train", "epochs": 12, "timestep": 22423, "ep_reward": 292.08477783203125, "reward": 0.9404397010803223, "action": -2.0}
{"mode": "train", "epochs": 12, "timestep": 22424, "ep_reward": 293.03515625, "reward": 0.9503790140151978, "action": -1.5694228410720825}
{"mode": "train", "epochs": 12, "timestep": 22425, "ep_reward": 293.9929504394531, "reward": 0.9577991366386414, "action": -1.3046817779541016}
{"mode": "train", "epochs": 12, "timestep": 22426, "ep_reward": 294.9552307128906, "reward": 0.9622840285301208, "action": -1.3121720552444458}
{"mode": "train", "epochs": 12, "timestep": 22427, "ep_reward": 295.91912841796875, "reward": 0.9638876914978027, "action": -0.37603163719177246}
{"mode": "train", "epochs": 12, "timestep": 22428, "ep_reward": 296.8804626464844, "reward": 0.9613460302352905, "action": -0.8655897378921509}
{"mode": "train", "epochs": 12, "timestep": 22429, "ep_reward": 297.8351745605469, "reward": 0.9547160267829895, "action": -1.3936553001403809}
{"mode": "train", "epochs": 12, "timestep": 22430, "ep_reward": 298.7802429199219, "reward": 0.9450535774230957, "action": -1.2919491529464722}
{"mode": "train", "epochs": 12, "timestep": 22431, "ep_reward": 299.7109375, "reward": 0.9306797385215759, "action": -0.4464271068572998}
{"mode": "train", "epochs": 12, "timestep": 22432, "ep_reward": 300.6173095703125, "reward": 0.9063683152198792, "action": 0.0019330978393554688}
{"mode": "train", "epochs": 12, "timestep": 22433, "ep_reward": 301.48614501953125, "reward": 0.868830680847168, "action": -0.8125563859939575}
{"mode": "train", "epochs": 12, "timestep": 22434, "ep_reward": 302.3084716796875, "reward": 0.8223171830177307, "action": -0.730293869972229}
{"mode": "train", "epochs": 12, "timestep": 22435, "ep_reward": 303.0686340332031, "reward": 0.7601701617240906, "action": -0.9346761107444763}
{"mode": "train", "epochs": 12, "timestep": 22436, "ep_reward": 303.7512512207031, "reward": 0.68262779712677, "action": -0.45374637842178345}
{"mode": "train", "epochs": 12, "timestep": 22437, "ep_reward": 304.333251953125, "reward": 0.582009494304657, "action": -0.3627970516681671}
{"mode": "train", "epochs": 12, "timestep": 22438, "ep_reward": 304.795166015625, "reward": 0.46190083026885986, "action": -0.8718750476837158}
{"mode": "train", "epochs": 12, "timestep": 22439, "ep_reward": 305.13018798828125, "reward": 0.33503538370132446, "action": -0.4261136054992676}
{"mode": "train", "epochs": 12, "timestep": 22440, "ep_reward": 305.3274230957031, "reward": 0.19722497463226318, "action": -0.9418761134147644}
{"mode": "train", "epochs": 12, "timestep": 22441, "ep_reward": 305.4911193847656, "reward": 0.16370528936386108, "action": -1.2222702503204346}
{"mode": "train", "epochs": 12, "timestep": 22442, "ep_reward": 305.7884216308594, "reward": 0.29730212688446045, "action": -1.0086021423339844}
{"mode": "train", "epochs": 12, "timestep": 22443, "ep_reward": 306.2133483886719, "reward": 0.4249163269996643, "action": -0.67191481590271}
{"mode": "train", "epochs": 12, "timestep": 22444, "ep_reward": 306.7532958984375, "reward": 0.5399513244628906, "action": -0.44209709763526917}
{"mode": "train", "epochs": 12, "timestep": 22445, "ep_reward": 307.3924255371094, "reward": 0.6391275525093079, "action": 1.0148171186447144}
{"mode": "train", "epochs": 12, "timestep": 22446, "ep_reward": 308.1057434082031, "reward": 0.7133148908615112, "action": 1.3822021484375}
{"mode": "train", "epochs": 12, "timestep": 22447, "ep_reward": 308.87890625, "reward": 0.7731757164001465, "action": 0.6896929740905762}
{"mode": "train", "epochs": 12, "timestep": 22448, "ep_reward": 309.7030029296875, "reward": 0.8240827918052673, "action": 0.8384721279144287}
{"mode": "train", "epochs": 12, "timestep": 22449, "ep_reward": 310.5644226074219, "reward": 0.8614085912704468, "action": 1.728885531425476}
{"mode": "train", "epochs": 12, "timestep": 22450, "ep_reward": 311.4506530761719, "reward": 0.8862354755401611, "action": 0.8061919808387756}
{"mode": "train", "epochs": 12, "timestep": 22451, "ep_reward": 312.3553771972656, "reward": 0.9047374725341797, "action": 0.7251890897750854}
{"mode": "train", "epochs": 12, "timestep": 22452, "ep_reward": 313.2697448730469, "reward": 0.9143543839454651, "action": 0.18220967054367065}
{"mode": "train", "epochs": 12, "timestep": 22453, "ep_reward": 314.1842041015625, "reward": 0.9144642949104309, "action": 2.0}
{"mode": "train", "epochs": 12, "timestep": 22454, "ep_reward": 315.0930480957031, "reward": 0.9088436365127563, "action": 1.6888971328735352}
{"mode": "train", "epochs": 12, "timestep": 22455, "ep_reward": 315.9902038574219, "reward": 0.897148847579956, "action": 1.3685153722763062}
{"mode": "train", "epochs": 12, "timestep": 22456, "ep_reward": 316.86767578125, "reward": 0.8774714469909668, "action": 0.7870408296585083}
{"mode": "train", "epochs": 12, "timestep": 22457, "ep_reward": 317.7135009765625, "reward": 0.845832347869873, "action": 0.8723602294921875}
{"mode": "train", "epochs": 12, "timestep": 22458, "ep_reward": 318.5157165527344, "reward": 0.8022106885910034, "action": 0.8846723437309265}
{"mode": "train", "epochs": 12, "timestep": 22459, "ep_reward": 319.2604675292969, "reward": 0.7447657585144043, "action": 0.9512919187545776}
{"mode": "train", "epochs": 12, "timestep": 22460, "ep_reward": 319.9333801269531, "reward": 0.6728997230529785, "action": 0.9756370782852173}
{"mode": "train", "epochs": 12, "timestep": 22461, "ep_reward": 320.5199890136719, "reward": 0.5866233110427856, "action": 0.5284674763679504}
{"mode": "train", "epochs": 12, "timestep": 22462, "ep_reward": 321.0024108886719, "reward": 0.4824269413948059, "action": 0.4752569794654846}
{"mode": "train", "epochs": 12, "timestep": 22463, "ep_reward": 321.3694152832031, "reward": 0.3669934868812561, "action": -1.3641124963760376}
{"mode": "train", "epochs": 12, "timestep": 22464, "ep_reward": 321.5912780761719, "reward": 0.22186607122421265, "action": -0.919055163860321}
{"mode": "train", "epochs": 12, "timestep": 22465, "ep_reward": 321.7831115722656, "reward": 0.1918480396270752, "action": 0.3128628730773926}
{"mode": "train", "epochs": 12, "timestep": 22466, "ep_reward": 322.0958251953125, "reward": 0.31270891427993774, "action": -0.7955089211463928}
{"mode": "train", "epochs": 12, "timestep": 22467, "ep_reward": 322.5181884765625, "reward": 0.4223586916923523, "action": -1.0493158102035522}
{"mode": "train", "epochs": 12, "timestep": 22468, "ep_reward": 323.04437255859375, "reward": 0.5261818170547485, "action": -0.24181586503982544}
{"mode": "train", "epochs": 12, "timestep": 22469, "ep_reward": 323.6721496582031, "reward": 0.6277697086334229, "action": -0.5684059858322144}
{"mode": "train", "epochs": 12, "timestep": 22470, "ep_reward": 324.3840637207031, "reward": 0.7119286060333252, "action": -1.8271311521530151}
{"mode": "train", "epochs": 12, "timestep": 22471, "ep_reward": 325.1579284667969, "reward": 0.7738497257232666, "action": -0.6761972904205322}
{"mode": "train", "epochs": 12, "timestep": 22472, "ep_reward": 325.9878234863281, "reward": 0.8298947215080261, "action": -1.4996919631958008}
{"mode": "train", "epochs": 12, "timestep": 22473, "ep_reward": 326.8570556640625, "reward": 0.8692261576652527, "action": -1.4976381063461304}
{"mode": "train", "epochs": 12, "timestep": 22474, "ep_reward": 327.75640869140625, "reward": 0.8993474245071411, "action": 0.058849215507507324}
{"mode": "train", "epochs": 12, "timestep": 22475, "ep_reward": 328.6815185546875, "reward": 0.925104558467865, "action": -1.5607876777648926}
{"mode": "train", "epochs": 12, "timestep": 22476, "ep_reward": 329.62054443359375, "reward": 0.939032256603241, "action": -0.9930674433708191}
{"mode": "train", "epochs": 12, "timestep": 22477, "ep_reward": 330.5693359375, "reward": 0.9488060474395752, "action": -0.45071035623550415}
{"mode": "train", "epochs": 12, "timestep": 22478, "ep_reward": 331.5227355957031, "reward": 0.9534129500389099, "action": -0.8077184557914734}
{"mode": "train", "epochs": 12, "timestep": 22479, "ep_reward": 332.47515869140625, "reward": 0.9524267911911011, "action": -1.798560380935669}
{"mode": "train", "epochs": 12, "timestep": 22480, "ep_reward": 333.4236755371094, "reward": 0.9485116600990295, "action": -1.41395902633667}
{"mode": "train", "epochs": 12, "timestep": 22481, "ep_reward": 334.3641357421875, "reward": 0.940470278263092, "action": -1.1101549863815308}
{"mode": "train", "epochs": 12, "timestep": 22482, "ep_reward": 335.2908630371094, "reward": 0.9267306923866272, "action": -0.5489042401313782}
{"mode": "train", "epochs": 12, "timestep": 22483, "ep_reward": 336.1946105957031, "reward": 0.9037447571754456, "action": -1.049461007118225}
{"mode": "train", "epochs": 12, "timestep": 22484, "ep_reward": 337.0679931640625, "reward": 0.8733688592910767, "action": -0.9426568746566772}
{"mode": "train", "epochs": 12, "timestep": 22485, "ep_reward": 337.8994140625, "reward": 0.8314156532287598, "action": -0.9353815913200378}
{"mode": "train", "epochs": 12, "timestep": 22486, "ep_reward": 338.6753234863281, "reward": 0.7758960723876953, "action": 0.1497618556022644}
{"mode": "train", "epochs": 12, "timestep": 22487, "ep_reward": 339.3696594238281, "reward": 0.6943391561508179, "action": -0.14340367913246155}
{"mode": "train", "epochs": 12, "timestep": 22488, "ep_reward": 339.9638366699219, "reward": 0.5941674709320068, "action": -0.6692858338356018}
{"mode": "train", "epochs": 12, "timestep": 22489, "ep_reward": 340.44488525390625, "reward": 0.48104381561279297, "action": -0.7584631443023682}
{"mode": "train", "epochs": 12, "timestep": 22490, "ep_reward": 340.801025390625, "reward": 0.35612624883651733, "action": -1.2191286087036133}
{"mode": "train", "epochs": 12, "timestep": 22491, "ep_reward": 341.03338623046875, "reward": 0.23235446214675903, "action": -1.7196238040924072}
{"mode": "train", "epochs": 12, "timestep": 22492, "ep_reward": 341.2005615234375, "reward": 0.16716885566711426, "action": -0.9842649698257446}
{"mode": "train", "epochs": 12, "timestep": 22493, "ep_reward": 341.49212646484375, "reward": 0.2915685176849365, "action": -1.4127964973449707}
{"mode": "train", "epochs": 12, "timestep": 22494, "ep_reward": 341.9091491699219, "reward": 0.41702306270599365, "action": -1.0695699453353882}
{"mode": "train", "epochs": 12, "timestep": 22495, "ep_reward": 342.4388732910156, "reward": 0.5297101140022278, "action": -0.6026374101638794}
{"mode": "train", "epochs": 12, "timestep": 22496, "ep_reward": 343.0639953613281, "reward": 0.6251358985900879, "action": 0.37077465653419495}
{"mode": "train", "epochs": 12, "timestep": 22497, "ep_reward": 343.76348876953125, "reward": 0.699489951133728, "action": 1.560951590538025}
{"mode": "train", "epochs": 12, "timestep": 22498, "ep_reward": 344.518798828125, "reward": 0.7553155422210693, "action": 0.43915891647338867}
{"mode": "train", "epochs": 12, "timestep": 22499, "ep_reward": 345.3232727050781, "reward": 0.8044739961624146, "action": 1.2975077629089355}
{"mode": "train", "epochs": 12, "timestep": 22500, "ep_reward": 346.1614685058594, "reward": 0.8381982445716858, "action": 0.8799590468406677}
{"mode": "train", "epochs": 12, "timestep": 22501, "ep_reward": 347.0238952636719, "reward": 0.8624253273010254, "action": 1.027479887008667}
{"mode": "train", "epochs": 12, "timestep": 22502, "ep_reward": 347.9000244140625, "reward": 0.8761163353919983, "action": 0.983646810054779}
{"mode": "train", "epochs": 12, "timestep": 22503, "ep_reward": 348.7802429199219, "reward": 0.8802148699760437, "action": 1.4083949327468872}
{"mode": "train", "epochs": 12, "timestep": 22504, "ep_reward": 349.65606689453125, "reward": 0.875825047492981, "action": 1.2767987251281738}
{"mode": "train", "epochs": 12, "timestep": 22505, "ep_reward": 350.5188293457031, "reward": 0.8627686500549316, "action": 0.9696924686431885}
{"mode": "train", "epochs": 12, "timestep": 22506, "ep_reward": 351.35772705078125, "reward": 0.8389118313789368, "action": 1.4970556497573853}
{"mode": "train", "epochs": 12, "timestep": 22507, "ep_reward": 352.1643371582031, "reward": 0.8066205978393555, "action": 1.077583909034729}
{"mode": "train", "epochs": 12, "timestep": 22508, "ep_reward": 352.9253845214844, "reward": 0.7610361576080322, "action": 0.8669804334640503}
{"mode": "train", "epochs": 12, "timestep": 22509, "ep_reward": 353.62615966796875, "reward": 0.7007633447647095, "action": 1.6828709840774536}
{"mode": "train", "epochs": 12, "timestep": 22510, "ep_reward": 354.260498046875, "reward": 0.6343415379524231, "action": 0.16540196537971497}
{"mode": "train", "epochs": 12, "timestep": 22511, "ep_reward": 354.80352783203125, "reward": 0.5430378913879395, "action": -0.9085972309112549}
{"mode": "train", "epochs": 12, "timestep": 22512, "ep_reward": 355.22991943359375, "reward": 0.4263985753059387, "action": -0.08062297850847244}
{"mode": "train", "epochs": 12, "timestep": 22513, "ep_reward": 355.53741455078125, "reward": 0.3074961304664612, "action": 0.11247813701629639}
{"mode": "train", "epochs": 12, "timestep": 22514, "ep_reward": 355.7261047363281, "reward": 0.18868470191955566, "action": -1.009648323059082}
{"mode": "train", "epochs": 12, "timestep": 22515, "ep_reward": 356.00592041015625, "reward": 0.27981454133987427, "action": -0.9812424182891846}
{"mode": "train", "epochs": 12, "timestep": 22516, "ep_reward": 356.3872375488281, "reward": 0.381325364112854, "action": -0.777732253074646}
{"mode": "train", "epochs": 12, "timestep": 22517, "ep_reward": 356.8713073730469, "reward": 0.48406022787094116, "action": -0.763913631439209}
{"mode": "train", "epochs": 12, "timestep": 22518, "ep_reward": 357.4521484375, "reward": 0.5808321237564087, "action": -0.831972599029541}
{"mode": "train", "epochs": 12, "timestep": 22519, "ep_reward": 358.11883544921875, "reward": 0.666678786277771, "action": -0.6788550615310669}
{"mode": "train", "epochs": 12, "timestep": 22520, "ep_reward": 358.8592224121094, "reward": 0.7403731346130371, "action": -0.9263908267021179}
{"mode": "train", "epochs": 12, "timestep": 22521, "ep_reward": 359.6578063964844, "reward": 0.7985817193984985, "action": -0.5389869213104248}
{"mode": "train", "epochs": 12, "timestep": 22522, "ep_reward": 360.5028381347656, "reward": 0.8450199961662292, "action": -1.5617196559906006}
{"mode": "train", "epochs": 12, "timestep": 22523, "ep_reward": 361.3789367675781, "reward": 0.8760888576507568, "action": -1.209385633468628}
{"mode": "train", "epochs": 12, "timestep": 22524, "ep_reward": 362.2784118652344, "reward": 0.8994832038879395, "action": -1.0596815347671509}
{"mode": "train", "epochs": 12, "timestep": 22525, "ep_reward": 363.1933288574219, "reward": 0.9149028658866882, "action": -1.4021108150482178}
{"mode": "train", "epochs": 12, "timestep": 22526, "ep_reward": 364.1163024902344, "reward": 0.9229615926742554, "action": -1.3751826286315918}
{"mode": "train", "epochs": 12, "timestep": 22527, "ep_reward": 365.04132080078125, "reward": 0.9250327348709106, "action": -1.702284574508667}
{"mode": "train", "epochs": 12, "timestep": 22528, "ep_reward": 365.96331787109375, "reward": 0.9219861030578613, "action": -1.3235633373260498}
{"mode": "train", "epochs": 12, "timestep": 22529, "ep_reward": 366.8760986328125, "reward": 0.9127758741378784, "action": -0.9785856008529663}
{"mode": "train", "epochs": 12, "timestep": 22530, "ep_reward": 367.771484375, "reward": 0.8953796029090881, "action": -0.8663880825042725}
{"mode": "train", "epochs": 12, "timestep": 22531, "ep_reward": 368.6397705078125, "reward": 0.8682724237442017, "action": -0.35581904649734497}
{"mode": "train", "epochs": 12, "timestep": 22532, "ep_reward": 369.4664611816406, "reward": 0.8266779184341431, "action": 0.4867526590824127}
{"mode": "train", "epochs": 12, "timestep": 22533, "ep_reward": 370.22955322265625, "reward": 0.7630968689918518, "action": -0.38116514682769775}
{"mode": "train", "epochs": 12, "timestep": 22534, "ep_reward": 370.91571044921875, "reward": 0.686150074005127, "action": 1.1822680234909058}
{"mode": "train", "epochs": 12, "timestep": 22535, "ep_reward": 371.4892272949219, "reward": 0.5735172033309937, "action": 0.019892029464244843}
{"mode": "train", "epochs": 12, "timestep": 22536, "ep_reward": 371.9399719238281, "reward": 0.4507371783256531, "action": -0.04664325714111328}
{"mode": "train", "epochs": 12, "timestep": 22537, "ep_reward": 372.2545166015625, "reward": 0.3145546317100525, "action": -0.5183953642845154}
{"mode": "train", "epochs": 12, "timestep": 22538, "ep_reward": 372.4337463378906, "reward": 0.1792324185371399, "action": -1.3280999660491943}
{"mode": "train", "epochs": 12, "timestep": 22539, "ep_reward": 372.6274108886719, "reward": 0.1936711072921753, "action": -0.4146692752838135}
{"mode": "train", "epochs": 12, "timestep": 22540, "ep_reward": 372.94482421875, "reward": 0.317413330078125, "action": -0.8818168640136719}
{"mode": "train", "epochs": 12, "timestep": 22541, "ep_reward": 373.38775634765625, "reward": 0.4429329037666321, "action": -0.06646287441253662}
{"mode": "train", "epochs": 12, "timestep": 22542, "ep_reward": 373.9394836425781, "reward": 0.5517339706420898, "action": 0.18479152023792267}
{"mode": "train", "epochs": 12, "timestep": 22543, "ep_reward": 374.58575439453125, "reward": 0.6462608575820923, "action": 0.7811270952224731}
{"mode": "train", "epochs": 12, "timestep": 22544, "ep_reward": 375.30816650390625, "reward": 0.7224066257476807, "action": 1.4492615461349487}
{"mode": "train", "epochs": 12, "timestep": 22545, "ep_reward": 376.08966064453125, "reward": 0.7814974188804626, "action": 1.0329996347427368}
{"mode": "train", "epochs": 12, "timestep": 22546, "ep_reward": 376.92034912109375, "reward": 0.8306839466094971, "action": 1.1131973266601562}
{"mode": "train", "epochs": 12, "timestep": 22547, "ep_reward": 377.7881774902344, "reward": 0.8678298592567444, "action": 0.6133478879928589}
{"mode": "train", "epochs": 12, "timestep": 22548, "ep_reward": 378.68402099609375, "reward": 0.8958300352096558, "action": 0.8570010662078857}
{"mode": "train", "epochs": 12, "timestep": 22549, "ep_reward": 379.5975036621094, "reward": 0.9134931564331055, "action": 0.3671349287033081}
{"mode": "train", "epochs": 12, "timestep": 22550, "ep_reward": 380.5203857421875, "reward": 0.9228913187980652, "action": 0.5589228868484497}
{"mode": "train", "epochs": 12, "timestep": 22551, "ep_reward": 381.4437561035156, "reward": 0.9233753681182861, "action": 1.3789703845977783}
{"mode": "train", "epochs": 12, "timestep": 22552, "ep_reward": 382.36114501953125, "reward": 0.9173864126205444, "action": 1.387662649154663}
{"mode": "train", "epochs": 12, "timestep": 22553, "ep_reward": 383.2662048339844, "reward": 0.9050604701042175, "action": 1.2814644575119019}
{"mode": "train", "epochs": 12, "timestep": 22554, "ep_reward": 384.1512756347656, "reward": 0.8850753307342529, "action": 1.1568230390548706}
{"mode": "train", "epochs": 12, "timestep": 22555, "ep_reward": 385.00689697265625, "reward": 0.8556333780288696, "action": 0.7031865119934082}
{"mode": "train", "epochs": 12, "timestep": 22556, "ep_reward": 385.8192443847656, "reward": 0.8123444318771362, "action": 0.3510743975639343}
{"mode": "train", "epochs": 12, "timestep": 22557, "ep_reward": 386.57098388671875, "reward": 0.7517251372337341, "action": 0.7996129393577576}
{"mode": "train", "epochs": 12, "timestep": 22558, "ep_reward": 387.24871826171875, "reward": 0.6777458786964417, "action": 0.35754746198654175}
{"mode": "train", "epochs": 12, "timestep": 22559, "ep_reward": 387.8316345214844, "reward": 0.5829073190689087, "action": 1.2434940338134766}
{"mode": "train", "epochs": 12, "timestep": 22560, "ep_reward": 388.3142395019531, "reward": 0.48259663581848145, "action": 0.9060139060020447}
{"mode": "train", "epochs": 12, "timestep": 22561, "ep_reward": 388.6840515136719, "reward": 0.36979949474334717, "action": 0.6348667740821838}
{"mode": "train", "epochs": 12, "timestep": 22562, "ep_reward": 388.93408203125, "reward": 0.2500242590904236, "action": -0.11124658584594727}
{"mode": "train", "epochs": 12, "timestep": 22563, "ep_reward": 389.1308288574219, "reward": 0.19674479961395264, "action": -0.01431296020746231}
{"mode": "train", "epochs": 12, "timestep": 22564, "ep_reward": 389.4396667480469, "reward": 0.3088268041610718, "action": -0.6337434649467468}
{"mode": "train", "epochs": 12, "timestep": 22565, "ep_reward": 389.8554992675781, "reward": 0.4158251881599426, "action": -0.4003598392009735}
{"mode": "train", "epochs": 12, "timestep": 22566, "ep_reward": 390.3768310546875, "reward": 0.5213422775268555, "action": -0.8211184740066528}
{"mode": "train", "epochs": 12, "timestep": 22567, "ep_reward": 390.991455078125, "reward": 0.6146258115768433, "action": -0.6995674967765808}
{"mode": "train", "epochs": 12, "timestep": 22568, "ep_reward": 391.6884460449219, "reward": 0.6970024108886719, "action": -0.9004478454589844}
{"mode": "train", "epochs": 12, "timestep": 22569, "ep_reward": 392.4524841308594, "reward": 0.7640522718429565, "action": -2.0}
{"mode": "train", "epochs": 12, "timestep": 22570, "ep_reward": 393.2654113769531, "reward": 0.8129132986068726, "action": -1.259311318397522}
{"mode": "train", "epochs": 12, "timestep": 22571, "ep_reward": 394.1204528808594, "reward": 0.8550336360931396, "action": -0.766942024230957}
{"mode": "train", "epochs": 12, "timestep": 22572, "ep_reward": 395.0084533691406, "reward": 0.8880043625831604, "action": -1.39444899559021}
{"mode": "train", "epochs": 12, "timestep": 22573, "ep_reward": 395.91815185546875, "reward": 0.9097127318382263, "action": -1.5434070825576782}
{"mode": "train", "epochs": 12, "timestep": 22574, "ep_reward": 396.84246826171875, "reward": 0.9243100881576538, "action": -1.7312564849853516}
{"mode": "train", "epochs": 12, "timestep": 22575, "ep_reward": 397.77581787109375, "reward": 0.9333348870277405, "action": -1.81642484664917}
{"mode": "train", "epochs": 12, "timestep": 22576, "ep_reward": 398.7138977050781, "reward": 0.938065230846405, "action": -1.5681160688400269}
{"mode": "train", "epochs": 12, "timestep": 22577, "ep_reward": 399.6526794433594, "reward": 0.9387708306312561, "action": -0.9656851887702942}
{"mode": "train", "epochs": 12, "timestep": 22578, "ep_reward": 400.58660888671875, "reward": 0.9339351654052734, "action": -0.8202100992202759}
{"mode": "train", "epochs": 12, "timestep": 22579, "ep_reward": 401.5088806152344, "reward": 0.9222777485847473, "action": -1.0731711387634277}
{"mode": "train", "epochs": 12, "timestep": 22580, "ep_reward": 402.4128112792969, "reward": 0.9039204120635986, "action": -0.6037859916687012}
{"mode": "train", "epochs": 12, "timestep": 22581, "ep_reward": 403.2875061035156, "reward": 0.8746991157531738, "action": -0.12436029314994812}
{"mode": "train", "epochs": 12, "timestep": 22582, "ep_reward": 404.1177673339844, "reward": 0.8302673697471619, "action": -0.17156431078910828}
{"mode": "train", "epochs": 12, "timestep": 22583, "ep_reward": 404.8874206542969, "reward": 0.7696517705917358, "action": -0.2819628417491913}
{"mode": "train", "epochs": 12, "timestep": 22584, "ep_reward": 405.5787048339844, "reward": 0.69127357006073, "action": 0.41543030738830566}
{"mode": "train", "epochs": 12, "timestep": 22585, "ep_reward": 406.16424560546875, "reward": 0.5855281949043274, "action": 0.47649121284484863}
{"mode": "train", "epochs": 12, "timestep": 22586, "ep_reward": 406.6212463378906, "reward": 0.45698654651641846, "action": -0.9597426652908325}
{"mode": "train", "epochs": 12, "timestep": 22587, "ep_reward": 406.9525451660156, "reward": 0.33129554986953735, "action": 0.04220515489578247}
{"mode": "train", "epochs": 12, "timestep": 22588, "ep_reward": 407.139404296875, "reward": 0.18684405088424683, "action": -2.0}
{"mode": "train", "epochs": 12, "timestep": 22589, "ep_reward": 407.3169250488281, "reward": 0.1775141954421997, "action": -0.18511509895324707}
{"mode": "train", "epochs": 12, "timestep": 22590, "ep_reward": 407.6160583496094, "reward": 0.2991297245025635, "action": -1.5181646347045898}
{"mode": "train", "epochs": 12, "timestep": 22591, "ep_reward": 408.0478210449219, "reward": 0.43176543712615967, "action": -0.7430199980735779}
{"mode": "train", "epochs": 12, "timestep": 22592, "ep_reward": 408.59393310546875, "reward": 0.546104907989502, "action": 0.4493080675601959}
{"mode": "train", "epochs": 12, "timestep": 22593, "ep_reward": 409.23162841796875, "reward": 0.6377017498016357, "action": 1.7562669515609741}
{"mode": "train", "epochs": 12, "timestep": 22594, "ep_reward": 409.9401550292969, "reward": 0.7085360288619995, "action": 1.0716569423675537}
{"mode": "train", "epochs": 12, "timestep": 22595, "ep_reward": 410.7125549316406, "reward": 0.7723868489265442, "action": 0.9702019095420837}
{"mode": "train", "epochs": 12, "timestep": 22596, "ep_reward": 411.5363464355469, "reward": 0.8237866759300232, "action": 0.6426250338554382}
{"mode": "train", "epochs": 12, "timestep": 22597, "ep_reward": 412.4002685546875, "reward": 0.8639172315597534, "action": 0.6361120939254761}
{"mode": "train", "epochs": 12, "timestep": 22598, "ep_reward": 413.2925109863281, "reward": 0.8922573924064636, "action": 0.2881854772567749}
{"mode": "train", "epochs": 12, "timestep": 22599, "ep_reward": 414.2030944824219, "reward": 0.9105739593505859, "action": 0.5420008897781372}
{"mode": "train", "epochs": 12, "timestep": 22600, "ep_reward": 415.1217041015625, "reward": 0.9186066389083862, "action": 1.5096238851547241}
{"mode": "train", "epochs": 12, "timestep": 22601, "ep_reward": 416.0410461425781, "reward": 0.919349193572998, "action": 0.25130951404571533}
{"mode": "train", "epochs": 12, "timestep": 22602, "ep_reward": 416.9522705078125, "reward": 0.9112197160720825, "action": 1.3457615375518799}
{"mode": "train", "epochs": 12, "timestep": 22603, "ep_reward": 417.8489685058594, "reward": 0.8966927528381348, "action": 0.4103240370750427}
{"mode": "train", "epochs": 12, "timestep": 22604, "ep_reward": 418.7189025878906, "reward": 0.8699299097061157, "action": 0.6908830404281616}
{"mode": "train", "epochs": 12, "timestep": 22605, "ep_reward": 419.5509033203125, "reward": 0.8320021629333496, "action": 1.1422570943832397}
{"mode": "train", "epochs": 12, "timestep": 22606, "ep_reward": 420.3345642089844, "reward": 0.7836572527885437, "action": 1.1625111103057861}
{"mode": "train", "epochs": 12, "timestep": 22607, "ep_reward": 421.0565185546875, "reward": 0.7219527959823608, "action": 0.698330819606781}
{"mode": "train", "epochs": 12, "timestep": 22608, "ep_reward": 421.6979064941406, "reward": 0.6413972973823547, "action": 0.7074170708656311}
{"mode": "train", "epochs": 12, "timestep": 22609, "ep_reward": 422.2431945800781, "reward": 0.5452874302864075, "action": 0.5909868478775024}
{"mode": "train", "epochs": 12, "timestep": 22610, "ep_reward": 422.6780090332031, "reward": 0.4348287582397461, "action": 1.0881524085998535}
{"mode": "train", "epochs": 12, "timestep": 22611, "ep_reward": 423.0007019042969, "reward": 0.3226858377456665, "action": 1.700209617614746}
{"mode": "train", "epochs": 12, "timestep": 22612, "ep_reward": 423.22015380859375, "reward": 0.219457745552063, "action": 0.06197535991668701}
{"mode": "train", "epochs": 12, "timestep": 22613, "ep_reward": 423.4767150878906, "reward": 0.25656670331954956, "action": 0.12231044471263885}
{"mode": "train", "epochs": 12, "timestep": 22614, "ep_reward": 423.8414306640625, "reward": 0.36471158266067505, "action": -1.178364634513855}
{"mode": "train", "epochs": 12, "timestep": 22615, "ep_reward": 424.3020935058594, "reward": 0.46065753698349, "action": -0.8221712708473206}
{"mode": "train", "epochs": 12, "timestep": 22616, "ep_reward": 424.85809326171875, "reward": 0.5560119152069092, "action": -0.30195969343185425}
{"mode": "train", "epochs": 12, "timestep": 22617, "ep_reward": 425.50390625, "reward": 0.6458271741867065, "action": -1.5125935077667236}
{"mode": "train", "epochs": 12, "timestep": 22618, "ep_reward": 426.2193298339844, "reward": 0.7154295444488525, "action": -0.22794508934020996}
{"mode": "train", "epochs": 12, "timestep": 22619, "ep_reward": 426.9992370605469, "reward": 0.7799149751663208, "action": -1.3131598234176636}
{"mode": "train", "epochs": 12, "timestep": 22620, "ep_reward": 427.8244934082031, "reward": 0.8252429366111755, "action": -1.2095561027526855}
{"mode": "train", "epochs": 12, "timestep": 22621, "ep_reward": 428.6845397949219, "reward": 0.8600335121154785, "action": -1.6858630180358887}
{"mode": "train", "epochs": 12, "timestep": 22622, "ep_reward": 429.56890869140625, "reward": 0.8843623399734497, "action": -0.23226529359817505}
{"mode": "train", "epochs": 12, "timestep": 22623, "ep_reward": 430.4710998535156, "reward": 0.9021822214126587, "action": -1.7828527688980103}
{"mode": "train", "epochs": 12, "timestep": 22624, "ep_reward": 431.3810119628906, "reward": 0.9099023342132568, "action": -1.2623558044433594}
{"mode": "train", "epochs": 12, "timestep": 22625, "ep_reward": 432.2924499511719, "reward": 0.911434531211853, "action": -0.7368398904800415}
{"mode": "train", "epochs": 12, "timestep": 22626, "ep_reward": 433.1971130371094, "reward": 0.9046482443809509, "action": -1.3487430810928345}
{"mode": "train", "epochs": 12, "timestep": 22627, "ep_reward": 434.0880126953125, "reward": 0.8908876776695251, "action": 0.09227824211120605}
{"mode": "train", "epochs": 12, "timestep": 22628, "ep_reward": 434.95037841796875, "reward": 0.8623806834220886, "action": 0.7313041090965271}
{"mode": "train", "epochs": 12, "timestep": 22629, "ep_reward": 435.7651062011719, "reward": 0.8147129416465759, "action": -0.28745824098587036}
{"mode": "train", "epochs": 12, "timestep": 22630, "ep_reward": 436.51971435546875, "reward": 0.7545992732048035, "action": -0.1638389229774475}
{"mode": "train", "epochs": 12, "timestep": 22631, "ep_reward": 437.19512939453125, "reward": 0.6754282712936401, "action": 0.8372787237167358}
{"mode": "train", "epochs": 12, "timestep": 22632, "ep_reward": 437.7613525390625, "reward": 0.5662307143211365, "action": -0.3180598020553589}
{"mode": "train", "epochs": 12, "timestep": 22633, "ep_reward": 438.210693359375, "reward": 0.44934672117233276, "action": -0.6936296820640564}
{"mode": "train", "epochs": 12, "timestep": 22634, "ep_reward": 438.53662109375, "reward": 0.3259396553039551, "action": -0.4390828609466553}
{"mode": "train", "epochs": 12, "timestep": 22635, "ep_reward": 438.7325744628906, "reward": 0.19595187902450562, "action": -1.0949199199676514}
{"mode": "train", "epochs": 12, "timestep": 22636, "ep_reward": 438.9451904296875, "reward": 0.21261847019195557, "action": -1.142446517944336}
{"mode": "train", "epochs": 12, "timestep": 22637, "ep_reward": 439.28326416015625, "reward": 0.3380601406097412, "action": -0.3650721311569214}
{"mode": "train", "epochs": 12, "timestep": 22638, "ep_reward": 439.7353515625, "reward": 0.452090859413147, "action": 0.07617464661598206}
{"mode": "train", "epochs": 12, "timestep": 22639, "ep_reward": 440.29010009765625, "reward": 0.554763674736023, "action": 0.11311215162277222}
{"mode": "train", "epochs": 12, "timestep": 22640, "ep_reward": 440.9358825683594, "reward": 0.6457726955413818, "action": 0.9049956202507019}
{"mode": "train", "epochs": 12, "timestep": 22641, "ep_reward": 441.654052734375, "reward": 0.7181673049926758, "action": 0.7674707174301147}
{"mode": "train", "epochs": 12, "timestep": 22642, "ep_reward": 442.4322204589844, "reward": 0.7781727910041809, "action": 1.7720849514007568}
{"mode": "train", "epochs": 12, "timestep": 22643, "ep_reward": 443.2537841796875, "reward": 0.8215566277503967, "action": 1.2740339040756226}
{"mode": "train", "epochs": 12, "timestep": 22644, "ep_reward": 444.11077880859375, "reward": 0.8569841980934143, "action": 0.8560932874679565}
{"mode": "train", "epochs": 12, "timestep": 22645, "ep_reward": 444.9939270019531, "reward": 0.8831616044044495, "action": 1.6825768947601318}
{"mode": "train", "epochs": 12, "timestep": 22646, "ep_reward": 445.89300537109375, "reward": 0.8990873098373413, "action": 0.7015632390975952}
{"mode": "train", "epochs": 12, "timestep": 22647, "ep_reward": 446.8012390136719, "reward": 0.9082204103469849, "action": 0.7878661155700684}
{"mode": "train", "epochs": 12, "timestep": 22648, "ep_reward": 447.709716796875, "reward": 0.9084930419921875, "action": 0.6053754091262817}
{"mode": "train", "epochs": 12, "timestep": 22649, "ep_reward": 448.6092224121094, "reward": 0.8995176553726196, "action": 0.9931851029396057}
{"mode": "train", "epochs": 12, "timestep": 22650, "ep_reward": 449.4912414550781, "reward": 0.8820154666900635, "action": 0.897270917892456}
{"mode": "train", "epochs": 12, "timestep": 22651, "ep_reward": 450.345458984375, "reward": 0.8542323112487793, "action": 0.9201175570487976}
{"mode": "train", "epochs": 12, "timestep": 22652, "ep_reward": 451.1602783203125, "reward": 0.8148132562637329, "action": 1.6415140628814697}
{"mode": "train", "epochs": 12, "timestep": 22653, "ep_reward": 451.9280090332031, "reward": 0.7677190899848938, "action": 0.22632503509521484}
{"mode": "train", "epochs": 12, "timestep": 22654, "ep_reward": 452.6248474121094, "reward": 0.6968384981155396, "action": 1.0048067569732666}
{"mode": "train", "epochs": 12, "timestep": 22655, "ep_reward": 453.2408447265625, "reward": 0.6159843802452087, "action": 0.36071091890335083}
{"mode": "train", "epochs": 12, "timestep": 22656, "ep_reward": 453.75537109375, "reward": 0.5145400762557983, "action": 1.0650004148483276}
{"mode": "train", "epochs": 12, "timestep": 22657, "ep_reward": 454.1646728515625, "reward": 0.40928953886032104, "action": 0.7445961833000183}
{"mode": "train", "epochs": 12, "timestep": 22658, "ep_reward": 454.4603271484375, "reward": 0.2956562042236328, "action": 0.7788033485412598}
{"mode": "train", "epochs": 12, "timestep": 22659, "ep_reward": 454.64593505859375, "reward": 0.18561482429504395, "action": -0.21028342843055725}
{"mode": "train", "epochs": 12, "timestep": 22660, "ep_reward": 454.93548583984375, "reward": 0.28955405950546265, "action": -1.3244850635528564}
{"mode": "train", "epochs": 12, "timestep": 22661, "ep_reward": 455.3218688964844, "reward": 0.38639163970947266, "action": -1.1275701522827148}
{"mode": "train", "epochs": 12, "timestep": 22662, "ep_reward": 455.8070983886719, "reward": 0.48522138595581055, "action": -0.7328999042510986}
{"mode": "train", "epochs": 12, "timestep": 22663, "ep_reward": 456.38909912109375, "reward": 0.5820038318634033, "action": -0.33080530166625977}
{"mode": "train", "epochs": 12, "timestep": 22664, "ep_reward": 457.0597229003906, "reward": 0.6706145405769348, "action": -1.5933161973953247}
{"mode": "train", "epochs": 12, "timestep": 22665, "ep_reward": 457.79742431640625, "reward": 0.7377125024795532, "action": -0.9653849601745605}
{"mode": "train", "epochs": 12, "timestep": 22666, "ep_reward": 458.5939636230469, "reward": 0.7965435981750488, "action": -0.42946553230285645}
{"mode": "train", "epochs": 12, "timestep": 22667, "ep_reward": 459.4382019042969, "reward": 0.8442298173904419, "action": -1.4811159372329712}
{"mode": "train", "epochs": 12, "timestep": 22668, "ep_reward": 460.3142395019531, "reward": 0.8760356307029724, "action": -0.37583214044570923}
{"mode": "train", "epochs": 12, "timestep": 22669, "ep_reward": 461.2151184082031, "reward": 0.9008736610412598, "action": -1.8798402547836304}
{"mode": "train", "epochs": 12, "timestep": 22670, "ep_reward": 462.1295471191406, "reward": 0.9144369959831238, "action": -1.565598487854004}
{"mode": "train", "epochs": 12, "timestep": 22671, "ep_reward": 463.05242919921875, "reward": 0.9228696227073669, "action": -0.7134867906570435}
{"mode": "train", "epochs": 12, "timestep": 22672, "ep_reward": 463.9774169921875, "reward": 0.9249858260154724, "action": 0.20872801542282104}
{"mode": "train", "epochs": 12, "timestep": 22673, "ep_reward": 464.89459228515625, "reward": 0.9171858429908752, "action": -0.841213583946228}
{"mode": "train", "epochs": 12, "timestep": 22674, "ep_reward": 465.796142578125, "reward": 0.9015489220619202, "action": -0.4850350022315979}
{"mode": "train", "epochs": 12, "timestep": 22675, "ep_reward": 466.6710510253906, "reward": 0.8749191164970398, "action": -1.1869524717330933}
{"mode": "train", "epochs": 12, "timestep": 22676, "ep_reward": 467.5113220214844, "reward": 0.8402811884880066, "action": -0.6453572511672974}
{"mode": "train", "epochs": 12, "timestep": 22677, "ep_reward": 468.3014221191406, "reward": 0.7900980114936829, "action": -0.7390822768211365}
{"mode": "train", "epochs": 12, "timestep": 22678, "ep_reward": 469.0265197753906, "reward": 0.7250962257385254, "action": 1.0603697299957275}
{"mode": "train", "epochs": 12, "timestep": 22679, "ep_reward": 469.6519775390625, "reward": 0.625464141368866, "action": 0.3976250886917114}
{"mode": "train", "epochs": 12, "timestep": 22680, "ep_reward": 470.16064453125, "reward": 0.508664608001709, "action": -0.958792507648468}
{"mode": "train", "epochs": 12, "timestep": 22681, "ep_reward": 470.5522766113281, "reward": 0.3916328549385071, "action": 0.7779442071914673}
{"mode": "train", "epochs": 12, "timestep": 22682, "ep_reward": 470.7961120605469, "reward": 0.2438308596611023, "action": 0.6395816802978516}
{"mode": "train", "epochs": 12, "timestep": 22683, "ep_reward": 470.9168701171875, "reward": 0.12075763940811157, "action": -0.687933087348938}
{"mode": "train", "epochs": 12, "timestep": 22684, "ep_reward": 471.1681823730469, "reward": 0.2513248920440674, "action": -0.32905954122543335}
{"mode": "train", "epochs": 12, "timestep": 22685, "ep_reward": 471.5462646484375, "reward": 0.37808340787887573, "action": -0.3901579976081848}
{"mode": "train", "epochs": 12, "timestep": 22686, "ep_reward": 472.04595947265625, "reward": 0.4996906518936157, "action": -0.27764174342155457}
{"mode": "train", "epochs": 12, "timestep": 22687, "ep_reward": 472.6540832519531, "reward": 0.608113169670105, "action": 0.6621806621551514}
{"mode": "train", "epochs": 12, "timestep": 22688, "ep_reward": 473.34814453125, "reward": 0.6940703988075256, "action": 0.4471092224121094}
{"mode": "train", "epochs": 12, "timestep": 22689, "ep_reward": 474.114501953125, "reward": 0.7663424611091614, "action": 1.6575018167495728}
{"mode": "train", "epochs": 12, "timestep": 22690, "ep_reward": 474.9322204589844, "reward": 0.8177242279052734, "action": 0.39835125207901}
{"mode": "train", "epochs": 12, "timestep": 22691, "ep_reward": 475.7952880859375, "reward": 0.863072395324707, "action": 1.1998214721679688}
{"mode": "train", "epochs": 12, "timestep": 22692, "ep_reward": 476.68878173828125, "reward": 0.8934786319732666, "action": 1.0041124820709229}
{"mode": "train", "epochs": 12, "timestep": 22693, "ep_reward": 477.6044006347656, "reward": 0.9156070947647095, "action": 1.0903996229171753}
{"mode": "train", "epochs": 12, "timestep": 22694, "ep_reward": 478.5343933105469, "reward": 0.9300035238265991, "action": 1.047156572341919}
{"mode": "train", "epochs": 12, "timestep": 22695, "ep_reward": 479.4724426269531, "reward": 0.9380528330802917, "action": 1.3102755546569824}
{"mode": "train", "epochs": 12, "timestep": 22696, "ep_reward": 480.4131164550781, "reward": 0.9406830072402954, "action": 0.26360154151916504}
{"mode": "train", "epochs": 12, "timestep": 22697, "ep_reward": 481.3497009277344, "reward": 0.9365818500518799, "action": 0.9739300608634949}
{"mode": "train", "epochs": 12, "timestep": 22698, "ep_reward": 482.2760009765625, "reward": 0.9262951612472534, "action": 1.300342321395874}
{"mode": "train", "epochs": 12, "timestep": 22699, "ep_reward": 483.18634033203125, "reward": 0.9103314280509949, "action": 0.8602362275123596}
{"mode": "train", "epochs": 12, "timestep": 22700, "ep_reward": 484.0713195800781, "reward": 0.8849650025367737, "action": -0.04292517900466919}
{"mode": "train", "epochs": 12, "timestep": 22701, "ep_reward": 484.9148254394531, "reward": 0.843518853187561, "action": 0.6566510200500488}
{"mode": "train", "epochs": 12, "timestep": 22702, "ep_reward": 485.7056884765625, "reward": 0.7908580899238586, "action": 1.1166679859161377}
{"mode": "train", "epochs": 12, "timestep": 22703, "ep_reward": 486.43194580078125, "reward": 0.7262524962425232, "action": 1.1545093059539795}
{"mode": "train", "epochs": 12, "timestep": 22704, "ep_reward": 487.0785827636719, "reward": 0.6466292142868042, "action": 0.2280026078224182}
{"mode": "train", "epochs": 12, "timestep": 22705, "ep_reward": 487.61981201171875, "reward": 0.5412294864654541, "action": 1.584458827972412}
{"mode": "train", "epochs": 12, "timestep": 22706, "ep_reward": 488.05682373046875, "reward": 0.4370194673538208, "action": 1.0493664741516113}
{"mode": "train", "epochs": 12, "timestep": 22707, "ep_reward": 488.37701416015625, "reward": 0.3201834559440613, "action": 1.745518445968628}
{"mode": "train", "epochs": 12, "timestep": 22708, "ep_reward": 488.58990478515625, "reward": 0.212904691696167, "action": 0.11159607768058777}
{"mode": "train", "epochs": 12, "timestep": 22709, "ep_reward": 488.8261413574219, "reward": 0.23623865842819214, "action": -1.0595496892929077}
{"mode": "train", "epochs": 12, "timestep": 22710, "ep_reward": 489.164794921875, "reward": 0.33865630626678467, "action": -0.08553582429885864}
{"mode": "train", "epochs": 12, "timestep": 22711, "ep_reward": 489.6154479980469, "reward": 0.45066511631011963, "action": -0.29444772005081177}
{"mode": "train", "epochs": 12, "timestep": 22712, "ep_reward": 490.1696472167969, "reward": 0.5542042255401611, "action": -0.9898584485054016}
{"mode": "train", "epochs": 12, "timestep": 22713, "ep_reward": 490.8117370605469, "reward": 0.6420788168907166, "action": -0.4772130846977234}
{"mode": "train", "epochs": 12, "timestep": 22714, "ep_reward": 491.5328674316406, "reward": 0.7211284637451172, "action": -0.8695827126502991}
{"mode": "train", "epochs": 12, "timestep": 22715, "ep_reward": 492.3161315917969, "reward": 0.7832680940628052, "action": -0.8418378233909607}
{"mode": "train", "epochs": 12, "timestep": 22716, "ep_reward": 493.1481628417969, "reward": 0.8320413827896118, "action": -1.3808486461639404}
{"mode": "train", "epochs": 12, "timestep": 22717, "ep_reward": 494.0151672363281, "reward": 0.8669928312301636, "action": -1.287017583847046}
{"mode": "train", "epochs": 12, "timestep": 22718, "ep_reward": 494.9080505371094, "reward": 0.8928890228271484, "action": -1.2556736469268799}
{"mode": "train", "epochs": 12, "timestep": 22719, "ep_reward": 495.8186340332031, "reward": 0.910592794418335, "action": -1.478596806526184}
{"mode": "train", "epochs": 12, "timestep": 22720, "ep_reward": 496.7397155761719, "reward": 0.9210795760154724, "action": -1.5837631225585938}
{"mode": "train", "epochs": 12, "timestep": 22721, "ep_reward": 497.6656799316406, "reward": 0.9259498715400696, "action": -0.5712943077087402}
{"mode": "train", "epochs": 12, "timestep": 22722, "ep_reward": 498.58953857421875, "reward": 0.9238495826721191, "action": -1.8416738510131836}
{"mode": "train", "epochs": 12, "timestep": 22723, "ep_reward": 499.5063171386719, "reward": 0.9167900681495667, "action": -1.8205476999282837}
{"mode": "train", "epochs": 12, "timestep": 22724, "ep_reward": 500.4109802246094, "reward": 0.9046676158905029, "action": -0.6650292873382568}
{"mode": "train", "epochs": 12, "timestep": 22725, "ep_reward": 501.29241943359375, "reward": 0.8814264535903931, "action": -1.3687419891357422}
{"mode": "train", "epochs": 12, "timestep": 22726, "ep_reward": 502.1434326171875, "reward": 0.8510075807571411, "action": -0.9742661118507385}
{"mode": "train", "epochs": 12, "timestep": 22727, "ep_reward": 502.950927734375, "reward": 0.8074894547462463, "action": -1.1395418643951416}
{"mode": "train", "epochs": 12, "timestep": 22728, "ep_reward": 503.7026062011719, "reward": 0.751686692237854, "action": -1.201350450515747}
{"mode": "train", "epochs": 12, "timestep": 22729, "ep_reward": 504.38494873046875, "reward": 0.6823381185531616, "action": -0.22222447395324707}
{"mode": "train", "epochs": 12, "timestep": 22730, "ep_reward": 504.97357177734375, "reward": 0.5886098146438599, "action": -0.510489284992218}
{"mode": "train", "epochs": 12, "timestep": 22731, "ep_reward": 505.4552307128906, "reward": 0.4816463589668274, "action": -0.19911161065101624}
{"mode": "train", "epochs": 12, "timestep": 22732, "ep_reward": 505.8146057128906, "reward": 0.3593686819076538, "action": 0.9424638152122498}
{"mode": "train", "epochs": 12, "timestep": 22733, "ep_reward": 506.0296630859375, "reward": 0.2150629162788391, "action": 0.05187886953353882}
{"mode": "train", "epochs": 12, "timestep": 22734, "ep_reward": 506.21697998046875, "reward": 0.18730485439300537, "action": 1.0868397951126099}
{"mode": "train", "epochs": 12, "timestep": 22735, "ep_reward": 506.5125732421875, "reward": 0.29559069871902466, "action": -0.5901821851730347}
{"mode": "train", "epochs": 12, "timestep": 22736, "ep_reward": 506.9344787597656, "reward": 0.4219099283218384, "action": -0.7943811416625977}
{"mode": "train", "epochs": 12, "timestep": 22737, "ep_reward": 507.4757080078125, "reward": 0.541226327419281, "action": 0.4506441354751587}
{"mode": "train", "epochs": 12, "timestep": 22738, "ep_reward": 508.1121520996094, "reward": 0.6364485621452332, "action": 0.9384949803352356}
{"mode": "train", "epochs": 12, "timestep": 22739, "ep_reward": 508.826904296875, "reward": 0.7147378325462341, "action": 1.2383559942245483}
{"mode": "train", "epochs": 12, "timestep": 22740, "ep_reward": 509.60479736328125, "reward": 0.7778805494308472, "action": 0.7753545045852661}
{"mode": "train", "epochs": 12, "timestep": 22741, "ep_reward": 510.4352111816406, "reward": 0.8304034471511841, "action": 0.9344589710235596}
{"mode": "train", "epochs": 12, "timestep": 22742, "ep_reward": 511.3047180175781, "reward": 0.8695032000541687, "action": 0.8909618258476257}
{"mode": "train", "epochs": 12, "timestep": 22743, "ep_reward": 512.2027587890625, "reward": 0.8980364799499512, "action": 0.2651011347770691}
{"mode": "train", "epochs": 12, "timestep": 22744, "ep_reward": 513.120849609375, "reward": 0.9180878400802612, "action": 0.8715339303016663}
{"mode": "train", "epochs": 12, "timestep": 22745, "ep_reward": 514.0491943359375, "reward": 0.9283159971237183, "action": 1.115907073020935}
{"mode": "train", "epochs": 12, "timestep": 22746, "ep_reward": 514.98095703125, "reward": 0.9317868947982788, "action": 0.3334934115409851}
{"mode": "train", "epochs": 12, "timestep": 22747, "ep_reward": 515.90869140625, "reward": 0.9277188181877136, "action": 0.9971907138824463}
{"mode": "train", "epochs": 12, "timestep": 22748, "ep_reward": 516.8255615234375, "reward": 0.9168785810470581, "action": -0.3573042154312134}
{"mode": "train", "epochs": 12, "timestep": 22749, "ep_reward": 517.7181396484375, "reward": 0.892591655254364, "action": 2.0}
{"mode": "train", "epochs": 12, "timestep": 22750, "ep_reward": 518.5852661132812, "reward": 0.8671352863311768, "action": 1.604802131652832}
{"mode": "train", "epochs": 12, "timestep": 22751, "ep_reward": 519.416748046875, "reward": 0.8314553499221802, "action": 0.9745341539382935}
{"mode": "train", "epochs": 12, "timestep": 22752, "ep_reward": 520.1972045898438, "reward": 0.7804816961288452, "action": 0.6410874128341675}
{"mode": "train", "epochs": 12, "timestep": 22753, "ep_reward": 520.9089965820312, "reward": 0.7117885947227478, "action": 2.0}
{"mode": "train", "epochs": 12, "timestep": 22754, "ep_reward": 521.5492553710938, "reward": 0.6402505040168762, "action": 0.6367045640945435}
{"mode": "train", "epochs": 12, "timestep": 22755, "ep_reward": 522.0923461914062, "reward": 0.5430867075920105, "action": 0.6229300498962402}
{"mode": "train", "epochs": 12, "timestep": 22756, "ep_reward": 522.5249633789062, "reward": 0.4326140284538269, "action": 0.7162847518920898}
{"mode": "train", "epochs": 12, "timestep": 22757, "ep_reward": 522.8403930664062, "reward": 0.3154541254043579, "action": 0.27826762199401855}
{"mode": "train", "epochs": 12, "timestep": 22758, "ep_reward": 523.0317993164062, "reward": 0.19140625, "action": -0.047511011362075806}
{"mode": "train", "epochs": 12, "timestep": 22759, "ep_reward": 523.2808837890625, "reward": 0.24907082319259644, "action": -1.8548088073730469}
{"mode": "train", "epochs": 12, "timestep": 22760, "ep_reward": 523.6266479492188, "reward": 0.3457382917404175, "action": -0.9512687921524048}
{"mode": "train", "epochs": 12, "timestep": 22761, "ep_reward": 524.0795288085938, "reward": 0.4528903365135193, "action": -1.874220848083496}
{"mode": "train", "epochs": 12, "timestep": 22762, "ep_reward": 524.6273193359375, "reward": 0.5477852821350098, "action": -0.7728487849235535}
{"mode": "train", "epochs": 12, "timestep": 22763, "ep_reward": 525.2713623046875, "reward": 0.6440306901931763, "action": -0.684603750705719}
{"mode": "train", "epochs": 12, "timestep": 22764, "ep_reward": 525.9979858398438, "reward": 0.7266056537628174, "action": -1.4370462894439697}
{"mode": "train", "epochs": 12, "timestep": 22765, "ep_reward": 526.7874145507812, "reward": 0.7894270420074463, "action": -0.33143407106399536}
{"mode": "train", "epochs": 12, "timestep": 22766, "ep_reward": 527.63232421875, "reward": 0.8449071645736694, "action": -0.6018997430801392}
{"mode": "train", "epochs": 12, "timestep": 22767, "ep_reward": 528.517333984375, "reward": 0.8849968314170837, "action": -0.916130006313324}
{"mode": "train", "epochs": 12, "timestep": 22768, "ep_reward": 529.4303588867188, "reward": 0.9130531549453735, "action": -1.0006346702575684}
{"mode": "train", "epochs": 12, "timestep": 22769, "ep_reward": 530.363037109375, "reward": 0.9326531887054443, "action": -1.3845033645629883}
{"mode": "train", "epochs": 12, "timestep": 22770, "ep_reward": 531.3085327148438, "reward": 0.9455026984214783, "action": -0.759210467338562}
{"mode": "train", "epochs": 12, "timestep": 22771, "ep_reward": 532.2628173828125, "reward": 0.9542558789253235, "action": -0.7485256195068359}
{"mode": "train", "epochs": 12, "timestep": 22772, "ep_reward": 533.2208251953125, "reward": 0.9579829573631287, "action": -1.0309135913848877}
{"mode": "train", "epochs": 12, "timestep": 22773, "ep_reward": 534.1782836914062, "reward": 0.9574739336967468, "action": -0.43032151460647583}
{"mode": "train", "epochs": 12, "timestep": 22774, "ep_reward": 535.1299438476562, "reward": 0.9516510963439941, "action": -1.2318451404571533}
{"mode": "train", "epochs": 12, "timestep": 22775, "ep_reward": 536.0720825195312, "reward": 0.9421272277832031, "action": -1.0148823261260986}
{"mode": "train", "epochs": 12, "timestep": 22776, "ep_reward": 536.9989013671875, "reward": 0.9268090128898621, "action": -0.5772331953048706}
{"mode": "train", "epochs": 12, "timestep": 22777, "ep_reward": 537.9013671875, "reward": 0.9024496674537659, "action": -0.4499266743659973}
{"mode": "train", "epochs": 12, "timestep": 22778, "ep_reward": 538.7683715820312, "reward": 0.8669837117195129, "action": -0.4475318491458893}
{"mode": "train", "epochs": 12, "timestep": 22779, "ep_reward": 539.58642578125, "reward": 0.8180506229400635, "action": -0.20509541034698486}
{"mode": "train", "epochs": 12, "timestep": 22780, "ep_reward": 540.3370361328125, "reward": 0.7506170868873596, "action": -0.5058337450027466}
{"mode": "train", "epochs": 12, "timestep": 22781, "ep_reward": 541.0034790039062, "reward": 0.6664270162582397, "action": 0.3979525566101074}
{"mode": "train", "epochs": 12, "timestep": 22782, "ep_reward": 541.5555419921875, "reward": 0.5520561933517456, "action": 0.3126879334449768}
{"mode": "train", "epochs": 12, "timestep": 22783, "ep_reward": 541.9723510742188, "reward": 0.4168086647987366, "action": 0.11976583302021027}
{"mode": "train", "epochs": 12, "timestep": 22784, "ep_reward": 542.2409057617188, "reward": 0.2685359716415405, "action": 0.44119662046432495}
{"mode": "train", "epochs": 12, "timestep": 22785, "ep_reward": 542.3501586914062, "reward": 0.10925430059432983, "action": 0.9763096570968628}
{"mode": "train", "epochs": 12, "timestep": 22786, "ep_reward": 542.5084228515625, "reward": 0.15824812650680542, "action": 0.718252956867218}
{"mode": "train", "epochs": 12, "timestep": 22787, "ep_reward": 542.7952270507812, "reward": 0.28682345151901245, "action": -0.677545428276062}
{"mode": "train", "epochs": 12, "timestep": 22788, "ep_reward": 543.2255249023438, "reward": 0.43029361963272095, "action": -0.5798988342285156}
{"mode": "train", "epochs": 12, "timestep": 22789, "ep_reward": 543.7855834960938, "reward": 0.5600332021713257, "action": -0.8590412735939026}
{"mode": "train", "epochs": 12, "timestep": 22790, "ep_reward": 544.4588623046875, "reward": 0.6732890605926514, "action": 0.875320553779602}
{"mode": "train", "epochs": 12, "timestep": 22791, "ep_reward": 545.2109985351562, "reward": 0.7521468997001648, "action": 1.0813721418380737}
{"mode": "train", "epochs": 12, "timestep": 22792, "ep_reward": 546.02490234375, "reward": 0.813886821269989, "action": 1.1166309118270874}
{"mode": "train", "epochs": 12, "timestep": 22793, "ep_reward": 546.8865356445312, "reward": 0.8616493940353394, "action": 0.4049444794654846}
{"mode": "train", "epochs": 12, "timestep": 22794, "ep_reward": 547.787353515625, "reward": 0.9008297324180603, "action": 0.5259064435958862}
{"mode": "train", "epochs": 12, "timestep": 22795, "ep_reward": 548.7160034179688, "reward": 0.9286611080169678, "action": 1.133772373199463}
{"mode": "train", "epochs": 12, "timestep": 22796, "ep_reward": 549.662841796875, "reward": 0.9468499422073364, "action": 1.0393738746643066}
{"mode": "train", "epochs": 12, "timestep": 22797, "ep_reward": 550.6231079101562, "reward": 0.9602687358856201, "action": 0.9155821800231934}
{"mode": "train", "epochs": 12, "timestep": 22798, "ep_reward": 551.5932006835938, "reward": 0.9701148867607117, "action": 0.46657097339630127}
{"mode": "train", "epochs": 12, "timestep": 22799, "ep_reward": 552.5706176757812, "reward": 0.9774377942085266, "action": 1.0598374605178833}
{"mode": "train", "epochs": 12, "timestep": 22800, "ep_reward": 553.5523071289062, "reward": 0.9816659688949585, "action": 0.3970727324485779}
{"mode": "train", "epochs": 12, "timestep": 22801, "ep_reward": 554.536865234375, "reward": 0.984564483165741, "action": -0.13844192028045654}
{"mode": "train", "epochs": 12, "timestep": 22802, "ep_reward": 555.5218505859375, "reward": 0.9849864840507507, "action": 1.75974702835083}
{"mode": "train", "epochs": 12, "timestep": 22803, "ep_reward": 556.5064697265625, "reward": 0.9846460819244385, "action": 1.1909356117248535}
{"mode": "train", "epochs": 12, "timestep": 22804, "ep_reward": 557.48974609375, "reward": 0.9832631349563599, "action": 1.2281386852264404}
{"mode": "train", "epochs": 12, "timestep": 22805, "ep_reward": 558.4706420898438, "reward": 0.9809015393257141, "action": 0.8529728651046753}
{"mode": "train", "epochs": 12, "timestep": 22806, "ep_reward": 559.4471435546875, "reward": 0.9765304923057556, "action": 0.6314500570297241}
{"mode": "train", "epochs": 12, "timestep": 22807, "ep_reward": 560.4164428710938, "reward": 0.9692978858947754, "action": 0.5022961497306824}
{"mode": "train", "epochs": 12, "timestep": 22808, "ep_reward": 561.37451171875, "reward": 0.9580889344215393, "action": 0.8373865485191345}
{"mode": "train", "epochs": 12, "timestep": 22809, "ep_reward": 562.3176879882812, "reward": 0.9431683421134949, "action": 0.9734053015708923}
{"mode": "train", "epochs": 12, "timestep": 22810, "ep_reward": 563.2406616210938, "reward": 0.9229971170425415, "action": 0.380105197429657}
{"mode": "train", "epochs": 12, "timestep": 22811, "ep_reward": 564.13232421875, "reward": 0.8916429877281189, "action": 0.9127250909805298}
{"mode": "train", "epochs": 12, "timestep": 22812, "ep_reward": 564.9843139648438, "reward": 0.8520191311836243, "action": 0.2333202362060547}
{"mode": "train", "epochs": 12, "timestep": 22813, "ep_reward": 565.7775268554688, "reward": 0.7932187914848328, "action": 1.2954868078231812}
{"mode": "train", "epochs": 12, "timestep": 22814, "ep_reward": 566.5033569335938, "reward": 0.7258390188217163, "action": 0.5736541152000427}
{"mode": "train", "epochs": 12, "timestep": 22815, "ep_reward": 567.136962890625, "reward": 0.6336036324501038, "action": 0.7265723943710327}
{"mode": "train", "epochs": 12, "timestep": 22816, "ep_reward": 567.6602783203125, "reward": 0.52332603931427, "action": 1.0192909240722656}
{"mode": "train", "epochs": 12, "timestep": 22817, "ep_reward": 568.0610961914062, "reward": 0.40081095695495605, "action": 1.0285178422927856}
{"mode": "train", "epochs": 12, "timestep": 22818, "ep_reward": 568.3309936523438, "reward": 0.26987361907958984, "action": 0.2394976019859314}
{"mode": "train", "epochs": 12, "timestep": 22819, "ep_reward": 568.4577026367188, "reward": 0.12667971849441528, "action": -0.4069579541683197}
{"mode": "train", "epochs": 12, "timestep": 22820, "ep_reward": 568.6534423828125, "reward": 0.19573837518692017, "action": 0.849504828453064}
{"mode": "train", "epochs": 12, "timestep": 22821, "ep_reward": 568.9864501953125, "reward": 0.33300238847732544, "action": -1.163942813873291}
{"mode": "train", "epochs": 12, "timestep": 22822, "ep_reward": 569.4324340820312, "reward": 0.44597935676574707, "action": 0.07366368174552917}
{"mode": "train", "epochs": 12, "timestep": 22823, "ep_reward": 569.9967651367188, "reward": 0.564332127571106, "action": -1.2946417331695557}
{"mode": "train", "epochs": 12, "timestep": 22824, "ep_reward": 570.6534423828125, "reward": 0.6566810011863708, "action": -0.3796050548553467}
{"mode": "train", "epochs": 12, "timestep": 22825, "ep_reward": 571.3952026367188, "reward": 0.7417499423027039, "action": -0.3954385221004486}
{"mode": "train", "epochs": 12, "timestep": 22826, "ep_reward": 572.204345703125, "reward": 0.8091347217559814, "action": -1.4736137390136719}
{"mode": "train", "epochs": 12, "timestep": 22827, "ep_reward": 573.0597534179688, "reward": 0.8553836345672607, "action": -1.5733764171600342}
{"mode": "train", "epochs": 12, "timestep": 22828, "ep_reward": 573.950439453125, "reward": 0.890667200088501, "action": -0.17775893211364746}
{"mode": "train", "epochs": 12, "timestep": 22829, "ep_reward": 574.8726806640625, "reward": 0.9222512245178223, "action": -0.49729710817337036}
{"mode": "train", "epochs": 12, "timestep": 22830, "ep_reward": 575.8160400390625, "reward": 0.94336998462677, "action": -1.1216386556625366}
{"mode": "train", "epochs": 12, "timestep": 22831, "ep_reward": 576.7728271484375, "reward": 0.9567769169807434, "action": -0.593393087387085}
{"mode": "train", "epochs": 12, "timestep": 22832, "ep_reward": 577.7396850585938, "reward": 0.9668307304382324, "action": -0.6073309183120728}
{"mode": "train", "epochs": 12, "timestep": 22833, "ep_reward": 578.7125854492188, "reward": 0.9729246497154236, "action": -0.8347697257995605}
{"mode": "train", "epochs": 12, "timestep": 22834, "ep_reward": 579.6883544921875, "reward": 0.9757644534111023, "action": -1.465161681175232}
{"mode": "train", "epochs": 12, "timestep": 22835, "ep_reward": 580.6650390625, "reward": 0.9766826629638672, "action": -0.7006816864013672}
{"mode": "train", "epochs": 12, "timestep": 22836, "ep_reward": 581.6405029296875, "reward": 0.9754473567008972, "action": -0.388995885848999}
{"mode": "train", "epochs": 12, "timestep": 22837, "ep_reward": 582.6114501953125, "reward": 0.9709235429763794, "action": -0.5325564742088318}
{"mode": "train", "epochs": 12, "timestep": 22838, "ep_reward": 583.5743408203125, "reward": 0.9628649950027466, "action": -0.9385056495666504}
{"mode": "train", "epochs": 12, "timestep": 22839, "ep_reward": 584.5260009765625, "reward": 0.9516581892967224, "action": -1.0369220972061157}
{"mode": "train", "epochs": 12, "timestep": 22840, "ep_reward": 585.4620361328125, "reward": 0.9360605478286743, "action": 0.49041587114334106}
{"mode": "train", "epochs": 12, "timestep": 22841, "ep_reward": 586.3683471679688, "reward": 0.9063202738761902, "action": -1.5343647003173828}
{"mode": "train", "epochs": 12, "timestep": 22842, "ep_reward": 587.2445068359375, "reward": 0.8761828541755676, "action": -1.3037054538726807}
{"mode": "train", "epochs": 12, "timestep": 22843, "ep_reward": 588.0791625976562, "reward": 0.8346437811851501, "action": -1.0121641159057617}
{"mode": "train", "epochs": 12, "timestep": 22844, "ep_reward": 588.8569946289062, "reward": 0.7778278589248657, "action": -0.5112674236297607}
{"mode": "train", "epochs": 12, "timestep": 22845, "ep_reward": 589.5568237304688, "reward": 0.6998465061187744, "action": -0.5737028121948242}
{"mode": "train", "epochs": 12, "timestep": 22846, "ep_reward": 590.1596069335938, "reward": 0.6028006672859192, "action": -0.21568064391613007}
{"mode": "train", "epochs": 12, "timestep": 22847, "ep_reward": 590.6419067382812, "reward": 0.4823101758956909, "action": 0.19981242716312408}
{"mode": "train", "epochs": 12, "timestep": 22848, "ep_reward": 590.9813232421875, "reward": 0.33938878774642944, "action": 0.2556823194026947}
{"mode": "train", "epochs": 12, "timestep": 22849, "ep_reward": 591.1661987304688, "reward": 0.18486666679382324, "action": -0.33378472924232483}
{"mode": "train", "epochs": 12, "timestep": 22850, "ep_reward": 591.280517578125, "reward": 0.11432182788848877, "action": 0.6387743949890137}
{"mode": "train", "epochs": 12, "timestep": 22851, "ep_reward": 591.5186767578125, "reward": 0.23817425966262817, "action": 0.19168508052825928}
{"mode": "train", "epochs": 12, "timestep": 22852, "ep_reward": 591.8883666992188, "reward": 0.36966508626937866, "action": -1.1027047634124756}
{"mode": "train", "epochs": 12, "timestep": 22853, "ep_reward": 592.3966674804688, "reward": 0.5083000659942627, "action": 0.42677852511405945}
{"mode": "train", "epochs": 12, "timestep": 22854, "ep_reward": 593.0130615234375, "reward": 0.6164087057113647, "action": 0.6616071462631226}
{"mode": "train", "epochs": 12, "timestep": 22855, "ep_reward": 593.7198486328125, "reward": 0.706811785697937, "action": 0.9940351247787476}
{"mode": "train", "epochs": 12, "timestep": 22856, "ep_reward": 594.4982299804688, "reward": 0.7783811688423157, "action": 0.8278378248214722}
{"mode": "train", "epochs": 12, "timestep": 22857, "ep_reward": 595.3340454101562, "reward": 0.8358261585235596, "action": 0.5998173952102661}
{"mode": "train", "epochs": 12, "timestep": 22858, "ep_reward": 596.214599609375, "reward": 0.880561351776123, "action": 1.133946418762207}
{"mode": "train", "epochs": 12, "timestep": 22859, "ep_reward": 597.1260986328125, "reward": 0.9114885926246643, "action": 1.1721882820129395}
{"mode": "train", "epochs": 12, "timestep": 22860, "ep_reward": 598.060302734375, "reward": 0.934213399887085, "action": 1.0936906337738037}
{"mode": "train", "epochs": 12, "timestep": 22861, "ep_reward": 599.0113525390625, "reward": 0.9510357975959778, "action": 1.1576629877090454}
{"mode": "train", "epochs": 12, "timestep": 22862, "ep_reward": 599.9743041992188, "reward": 0.9629215002059937, "action": 1.9381639957427979}
{"mode": "train", "epochs": 12, "timestep": 22863, "ep_reward": 600.9446411132812, "reward": 0.9703539609909058, "action": 0.8829438090324402}
{"mode": "train", "epochs": 12, "timestep": 22864, "ep_reward": 601.92236328125, "reward": 0.9777032732963562, "action": 0.5802232027053833}
{"mode": "train", "epochs": 12, "timestep": 22865, "ep_reward": 602.9054565429688, "reward": 0.9831094145774841, "action": 1.3921709060668945}
{"mode": "train", "epochs": 12, "timestep": 22866, "ep_reward": 603.8916625976562, "reward": 0.9861775040626526, "action": 0.574899435043335}
{"mode": "train", "epochs": 12, "timestep": 22867, "ep_reward": 604.8805541992188, "reward": 0.9889122843742371, "action": 0.901603102684021}
{"mode": "train", "epochs": 12, "timestep": 22868, "ep_reward": 605.8709716796875, "reward": 0.9903888702392578, "action": 1.214110016822815}
{"mode": "train", "epochs": 12, "timestep": 22869, "ep_reward": 606.8623046875, "reward": 0.9913203120231628, "action": 0.20818525552749634}
{"mode": "train", "epochs": 12, "timestep": 22870, "ep_reward": 607.853759765625, "reward": 0.9914329648017883, "action": 1.6901394128799438}
{"mode": "train", "epochs": 12, "timestep": 22871, "ep_reward": 608.84521484375, "reward": 0.9914743900299072, "action": 1.0684295892715454}
{"mode": "train", "epochs": 12, "timestep": 22872, "ep_reward": 609.8363037109375, "reward": 0.9911137819290161, "action": 0.2521477937698364}
{"mode": "train", "epochs": 12, "timestep": 22873, "ep_reward": 610.8257446289062, "reward": 0.9894141554832458, "action": 0.9473567008972168}
{"mode": "train", "epochs": 12, "timestep": 22874, "ep_reward": 611.81298828125, "reward": 0.987250566482544, "action": 1.2379988431930542}
{"mode": "train", "epochs": 12, "timestep": 22875, "ep_reward": 612.7976684570312, "reward": 0.9846525192260742, "action": 1.247267246246338}
{"mode": "train", "epochs": 12, "timestep": 22876, "ep_reward": 613.77880859375, "reward": 0.9811651706695557, "action": 1.0045939683914185}
{"mode": "train", "epochs": 12, "timestep": 22877, "ep_reward": 614.754638671875, "reward": 0.9758081436157227, "action": 0.9094430804252625}
{"mode": "train", "epochs": 12, "timestep": 22878, "ep_reward": 615.7225952148438, "reward": 0.9679722785949707, "action": 1.1981956958770752}
{"mode": "train", "epochs": 12, "timestep": 22879, "ep_reward": 616.6806030273438, "reward": 0.9579928517341614, "action": 1.2312510013580322}
{"mode": "train", "epochs": 12, "timestep": 22880, "ep_reward": 617.6250610351562, "reward": 0.9444639682769775, "action": 0.7851159572601318}
{"mode": "train", "epochs": 12, "timestep": 22881, "ep_reward": 618.5486450195312, "reward": 0.9235563278198242, "action": 1.7698397636413574}
{"mode": "train", "epochs": 12, "timestep": 22882, "ep_reward": 619.4491577148438, "reward": 0.9004977345466614, "action": 0.9682754874229431}
{"mode": "train", "epochs": 12, "timestep": 22883, "ep_reward": 620.3135375976562, "reward": 0.8643699288368225, "action": 2.0}
{"mode": "train", "epochs": 12, "timestep": 22884, "ep_reward": 621.1376342773438, "reward": 0.8241073489189148, "action": 1.512306571006775}
{"mode": "train", "epochs": 12, "timestep": 22885, "ep_reward": 621.9061279296875, "reward": 0.7685167789459229, "action": 0.7269313335418701}
{"mode": "train", "epochs": 12, "timestep": 22886, "ep_reward": 622.5964965820312, "reward": 0.6903924942016602, "action": 1.8111786842346191}
{"mode": "train", "epochs": 12, "timestep": 22887, "ep_reward": 623.20263671875, "reward": 0.6061509847640991, "action": 0.58882737159729}
{"mode": "train", "epochs": 12, "timestep": 22888, "ep_reward": 623.6964111328125, "reward": 0.4937993884086609, "action": 0.8071281909942627}
{"mode": "train", "epochs": 12, "timestep": 22889, "ep_reward": 624.06689453125, "reward": 0.3704802393913269, "action": 0.4520987868309021}
{"mode": "train", "epochs": 12, "timestep": 22890, "ep_reward": 624.3026733398438, "reward": 0.23576927185058594, "action": -0.07119512557983398}
{"mode": "train", "epochs": 12, "timestep": 22891, "ep_reward": 624.4346923828125, "reward": 0.1319950819015503, "action": -0.2302931398153305}
{"mode": "train", "epochs": 12, "timestep": 22892, "ep_reward": 624.6871337890625, "reward": 0.25244373083114624, "action": 0.22477425634860992}
{"mode": "train", "epochs": 12, "timestep": 22893, "ep_reward": 625.0665283203125, "reward": 0.3793705701828003, "action": 0.08608025312423706}
{"mode": "train", "epochs": 12, "timestep": 22894, "ep_reward": 625.56591796875, "reward": 0.4993664622306824, "action": -1.3277465105056763}
{"mode": "train", "epochs": 12, "timestep": 22895, "ep_reward": 626.1625366210938, "reward": 0.5966286659240723, "action": -1.1622116565704346}
{"mode": "train", "epochs": 12, "timestep": 22896, "ep_reward": 626.8465576171875, "reward": 0.6840373277664185, "action": -1.4129165410995483}
{"mode": "train", "epochs": 12, "timestep": 22897, "ep_reward": 627.6024780273438, "reward": 0.7559288740158081, "action": -0.45935383439064026}
{"mode": "train", "epochs": 12, "timestep": 22898, "ep_reward": 628.4220581054688, "reward": 0.8195520043373108, "action": -0.5812333226203918}
{"mode": "train", "epochs": 12, "timestep": 22899, "ep_reward": 629.2893676757812, "reward": 0.8673350811004639, "action": -1.0383319854736328}
{"mode": "train", "epochs": 12, "timestep": 22900, "ep_reward": 630.1904296875, "reward": 0.9010372161865234, "action": -0.8734104037284851}
{"mode": "train", "epochs": 12, "timestep": 22901, "ep_reward": 631.1166381835938, "reward": 0.9262336492538452, "action": -1.0787725448608398}
{"mode": "train", "epochs": 12, "timestep": 22902, "ep_reward": 632.0603637695312, "reward": 0.9437397718429565, "action": 0.21647804975509644}
{"mode": "train", "epochs": 12, "timestep": 22903, "ep_reward": 633.0178833007812, "reward": 0.957500696182251, "action": -0.7424989938735962}
{"mode": "train", "epochs": 12, "timestep": 22904, "ep_reward": 633.9816284179688, "reward": 0.9637622833251953, "action": -2.0}
{"mode": "train", "epochs": 12, "timestep": 22905, "ep_reward": 634.9483032226562, "reward": 0.9666746258735657, "action": -1.1733640432357788}
{"mode": "train", "epochs": 12, "timestep": 22906, "ep_reward": 635.9159545898438, "reward": 0.9676246643066406, "action": -0.6752140522003174}
{"mode": "train", "epochs": 12, "timestep": 22907, "ep_reward": 636.881103515625, "reward": 0.9651485085487366, "action": -0.7692399024963379}
{"mode": "train", "epochs": 12, "timestep": 22908, "ep_reward": 637.8399658203125, "reward": 0.9588900208473206, "action": -0.7383826971054077}
{"mode": "train", "epochs": 12, "timestep": 22909, "ep_reward": 638.7880859375, "reward": 0.9480981230735779, "action": -0.2874242663383484}
{"mode": "train", "epochs": 12, "timestep": 22910, "ep_reward": 639.7178955078125, "reward": 0.9298230409622192, "action": -0.21402639150619507}
{"mode": "train", "epochs": 12, "timestep": 22911, "ep_reward": 640.6203002929688, "reward": 0.9023861885070801, "action": -0.408796101808548}
{"mode": "train", "epochs": 12, "timestep": 22912, "ep_reward": 641.48486328125, "reward": 0.8645601272583008, "action": -0.7614431381225586}
{"mode": "train", "epochs": 12, "timestep": 22913, "ep_reward": 642.3003540039062, "reward": 0.8154990673065186, "action": -0.48246872425079346}
{"mode": "train", "epochs": 12, "timestep": 22914, "ep_reward": 643.0486450195312, "reward": 0.7483062744140625, "action": -0.07489767670631409}
{"mode": "train", "epochs": 12, "timestep": 22915, "ep_reward": 643.7061767578125, "reward": 0.6575435996055603, "action": -1.0240527391433716}
{"mode": "train", "epochs": 12, "timestep": 22916, "ep_reward": 644.2625122070312, "reward": 0.5563620328903198, "action": 0.1524389237165451}
{"mode": "train", "epochs": 12, "timestep": 22917, "ep_reward": 644.6862182617188, "reward": 0.4237126111984253, "action": -0.13612431287765503}
{"mode": "train", "epochs": 12, "timestep": 22918, "ep_reward": 644.966064453125, "reward": 0.2798733711242676, "action": 0.5709037780761719}
{"mode": "train", "epochs": 12, "timestep": 22919, "ep_reward": 645.085693359375, "reward": 0.11962753534317017, "action": 0.3747802674770355}
{"mode": "train", "epochs": 12, "timestep": 22920, "ep_reward": 645.2447509765625, "reward": 0.1590632200241089, "action": 0.27355581521987915}
{"mode": "train", "epochs": 12, "timestep": 22921, "ep_reward": 645.5350952148438, "reward": 0.29031848907470703, "action": -1.0330244302749634}
{"mode": "train", "epochs": 12, "timestep": 22922, "ep_reward": 645.96923828125, "reward": 0.43414074182510376, "action": -0.4455137848854065}
{"mode": "train", "epochs": 12, "timestep": 22923, "ep_reward": 646.5283813476562, "reward": 0.5591674447059631, "action": -0.5737276673316956}
{"mode": "train", "epochs": 12, "timestep": 22924, "ep_reward": 647.1963500976562, "reward": 0.6679637432098389, "action": 0.7642243504524231}
{"mode": "train", "epochs": 12, "timestep": 22925, "ep_reward": 647.943603515625, "reward": 0.7472716569900513, "action": 1.161088466644287}
{"mode": "train", "epochs": 12, "timestep": 22926, "ep_reward": 648.7522583007812, "reward": 0.8086245059967041, "action": 0.6012687683105469}
{"mode": "train", "epochs": 12, "timestep": 22927, "ep_reward": 649.6114501953125, "reward": 0.859210729598999, "action": 1.2654680013656616}
{"mode": "train", "epochs": 12, "timestep": 22928, "ep_reward": 650.5057983398438, "reward": 0.8943387269973755, "action": 1.1747170686721802}
{"mode": "train", "epochs": 12, "timestep": 22929, "ep_reward": 651.4266967773438, "reward": 0.9209118485450745, "action": 0.947049617767334}
{"mode": "train", "epochs": 12, "timestep": 22930, "ep_reward": 652.36767578125, "reward": 0.9409767985343933, "action": -0.0517728328704834}
{"mode": "train", "epochs": 12, "timestep": 22931, "ep_reward": 653.324462890625, "reward": 0.9568003416061401, "action": 0.4720938205718994}
{"mode": "train", "epochs": 12, "timestep": 22932, "ep_reward": 654.2900390625, "reward": 0.9655788540840149, "action": 0.8083451986312866}
{"mode": "train", "epochs": 12, "timestep": 22933, "ep_reward": 655.2600708007812, "reward": 0.9700117707252502, "action": 0.5058557987213135}
{"mode": "train", "epochs": 12, "timestep": 22934, "ep_reward": 656.2308959960938, "reward": 0.9708454012870789, "action": 2.0}
{"mode": "train", "epochs": 12, "timestep": 22935, "ep_reward": 657.2011108398438, "reward": 0.9702044725418091, "action": 0.7387145757675171}
{"mode": "train", "epochs": 12, "timestep": 22936, "ep_reward": 658.1673583984375, "reward": 0.966256320476532, "action": 1.2234023809432983}
{"mode": "train", "epochs": 12, "timestep": 22937, "ep_reward": 659.127197265625, "reward": 0.9598488211631775, "action": 0.7654120922088623}
{"mode": "train", "epochs": 12, "timestep": 22938, "ep_reward": 660.07568359375, "reward": 0.9484847187995911, "action": 1.5300278663635254}
{"mode": "train", "epochs": 12, "timestep": 22939, "ep_reward": 661.01025390625, "reward": 0.9345682859420776, "action": 1.8018369674682617}
{"mode": "train", "epochs": 12, "timestep": 22940, "ep_reward": 661.92724609375, "reward": 0.9170026183128357, "action": 0.5661543607711792}
{"mode": "train", "epochs": 12, "timestep": 22941, "ep_reward": 662.8139038085938, "reward": 0.8866403102874756, "action": 1.163275957107544}
{"mode": "train", "epochs": 12, "timestep": 22942, "ep_reward": 663.6624755859375, "reward": 0.8485839366912842, "action": 1.4429517984390259}
{"mode": "train", "epochs": 12, "timestep": 22943, "ep_reward": 664.4629516601562, "reward": 0.8004841804504395, "action": 1.4577535390853882}
{"mode": "train", "epochs": 12, "timestep": 22944, "ep_reward": 665.2020874023438, "reward": 0.739148736000061, "action": 1.1978470087051392}
{"mode": "train", "epochs": 12, "timestep": 22945, "ep_reward": 665.8626098632812, "reward": 0.6604998111724854, "action": 0.6456882357597351}
{"mode": "train", "epochs": 12, "timestep": 22946, "ep_reward": 666.42236328125, "reward": 0.5597600936889648, "action": 0.06904023885726929}
{"mode": "train", "epochs": 12, "timestep": 22947, "ep_reward": 666.8580322265625, "reward": 0.435668408870697, "action": 0.06105107069015503}
{"mode": "train", "epochs": 12, "timestep": 22948, "ep_reward": 667.1563110351562, "reward": 0.2982526421546936, "action": 0.1468716859817505}
{"mode": "train", "epochs": 12, "timestep": 22949, "ep_reward": 667.313232421875, "reward": 0.1569322943687439, "action": 1.2525761127471924}
{"mode": "train", "epochs": 12, "timestep": 22950, "ep_reward": 667.5167846679688, "reward": 0.20357149839401245, "action": 0.24446001648902893}
{"mode": "train", "epochs": 12, "timestep": 22951, "ep_reward": 667.8441772460938, "reward": 0.32736825942993164, "action": -1.2561248540878296}
{"mode": "train", "epochs": 12, "timestep": 22952, "ep_reward": 668.279541015625, "reward": 0.43538379669189453, "action": -0.5987341403961182}
{"mode": "train", "epochs": 12, "timestep": 22953, "ep_reward": 668.8248291015625, "reward": 0.545312762260437, "action": 0.28020530939102173}
{"mode": "train", "epochs": 12, "timestep": 22954, "ep_reward": 669.475341796875, "reward": 0.6505136489868164, "action": -0.7603586912155151}
{"mode": "train", "epochs": 12, "timestep": 22955, "ep_reward": 670.2061767578125, "reward": 0.7308111786842346, "action": -1.117685079574585}
{"mode": "train", "epochs": 12, "timestep": 22956, "ep_reward": 671.000244140625, "reward": 0.7940608859062195, "action": -0.6049423217773438}
{"mode": "train", "epochs": 12, "timestep": 22957, "ep_reward": 671.8464965820312, "reward": 0.8462756276130676, "action": -0.9169721603393555}
{"mode": "train", "epochs": 12, "timestep": 22958, "ep_reward": 672.730712890625, "reward": 0.8841865658760071, "action": -0.5882370471954346}
{"mode": "train", "epochs": 12, "timestep": 22959, "ep_reward": 673.6434326171875, "reward": 0.9126982688903809, "action": -0.8910030126571655}
{"mode": "train", "epochs": 12, "timestep": 22960, "ep_reward": 674.5750122070312, "reward": 0.9315906167030334, "action": -0.36961013078689575}
{"mode": "train", "epochs": 12, "timestep": 22961, "ep_reward": 675.51904296875, "reward": 0.9440551996231079, "action": -0.7203752994537354}
{"mode": "train", "epochs": 12, "timestep": 22962, "ep_reward": 676.4685668945312, "reward": 0.9495409727096558, "action": -0.80474454164505}
{"mode": "train", "epochs": 12, "timestep": 22963, "ep_reward": 677.4180908203125, "reward": 0.9495536684989929, "action": -0.726555347442627}
{"mode": "train", "epochs": 12, "timestep": 22964, "ep_reward": 678.3621215820312, "reward": 0.9440034627914429, "action": -1.0642292499542236}
{"mode": "train", "epochs": 12, "timestep": 22965, "ep_reward": 679.2953491210938, "reward": 0.9332277178764343, "action": -1.7904181480407715}
{"mode": "train", "epochs": 12, "timestep": 22966, "ep_reward": 680.2145385742188, "reward": 0.9192116260528564, "action": -0.9930791854858398}
{"mode": "train", "epochs": 12, "timestep": 22967, "ep_reward": 681.1105346679688, "reward": 0.8959906697273254, "action": -1.1450477838516235}
{"mode": "train", "epochs": 12, "timestep": 22968, "ep_reward": 681.974853515625, "reward": 0.864291787147522, "action": -0.9024066925048828}
{"mode": "train", "epochs": 12, "timestep": 22969, "ep_reward": 682.7947387695312, "reward": 0.8198846578598022, "action": -1.126330852508545}
{"mode": "train", "epochs": 12, "timestep": 22970, "ep_reward": 683.5580444335938, "reward": 0.7633330225944519, "action": 0.1103462278842926}
{"mode": "train", "epochs": 12, "timestep": 22971, "ep_reward": 684.2379150390625, "reward": 0.6798457503318787, "action": 0.0993482768535614}
{"mode": "train", "epochs": 12, "timestep": 22972, "ep_reward": 684.81298828125, "reward": 0.5750961303710938, "action": -0.17406940460205078}
{"mode": "train", "epochs": 12, "timestep": 22973, "ep_reward": 685.2667846679688, "reward": 0.4537857174873352, "action": 1.4255791902542114}
{"mode": "train", "epochs": 12, "timestep": 22974, "ep_reward": 685.562744140625, "reward": 0.2959367632865906, "action": 0.2806900143623352}
{"mode": "train", "epochs": 12, "timestep": 22975, "ep_reward": 685.7053833007812, "reward": 0.14266395568847656, "action": -1.0825169086456299}
{"mode": "train", "epochs": 12, "timestep": 22976, "ep_reward": 685.8794555664062, "reward": 0.17408186197280884, "action": 0.3392908573150635}
{"mode": "train", "epochs": 12, "timestep": 22977, "ep_reward": 686.1775512695312, "reward": 0.29812341928482056, "action": -0.27558034658432007}
{"mode": "train", "epochs": 12, "timestep": 22978, "ep_reward": 686.6055297851562, "reward": 0.4279891848564148, "action": -0.8935285806655884}
{"mode": "train", "epochs": 12, "timestep": 22979, "ep_reward": 687.15966796875, "reward": 0.5541141033172607, "action": -0.08319548517465591}
{"mode": "train", "epochs": 12, "timestep": 22980, "ep_reward": 687.8161010742188, "reward": 0.6564592123031616, "action": 0.20732784271240234}
{"mode": "train", "epochs": 12, "timestep": 22981, "ep_reward": 688.555419921875, "reward": 0.7392945289611816, "action": 1.3084986209869385}
{"mode": "train", "epochs": 12, "timestep": 22982, "ep_reward": 689.3545532226562, "reward": 0.7991597056388855, "action": 1.9362953901290894}
{"mode": "train", "epochs": 12, "timestep": 22983, "ep_reward": 690.1984252929688, "reward": 0.8438860177993774, "action": 1.0513687133789062}
{"mode": "train", "epochs": 12, "timestep": 22984, "ep_reward": 691.080810546875, "reward": 0.8823761343955994, "action": 1.8379005193710327}
{"mode": "train", "epochs": 12, "timestep": 22985, "ep_reward": 691.9895629882812, "reward": 0.9087597131729126, "action": 0.3658267855644226}
{"mode": "train", "epochs": 12, "timestep": 22986, "ep_reward": 692.9217529296875, "reward": 0.9321771860122681, "action": 0.8143562078475952}
{"mode": "train", "epochs": 12, "timestep": 22987, "ep_reward": 693.8685913085938, "reward": 0.9468405842781067, "action": 0.8194007277488708}
{"mode": "train", "epochs": 12, "timestep": 22988, "ep_reward": 694.8245239257812, "reward": 0.9559234976768494, "action": 0.7264223098754883}
{"mode": "train", "epochs": 12, "timestep": 22989, "ep_reward": 695.7848510742188, "reward": 0.9603428244590759, "action": 0.17870426177978516}
{"mode": "train", "epochs": 12, "timestep": 22990, "ep_reward": 696.7444458007812, "reward": 0.959587037563324, "action": 1.5075364112854004}
{"mode": "train", "epochs": 12, "timestep": 22991, "ep_reward": 697.7001953125, "reward": 0.9557265639305115, "action": 0.8559081554412842}
{"mode": "train", "epochs": 12, "timestep": 22992, "ep_reward": 698.6470947265625, "reward": 0.9469212889671326, "action": 1.2986693382263184}
{"mode": "train", "epochs": 12, "timestep": 22993, "ep_reward": 699.581298828125, "reward": 0.9342056512832642, "action": 1.1925489902496338}
{"mode": "train", "epochs": 12, "timestep": 22994, "ep_reward": 700.4967651367188, "reward": 0.9154849052429199, "action": 0.8960868120193481}
{"mode": "train", "epochs": 12, "timestep": 22995, "ep_reward": 701.3844604492188, "reward": 0.8877004981040955, "action": 1.1792272329330444}
{"mode": "train", "epochs": 12, "timestep": 22996, "ep_reward": 702.23583984375, "reward": 0.8513880372047424, "action": -0.18112802505493164}
{"mode": "train", "epochs": 12, "timestep": 22997, "ep_reward": 703.0283203125, "reward": 0.7924677133560181, "action": 1.7789561748504639}
{"mode": "train", "epochs": 12, "timestep": 22998, "ep_reward": 703.7603149414062, "reward": 0.7319954633712769, "action": 0.430189847946167}
{"mode": "train", "epochs": 12, "timestep": 22999, "ep_reward": 704.4041137695312, "reward": 0.6437894105911255, "action": 1.4662574529647827}
{"mode": "train", "epochs": 12, "timestep": 23000, "ep_reward": 704.953125, "reward": 0.5490171909332275, "action": 0.578077495098114}
{"mode": "train", "epochs": 12, "timestep": 23001, "ep_reward": 705.384033203125, "reward": 0.43091630935668945, "action": 0.5715212821960449}
{"mode": "train", "epochs": 12, "timestep": 23002, "ep_reward": 705.6864624023438, "reward": 0.3024584650993347, "action": 1.7058930397033691}
{"mode": "train", "epochs": 12, "timestep": 23003, "ep_reward": 705.874755859375, "reward": 0.18828970193862915, "action": 1.379402995109558}
{"mode": "train", "epochs": 12, "timestep": 23004, "ep_reward": 706.10498046875, "reward": 0.23020410537719727, "action": -0.5127852559089661}
{"mode": "train", "epochs": 12, "timestep": 23005, "ep_reward": 706.4443969726562, "reward": 0.33942294120788574, "action": -0.2584126591682434}
{"mode": "train", "epochs": 12, "timestep": 23006, "ep_reward": 706.8950805664062, "reward": 0.45069271326065063, "action": 0.088764488697052}
{"mode": "train", "epochs": 12, "timestep": 23007, "ep_reward": 707.4532470703125, "reward": 0.5581904649734497, "action": -0.4667068123817444}
{"mode": "train", "epochs": 12, "timestep": 23008, "ep_reward": 708.1023559570312, "reward": 0.6491134166717529, "action": -1.6073930263519287}
{"mode": "train", "epochs": 12, "timestep": 23009, "ep_reward": 708.8220825195312, "reward": 0.7197098135948181, "action": -1.612317681312561}
{"mode": "train", "epochs": 12, "timestep": 23010, "ep_reward": 709.6012573242188, "reward": 0.7791903018951416, "action": -1.0069913864135742}
{"mode": "train", "epochs": 12, "timestep": 23011, "ep_reward": 710.4312133789062, "reward": 0.8299522399902344, "action": -1.1497411727905273}
{"mode": "train", "epochs": 12, "timestep": 23012, "ep_reward": 711.2994384765625, "reward": 0.8682217597961426, "action": -0.5469061136245728}
{"mode": "train", "epochs": 12, "timestep": 23013, "ep_reward": 712.1971435546875, "reward": 0.8977070450782776, "action": -1.0067909955978394}
{"mode": "train", "epochs": 12, "timestep": 23014, "ep_reward": 713.113525390625, "reward": 0.9163963794708252, "action": -0.8000732660293579}
{"mode": "train", "epochs": 12, "timestep": 23015, "ep_reward": 714.0411376953125, "reward": 0.927608847618103, "action": -0.4554002285003662}
{"mode": "train", "epochs": 12, "timestep": 23016, "ep_reward": 714.9722900390625, "reward": 0.9311776161193848, "action": -1.0438730716705322}
{"mode": "train", "epochs": 12, "timestep": 23017, "ep_reward": 715.89990234375, "reward": 0.9275906085968018, "action": -2.0}
{"mode": "train", "epochs": 12, "timestep": 23018, "ep_reward": 716.8201293945312, "reward": 0.9202168583869934, "action": -1.0285601615905762}
{"mode": "train", "epochs": 12, "timestep": 23019, "ep_reward": 717.7249755859375, "reward": 0.9048742651939392, "action": -0.6361725926399231}
{"mode": "train", "epochs": 12, "timestep": 23020, "ep_reward": 718.604248046875, "reward": 0.8792811036109924, "action": -0.2731512784957886}
{"mode": "train", "epochs": 12, "timestep": 23021, "ep_reward": 719.4442138671875, "reward": 0.8399658799171448, "action": -0.3477899134159088}
{"mode": "train", "epochs": 12, "timestep": 23022, "ep_reward": 720.2301635742188, "reward": 0.7859690189361572, "action": 0.20431634783744812}
{"mode": "train", "epochs": 12, "timestep": 23023, "ep_reward": 720.93994140625, "reward": 0.7097563743591309, "action": 0.15707574784755707}
{"mode": "train", "epochs": 12, "timestep": 23024, "ep_reward": 721.5526123046875, "reward": 0.6126813888549805, "action": 0.3816596567630768}
{"mode": "train", "epochs": 12, "timestep": 23025, "ep_reward": 722.0447387695312, "reward": 0.4920960068702698, "action": -0.6351817846298218}
{"mode": "train", "epochs": 12, "timestep": 23026, "ep_reward": 722.4119873046875, "reward": 0.3672388792037964, "action": 1.3754793405532837}
{"mode": "train", "epochs": 12, "timestep": 23027, "ep_reward": 722.6182861328125, "reward": 0.20628494024276733, "action": -0.45318907499313354}
{"mode": "train", "epochs": 12, "timestep": 23028, "ep_reward": 722.7511596679688, "reward": 0.1329026222229004, "action": 0.2792506814002991}
{"mode": "train", "epochs": 12, "timestep": 23029, "ep_reward": 723.0067749023438, "reward": 0.2555866241455078, "action": -1.2211291790008545}
{"mode": "train", "epochs": 12, "timestep": 23030, "ep_reward": 723.4014892578125, "reward": 0.3947080969810486, "action": -0.952482283115387}
{"mode": "train", "epochs": 12, "timestep": 23031, "ep_reward": 723.9227294921875, "reward": 0.5212259888648987, "action": -0.37212055921554565}
{"mode": "train", "epochs": 12, "timestep": 23032, "ep_reward": 724.5503540039062, "reward": 0.6276317834854126, "action": 0.9945180416107178}
{"mode": "train", "epochs": 12, "timestep": 23033, "ep_reward": 725.258544921875, "reward": 0.7081654071807861, "action": 0.1936621069908142}
{"mode": "train", "epochs": 12, "timestep": 23034, "ep_reward": 726.0377807617188, "reward": 0.7792147397994995, "action": 1.3245725631713867}
{"mode": "train", "epochs": 12, "timestep": 23035, "ep_reward": 726.8670043945312, "reward": 0.8291940093040466, "action": 0.6293538808822632}
{"mode": "train", "epochs": 12, "timestep": 23036, "ep_reward": 727.7371826171875, "reward": 0.8701705932617188, "action": 1.5102753639221191}
{"mode": "train", "epochs": 12, "timestep": 23037, "ep_reward": 728.6346435546875, "reward": 0.8974422216415405, "action": 1.1930592060089111}
{"mode": "train", "epochs": 12, "timestep": 23038, "ep_reward": 729.5524291992188, "reward": 0.9178103804588318, "action": 0.6588677167892456}
{"mode": "train", "epochs": 12, "timestep": 23039, "ep_reward": 730.48388671875, "reward": 0.9314640760421753, "action": 1.4724714756011963}
{"mode": "train", "epochs": 12, "timestep": 23040, "ep_reward": 731.421875, "reward": 0.9379953145980835, "action": 1.1520805358886719}
{"mode": "train", "epochs": 12, "timestep": 23041, "ep_reward": 732.3613891601562, "reward": 0.9395073652267456, "action": 1.3916831016540527}
{"mode": "train", "epochs": 12, "timestep": 23042, "ep_reward": 733.2975463867188, "reward": 0.9361346364021301, "action": 1.297461986541748}
{"mode": "train", "epochs": 12, "timestep": 23043, "ep_reward": 734.22509765625, "reward": 0.9275525808334351, "action": 0.8393237590789795}
{"mode": "train", "epochs": 12, "timestep": 23044, "ep_reward": 735.13623046875, "reward": 0.9111204743385315, "action": 2.0}
{"mode": "train", "epochs": 12, "timestep": 23045, "ep_reward": 736.02783203125, "reward": 0.8915923833847046, "action": 1.7017165422439575}
{"mode": "train", "epochs": 12, "timestep": 23046, "ep_reward": 736.8917846679688, "reward": 0.8639301061630249, "action": 1.326565146446228}
{"mode": "train", "epochs": 12, "timestep": 23047, "ep_reward": 737.7166137695312, "reward": 0.824805736541748, "action": 1.7292571067810059}
{"mode": "train", "epochs": 12, "timestep": 23048, "ep_reward": 738.4935913085938, "reward": 0.7769506573677063, "action": 1.293313980102539}
{"mode": "train", "epochs": 12, "timestep": 23049, "ep_reward": 739.20703125, "reward": 0.7134603261947632, "action": 1.3735480308532715}
{"mode": "train", "epochs": 12, "timestep": 23050, "ep_reward": 739.8439331054688, "reward": 0.6368959546089172, "action": 0.3419305682182312}
{"mode": "train", "epochs": 12, "timestep": 23051, "ep_reward": 740.3798828125, "reward": 0.5359548926353455, "action": 0.8356469869613647}
{"mode": "train", "epochs": 12, "timestep": 23052, "ep_reward": 740.8068237304688, "reward": 0.4269132614135742, "action": 0.9671793580055237}
{"mode": "train", "epochs": 12, "timestep": 23053, "ep_reward": 741.1196899414062, "reward": 0.3128699064254761, "action": 0.8997647166252136}
{"mode": "train", "epochs": 12, "timestep": 23054, "ep_reward": 741.3180541992188, "reward": 0.19835978746414185, "action": 0.4216609597206116}
{"mode": "train", "epochs": 12, "timestep": 23055, "ep_reward": 741.5807495117188, "reward": 0.26267439126968384, "action": -0.3761821687221527}
{"mode": "train", "epochs": 12, "timestep": 23056, "ep_reward": 741.9490966796875, "reward": 0.3683735728263855, "action": -0.8975517153739929}
{"mode": "train", "epochs": 12, "timestep": 23057, "ep_reward": 742.4177856445312, "reward": 0.4686892628669739, "action": -1.0073657035827637}
{"mode": "train", "epochs": 12, "timestep": 23058, "ep_reward": 742.9812622070312, "reward": 0.5634878873825073, "action": -1.2765793800354004}
{"mode": "train", "epochs": 12, "timestep": 23059, "ep_reward": 743.6290283203125, "reward": 0.6477675437927246, "action": -1.0398914813995361}
{"mode": "train", "epochs": 12, "timestep": 23060, "ep_reward": 744.3514404296875, "reward": 0.722396731376648, "action": -1.644713282585144}
{"mode": "train", "epochs": 12, "timestep": 23061, "ep_reward": 745.1324462890625, "reward": 0.7809880971908569, "action": -1.4046289920806885}
{"mode": "train", "epochs": 12, "timestep": 23062, "ep_reward": 745.9620361328125, "reward": 0.8295761346817017, "action": -0.8612133860588074}
{"mode": "train", "epochs": 12, "timestep": 23063, "ep_reward": 746.8311157226562, "reward": 0.8690615296363831, "action": -0.9550758600234985}
{"mode": "train", "epochs": 12, "timestep": 23064, "ep_reward": 747.728515625, "reward": 0.897393524646759, "action": -0.8420886993408203}
{"mode": "train", "epochs": 12, "timestep": 23065, "ep_reward": 748.6453247070312, "reward": 0.916818380355835, "action": -1.054765224456787}
{"mode": "train", "epochs": 12, "timestep": 23066, "ep_reward": 749.5735473632812, "reward": 0.9282267093658447, "action": -0.4073891043663025}
{"mode": "train", "epochs": 12, "timestep": 23067, "ep_reward": 750.5062255859375, "reward": 0.9326939582824707, "action": -0.25042861700057983}
{"mode": "train", "epochs": 12, "timestep": 23068, "ep_reward": 751.4349365234375, "reward": 0.9287358522415161, "action": -0.6551548838615417}
{"mode": "train", "epochs": 12, "timestep": 23069, "ep_reward": 752.3518676757812, "reward": 0.9169596433639526, "action": -0.978559672832489}
{"mode": "train", "epochs": 12, "timestep": 23070, "ep_reward": 753.2496337890625, "reward": 0.8977463245391846, "action": -1.3850188255310059}
{"mode": "train", "epochs": 12, "timestep": 23071, "ep_reward": 754.1212158203125, "reward": 0.871597409248352, "action": -0.7058153748512268}
{"mode": "train", "epochs": 12, "timestep": 23072, "ep_reward": 754.9529418945312, "reward": 0.8317052721977234, "action": -0.7724183797836304}
{"mode": "train", "epochs": 12, "timestep": 23073, "ep_reward": 755.7313842773438, "reward": 0.7784226536750793, "action": -0.3407939076423645}
{"mode": "train", "epochs": 12, "timestep": 23074, "ep_reward": 756.43701171875, "reward": 0.7056523561477661, "action": -0.27032217383384705}
{"mode": "train", "epochs": 12, "timestep": 23075, "ep_reward": 757.0505981445312, "reward": 0.6135767102241516, "action": 0.10706138610839844}
{"mode": "train", "epochs": 12, "timestep": 23076, "ep_reward": 757.5493774414062, "reward": 0.4987746477127075, "action": -0.8080481290817261}
{"mode": "train", "epochs": 12, "timestep": 23077, "ep_reward": 757.9293823242188, "reward": 0.3799933195114136, "action": 0.4886944591999054}
{"mode": "train", "epochs": 12, "timestep": 23078, "ep_reward": 758.1663818359375, "reward": 0.23702102899551392, "action": 0.11001983284950256}
{"mode": "train", "epochs": 12, "timestep": 23079, "ep_reward": 758.3101196289062, "reward": 0.1437198519706726, "action": -0.10099953413009644}
{"mode": "train", "epochs": 12, "timestep": 23080, "ep_reward": 758.575927734375, "reward": 0.2658041715621948, "action": 0.020902037620544434}
{"mode": "train", "epochs": 12, "timestep": 23081, "ep_reward": 758.9635009765625, "reward": 0.38758230209350586, "action": -0.6302783489227295}
{"mode": "train", "epochs": 12, "timestep": 23082, "ep_reward": 759.4735717773438, "reward": 0.5100716352462769, "action": 0.0650394856929779}
{"mode": "train", "epochs": 12, "timestep": 23083, "ep_reward": 760.0873413085938, "reward": 0.6137667298316956, "action": 0.5190327763557434}
{"mode": "train", "epochs": 12, "timestep": 23084, "ep_reward": 760.7866821289062, "reward": 0.6993601322174072, "action": 1.5586235523223877}
{"mode": "train", "epochs": 12, "timestep": 23085, "ep_reward": 761.55078125, "reward": 0.7641114592552185, "action": 1.1087840795516968}
{"mode": "train", "epochs": 12, "timestep": 23086, "ep_reward": 762.369873046875, "reward": 0.8190765976905823, "action": 1.2607555389404297}
{"mode": "train", "epochs": 12, "timestep": 23087, "ep_reward": 763.2310791015625, "reward": 0.8612049221992493, "action": 0.08309608697891235}
{"mode": "train", "epochs": 12, "timestep": 23088, "ep_reward": 764.12744140625, "reward": 0.8963449597358704, "action": 0.5325008630752563}
{"mode": "train", "epochs": 12, "timestep": 23089, "ep_reward": 765.046142578125, "reward": 0.9187294840812683, "action": 0.7500030398368835}
{"mode": "train", "epochs": 12, "timestep": 23090, "ep_reward": 765.9780883789062, "reward": 0.9319432973861694, "action": 1.9157367944717407}
{"mode": "train", "epochs": 12, "timestep": 23091, "ep_reward": 766.9166870117188, "reward": 0.9385735988616943, "action": 0.2504984140396118}
{"mode": "train", "epochs": 12, "timestep": 23092, "ep_reward": 767.856689453125, "reward": 0.940015971660614, "action": 1.198333501815796}
{"mode": "train", "epochs": 12, "timestep": 23093, "ep_reward": 768.7922973632812, "reward": 0.9355902075767517, "action": 0.5998717546463013}
{"mode": "train", "epochs": 12, "timestep": 23094, "ep_reward": 769.716064453125, "reward": 0.9237552285194397, "action": 1.1936088800430298}
{"mode": "train", "epochs": 12, "timestep": 23095, "ep_reward": 770.6220703125, "reward": 0.9060125946998596, "action": 1.102691411972046}
{"mode": "train", "epochs": 12, "timestep": 23096, "ep_reward": 771.5018920898438, "reward": 0.8798277974128723, "action": 1.311576247215271}
{"mode": "train", "epochs": 12, "timestep": 23097, "ep_reward": 772.3468627929688, "reward": 0.8449841141700745, "action": 0.7323448061943054}
{"mode": "train", "epochs": 12, "timestep": 23098, "ep_reward": 773.1414794921875, "reward": 0.7946311831474304, "action": 0.5919734239578247}
{"mode": "train", "epochs": 12, "timestep": 23099, "ep_reward": 773.8690185546875, "reward": 0.7275287508964539, "action": 1.2110576629638672}
{"mode": "train", "epochs": 12, "timestep": 23100, "ep_reward": 774.5183715820312, "reward": 0.649326741695404, "action": 0.5059826374053955}
{"mode": "train", "epochs": 12, "timestep": 23101, "ep_reward": 775.0669555664062, "reward": 0.5485593676567078, "action": 0.329190731048584}
{"mode": "train", "epochs": 12, "timestep": 23102, "ep_reward": 775.4974975585938, "reward": 0.43052738904953003, "action": 0.5849621891975403}
{"mode": "train", "epochs": 12, "timestep": 23103, "ep_reward": 775.8031005859375, "reward": 0.30561864376068115, "action": 0.8298357129096985}
{"mode": "train", "epochs": 12, "timestep": 23104, "ep_reward": 775.9855346679688, "reward": 0.18242573738098145, "action": -0.04804087057709694}
{"mode": "train", "epochs": 12, "timestep": 23105, "ep_reward": 776.2138061523438, "reward": 0.2282785177230835, "action": -0.5554728507995605}
{"mode": "train", "epochs": 12, "timestep": 23106, "ep_reward": 776.5540161132812, "reward": 0.3401971459388733, "action": -0.785503625869751}
{"mode": "train", "epochs": 12, "timestep": 23107, "ep_reward": 777.0038452148438, "reward": 0.44983339309692383, "action": -0.4292207956314087}
{"mode": "train", "epochs": 12, "timestep": 23108, "ep_reward": 777.5609130859375, "reward": 0.5570422410964966, "action": -0.6611496806144714}
{"mode": "train", "epochs": 12, "timestep": 23109, "ep_reward": 778.211669921875, "reward": 0.6507512331008911, "action": -1.5964237451553345}
{"mode": "train", "epochs": 12, "timestep": 23110, "ep_reward": 778.936279296875, "reward": 0.7245960235595703, "action": -0.6317684650421143}
{"mode": "train", "epochs": 12, "timestep": 23111, "ep_reward": 779.7278442382812, "reward": 0.7915526032447815, "action": -0.7259867191314697}
{"mode": "train", "epochs": 12, "timestep": 23112, "ep_reward": 780.5709228515625, "reward": 0.8430880308151245, "action": -1.4729702472686768}
{"mode": "train", "epochs": 12, "timestep": 23113, "ep_reward": 781.4501953125, "reward": 0.8792685866355896, "action": -0.7531189918518066}
{"mode": "train", "epochs": 12, "timestep": 23114, "ep_reward": 782.3587646484375, "reward": 0.908543586730957, "action": -0.05090576410293579}
{"mode": "train", "epochs": 12, "timestep": 23115, "ep_reward": 783.28857421875, "reward": 0.9298084378242493, "action": -1.478912353515625}
{"mode": "train", "epochs": 12, "timestep": 23116, "ep_reward": 784.2294921875, "reward": 0.9409414529800415, "action": -1.0153815746307373}
{"mode": "train", "epochs": 12, "timestep": 23117, "ep_reward": 785.1770629882812, "reward": 0.9475833773612976, "action": -0.9142477512359619}
{"mode": "train", "epochs": 12, "timestep": 23118, "ep_reward": 786.1260986328125, "reward": 0.9490652680397034, "action": -1.3554052114486694}
{"mode": "train", "epochs": 12, "timestep": 23119, "ep_reward": 787.0723266601562, "reward": 0.9462568759918213, "action": -0.9487124085426331}
{"mode": "train", "epochs": 12, "timestep": 23120, "ep_reward": 788.0103759765625, "reward": 0.9380643963813782, "action": -1.3680328130722046}
{"mode": "train", "epochs": 12, "timestep": 23121, "ep_reward": 788.9356079101562, "reward": 0.9252591729164124, "action": -1.3525867462158203}
{"mode": "train", "epochs": 12, "timestep": 23122, "ep_reward": 789.8419799804688, "reward": 0.906345546245575, "action": -1.2845659255981445}
{"mode": "train", "epochs": 12, "timestep": 23123, "ep_reward": 790.7215576171875, "reward": 0.8795904517173767, "action": -0.7222183346748352}
{"mode": "train", "epochs": 12, "timestep": 23124, "ep_reward": 791.5612182617188, "reward": 0.8396539688110352, "action": -0.5747408866882324}
{"mode": "train", "epochs": 12, "timestep": 23125, "ep_reward": 792.3460083007812, "reward": 0.7847709655761719, "action": -0.13749058544635773}
{"mode": "train", "epochs": 12, "timestep": 23126, "ep_reward": 793.0551147460938, "reward": 0.7091223001480103, "action": 0.01898491382598877}
{"mode": "train", "epochs": 12, "timestep": 23127, "ep_reward": 793.6666259765625, "reward": 0.6115067005157471, "action": 0.8797870874404907}
{"mode": "train", "epochs": 12, "timestep": 23128, "ep_reward": 794.149169921875, "reward": 0.48252683877944946, "action": 0.9501373767852783}
{"mode": "train", "epochs": 12, "timestep": 23129, "ep_reward": 794.4805297851562, "reward": 0.33134645223617554, "action": 0.39592495560646057}
{"mode": "train", "epochs": 12, "timestep": 23130, "ep_reward": 794.6556396484375, "reward": 0.17509669065475464, "action": -0.1263626515865326}
{"mode": "train", "epochs": 12, "timestep": 23131, "ep_reward": 794.7776489257812, "reward": 0.12201482057571411, "action": 1.475627064704895}
{"mode": "train", "epochs": 12, "timestep": 23132, "ep_reward": 795.01513671875, "reward": 0.2374858856201172, "action": -1.1100311279296875}
{"mode": "train", "epochs": 12, "timestep": 23133, "ep_reward": 795.400390625, "reward": 0.38522374629974365, "action": -0.725511372089386}
{"mode": "train", "epochs": 12, "timestep": 23134, "ep_reward": 795.918701171875, "reward": 0.5183013081550598, "action": 0.0035664141178131104}
{"mode": "train", "epochs": 12, "timestep": 23135, "ep_reward": 796.5474243164062, "reward": 0.6287351846694946, "action": 0.2830239534378052}
{"mode": "train", "epochs": 12, "timestep": 23136, "ep_reward": 797.2667236328125, "reward": 0.7193257808685303, "action": 1.2536776065826416}
{"mode": "train", "epochs": 12, "timestep": 23137, "ep_reward": 798.0529174804688, "reward": 0.7861677408218384, "action": 0.9536505937576294}
{"mode": "train", "epochs": 12, "timestep": 23138, "ep_reward": 798.8935546875, "reward": 0.8406221270561218, "action": 1.7154765129089355}
{"mode": "train", "epochs": 12, "timestep": 23139, "ep_reward": 799.7723388671875, "reward": 0.8787732720375061, "action": 1.3191735744476318}
{"mode": "train", "epochs": 12, "timestep": 23140, "ep_reward": 800.6819458007812, "reward": 0.909580647945404, "action": 0.4853277802467346}
{"mode": "train", "epochs": 12, "timestep": 23141, "ep_reward": 801.6170654296875, "reward": 0.9351458549499512, "action": 1.1803230047225952}
{"mode": "train", "epochs": 12, "timestep": 23142, "ep_reward": 802.568603515625, "reward": 0.9515191912651062, "action": 0.7417546510696411}
{"mode": "train", "epochs": 12, "timestep": 23143, "ep_reward": 803.5328979492188, "reward": 0.9642878770828247, "action": 0.9296198487281799}
{"mode": "train", "epochs": 12, "timestep": 23144, "ep_reward": 804.505615234375, "reward": 0.9727277159690857, "action": 1.8649208545684814}
{"mode": "train", "epochs": 12, "timestep": 23145, "ep_reward": 805.4832153320312, "reward": 0.9775916337966919, "action": 1.6655126810073853}
{"mode": "train", "epochs": 12, "timestep": 23146, "ep_reward": 806.4649658203125, "reward": 0.9817349910736084, "action": 0.5666176080703735}
{"mode": "train", "epochs": 12, "timestep": 23147, "ep_reward": 807.4507446289062, "reward": 0.9858009815216064, "action": 0.8156870007514954}
{"mode": "train", "epochs": 12, "timestep": 23148, "ep_reward": 808.4389038085938, "reward": 0.9881579279899597, "action": 1.1455367803573608}
{"mode": "train", "epochs": 12, "timestep": 23149, "ep_reward": 809.4283447265625, "reward": 0.9894289970397949, "action": 1.5775079727172852}
{"mode": "train", "epochs": 12, "timestep": 23150, "ep_reward": 810.418701171875, "reward": 0.9903646111488342, "action": 0.29272574186325073}
{"mode": "train", "epochs": 12, "timestep": 23151, "ep_reward": 811.4093627929688, "reward": 0.9906911253929138, "action": 1.1403231620788574}
{"mode": "train", "epochs": 12, "timestep": 23152, "ep_reward": 812.399658203125, "reward": 0.9903116822242737, "action": 1.5701019763946533}
{"mode": "train", "epochs": 12, "timestep": 23153, "ep_reward": 813.3895874023438, "reward": 0.9898998141288757, "action": 1.3891749382019043}
{"mode": "train", "epochs": 12, "timestep": 23154, "ep_reward": 814.3787841796875, "reward": 0.9892014861106873, "action": 0.8262802362442017}
{"mode": "train", "epochs": 12, "timestep": 23155, "ep_reward": 815.3662719726562, "reward": 0.9874799251556396, "action": 0.4450412392616272}
{"mode": "train", "epochs": 12, "timestep": 23156, "ep_reward": 816.3502807617188, "reward": 0.984001874923706, "action": 1.033911943435669}
{"mode": "train", "epochs": 12, "timestep": 23157, "ep_reward": 817.330078125, "reward": 0.9798069000244141, "action": 1.354268193244934}
{"mode": "train", "epochs": 12, "timestep": 23158, "ep_reward": 818.304931640625, "reward": 0.9748473763465881, "action": 0.6661085486412048}
{"mode": "train", "epochs": 12, "timestep": 23159, "ep_reward": 819.2708740234375, "reward": 0.9659706950187683, "action": 1.1031156778335571}
{"mode": "train", "epochs": 12, "timestep": 23160, "ep_reward": 820.225830078125, "reward": 0.9549672603607178, "action": 0.43448930978775024}
{"mode": "train", "epochs": 12, "timestep": 23161, "ep_reward": 821.16259765625, "reward": 0.936750054359436, "action": 0.7871958017349243}
{"mode": "train", "epochs": 12, "timestep": 23162, "ep_reward": 822.0753784179688, "reward": 0.9127892255783081, "action": 1.1804463863372803}
{"mode": "train", "epochs": 12, "timestep": 23163, "ep_reward": 822.9577026367188, "reward": 0.8823219537734985, "action": 0.6752099990844727}
{"mode": "train", "epochs": 12, "timestep": 23164, "ep_reward": 823.7952880859375, "reward": 0.8376115560531616, "action": 0.13759231567382812}
{"mode": "train", "epochs": 12, "timestep": 23165, "ep_reward": 824.5682983398438, "reward": 0.7730153799057007, "action": 0.255858838558197}
{"mode": "train", "epochs": 12, "timestep": 23166, "ep_reward": 825.2572631835938, "reward": 0.6889698505401611, "action": 1.7540028095245361}
{"mode": "train", "epochs": 12, "timestep": 23167, "ep_reward": 825.8579711914062, "reward": 0.6006997227668762, "action": 1.9102814197540283}
{"mode": "train", "epochs": 12, "timestep": 23168, "ep_reward": 826.35791015625, "reward": 0.49992263317108154, "action": 1.8415396213531494}
{"mode": "train", "epochs": 12, "timestep": 23169, "ep_reward": 826.74658203125, "reward": 0.38867616653442383, "action": 0.17508137226104736}
{"mode": "train", "epochs": 12, "timestep": 23170, "ep_reward": 826.9963989257812, "reward": 0.24979889392852783, "action": 0.6179827451705933}
{"mode": "train", "epochs": 12, "timestep": 23171, "ep_reward": 827.1124877929688, "reward": 0.11609530448913574, "action": 1.153630018234253}
{"mode": "train", "epochs": 12, "timestep": 23172, "ep_reward": 827.3610229492188, "reward": 0.2485371232032776, "action": 0.48971331119537354}
{"mode": "train", "epochs": 12, "timestep": 23173, "ep_reward": 827.734619140625, "reward": 0.3735819458961487, "action": 0.5714558959007263}
{"mode": "train", "epochs": 12, "timestep": 23174, "ep_reward": 828.2284545898438, "reward": 0.49381589889526367, "action": 0.2629299759864807}
{"mode": "train", "epochs": 12, "timestep": 23175, "ep_reward": 828.8281860351562, "reward": 0.5997149348258972, "action": -0.6567440032958984}
{"mode": "train", "epochs": 12, "timestep": 23176, "ep_reward": 829.5125732421875, "reward": 0.6843733787536621, "action": -1.6093738079071045}
{"mode": "train", "epochs": 12, "timestep": 23177, "ep_reward": 830.2625122070312, "reward": 0.7499686479568481, "action": -0.8620209097862244}
{"mode": "train", "epochs": 12, "timestep": 23178, "ep_reward": 831.0701293945312, "reward": 0.8076052069664001, "action": -0.9718307256698608}
{"mode": "train", "epochs": 12, "timestep": 23179, "ep_reward": 831.9218139648438, "reward": 0.8516860008239746, "action": -0.6463154554367065}
{"mode": "train", "epochs": 12, "timestep": 23180, "ep_reward": 832.8070678710938, "reward": 0.8852252960205078, "action": -0.7457081079483032}
{"mode": "train", "epochs": 12, "timestep": 23181, "ep_reward": 833.7149658203125, "reward": 0.9078807234764099, "action": -0.8045205473899841}
{"mode": "train", "epochs": 12, "timestep": 23182, "ep_reward": 834.636474609375, "reward": 0.921536386013031, "action": -1.081532597541809}
{"mode": "train", "epochs": 12, "timestep": 23183, "ep_reward": 835.5640869140625, "reward": 0.9276397228240967, "action": -0.4167747497558594}
{"mode": "train", "epochs": 12, "timestep": 23184, "ep_reward": 836.4903564453125, "reward": 0.9262882471084595, "action": 0.1542506217956543}
{"mode": "train", "epochs": 12, "timestep": 23185, "ep_reward": 837.4049682617188, "reward": 0.9146119356155396, "action": -1.1893310546875}
{"mode": "train", "epochs": 12, "timestep": 23186, "ep_reward": 838.3015747070312, "reward": 0.8966048955917358, "action": -1.7589932680130005}
{"mode": "train", "epochs": 12, "timestep": 23187, "ep_reward": 839.1746826171875, "reward": 0.8731131553649902, "action": -0.845807671546936}
{"mode": "train", "epochs": 12, "timestep": 23188, "ep_reward": 840.0106811523438, "reward": 0.8359981775283813, "action": -1.0919432640075684}
{"mode": "train", "epochs": 12, "timestep": 23189, "ep_reward": 840.7984008789062, "reward": 0.7877005338668823, "action": 0.06614157557487488}
{"mode": "train", "epochs": 12, "timestep": 23190, "ep_reward": 841.513916015625, "reward": 0.7154966592788696, "action": 0.551287829875946}
{"mode": "train", "epochs": 12, "timestep": 23191, "ep_reward": 842.1320190429688, "reward": 0.6180869936943054, "action": 0.1874973475933075}
{"mode": "train", "epochs": 12, "timestep": 23192, "ep_reward": 842.634765625, "reward": 0.5027670860290527, "action": 0.7815061807632446}
{"mode": "train", "epochs": 12, "timestep": 23193, "ep_reward": 842.9971923828125, "reward": 0.3624213933944702, "action": 0.25940027832984924}
{"mode": "train", "epochs": 12, "timestep": 23194, "ep_reward": 843.2139892578125, "reward": 0.2167903184890747, "action": 0.9940105676651001}
{"mode": "train", "epochs": 12, "timestep": 23195, "ep_reward": 843.339111328125, "reward": 0.12514525651931763, "action": 0.8104726672172546}
{"mode": "train", "epochs": 12, "timestep": 23196, "ep_reward": 843.5833740234375, "reward": 0.2442539930343628, "action": -0.6039264798164368}
{"mode": "train", "epochs": 12, "timestep": 23197, "ep_reward": 843.9644165039062, "reward": 0.3810650110244751, "action": -1.2085767984390259}
{"mode": "train", "epochs": 12, "timestep": 23198, "ep_reward": 844.4798583984375, "reward": 0.5154554843902588, "action": 0.48009347915649414}
{"mode": "train", "epochs": 12, "timestep": 23199, "ep_reward": 845.098876953125, "reward": 0.6190434694290161, "action": 1.049978256225586}
{"mode": "train", "epochs": 12, "timestep": 23200, "ep_reward": 845.8027954101562, "reward": 0.7038958072662354, "action": 0.73514723777771}
{"mode": "train", "epochs": 12, "timestep": 23201, "ep_reward": 846.5789184570312, "reward": 0.7761078476905823, "action": 0.9921768307685852}
{"mode": "train", "epochs": 12, "timestep": 23202, "ep_reward": 847.410400390625, "reward": 0.8314926624298096, "action": 2.0}
{"mode": "train", "epochs": 12, "timestep": 23203, "ep_reward": 848.2802124023438, "reward": 0.8698240518569946, "action": 1.193900227546692}
{"mode": "train", "epochs": 12, "timestep": 23204, "ep_reward": 849.1827392578125, "reward": 0.902549684047699, "action": 1.7526814937591553}
{"mode": "train", "epochs": 12, "timestep": 23205, "ep_reward": 850.1079711914062, "reward": 0.9252320528030396, "action": 1.1080750226974487}
{"mode": "train", "epochs": 12, "timestep": 23206, "ep_reward": 851.0518798828125, "reward": 0.943922221660614, "action": 1.332377314567566}
{"mode": "train", "epochs": 12, "timestep": 23207, "ep_reward": 852.0087890625, "reward": 0.9569209218025208, "action": 1.3623096942901611}
{"mode": "train", "epochs": 12, "timestep": 23208, "ep_reward": 852.97509765625, "reward": 0.966317892074585, "action": 1.111411690711975}
{"mode": "train", "epochs": 12, "timestep": 23209, "ep_reward": 853.9483642578125, "reward": 0.9732771515846252, "action": 1.4940905570983887}
{"mode": "train", "epochs": 12, "timestep": 23210, "ep_reward": 854.9262084960938, "reward": 0.9778393507003784, "action": 0.6772365570068359}
{"mode": "train", "epochs": 12, "timestep": 23211, "ep_reward": 855.9074096679688, "reward": 0.9811986088752747, "action": 1.5152881145477295}
{"mode": "train", "epochs": 12, "timestep": 23212, "ep_reward": 856.8901977539062, "reward": 0.9827936887741089, "action": 1.108854055404663}
{"mode": "train", "epochs": 12, "timestep": 23213, "ep_reward": 857.8736572265625, "reward": 0.9834290146827698, "action": 1.053717017173767}
{"mode": "train", "epochs": 12, "timestep": 23214, "ep_reward": 858.8565673828125, "reward": 0.9828954935073853, "action": 0.5636003017425537}
{"mode": "train", "epochs": 12, "timestep": 23215, "ep_reward": 859.8369750976562, "reward": 0.9803829789161682, "action": 0.7618672251701355}
{"mode": "train", "epochs": 12, "timestep": 23216, "ep_reward": 860.8129272460938, "reward": 0.9759525656700134, "action": 0.759566068649292}
{"mode": "train", "epochs": 12, "timestep": 23217, "ep_reward": 861.7818603515625, "reward": 0.968941867351532, "action": 1.2463481426239014}
{"mode": "train", "epochs": 12, "timestep": 23218, "ep_reward": 862.7421264648438, "reward": 0.9602637887001038, "action": 0.1915879249572754}
{"mode": "train", "epochs": 12, "timestep": 23219, "ep_reward": 863.6861572265625, "reward": 0.9440310597419739, "action": 1.1435692310333252}
{"mode": "train", "epochs": 12, "timestep": 23220, "ep_reward": 864.6112060546875, "reward": 0.9250226616859436, "action": 1.18805730342865}
{"mode": "train", "epochs": 12, "timestep": 23221, "ep_reward": 865.5105590820312, "reward": 0.8993346095085144, "action": 0.4501405358314514}
{"mode": "train", "epochs": 12, "timestep": 23222, "ep_reward": 866.3700561523438, "reward": 0.8595072031021118, "action": 1.2503325939178467}
{"mode": "train", "epochs": 12, "timestep": 23223, "ep_reward": 867.1817626953125, "reward": 0.8117285370826721, "action": 1.499283790588379}
{"mode": "train", "epochs": 12, "timestep": 23224, "ep_reward": 867.93359375, "reward": 0.7518584132194519, "action": 1.9941420555114746}
{"mode": "train", "epochs": 12, "timestep": 23225, "ep_reward": 868.61572265625, "reward": 0.6821237802505493, "action": 1.061453938484192}
{"mode": "train", "epochs": 12, "timestep": 23226, "ep_reward": 869.203857421875, "reward": 0.5881527662277222, "action": 1.5752711296081543}
{"mode": "train", "epochs": 12, "timestep": 23227, "ep_reward": 869.6890869140625, "reward": 0.4852520227432251, "action": 1.2468023300170898}
{"mode": "train", "epochs": 12, "timestep": 23228, "ep_reward": 870.0580444335938, "reward": 0.368985652923584, "action": 0.2723931670188904}
{"mode": "train", "epochs": 12, "timestep": 23229, "ep_reward": 870.2931518554688, "reward": 0.23510313034057617, "action": 0.009215138852596283}
{"mode": "train", "epochs": 12, "timestep": 23230, "ep_reward": 870.44482421875, "reward": 0.1516469120979309, "action": 0.23192095756530762}
{"mode": "train", "epochs": 12, "timestep": 23231, "ep_reward": 870.7188110351562, "reward": 0.2740098834037781, "action": -0.11103302240371704}
{"mode": "train", "epochs": 12, "timestep": 23232, "ep_reward": 871.1122436523438, "reward": 0.39343148469924927, "action": -0.8153243660926819}
{"mode": "train", "epochs": 12, "timestep": 23233, "ep_reward": 871.6144409179688, "reward": 0.5021737813949585, "action": -0.2026624083518982}
{"mode": "train", "epochs": 12, "timestep": 23234, "ep_reward": 872.2219848632812, "reward": 0.6075403094291687, "action": -0.5315559506416321}
{"mode": "train", "epochs": 12, "timestep": 23235, "ep_reward": 872.9178466796875, "reward": 0.6958635449409485, "action": -0.8492022156715393}
{"mode": "train", "epochs": 12, "timestep": 23236, "ep_reward": 873.6845703125, "reward": 0.7667175531387329, "action": -1.3516405820846558}
{"mode": "train", "epochs": 12, "timestep": 23237, "ep_reward": 874.50537109375, "reward": 0.8207982182502747, "action": -0.11481046676635742}
{"mode": "train", "epochs": 12, "timestep": 23238, "ep_reward": 875.3732299804688, "reward": 0.8678662776947021, "action": -1.2093695402145386}
{"mode": "train", "epochs": 12, "timestep": 23239, "ep_reward": 876.2714233398438, "reward": 0.8982093334197998, "action": -1.1530301570892334}
{"mode": "train", "epochs": 12, "timestep": 23240, "ep_reward": 877.1917724609375, "reward": 0.9203213453292847, "action": -0.8469038009643555}
{"mode": "train", "epochs": 12, "timestep": 23241, "ep_reward": 878.1275634765625, "reward": 0.9358148574829102, "action": -0.8348160982131958}
{"mode": "train", "epochs": 12, "timestep": 23242, "ep_reward": 879.0723876953125, "reward": 0.9448443651199341, "action": -0.1787881851196289}
{"mode": "train", "epochs": 12, "timestep": 23243, "ep_reward": 880.0198974609375, "reward": 0.9475041031837463, "action": -1.692631483078003}
{"mode": "train", "epochs": 12, "timestep": 23244, "ep_reward": 880.96533203125, "reward": 0.945420503616333, "action": -1.8455007076263428}
{"mode": "train", "epochs": 12, "timestep": 23245, "ep_reward": 881.905517578125, "reward": 0.9401992559432983, "action": -1.3598695993423462}
{"mode": "train", "epochs": 12, "timestep": 23246, "ep_reward": 882.8355102539062, "reward": 0.9299696683883667, "action": 0.2732095718383789}
{"mode": "train", "epochs": 12, "timestep": 23247, "ep_reward": 883.7429809570312, "reward": 0.9074434041976929, "action": -0.9944943189620972}
{"mode": "train", "epochs": 12, "timestep": 23248, "ep_reward": 884.6220703125, "reward": 0.8791120648384094, "action": -0.4084993302822113}
{"mode": "train", "epochs": 12, "timestep": 23249, "ep_reward": 885.4583740234375, "reward": 0.8363004326820374, "action": -0.8106957674026489}
{"mode": "train", "epochs": 12, "timestep": 23250, "ep_reward": 886.23974609375, "reward": 0.781380832195282, "action": -1.2527605295181274}
{"mode": "train", "epochs": 12, "timestep": 23251, "ep_reward": 886.9544677734375, "reward": 0.7147155404090881, "action": -0.04506286233663559}
{"mode": "train", "epochs": 12, "timestep": 23252, "ep_reward": 887.5744018554688, "reward": 0.6199164390563965, "action": 0.7132969498634338}
{"mode": "train", "epochs": 12, "timestep": 23253, "ep_reward": 888.0698852539062, "reward": 0.4954531788825989, "action": 1.8771206140518188}
{"mode": "train", "epochs": 12, "timestep": 23254, "ep_reward": 888.4041137695312, "reward": 0.3342452645301819, "action": -0.6384682655334473}
{"mode": "train", "epochs": 12, "timestep": 23255, "ep_reward": 888.5972900390625, "reward": 0.19319301843643188, "action": 0.820885181427002}
{"mode": "train", "epochs": 12, "timestep": 23256, "ep_reward": 888.7095336914062, "reward": 0.1122204065322876, "action": -0.02321872115135193}
{"mode": "train", "epochs": 12, "timestep": 23257, "ep_reward": 888.95361328125, "reward": 0.2440508008003235, "action": -0.06685873866081238}
{"mode": "train", "epochs": 12, "timestep": 23258, "ep_reward": 889.3308715820312, "reward": 0.3772335648536682, "action": -1.4208745956420898}
{"mode": "train", "epochs": 12, "timestep": 23259, "ep_reward": 889.8477172851562, "reward": 0.5168530941009521, "action": -0.29732969403266907}
{"mode": "train", "epochs": 12, "timestep": 23260, "ep_reward": 890.47607421875, "reward": 0.6283543109893799, "action": 0.39294740557670593}
{"mode": "train", "epochs": 12, "timestep": 23261, "ep_reward": 891.1926879882812, "reward": 0.7166265845298767, "action": 1.4622398614883423}
{"mode": "train", "epochs": 12, "timestep": 23262, "ep_reward": 891.974365234375, "reward": 0.7816480994224548, "action": 1.4833070039749146}
{"mode": "train", "epochs": 12, "timestep": 23263, "ep_reward": 892.80810546875, "reward": 0.8337398767471313, "action": 0.7266860008239746}
{"mode": "train", "epochs": 12, "timestep": 23264, "ep_reward": 893.6856079101562, "reward": 0.8775026202201843, "action": 1.5917894840240479}
{"mode": "train", "epochs": 12, "timestep": 23265, "ep_reward": 894.5925903320312, "reward": 0.9069526791572571, "action": 0.37125998735427856}
{"mode": "train", "epochs": 12, "timestep": 23266, "ep_reward": 895.5250854492188, "reward": 0.9325182437896729, "action": 1.4260798692703247}
{"mode": "train", "epochs": 12, "timestep": 23267, "ep_reward": 896.47314453125, "reward": 0.9480431079864502, "action": 0.34883415699005127}
{"mode": "train", "epochs": 12, "timestep": 23268, "ep_reward": 897.4339599609375, "reward": 0.9608014822006226, "action": 1.2470283508300781}
{"mode": "train", "epochs": 12, "timestep": 23269, "ep_reward": 898.4017333984375, "reward": 0.9677551984786987, "action": 1.590444803237915}
{"mode": "train", "epochs": 12, "timestep": 23270, "ep_reward": 899.373779296875, "reward": 0.9720553755760193, "action": 1.4546765089035034}
{"mode": "train", "epochs": 12, "timestep": 23271, "ep_reward": 900.3485107421875, "reward": 0.9747570753097534, "action": 1.099267840385437}
{"mode": "train", "epochs": 12, "timestep": 23272, "ep_reward": 901.32421875, "reward": 0.9757109880447388, "action": 0.9267289638519287}
{"mode": "train", "epochs": 12, "timestep": 23273, "ep_reward": 902.2987060546875, "reward": 0.9744846224784851, "action": 0.7549495697021484}
{"mode": "train", "epochs": 12, "timestep": 23274, "ep_reward": 903.2692260742188, "reward": 0.9705144166946411, "action": 0.9162624478340149}
{"mode": "train", "epochs": 12, "timestep": 23275, "ep_reward": 904.2327880859375, "reward": 0.9635632634162903, "action": 1.984107494354248}
{"mode": "train", "epochs": 12, "timestep": 23276, "ep_reward": 905.1892700195312, "reward": 0.9564540982246399, "action": 1.0491596460342407}
{"mode": "train", "epochs": 12, "timestep": 23277, "ep_reward": 906.1328735351562, "reward": 0.9436022639274597, "action": 1.1634230613708496}
{"mode": "train", "epochs": 12, "timestep": 23278, "ep_reward": 907.0587768554688, "reward": 0.9259257316589355, "action": 0.5552586317062378}
{"mode": "train", "epochs": 12, "timestep": 23279, "ep_reward": 907.9569702148438, "reward": 0.8981636166572571, "action": 1.0234637260437012}
{"mode": "train", "epochs": 12, "timestep": 23280, "ep_reward": 908.8195190429688, "reward": 0.8625527024269104, "action": 1.2558856010437012}
{"mode": "train", "epochs": 12, "timestep": 23281, "ep_reward": 909.63623046875, "reward": 0.8167127966880798, "action": 1.1833993196487427}
{"mode": "train", "epochs": 12, "timestep": 23282, "ep_reward": 910.3927612304688, "reward": 0.7565453052520752, "action": 1.253649115562439}
{"mode": "train", "epochs": 12, "timestep": 23283, "ep_reward": 911.0740356445312, "reward": 0.6812978982925415, "action": 0.9435918927192688}
{"mode": "train", "epochs": 12, "timestep": 23284, "ep_reward": 911.6604614257812, "reward": 0.5864438414573669, "action": 0.03123164176940918}
{"mode": "train", "epochs": 12, "timestep": 23285, "ep_reward": 912.12451171875, "reward": 0.46407264471054077, "action": 0.40003180503845215}
{"mode": "train", "epochs": 12, "timestep": 23286, "ep_reward": 912.4559936523438, "reward": 0.3314579129219055, "action": 0.8528066873550415}
{"mode": "train", "epochs": 12, "timestep": 23287, "ep_reward": 912.6554565429688, "reward": 0.19945788383483887, "action": 1.6003057956695557}
{"mode": "train", "epochs": 12, "timestep": 23288, "ep_reward": 912.828857421875, "reward": 0.17338401079177856, "action": 0.6515621542930603}
{"mode": "train", "epochs": 12, "timestep": 23289, "ep_reward": 913.1277465820312, "reward": 0.29889076948165894, "action": -1.0588936805725098}
{"mode": "train", "epochs": 12, "timestep": 23290, "ep_reward": 913.5350341796875, "reward": 0.4073140621185303, "action": -0.2043474018573761}
{"mode": "train", "epochs": 12, "timestep": 23291, "ep_reward": 914.0555419921875, "reward": 0.5205087661743164, "action": -0.6064530611038208}
{"mode": "train", "epochs": 12, "timestep": 23292, "ep_reward": 914.6752319335938, "reward": 0.6196846961975098, "action": -0.4919198751449585}
{"mode": "train", "epochs": 12, "timestep": 23293, "ep_reward": 915.3812255859375, "reward": 0.7059892416000366, "action": -1.2876571416854858}
{"mode": "train", "epochs": 12, "timestep": 23294, "ep_reward": 916.1534423828125, "reward": 0.7722069025039673, "action": -0.3947603106498718}
{"mode": "train", "epochs": 12, "timestep": 23295, "ep_reward": 916.9830322265625, "reward": 0.8296135663986206, "action": -1.229822039604187}
{"mode": "train", "epochs": 12, "timestep": 23296, "ep_reward": 917.8525390625, "reward": 0.8695347905158997, "action": -1.020564317703247}
{"mode": "train", "epochs": 12, "timestep": 23297, "ep_reward": 918.7526245117188, "reward": 0.9000871181488037, "action": -0.4077102541923523}
{"mode": "train", "epochs": 12, "timestep": 23298, "ep_reward": 919.6755981445312, "reward": 0.9229610562324524, "action": 0.04094976186752319}
{"mode": "train", "epochs": 12, "timestep": 23299, "ep_reward": 920.61279296875, "reward": 0.9371761679649353, "action": -1.066028356552124}
{"mode": "train", "epochs": 12, "timestep": 23300, "ep_reward": 921.5556640625, "reward": 0.9428606629371643, "action": -0.43718773126602173}
{"mode": "train", "epochs": 12, "timestep": 23301, "ep_reward": 922.4981079101562, "reward": 0.9424244165420532, "action": -0.9839027523994446}
{"mode": "train", "epochs": 12, "timestep": 23302, "ep_reward": 923.4342041015625, "reward": 0.936122715473175, "action": -1.1523059606552124}
{"mode": "train", "epochs": 12, "timestep": 23303, "ep_reward": 924.3584594726562, "reward": 0.9242513179779053, "action": -1.011343240737915}
{"mode": "train", "epochs": 12, "timestep": 23304, "ep_reward": 925.2634887695312, "reward": 0.9050287008285522, "action": -1.5655970573425293}
{"mode": "train", "epochs": 12, "timestep": 23305, "ep_reward": 926.1436767578125, "reward": 0.8802084922790527, "action": -0.7296955585479736}
{"mode": "train", "epochs": 12, "timestep": 23306, "ep_reward": 926.9851684570312, "reward": 0.8415096998214722, "action": -1.3878910541534424}
{"mode": "train", "epochs": 12, "timestep": 23307, "ep_reward": 927.7794799804688, "reward": 0.7942903637886047, "action": -0.8855409622192383}
{"mode": "train", "epochs": 12, "timestep": 23308, "ep_reward": 928.5091552734375, "reward": 0.72966468334198, "action": -1.1621679067611694}
{"mode": "train", "epochs": 12, "timestep": 23309, "ep_reward": 929.160888671875, "reward": 0.651711106300354, "action": -0.8053632378578186}
{"mode": "train", "epochs": 12, "timestep": 23310, "ep_reward": 929.7159423828125, "reward": 0.5550628900527954, "action": 0.12069803476333618}
{"mode": "train", "epochs": 12, "timestep": 23311, "ep_reward": 930.1489868164062, "reward": 0.4330299496650696, "action": 0.28487497568130493}
{"mode": "train", "epochs": 12, "timestep": 23312, "ep_reward": 930.445068359375, "reward": 0.2960880398750305, "action": 0.25191354751586914}
{"mode": "train", "epochs": 12, "timestep": 23313, "ep_reward": 930.5991821289062, "reward": 0.15411752462387085, "action": -0.8081550598144531}
{"mode": "train", "epochs": 12, "timestep": 23314, "ep_reward": 930.8234252929688, "reward": 0.22421526908874512, "action": -0.00991871953010559}
{"mode": "train", "epochs": 12, "timestep": 23315, "ep_reward": 931.1675415039062, "reward": 0.34411871433258057, "action": 0.6411463022232056}
{"mode": "train", "epochs": 12, "timestep": 23316, "ep_reward": 931.6234130859375, "reward": 0.4558674097061157, "action": -1.4149036407470703}
{"mode": "train", "epochs": 12, "timestep": 23317, "ep_reward": 932.2012939453125, "reward": 0.5779011249542236, "action": 0.10224410891532898}
{"mode": "train", "epochs": 12, "timestep": 23318, "ep_reward": 932.8715209960938, "reward": 0.6702190637588501, "action": 0.9833181500434875}
{"mode": "train", "epochs": 12, "timestep": 23319, "ep_reward": 933.61328125, "reward": 0.7417527437210083, "action": 0.9842161536216736}
{"mode": "train", "epochs": 12, "timestep": 23320, "ep_reward": 934.4132080078125, "reward": 0.799906849861145, "action": 0.8005305528640747}
{"mode": "train", "epochs": 12, "timestep": 23321, "ep_reward": 935.2589721679688, "reward": 0.845742404460907, "action": 1.6426727771759033}
{"mode": "train", "epochs": 12, "timestep": 23322, "ep_reward": 936.1363525390625, "reward": 0.8773911595344543, "action": 0.9921413064002991}
{"mode": "train", "epochs": 12, "timestep": 23323, "ep_reward": 937.03857421875, "reward": 0.9021989107131958, "action": 0.6160262823104858}
{"mode": "train", "epochs": 12, "timestep": 23324, "ep_reward": 937.9573364257812, "reward": 0.9187659025192261, "action": 0.2719672918319702}
{"mode": "train", "epochs": 12, "timestep": 23325, "ep_reward": 938.8838500976562, "reward": 0.9265360236167908, "action": 1.4354404211044312}
{"mode": "train", "epochs": 12, "timestep": 23326, "ep_reward": 939.8108520507812, "reward": 0.9269871711730957, "action": 0.6204568147659302}
{"mode": "train", "epochs": 12, "timestep": 23327, "ep_reward": 940.7308959960938, "reward": 0.9200558066368103, "action": 0.6669610738754272}
{"mode": "train", "epochs": 12, "timestep": 23328, "ep_reward": 941.6355590820312, "reward": 0.9046810865402222, "action": 1.2554563283920288}
{"mode": "train", "epochs": 12, "timestep": 23329, "ep_reward": 942.51806640625, "reward": 0.8825117349624634, "action": -0.29535382986068726}
{"mode": "train", "epochs": 12, "timestep": 23330, "ep_reward": 943.3601684570312, "reward": 0.8420781493186951, "action": 1.5372387170791626}
{"mode": "train", "epochs": 12, "timestep": 23331, "ep_reward": 944.1578979492188, "reward": 0.7977206110954285, "action": 1.2279510498046875}
{"mode": "train", "epochs": 12, "timestep": 23332, "ep_reward": 944.896728515625, "reward": 0.7388092875480652, "action": 0.7060842514038086}
{"mode": "train", "epochs": 12, "timestep": 23333, "ep_reward": 945.557373046875, "reward": 0.6606411933898926, "action": 0.4380703568458557}
{"mode": "train", "epochs": 12, "timestep": 23334, "ep_reward": 946.1205444335938, "reward": 0.5631728768348694, "action": 0.7334845066070557}
{"mode": "train", "epochs": 12, "timestep": 23335, "ep_reward": 946.5746459960938, "reward": 0.4541119337081909, "action": 0.18477129936218262}
{"mode": "train", "epochs": 12, "timestep": 23336, "ep_reward": 946.9031982421875, "reward": 0.3285326361656189, "action": -0.9066678285598755}
{"mode": "train", "epochs": 12, "timestep": 23337, "ep_reward": 947.0860595703125, "reward": 0.18286073207855225, "action": -0.876749575138092}
{"mode": "train", "epochs": 12, "timestep": 23338, "ep_reward": 947.2879028320312, "reward": 0.20185613632202148, "action": -0.5458436012268066}
{"mode": "train", "epochs": 12, "timestep": 23339, "ep_reward": 947.6063842773438, "reward": 0.31849926710128784, "action": -0.5846577882766724}
{"mode": "train", "epochs": 12, "timestep": 23340, "ep_reward": 948.0413208007812, "reward": 0.4349585175514221, "action": 0.14664357900619507}
{"mode": "train", "epochs": 12, "timestep": 23341, "ep_reward": 948.593017578125, "reward": 0.5517057180404663, "action": -0.5179581642150879}
{"mode": "train", "epochs": 12, "timestep": 23342, "ep_reward": 949.2421264648438, "reward": 0.6490874290466309, "action": -1.5771970748901367}
{"mode": "train", "epochs": 12, "timestep": 23343, "ep_reward": 949.9666748046875, "reward": 0.7245573997497559, "action": -0.8266751170158386}
{"mode": "train", "epochs": 12, "timestep": 23344, "ep_reward": 950.75830078125, "reward": 0.7916333079338074, "action": -1.0946604013442993}
{"mode": "train", "epochs": 12, "timestep": 23345, "ep_reward": 951.6011962890625, "reward": 0.8428940773010254, "action": -0.7738319635391235}
{"mode": "train", "epochs": 12, "timestep": 23346, "ep_reward": 952.4845581054688, "reward": 0.8833905458450317, "action": -0.47642338275909424}
{"mode": "train", "epochs": 12, "timestep": 23347, "ep_reward": 953.3984375, "reward": 0.9138592481613159, "action": -1.1730570793151855}
{"mode": "train", "epochs": 12, "timestep": 23348, "ep_reward": 954.3319702148438, "reward": 0.933517575263977, "action": -0.9763481020927429}
{"mode": "train", "epochs": 12, "timestep": 23349, "ep_reward": 955.279541015625, "reward": 0.947543203830719, "action": -0.4302680492401123}
{"mode": "train", "epochs": 12, "timestep": 23350, "ep_reward": 956.2362060546875, "reward": 0.9566479921340942, "action": -1.095213770866394}
{"mode": "train", "epochs": 12, "timestep": 23351, "ep_reward": 957.1966552734375, "reward": 0.9604758024215698, "action": -0.87590491771698}
{"mode": "train", "epochs": 12, "timestep": 23352, "ep_reward": 958.1571044921875, "reward": 0.9604780673980713, "action": -0.9884035587310791}
{"mode": "train", "epochs": 12, "timestep": 23353, "ep_reward": 959.1137084960938, "reward": 0.956622838973999, "action": -0.930277943611145}
{"mode": "train", "epochs": 12, "timestep": 23354, "ep_reward": 960.0621337890625, "reward": 0.9484076499938965, "action": -0.9419316649436951}
{"mode": "train", "epochs": 12, "timestep": 23355, "ep_reward": 960.9972534179688, "reward": 0.9351214170455933, "action": -0.0739707350730896}
{"mode": "train", "epochs": 12, "timestep": 23356, "ep_reward": 961.9087524414062, "reward": 0.9114780426025391, "action": -0.8804320096969604}
{"mode": "train", "epochs": 12, "timestep": 23357, "ep_reward": 962.7901000976562, "reward": 0.881323516368866, "action": -0.20555800199508667}
{"mode": "train", "epochs": 12, "timestep": 23358, "ep_reward": 963.6255493164062, "reward": 0.8354359865188599, "action": 0.2178041934967041}
{"mode": "train", "epochs": 12, "timestep": 23359, "ep_reward": 964.39501953125, "reward": 0.769457221031189, "action": -0.5760497450828552}
{"mode": "train", "epochs": 12, "timestep": 23360, "ep_reward": 965.0851440429688, "reward": 0.6901183128356934, "action": 0.10243351012468338}
{"mode": "train", "epochs": 12, "timestep": 23361, "ep_reward": 965.6685180664062, "reward": 0.5833500623703003, "action": 1.3265129327774048}
{"mode": "train", "epochs": 12, "timestep": 23362, "ep_reward": 966.1071166992188, "reward": 0.4385717511177063, "action": 0.5759124159812927}
{"mode": "train", "epochs": 12, "timestep": 23363, "ep_reward": 966.3887329101562, "reward": 0.2816261053085327, "action": 1.0436965227127075}
{"mode": "train", "epochs": 12, "timestep": 23364, "ep_reward": 966.4955444335938, "reward": 0.10680299997329712, "action": -0.6515770554542542}
{"mode": "train", "epochs": 12, "timestep": 23365, "ep_reward": 966.6241455078125, "reward": 0.1285799741744995, "action": -0.2589164078235626}
{"mode": "train", "epochs": 12, "timestep": 23366, "ep_reward": 966.8931884765625, "reward": 0.26902759075164795, "action": -0.926983118057251}
{"mode": "train", "epochs": 12, "timestep": 23367, "ep_reward": 967.3079833984375, "reward": 0.41481101512908936, "action": -0.7710172533988953}
{"mode": "train", "epochs": 12, "timestep": 23368, "ep_reward": 967.8546752929688, "reward": 0.5467041730880737, "action": 0.20397937297821045}
{"mode": "train", "epochs": 12, "timestep": 23369, "ep_reward": 968.5068969726562, "reward": 0.6522172093391418, "action": 0.4289303719997406}
{"mode": "train", "epochs": 12, "timestep": 23370, "ep_reward": 969.2451782226562, "reward": 0.7382746338844299, "action": 0.8546867370605469}
{"mode": "train", "epochs": 12, "timestep": 23371, "ep_reward": 970.0494384765625, "reward": 0.8042742013931274, "action": 0.3657025694847107}
{"mode": "train", "epochs": 12, "timestep": 23372, "ep_reward": 970.9072875976562, "reward": 0.8578770160675049, "action": 1.2076208591461182}
{"mode": "train", "epochs": 12, "timestep": 23373, "ep_reward": 971.801513671875, "reward": 0.894199788570404, "action": 0.10226845741271973}
{"mode": "train", "epochs": 12, "timestep": 23374, "ep_reward": 972.7264404296875, "reward": 0.9249354600906372, "action": 1.3902506828308105}
{"mode": "train", "epochs": 12, "timestep": 23375, "ep_reward": 973.66943359375, "reward": 0.9430030584335327, "action": 1.2914388179779053}
{"mode": "train", "epochs": 12, "timestep": 23376, "ep_reward": 974.6259155273438, "reward": 0.9565016627311707, "action": 1.0482150316238403}
{"mode": "train", "epochs": 12, "timestep": 23377, "ep_reward": 975.5926513671875, "reward": 0.966705322265625, "action": 0.31792038679122925}
{"mode": "train", "epochs": 12, "timestep": 23378, "ep_reward": 976.5670776367188, "reward": 0.9744188189506531, "action": 1.1215429306030273}
{"mode": "train", "epochs": 12, "timestep": 23379, "ep_reward": 977.5454711914062, "reward": 0.9784113764762878, "action": 0.9124691486358643}
{"mode": "train", "epochs": 12, "timestep": 23380, "ep_reward": 978.5261840820312, "reward": 0.9806869626045227, "action": 0.8226296901702881}
{"mode": "train", "epochs": 12, "timestep": 23381, "ep_reward": 979.50732421875, "reward": 0.9811493158340454, "action": 0.9189652800559998}
{"mode": "train", "epochs": 12, "timestep": 23382, "ep_reward": 980.4871826171875, "reward": 0.9798757433891296, "action": 1.0769938230514526}
{"mode": "train", "epochs": 12, "timestep": 23383, "ep_reward": 981.4642333984375, "reward": 0.977057158946991, "action": 0.9335217475891113}
{"mode": "train", "epochs": 12, "timestep": 23384, "ep_reward": 982.436279296875, "reward": 0.9720376133918762, "action": 0.9781818985939026}
{"mode": "train", "epochs": 12, "timestep": 23385, "ep_reward": 983.4007568359375, "reward": 0.9644644260406494, "action": 0.9958124756813049}
{"mode": "train", "epochs": 12, "timestep": 23386, "ep_reward": 984.354248046875, "reward": 0.9534716010093689, "action": 1.3756396770477295}
{"mode": "train", "epochs": 12, "timestep": 23387, "ep_reward": 985.2938842773438, "reward": 0.9396060109138489, "action": 0.4008921980857849}
{"mode": "train", "epochs": 12, "timestep": 23388, "ep_reward": 986.209716796875, "reward": 0.9158221483230591, "action": 0.6714096069335938}
{"mode": "train", "epochs": 12, "timestep": 23389, "ep_reward": 987.093505859375, "reward": 0.8838135004043579, "action": 1.1310877799987793}
{"mode": "train", "epochs": 12, "timestep": 23390, "ep_reward": 987.9368286132812, "reward": 0.8433309197425842, "action": 1.272092342376709}
{"mode": "train", "epochs": 12, "timestep": 23391, "ep_reward": 988.7279052734375, "reward": 0.7910579442977905, "action": 0.9904755353927612}
{"mode": "train", "epochs": 12, "timestep": 23392, "ep_reward": 989.4491577148438, "reward": 0.7212232351303101, "action": 0.8891266584396362}
{"mode": "train", "epochs": 12, "timestep": 23393, "ep_reward": 990.0819091796875, "reward": 0.6327757239341736, "action": 0.536758542060852}
{"mode": "train", "epochs": 12, "timestep": 23394, "ep_reward": 990.6040649414062, "reward": 0.5221661329269409, "action": 1.0069806575775146}
{"mode": "train", "epochs": 12, "timestep": 23395, "ep_reward": 991.0057373046875, "reward": 0.40166646242141724, "action": 1.3591209650039673}
{"mode": "train", "epochs": 12, "timestep": 23396, "ep_reward": 991.2841186523438, "reward": 0.2783586382865906, "action": 1.4556843042373657}
{"mode": "train", "epochs": 12, "timestep": 23397, "ep_reward": 991.4421997070312, "reward": 0.15809452533721924, "action": -0.11603015661239624}
{"mode": "train", "epochs": 12, "timestep": 23398, "ep_reward": 991.66455078125, "reward": 0.22237282991409302, "action": 1.3367058038711548}
{"mode": "train", "epochs": 12, "timestep": 23399, "ep_reward": 992.02001953125, "reward": 0.3554426431655884, "action": -1.3601465225219727}
{"mode": "train", "epochs": 12, "timestep": 23400, "ep_reward": 992.478515625, "reward": 0.45851922035217285, "action": -0.630226194858551}
{"mode": "train", "epochs": 12, "timestep": 23401, "ep_reward": 993.0419921875, "reward": 0.5634548664093018, "action": -1.2143919467926025}
{"mode": "train", "epochs": 12, "timestep": 23402, "ep_reward": 993.6947021484375, "reward": 0.6527085304260254, "action": -1.6929725408554077}
{"mode": "train", "epochs": 12, "timestep": 23403, "ep_reward": 994.421142578125, "reward": 0.7264411449432373, "action": -1.1304305791854858}
{"mode": "train", "epochs": 12, "timestep": 23404, "ep_reward": 995.2122192382812, "reward": 0.7910729050636292, "action": -1.5849039554595947}
{"mode": "train", "epochs": 12, "timestep": 23405, "ep_reward": 996.05224609375, "reward": 0.8400570750236511, "action": -0.8700159788131714}
{"mode": "train", "epochs": 12, "timestep": 23406, "ep_reward": 996.9334106445312, "reward": 0.8811894655227661, "action": -0.6636824607849121}
{"mode": "train", "epochs": 12, "timestep": 23407, "ep_reward": 997.8455810546875, "reward": 0.912181556224823, "action": -1.183610439300537}
{"mode": "train", "epochs": 12, "timestep": 23408, "ep_reward": 998.778564453125, "reward": 0.932974636554718, "action": -0.8231414556503296}
{"mode": "train", "epochs": 12, "timestep": 23409, "ep_reward": 999.726806640625, "reward": 0.9482199549674988, "action": -1.6084113121032715}
{"mode": "train", "epochs": 12, "timestep": 23410, "ep_reward": 1000.684326171875, "reward": 0.9575220346450806, "action": -0.3152596354484558}
{"mode": "train", "epochs": 12, "timestep": 23411, "ep_reward": 1001.6485595703125, "reward": 0.9642036557197571, "action": -1.4539228677749634}
{"mode": "train", "epochs": 12, "timestep": 23412, "ep_reward": 1002.6151123046875, "reward": 0.9665654301643372, "action": -1.4080893993377686}
{"mode": "train", "epochs": 12, "timestep": 23413, "ep_reward": 1003.5817260742188, "reward": 0.9666329622268677, "action": -1.0748103857040405}
{"mode": "train", "epochs": 12, "timestep": 23414, "ep_reward": 1004.5455932617188, "reward": 0.9638679623603821, "action": -0.4260464310646057}
{"mode": "train", "epochs": 12, "timestep": 23415, "ep_reward": 1005.5018310546875, "reward": 0.9562665224075317, "action": -0.8621020317077637}
{"mode": "train", "epochs": 12, "timestep": 23416, "ep_reward": 1006.4464111328125, "reward": 0.9445666670799255, "action": -0.06162756681442261}
{"mode": "train", "epochs": 12, "timestep": 23417, "ep_reward": 1007.3700561523438, "reward": 0.9236288070678711, "action": -1.434894323348999}
{"mode": "train", "epochs": 12, "timestep": 23418, "ep_reward": 1008.2701416015625, "reward": 0.9000746607780457, "action": -1.208021879196167}
{"mode": "train", "epochs": 12, "timestep": 23419, "ep_reward": 1009.13720703125, "reward": 0.8670493364334106, "action": -0.7173253893852234}
{"mode": "train", "epochs": 12, "timestep": 23420, "ep_reward": 1009.95654296875, "reward": 0.8193645477294922, "action": -0.6368642449378967}
{"mode": "train", "epochs": 12, "timestep": 23421, "ep_reward": 1010.712158203125, "reward": 0.7555922269821167, "action": -0.7418048977851868}
{"mode": "train", "epochs": 12, "timestep": 23422, "ep_reward": 1011.3870849609375, "reward": 0.6749278903007507, "action": 0.10561072826385498}
{"mode": "train", "epochs": 12, "timestep": 23423, "ep_reward": 1011.9530029296875, "reward": 0.5659023523330688, "action": 0.43193599581718445}
{"mode": "train", "epochs": 12, "timestep": 23424, "ep_reward": 1012.3846435546875, "reward": 0.4316452145576477, "action": 0.7104878425598145}
{"mode": "train", "epochs": 12, "timestep": 23425, "ep_reward": 1012.6607055664062, "reward": 0.27604764699935913, "action": 0.3790423572063446}
{"mode": "train", "epochs": 12, "timestep": 23426, "ep_reward": 1012.7769775390625, "reward": 0.11630094051361084, "action": -0.32349902391433716}
{"mode": "train", "epochs": 12, "timestep": 23427, "ep_reward": 1012.9349365234375, "reward": 0.15795618295669556, "action": -1.147428274154663}
{"mode": "train", "epochs": 12, "timestep": 23428, "ep_reward": 1013.2385864257812, "reward": 0.30366045236587524, "action": -0.4992757737636566}
{"mode": "train", "epochs": 12, "timestep": 23429, "ep_reward": 1013.6759643554688, "reward": 0.43738824129104614, "action": -0.40654659271240234}
{"mode": "train", "epochs": 12, "timestep": 23430, "ep_reward": 1014.2354125976562, "reward": 0.559471845626831, "action": -0.2135002613067627}
{"mode": "train", "epochs": 12, "timestep": 23431, "ep_reward": 1014.8989868164062, "reward": 0.6635650396347046, "action": 1.2737911939620972}
{"mode": "train", "epochs": 12, "timestep": 23432, "ep_reward": 1015.638427734375, "reward": 0.7394302487373352, "action": 0.7104610204696655}
{"mode": "train", "epochs": 12, "timestep": 23433, "ep_reward": 1016.4429321289062, "reward": 0.804528534412384, "action": 1.3020966053009033}
{"mode": "train", "epochs": 12, "timestep": 23434, "ep_reward": 1017.2950439453125, "reward": 0.8521122336387634, "action": 1.3439249992370605}
{"mode": "train", "epochs": 12, "timestep": 23435, "ep_reward": 1018.1835327148438, "reward": 0.8884595036506653, "action": 1.1367621421813965}
{"mode": "train", "epochs": 12, "timestep": 23436, "ep_reward": 1019.0999755859375, "reward": 0.9164228439331055, "action": 1.3503069877624512}
{"mode": "train", "epochs": 12, "timestep": 23437, "ep_reward": 1020.036376953125, "reward": 0.936426043510437, "action": 0.46623694896698}
{"mode": "train", "epochs": 12, "timestep": 23438, "ep_reward": 1020.9888916015625, "reward": 0.952495813369751, "action": 1.5930699110031128}
{"mode": "train", "epochs": 12, "timestep": 23439, "ep_reward": 1021.950439453125, "reward": 0.9615746736526489, "action": 1.5473604202270508}
{"mode": "train", "epochs": 12, "timestep": 23440, "ep_reward": 1022.9186401367188, "reward": 0.9681971073150635, "action": 0.1561909317970276}
{"mode": "train", "epochs": 12, "timestep": 23441, "ep_reward": 1023.891357421875, "reward": 0.9727376103401184, "action": 2.0}
{"mode": "train", "epochs": 12, "timestep": 23442, "ep_reward": 1024.86572265625, "reward": 0.9744159579277039, "action": 0.6064750552177429}
{"mode": "train", "epochs": 12, "timestep": 23443, "ep_reward": 1025.83984375, "reward": 0.9740942716598511, "action": 0.3735293745994568}
{"mode": "train", "epochs": 12, "timestep": 23444, "ep_reward": 1026.81005859375, "reward": 0.9702517986297607, "action": 1.0913976430892944}
{"mode": "train", "epochs": 12, "timestep": 23445, "ep_reward": 1027.7742919921875, "reward": 0.9641866087913513, "action": 0.638060450553894}
{"mode": "train", "epochs": 12, "timestep": 23446, "ep_reward": 1028.727783203125, "reward": 0.9534949064254761, "action": 0.7370351552963257}
{"mode": "train", "epochs": 12, "timestep": 23447, "ep_reward": 1029.6654052734375, "reward": 0.9376437067985535, "action": 2.0}
{"mode": "train", "epochs": 12, "timestep": 23448, "ep_reward": 1030.586669921875, "reward": 0.9213128089904785, "action": 0.9994807839393616}
{"mode": "train", "epochs": 12, "timestep": 23449, "ep_reward": 1031.48095703125, "reward": 0.8942816853523254, "action": 0.9946544766426086}
{"mode": "train", "epochs": 12, "timestep": 23450, "ep_reward": 1032.3382568359375, "reward": 0.8573235273361206, "action": 1.4190479516983032}
{"mode": "train", "epochs": 12, "timestep": 23451, "ep_reward": 1033.149658203125, "reward": 0.8113456964492798, "action": 0.8811858296394348}
{"mode": "train", "epochs": 12, "timestep": 23452, "ep_reward": 1033.89697265625, "reward": 0.7473312616348267, "action": 0.5505222082138062}
{"mode": "train", "epochs": 12, "timestep": 23453, "ep_reward": 1034.5596923828125, "reward": 0.662696361541748, "action": 0.8500533699989319}
{"mode": "train", "epochs": 12, "timestep": 23454, "ep_reward": 1035.1220703125, "reward": 0.5624071955680847, "action": 0.9801852107048035}
{"mode": "train", "epochs": 12, "timestep": 23455, "ep_reward": 1035.570068359375, "reward": 0.4479837417602539, "action": 1.2596442699432373}
{"mode": "train", "epochs": 12, "timestep": 23456, "ep_reward": 1035.8975830078125, "reward": 0.327522873878479, "action": 0.4513201117515564}
{"mode": "train", "epochs": 12, "timestep": 23457, "ep_reward": 1036.0911865234375, "reward": 0.19354993104934692, "action": 1.2869938611984253}
{"mode": "train", "epochs": 12, "timestep": 23458, "ep_reward": 1036.28369140625, "reward": 0.1925346851348877, "action": 0.8372121453285217}
{"mode": "train", "epochs": 12, "timestep": 23459, "ep_reward": 1036.60205078125, "reward": 0.3183808922767639, "action": -0.6622838377952576}
{"mode": "train", "epochs": 12, "timestep": 23460, "ep_reward": 1037.030029296875, "reward": 0.42802751064300537, "action": -0.14310775697231293}
{"mode": "train", "epochs": 12, "timestep": 23461, "ep_reward": 1037.567626953125, "reward": 0.5375570058822632, "action": -0.7721613645553589}
{"mode": "train", "epochs": 12, "timestep": 23462, "ep_reward": 1038.1986083984375, "reward": 0.6309701204299927, "action": -2.0}
{"mode": "train", "epochs": 12, "timestep": 23463, "ep_reward": 1038.902587890625, "reward": 0.703986644744873, "action": -1.2621464729309082}
{"mode": "train", "epochs": 12, "timestep": 23464, "ep_reward": 1039.67333984375, "reward": 0.7707353830337524, "action": -0.7601075172424316}
{"mode": "train", "epochs": 12, "timestep": 23465, "ep_reward": 1040.500244140625, "reward": 0.826865553855896, "action": -0.4491084814071655}
{"mode": "train", "epochs": 12, "timestep": 23466, "ep_reward": 1041.3709716796875, "reward": 0.8707072734832764, "action": -0.7782206535339355}
{"mode": "train", "epochs": 12, "timestep": 23467, "ep_reward": 1042.272216796875, "reward": 0.9012545943260193, "action": -1.0275195837020874}
{"mode": "train", "epochs": 12, "timestep": 23468, "ep_reward": 1043.1942138671875, "reward": 0.9219737648963928, "action": -1.0656802654266357}
{"mode": "train", "epochs": 12, "timestep": 23469, "ep_reward": 1044.1295166015625, "reward": 0.9353504776954651, "action": -1.9380075931549072}
{"mode": "train", "epochs": 12, "timestep": 23470, "ep_reward": 1045.072265625, "reward": 0.9427947998046875, "action": -1.6322453022003174}
{"mode": "train", "epochs": 12, "timestep": 23471, "ep_reward": 1046.0191650390625, "reward": 0.9469363689422607, "action": -0.7833274602890015}
{"mode": "train", "epochs": 12, "timestep": 23472, "ep_reward": 1046.9656982421875, "reward": 0.9464885592460632, "action": 0.11159175634384155}
{"mode": "train", "epochs": 12, "timestep": 23473, "ep_reward": 1047.90380859375, "reward": 0.9381408095359802, "action": -1.5092377662658691}
{"mode": "train", "epochs": 12, "timestep": 23474, "ep_reward": 1048.830078125, "reward": 0.926263689994812, "action": -0.8951122164726257}
{"mode": "train", "epochs": 12, "timestep": 23475, "ep_reward": 1049.736328125, "reward": 0.9062240719795227, "action": -0.39571645855903625}
{"mode": "train", "epochs": 12, "timestep": 23476, "ep_reward": 1050.61083984375, "reward": 0.8745520114898682, "action": -0.24838122725486755}
{"mode": "train", "epochs": 12, "timestep": 23477, "ep_reward": 1051.439697265625, "reward": 0.8289094567298889, "action": -0.2136266529560089}
{"mode": "train", "epochs": 12, "timestep": 23478, "ep_reward": 1052.206298828125, "reward": 0.7666305303573608, "action": -0.6030275821685791}
{"mode": "train", "epochs": 12, "timestep": 23479, "ep_reward": 1052.8955078125, "reward": 0.6891542673110962, "action": -0.6796279549598694}
{"mode": "train", "epochs": 12, "timestep": 23480, "ep_reward": 1053.4896240234375, "reward": 0.5940849781036377, "action": 0.8566168546676636}
{"mode": "train", "epochs": 12, "timestep": 23481, "ep_reward": 1053.9522705078125, "reward": 0.4626682996749878, "action": -0.546593189239502}
{"mode": "train", "epochs": 12, "timestep": 23482, "ep_reward": 1054.2835693359375, "reward": 0.3313225507736206, "action": 0.036688268184661865}
{"mode": "train", "epochs": 12, "timestep": 23483, "ep_reward": 1054.4691162109375, "reward": 0.18560224771499634, "action": -0.6201223134994507}
{"mode": "train", "epochs": 12, "timestep": 23484, "ep_reward": 1054.62548828125, "reward": 0.15641480684280396, "action": -0.473261296749115}
{"mode": "train", "epochs": 12, "timestep": 23485, "ep_reward": 1054.911376953125, "reward": 0.28594499826431274, "action": -1.545759677886963}
{"mode": "train", "epochs": 12, "timestep": 23486, "ep_reward": 1055.335205078125, "reward": 0.4238624572753906, "action": -1.2120039463043213}
{"mode": "train", "epochs": 12, "timestep": 23487, "ep_reward": 1055.881591796875, "reward": 0.5464211702346802, "action": -0.16179025173187256}
{"mode": "train", "epochs": 12, "timestep": 23488, "ep_reward": 1056.526123046875, "reward": 0.6444845199584961, "action": 1.0844933986663818}
{"mode": "train", "epochs": 12, "timestep": 23489, "ep_reward": 1057.2452392578125, "reward": 0.7191546559333801, "action": 1.142749309539795}
{"mode": "train", "epochs": 12, "timestep": 23490, "ep_reward": 1058.0260009765625, "reward": 0.7807607650756836, "action": 0.1219976544380188}
{"mode": "train", "epochs": 12, "timestep": 23491, "ep_reward": 1058.859619140625, "reward": 0.8335703015327454, "action": 1.6640040874481201}
{"mode": "train", "epochs": 12, "timestep": 23492, "ep_reward": 1059.7269287109375, "reward": 0.8673517107963562, "action": 1.25973641872406}
{"mode": "train", "epochs": 12, "timestep": 23493, "ep_reward": 1060.6204833984375, "reward": 0.8935290575027466, "action": 1.2428494691848755}
{"mode": "train", "epochs": 12, "timestep": 23494, "ep_reward": 1061.531982421875, "reward": 0.9115545153617859, "action": 0.5675681233406067}
{"mode": "train", "epochs": 12, "timestep": 23495, "ep_reward": 1062.454345703125, "reward": 0.922405481338501, "action": 1.2592765092849731}
{"mode": "train", "epochs": 12, "timestep": 23496, "ep_reward": 1063.3798828125, "reward": 0.9255961775779724, "action": 0.3840070962905884}
{"mode": "train", "epochs": 12, "timestep": 23497, "ep_reward": 1064.30078125, "reward": 0.9208935499191284, "action": 1.319857120513916}
{"mode": "train", "epochs": 12, "timestep": 23498, "ep_reward": 1065.210693359375, "reward": 0.9099504351615906, "action": 0.7470974326133728}
{"mode": "train", "epochs": 12, "timestep": 23499, "ep_reward": 1066.1002197265625, "reward": 0.8895344734191895, "action": 0.9691799879074097}
{"mode": "train", "epochs": 12, "timestep": 23500, "ep_reward": 1066.9599609375, "reward": 0.8597387075424194, "action": 1.9358943700790405}
{"mode": "train", "epochs": 12, "timestep": 23501, "ep_reward": 1067.784912109375, "reward": 0.8249392509460449, "action": 1.0014317035675049}
{"mode": "train", "epochs": 12, "timestep": 23502, "ep_reward": 1068.55859375, "reward": 0.773657500743866, "action": 0.41534167528152466}
{"mode": "train", "epochs": 12, "timestep": 23503, "ep_reward": 1069.2613525390625, "reward": 0.7028143405914307, "action": 0.7208284139633179}
{"mode": "train", "epochs": 12, "timestep": 23504, "ep_reward": 1069.8787841796875, "reward": 0.6174240112304688, "action": 1.1687346696853638}
{"mode": "train", "epochs": 12, "timestep": 23505, "ep_reward": 1070.4007568359375, "reward": 0.521946907043457, "action": 1.065524697303772}
{"mode": "train", "epochs": 12, "timestep": 23506, "ep_reward": 1070.8160400390625, "reward": 0.4152381420135498, "action": -0.7906710505485535}
{"mode": "train", "epochs": 12, "timestep": 23507, "ep_reward": 1071.0947265625, "reward": 0.2787235975265503, "action": 0.04588472843170166}
{"mode": "train", "epochs": 12, "timestep": 23508, "ep_reward": 1071.24951171875, "reward": 0.15472549200057983, "action": -0.6087226271629333}
{"mode": "train", "epochs": 12, "timestep": 23509, "ep_reward": 1071.5125732421875, "reward": 0.2630418539047241, "action": -0.8426291346549988}
{"mode": "train", "epochs": 12, "timestep": 23510, "ep_reward": 1071.885009765625, "reward": 0.3724943995475769, "action": -1.0739479064941406}
{"mode": "train", "epochs": 12, "timestep": 23511, "ep_reward": 1072.3638916015625, "reward": 0.47886085510253906, "action": -0.7738621234893799}
{"mode": "train", "epochs": 12, "timestep": 23512, "ep_reward": 1072.9454345703125, "reward": 0.5816007852554321, "action": -0.6685405373573303}
{"mode": "train", "epochs": 12, "timestep": 23513, "ep_reward": 1073.6185302734375, "reward": 0.6730886697769165, "action": -1.862215518951416}
{"mode": "train", "epochs": 12, "timestep": 23514, "ep_reward": 1074.3609619140625, "reward": 0.7423908114433289, "action": -1.0302598476409912}
{"mode": "train", "epochs": 12, "timestep": 23515, "ep_reward": 1075.165283203125, "reward": 0.8043801188468933, "action": -1.8736369609832764}
{"mode": "train", "epochs": 12, "timestep": 23516, "ep_reward": 1076.0142822265625, "reward": 0.8490341305732727, "action": -1.1578655242919922}
{"mode": "train", "epochs": 12, "timestep": 23517, "ep_reward": 1076.901123046875, "reward": 0.8868744969367981, "action": -1.1365752220153809}
{"mode": "train", "epochs": 12, "timestep": 23518, "ep_reward": 1077.8162841796875, "reward": 0.9151914119720459, "action": -1.1556154489517212}
{"mode": "train", "epochs": 12, "timestep": 23519, "ep_reward": 1078.752197265625, "reward": 0.9359120726585388, "action": -0.41057515144348145}
{"mode": "train", "epochs": 12, "timestep": 23520, "ep_reward": 1079.7042236328125, "reward": 0.9520447254180908, "action": -0.7239065170288086}
{"mode": "train", "epochs": 12, "timestep": 23521, "ep_reward": 1080.6661376953125, "reward": 0.9618743062019348, "action": -0.7735909819602966}
{"mode": "train", "epochs": 12, "timestep": 23522, "ep_reward": 1081.6336669921875, "reward": 0.9674749970436096, "action": -0.5076900720596313}
{"mode": "train", "epochs": 12, "timestep": 23523, "ep_reward": 1082.6029052734375, "reward": 0.9691788554191589, "action": -2.0}
{"mode": "train", "epochs": 12, "timestep": 23524, "ep_reward": 1083.5718994140625, "reward": 0.9689646363258362, "action": -1.1521990299224854}
{"mode": "train", "epochs": 12, "timestep": 23525, "ep_reward": 1084.5382080078125, "reward": 0.9662629961967468, "action": -0.8460817933082581}
{"mode": "train", "epochs": 12, "timestep": 23526, "ep_reward": 1085.4981689453125, "reward": 0.959963858127594, "action": -1.0401214361190796}
{"mode": "train", "epochs": 12, "timestep": 23527, "ep_reward": 1086.4482421875, "reward": 0.950110137462616, "action": -0.7589332461357117}
{"mode": "train", "epochs": 12, "timestep": 23528, "ep_reward": 1087.3826904296875, "reward": 0.9343904256820679, "action": -0.9641691446304321}
{"mode": "train", "epochs": 12, "timestep": 23529, "ep_reward": 1088.29541015625, "reward": 0.9127241969108582, "action": -0.11786645650863647}
{"mode": "train", "epochs": 12, "timestep": 23530, "ep_reward": 1089.1728515625, "reward": 0.877467930316925, "action": -1.666987419128418}
{"mode": "train", "epochs": 12, "timestep": 23531, "ep_reward": 1090.0123291015625, "reward": 0.8395284414291382, "action": -0.9143456220626831}
{"mode": "train", "epochs": 12, "timestep": 23532, "ep_reward": 1090.796630859375, "reward": 0.7842416763305664, "action": -0.3508111834526062}
{"mode": "train", "epochs": 12, "timestep": 23533, "ep_reward": 1091.5040283203125, "reward": 0.7074265480041504, "action": -0.5549042224884033}
{"mode": "train", "epochs": 12, "timestep": 23534, "ep_reward": 1092.11669921875, "reward": 0.6127027273178101, "action": -1.2336323261260986}
{"mode": "train", "epochs": 12, "timestep": 23535, "ep_reward": 1092.62451171875, "reward": 0.507780909538269, "action": -1.3096888065338135}
{"mode": "train", "epochs": 12, "timestep": 23536, "ep_reward": 1093.0164794921875, "reward": 0.391918420791626, "action": -0.1916564702987671}
{"mode": "train", "epochs": 12, "timestep": 23537, "ep_reward": 1093.2708740234375, "reward": 0.25434768199920654, "action": -1.8397843837738037}
{"mode": "train", "epochs": 12, "timestep": 23538, "ep_reward": 1093.4111328125, "reward": 0.1402551531791687, "action": -1.1633776426315308}
{"mode": "train", "epochs": 12, "timestep": 23539, "ep_reward": 1093.6690673828125, "reward": 0.25798338651657104, "action": -1.127595067024231}
{"mode": "train", "epochs": 12, "timestep": 23540, "ep_reward": 1094.0528564453125, "reward": 0.3837739825248718, "action": -1.176027536392212}
{"mode": "train", "epochs": 12, "timestep": 23541, "ep_reward": 1094.55517578125, "reward": 0.5023269057273865, "action": 0.22706010937690735}
{"mode": "train", "epochs": 12, "timestep": 23542, "ep_reward": 1095.1529541015625, "reward": 0.5977247953414917, "action": 0.3364297151565552}
{"mode": "train", "epochs": 12, "timestep": 23543, "ep_reward": 1095.8331298828125, "reward": 0.6801190376281738, "action": 1.198673963546753}
{"mode": "train", "epochs": 12, "timestep": 23544, "ep_reward": 1096.577392578125, "reward": 0.7442858219146729, "action": 0.5701247453689575}
{"mode": "train", "epochs": 12, "timestep": 23545, "ep_reward": 1097.3763427734375, "reward": 0.7989599704742432, "action": 1.3023943901062012}
{"mode": "train", "epochs": 12, "timestep": 23546, "ep_reward": 1098.21435546875, "reward": 0.8380260467529297, "action": 0.7370713949203491}
{"mode": "train", "epochs": 12, "timestep": 23547, "ep_reward": 1099.0821533203125, "reward": 0.8678076267242432, "action": 1.4170218706130981}
{"mode": "train", "epochs": 12, "timestep": 23548, "ep_reward": 1099.9683837890625, "reward": 0.8862513303756714, "action": 0.4116511940956116}
{"mode": "train", "epochs": 12, "timestep": 23549, "ep_reward": 1100.8648681640625, "reward": 0.8964303135871887, "action": 1.277125597000122}
{"mode": "train", "epochs": 12, "timestep": 23550, "ep_reward": 1101.7620849609375, "reward": 0.8971713185310364, "action": 1.5369154214859009}
{"mode": "train", "epochs": 12, "timestep": 23551, "ep_reward": 1102.6529541015625, "reward": 0.8908981084823608, "action": 0.9401066899299622}
{"mode": "train", "epochs": 12, "timestep": 23552, "ep_reward": 1103.5281982421875, "reward": 0.8752074241638184, "action": 1.1312366724014282}
{"mode": "train", "epochs": 12, "timestep": 23553, "ep_reward": 1104.37841796875, "reward": 0.8502249121665955, "action": 1.0455440282821655}
{"mode": "train", "epochs": 12, "timestep": 23554, "ep_reward": 1105.1923828125, "reward": 0.81397944688797, "action": 1.078573226928711}
{"mode": "train", "epochs": 12, "timestep": 23555, "ep_reward": 1105.9580078125, "reward": 0.7656031847000122, "action": 0.324360728263855}
{"mode": "train", "epochs": 12, "timestep": 23556, "ep_reward": 1106.6553955078125, "reward": 0.6973859071731567, "action": 1.2271815538406372}
{"mode": "train", "epochs": 12, "timestep": 23557, "ep_reward": 1107.2764892578125, "reward": 0.6211045384407043, "action": 0.6679767370223999}
{"mode": "train", "epochs": 12, "timestep": 23558, "ep_reward": 1107.80322265625, "reward": 0.5267205238342285, "action": 1.489051103591919}
{"mode": "train", "epochs": 12, "timestep": 23559, "ep_reward": 1108.2344970703125, "reward": 0.4312793016433716, "action": 0.4711472988128662}
{"mode": "train", "epochs": 12, "timestep": 23560, "ep_reward": 1108.5546875, "reward": 0.3201325535774231, "action": -0.9452394247055054}
{"mode": "train", "epochs": 12, "timestep": 23561, "ep_reward": 1108.744140625, "reward": 0.1894993782043457, "action": -0.26141178607940674}
{"mode": "train", "epochs": 12, "timestep": 23562, "ep_reward": 1109.0230712890625, "reward": 0.2789449691772461, "action": -0.9805837273597717}
{"mode": "train", "epochs": 12, "timestep": 23563, "ep_reward": 1109.40234375, "reward": 0.37933188676834106, "action": -1.6957659721374512}
{"mode": "train", "epochs": 12, "timestep": 23564, "ep_reward": 1109.876220703125, "reward": 0.473932683467865, "action": -1.1316823959350586}
{"mode": "train", "epochs": 12, "timestep": 23565, "ep_reward": 1110.446044921875, "reward": 0.569829523563385, "action": -1.1258549690246582}
{"mode": "train", "epochs": 12, "timestep": 23566, "ep_reward": 1111.1025390625, "reward": 0.6565093994140625, "action": -1.63838529586792}
{"mode": "train", "epochs": 12, "timestep": 23567, "ep_reward": 1111.83056640625, "reward": 0.7280669212341309, "action": -0.16130942106246948}
{"mode": "train", "epochs": 12, "timestep": 23568, "ep_reward": 1112.6260986328125, "reward": 0.7955300211906433, "action": -1.0535249710083008}
{"mode": "train", "epochs": 12, "timestep": 23569, "ep_reward": 1113.46923828125, "reward": 0.843173623085022, "action": -1.216417670249939}
{"mode": "train", "epochs": 12, "timestep": 23570, "ep_reward": 1114.3480224609375, "reward": 0.8787916302680969, "action": -0.6068865060806274}
{"mode": "train", "epochs": 12, "timestep": 23571, "ep_reward": 1115.2542724609375, "reward": 0.9062990546226501, "action": -0.7924023270606995}
{"mode": "train", "epochs": 12, "timestep": 23572, "ep_reward": 1116.1783447265625, "reward": 0.924071729183197, "action": -0.5872821807861328}
{"mode": "train", "epochs": 12, "timestep": 23573, "ep_reward": 1117.1124267578125, "reward": 0.9341375827789307, "action": -1.467231273651123}
{"mode": "train", "epochs": 12, "timestep": 23574, "ep_reward": 1118.050048828125, "reward": 0.937623143196106, "action": -0.7395853996276855}
{"mode": "train", "epochs": 12, "timestep": 23575, "ep_reward": 1118.9852294921875, "reward": 0.9351245760917664, "action": -1.6861979961395264}
{"mode": "train", "epochs": 12, "timestep": 23576, "ep_reward": 1119.9134521484375, "reward": 0.9282814264297485, "action": -1.1666440963745117}
{"mode": "train", "epochs": 12, "timestep": 23577, "ep_reward": 1120.8282470703125, "reward": 0.9147732853889465, "action": -1.459496021270752}
{"mode": "train", "epochs": 12, "timestep": 23578, "ep_reward": 1121.7235107421875, "reward": 0.8952404260635376, "action": -1.3349802494049072}
{"mode": "train", "epochs": 12, "timestep": 23579, "ep_reward": 1122.5908203125, "reward": 0.8673022389411926, "action": -0.31667283177375793}
{"mode": "train", "epochs": 12, "timestep": 23580, "ep_reward": 1123.41357421875, "reward": 0.8227777481079102, "action": -0.4266909956932068}
{"mode": "train", "epochs": 12, "timestep": 23581, "ep_reward": 1124.1767578125, "reward": 0.7631860375404358, "action": -0.08618050813674927}
{"mode": "train", "epochs": 12, "timestep": 23582, "ep_reward": 1124.8594970703125, "reward": 0.6827483177185059, "action": -0.3204439878463745}
{"mode": "train", "epochs": 12, "timestep": 23583, "ep_reward": 1125.4443359375, "reward": 0.5848386287689209, "action": 0.3426320254802704}
{"mode": "train", "epochs": 12, "timestep": 23584, "ep_reward": 1125.9052734375, "reward": 0.46093136072158813, "action": -1.0925201177597046}
{"mode": "train", "epochs": 12, "timestep": 23585, "ep_reward": 1126.2462158203125, "reward": 0.3408825397491455, "action": 0.32183778285980225}
{"mode": "train", "epochs": 12, "timestep": 23586, "ep_reward": 1126.4437255859375, "reward": 0.19747918844223022, "action": -1.364673137664795}
{"mode": "train", "epochs": 12, "timestep": 23587, "ep_reward": 1126.6292724609375, "reward": 0.18548935651779175, "action": 0.1188509464263916}
{"mode": "train", "epochs": 12, "timestep": 23588, "ep_reward": 1126.9322509765625, "reward": 0.30303335189819336, "action": 0.40457528829574585}
{"mode": "train", "epochs": 12, "timestep": 23589, "ep_reward": 1127.3502197265625, "reward": 0.41791433095932007, "action": -1.7041361331939697}
{"mode": "train", "epochs": 12, "timestep": 23590, "ep_reward": 1127.8953857421875, "reward": 0.545204222202301, "action": 0.30713486671447754}
{"mode": "train", "epochs": 12, "timestep": 23591, "ep_reward": 1128.5350341796875, "reward": 0.6396036148071289, "action": 0.32081085443496704}
{"mode": "train", "epochs": 12, "timestep": 23592, "ep_reward": 1129.254638671875, "reward": 0.7195881605148315, "action": 1.4204181432724}
{"mode": "train", "epochs": 12, "timestep": 23593, "ep_reward": 1130.033447265625, "reward": 0.7788349986076355, "action": 1.359758973121643}
{"mode": "train", "epochs": 12, "timestep": 23594, "ep_reward": 1130.860107421875, "reward": 0.8267168402671814, "action": 1.5583338737487793}
{"mode": "train", "epochs": 12, "timestep": 23595, "ep_reward": 1131.7232666015625, "reward": 0.8631740808486938, "action": 1.2827563285827637}
{"mode": "train", "epochs": 12, "timestep": 23596, "ep_reward": 1132.6146240234375, "reward": 0.89137864112854, "action": 0.23335427045822144}
{"mode": "train", "epochs": 12, "timestep": 23597, "ep_reward": 1133.527099609375, "reward": 0.9125314950942993, "action": 0.37387019395828247}
{"mode": "train", "epochs": 12, "timestep": 23598, "ep_reward": 1134.450439453125, "reward": 0.9233880043029785, "action": 0.03050631284713745}
{"mode": "train", "epochs": 12, "timestep": 23599, "ep_reward": 1135.375244140625, "reward": 0.9248358011245728, "action": 0.3552122116088867}
{"mode": "train", "epochs": 12, "timestep": 23600, "ep_reward": 1136.292236328125, "reward": 0.9169560074806213, "action": 0.61082524061203}
{"mode": "train", "epochs": 12, "timestep": 23601, "ep_reward": 1137.192626953125, "reward": 0.9003313183784485, "action": 0.614867091178894}
{"mode": "train", "epochs": 12, "timestep": 23602, "ep_reward": 1138.066162109375, "reward": 0.8735156059265137, "action": 1.446197509765625}
{"mode": "train", "epochs": 12, "timestep": 23603, "ep_reward": 1138.9061279296875, "reward": 0.8399448990821838, "action": 0.33663737773895264}
{"mode": "train", "epochs": 12, "timestep": 23604, "ep_reward": 1139.693603515625, "reward": 0.7874760627746582, "action": 1.7493112087249756}
{"mode": "train", "epochs": 12, "timestep": 23605, "ep_reward": 1140.424072265625, "reward": 0.7304094433784485, "action": 1.0095127820968628}
{"mode": "train", "epochs": 12, "timestep": 23606, "ep_reward": 1141.078125, "reward": 0.654062807559967, "action": 0.47249042987823486}
{"mode": "train", "epochs": 12, "timestep": 23607, "ep_reward": 1141.63525390625, "reward": 0.557138204574585, "action": 0.8428251147270203}
{"mode": "train", "epochs": 12, "timestep": 23608, "ep_reward": 1142.08544921875, "reward": 0.45018625259399414, "action": 1.2163113355636597}
{"mode": "train", "epochs": 12, "timestep": 23609, "ep_reward": 1142.4256591796875, "reward": 0.3402172327041626, "action": -0.44036373496055603}
{"mode": "train", "epochs": 12, "timestep": 23610, "ep_reward": 1142.6329345703125, "reward": 0.20722341537475586, "action": -1.097772240638733}
{"mode": "train", "epochs": 12, "timestep": 23611, "ep_reward": 1142.8516845703125, "reward": 0.218736469745636, "action": -1.3322789669036865}
{"mode": "train", "epochs": 12, "timestep": 23612, "ep_reward": 1143.1749267578125, "reward": 0.32329481840133667, "action": -0.8339271545410156}
{"mode": "train", "epochs": 12, "timestep": 23613, "ep_reward": 1143.609619140625, "reward": 0.43466073274612427, "action": -0.6748233437538147}
{"mode": "train", "epochs": 12, "timestep": 23614, "ep_reward": 1144.152099609375, "reward": 0.5424528121948242, "action": -1.9500212669372559}
{"mode": "train", "epochs": 12, "timestep": 23615, "ep_reward": 1144.7821044921875, "reward": 0.6299459934234619, "action": -0.932025134563446}
{"mode": "train", "epochs": 12, "timestep": 23616, "ep_reward": 1145.49658203125, "reward": 0.714417576789856, "action": -0.06668722629547119}
{"mode": "train", "epochs": 12, "timestep": 23617, "ep_reward": 1146.285400390625, "reward": 0.7888398766517639, "action": -1.1411319971084595}
{"mode": "train", "epochs": 12, "timestep": 23618, "ep_reward": 1147.1260986328125, "reward": 0.84064781665802, "action": -0.9317796230316162}
{"mode": "train", "epochs": 12, "timestep": 23619, "ep_reward": 1148.0072021484375, "reward": 0.8811227679252625, "action": -1.7423510551452637}
{"mode": "train", "epochs": 12, "timestep": 23620, "ep_reward": 1148.9158935546875, "reward": 0.908676266670227, "action": -0.3909515142440796}
{"mode": "train", "epochs": 12, "timestep": 23621, "ep_reward": 1149.848876953125, "reward": 0.9330066442489624, "action": -0.7013249397277832}
{"mode": "train", "epochs": 12, "timestep": 23622, "ep_reward": 1150.7974853515625, "reward": 0.9486498832702637, "action": -1.835532307624817}
{"mode": "train", "epochs": 12, "timestep": 23623, "ep_reward": 1151.7552490234375, "reward": 0.957780122756958, "action": -0.5511277318000793}
{"mode": "train", "epochs": 12, "timestep": 23624, "ep_reward": 1152.72021484375, "reward": 0.9650198221206665, "action": -0.3620039224624634}
{"mode": "train", "epochs": 12, "timestep": 23625, "ep_reward": 1153.68798828125, "reward": 0.9677889347076416, "action": -1.3784016370773315}
{"mode": "train", "epochs": 12, "timestep": 23626, "ep_reward": 1154.6553955078125, "reward": 0.9674203395843506, "action": -0.7586036920547485}
{"mode": "train", "epochs": 12, "timestep": 23627, "ep_reward": 1155.6190185546875, "reward": 0.9635859131813049, "action": -1.286835789680481}
{"mode": "train", "epochs": 12, "timestep": 23628, "ep_reward": 1156.576171875, "reward": 0.9571462869644165, "action": -0.786641538143158}
{"mode": "train", "epochs": 12, "timestep": 23629, "ep_reward": 1157.521728515625, "reward": 0.9456102252006531, "action": -0.5939308404922485}
{"mode": "train", "epochs": 12, "timestep": 23630, "ep_reward": 1158.4490966796875, "reward": 0.9274288415908813, "action": -0.9802420735359192}
{"mode": "train", "epochs": 12, "timestep": 23631, "ep_reward": 1159.35205078125, "reward": 0.9029410481452942, "action": -2.0}
{"mode": "train", "epochs": 12, "timestep": 23632, "ep_reward": 1160.227783203125, "reward": 0.87571120262146, "action": -1.1947393417358398}
{"mode": "train", "epochs": 12, "timestep": 23633, "ep_reward": 1161.0625, "reward": 0.8347527980804443, "action": -0.911159336566925}
{"mode": "train", "epochs": 12, "timestep": 23634, "ep_reward": 1161.8411865234375, "reward": 0.778659999370575, "action": -1.073135256767273}
{"mode": "train", "epochs": 12, "timestep": 23635, "ep_reward": 1162.54931640625, "reward": 0.7081704139709473, "action": -0.10872650146484375}
{"mode": "train", "epochs": 12, "timestep": 23636, "ep_reward": 1163.159912109375, "reward": 0.6105358600616455, "action": -0.5622987151145935}
{"mode": "train", "epochs": 12, "timestep": 23637, "ep_reward": 1163.658203125, "reward": 0.49824953079223633, "action": -1.3002583980560303}
{"mode": "train", "epochs": 12, "timestep": 23638, "ep_reward": 1164.039794921875, "reward": 0.38162654638290405, "action": -1.4537131786346436}
{"mode": "train", "epochs": 12, "timestep": 23639, "ep_reward": 1164.30224609375, "reward": 0.262395441532135, "action": -2.0}
{"mode": "train", "epochs": 12, "timestep": 23640, "ep_reward": 1164.4571533203125, "reward": 0.15488815307617188, "action": -0.07886868715286255}
{"mode": "train", "epochs": 12, "timestep": 23641, "ep_reward": 1164.7218017578125, "reward": 0.26468634605407715, "action": -0.8559286594390869}
{"mode": "train", "epochs": 12, "timestep": 23642, "ep_reward": 1165.108642578125, "reward": 0.3868471384048462, "action": -0.48977917432785034}
{"mode": "train", "epochs": 12, "timestep": 23643, "ep_reward": 1165.6080322265625, "reward": 0.4994487166404724, "action": -0.6444222927093506}
{"mode": "train", "epochs": 12, "timestep": 23644, "ep_reward": 1166.2100830078125, "reward": 0.6020773649215698, "action": 0.5935512185096741}
{"mode": "train", "epochs": 12, "timestep": 23645, "ep_reward": 1166.8917236328125, "reward": 0.6816508173942566, "action": 1.8109362125396729}
{"mode": "train", "epochs": 12, "timestep": 23646, "ep_reward": 1167.634033203125, "reward": 0.7423027753829956, "action": 1.421553373336792}
{"mode": "train", "epochs": 12, "timestep": 23647, "ep_reward": 1168.4288330078125, "reward": 0.7947816848754883, "action": 0.524956226348877}
{"mode": "train", "epochs": 12, "timestep": 23648, "ep_reward": 1169.267822265625, "reward": 0.8389542698860168, "action": 1.6031162738800049}
{"mode": "train", "epochs": 12, "timestep": 23649, "ep_reward": 1170.135986328125, "reward": 0.8681629300117493, "action": 0.8008158802986145}
{"mode": "train", "epochs": 12, "timestep": 23650, "ep_reward": 1171.02587890625, "reward": 0.8899519443511963, "action": 1.294288992881775}
{"mode": "train", "epochs": 12, "timestep": 23651, "ep_reward": 1171.927978515625, "reward": 0.9020395874977112, "action": 1.0046985149383545}
{"mode": "train", "epochs": 12, "timestep": 23652, "ep_reward": 1172.8343505859375, "reward": 0.9063799381256104, "action": 1.172629952430725}
{"mode": "train", "epochs": 12, "timestep": 23653, "ep_reward": 1173.7374267578125, "reward": 0.9030235409736633, "action": -0.02444159984588623}
{"mode": "train", "epochs": 12, "timestep": 23654, "ep_reward": 1174.6253662109375, "reward": 0.8879949450492859, "action": 1.2320297956466675}
{"mode": "train", "epochs": 12, "timestep": 23655, "ep_reward": 1175.490966796875, "reward": 0.8656160831451416, "action": 0.3176145553588867}
{"mode": "train", "epochs": 12, "timestep": 23656, "ep_reward": 1176.319091796875, "reward": 0.8281204104423523, "action": 1.138990044593811}
{"mode": "train", "epochs": 12, "timestep": 23657, "ep_reward": 1177.1005859375, "reward": 0.7814540863037109, "action": -0.022915363311767578}
{"mode": "train", "epochs": 12, "timestep": 23658, "ep_reward": 1177.8123779296875, "reward": 0.7117364406585693, "action": 0.6307368278503418}
{"mode": "train", "epochs": 12, "timestep": 23659, "ep_reward": 1178.441650390625, "reward": 0.6293018460273743, "action": 0.7962816953659058}
{"mode": "train", "epochs": 12, "timestep": 23660, "ep_reward": 1178.974853515625, "reward": 0.5331847667694092, "action": 1.1587644815444946}
{"mode": "train", "epochs": 12, "timestep": 23661, "ep_reward": 1179.40478515625, "reward": 0.42988741397857666, "action": 0.6918148994445801}
{"mode": "train", "epochs": 12, "timestep": 23662, "ep_reward": 1179.7200927734375, "reward": 0.3152539134025574, "action": -1.8974814414978027}
{"mode": "train", "epochs": 12, "timestep": 23663, "ep_reward": 1179.8846435546875, "reward": 0.1644967794418335, "action": -1.274520993232727}
{"mode": "train", "epochs": 12, "timestep": 23664, "ep_reward": 1180.1268310546875, "reward": 0.2422192096710205, "action": -1.2620466947555542}
{"mode": "train", "epochs": 12, "timestep": 23665, "ep_reward": 1180.4765625, "reward": 0.34971243143081665, "action": -0.8314108848571777}
{"mode": "train", "epochs": 12, "timestep": 23666, "ep_reward": 1180.9383544921875, "reward": 0.4617467522621155, "action": -1.3484861850738525}
{"mode": "train", "epochs": 12, "timestep": 23667, "ep_reward": 1181.501220703125, "reward": 0.5628972053527832, "action": -1.8233537673950195}
{"mode": "train", "epochs": 12, "timestep": 23668, "ep_reward": 1182.1517333984375, "reward": 0.6505529880523682, "action": -0.9439613819122314}
{"mode": "train", "epochs": 12, "timestep": 23669, "ep_reward": 1182.8843994140625, "reward": 0.7326149940490723, "action": -1.2738571166992188}
{"mode": "train", "epochs": 12, "timestep": 23670, "ep_reward": 1183.6815185546875, "reward": 0.7970908880233765, "action": -0.6468905210494995}
{"mode": "train", "epochs": 12, "timestep": 23671, "ep_reward": 1184.5325927734375, "reward": 0.851091206073761, "action": -1.1853586435317993}
{"mode": "train", "epochs": 12, "timestep": 23672, "ep_reward": 1185.421875, "reward": 0.8892816305160522, "action": -1.1786389350891113}
{"mode": "train", "epochs": 12, "timestep": 23673, "ep_reward": 1186.33984375, "reward": 0.9179269075393677, "action": -0.6871706247329712}
{"mode": "train", "epochs": 12, "timestep": 23674, "ep_reward": 1187.2802734375, "reward": 0.9403694272041321, "action": -1.8250911235809326}
{"mode": "train", "epochs": 12, "timestep": 23675, "ep_reward": 1188.2340087890625, "reward": 0.953730046749115, "action": -0.8521656394004822}
{"mode": "train", "epochs": 12, "timestep": 23676, "ep_reward": 1189.1998291015625, "reward": 0.9657922983169556, "action": -1.3832651376724243}
{"mode": "train", "epochs": 12, "timestep": 23677, "ep_reward": 1190.17333984375, "reward": 0.9735151529312134, "action": -1.0360416173934937}
{"mode": "train", "epochs": 12, "timestep": 23678, "ep_reward": 1191.153076171875, "reward": 0.9797835946083069, "action": -0.21262001991271973}
{"mode": "train", "epochs": 12, "timestep": 23679, "ep_reward": 1192.13818359375, "reward": 0.9850630760192871, "action": -0.8897278308868408}
{"mode": "train", "epochs": 12, "timestep": 23680, "ep_reward": 1193.1259765625, "reward": 0.9878467917442322, "action": -1.030624508857727}
{"mode": "train", "epochs": 12, "timestep": 23681, "ep_reward": 1194.11572265625, "reward": 0.9896907210350037, "action": -0.21277475357055664}
{"mode": "train", "epochs": 12, "timestep": 23682, "ep_reward": 1195.1065673828125, "reward": 0.9908488988876343, "action": -0.172635018825531}
{"mode": "train", "epochs": 12, "timestep": 23683, "ep_reward": 1196.0970458984375, "reward": 0.9904789328575134, "action": -1.4654682874679565}
{"mode": "train", "epochs": 12, "timestep": 23684, "ep_reward": 1197.0870361328125, "reward": 0.99000084400177, "action": -1.0341588258743286}
{"mode": "train", "epochs": 12, "timestep": 23685, "ep_reward": 1198.0758056640625, "reward": 0.9887569546699524, "action": -1.4105956554412842}
{"mode": "train", "epochs": 12, "timestep": 23686, "ep_reward": 1199.063232421875, "reward": 0.9874183535575867, "action": -0.7057746648788452}
{"mode": "train", "epochs": 12, "timestep": 23687, "ep_reward": 1200.0477294921875, "reward": 0.9844377636909485, "action": -0.7295572757720947}
{"mode": "train", "epochs": 12, "timestep": 23688, "ep_reward": 1201.0277099609375, "reward": 0.9799535870552063, "action": -0.6054715514183044}
{"mode": "train", "epochs": 12, "timestep": 23689, "ep_reward": 1202.000732421875, "reward": 0.9730650186538696, "action": -0.6786994934082031}
{"mode": "train", "epochs": 12, "timestep": 23690, "ep_reward": 1202.9639892578125, "reward": 0.9632138013839722, "action": -1.532395362854004}
{"mode": "train", "epochs": 12, "timestep": 23691, "ep_reward": 1203.916748046875, "reward": 0.9527074098587036, "action": -0.9156074523925781}
{"mode": "train", "epochs": 12, "timestep": 23692, "ep_reward": 1204.8525390625, "reward": 0.9357622861862183, "action": 0.5557882189750671}
{"mode": "train", "epochs": 12, "timestep": 23693, "ep_reward": 1205.756591796875, "reward": 0.9040572643280029, "action": -1.2831083536148071}
{"mode": "train", "epochs": 12, "timestep": 23694, "ep_reward": 1206.627685546875, "reward": 0.8710993528366089, "action": -0.4478806257247925}
{"mode": "train", "epochs": 12, "timestep": 23695, "ep_reward": 1207.4481201171875, "reward": 0.8203883767127991, "action": -1.1818512678146362}
{"mode": "train", "epochs": 12, "timestep": 23696, "ep_reward": 1208.2076416015625, "reward": 0.7594625949859619, "action": -1.0660679340362549}
{"mode": "train", "epochs": 12, "timestep": 23697, "ep_reward": 1208.8883056640625, "reward": 0.6806155443191528, "action": -0.6366927027702332}
{"mode": "train", "epochs": 12, "timestep": 23698, "ep_reward": 1209.466796875, "reward": 0.5784496068954468, "action": -0.9535572528839111}
{"mode": "train", "epochs": 12, "timestep": 23699, "ep_reward": 1209.9287109375, "reward": 0.46187829971313477, "action": -0.5387051701545715}
{"mode": "train", "epochs": 12, "timestep": 23700, "ep_reward": 1210.2554931640625, "reward": 0.3267882466316223, "action": -1.2438013553619385}
{"mode": "train", "epochs": 12, "timestep": 23701, "ep_reward": 1210.4517822265625, "reward": 0.19629472494125366, "action": -0.4598209261894226}
{"mode": "train", "epochs": 12, "timestep": 23702, "ep_reward": 1210.595703125, "reward": 0.14395588636398315, "action": -0.9008831977844238}
{"mode": "train", "epochs": 12, "timestep": 23703, "ep_reward": 1210.8739013671875, "reward": 0.2781984210014343, "action": -1.1016559600830078}
{"mode": "train", "epochs": 12, "timestep": 23704, "ep_reward": 1211.2857666015625, "reward": 0.4118216037750244, "action": -0.5903345346450806}
{"mode": "train", "epochs": 12, "timestep": 23705, "ep_reward": 1211.8167724609375, "reward": 0.5309901237487793, "action": -0.0048719048500061035}
{"mode": "train", "epochs": 12, "timestep": 23706, "ep_reward": 1212.448486328125, "reward": 0.6316943168640137, "action": 0.7807912230491638}
{"mode": "train", "epochs": 12, "timestep": 23707, "ep_reward": 1213.160400390625, "reward": 0.7118852734565735, "action": 1.281796932220459}
{"mode": "train", "epochs": 12, "timestep": 23708, "ep_reward": 1213.9356689453125, "reward": 0.7752438187599182, "action": 1.408497929573059}
{"mode": "train", "epochs": 12, "timestep": 23709, "ep_reward": 1214.76123046875, "reward": 0.8256217241287231, "action": 1.16274094581604}
{"mode": "train", "epochs": 12, "timestep": 23710, "ep_reward": 1215.6270751953125, "reward": 0.8658372163772583, "action": 0.6695373058319092}
{"mode": "train", "epochs": 12, "timestep": 23711, "ep_reward": 1216.5240478515625, "reward": 0.8969425559043884, "action": 1.4353771209716797}
{"mode": "train", "epochs": 12, "timestep": 23712, "ep_reward": 1217.4410400390625, "reward": 0.916976809501648, "action": 0.6990996599197388}
{"mode": "train", "epochs": 12, "timestep": 23713, "ep_reward": 1218.3721923828125, "reward": 0.9311496019363403, "action": 1.1223212480545044}
{"mode": "train", "epochs": 12, "timestep": 23714, "ep_reward": 1219.310302734375, "reward": 0.9381301403045654, "action": 0.8877547383308411}
{"mode": "train", "epochs": 12, "timestep": 23715, "ep_reward": 1220.2496337890625, "reward": 0.9393506050109863, "action": 0.45397961139678955}
{"mode": "train", "epochs": 12, "timestep": 23716, "ep_reward": 1221.1832275390625, "reward": 0.9335867762565613, "action": 0.4399058222770691}
{"mode": "train", "epochs": 12, "timestep": 23717, "ep_reward": 1222.10302734375, "reward": 0.9198060035705566, "action": 1.086683988571167}
{"mode": "train", "epochs": 12, "timestep": 23718, "ep_reward": 1223.0025634765625, "reward": 0.89958655834198, "action": 1.473244309425354}
{"mode": "train", "epochs": 12, "timestep": 23719, "ep_reward": 1223.8753662109375, "reward": 0.872763991355896, "action": 1.0554182529449463}
{"mode": "train", "epochs": 12, "timestep": 23720, "ep_reward": 1224.7093505859375, "reward": 0.8339933156967163, "action": 1.1299471855163574}
{"mode": "train", "epochs": 12, "timestep": 23721, "ep_reward": 1225.4925537109375, "reward": 0.7831887006759644, "action": 0.7088830471038818}
{"mode": "train", "epochs": 12, "timestep": 23722, "ep_reward": 1226.20703125, "reward": 0.7144531011581421, "action": 0.6062467098236084}
{"mode": "train", "epochs": 12, "timestep": 23723, "ep_reward": 1226.834716796875, "reward": 0.6276935338973999, "action": 0.6234763264656067}
{"mode": "train", "epochs": 12, "timestep": 23724, "ep_reward": 1227.35888671875, "reward": 0.524161696434021, "action": 1.8058857917785645}
{"mode": "train", "epochs": 12, "timestep": 23725, "ep_reward": 1227.7813720703125, "reward": 0.4225047826766968, "action": 0.7696191072463989}
{"mode": "train", "epochs": 12, "timestep": 23726, "ep_reward": 1228.0849609375, "reward": 0.30364590883255005, "action": -0.9761122465133667}
{"mode": "train", "epochs": 12, "timestep": 23727, "ep_reward": 1228.24462890625, "reward": 0.15968358516693115, "action": -1.3528921604156494}
{"mode": "train", "epochs": 12, "timestep": 23728, "ep_reward": 1228.476318359375, "reward": 0.23174989223480225, "action": -0.8536117076873779}
{"mode": "train", "epochs": 12, "timestep": 23729, "ep_reward": 1228.8212890625, "reward": 0.3449249863624573, "action": -1.672383189201355}
{"mode": "train", "epochs": 12, "timestep": 23730, "ep_reward": 1229.271728515625, "reward": 0.4504554867744446, "action": -0.5720593333244324}
{"mode": "train", "epochs": 12, "timestep": 23731, "ep_reward": 1229.8333740234375, "reward": 0.5615878105163574, "action": -1.614086389541626}
{"mode": "train", "epochs": 12, "timestep": 23732, "ep_reward": 1230.485107421875, "reward": 0.6517937779426575, "action": -0.3973841667175293}
{"mode": "train", "epochs": 12, "timestep": 23733, "ep_reward": 1231.2230224609375, "reward": 0.7379193902015686, "action": -1.1206244230270386}
{"mode": "train", "epochs": 12, "timestep": 23734, "ep_reward": 1232.0252685546875, "reward": 0.8022100329399109, "action": -0.5024095773696899}
{"mode": "train", "epochs": 12, "timestep": 23735, "ep_reward": 1232.880859375, "reward": 0.8555995225906372, "action": -1.232358694076538}
{"mode": "train", "epochs": 12, "timestep": 23736, "ep_reward": 1233.773193359375, "reward": 0.8923023343086243, "action": -1.3619499206542969}
{"mode": "train", "epochs": 12, "timestep": 23737, "ep_reward": 1234.6925048828125, "reward": 0.9192935228347778, "action": -1.384661316871643}
{"mode": "train", "epochs": 12, "timestep": 23738, "ep_reward": 1235.6318359375, "reward": 0.9393541812896729, "action": -0.6309082508087158}
{"mode": "train", "epochs": 12, "timestep": 23739, "ep_reward": 1236.5877685546875, "reward": 0.9559802412986755, "action": -0.9337366819381714}
{"mode": "train", "epochs": 12, "timestep": 23740, "ep_reward": 1237.5548095703125, "reward": 0.9670639038085938, "action": -0.6899588108062744}
{"mode": "train", "epochs": 12, "timestep": 23741, "ep_reward": 1238.5299072265625, "reward": 0.9751184582710266, "action": -1.325923204421997}
{"mode": "train", "epochs": 12, "timestep": 23742, "ep_reward": 1239.5098876953125, "reward": 0.9800004363059998, "action": -0.604076623916626}
{"mode": "train", "epochs": 12, "timestep": 23743, "ep_reward": 1240.4937744140625, "reward": 0.9838592410087585, "action": -1.2573189735412598}
{"mode": "train", "epochs": 12, "timestep": 23744, "ep_reward": 1241.4796142578125, "reward": 0.9858757257461548, "action": -1.220984935760498}
{"mode": "train", "epochs": 12, "timestep": 23745, "ep_reward": 1242.4666748046875, "reward": 0.9871179461479187, "action": -1.132836103439331}
{"mode": "train", "epochs": 12, "timestep": 23746, "ep_reward": 1243.454345703125, "reward": 0.9876900911331177, "action": -0.6640346646308899}
{"mode": "train", "epochs": 12, "timestep": 23747, "ep_reward": 1244.44140625, "reward": 0.987040102481842, "action": -1.7507667541503906}
{"mode": "train", "epochs": 12, "timestep": 23748, "ep_reward": 1245.4278564453125, "reward": 0.9864432215690613, "action": -1.0147979259490967}
{"mode": "train", "epochs": 12, "timestep": 23749, "ep_reward": 1246.4124755859375, "reward": 0.9846335649490356, "action": -1.0470967292785645}
{"mode": "train", "epochs": 12, "timestep": 23750, "ep_reward": 1247.3941650390625, "reward": 0.9817199110984802, "action": -1.0538007020950317}
{"mode": "train", "epochs": 12, "timestep": 23751, "ep_reward": 1248.37158203125, "reward": 0.9774355292320251, "action": -0.5163946747779846}
{"mode": "train", "epochs": 12, "timestep": 23752, "ep_reward": 1249.3414306640625, "reward": 0.9697925448417664, "action": -0.9280368089675903}
{"mode": "train", "epochs": 12, "timestep": 23753, "ep_reward": 1250.3013916015625, "reward": 0.959926962852478, "action": 0.30514419078826904}
{"mode": "train", "epochs": 12, "timestep": 23754, "ep_reward": 1251.2423095703125, "reward": 0.9409478902816772, "action": 0.2687116265296936}
{"mode": "train", "epochs": 12, "timestep": 23755, "ep_reward": 1252.1552734375, "reward": 0.9130074381828308, "action": -0.8794729709625244}
{"mode": "train", "epochs": 12, "timestep": 23756, "ep_reward": 1253.0357666015625, "reward": 0.8804327249526978, "action": -1.3572864532470703}
{"mode": "train", "epochs": 12, "timestep": 23757, "ep_reward": 1253.8756103515625, "reward": 0.8398798704147339, "action": -1.3138693571090698}
{"mode": "train", "epochs": 12, "timestep": 23758, "ep_reward": 1254.6617431640625, "reward": 0.7860954999923706, "action": -1.5370588302612305}
{"mode": "train", "epochs": 12, "timestep": 23759, "ep_reward": 1255.3809814453125, "reward": 0.719222903251648, "action": -1.4571359157562256}
{"mode": "train", "epochs": 12, "timestep": 23760, "ep_reward": 1256.0167236328125, "reward": 0.6357935070991516, "action": 0.3159668743610382}
{"mode": "train", "epochs": 12, "timestep": 23761, "ep_reward": 1256.531494140625, "reward": 0.5147413015365601, "action": 0.3389742970466614}
{"mode": "train", "epochs": 12, "timestep": 23762, "ep_reward": 1256.904052734375, "reward": 0.3726186156272888, "action": -0.08214753866195679}
{"mode": "train", "epochs": 12, "timestep": 23763, "ep_reward": 1257.1270751953125, "reward": 0.22302430868148804, "action": -0.6821615695953369}
{"mode": "train", "epochs": 12, "timestep": 23764, "ep_reward": 1257.208251953125, "reward": 0.08118546009063721, "action": -0.9089429378509521}
{"mode": "train", "epochs": 12, "timestep": 23765, "ep_reward": 1257.427734375, "reward": 0.21953260898590088, "action": -0.26897966861724854}
{"mode": "train", "epochs": 12, "timestep": 23766, "ep_reward": 1257.779052734375, "reward": 0.35127246379852295, "action": -1.175937533378601}
{"mode": "train", "epochs": 12, "timestep": 23767, "ep_reward": 1258.265625, "reward": 0.4865679144859314, "action": -0.7863778471946716}
{"mode": "train", "epochs": 12, "timestep": 23768, "ep_reward": 1258.8687744140625, "reward": 0.6030915379524231, "action": 1.247358798980713}
{"mode": "train", "epochs": 12, "timestep": 23769, "ep_reward": 1259.5557861328125, "reward": 0.6869949102401733, "action": 1.4322474002838135}
{"mode": "train", "epochs": 12, "timestep": 23770, "ep_reward": 1260.3125, "reward": 0.7567739486694336, "action": 0.49643975496292114}
{"mode": "train", "epochs": 12, "timestep": 23771, "ep_reward": 1261.1309814453125, "reward": 0.8184639811515808, "action": 0.6763341426849365}
{"mode": "train", "epochs": 12, "timestep": 23772, "ep_reward": 1261.99560546875, "reward": 0.8645744919776917, "action": 1.0486605167388916}
{"mode": "train", "epochs": 12, "timestep": 23773, "ep_reward": 1262.89306640625, "reward": 0.8974229693412781, "action": 0.8953946828842163}
{"mode": "train", "epochs": 12, "timestep": 23774, "ep_reward": 1263.8145751953125, "reward": 0.9215680360794067, "action": 1.3848003149032593}
{"mode": "train", "epochs": 12, "timestep": 23775, "ep_reward": 1264.7520751953125, "reward": 0.9375203251838684, "action": 0.050268709659576416}
{"mode": "train", "epochs": 12, "timestep": 23776, "ep_reward": 1265.701416015625, "reward": 0.9493070840835571, "action": 0.9272441267967224}
{"mode": "train", "epochs": 12, "timestep": 23777, "ep_reward": 1266.6553955078125, "reward": 0.9539812207221985, "action": 0.9489016532897949}
{"mode": "train", "epochs": 12, "timestep": 23778, "ep_reward": 1267.609375, "reward": 0.9539267420768738, "action": 1.7694761753082275}
{"mode": "train", "epochs": 12, "timestep": 23779, "ep_reward": 1268.5604248046875, "reward": 0.9509974122047424, "action": 0.7982531189918518}
{"mode": "train", "epochs": 12, "timestep": 23780, "ep_reward": 1269.5029296875, "reward": 0.942474365234375, "action": 1.7794568538665771}
{"mode": "train", "epochs": 12, "timestep": 23781, "ep_reward": 1270.434326171875, "reward": 0.9314545392990112, "action": 0.3556017279624939}
{"mode": "train", "epochs": 12, "timestep": 23782, "ep_reward": 1271.3441162109375, "reward": 0.909835934638977, "action": -0.014169275760650635}
{"mode": "train", "epochs": 12, "timestep": 23783, "ep_reward": 1272.2198486328125, "reward": 0.8756738305091858, "action": 1.0249934196472168}
{"mode": "train", "epochs": 12, "timestep": 23784, "ep_reward": 1273.0540771484375, "reward": 0.834277868270874, "action": 1.0166977643966675}
{"mode": "train", "epochs": 12, "timestep": 23785, "ep_reward": 1273.8336181640625, "reward": 0.7795684933662415, "action": 0.9756947159767151}
{"mode": "train", "epochs": 12, "timestep": 23786, "ep_reward": 1274.5426025390625, "reward": 0.7089418768882751, "action": 1.7656536102294922}
{"mode": "train", "epochs": 12, "timestep": 23787, "ep_reward": 1275.1728515625, "reward": 0.6302995681762695, "action": 0.4165179133415222}
{"mode": "train", "epochs": 12, "timestep": 23788, "ep_reward": 1275.6959228515625, "reward": 0.5230885744094849, "action": 0.5349172353744507}
{"mode": "train", "epochs": 12, "timestep": 23789, "ep_reward": 1276.0982666015625, "reward": 0.4023405909538269, "action": 0.8983644843101501}
{"mode": "train", "epochs": 12, "timestep": 23790, "ep_reward": 1276.3765869140625, "reward": 0.27828818559646606, "action": 0.8314037322998047}
{"mode": "train", "epochs": 12, "timestep": 23791, "ep_reward": 1276.530517578125, "reward": 0.15397489070892334, "action": -0.798372745513916}
{"mode": "train", "epochs": 12, "timestep": 23792, "ep_reward": 1276.7696533203125, "reward": 0.23910772800445557, "action": -0.11717438697814941}
{"mode": "train", "epochs": 12, "timestep": 23793, "ep_reward": 1277.1278076171875, "reward": 0.3581642508506775, "action": -0.7046149969100952}
{"mode": "train", "epochs": 12, "timestep": 23794, "ep_reward": 1277.59716796875, "reward": 0.46932369470596313, "action": -0.9063697457313538}
{"mode": "train", "epochs": 12, "timestep": 23795, "ep_reward": 1278.169189453125, "reward": 0.572014570236206, "action": -1.0263441801071167}
{"mode": "train", "epochs": 12, "timestep": 23796, "ep_reward": 1278.8319091796875, "reward": 0.6627776622772217, "action": -0.6553940773010254}
{"mode": "train", "epochs": 12, "timestep": 23797, "ep_reward": 1279.5740966796875, "reward": 0.7422029972076416, "action": -1.281858205795288}
{"mode": "train", "epochs": 12, "timestep": 23798, "ep_reward": 1280.3765869140625, "reward": 0.8024337291717529, "action": -2.0}
{"mode": "train", "epochs": 12, "timestep": 23799, "ep_reward": 1281.223388671875, "reward": 0.8468155860900879, "action": -0.6895687580108643}
{"mode": "train", "epochs": 12, "timestep": 23800, "ep_reward": 1282.1102294921875, "reward": 0.8868969678878784, "action": -1.4301869869232178}
{"mode": "train", "epochs": 12, "timestep": 23801, "ep_reward": 1283.024169921875, "reward": 0.9139829277992249, "action": -0.61208575963974}
{"mode": "train", "epochs": 12, "timestep": 23802, "ep_reward": 1283.9600830078125, "reward": 0.9359609484672546, "action": -1.0755854845046997}
{"mode": "train", "epochs": 12, "timestep": 23803, "ep_reward": 1284.9100341796875, "reward": 0.9499722123146057, "action": -1.8509546518325806}
{"mode": "train", "epochs": 12, "timestep": 23804, "ep_reward": 1285.8687744140625, "reward": 0.9587775468826294, "action": -0.6993804574012756}
{"mode": "train", "epochs": 12, "timestep": 23805, "ep_reward": 1286.8343505859375, "reward": 0.9656195640563965, "action": -1.4237847328186035}
{"mode": "train", "epochs": 12, "timestep": 23806, "ep_reward": 1287.80322265625, "reward": 0.9688165187835693, "action": -1.1404365301132202}
{"mode": "train", "epochs": 12, "timestep": 23807, "ep_reward": 1288.77294921875, "reward": 0.9697016477584839, "action": -0.7034854292869568}
{"mode": "train", "epochs": 12, "timestep": 23808, "ep_reward": 1289.740234375, "reward": 0.9673262238502502, "action": -1.4432309865951538}
{"mode": "train", "epochs": 12, "timestep": 23809, "ep_reward": 1290.703125, "reward": 0.9629258513450623, "action": -0.8134159445762634}
{"mode": "train", "epochs": 12, "timestep": 23810, "ep_reward": 1291.6573486328125, "reward": 0.9541836380958557, "action": -0.39152342081069946}
{"mode": "train", "epochs": 12, "timestep": 23811, "ep_reward": 1292.5963134765625, "reward": 0.9389954209327698, "action": -1.027787685394287}
{"mode": "train", "epochs": 12, "timestep": 23812, "ep_reward": 1293.515625, "reward": 0.9193075299263, "action": -0.15965121984481812}
{"mode": "train", "epochs": 12, "timestep": 23813, "ep_reward": 1294.402587890625, "reward": 0.8870117664337158, "action": -0.6361104846000671}
{"mode": "train", "epochs": 12, "timestep": 23814, "ep_reward": 1295.2474365234375, "reward": 0.8448938131332397, "action": -1.00857675075531}
{"mode": "train", "epochs": 12, "timestep": 23815, "ep_reward": 1296.038818359375, "reward": 0.7913408875465393, "action": -1.371711015701294}
{"mode": "train", "epochs": 12, "timestep": 23816, "ep_reward": 1296.7645263671875, "reward": 0.7256783246994019, "action": -0.7245950102806091}
{"mode": "train", "epochs": 12, "timestep": 23817, "ep_reward": 1297.40185546875, "reward": 0.6373673677444458, "action": -0.5475805997848511}
{"mode": "train", "epochs": 12, "timestep": 23818, "ep_reward": 1297.9305419921875, "reward": 0.528680145740509, "action": 0.5000762343406677}
{"mode": "train", "epochs": 12, "timestep": 23819, "ep_reward": 1298.320068359375, "reward": 0.3895713686943054, "action": -0.3209260404109955}
{"mode": "train", "epochs": 12, "timestep": 23820, "ep_reward": 1298.568115234375, "reward": 0.24804747104644775, "action": -0.7434775829315186}
{"mode": "train", "epochs": 12, "timestep": 23821, "ep_reward": 1298.679443359375, "reward": 0.1113210916519165, "action": -0.8691825270652771}
{"mode": "train", "epochs": 12, "timestep": 23822, "ep_reward": 1298.90234375, "reward": 0.2228577733039856, "action": -1.3277467489242554}
{"mode": "train", "epochs": 12, "timestep": 23823, "ep_reward": 1299.2630615234375, "reward": 0.36067795753479004, "action": -0.06279507279396057}
{"mode": "train", "epochs": 12, "timestep": 23824, "ep_reward": 1299.7423095703125, "reward": 0.47929733991622925, "action": -0.29146984219551086}
{"mode": "train", "epochs": 12, "timestep": 23825, "ep_reward": 1300.33203125, "reward": 0.5897496938705444, "action": 1.043850064277649}
{"mode": "train", "epochs": 12, "timestep": 23826, "ep_reward": 1301.007568359375, "reward": 0.6755208969116211, "action": 1.3455793857574463}
{"mode": "train", "epochs": 12, "timestep": 23827, "ep_reward": 1301.75390625, "reward": 0.7463297247886658, "action": 1.5667178630828857}
{"mode": "train", "epochs": 12, "timestep": 23828, "ep_reward": 1302.55712890625, "reward": 0.803278386592865, "action": 0.8406451344490051}
{"mode": "train", "epochs": 12, "timestep": 23829, "ep_reward": 1303.4088134765625, "reward": 0.8517158031463623, "action": 1.3847047090530396}
{"mode": "train", "epochs": 12, "timestep": 23830, "ep_reward": 1304.2950439453125, "reward": 0.8862107992172241, "action": 1.2935891151428223}
{"mode": "train", "epochs": 12, "timestep": 23831, "ep_reward": 1305.2073974609375, "reward": 0.9123088121414185, "action": -0.49260038137435913}
{"mode": "train", "epochs": 12, "timestep": 23832, "ep_reward": 1306.1414794921875, "reward": 0.9340539574623108, "action": 0.9931959509849548}
{"mode": "train", "epochs": 12, "timestep": 23833, "ep_reward": 1307.0859375, "reward": 0.9444594383239746, "action": 0.820489764213562}
{"mode": "train", "epochs": 12, "timestep": 23834, "ep_reward": 1308.035400390625, "reward": 0.949462890625, "action": 0.7399774789810181}
{"mode": "train", "epochs": 12, "timestep": 23835, "ep_reward": 1308.984375, "reward": 0.9490328431129456, "action": 0.8238503932952881}
{"mode": "train", "epochs": 12, "timestep": 23836, "ep_reward": 1309.9276123046875, "reward": 0.9431931972503662, "action": 0.8728588819503784}
{"mode": "train", "epochs": 12, "timestep": 23837, "ep_reward": 1310.859130859375, "reward": 0.9315126538276672, "action": 1.318269968032837}
{"mode": "train", "epochs": 12, "timestep": 23838, "ep_reward": 1311.77392578125, "reward": 0.914826512336731, "action": 0.830040693283081}
{"mode": "train", "epochs": 12, "timestep": 23839, "ep_reward": 1312.66259765625, "reward": 0.8886954188346863, "action": 0.396375834941864}
{"mode": "train", "epochs": 12, "timestep": 23840, "ep_reward": 1313.5118408203125, "reward": 0.8492715954780579, "action": 1.3580636978149414}
{"mode": "train", "epochs": 12, "timestep": 23841, "ep_reward": 1314.3145751953125, "reward": 0.8026819229125977, "action": -0.09648919105529785}
{"mode": "train", "epochs": 12, "timestep": 23842, "ep_reward": 1315.0445556640625, "reward": 0.729985237121582, "action": 1.0552864074707031}
{"mode": "train", "epochs": 12, "timestep": 23843, "ep_reward": 1315.6927490234375, "reward": 0.6482275724411011, "action": 1.2844581604003906}
{"mode": "train", "epochs": 12, "timestep": 23844, "ep_reward": 1316.2459716796875, "reward": 0.5531766414642334, "action": 1.0804063081741333}
{"mode": "train", "epochs": 12, "timestep": 23845, "ep_reward": 1316.6890869140625, "reward": 0.4431651830673218, "action": 0.6868400573730469}
{"mode": "train", "epochs": 12, "timestep": 23846, "ep_reward": 1317.0087890625, "reward": 0.31973713636398315, "action": 0.5600405931472778}
{"mode": "train", "epochs": 12, "timestep": 23847, "ep_reward": 1317.200927734375, "reward": 0.1920870542526245, "action": -0.49799469113349915}
{"mode": "train", "epochs": 12, "timestep": 23848, "ep_reward": 1317.408447265625, "reward": 0.207469642162323, "action": -0.2823677659034729}
{"mode": "train", "epochs": 12, "timestep": 23849, "ep_reward": 1317.7325439453125, "reward": 0.32409656047821045, "action": -0.8699261546134949}
{"mode": "train", "epochs": 12, "timestep": 23850, "ep_reward": 1318.16748046875, "reward": 0.4349091053009033, "action": -1.3109567165374756}
{"mode": "train", "epochs": 12, "timestep": 23851, "ep_reward": 1318.7049560546875, "reward": 0.5374736785888672, "action": -0.6444610357284546}
{"mode": "train", "epochs": 12, "timestep": 23852, "ep_reward": 1319.341552734375, "reward": 0.6365973949432373, "action": -1.0811375379562378}
{"mode": "train", "epochs": 12, "timestep": 23853, "ep_reward": 1320.0596923828125, "reward": 0.7181698083877563, "action": -1.0635005235671997}
{"mode": "train", "epochs": 12, "timestep": 23854, "ep_reward": 1320.84521484375, "reward": 0.7854659557342529, "action": -0.3123420476913452}
{"mode": "train", "epochs": 12, "timestep": 23855, "ep_reward": 1321.6875, "reward": 0.8422759771347046, "action": -1.563086748123169}
{"mode": "train", "epochs": 12, "timestep": 23856, "ep_reward": 1322.567138671875, "reward": 0.8796835541725159, "action": -1.1439839601516724}
{"mode": "train", "epochs": 12, "timestep": 23857, "ep_reward": 1323.476806640625, "reward": 0.9096174240112305, "action": -0.635170578956604}
{"mode": "train", "epochs": 12, "timestep": 23858, "ep_reward": 1324.409423828125, "reward": 0.9325584769248962, "action": -2.0}
{"mode": "train", "epochs": 12, "timestep": 23859, "ep_reward": 1325.35546875, "reward": 0.9460819363594055, "action": -0.7601041197776794}
{"mode": "train", "epochs": 12, "timestep": 23860, "ep_reward": 1326.3133544921875, "reward": 0.9578810334205627, "action": -0.7672208547592163}
{"mode": "train", "epochs": 12, "timestep": 23861, "ep_reward": 1327.2784423828125, "reward": 0.9651094675064087, "action": -0.4769948124885559}
{"mode": "train", "epochs": 12, "timestep": 23862, "ep_reward": 1328.2467041015625, "reward": 0.9682614207267761, "action": -1.844451665878296}
{"mode": "train", "epochs": 12, "timestep": 23863, "ep_reward": 1329.215576171875, "reward": 0.9688453078269958, "action": -0.8511311411857605}
{"mode": "train", "epochs": 12, "timestep": 23864, "ep_reward": 1330.18212890625, "reward": 0.9665105938911438, "action": -1.5707285404205322}
{"mode": "train", "epochs": 12, "timestep": 23865, "ep_reward": 1331.1444091796875, "reward": 0.9622997641563416, "action": -1.1243152618408203}
{"mode": "train", "epochs": 12, "timestep": 23866, "ep_reward": 1332.098876953125, "reward": 0.9544627070426941, "action": -0.6891703605651855}
{"mode": "train", "epochs": 12, "timestep": 23867, "ep_reward": 1333.039794921875, "reward": 0.9408707618713379, "action": -1.51871657371521}
{"mode": "train", "epochs": 12, "timestep": 23868, "ep_reward": 1333.9642333984375, "reward": 0.924454927444458, "action": -1.0989667177200317}
{"mode": "train", "epochs": 12, "timestep": 23869, "ep_reward": 1334.8641357421875, "reward": 0.8999573588371277, "action": -0.6208197474479675}
{"mode": "train", "epochs": 12, "timestep": 23870, "ep_reward": 1335.7275390625, "reward": 0.8634254336357117, "action": -0.653114914894104}
{"mode": "train", "epochs": 12, "timestep": 23871, "ep_reward": 1336.54150390625, "reward": 0.8139615058898926, "action": -0.16665929555892944}
{"mode": "train", "epochs": 12, "timestep": 23872, "ep_reward": 1337.28564453125, "reward": 0.7441892027854919, "action": -0.6168484091758728}
{"mode": "train", "epochs": 12, "timestep": 23873, "ep_reward": 1337.9444580078125, "reward": 0.658789873123169, "action": 0.10599178075790405}
{"mode": "train", "epochs": 12, "timestep": 23874, "ep_reward": 1338.489990234375, "reward": 0.5454884767532349, "action": -0.7005714774131775}
{"mode": "train", "epochs": 12, "timestep": 23875, "ep_reward": 1338.9127197265625, "reward": 0.4226917028427124, "action": 0.024403125047683716}
{"mode": "train", "epochs": 12, "timestep": 23876, "ep_reward": 1339.1910400390625, "reward": 0.2782805562019348, "action": -0.19636571407318115}
{"mode": "train", "epochs": 12, "timestep": 23877, "ep_reward": 1339.32275390625, "reward": 0.13176649808883667, "action": -1.3297576904296875}
{"mode": "train", "epochs": 12, "timestep": 23878, "ep_reward": 1339.51513671875, "reward": 0.1923966407775879, "action": -0.004118680953979492}
{"mode": "train", "epochs": 12, "timestep": 23879, "ep_reward": 1339.8336181640625, "reward": 0.3184922933578491, "action": -0.0966227650642395}
{"mode": "train", "epochs": 12, "timestep": 23880, "ep_reward": 1340.2772216796875, "reward": 0.4435986876487732, "action": -0.43458712100982666}
{"mode": "train", "epochs": 12, "timestep": 23881, "ep_reward": 1340.83984375, "reward": 0.5625926852226257, "action": 0.6536751985549927}
{"mode": "train", "epochs": 12, "timestep": 23882, "ep_reward": 1341.49755859375, "reward": 0.6576693654060364, "action": -0.0339961051940918}
{"mode": "train", "epochs": 12, "timestep": 23883, "ep_reward": 1342.2398681640625, "reward": 0.7422688007354736, "action": 0.7279452085494995}
{"mode": "train", "epochs": 12, "timestep": 23884, "ep_reward": 1343.044677734375, "reward": 0.8048356771469116, "action": 1.0078516006469727}
{"mode": "train", "epochs": 12, "timestep": 23885, "ep_reward": 1343.896728515625, "reward": 0.8520612716674805, "action": 0.5758063793182373}
{"mode": "train", "epochs": 12, "timestep": 23886, "ep_reward": 1344.785888671875, "reward": 0.8891005516052246, "action": 0.21029877662658691}
{"mode": "train", "epochs": 12, "timestep": 23887, "ep_reward": 1345.7017822265625, "reward": 0.9159082770347595, "action": 1.3241167068481445}
{"mode": "train", "epochs": 12, "timestep": 23888, "ep_reward": 1346.63330078125, "reward": 0.9314784407615662, "action": 0.8111989498138428}
{"mode": "train", "epochs": 12, "timestep": 23889, "ep_reward": 1347.5748291015625, "reward": 0.9415671229362488, "action": 1.2502952814102173}
{"mode": "train", "epochs": 12, "timestep": 23890, "ep_reward": 1348.5206298828125, "reward": 0.9457859992980957, "action": 1.3534411191940308}
{"mode": "train", "epochs": 12, "timestep": 23891, "ep_reward": 1349.4661865234375, "reward": 0.945589542388916, "action": 1.1654828786849976}
{"mode": "train", "epochs": 12, "timestep": 23892, "ep_reward": 1350.40673828125, "reward": 0.940565288066864, "action": 1.7116591930389404}
{"mode": "train", "epochs": 12, "timestep": 23893, "ep_reward": 1351.3387451171875, "reward": 0.932040810585022, "action": 0.33383965492248535}
{"mode": "train", "epochs": 12, "timestep": 23894, "ep_reward": 1352.25244140625, "reward": 0.9137434363365173, "action": 0.8161289095878601}
{"mode": "train", "epochs": 12, "timestep": 23895, "ep_reward": 1353.1402587890625, "reward": 0.8877575993537903, "action": 0.919542670249939}
{"mode": "train", "epochs": 12, "timestep": 23896, "ep_reward": 1353.9920654296875, "reward": 0.8517624735832214, "action": 1.5796592235565186}
{"mode": "train", "epochs": 12, "timestep": 23897, "ep_reward": 1354.80029296875, "reward": 0.8082379102706909, "action": 1.205651044845581}
{"mode": "train", "epochs": 12, "timestep": 23898, "ep_reward": 1355.5499267578125, "reward": 0.7496082782745361, "action": 0.6888523697853088}
{"mode": "train", "epochs": 12, "timestep": 23899, "ep_reward": 1356.2210693359375, "reward": 0.6711791753768921, "action": 0.679031491279602}
{"mode": "train", "epochs": 12, "timestep": 23900, "ep_reward": 1356.79638671875, "reward": 0.5753492116928101, "action": 1.385600209236145}
{"mode": "train", "epochs": 12, "timestep": 23901, "ep_reward": 1357.269287109375, "reward": 0.4728966951370239, "action": 1.6942064762115479}
{"mode": "train", "epochs": 12, "timestep": 23902, "ep_reward": 1357.6361083984375, "reward": 0.36688143014907837, "action": -0.42632338404655457}
{"mode": "train", "epochs": 12, "timestep": 23903, "ep_reward": 1357.8671875, "reward": 0.23104381561279297, "action": -1.1922786235809326}
{"mode": "train", "epochs": 12, "timestep": 23904, "ep_reward": 1358.0455322265625, "reward": 0.17839324474334717, "action": -0.43477049469947815}
{"mode": "train", "epochs": 12, "timestep": 23905, "ep_reward": 1358.3388671875, "reward": 0.29330408573150635, "action": -1.6015846729278564}
{"mode": "train", "epochs": 12, "timestep": 23906, "ep_reward": 1358.7376708984375, "reward": 0.3988461494445801, "action": -1.2136585712432861}
{"mode": "train", "epochs": 12, "timestep": 23907, "ep_reward": 1359.2442626953125, "reward": 0.5066331624984741, "action": -1.8514647483825684}
{"mode": "train", "epochs": 12, "timestep": 23908, "ep_reward": 1359.8453369140625, "reward": 0.6010282039642334, "action": -1.713265299797058}
{"mode": "train", "epochs": 12, "timestep": 23909, "ep_reward": 1360.53125, "reward": 0.685943067073822, "action": -1.1677770614624023}
{"mode": "train", "epochs": 12, "timestep": 23910, "ep_reward": 1361.29248046875, "reward": 0.7611740231513977, "action": -1.0644714832305908}
{"mode": "train", "epochs": 12, "timestep": 23911, "ep_reward": 1362.1142578125, "reward": 0.8217464685440063, "action": -0.6875047087669373}
{"mode": "train", "epochs": 12, "timestep": 23912, "ep_reward": 1362.984375, "reward": 0.87017822265625, "action": -1.4911143779754639}
{"mode": "train", "epochs": 12, "timestep": 23913, "ep_reward": 1363.8868408203125, "reward": 0.9024816751480103, "action": -1.5341249704360962}
{"mode": "train", "epochs": 12, "timestep": 23914, "ep_reward": 1364.813232421875, "reward": 0.9264282584190369, "action": -0.14759504795074463}
{"mode": "train", "epochs": 12, "timestep": 23915, "ep_reward": 1365.761962890625, "reward": 0.948726236820221, "action": -1.7947216033935547}
{"mode": "train", "epochs": 12, "timestep": 23916, "ep_reward": 1366.7215576171875, "reward": 0.9595794677734375, "action": -0.7275264263153076}
{"mode": "train", "epochs": 12, "timestep": 23917, "ep_reward": 1367.691650390625, "reward": 0.9701494574546814, "action": -1.6388500928878784}
{"mode": "train", "epochs": 12, "timestep": 23918, "ep_reward": 1368.666748046875, "reward": 0.9751508235931396, "action": -0.9688111543655396}
{"mode": "train", "epochs": 12, "timestep": 23919, "ep_reward": 1369.6466064453125, "reward": 0.9798466563224792, "action": -0.04340082406997681}
{"mode": "train", "epochs": 12, "timestep": 23920, "ep_reward": 1370.6314697265625, "reward": 0.9848744869232178, "action": -0.5615255236625671}
{"mode": "train", "epochs": 12, "timestep": 23921, "ep_reward": 1371.6181640625, "reward": 0.986643373966217, "action": -0.026667743921279907}
{"mode": "train", "epochs": 12, "timestep": 23922, "ep_reward": 1372.6063232421875, "reward": 0.9881569743156433, "action": 0.7467304468154907}
{"mode": "train", "epochs": 12, "timestep": 23923, "ep_reward": 1373.596435546875, "reward": 0.9901517629623413, "action": 0.5723809003829956}
{"mode": "train", "epochs": 12, "timestep": 23924, "ep_reward": 1374.5867919921875, "reward": 0.9903513193130493, "action": 1.2438311576843262}
{"mode": "train", "epochs": 12, "timestep": 23925, "ep_reward": 1375.577880859375, "reward": 0.9910496473312378, "action": 1.1465619802474976}
{"mode": "train", "epochs": 12, "timestep": 23926, "ep_reward": 1376.568359375, "reward": 0.9905236959457397, "action": 1.6008820533752441}
{"mode": "train", "epochs": 12, "timestep": 23927, "ep_reward": 1377.5584716796875, "reward": 0.9901169538497925, "action": 2.0}
{"mode": "train", "epochs": 12, "timestep": 23928, "ep_reward": 1378.548583984375, "reward": 0.9900683164596558, "action": 1.19504714012146}
{"mode": "train", "epochs": 12, "timestep": 23929, "ep_reward": 1379.536376953125, "reward": 0.9878433346748352, "action": 1.5352668762207031}
{"mode": "train", "epochs": 12, "timestep": 23930, "ep_reward": 1380.5220947265625, "reward": 0.9856944680213928, "action": 0.8737161755561829}
{"mode": "train", "epochs": 12, "timestep": 23931, "ep_reward": 1381.5032958984375, "reward": 0.9811409115791321, "action": 1.222827672958374}
{"mode": "train", "epochs": 12, "timestep": 23932, "ep_reward": 1382.47900390625, "reward": 0.9757287502288818, "action": 1.807419776916504}
{"mode": "train", "epochs": 12, "timestep": 23933, "ep_reward": 1383.4493408203125, "reward": 0.9703425168991089, "action": 1.310147762298584}
{"mode": "train", "epochs": 12, "timestep": 23934, "ep_reward": 1384.410888671875, "reward": 0.9615061283111572, "action": 0.8483803272247314}
{"mode": "train", "epochs": 12, "timestep": 23935, "ep_reward": 1385.3583984375, "reward": 0.9474675059318542, "action": 1.3943190574645996}
{"mode": "train", "epochs": 12, "timestep": 23936, "ep_reward": 1386.2890625, "reward": 0.930682361125946, "action": 0.4797406792640686}
{"mode": "train", "epochs": 12, "timestep": 23937, "ep_reward": 1387.1917724609375, "reward": 0.9027225375175476, "action": 0.08262401819229126}
{"mode": "train", "epochs": 12, "timestep": 23938, "ep_reward": 1388.0528564453125, "reward": 0.8611171245574951, "action": 0.540003776550293}
{"mode": "train", "epochs": 12, "timestep": 23939, "ep_reward": 1388.8603515625, "reward": 0.8075125813484192, "action": 1.2830169200897217}
{"mode": "train", "epochs": 12, "timestep": 23940, "ep_reward": 1389.6038818359375, "reward": 0.7435462474822998, "action": 1.5759105682373047}
{"mode": "train", "epochs": 12, "timestep": 23941, "ep_reward": 1390.2698974609375, "reward": 0.665982186794281, "action": 1.202834129333496}
{"mode": "train", "epochs": 12, "timestep": 23942, "ep_reward": 1390.837890625, "reward": 0.568011999130249, "action": 0.5418112277984619}
{"mode": "train", "epochs": 12, "timestep": 23943, "ep_reward": 1391.28369140625, "reward": 0.4457712173461914, "action": 1.0561877489089966}
{"mode": "train", "epochs": 12, "timestep": 23944, "ep_reward": 1391.601318359375, "reward": 0.3176742196083069, "action": 1.9713385105133057}
{"mode": "train", "epochs": 12, "timestep": 23945, "ep_reward": 1391.8018798828125, "reward": 0.20055025815963745, "action": -1.1900523900985718}
{"mode": "train", "epochs": 12, "timestep": 23946, "ep_reward": 1391.9576416015625, "reward": 0.1557239294052124, "action": -0.9272820353507996}
{"mode": "train", "epochs": 12, "timestep": 23947, "ep_reward": 1392.2301025390625, "reward": 0.2725043296813965, "action": 0.1855618953704834}
{"mode": "train", "epochs": 12, "timestep": 23948, "ep_reward": 1392.633056640625, "reward": 0.4029025435447693, "action": -1.0842432975769043}
{"mode": "train", "epochs": 12, "timestep": 23949, "ep_reward": 1393.1473388671875, "reward": 0.5142370462417603, "action": -0.43381425738334656}
{"mode": "train", "epochs": 12, "timestep": 23950, "ep_reward": 1393.7689208984375, "reward": 0.6215649843215942, "action": -0.6723043322563171}
{"mode": "train", "epochs": 12, "timestep": 23951, "ep_reward": 1394.4798583984375, "reward": 0.710972785949707, "action": -1.4284751415252686}
{"mode": "train", "epochs": 12, "timestep": 23952, "ep_reward": 1395.2587890625, "reward": 0.7789391279220581, "action": -0.09250086545944214}
{"mode": "train", "epochs": 12, "timestep": 23953, "ep_reward": 1396.099365234375, "reward": 0.8405505418777466, "action": -0.8286361694335938}
{"mode": "train", "epochs": 12, "timestep": 23954, "ep_reward": 1396.982421875, "reward": 0.8830252885818481, "action": -0.5194189548492432}
{"mode": "train", "epochs": 12, "timestep": 23955, "ep_reward": 1397.8978271484375, "reward": 0.9154351949691772, "action": -1.9255554676055908}
{"mode": "train", "epochs": 12, "timestep": 23956, "ep_reward": 1398.83251953125, "reward": 0.9346716403961182, "action": -0.9805065393447876}
{"mode": "train", "epochs": 12, "timestep": 23957, "ep_reward": 1399.7841796875, "reward": 0.951628565788269, "action": -1.2846472263336182}
{"mode": "train", "epochs": 12, "timestep": 23958, "ep_reward": 1400.7474365234375, "reward": 0.963209331035614, "action": -1.1002761125564575}
{"mode": "train", "epochs": 12, "timestep": 23959, "ep_reward": 1401.7193603515625, "reward": 0.9719399213790894, "action": -1.2501423358917236}
{"mode": "train", "epochs": 12, "timestep": 23960, "ep_reward": 1402.6973876953125, "reward": 0.9780070781707764, "action": -1.2482620477676392}
{"mode": "train", "epochs": 12, "timestep": 23961, "ep_reward": 1403.6798095703125, "reward": 0.9824637174606323, "action": -0.9638283252716064}
{"mode": "train", "epochs": 12, "timestep": 23962, "ep_reward": 1404.665771484375, "reward": 0.9859462976455688, "action": -0.6424919366836548}
{"mode": "train", "epochs": 12, "timestep": 23963, "ep_reward": 1405.654052734375, "reward": 0.9883200526237488, "action": -1.4184616804122925}
{"mode": "train", "epochs": 12, "timestep": 23964, "ep_reward": 1406.6435546875, "reward": 0.9895561337471008, "action": -1.2263952493667603}
{"mode": "train", "epochs": 12, "timestep": 23965, "ep_reward": 1407.634033203125, "reward": 0.9904612898826599, "action": -1.0654597282409668}
{"mode": "train", "epochs": 12, "timestep": 23966, "ep_reward": 1408.6248779296875, "reward": 0.9908543229103088, "action": -1.547271490097046}
{"mode": "train", "epochs": 12, "timestep": 23967, "ep_reward": 1409.615966796875, "reward": 0.9911487102508545, "action": -0.607422411441803}
{"mode": "train", "epochs": 12, "timestep": 23968, "ep_reward": 1410.606689453125, "reward": 0.9906854629516602, "action": -1.1883118152618408}
{"mode": "train", "epochs": 12, "timestep": 23969, "ep_reward": 1411.5966796875, "reward": 0.9899795055389404, "action": -0.1993396282196045}
{"mode": "train", "epochs": 12, "timestep": 23970, "ep_reward": 1412.584228515625, "reward": 0.9875624775886536, "action": -0.4915415644645691}
{"mode": "train", "epochs": 12, "timestep": 23971, "ep_reward": 1413.568115234375, "reward": 0.9838585257530212, "action": -0.40391266345977783}
{"mode": "train", "epochs": 12, "timestep": 23972, "ep_reward": 1414.546142578125, "reward": 0.9780069589614868, "action": -0.7523740530014038}
{"mode": "train", "epochs": 12, "timestep": 23973, "ep_reward": 1415.5164794921875, "reward": 0.9703750610351562, "action": -1.0304124355316162}
{"mode": "train", "epochs": 12, "timestep": 23974, "ep_reward": 1416.47705078125, "reward": 0.9605953097343445, "action": -0.8478578925132751}
{"mode": "train", "epochs": 12, "timestep": 23975, "ep_reward": 1417.42333984375, "reward": 0.9462610483169556, "action": -0.9656709432601929}
{"mode": "train", "epochs": 12, "timestep": 23976, "ep_reward": 1418.3502197265625, "reward": 0.9269207715988159, "action": -0.18601727485656738}
{"mode": "train", "epochs": 12, "timestep": 23977, "ep_reward": 1419.245849609375, "reward": 0.8956184983253479, "action": -0.6148647665977478}
{"mode": "train", "epochs": 12, "timestep": 23978, "ep_reward": 1420.100830078125, "reward": 0.8549506664276123, "action": -0.7242117524147034}
{"mode": "train", "epochs": 12, "timestep": 23979, "ep_reward": 1420.901611328125, "reward": 0.8007460832595825, "action": -1.592867136001587}
{"mode": "train", "epochs": 12, "timestep": 23980, "ep_reward": 1421.6395263671875, "reward": 0.7379536628723145, "action": -1.4050798416137695}
{"mode": "train", "epochs": 12, "timestep": 23981, "ep_reward": 1422.297119140625, "reward": 0.6575508117675781, "action": -0.6880149841308594}
{"mode": "train", "epochs": 12, "timestep": 23982, "ep_reward": 1422.84912109375, "reward": 0.551956295967102, "action": 0.550986111164093}
{"mode": "train", "epochs": 12, "timestep": 23983, "ep_reward": 1423.26123046875, "reward": 0.41216951608657837, "action": 0.28134840726852417}
{"mode": "train", "epochs": 12, "timestep": 23984, "ep_reward": 1423.5201416015625, "reward": 0.25896352529525757, "action": -0.9330499768257141}
{"mode": "train", "epochs": 12, "timestep": 23985, "ep_reward": 1423.6387939453125, "reward": 0.11868667602539062, "action": -0.8113596439361572}
{"mode": "train", "epochs": 12, "timestep": 23986, "ep_reward": 1423.8182373046875, "reward": 0.1794375777244568, "action": -1.0192842483520508}
{"mode": "train", "epochs": 12, "timestep": 23987, "ep_reward": 1424.1380615234375, "reward": 0.3197770118713379, "action": -0.3233295679092407}
{"mode": "train", "epochs": 12, "timestep": 23988, "ep_reward": 1424.5860595703125, "reward": 0.4479602575302124, "action": -0.863420307636261}
{"mode": "train", "epochs": 12, "timestep": 23989, "ep_reward": 1425.1566162109375, "reward": 0.5705618858337402, "action": 0.199435293674469}
{"mode": "train", "epochs": 12, "timestep": 23990, "ep_reward": 1425.823974609375, "reward": 0.6674153804779053, "action": 1.1872777938842773}
{"mode": "train", "epochs": 12, "timestep": 23991, "ep_reward": 1426.565673828125, "reward": 0.7417566776275635, "action": 0.40776288509368896}
{"mode": "train", "epochs": 12, "timestep": 23992, "ep_reward": 1427.3721923828125, "reward": 0.8065400719642639, "action": 0.7571572661399841}
{"mode": "train", "epochs": 12, "timestep": 23993, "ep_reward": 1428.226806640625, "reward": 0.8545617461204529, "action": -0.07824689149856567}
{"mode": "train", "epochs": 12, "timestep": 23994, "ep_reward": 1429.11962890625, "reward": 0.8927893042564392, "action": 1.0861997604370117}
{"mode": "train", "epochs": 12, "timestep": 23995, "ep_reward": 1430.03564453125, "reward": 0.9159907698631287, "action": 0.9342751502990723}
{"mode": "train", "epochs": 12, "timestep": 23996, "ep_reward": 1430.967529296875, "reward": 0.931887149810791, "action": 1.1579619646072388}
{"mode": "train", "epochs": 12, "timestep": 23997, "ep_reward": 1431.90869140625, "reward": 0.941173255443573, "action": 0.8464261293411255}
{"mode": "train", "epochs": 12, "timestep": 23998, "ep_reward": 1432.853759765625, "reward": 0.9450316429138184, "action": 1.1392371654510498}
{"mode": "train", "epochs": 12, "timestep": 23999, "ep_reward": 1433.79736328125, "reward": 0.9436635971069336, "action": 0.9991459250450134}
{"mode": "train", "epochs": 12, "timestep": 24000, "ep_reward": 1434.7342529296875, "reward": 0.9368752837181091, "action": 1.352103590965271}
{"mode": "train", "epochs": 13, "timestep": 24001, "ep_reward": 0.9977742433547974, "reward": 0.9977742433547974, "action": 0.005508244037628174}
{"mode": "train", "epochs": 13, "timestep": 24002, "ep_reward": 1.996018886566162, "reward": 0.9982446432113647, "action": -0.19948434829711914}
{"mode": "train", "epochs": 13, "timestep": 24003, "ep_reward": 2.9946515560150146, "reward": 0.9986326098442078, "action": 0.789945125579834}
{"mode": "train", "epochs": 13, "timestep": 24004, "ep_reward": 3.9926211833953857, "reward": 0.9979696273803711, "action": 0.3837178945541382}
{"mode": "train", "epochs": 13, "timestep": 24005, "ep_reward": 4.989924907684326, "reward": 0.9973037838935852, "action": -0.8201833963394165}
{"mode": "train", "epochs": 13, "timestep": 24006, "ep_reward": 5.987709999084473, "reward": 0.997785210609436, "action": -0.40011775493621826}
{"mode": "train", "epochs": 13, "timestep": 24007, "ep_reward": 6.985165596008301, "reward": 0.9974554777145386, "action": -1.1272262334823608}
{"mode": "train", "epochs": 13, "timestep": 24008, "ep_reward": 7.982884407043457, "reward": 0.9977187514305115, "action": -1.1583263874053955}
{"mode": "train", "epochs": 13, "timestep": 24009, "ep_reward": 8.980751991271973, "reward": 0.9978674650192261, "action": -0.8875240683555603}
{"mode": "train", "epochs": 13, "timestep": 24010, "ep_reward": 9.978458404541016, "reward": 0.9977066516876221, "action": -0.4887242019176483}
{"mode": "train", "epochs": 13, "timestep": 24011, "ep_reward": 10.97555923461914, "reward": 0.9971011281013489, "action": -0.518237829208374}
{"mode": "train", "epochs": 13, "timestep": 24012, "ep_reward": 11.971870422363281, "reward": 0.9963107109069824, "action": -0.4466397762298584}
{"mode": "train", "epochs": 13, "timestep": 24013, "ep_reward": 12.966951370239258, "reward": 0.9950809478759766, "action": -1.0362855195999146}
{"mode": "train", "epochs": 13, "timestep": 24014, "ep_reward": 13.961211204528809, "reward": 0.994259774684906, "action": -0.5410070419311523}
{"mode": "train", "epochs": 13, "timestep": 24015, "ep_reward": 14.953474044799805, "reward": 0.9922627806663513, "action": -1.6942155361175537}
{"mode": "train", "epochs": 13, "timestep": 24016, "ep_reward": 15.945035934448242, "reward": 0.9915618896484375, "action": -1.3640762567520142}
{"mode": "train", "epochs": 13, "timestep": 24017, "ep_reward": 16.93518829345703, "reward": 0.9901529550552368, "action": -0.9316793084144592}
{"mode": "train", "epochs": 13, "timestep": 24018, "ep_reward": 17.922780990600586, "reward": 0.9875929951667786, "action": -0.01049339771270752}
{"mode": "train", "epochs": 13, "timestep": 24019, "ep_reward": 18.904741287231445, "reward": 0.9819602966308594, "action": -0.9547941088676453}
{"mode": "train", "epochs": 13, "timestep": 24020, "ep_reward": 19.88098907470703, "reward": 0.9762483239173889, "action": -0.8525552749633789}
{"mode": "train", "epochs": 13, "timestep": 24021, "ep_reward": 20.84893035888672, "reward": 0.9679412841796875, "action": -1.3004405498504639}
{"mode": "train", "epochs": 13, "timestep": 24022, "ep_reward": 21.806941986083984, "reward": 0.9580125212669373, "action": -1.6316773891448975}
{"mode": "train", "epochs": 13, "timestep": 24023, "ep_reward": 22.75296401977539, "reward": 0.9460228085517883, "action": -0.767821192741394}
{"mode": "train", "epochs": 13, "timestep": 24024, "ep_reward": 23.678462982177734, "reward": 0.9254999160766602, "action": -1.24505615234375}
{"mode": "train", "epochs": 13, "timestep": 24025, "ep_reward": 24.578365325927734, "reward": 0.8999030590057373, "action": -0.9702118039131165}
{"mode": "train", "epochs": 13, "timestep": 24026, "ep_reward": 25.4417667388916, "reward": 0.8634019494056702, "action": -1.1432522535324097}
{"mode": "train", "epochs": 13, "timestep": 24027, "ep_reward": 26.25758171081543, "reward": 0.815814733505249, "action": -1.061719536781311}
{"mode": "train", "epochs": 13, "timestep": 24028, "ep_reward": 27.010498046875, "reward": 0.752916693687439, "action": -0.15264977514743805}
{"mode": "train", "epochs": 13, "timestep": 24029, "ep_reward": 27.673725128173828, "reward": 0.6632276773452759, "action": -0.1487109363079071}
{"mode": "train", "epochs": 13, "timestep": 24030, "ep_reward": 28.224998474121094, "reward": 0.551272451877594, "action": 0.8849952220916748}
{"mode": "train", "epochs": 13, "timestep": 24031, "ep_reward": 28.62948226928711, "reward": 0.40448427200317383, "action": 0.2627854347229004}
{"mode": "train", "epochs": 13, "timestep": 24032, "ep_reward": 28.876829147338867, "reward": 0.2473468780517578, "action": -1.4777491092681885}
{"mode": "train", "epochs": 13, "timestep": 24033, "ep_reward": 28.988910675048828, "reward": 0.11208140850067139, "action": -0.23867765069007874}
{"mode": "train", "epochs": 13, "timestep": 24034, "ep_reward": 29.154083251953125, "reward": 0.16517305374145508, "action": 0.020506560802459717}
{"mode": "train", "epochs": 13, "timestep": 24035, "ep_reward": 29.452465057373047, "reward": 0.29838114976882935, "action": -0.5543802976608276}
{"mode": "train", "epochs": 13, "timestep": 24036, "ep_reward": 29.888029098510742, "reward": 0.43556463718414307, "action": -0.8076658844947815}
{"mode": "train", "epochs": 13, "timestep": 24037, "ep_reward": 30.45153045654297, "reward": 0.5635011792182922, "action": 0.25402969121932983}
{"mode": "train", "epochs": 13, "timestep": 24038, "ep_reward": 31.116064071655273, "reward": 0.6645339727401733, "action": 0.4022497534751892}
{"mode": "train", "epochs": 13, "timestep": 24039, "ep_reward": 31.863256454467773, "reward": 0.7471932172775269, "action": 1.2103432416915894}
{"mode": "train", "epochs": 13, "timestep": 24040, "ep_reward": 32.671451568603516, "reward": 0.8081937432289124, "action": 1.2630648612976074}
{"mode": "train", "epochs": 13, "timestep": 24041, "ep_reward": 33.52712631225586, "reward": 0.8556742668151855, "action": 1.475172996520996}
{"mode": "train", "epochs": 13, "timestep": 24042, "ep_reward": 34.41820526123047, "reward": 0.8910790085792542, "action": 1.4048069715499878}
{"mode": "train", "epochs": 13, "timestep": 24043, "ep_reward": 35.33631896972656, "reward": 0.9181124567985535, "action": 1.059181571006775}
{"mode": "train", "epochs": 13, "timestep": 24044, "ep_reward": 36.275569915771484, "reward": 0.9392492771148682, "action": 0.7422628402709961}
{"mode": "train", "epochs": 13, "timestep": 24045, "ep_reward": 37.23070526123047, "reward": 0.9551346302032471, "action": 1.4979573488235474}
{"mode": "train", "epochs": 13, "timestep": 24046, "ep_reward": 38.195682525634766, "reward": 0.9649786353111267, "action": 1.215559959411621}
{"mode": "train", "epochs": 13, "timestep": 24047, "ep_reward": 39.16831588745117, "reward": 0.972632646560669, "action": 0.9073532819747925}
{"mode": "train", "epochs": 13, "timestep": 24048, "ep_reward": 40.146690368652344, "reward": 0.9783730506896973, "action": -0.0847126841545105}
{"mode": "train", "epochs": 13, "timestep": 24049, "ep_reward": 41.128971099853516, "reward": 0.9822803735733032, "action": 1.1639986038208008}
{"mode": "train", "epochs": 13, "timestep": 24050, "ep_reward": 42.11249542236328, "reward": 0.9835225939750671, "action": 0.7789553999900818}
{"mode": "train", "epochs": 13, "timestep": 24051, "ep_reward": 43.09591293334961, "reward": 0.9834166169166565, "action": 0.5239152312278748}
{"mode": "train", "epochs": 13, "timestep": 24052, "ep_reward": 44.077293395996094, "reward": 0.981380045413971, "action": 0.48056089878082275}
{"mode": "train", "epochs": 13, "timestep": 24053, "ep_reward": 45.05421447753906, "reward": 0.9769218564033508, "action": 1.274773120880127}
{"mode": "train", "epochs": 13, "timestep": 24054, "ep_reward": 46.02571105957031, "reward": 0.9714968800544739, "action": 1.6107333898544312}
{"mode": "train", "epochs": 13, "timestep": 24055, "ep_reward": 46.990699768066406, "reward": 0.9649888873100281, "action": 0.6440932154655457}
{"mode": "train", "epochs": 13, "timestep": 24056, "ep_reward": 47.943546295166016, "reward": 0.9528465867042542, "action": 0.6657531261444092}
{"mode": "train", "epochs": 13, "timestep": 24057, "ep_reward": 48.87893295288086, "reward": 0.9353870749473572, "action": 1.0030066967010498}
{"mode": "train", "epochs": 13, "timestep": 24058, "ep_reward": 49.791465759277344, "reward": 0.9125330448150635, "action": 0.9955170154571533}
{"mode": "train", "epochs": 13, "timestep": 24059, "ep_reward": 50.67258834838867, "reward": 0.881123423576355, "action": 1.3188445568084717}
{"mode": "train", "epochs": 13, "timestep": 24060, "ep_reward": 51.51375198364258, "reward": 0.8411620259284973, "action": 0.559805154800415}
{"mode": "train", "epochs": 13, "timestep": 24061, "ep_reward": 52.295982360839844, "reward": 0.7822294235229492, "action": 0.7718592286109924}
{"mode": "train", "epochs": 13, "timestep": 24062, "ep_reward": 53.00332260131836, "reward": 0.7073404788970947, "action": 1.3932878971099854}
{"mode": "train", "epochs": 13, "timestep": 24063, "ep_reward": 53.62397003173828, "reward": 0.6206467151641846, "action": 1.4730637073516846}
{"mode": "train", "epochs": 13, "timestep": 24064, "ep_reward": 54.143310546875, "reward": 0.5193390846252441, "action": 1.8234295845031738}
{"mode": "train", "epochs": 13, "timestep": 24065, "ep_reward": 54.554527282714844, "reward": 0.4112151861190796, "action": 0.9133785367012024}
{"mode": "train", "epochs": 13, "timestep": 24066, "ep_reward": 54.84052276611328, "reward": 0.28599411249160767, "action": -0.07099515199661255}
{"mode": "train", "epochs": 13, "timestep": 24067, "ep_reward": 54.986629486083984, "reward": 0.14610666036605835, "action": -0.48922693729400635}
{"mode": "train", "epochs": 13, "timestep": 24068, "ep_reward": 55.205596923828125, "reward": 0.21896874904632568, "action": 0.1727275848388672}
{"mode": "train", "epochs": 13, "timestep": 24069, "ep_reward": 55.54964065551758, "reward": 0.34404200315475464, "action": -1.2784229516983032}
{"mode": "train", "epochs": 13, "timestep": 24070, "ep_reward": 56.002342224121094, "reward": 0.4527033567428589, "action": -1.2584192752838135}
{"mode": "train", "epochs": 13, "timestep": 24071, "ep_reward": 56.558956146240234, "reward": 0.5566130876541138, "action": -1.4822051525115967}
{"mode": "train", "epochs": 13, "timestep": 24072, "ep_reward": 57.2075309753418, "reward": 0.6485730409622192, "action": -0.43883150815963745}
{"mode": "train", "epochs": 13, "timestep": 24073, "ep_reward": 57.9424934387207, "reward": 0.7349625825881958, "action": -0.7303897142410278}
{"mode": "train", "epochs": 13, "timestep": 24074, "ep_reward": 58.74449920654297, "reward": 0.8020040988922119, "action": -1.8954358100891113}
{"mode": "train", "epochs": 13, "timestep": 24075, "ep_reward": 59.59260177612305, "reward": 0.8481026291847229, "action": -0.6406455039978027}
{"mode": "train", "epochs": 13, "timestep": 24076, "ep_reward": 60.48219299316406, "reward": 0.8895922303199768, "action": -1.337323784828186}
{"mode": "train", "epochs": 13, "timestep": 24077, "ep_reward": 61.39966583251953, "reward": 0.9174709320068359, "action": -1.4076886177062988}
{"mode": "train", "epochs": 13, "timestep": 24078, "ep_reward": 62.33759307861328, "reward": 0.9379287362098694, "action": -1.4284443855285645}
{"mode": "train", "epochs": 13, "timestep": 24079, "ep_reward": 63.29058837890625, "reward": 0.9529961347579956, "action": -1.3305755853652954}
{"mode": "train", "epochs": 13, "timestep": 24080, "ep_reward": 64.25496673583984, "reward": 0.9643815755844116, "action": -0.9475260972976685}
{"mode": "train", "epochs": 13, "timestep": 24081, "ep_reward": 65.22843933105469, "reward": 0.9734739661216736, "action": -1.1257637739181519}
{"mode": "train", "epochs": 13, "timestep": 24082, "ep_reward": 66.20823669433594, "reward": 0.979800283908844, "action": -0.24948006868362427}
{"mode": "train", "epochs": 13, "timestep": 24083, "ep_reward": 67.19373321533203, "reward": 0.9854980111122131, "action": -1.2060469388961792}
{"mode": "train", "epochs": 13, "timestep": 24084, "ep_reward": 68.18209838867188, "reward": 0.9883620142936707, "action": -1.257537841796875}
{"mode": "train", "epochs": 13, "timestep": 24085, "ep_reward": 69.17266082763672, "reward": 0.9905633330345154, "action": -0.4536672830581665}
{"mode": "train", "epochs": 13, "timestep": 24086, "ep_reward": 70.16546630859375, "reward": 0.9928032159805298, "action": -0.8726669549942017}
{"mode": "train", "epochs": 13, "timestep": 24087, "ep_reward": 71.15949249267578, "reward": 0.9940275549888611, "action": -1.3307201862335205}
{"mode": "train", "epochs": 13, "timestep": 24088, "ep_reward": 72.154296875, "reward": 0.9948071837425232, "action": -0.9264821410179138}
{"mode": "train", "epochs": 13, "timestep": 24089, "ep_reward": 73.14993286132812, "reward": 0.9956349730491638, "action": -0.8645913004875183}
{"mode": "train", "epochs": 13, "timestep": 24090, "ep_reward": 74.14615631103516, "reward": 0.9962206482887268, "action": -1.4374001026153564}
{"mode": "train", "epochs": 13, "timestep": 24091, "ep_reward": 75.14268493652344, "reward": 0.9965257048606873, "action": -1.1624301671981812}
{"mode": "train", "epochs": 13, "timestep": 24092, "ep_reward": 76.13961791992188, "reward": 0.9969324469566345, "action": -0.6855291128158569}
{"mode": "train", "epochs": 13, "timestep": 24093, "ep_reward": 77.13687896728516, "reward": 0.9972624182701111, "action": -2.0}
{"mode": "train", "epochs": 13, "timestep": 24094, "ep_reward": 78.13373565673828, "reward": 0.9968587160110474, "action": -1.1350089311599731}
{"mode": "train", "epochs": 13, "timestep": 24095, "ep_reward": 79.1304702758789, "reward": 0.9967326521873474, "action": -1.3170275688171387}
{"mode": "train", "epochs": 13, "timestep": 24096, "ep_reward": 80.12654876708984, "reward": 0.9960772395133972, "action": -0.8606947660446167}
{"mode": "train", "epochs": 13, "timestep": 24097, "ep_reward": 81.12197875976562, "reward": 0.9954312443733215, "action": -0.8163107633590698}
{"mode": "train", "epochs": 13, "timestep": 24098, "ep_reward": 82.11616516113281, "reward": 0.9941827058792114, "action": 0.34401145577430725}
{"mode": "train", "epochs": 13, "timestep": 24099, "ep_reward": 83.11036682128906, "reward": 0.9942018389701843, "action": 0.3376952111721039}
{"mode": "train", "epochs": 13, "timestep": 24100, "ep_reward": 84.10388946533203, "reward": 0.9935248494148254, "action": 0.27052968740463257}
{"mode": "train", "epochs": 13, "timestep": 24101, "ep_reward": 85.0958251953125, "reward": 0.9919328093528748, "action": 0.7894641757011414}
{"mode": "train", "epochs": 13, "timestep": 24102, "ep_reward": 86.0863037109375, "reward": 0.9904757738113403, "action": 1.3056271076202393}
{"mode": "train", "epochs": 13, "timestep": 24103, "ep_reward": 87.07554626464844, "reward": 0.9892438650131226, "action": 1.7310186624526978}
{"mode": "train", "epochs": 13, "timestep": 24104, "ep_reward": 88.06381225585938, "reward": 0.9882645010948181, "action": 1.5728752613067627}
{"mode": "train", "epochs": 13, "timestep": 24105, "ep_reward": 89.05029296875, "reward": 0.9864780902862549, "action": 0.15412002801895142}
{"mode": "train", "epochs": 13, "timestep": 24106, "ep_reward": 90.03071594238281, "reward": 0.9804196357727051, "action": 0.8934961557388306}
{"mode": "train", "epochs": 13, "timestep": 24107, "ep_reward": 91.00469207763672, "reward": 0.9739757180213928, "action": 0.26800763607025146}
{"mode": "train", "epochs": 13, "timestep": 24108, "ep_reward": 91.96724700927734, "reward": 0.962554931640625, "action": 1.6917366981506348}
{"mode": "train", "epochs": 13, "timestep": 24109, "ep_reward": 92.9197769165039, "reward": 0.9525286555290222, "action": 0.7531342506408691}
{"mode": "train", "epochs": 13, "timestep": 24110, "ep_reward": 93.8541030883789, "reward": 0.9343261122703552, "action": 1.4003552198410034}
{"mode": "train", "epochs": 13, "timestep": 24111, "ep_reward": 94.76683807373047, "reward": 0.9127315878868103, "action": 1.0438129901885986}
{"mode": "train", "epochs": 13, "timestep": 24112, "ep_reward": 95.64807891845703, "reward": 0.8812407851219177, "action": 0.4495386481285095}
{"mode": "train", "epochs": 13, "timestep": 24113, "ep_reward": 96.48221588134766, "reward": 0.8341353535652161, "action": 0.638405442237854}
{"mode": "train", "epochs": 13, "timestep": 24114, "ep_reward": 97.25458526611328, "reward": 0.7723674774169922, "action": 1.2923619747161865}
{"mode": "train", "epochs": 13, "timestep": 24115, "ep_reward": 97.95343780517578, "reward": 0.6988550424575806, "action": 0.765705406665802}
{"mode": "train", "epochs": 13, "timestep": 24116, "ep_reward": 98.55509185791016, "reward": 0.6016541719436646, "action": 1.6781136989593506}
{"mode": "train", "epochs": 13, "timestep": 24117, "ep_reward": 99.05266571044922, "reward": 0.49757713079452515, "action": 1.3073601722717285}
{"mode": "train", "epochs": 13, "timestep": 24118, "ep_reward": 99.42994689941406, "reward": 0.37727904319763184, "action": 2.0}
{"mode": "train", "epochs": 13, "timestep": 24119, "ep_reward": 99.69166564941406, "reward": 0.26171982288360596, "action": 1.6659141778945923}
{"mode": "train", "epochs": 13, "timestep": 24120, "ep_reward": 99.83779907226562, "reward": 0.14613211154937744, "action": 0.6436589360237122}
{"mode": "train", "epochs": 13, "timestep": 24121, "ep_reward": 100.08991241455078, "reward": 0.25211286544799805, "action": -0.8583924174308777}
{"mode": "train", "epochs": 13, "timestep": 24122, "ep_reward": 100.45146179199219, "reward": 0.36154842376708984, "action": -0.8081486821174622}
{"mode": "train", "epochs": 13, "timestep": 24123, "ep_reward": 100.9223403930664, "reward": 0.47088176012039185, "action": 0.3331615924835205}
{"mode": "train", "epochs": 13, "timestep": 24124, "ep_reward": 101.50513458251953, "reward": 0.5827934741973877, "action": -1.144948124885559}
{"mode": "train", "epochs": 13, "timestep": 24125, "ep_reward": 102.1741943359375, "reward": 0.6690612435340881, "action": -0.7733975648880005}
{"mode": "train", "epochs": 13, "timestep": 24126, "ep_reward": 102.91901397705078, "reward": 0.74482262134552, "action": -0.9401084780693054}
{"mode": "train", "epochs": 13, "timestep": 24127, "ep_reward": 103.72406005859375, "reward": 0.8050441145896912, "action": -0.37888121604919434}
{"mode": "train", "epochs": 13, "timestep": 24128, "ep_reward": 104.57820892333984, "reward": 0.8541475534439087, "action": -0.42347413301467896}
{"mode": "train", "epochs": 13, "timestep": 24129, "ep_reward": 105.46776580810547, "reward": 0.8895567655563354, "action": -1.2924271821975708}
{"mode": "train", "epochs": 13, "timestep": 24130, "ep_reward": 106.37992858886719, "reward": 0.9121620655059814, "action": -1.0231443643569946}
{"mode": "train", "epochs": 13, "timestep": 24131, "ep_reward": 107.30767822265625, "reward": 0.9277503490447998, "action": -2.0}
{"mode": "train", "epochs": 13, "timestep": 24132, "ep_reward": 108.24434661865234, "reward": 0.9366672039031982, "action": -1.055938720703125}
{"mode": "train", "epochs": 13, "timestep": 24133, "ep_reward": 109.1860122680664, "reward": 0.9416687488555908, "action": -0.7464511394500732}
{"mode": "train", "epochs": 13, "timestep": 24134, "ep_reward": 110.12676239013672, "reward": 0.9407508373260498, "action": -1.3416180610656738}
{"mode": "train", "epochs": 13, "timestep": 24135, "ep_reward": 111.06160736083984, "reward": 0.934842586517334, "action": -1.3804943561553955}
{"mode": "train", "epochs": 13, "timestep": 24136, "ep_reward": 111.9854507446289, "reward": 0.9238443970680237, "action": -0.9819051623344421}
{"mode": "train", "epochs": 13, "timestep": 24137, "ep_reward": 112.8906021118164, "reward": 0.9051535129547119, "action": -1.1013309955596924}
{"mode": "train", "epochs": 13, "timestep": 24138, "ep_reward": 113.76898193359375, "reward": 0.8783782720565796, "action": -1.3236820697784424}
{"mode": "train", "epochs": 13, "timestep": 24139, "ep_reward": 114.6119155883789, "reward": 0.8429335355758667, "action": -0.7751745581626892}
{"mode": "train", "epochs": 13, "timestep": 24140, "ep_reward": 115.4040298461914, "reward": 0.7921128273010254, "action": -0.1763918697834015}
{"mode": "train", "epochs": 13, "timestep": 24141, "ep_reward": 116.12454986572266, "reward": 0.7205171585083008, "action": -1.0841169357299805}
{"mode": "train", "epochs": 13, "timestep": 24142, "ep_reward": 116.76349639892578, "reward": 0.6389430165290833, "action": -0.3352632522583008}
{"mode": "train", "epochs": 13, "timestep": 24143, "ep_reward": 117.29702758789062, "reward": 0.53353351354599, "action": 0.3682522177696228}
{"mode": "train", "epochs": 13, "timestep": 24144, "ep_reward": 117.70042419433594, "reward": 0.40339332818984985, "action": 0.14985615015029907}
{"mode": "train", "epochs": 13, "timestep": 24145, "ep_reward": 117.96392059326172, "reward": 0.2634974718093872, "action": -0.7078341245651245}
{"mode": "train", "epochs": 13, "timestep": 24146, "ep_reward": 118.09707641601562, "reward": 0.13315749168395996, "action": -1.0173016786575317}
{"mode": "train", "epochs": 13, "timestep": 24147, "ep_reward": 118.34342956542969, "reward": 0.2463512420654297, "action": -2.0}
{"mode": "train", "epochs": 13, "timestep": 24148, "ep_reward": 118.72637939453125, "reward": 0.3829473853111267, "action": -0.7479774951934814}
{"mode": "train", "epochs": 13, "timestep": 24149, "ep_reward": 119.22499084472656, "reward": 0.4986114501953125, "action": 0.013456910848617554}
{"mode": "train", "epochs": 13, "timestep": 24150, "ep_reward": 119.8220443725586, "reward": 0.5970513820648193, "action": -0.015348732471466064}
{"mode": "train", "epochs": 13, "timestep": 24151, "ep_reward": 120.5042495727539, "reward": 0.6822019219398499, "action": 1.8117940425872803}
{"mode": "train", "epochs": 13, "timestep": 24152, "ep_reward": 121.24739837646484, "reward": 0.7431514859199524, "action": 0.5187287330627441}
{"mode": "train", "epochs": 13, "timestep": 24153, "ep_reward": 122.046630859375, "reward": 0.7992330193519592, "action": 1.7373924255371094}
{"mode": "train", "epochs": 13, "timestep": 24154, "ep_reward": 122.88444519042969, "reward": 0.837813138961792, "action": 1.668837070465088}
{"mode": "train", "epochs": 13, "timestep": 24155, "ep_reward": 123.75220489501953, "reward": 0.8677561283111572, "action": 0.47824394702911377}
{"mode": "train", "epochs": 13, "timestep": 24156, "ep_reward": 124.64326477050781, "reward": 0.8910597562789917, "action": 0.5129854679107666}
{"mode": "train", "epochs": 13, "timestep": 24157, "ep_reward": 125.54667663574219, "reward": 0.9034098982810974, "action": 1.5367685556411743}
{"mode": "train", "epochs": 13, "timestep": 24158, "ep_reward": 126.45355987548828, "reward": 0.9068840146064758, "action": 1.899989366531372}
{"mode": "train", "epochs": 13, "timestep": 24159, "ep_reward": 127.35819244384766, "reward": 0.9046310782432556, "action": 1.822950005531311}
{"mode": "train", "epochs": 13, "timestep": 24160, "ep_reward": 128.2549285888672, "reward": 0.8967388272285461, "action": 1.1655930280685425}
{"mode": "train", "epochs": 13, "timestep": 24161, "ep_reward": 129.1351776123047, "reward": 0.8802439570426941, "action": 0.8345835208892822}
{"mode": "train", "epochs": 13, "timestep": 24162, "ep_reward": 129.98802185058594, "reward": 0.8528439998626709, "action": 1.1422609090805054}
{"mode": "train", "epochs": 13, "timestep": 24163, "ep_reward": 130.80352783203125, "reward": 0.8155103921890259, "action": 0.374592661857605}
{"mode": "train", "epochs": 13, "timestep": 24164, "ep_reward": 131.56378173828125, "reward": 0.7602598667144775, "action": 0.5417218804359436}
{"mode": "train", "epochs": 13, "timestep": 24165, "ep_reward": 132.25335693359375, "reward": 0.6895759105682373, "action": 1.5489413738250732}
{"mode": "train", "epochs": 13, "timestep": 24166, "ep_reward": 132.8661346435547, "reward": 0.6127710342407227, "action": 0.9620450139045715}
{"mode": "train", "epochs": 13, "timestep": 24167, "ep_reward": 133.38465881347656, "reward": 0.5185307264328003, "action": 1.616580843925476}
{"mode": "train", "epochs": 13, "timestep": 24168, "ep_reward": 133.80718994140625, "reward": 0.4225327968597412, "action": 1.5539448261260986}
{"mode": "train", "epochs": 13, "timestep": 24169, "ep_reward": 134.1309051513672, "reward": 0.3237091302871704, "action": -0.7959151268005371}
{"mode": "train", "epochs": 13, "timestep": 24170, "ep_reward": 134.3282928466797, "reward": 0.19738411903381348, "action": -1.1753953695297241}
{"mode": "train", "epochs": 13, "timestep": 24171, "ep_reward": 134.6067352294922, "reward": 0.27843648195266724, "action": -0.3428305983543396}
{"mode": "train", "epochs": 13, "timestep": 24172, "ep_reward": 134.99110412597656, "reward": 0.3843640089035034, "action": -1.1232542991638184}
{"mode": "train", "epochs": 13, "timestep": 24173, "ep_reward": 135.47323608398438, "reward": 0.48212897777557373, "action": -1.1624834537506104}
{"mode": "train", "epochs": 13, "timestep": 24174, "ep_reward": 136.0481414794922, "reward": 0.5749030113220215, "action": -1.4799078702926636}
{"mode": "train", "epochs": 13, "timestep": 24175, "ep_reward": 136.70498657226562, "reward": 0.6568515300750732, "action": -0.9889267086982727}
{"mode": "train", "epochs": 13, "timestep": 24176, "ep_reward": 137.43585205078125, "reward": 0.7308633327484131, "action": -1.903348684310913}
{"mode": "train", "epochs": 13, "timestep": 24177, "ep_reward": 138.22296142578125, "reward": 0.7871100902557373, "action": -0.8204879760742188}
{"mode": "train", "epochs": 13, "timestep": 24178, "ep_reward": 139.06048583984375, "reward": 0.8375305533409119, "action": -0.6032865047454834}
{"mode": "train", "epochs": 13, "timestep": 24179, "ep_reward": 139.93653869628906, "reward": 0.8760535717010498, "action": -0.8519415855407715}
{"mode": "train", "epochs": 13, "timestep": 24180, "ep_reward": 140.83909606933594, "reward": 0.9025646448135376, "action": -1.316167950630188}
{"mode": "train", "epochs": 13, "timestep": 24181, "ep_reward": 141.7586669921875, "reward": 0.9195671081542969, "action": -1.398066520690918}
{"mode": "train", "epochs": 13, "timestep": 24182, "ep_reward": 142.68881225585938, "reward": 0.930145263671875, "action": -1.0539932250976562}
{"mode": "train", "epochs": 13, "timestep": 24183, "ep_reward": 143.6239013671875, "reward": 0.9350871443748474, "action": -1.1061909198760986}
{"mode": "train", "epochs": 13, "timestep": 24184, "ep_reward": 144.55807495117188, "reward": 0.9341756701469421, "action": -0.7150143384933472}
{"mode": "train", "epochs": 13, "timestep": 24185, "ep_reward": 145.48448181152344, "reward": 0.9264074563980103, "action": -0.65364009141922}
{"mode": "train", "epochs": 13, "timestep": 24186, "ep_reward": 146.39517211914062, "reward": 0.9106832146644592, "action": -0.6993786096572876}
{"mode": "train", "epochs": 13, "timestep": 24187, "ep_reward": 147.28111267089844, "reward": 0.8859469294548035, "action": -0.49073052406311035}
{"mode": "train", "epochs": 13, "timestep": 24188, "ep_reward": 148.13014221191406, "reward": 0.8490258455276489, "action": -0.5543838739395142}
{"mode": "train", "epochs": 13, "timestep": 24189, "ep_reward": 148.92868041992188, "reward": 0.798539400100708, "action": -0.7835547924041748}
{"mode": "train", "epochs": 13, "timestep": 24190, "ep_reward": 149.66253662109375, "reward": 0.733862042427063, "action": -1.5919883251190186}
{"mode": "train", "epochs": 13, "timestep": 24191, "ep_reward": 150.32333374023438, "reward": 0.6607919931411743, "action": -0.7619142532348633}
{"mode": "train", "epochs": 13, "timestep": 24192, "ep_reward": 150.88877868652344, "reward": 0.5654393434524536, "action": -0.12629008293151855}
{"mode": "train", "epochs": 13, "timestep": 24193, "ep_reward": 151.3367156982422, "reward": 0.4479365348815918, "action": -0.13274002075195312}
{"mode": "train", "epochs": 13, "timestep": 24194, "ep_reward": 151.65505981445312, "reward": 0.31834959983825684, "action": -0.9842857122421265}
{"mode": "train", "epochs": 13, "timestep": 24195, "ep_reward": 151.85154724121094, "reward": 0.19649088382720947, "action": -0.4205982983112335}
{"mode": "train", "epochs": 13, "timestep": 24196, "ep_reward": 152.0691375732422, "reward": 0.21759414672851562, "action": -1.1589977741241455}
{"mode": "train", "epochs": 13, "timestep": 24197, "ep_reward": 152.41258239746094, "reward": 0.34344589710235596, "action": -0.6710765361785889}
{"mode": "train", "epochs": 13, "timestep": 24198, "ep_reward": 152.8724365234375, "reward": 0.45984870195388794, "action": -0.4610412120819092}
{"mode": "train", "epochs": 13, "timestep": 24199, "ep_reward": 153.4375, "reward": 0.5650652647018433, "action": 0.8192059993743896}
{"mode": "train", "epochs": 13, "timestep": 24200, "ep_reward": 154.0863494873047, "reward": 0.6488529443740845, "action": 0.4087207317352295}
{"mode": "train", "epochs": 13, "timestep": 24201, "ep_reward": 154.80931091308594, "reward": 0.7229622602462769, "action": 1.209127426147461}
{"mode": "train", "epochs": 13, "timestep": 24202, "ep_reward": 155.58843994140625, "reward": 0.7791272401809692, "action": 1.5079641342163086}
{"mode": "train", "epochs": 13, "timestep": 24203, "ep_reward": 156.4112091064453, "reward": 0.8227636814117432, "action": 0.6117843389511108}
{"mode": "train", "epochs": 13, "timestep": 24204, "ep_reward": 157.26966857910156, "reward": 0.8584564924240112, "action": 0.8824887275695801}
{"mode": "train", "epochs": 13, "timestep": 24205, "ep_reward": 158.15151977539062, "reward": 0.8818519711494446, "action": 1.4650170803070068}
{"mode": "train", "epochs": 13, "timestep": 24206, "ep_reward": 159.0469512939453, "reward": 0.8954300284385681, "action": 0.56424880027771}
{"mode": "train", "epochs": 13, "timestep": 24207, "ep_reward": 159.9478302001953, "reward": 0.9008828997612, "action": 1.5588784217834473}
{"mode": "train", "epochs": 13, "timestep": 24208, "ep_reward": 160.84620666503906, "reward": 0.8983839750289917, "action": 1.5690885782241821}
{"mode": "train", "epochs": 13, "timestep": 24209, "ep_reward": 161.73521423339844, "reward": 0.8890146017074585, "action": 1.8340649604797363}
{"mode": "train", "epochs": 13, "timestep": 24210, "ep_reward": 162.60858154296875, "reward": 0.873364269733429, "action": 1.5168907642364502}
{"mode": "train", "epochs": 13, "timestep": 24211, "ep_reward": 163.45755004882812, "reward": 0.8489679098129272, "action": 0.7514776587486267}
{"mode": "train", "epochs": 13, "timestep": 24212, "ep_reward": 164.26815795898438, "reward": 0.8106110095977783, "action": 0.3744134306907654}
{"mode": "train", "epochs": 13, "timestep": 24213, "ep_reward": 165.02369689941406, "reward": 0.7555328011512756, "action": 1.9854669570922852}
{"mode": "train", "epochs": 13, "timestep": 24214, "ep_reward": 165.72177124023438, "reward": 0.6980726718902588, "action": 0.8251453638076782}
{"mode": "train", "epochs": 13, "timestep": 24215, "ep_reward": 166.34115600585938, "reward": 0.6193898916244507, "action": 0.306185245513916}
{"mode": "train", "epochs": 13, "timestep": 24216, "ep_reward": 166.86268615722656, "reward": 0.5215284824371338, "action": 1.4866936206817627}
{"mode": "train", "epochs": 13, "timestep": 24217, "ep_reward": 167.28831481933594, "reward": 0.4256212115287781, "action": -0.8099046945571899}
{"mode": "train", "epochs": 13, "timestep": 24218, "ep_reward": 167.58627319335938, "reward": 0.2979571223258972, "action": -0.01699209213256836}
{"mode": "train", "epochs": 13, "timestep": 24219, "ep_reward": 167.76800537109375, "reward": 0.1817365288734436, "action": -0.7220233678817749}
{"mode": "train", "epochs": 13, "timestep": 24220, "ep_reward": 168.0508270263672, "reward": 0.2828289866447449, "action": -2.0}
{"mode": "train", "epochs": 13, "timestep": 24221, "ep_reward": 168.42733764648438, "reward": 0.37650394439697266, "action": -1.5550875663757324}
{"mode": "train", "epochs": 13, "timestep": 24222, "ep_reward": 168.90333557128906, "reward": 0.47600144147872925, "action": -0.9611091613769531}
{"mode": "train", "epochs": 13, "timestep": 24223, "ep_reward": 169.47933959960938, "reward": 0.5760096907615662, "action": -1.4898929595947266}
{"mode": "train", "epochs": 13, "timestep": 24224, "ep_reward": 170.1409912109375, "reward": 0.6616494655609131, "action": -0.9748605489730835}
{"mode": "train", "epochs": 13, "timestep": 24225, "ep_reward": 170.87977600097656, "reward": 0.7387914657592773, "action": -0.2805817127227783}
{"mode": "train", "epochs": 13, "timestep": 24226, "ep_reward": 171.68470764160156, "reward": 0.8049331307411194, "action": -2.0}
{"mode": "train", "epochs": 13, "timestep": 24227, "ep_reward": 172.5327911376953, "reward": 0.8480782508850098, "action": -0.5103829503059387}
{"mode": "train", "epochs": 13, "timestep": 24228, "ep_reward": 173.42019653320312, "reward": 0.887406587600708, "action": -1.629354476928711}
{"mode": "train", "epochs": 13, "timestep": 24229, "ep_reward": 174.3328857421875, "reward": 0.9126940369606018, "action": -0.3352222442626953}
{"mode": "train", "epochs": 13, "timestep": 24230, "ep_reward": 175.2669219970703, "reward": 0.9340291023254395, "action": -0.5811452269554138}
{"mode": "train", "epochs": 13, "timestep": 24231, "ep_reward": 176.21388244628906, "reward": 0.9469572305679321, "action": -1.2820929288864136}
{"mode": "train", "epochs": 13, "timestep": 24232, "ep_reward": 177.16761779785156, "reward": 0.9537315964698792, "action": -0.7301177978515625}
{"mode": "train", "epochs": 13, "timestep": 24233, "ep_reward": 178.1239776611328, "reward": 0.9563652276992798, "action": -0.49093323945999146}
{"mode": "train", "epochs": 13, "timestep": 24234, "ep_reward": 179.0777587890625, "reward": 0.9537851810455322, "action": -0.41140228509902954}
{"mode": "train", "epochs": 13, "timestep": 24235, "ep_reward": 180.02281188964844, "reward": 0.9450529217720032, "action": -1.865199327468872}
{"mode": "train", "epochs": 13, "timestep": 24236, "ep_reward": 180.95733642578125, "reward": 0.9345297813415527, "action": -1.4709392786026}
{"mode": "train", "epochs": 13, "timestep": 24237, "ep_reward": 181.8756561279297, "reward": 0.918326199054718, "action": -0.6646846532821655}
{"mode": "train", "epochs": 13, "timestep": 24238, "ep_reward": 182.76731872558594, "reward": 0.8916608691215515, "action": -0.6814423203468323}
{"mode": "train", "epochs": 13, "timestep": 24239, "ep_reward": 183.6215362548828, "reward": 0.854224443435669, "action": -0.8489367961883545}
