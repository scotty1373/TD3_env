{"mode": "train", "epochs": 1, "timestep": 1, "ep_reward": 0.8965356945991516, "reward": 0.8965356945991516, "action": 0.5123792886734009}
{"mode": "train", "epochs": 1, "timestep": 2, "ep_reward": 1.7952466011047363, "reward": 0.8987109661102295, "action": 0.934807300567627}
{"mode": "train", "epochs": 1, "timestep": 3, "ep_reward": 2.686962127685547, "reward": 0.891715407371521, "action": 0.07997605949640274}
{"mode": "train", "epochs": 1, "timestep": 4, "ep_reward": 3.559251070022583, "reward": 0.8722889423370361, "action": -0.5290560126304626}
{"mode": "train", "epochs": 1, "timestep": 5, "ep_reward": 4.395209312438965, "reward": 0.8359584212303162, "action": -0.5766952037811279}
{"mode": "train", "epochs": 1, "timestep": 6, "ep_reward": 5.1761322021484375, "reward": 0.7809229493141174, "action": 0.08921517431735992}
{"mode": "train", "epochs": 1, "timestep": 7, "ep_reward": 5.886922836303711, "reward": 0.7107908725738525, "action": 0.21512001752853394}
{"mode": "train", "epochs": 1, "timestep": 8, "ep_reward": 6.509915351867676, "reward": 0.6229923367500305, "action": -0.6704347729682922}
{"mode": "train", "epochs": 1, "timestep": 9, "ep_reward": 7.017132759094238, "reward": 0.507217526435852, "action": 0.7405452132225037}
{"mode": "train", "epochs": 1, "timestep": 10, "ep_reward": 7.408496856689453, "reward": 0.39136433601379395, "action": 0.005559965968132019}
{"mode": "train", "epochs": 1, "timestep": 11, "ep_reward": 7.667863368988037, "reward": 0.25936657190322876, "action": -0.00715811550617218}
{"mode": "train", "epochs": 1, "timestep": 12, "ep_reward": 7.822567939758301, "reward": 0.15470445156097412, "action": -0.5257925391197205}
{"mode": "train", "epochs": 1, "timestep": 13, "ep_reward": 8.08900260925293, "reward": 0.2664344310760498, "action": -0.6990881562232971}
{"mode": "train", "epochs": 1, "timestep": 14, "ep_reward": 8.468327522277832, "reward": 0.379325270652771, "action": -0.9570227265357971}
{"mode": "train", "epochs": 1, "timestep": 15, "ep_reward": 8.956219673156738, "reward": 0.4878924489021301, "action": -0.00990845263004303}
{"mode": "train", "epochs": 1, "timestep": 16, "ep_reward": 9.553144454956055, "reward": 0.5969248414039612, "action": -0.005185708403587341}
{"mode": "train", "epochs": 1, "timestep": 17, "ep_reward": 10.243873596191406, "reward": 0.6907287836074829, "action": 0.5239771604537964}
{"mode": "train", "epochs": 1, "timestep": 18, "ep_reward": 11.013899803161621, "reward": 0.7700263857841492, "action": 0.37554100155830383}
{"mode": "train", "epochs": 1, "timestep": 19, "ep_reward": 11.843092918395996, "reward": 0.829193115234375, "action": 0.6660847067832947}
{"mode": "train", "epochs": 1, "timestep": 20, "ep_reward": 12.715020179748535, "reward": 0.8719271421432495, "action": 0.16866791248321533}
{"mode": "train", "epochs": 1, "timestep": 21, "ep_reward": 13.612597465515137, "reward": 0.8975771069526672, "action": -0.4096266031265259}
{"mode": "train", "epochs": 1, "timestep": 22, "ep_reward": 14.522961616516113, "reward": 0.9103644490242004, "action": 0.40882787108421326}
{"mode": "train", "epochs": 1, "timestep": 23, "ep_reward": 15.43529987335205, "reward": 0.9123383164405823, "action": -0.33145469427108765}
{"mode": "train", "epochs": 1, "timestep": 24, "ep_reward": 16.338729858398438, "reward": 0.9034292101860046, "action": 0.06053139269351959}
{"mode": "train", "epochs": 1, "timestep": 25, "ep_reward": 17.220962524414062, "reward": 0.8822327852249146, "action": 0.22934462130069733}
{"mode": "train", "epochs": 1, "timestep": 26, "ep_reward": 18.067285537719727, "reward": 0.8463231325149536, "action": 0.040345728397369385}
{"mode": "train", "epochs": 1, "timestep": 27, "ep_reward": 18.862220764160156, "reward": 0.7949360609054565, "action": 0.806430459022522}
{"mode": "train", "epochs": 1, "timestep": 28, "ep_reward": 19.580904006958008, "reward": 0.718683660030365, "action": -0.4705202877521515}
{"mode": "train", "epochs": 1, "timestep": 29, "ep_reward": 20.212663650512695, "reward": 0.6317593455314636, "action": 1.1840602159500122}
{"mode": "train", "epochs": 1, "timestep": 30, "ep_reward": 20.720502853393555, "reward": 0.5078399181365967, "action": 0.44607213139533997}
{"mode": "train", "epochs": 1, "timestep": 31, "ep_reward": 21.091825485229492, "reward": 0.3713219165802002, "action": -0.04653191566467285}
{"mode": "train", "epochs": 1, "timestep": 32, "ep_reward": 21.3218936920166, "reward": 0.23006904125213623, "action": -0.4261595606803894}
{"mode": "train", "epochs": 1, "timestep": 33, "ep_reward": 21.452014923095703, "reward": 0.1301206350326538, "action": 1.1580674648284912}
{"mode": "train", "epochs": 1, "timestep": 34, "ep_reward": 21.69365882873535, "reward": 0.24164366722106934, "action": 0.4506552517414093}
{"mode": "train", "epochs": 1, "timestep": 35, "ep_reward": 22.05849838256836, "reward": 0.3648396134376526, "action": 0.8339992165565491}
{"mode": "train", "epochs": 1, "timestep": 36, "ep_reward": 22.539691925048828, "reward": 0.48119300603866577, "action": 0.12960201501846313}
{"mode": "train", "epochs": 1, "timestep": 37, "ep_reward": 23.134693145751953, "reward": 0.5950002670288086, "action": -0.45242658257484436}
{"mode": "train", "epochs": 1, "timestep": 38, "ep_reward": 23.83156394958496, "reward": 0.6968704462051392, "action": 1.2491507530212402}
{"mode": "train", "epochs": 1, "timestep": 39, "ep_reward": 24.59926414489746, "reward": 0.7676994800567627, "action": -0.0679018497467041}
{"mode": "train", "epochs": 1, "timestep": 40, "ep_reward": 25.43083381652832, "reward": 0.8315696716308594, "action": 0.7930529117584229}
{"mode": "train", "epochs": 1, "timestep": 41, "ep_reward": 26.30609893798828, "reward": 0.8752649426460266, "action": 0.676323413848877}
{"mode": "train", "epochs": 1, "timestep": 42, "ep_reward": 27.21413230895996, "reward": 0.9080336093902588, "action": 0.020224690437316895}
{"mode": "train", "epochs": 1, "timestep": 43, "ep_reward": 28.147022247314453, "reward": 0.932889461517334, "action": 0.9554581642150879}
{"mode": "train", "epochs": 1, "timestep": 44, "ep_reward": 29.0944766998291, "reward": 0.9474539160728455, "action": -0.09822879731655121}
{"mode": "train", "epochs": 1, "timestep": 45, "ep_reward": 30.051895141601562, "reward": 0.9574186205863953, "action": 0.2338334321975708}
{"mode": "train", "epochs": 1, "timestep": 46, "ep_reward": 31.012523651123047, "reward": 0.9606276750564575, "action": -0.7741339206695557}
{"mode": "train", "epochs": 1, "timestep": 47, "ep_reward": 31.969226837158203, "reward": 0.9567022323608398, "action": 0.025466693565249443}
{"mode": "train", "epochs": 1, "timestep": 48, "ep_reward": 32.915157318115234, "reward": 0.9459306001663208, "action": -0.46768271923065186}
{"mode": "train", "epochs": 1, "timestep": 49, "ep_reward": 33.840476989746094, "reward": 0.9253213405609131, "action": 0.5792929530143738}
{"mode": "train", "epochs": 1, "timestep": 50, "ep_reward": 34.73906707763672, "reward": 0.8985916376113892, "action": 0.07703720033168793}
{"mode": "train", "epochs": 1, "timestep": 51, "ep_reward": 35.59693908691406, "reward": 0.8578733205795288, "action": 0.5650599598884583}
{"mode": "train", "epochs": 1, "timestep": 52, "ep_reward": 36.40233612060547, "reward": 0.8053988218307495, "action": -0.5818130970001221}
{"mode": "train", "epochs": 1, "timestep": 53, "ep_reward": 37.12760543823242, "reward": 0.7252697944641113, "action": -1.6481025218963623}
{"mode": "train", "epochs": 1, "timestep": 54, "ep_reward": 37.736080169677734, "reward": 0.6084754467010498, "action": -0.5474722385406494}
{"mode": "train", "epochs": 1, "timestep": 55, "ep_reward": 38.210872650146484, "reward": 0.4747927784919739, "action": -0.5069003105163574}
{"mode": "train", "epochs": 1, "timestep": 56, "ep_reward": 38.53038024902344, "reward": 0.31950730085372925, "action": -0.08211631327867508}
{"mode": "train", "epochs": 1, "timestep": 57, "ep_reward": 38.68793487548828, "reward": 0.1575552225112915, "action": 0.2739017605781555}
{"mode": "train", "epochs": 1, "timestep": 58, "ep_reward": 38.764930725097656, "reward": 0.07699543237686157, "action": 0.10668295621871948}
{"mode": "train", "epochs": 1, "timestep": 59, "ep_reward": 38.98107147216797, "reward": 0.21614080667495728, "action": -0.016682907938957214}
{"mode": "train", "epochs": 1, "timestep": 60, "ep_reward": 39.336334228515625, "reward": 0.3552646040916443, "action": -0.8059743642807007}
{"mode": "train", "epochs": 1, "timestep": 61, "ep_reward": 39.81642150878906, "reward": 0.4800879955291748, "action": 0.04727722704410553}
{"mode": "train", "epochs": 1, "timestep": 62, "ep_reward": 40.41823196411133, "reward": 0.6018102169036865, "action": -0.10855042189359665}
{"mode": "train", "epochs": 1, "timestep": 63, "ep_reward": 41.1209831237793, "reward": 0.7027500867843628, "action": -0.2805289030075073}
{"mode": "train", "epochs": 1, "timestep": 64, "ep_reward": 41.90311813354492, "reward": 0.7821342349052429, "action": 0.18072567880153656}
{"mode": "train", "epochs": 1, "timestep": 65, "ep_reward": 42.7490234375, "reward": 0.8459072113037109, "action": -0.20583386719226837}
{"mode": "train", "epochs": 1, "timestep": 66, "ep_reward": 43.63985061645508, "reward": 0.8908288478851318, "action": 0.5299288034439087}
{"mode": "train", "epochs": 1, "timestep": 67, "ep_reward": 44.56615447998047, "reward": 0.9263026118278503, "action": 0.06081646680831909}
{"mode": "train", "epochs": 1, "timestep": 68, "ep_reward": 45.515380859375, "reward": 0.949226975440979, "action": -0.160305917263031}
{"mode": "train", "epochs": 1, "timestep": 69, "ep_reward": 46.479736328125, "reward": 0.9643544554710388, "action": 0.35766884684562683}
{"mode": "train", "epochs": 1, "timestep": 70, "ep_reward": 47.4549446105957, "reward": 0.9752098321914673, "action": -0.6565843224525452}
{"mode": "train", "epochs": 1, "timestep": 71, "ep_reward": 48.435611724853516, "reward": 0.9806680083274841, "action": 0.008069083094596863}
{"mode": "train", "epochs": 1, "timestep": 72, "ep_reward": 49.41974639892578, "reward": 0.9841355681419373, "action": 0.4933507442474365}
{"mode": "train", "epochs": 1, "timestep": 73, "ep_reward": 50.40431594848633, "reward": 0.9845709204673767, "action": -0.2838015854358673}
{"mode": "train", "epochs": 1, "timestep": 74, "ep_reward": 51.38666915893555, "reward": 0.9823541045188904, "action": -0.2586258053779602}
{"mode": "train", "epochs": 1, "timestep": 75, "ep_reward": 52.36418533325195, "reward": 0.9775161743164062, "action": 0.9752158522605896}
{"mode": "train", "epochs": 1, "timestep": 76, "ep_reward": 53.33036422729492, "reward": 0.9661771655082703, "action": 0.04836566001176834}
{"mode": "train", "epochs": 1, "timestep": 77, "ep_reward": 54.281253814697266, "reward": 0.9508912563323975, "action": -0.596400797367096}
{"mode": "train", "epochs": 1, "timestep": 78, "ep_reward": 55.21281814575195, "reward": 0.9315630793571472, "action": -0.12783154845237732}
{"mode": "train", "epochs": 1, "timestep": 79, "ep_reward": 56.11457061767578, "reward": 0.901752769947052, "action": 0.3607511818408966}
{"mode": "train", "epochs": 1, "timestep": 80, "ep_reward": 56.97095489501953, "reward": 0.8563848733901978, "action": 0.663769006729126}
{"mode": "train", "epochs": 1, "timestep": 81, "ep_reward": 57.76152801513672, "reward": 0.7905741333961487, "action": 0.24268630146980286}
{"mode": "train", "epochs": 1, "timestep": 82, "ep_reward": 58.46698760986328, "reward": 0.7054588198661804, "action": 0.5513480305671692}
{"mode": "train", "epochs": 1, "timestep": 83, "ep_reward": 59.058380126953125, "reward": 0.5913942456245422, "action": 0.6729506254196167}
{"mode": "train", "epochs": 1, "timestep": 84, "ep_reward": 59.5065803527832, "reward": 0.448200523853302, "action": 0.8075435161590576}
{"mode": "train", "epochs": 1, "timestep": 85, "ep_reward": 59.785369873046875, "reward": 0.2787896990776062, "action": 1.238743543624878}
{"mode": "train", "epochs": 1, "timestep": 86, "ep_reward": 59.872283935546875, "reward": 0.08691465854644775, "action": 0.5061771273612976}
{"mode": "train", "epochs": 1, "timestep": 87, "ep_reward": 59.91838073730469, "reward": 0.0460963249206543, "action": 1.2964529991149902}
{"mode": "train", "epochs": 1, "timestep": 88, "ep_reward": 60.103416442871094, "reward": 0.1850343942642212, "action": 0.18958935141563416}
{"mode": "train", "epochs": 1, "timestep": 89, "ep_reward": 60.43852615356445, "reward": 0.33510977029800415, "action": 1.2691388130187988}
{"mode": "train", "epochs": 1, "timestep": 90, "ep_reward": 60.90325164794922, "reward": 0.4647267460823059, "action": 0.7966080904006958}
{"mode": "train", "epochs": 1, "timestep": 91, "ep_reward": 61.4891242980957, "reward": 0.5858741998672485, "action": 0.3113412857055664}
{"mode": "train", "epochs": 1, "timestep": 92, "ep_reward": 62.17982864379883, "reward": 0.6907061338424683, "action": 1.1995365619659424}
{"mode": "train", "epochs": 1, "timestep": 93, "ep_reward": 62.94356918334961, "reward": 0.7637407779693604, "action": -0.04531663656234741}
{"mode": "train", "epochs": 1, "timestep": 94, "ep_reward": 63.77064895629883, "reward": 0.827078104019165, "action": 0.27509599924087524}
{"mode": "train", "epochs": 1, "timestep": 95, "ep_reward": 64.63893127441406, "reward": 0.8682807683944702, "action": 0.8174746036529541}
{"mode": "train", "epochs": 1, "timestep": 96, "ep_reward": 65.52904510498047, "reward": 0.8901160359382629, "action": -0.29843392968177795}
{"mode": "train", "epochs": 1, "timestep": 97, "ep_reward": 66.43614959716797, "reward": 0.9071072936058044, "action": -0.04348587989807129}
{"mode": "train", "epochs": 1, "timestep": 98, "ep_reward": 67.34659576416016, "reward": 0.9104465842247009, "action": 0.13083003461360931}
{"mode": "train", "epochs": 1, "timestep": 99, "ep_reward": 68.2477798461914, "reward": 0.9011875987052917, "action": 0.0988893061876297}
{"mode": "train", "epochs": 1, "timestep": 100, "ep_reward": 69.12723541259766, "reward": 0.8794586062431335, "action": 1.0108243227005005}
{"mode": "train", "epochs": 1, "timestep": 101, "ep_reward": 69.96134185791016, "reward": 0.8341065645217896, "action": 0.10056602954864502}
{"mode": "train", "epochs": 1, "timestep": 102, "ep_reward": 70.73673248291016, "reward": 0.7753939032554626, "action": -0.14678964018821716}
{"mode": "train", "epochs": 1, "timestep": 103, "ep_reward": 71.4307861328125, "reward": 0.6940571665763855, "action": 1.3297450542449951}
{"mode": "train", "epochs": 1, "timestep": 104, "ep_reward": 71.99449920654297, "reward": 0.5637115240097046, "action": 0.38175612688064575}
{"mode": "train", "epochs": 1, "timestep": 105, "ep_reward": 72.40386199951172, "reward": 0.409366250038147, "action": -0.39298760890960693}
{"mode": "train", "epochs": 1, "timestep": 106, "ep_reward": 72.65116882324219, "reward": 0.24730974435806274, "action": 0.5778723359107971}
{"mode": "train", "epochs": 1, "timestep": 107, "ep_reward": 72.76964569091797, "reward": 0.1184806227684021, "action": 1.117276668548584}
{"mode": "train", "epochs": 1, "timestep": 108, "ep_reward": 72.7660140991211, "reward": -0.003633856773376465, "action": 0.2318236529827118}
{"mode": "train", "epochs": 1, "timestep": 109, "ep_reward": 72.90772247314453, "reward": 0.14170581102371216, "action": 0.9043042659759521}
{"mode": "train", "epochs": 1, "timestep": 110, "ep_reward": 73.19002532958984, "reward": 0.2823027968406677, "action": -0.32216376066207886}
{"mode": "train", "epochs": 1, "timestep": 111, "ep_reward": 73.62503051757812, "reward": 0.4350033402442932, "action": 0.8537472486495972}
{"mode": "train", "epochs": 1, "timestep": 112, "ep_reward": 74.18367004394531, "reward": 0.5586404800415039, "action": 0.015589296817779541}
{"mode": "train", "epochs": 1, "timestep": 113, "ep_reward": 74.85536193847656, "reward": 0.6716945767402649, "action": 0.7452754378318787}
{"mode": "train", "epochs": 1, "timestep": 114, "ep_reward": 75.60971069335938, "reward": 0.7543475031852722, "action": 0.7653231024742126}
{"mode": "train", "epochs": 1, "timestep": 115, "ep_reward": 76.42604064941406, "reward": 0.8163315653800964, "action": -0.5327873229980469}
{"mode": "train", "epochs": 1, "timestep": 116, "ep_reward": 77.29590606689453, "reward": 0.8698671460151672, "action": 1.073192834854126}
{"mode": "train", "epochs": 1, "timestep": 117, "ep_reward": 78.19208526611328, "reward": 0.8961808085441589, "action": 0.07780526578426361}
{"mode": "train", "epochs": 1, "timestep": 118, "ep_reward": 79.10958099365234, "reward": 0.9174973964691162, "action": -0.2753918468952179}
{"mode": "train", "epochs": 1, "timestep": 119, "ep_reward": 80.04025268554688, "reward": 0.9306711554527283, "action": 0.6512113213539124}
{"mode": "train", "epochs": 1, "timestep": 120, "ep_reward": 80.9695053100586, "reward": 0.9292490482330322, "action": 0.0027461349964141846}
{"mode": "train", "epochs": 1, "timestep": 121, "ep_reward": 81.892333984375, "reward": 0.9228296279907227, "action": 1.4629415273666382}
{"mode": "train", "epochs": 1, "timestep": 122, "ep_reward": 82.78843688964844, "reward": 0.8961034417152405, "action": 0.12032963335514069}
{"mode": "train", "epochs": 1, "timestep": 123, "ep_reward": 83.65315246582031, "reward": 0.8647156953811646, "action": 0.23940441012382507}
{"mode": "train", "epochs": 1, "timestep": 124, "ep_reward": 84.46825408935547, "reward": 0.815098226070404, "action": 0.5198986530303955}
{"mode": "train", "epochs": 1, "timestep": 125, "ep_reward": 85.20828247070312, "reward": 0.7400309443473816, "action": 0.8265074491500854}
{"mode": "train", "epochs": 1, "timestep": 126, "ep_reward": 85.84037017822266, "reward": 0.6320871114730835, "action": 0.7220012545585632}
{"mode": "train", "epochs": 1, "timestep": 127, "ep_reward": 86.33113861083984, "reward": 0.4907659888267517, "action": 1.226025938987732}
{"mode": "train", "epochs": 1, "timestep": 128, "ep_reward": 86.63800048828125, "reward": 0.30686062574386597, "action": 1.5181211233139038}
{"mode": "train", "epochs": 1, "timestep": 129, "ep_reward": 86.81436157226562, "reward": 0.17635983228683472, "action": 0.6647891402244568}
{"mode": "train", "epochs": 1, "timestep": 130, "ep_reward": 86.85057067871094, "reward": 0.03621053695678711, "action": 0.30854859948158264}
{"mode": "train", "epochs": 1, "timestep": 131, "ep_reward": 86.93223571777344, "reward": 0.08166569471359253, "action": 0.5477808713912964}
{"mode": "train", "epochs": 1, "timestep": 132, "ep_reward": 87.15728759765625, "reward": 0.22505342960357666, "action": 0.07972049713134766}
{"mode": "train", "epochs": 1, "timestep": 133, "ep_reward": 87.53192901611328, "reward": 0.37463831901550293, "action": 1.0342116355895996}
{"mode": "train", "epochs": 1, "timestep": 134, "ep_reward": 88.0347671508789, "reward": 0.5028412342071533, "action": 0.37754207849502563}
{"mode": "train", "epochs": 1, "timestep": 135, "ep_reward": 88.65687561035156, "reward": 0.6221073865890503, "action": -0.29928770661354065}
{"mode": "train", "epochs": 1, "timestep": 136, "ep_reward": 89.3821029663086, "reward": 0.7252309322357178, "action": 0.2224499136209488}
{"mode": "train", "epochs": 1, "timestep": 137, "ep_reward": 90.18164825439453, "reward": 0.7995449304580688, "action": 1.0482885837554932}
{"mode": "train", "epochs": 1, "timestep": 138, "ep_reward": 91.02958679199219, "reward": 0.8479369878768921, "action": 0.35352662205696106}
{"mode": "train", "epochs": 1, "timestep": 139, "ep_reward": 91.91563415527344, "reward": 0.8860493302345276, "action": 0.10711853206157684}
{"mode": "train", "epochs": 1, "timestep": 140, "ep_reward": 92.82807159423828, "reward": 0.9124389290809631, "action": 0.5695133209228516}
{"mode": "train", "epochs": 1, "timestep": 141, "ep_reward": 93.75321197509766, "reward": 0.9251415729522705, "action": 0.2548506259918213}
{"mode": "train", "epochs": 1, "timestep": 142, "ep_reward": 94.68386840820312, "reward": 0.9306569695472717, "action": 0.624944806098938}
{"mode": "train", "epochs": 1, "timestep": 143, "ep_reward": 95.60891723632812, "reward": 0.9250515103340149, "action": 0.5656309127807617}
{"mode": "train", "epochs": 1, "timestep": 144, "ep_reward": 96.51885223388672, "reward": 0.9099386930465698, "action": 0.20923393964767456}
{"mode": "train", "epochs": 1, "timestep": 145, "ep_reward": 97.40422821044922, "reward": 0.8853748440742493, "action": -0.3922881782054901}
{"mode": "train", "epochs": 1, "timestep": 146, "ep_reward": 98.25544738769531, "reward": 0.8512153625488281, "action": 0.15413452684879303}
{"mode": "train", "epochs": 1, "timestep": 147, "ep_reward": 99.04995727539062, "reward": 0.7945106029510498, "action": 0.47431328892707825}
{"mode": "train", "epochs": 1, "timestep": 148, "ep_reward": 99.76045989990234, "reward": 0.7105060815811157, "action": -0.9069982767105103}
{"mode": "train", "epochs": 1, "timestep": 149, "ep_reward": 100.37503814697266, "reward": 0.6145813465118408, "action": 0.48375752568244934}
{"mode": "train", "epochs": 1, "timestep": 150, "ep_reward": 100.8476333618164, "reward": 0.4725915193557739, "action": 1.071531891822815}
{"mode": "train", "epochs": 1, "timestep": 151, "ep_reward": 101.13853454589844, "reward": 0.29090332984924316, "action": -0.26225119829177856}
{"mode": "train", "epochs": 1, "timestep": 152, "ep_reward": 101.28025817871094, "reward": 0.1417231559753418, "action": 0.006822526454925537}
{"mode": "train", "epochs": 1, "timestep": 153, "ep_reward": 101.27651977539062, "reward": -0.003741741180419922, "action": 1.0785714387893677}
{"mode": "train", "epochs": 1, "timestep": 154, "ep_reward": 101.39509582519531, "reward": 0.11857825517654419, "action": 0.483401894569397}
{"mode": "train", "epochs": 1, "timestep": 155, "ep_reward": 101.65885925292969, "reward": 0.2637597322463989, "action": 0.901572585105896}
{"mode": "train", "epochs": 1, "timestep": 156, "ep_reward": 102.06082916259766, "reward": 0.4019666314125061, "action": 0.6865403652191162}
{"mode": "train", "epochs": 1, "timestep": 157, "ep_reward": 102.59295654296875, "reward": 0.5321290493011475, "action": 0.49290525913238525}
{"mode": "train", "epochs": 1, "timestep": 158, "ep_reward": 103.23841094970703, "reward": 0.6454510688781738, "action": 0.11771506071090698}
{"mode": "train", "epochs": 1, "timestep": 159, "ep_reward": 103.97769165039062, "reward": 0.7392824292182922, "action": 1.3436123132705688}
{"mode": "train", "epochs": 1, "timestep": 160, "ep_reward": 104.7774887084961, "reward": 0.7998000383377075, "action": 0.38908907771110535}
{"mode": "train", "epochs": 1, "timestep": 161, "ep_reward": 105.62731170654297, "reward": 0.8498229384422302, "action": 1.2621514797210693}
{"mode": "train", "epochs": 1, "timestep": 162, "ep_reward": 106.5040283203125, "reward": 0.8767194747924805, "action": 0.6319025754928589}
{"mode": "train", "epochs": 1, "timestep": 163, "ep_reward": 107.39864349365234, "reward": 0.8946167230606079, "action": 1.001577615737915}
{"mode": "train", "epochs": 1, "timestep": 164, "ep_reward": 108.29568481445312, "reward": 0.8970438838005066, "action": 0.4921254813671112}
{"mode": "train", "epochs": 1, "timestep": 165, "ep_reward": 109.18604278564453, "reward": 0.8903608322143555, "action": -0.019369304180145264}
{"mode": "train", "epochs": 1, "timestep": 166, "ep_reward": 110.05977630615234, "reward": 0.8737362027168274, "action": -0.26120737195014954}
{"mode": "train", "epochs": 1, "timestep": 167, "ep_reward": 110.9032211303711, "reward": 0.8434455394744873, "action": 0.12533345818519592}
{"mode": "train", "epochs": 1, "timestep": 168, "ep_reward": 111.69371795654297, "reward": 0.7904955744743347, "action": 0.246441051363945}
{"mode": "train", "epochs": 1, "timestep": 169, "ep_reward": 112.40530395507812, "reward": 0.7115849256515503, "action": 0.6322039365768433}
{"mode": "train", "epochs": 1, "timestep": 170, "ep_reward": 113.00269317626953, "reward": 0.5973899960517883, "action": -0.2932199239730835}
{"mode": "train", "epochs": 1, "timestep": 171, "ep_reward": 113.46461486816406, "reward": 0.46192508935928345, "action": -0.48451513051986694}
{"mode": "train", "epochs": 1, "timestep": 172, "ep_reward": 113.76573944091797, "reward": 0.30112242698669434, "action": 0.5240128040313721}
{"mode": "train", "epochs": 1, "timestep": 173, "ep_reward": 113.92410278320312, "reward": 0.15836101770401, "action": 1.2593705654144287}
{"mode": "train", "epochs": 1, "timestep": 174, "ep_reward": 113.93964385986328, "reward": 0.015543162822723389, "action": 0.5683426856994629}
{"mode": "train", "epochs": 1, "timestep": 175, "ep_reward": 114.04076385498047, "reward": 0.10111910104751587, "action": 0.26530691981315613}
{"mode": "train", "epochs": 1, "timestep": 176, "ep_reward": 114.28932189941406, "reward": 0.24855506420135498, "action": 0.4016570746898651}
{"mode": "train", "epochs": 1, "timestep": 177, "ep_reward": 114.68218994140625, "reward": 0.39286547899246216, "action": 0.00038743019104003906}
{"mode": "train", "epochs": 1, "timestep": 178, "ep_reward": 115.212890625, "reward": 0.53070068359375, "action": 0.643675684928894}
{"mode": "train", "epochs": 1, "timestep": 179, "ep_reward": 115.8548812866211, "reward": 0.6419885754585266, "action": 1.6197197437286377}
{"mode": "train", "epochs": 1, "timestep": 180, "ep_reward": 116.57823181152344, "reward": 0.7233508229255676, "action": 0.32915419340133667}
{"mode": "train", "epochs": 1, "timestep": 181, "ep_reward": 117.37491607666016, "reward": 0.7966864109039307, "action": -0.10110589861869812}
{"mode": "train", "epochs": 1, "timestep": 182, "ep_reward": 118.22804260253906, "reward": 0.8531266450881958, "action": 0.003911912441253662}
{"mode": "train", "epochs": 1, "timestep": 183, "ep_reward": 119.11953735351562, "reward": 0.8914968967437744, "action": 0.9677141308784485}
{"mode": "train", "epochs": 1, "timestep": 184, "ep_reward": 120.02993774414062, "reward": 0.9103989005088806, "action": 0.7837648391723633}
{"mode": "train", "epochs": 1, "timestep": 185, "ep_reward": 120.95012664794922, "reward": 0.9201910495758057, "action": -0.029795020818710327}
{"mode": "train", "epochs": 1, "timestep": 186, "ep_reward": 121.87567901611328, "reward": 0.9255524277687073, "action": -0.07081112265586853}
{"mode": "train", "epochs": 1, "timestep": 187, "ep_reward": 122.7974853515625, "reward": 0.9218032360076904, "action": 0.11680534482002258}
{"mode": "train", "epochs": 1, "timestep": 188, "ep_reward": 123.70431518554688, "reward": 0.9068275690078735, "action": -0.41046014428138733}
{"mode": "train", "epochs": 1, "timestep": 189, "ep_reward": 124.58829498291016, "reward": 0.8839824795722961, "action": 0.6205788850784302}
{"mode": "train", "epochs": 1, "timestep": 190, "ep_reward": 125.42655181884766, "reward": 0.8382535576820374, "action": -0.10072517395019531}
{"mode": "train", "epochs": 1, "timestep": 191, "ep_reward": 126.20523071289062, "reward": 0.778681218624115, "action": 0.21334636211395264}
{"mode": "train", "epochs": 1, "timestep": 192, "ep_reward": 126.89678192138672, "reward": 0.691552996635437, "action": 0.6615091562271118}
{"mode": "train", "epochs": 1, "timestep": 193, "ep_reward": 127.46564483642578, "reward": 0.5688661932945251, "action": 0.34119468927383423}
{"mode": "train", "epochs": 1, "timestep": 194, "ep_reward": 127.88291931152344, "reward": 0.41727203130722046, "action": 1.688615322113037}
{"mode": "train", "epochs": 1, "timestep": 195, "ep_reward": 128.11619567871094, "reward": 0.23327100276947021, "action": 0.9939046502113342}
{"mode": "train", "epochs": 1, "timestep": 196, "ep_reward": 128.21841430664062, "reward": 0.1022147536277771, "action": 0.43817129731178284}
{"mode": "train", "epochs": 1, "timestep": 197, "ep_reward": 128.23275756835938, "reward": 0.014343798160552979, "action": 0.6218630075454712}
{"mode": "train", "epochs": 1, "timestep": 198, "ep_reward": 128.3901824951172, "reward": 0.15742003917694092, "action": -0.1245221495628357}
{"mode": "train", "epochs": 1, "timestep": 199, "ep_reward": 128.70115661621094, "reward": 0.3109813332557678, "action": 0.4156954884529114}
{"mode": "train", "epochs": 1, "timestep": 200, "ep_reward": 129.1524658203125, "reward": 0.4513084292411804, "action": 1.083716869354248}
{"mode": "train", "epochs": 1, "timestep": 201, "ep_reward": 129.72262573242188, "reward": 0.5701572299003601, "action": 0.31493014097213745}
{"mode": "train", "epochs": 1, "timestep": 202, "ep_reward": 130.4007110595703, "reward": 0.6780868768692017, "action": 0.6173382997512817}
{"mode": "train", "epochs": 1, "timestep": 203, "ep_reward": 131.16099548339844, "reward": 0.7602777481079102, "action": 0.7842782735824585}
{"mode": "train", "epochs": 1, "timestep": 204, "ep_reward": 131.9813232421875, "reward": 0.8203272819519043, "action": 0.8859729170799255}
{"mode": "train", "epochs": 1, "timestep": 205, "ep_reward": 132.84329223632812, "reward": 0.8619755506515503, "action": 0.5531452894210815}
{"mode": "train", "epochs": 1, "timestep": 206, "ep_reward": 133.73455810546875, "reward": 0.8912653923034668, "action": -0.05516156554222107}
{"mode": "train", "epochs": 1, "timestep": 207, "ep_reward": 134.64651489257812, "reward": 0.9119547605514526, "action": 0.3877060115337372}
{"mode": "train", "epochs": 1, "timestep": 208, "ep_reward": 135.56507873535156, "reward": 0.918556809425354, "action": 0.7659285068511963}
{"mode": "train", "epochs": 1, "timestep": 209, "ep_reward": 136.47738647460938, "reward": 0.9123097062110901, "action": -0.396129310131073}
{"mode": "train", "epochs": 1, "timestep": 210, "ep_reward": 137.3805389404297, "reward": 0.9031550884246826, "action": 0.5869408845901489}
{"mode": "train", "epochs": 1, "timestep": 211, "ep_reward": 138.2547149658203, "reward": 0.8741798400878906, "action": 0.6489813327789307}
{"mode": "train", "epochs": 1, "timestep": 212, "ep_reward": 139.08230590820312, "reward": 0.8275972604751587, "action": -0.3830389082431793}
{"mode": "train", "epochs": 1, "timestep": 213, "ep_reward": 139.85177612304688, "reward": 0.7694689035415649, "action": 0.042177170515060425}
{"mode": "train", "epochs": 1, "timestep": 214, "ep_reward": 140.53404235839844, "reward": 0.6822614669799805, "action": 0.8564338684082031}
{"mode": "train", "epochs": 1, "timestep": 215, "ep_reward": 141.0882568359375, "reward": 0.554218053817749, "action": -0.014322638511657715}
{"mode": "train", "epochs": 1, "timestep": 216, "ep_reward": 141.4926300048828, "reward": 0.40437984466552734, "action": 0.10655727982521057}
{"mode": "train", "epochs": 1, "timestep": 217, "ep_reward": 141.72314453125, "reward": 0.23051095008850098, "action": 0.6225064992904663}
{"mode": "train", "epochs": 1, "timestep": 218, "ep_reward": 141.8220977783203, "reward": 0.09895890951156616, "action": 0.3694833219051361}
{"mode": "train", "epochs": 1, "timestep": 219, "ep_reward": 141.8399200439453, "reward": 0.017823398113250732, "action": 1.054939866065979}
{"mode": "train", "epochs": 1, "timestep": 220, "ep_reward": 142.00033569335938, "reward": 0.16041839122772217, "action": 1.0342587232589722}
{"mode": "train", "epochs": 1, "timestep": 221, "ep_reward": 142.30014038085938, "reward": 0.29980021715164185, "action": 0.43580663204193115}
{"mode": "train", "epochs": 1, "timestep": 222, "ep_reward": 142.7430419921875, "reward": 0.4429062604904175, "action": 0.16611483693122864}
{"mode": "train", "epochs": 1, "timestep": 223, "ep_reward": 143.31692504882812, "reward": 0.573879063129425, "action": 0.8918317556381226}
{"mode": "train", "epochs": 1, "timestep": 224, "ep_reward": 143.99237060546875, "reward": 0.6754521131515503, "action": -0.527623176574707}
{"mode": "train", "epochs": 1, "timestep": 225, "ep_reward": 144.76025390625, "reward": 0.7678908109664917, "action": 0.9760081171989441}
{"mode": "train", "epochs": 1, "timestep": 226, "ep_reward": 145.58456420898438, "reward": 0.8243165016174316, "action": 0.08301562070846558}
{"mode": "train", "epochs": 1, "timestep": 227, "ep_reward": 146.45480346679688, "reward": 0.8702439069747925, "action": -0.33406710624694824}
{"mode": "train", "epochs": 1, "timestep": 228, "ep_reward": 147.35838317871094, "reward": 0.9035749435424805, "action": 0.2571362853050232}
{"mode": "train", "epochs": 1, "timestep": 229, "ep_reward": 148.27899169921875, "reward": 0.9206079840660095, "action": 0.46348506212234497}
{"mode": "train", "epochs": 1, "timestep": 230, "ep_reward": 149.20550537109375, "reward": 0.926511824131012, "action": 0.6690288186073303}
{"mode": "train", "epochs": 1, "timestep": 231, "ep_reward": 150.12733459472656, "reward": 0.9218252301216125, "action": 0.6940369009971619}
{"mode": "train", "epochs": 1, "timestep": 232, "ep_reward": 151.03399658203125, "reward": 0.9066637754440308, "action": 0.03904455900192261}
{"mode": "train", "epochs": 1, "timestep": 233, "ep_reward": 151.9178466796875, "reward": 0.8838543891906738, "action": 1.1091376543045044}
{"mode": "train", "epochs": 1, "timestep": 234, "ep_reward": 152.75460815429688, "reward": 0.8367620706558228, "action": -0.9997656345367432}
{"mode": "train", "epochs": 1, "timestep": 235, "ep_reward": 153.543212890625, "reward": 0.7885971069335938, "action": -0.5775796175003052}
{"mode": "train", "epochs": 1, "timestep": 236, "ep_reward": 154.25823974609375, "reward": 0.7150243520736694, "action": 0.31312841176986694}
{"mode": "train", "epochs": 1, "timestep": 237, "ep_reward": 154.8626708984375, "reward": 0.6044368743896484, "action": -0.2926093339920044}
{"mode": "train", "epochs": 1, "timestep": 238, "ep_reward": 155.33377075195312, "reward": 0.4711058735847473, "action": 0.9268115162849426}
{"mode": "train", "epochs": 1, "timestep": 239, "ep_reward": 155.6254119873047, "reward": 0.2916361689567566, "action": 0.7564422488212585}
{"mode": "train", "epochs": 1, "timestep": 240, "ep_reward": 155.76551818847656, "reward": 0.1401117444038391, "action": 0.6497332453727722}
{"mode": "train", "epochs": 1, "timestep": 241, "ep_reward": 155.75999450683594, "reward": -0.005528926849365234, "action": 0.8013862371444702}
{"mode": "train", "epochs": 1, "timestep": 242, "ep_reward": 155.88018798828125, "reward": 0.12019556760787964, "action": 0.5709044933319092}
{"mode": "train", "epochs": 1, "timestep": 243, "ep_reward": 156.14454650878906, "reward": 0.2643646001815796, "action": 0.6462072730064392}
{"mode": "train", "epochs": 1, "timestep": 244, "ep_reward": 156.55030822753906, "reward": 0.40576642751693726, "action": 0.7406306266784668}
{"mode": "train", "epochs": 1, "timestep": 245, "ep_reward": 157.08502197265625, "reward": 0.5347206592559814, "action": 0.1788366436958313}
{"mode": "train", "epochs": 1, "timestep": 246, "ep_reward": 157.73568725585938, "reward": 0.6506624221801758, "action": 1.1650408506393433}
{"mode": "train", "epochs": 1, "timestep": 247, "ep_reward": 158.4696044921875, "reward": 0.7339162826538086, "action": 0.6738179922103882}
{"mode": "train", "epochs": 1, "timestep": 248, "ep_reward": 159.27053833007812, "reward": 0.8009340167045593, "action": -0.22125118970870972}
{"mode": "train", "epochs": 1, "timestep": 249, "ep_reward": 160.1260223388672, "reward": 0.8554872870445251, "action": 0.5747241973876953}
{"mode": "train", "epochs": 1, "timestep": 250, "ep_reward": 161.01290893554688, "reward": 0.8868830800056458, "action": 0.8021131753921509}
{"mode": "train", "epochs": 1, "timestep": 251, "ep_reward": 161.91651916503906, "reward": 0.9036111235618591, "action": -0.4767080843448639}
{"mode": "train", "epochs": 1, "timestep": 252, "ep_reward": 162.83419799804688, "reward": 0.9176819920539856, "action": 0.13344621658325195}
{"mode": "train", "epochs": 1, "timestep": 253, "ep_reward": 163.751220703125, "reward": 0.9170176982879639, "action": 0.5246036052703857}
{"mode": "train", "epochs": 1, "timestep": 254, "ep_reward": 164.6541748046875, "reward": 0.9029485583305359, "action": 0.07441702485084534}
{"mode": "train", "epochs": 1, "timestep": 255, "ep_reward": 165.53370666503906, "reward": 0.879531979560852, "action": 0.23594532907009125}
{"mode": "train", "epochs": 1, "timestep": 256, "ep_reward": 166.37303161621094, "reward": 0.839328408241272, "action": 0.48650163412094116}
{"mode": "train", "epochs": 1, "timestep": 257, "ep_reward": 167.14942932128906, "reward": 0.7763996720314026, "action": 0.7866061925888062}
{"mode": "train", "epochs": 1, "timestep": 258, "ep_reward": 167.83279418945312, "reward": 0.6833683252334595, "action": 0.12471827864646912}
{"mode": "train", "epochs": 1, "timestep": 259, "ep_reward": 168.39894104003906, "reward": 0.5661475658416748, "action": 0.24127429723739624}
{"mode": "train", "epochs": 1, "timestep": 260, "ep_reward": 168.8138885498047, "reward": 0.41494065523147583, "action": 0.6413587331771851}
{"mode": "train", "epochs": 1, "timestep": 261, "ep_reward": 169.05560302734375, "reward": 0.2417212724685669, "action": -0.0033202767372131348}
{"mode": "train", "epochs": 1, "timestep": 262, "ep_reward": 169.16758728027344, "reward": 0.11198210716247559, "action": 0.6435912251472473}
{"mode": "train", "epochs": 1, "timestep": 263, "ep_reward": 169.17124938964844, "reward": 0.003656744956970215, "action": -0.14455687999725342}
{"mode": "train", "epochs": 1, "timestep": 264, "ep_reward": 169.32440185546875, "reward": 0.15315377712249756, "action": 0.4957372546195984}
{"mode": "train", "epochs": 1, "timestep": 265, "ep_reward": 169.62222290039062, "reward": 0.2978265881538391, "action": -0.5356255173683167}
{"mode": "train", "epochs": 1, "timestep": 266, "ep_reward": 170.072509765625, "reward": 0.4502826929092407, "action": 0.9875813126564026}
{"mode": "train", "epochs": 1, "timestep": 267, "ep_reward": 170.64207458496094, "reward": 0.5695596933364868, "action": -0.36104026436805725}
{"mode": "train", "epochs": 1, "timestep": 268, "ep_reward": 171.3258819580078, "reward": 0.683810830116272, "action": -0.14126071333885193}
{"mode": "train", "epochs": 1, "timestep": 269, "ep_reward": 172.0975341796875, "reward": 0.7716479301452637, "action": 0.09532234072685242}
{"mode": "train", "epochs": 1, "timestep": 270, "ep_reward": 172.93350219726562, "reward": 0.8359618186950684, "action": -0.39285701513290405}
{"mode": "train", "epochs": 1, "timestep": 271, "ep_reward": 173.81919860839844, "reward": 0.8856976628303528, "action": 1.159130573272705}
{"mode": "train", "epochs": 1, "timestep": 272, "ep_reward": 174.73129272460938, "reward": 0.9120908975601196, "action": 1.3626883029937744}
{"mode": "train", "epochs": 1, "timestep": 273, "ep_reward": 175.65963745117188, "reward": 0.9283419847488403, "action": 0.6174095273017883}
{"mode": "train", "epochs": 1, "timestep": 274, "ep_reward": 176.60057067871094, "reward": 0.9409266710281372, "action": -0.06362846493721008}
{"mode": "train", "epochs": 1, "timestep": 275, "ep_reward": 177.55059814453125, "reward": 0.9500199556350708, "action": -0.03559026122093201}
{"mode": "train", "epochs": 1, "timestep": 276, "ep_reward": 178.50320434570312, "reward": 0.9526050090789795, "action": 0.48322874307632446}
{"mode": "train", "epochs": 1, "timestep": 277, "ep_reward": 179.4495849609375, "reward": 0.9463770985603333, "action": -0.6484560370445251}
{"mode": "train", "epochs": 1, "timestep": 278, "ep_reward": 180.38926696777344, "reward": 0.9396883249282837, "action": 0.31800276041030884}
{"mode": "train", "epochs": 1, "timestep": 279, "ep_reward": 181.30899047851562, "reward": 0.919727087020874, "action": 0.275350958108902}
{"mode": "train", "epochs": 1, "timestep": 280, "ep_reward": 182.1981201171875, "reward": 0.8891274929046631, "action": 0.01811501383781433}
{"mode": "train", "epochs": 1, "timestep": 281, "ep_reward": 183.044189453125, "reward": 0.8460661172866821, "action": 0.2540111541748047}
{"mode": "train", "epochs": 1, "timestep": 282, "ep_reward": 183.82650756835938, "reward": 0.7823151350021362, "action": 0.31126636266708374}
{"mode": "train", "epochs": 1, "timestep": 283, "ep_reward": 184.52017211914062, "reward": 0.6936718225479126, "action": 0.3778531849384308}
{"mode": "train", "epochs": 1, "timestep": 284, "ep_reward": 185.09547424316406, "reward": 0.5753077268600464, "action": -0.04733157157897949}
{"mode": "train", "epochs": 1, "timestep": 285, "ep_reward": 185.52816772460938, "reward": 0.4326965808868408, "action": 0.6092820763587952}
{"mode": "train", "epochs": 1, "timestep": 286, "ep_reward": 185.7830810546875, "reward": 0.254913330078125, "action": 0.5591864585876465}
{"mode": "train", "epochs": 1, "timestep": 287, "ep_reward": 185.87841796875, "reward": 0.0953415036201477, "action": 0.3280804455280304}
{"mode": "train", "epochs": 1, "timestep": 288, "ep_reward": 185.9001922607422, "reward": 0.021779417991638184, "action": -0.1233789324760437}
{"mode": "train", "epochs": 1, "timestep": 289, "ep_reward": 186.0716552734375, "reward": 0.17146509885787964, "action": 1.4703755378723145}
{"mode": "train", "epochs": 1, "timestep": 290, "ep_reward": 186.3756561279297, "reward": 0.30400288105010986, "action": -0.2151971459388733}
{"mode": "train", "epochs": 1, "timestep": 291, "ep_reward": 186.82977294921875, "reward": 0.45412319898605347, "action": 0.39868223667144775}
{"mode": "train", "epochs": 1, "timestep": 292, "ep_reward": 187.41009521484375, "reward": 0.5803154706954956, "action": 0.1587657332420349}
{"mode": "train", "epochs": 1, "timestep": 293, "ep_reward": 188.09786987304688, "reward": 0.6877731084823608, "action": 0.20539911091327667}
{"mode": "train", "epochs": 1, "timestep": 294, "ep_reward": 188.86932373046875, "reward": 0.7714571356773376, "action": -0.27684444189071655}
{"mode": "train", "epochs": 1, "timestep": 295, "ep_reward": 189.70680236816406, "reward": 0.8374857902526855, "action": 0.2540229260921478}
{"mode": "train", "epochs": 1, "timestep": 296, "ep_reward": 190.58792114257812, "reward": 0.8811187744140625, "action": 0.20059141516685486}
{"mode": "train", "epochs": 1, "timestep": 297, "ep_reward": 191.4991912841797, "reward": 0.9112772941589355, "action": 0.5372931361198425}
{"mode": "train", "epochs": 1, "timestep": 298, "ep_reward": 192.42788696289062, "reward": 0.9286932349205017, "action": 0.22838972508907318}
{"mode": "train", "epochs": 1, "timestep": 299, "ep_reward": 193.36721801757812, "reward": 0.9393293857574463, "action": 0.13709676265716553}
{"mode": "train", "epochs": 1, "timestep": 300, "ep_reward": 194.3101348876953, "reward": 0.942919135093689, "action": 0.11839178204536438}
{"mode": "train", "epochs": 1, "timestep": 301, "ep_reward": 195.24954223632812, "reward": 0.9394001364707947, "action": 0.3966958522796631}
{"mode": "train", "epochs": 1, "timestep": 302, "ep_reward": 196.1759033203125, "reward": 0.9263542890548706, "action": 0.02586159110069275}
{"mode": "train", "epochs": 1, "timestep": 303, "ep_reward": 197.08187866210938, "reward": 0.9059816598892212, "action": 0.138819620013237}
{"mode": "train", "epochs": 1, "timestep": 304, "ep_reward": 197.95449829101562, "reward": 0.8726229071617126, "action": 0.6678369641304016}
{"mode": "train", "epochs": 1, "timestep": 305, "ep_reward": 198.7727508544922, "reward": 0.8182519674301147, "action": 0.5494673252105713}
{"mode": "train", "epochs": 1, "timestep": 306, "ep_reward": 199.51466369628906, "reward": 0.741911768913269, "action": -0.4735782742500305}
{"mode": "train", "epochs": 1, "timestep": 307, "ep_reward": 200.16452026367188, "reward": 0.6498533487319946, "action": -0.5896289944648743}
{"mode": "train", "epochs": 1, "timestep": 308, "ep_reward": 200.69680786132812, "reward": 0.5322887897491455, "action": -1.3652472496032715}
{"mode": "train", "epochs": 1, "timestep": 309, "ep_reward": 201.0981903076172, "reward": 0.4013873338699341, "action": -0.04783374071121216}
{"mode": "train", "epochs": 1, "timestep": 310, "ep_reward": 201.33135986328125, "reward": 0.2331768274307251, "action": -1.236774206161499}
{"mode": "train", "epochs": 1, "timestep": 311, "ep_reward": 201.40736389160156, "reward": 0.07599997520446777, "action": -0.7353237867355347}
{"mode": "train", "epochs": 1, "timestep": 312, "ep_reward": 201.47372436523438, "reward": 0.06635993719100952, "action": -0.5005943775177002}
{"mode": "train", "epochs": 1, "timestep": 313, "ep_reward": 201.69334411621094, "reward": 0.21961694955825806, "action": -1.714843511581421}
{"mode": "train", "epochs": 1, "timestep": 314, "ep_reward": 202.0789031982422, "reward": 0.38556426763534546, "action": -0.20412206649780273}
{"mode": "train", "epochs": 1, "timestep": 315, "ep_reward": 202.59910583496094, "reward": 0.5202096700668335, "action": -1.046325445175171}
{"mode": "train", "epochs": 1, "timestep": 316, "ep_reward": 203.24424743652344, "reward": 0.6451455354690552, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 317, "ep_reward": 203.9970703125, "reward": 0.7528188228607178, "action": -1.5820269584655762}
{"mode": "train", "epochs": 1, "timestep": 318, "ep_reward": 204.82717895507812, "reward": 0.8301070928573608, "action": -0.2698974013328552}
{"mode": "train", "epochs": 1, "timestep": 319, "ep_reward": 205.70608520507812, "reward": 0.8788986802101135, "action": -1.1827971935272217}
{"mode": "train", "epochs": 1, "timestep": 320, "ep_reward": 206.6217803955078, "reward": 0.9156964421272278, "action": -1.0240182876586914}
{"mode": "train", "epochs": 1, "timestep": 321, "ep_reward": 207.55892944335938, "reward": 0.9371479749679565, "action": -1.2922252416610718}
{"mode": "train", "epochs": 1, "timestep": 322, "ep_reward": 208.5051727294922, "reward": 0.9462475776672363, "action": -0.658012866973877}
{"mode": "train", "epochs": 1, "timestep": 323, "ep_reward": 209.44900512695312, "reward": 0.9438250064849854, "action": -0.17511743307113647}
{"mode": "train", "epochs": 1, "timestep": 324, "ep_reward": 210.381103515625, "reward": 0.9321032166481018, "action": -1.573044776916504}
{"mode": "train", "epochs": 1, "timestep": 325, "ep_reward": 211.28565979003906, "reward": 0.9045529961585999, "action": -0.337690532207489}
{"mode": "train", "epochs": 1, "timestep": 326, "ep_reward": 212.15174865722656, "reward": 0.8660882115364075, "action": -0.2276902198791504}
{"mode": "train", "epochs": 1, "timestep": 327, "ep_reward": 212.96368408203125, "reward": 0.8119345307350159, "action": -0.0967782735824585}
{"mode": "train", "epochs": 1, "timestep": 328, "ep_reward": 213.70309448242188, "reward": 0.7394125461578369, "action": -1.0453873872756958}
{"mode": "train", "epochs": 1, "timestep": 329, "ep_reward": 214.3380584716797, "reward": 0.6349712610244751, "action": -0.428311288356781}
{"mode": "train", "epochs": 1, "timestep": 330, "ep_reward": 214.84872436523438, "reward": 0.5106596946716309, "action": -0.8123239278793335}
{"mode": "train", "epochs": 1, "timestep": 331, "ep_reward": 215.20758056640625, "reward": 0.35886049270629883, "action": -1.1758474111557007}
{"mode": "train", "epochs": 1, "timestep": 332, "ep_reward": 215.39224243164062, "reward": 0.1846587061882019, "action": -0.7458770275115967}
{"mode": "train", "epochs": 1, "timestep": 333, "ep_reward": 215.436279296875, "reward": 0.04403793811798096, "action": -0.9012329578399658}
{"mode": "train", "epochs": 1, "timestep": 334, "ep_reward": 215.60935974121094, "reward": 0.17308175563812256, "action": -1.771223783493042}
{"mode": "train", "epochs": 1, "timestep": 335, "ep_reward": 215.90672302246094, "reward": 0.2973666787147522, "action": -1.4862467050552368}
{"mode": "train", "epochs": 1, "timestep": 336, "ep_reward": 216.33175659179688, "reward": 0.4250410199165344, "action": -1.4940091371536255}
{"mode": "train", "epochs": 1, "timestep": 337, "ep_reward": 216.87481689453125, "reward": 0.5430643558502197, "action": -0.48004651069641113}
{"mode": "train", "epochs": 1, "timestep": 338, "ep_reward": 217.52935791015625, "reward": 0.6545451879501343, "action": -1.0910285711288452}
{"mode": "train", "epochs": 1, "timestep": 339, "ep_reward": 218.2665252685547, "reward": 0.7371608018875122, "action": -0.8708752989768982}
{"mode": "train", "epochs": 1, "timestep": 340, "ep_reward": 219.06712341308594, "reward": 0.8006001710891724, "action": -1.2961839437484741}
{"mode": "train", "epochs": 1, "timestep": 341, "ep_reward": 219.9084014892578, "reward": 0.8412814140319824, "action": -0.890106201171875}
{"mode": "train", "epochs": 1, "timestep": 342, "ep_reward": 220.7769317626953, "reward": 0.8685230612754822, "action": -1.904654860496521}
{"mode": "train", "epochs": 1, "timestep": 343, "ep_reward": 221.64952087402344, "reward": 0.8725947737693787, "action": -0.9537567496299744}
{"mode": "train", "epochs": 1, "timestep": 344, "ep_reward": 222.5183563232422, "reward": 0.8688371777534485, "action": -1.1330804824829102}
{"mode": "train", "epochs": 1, "timestep": 345, "ep_reward": 223.3646697998047, "reward": 0.8463088870048523, "action": -1.0094331502914429}
{"mode": "train", "epochs": 1, "timestep": 346, "ep_reward": 224.16867065429688, "reward": 0.8039940595626831, "action": -0.27768999338150024}
{"mode": "train", "epochs": 1, "timestep": 347, "ep_reward": 224.91229248046875, "reward": 0.7436225414276123, "action": -1.1394193172454834}
{"mode": "train", "epochs": 1, "timestep": 348, "ep_reward": 225.5543212890625, "reward": 0.6420316696166992, "action": -0.6432409286499023}
{"mode": "train", "epochs": 1, "timestep": 349, "ep_reward": 226.0625457763672, "reward": 0.5082190036773682, "action": -1.1636128425598145}
{"mode": "train", "epochs": 1, "timestep": 350, "ep_reward": 226.412841796875, "reward": 0.3503018617630005, "action": -0.9508284330368042}
{"mode": "train", "epochs": 1, "timestep": 351, "ep_reward": 226.65325927734375, "reward": 0.24042350053787231, "action": -0.31346893310546875}
{"mode": "train", "epochs": 1, "timestep": 352, "ep_reward": 226.76373291015625, "reward": 0.1104738712310791, "action": -0.6547728776931763}
{"mode": "train", "epochs": 1, "timestep": 353, "ep_reward": 226.76893615722656, "reward": 0.005208253860473633, "action": -1.3483749628067017}
{"mode": "train", "epochs": 1, "timestep": 354, "ep_reward": 226.91845703125, "reward": 0.14952415227890015, "action": -0.6815354824066162}
{"mode": "train", "epochs": 1, "timestep": 355, "ep_reward": 227.2113800048828, "reward": 0.29291844367980957, "action": -1.4681048393249512}
{"mode": "train", "epochs": 1, "timestep": 356, "ep_reward": 227.63479614257812, "reward": 0.42342203855514526, "action": -0.7246896028518677}
{"mode": "train", "epochs": 1, "timestep": 357, "ep_reward": 228.1861114501953, "reward": 0.5513086318969727, "action": -1.2798340320587158}
{"mode": "train", "epochs": 1, "timestep": 358, "ep_reward": 228.83908081054688, "reward": 0.6529688835144043, "action": -1.338451862335205}
{"mode": "train", "epochs": 1, "timestep": 359, "ep_reward": 229.57130432128906, "reward": 0.7322273254394531, "action": -1.4871877431869507}
{"mode": "train", "epochs": 1, "timestep": 360, "ep_reward": 230.35971069335938, "reward": 0.7883996963500977, "action": -1.605431079864502}
{"mode": "train", "epochs": 1, "timestep": 361, "ep_reward": 231.18324279785156, "reward": 0.823535680770874, "action": -0.9165146350860596}
{"mode": "train", "epochs": 1, "timestep": 362, "ep_reward": 232.02919006347656, "reward": 0.845941424369812, "action": -0.8961683511734009}
{"mode": "train", "epochs": 1, "timestep": 363, "ep_reward": 232.87921142578125, "reward": 0.8500179648399353, "action": -1.1566710472106934}
{"mode": "train", "epochs": 1, "timestep": 364, "ep_reward": 233.7117462158203, "reward": 0.8325324654579163, "action": -0.6815717220306396}
{"mode": "train", "epochs": 1, "timestep": 365, "ep_reward": 234.50917053222656, "reward": 0.7974188327789307, "action": -1.233981728553772}
{"mode": "train", "epochs": 1, "timestep": 366, "ep_reward": 235.238525390625, "reward": 0.7293491363525391, "action": -1.093531847000122}
{"mode": "train", "epochs": 1, "timestep": 367, "ep_reward": 235.8665313720703, "reward": 0.628004789352417, "action": -1.2481775283813477}
{"mode": "train", "epochs": 1, "timestep": 368, "ep_reward": 236.34942626953125, "reward": 0.48289018869400024, "action": -0.9409587979316711}
{"mode": "train", "epochs": 1, "timestep": 369, "ep_reward": 236.70535278320312, "reward": 0.35592418909072876, "action": -1.7626585960388184}
{"mode": "train", "epochs": 1, "timestep": 370, "ep_reward": 236.9525604248047, "reward": 0.24720525741577148, "action": -1.51716947555542}
{"mode": "train", "epochs": 1, "timestep": 371, "ep_reward": 237.07110595703125, "reward": 0.11853820085525513, "action": -0.8159574866294861}
{"mode": "train", "epochs": 1, "timestep": 372, "ep_reward": 237.06729125976562, "reward": -0.0038167238235473633, "action": -1.6154170036315918}
{"mode": "train", "epochs": 1, "timestep": 373, "ep_reward": 237.20899963378906, "reward": 0.14171570539474487, "action": -0.5863578915596008}
{"mode": "train", "epochs": 1, "timestep": 374, "ep_reward": 237.49522399902344, "reward": 0.2862226963043213, "action": -0.619543194770813}
{"mode": "train", "epochs": 1, "timestep": 375, "ep_reward": 237.9221649169922, "reward": 0.42694753408432007, "action": -0.8628897070884705}
{"mode": "train", "epochs": 1, "timestep": 376, "ep_reward": 238.47413635253906, "reward": 0.5519713163375854, "action": -1.2437344789505005}
{"mode": "train", "epochs": 1, "timestep": 377, "ep_reward": 239.1279754638672, "reward": 0.6538436412811279, "action": -1.8880057334899902}
{"mode": "train", "epochs": 1, "timestep": 378, "ep_reward": 239.8566131591797, "reward": 0.7286344766616821, "action": -1.046818494796753}
{"mode": "train", "epochs": 1, "timestep": 379, "ep_reward": 240.64756774902344, "reward": 0.7909552454948425, "action": -1.298459529876709}
{"mode": "train", "epochs": 1, "timestep": 380, "ep_reward": 241.47854614257812, "reward": 0.8309847116470337, "action": -0.5789211988449097}
{"mode": "train", "epochs": 1, "timestep": 381, "ep_reward": 242.33763122558594, "reward": 0.8590901494026184, "action": -1.1206035614013672}
{"mode": "train", "epochs": 1, "timestep": 382, "ep_reward": 243.2034149169922, "reward": 0.8657891750335693, "action": -1.1693706512451172}
{"mode": "train", "epochs": 1, "timestep": 383, "ep_reward": 244.05860900878906, "reward": 0.8551984429359436, "action": -0.9211505055427551}
{"mode": "train", "epochs": 1, "timestep": 384, "ep_reward": 244.88619995117188, "reward": 0.8275911808013916, "action": -1.3167660236358643}
{"mode": "train", "epochs": 1, "timestep": 385, "ep_reward": 245.6586151123047, "reward": 0.7724083662033081, "action": -1.4180514812469482}
{"mode": "train", "epochs": 1, "timestep": 386, "ep_reward": 246.34356689453125, "reward": 0.6849504709243774, "action": -1.3953831195831299}
{"mode": "train", "epochs": 1, "timestep": 387, "ep_reward": 246.90219116210938, "reward": 0.5586254596710205, "action": -1.034546136856079}
{"mode": "train", "epochs": 1, "timestep": 388, "ep_reward": 247.30007934570312, "reward": 0.39788198471069336, "action": -0.6161154508590698}
{"mode": "train", "epochs": 1, "timestep": 389, "ep_reward": 247.5980224609375, "reward": 0.2979443073272705, "action": -0.9046081304550171}
{"mode": "train", "epochs": 1, "timestep": 390, "ep_reward": 247.7760772705078, "reward": 0.17806202173233032, "action": -0.6078879833221436}
{"mode": "train", "epochs": 1, "timestep": 391, "ep_reward": 247.81423950195312, "reward": 0.03815948963165283, "action": -0.4903706908226013}
{"mode": "train", "epochs": 1, "timestep": 392, "ep_reward": 247.89401245117188, "reward": 0.07976710796356201, "action": -0.7726081609725952}
{"mode": "train", "epochs": 1, "timestep": 393, "ep_reward": 248.11428833007812, "reward": 0.22027373313903809, "action": -0.7421948909759521}
{"mode": "train", "epochs": 1, "timestep": 394, "ep_reward": 248.47669982910156, "reward": 0.3624058961868286, "action": -1.83589506149292}
{"mode": "train", "epochs": 1, "timestep": 395, "ep_reward": 248.96034240722656, "reward": 0.4836466908454895, "action": -0.22088974714279175}
{"mode": "train", "epochs": 1, "timestep": 396, "ep_reward": 249.56887817382812, "reward": 0.6085410118103027, "action": -1.1829144954681396}
{"mode": "train", "epochs": 1, "timestep": 397, "ep_reward": 250.268798828125, "reward": 0.699915885925293, "action": -0.14793890714645386}
{"mode": "train", "epochs": 1, "timestep": 398, "ep_reward": 251.04745483398438, "reward": 0.7786616683006287, "action": -1.24029541015625}
{"mode": "train", "epochs": 1, "timestep": 399, "ep_reward": 251.873291015625, "reward": 0.8258407711982727, "action": -0.29814982414245605}
{"mode": "train", "epochs": 1, "timestep": 400, "ep_reward": 252.73622131347656, "reward": 0.8629346489906311, "action": -0.8239823579788208}
{"mode": "train", "epochs": 1, "timestep": 401, "ep_reward": 253.61573791503906, "reward": 0.8795187473297119, "action": -1.4214777946472168}
{"mode": "train", "epochs": 1, "timestep": 402, "ep_reward": 254.49241638183594, "reward": 0.8766717910766602, "action": -1.1911689043045044}
{"mode": "train", "epochs": 1, "timestep": 403, "ep_reward": 255.35211181640625, "reward": 0.8596904277801514, "action": -0.8751930594444275}
{"mode": "train", "epochs": 1, "timestep": 404, "ep_reward": 256.17852783203125, "reward": 0.8264292478561401, "action": -1.6551852226257324}
{"mode": "train", "epochs": 1, "timestep": 405, "ep_reward": 256.9397277832031, "reward": 0.761194109916687, "action": -1.6088008880615234}
{"mode": "train", "epochs": 1, "timestep": 406, "ep_reward": 257.60302734375, "reward": 0.6632975339889526, "action": -1.203500747680664}
{"mode": "train", "epochs": 1, "timestep": 407, "ep_reward": 258.1331787109375, "reward": 0.5301649570465088, "action": -1.334282636642456}
{"mode": "train", "epochs": 1, "timestep": 408, "ep_reward": 258.50836181640625, "reward": 0.375182569026947, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 409, "ep_reward": 258.7789306640625, "reward": 0.2705755829811096, "action": -1.1274001598358154}
{"mode": "train", "epochs": 1, "timestep": 410, "ep_reward": 258.9248046875, "reward": 0.1458725929260254, "action": -0.27552109956741333}
{"mode": "train", "epochs": 1, "timestep": 411, "ep_reward": 258.9259033203125, "reward": 0.0010980963706970215, "action": -0.1479284167289734}
{"mode": "train", "epochs": 1, "timestep": 412, "ep_reward": 259.0401611328125, "reward": 0.11424523591995239, "action": -1.0737855434417725}
{"mode": "train", "epochs": 1, "timestep": 413, "ep_reward": 259.2921447753906, "reward": 0.251994788646698, "action": -0.9344232678413391}
{"mode": "train", "epochs": 1, "timestep": 414, "ep_reward": 259.6836242675781, "reward": 0.3914835453033447, "action": -0.9026898145675659}
{"mode": "train", "epochs": 1, "timestep": 415, "ep_reward": 260.20465087890625, "reward": 0.5210247039794922, "action": -1.1330931186676025}
{"mode": "train", "epochs": 1, "timestep": 416, "ep_reward": 260.8343811035156, "reward": 0.6297250986099243, "action": -0.846526026725769}
{"mode": "train", "epochs": 1, "timestep": 417, "ep_reward": 261.5538330078125, "reward": 0.7194570302963257, "action": -0.8824891448020935}
{"mode": "train", "epochs": 1, "timestep": 418, "ep_reward": 262.33984375, "reward": 0.786022424697876, "action": -1.1439608335494995}
{"mode": "train", "epochs": 1, "timestep": 419, "ep_reward": 263.16961669921875, "reward": 0.8297657370567322, "action": -0.15994524955749512}
{"mode": "train", "epochs": 1, "timestep": 420, "ep_reward": 264.0332336425781, "reward": 0.8636137247085571, "action": -1.0025593042373657}
{"mode": "train", "epochs": 1, "timestep": 421, "ep_reward": 264.90728759765625, "reward": 0.8740628361701965, "action": -0.8759961128234863}
{"mode": "train", "epochs": 1, "timestep": 422, "ep_reward": 265.7771301269531, "reward": 0.8698301315307617, "action": -1.8152976036071777}
{"mode": "train", "epochs": 1, "timestep": 423, "ep_reward": 266.61700439453125, "reward": 0.8398784399032593, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 424, "ep_reward": 267.4017333984375, "reward": 0.7847415208816528, "action": -0.9078227877616882}
{"mode": "train", "epochs": 1, "timestep": 425, "ep_reward": 268.11285400390625, "reward": 0.7111170291900635, "action": -1.4772846698760986}
{"mode": "train", "epochs": 1, "timestep": 426, "ep_reward": 268.707275390625, "reward": 0.5944267511367798, "action": -0.32462984323501587}
{"mode": "train", "epochs": 1, "timestep": 427, "ep_reward": 269.1592102050781, "reward": 0.45193278789520264, "action": -0.6934032440185547}
{"mode": "train", "epochs": 1, "timestep": 428, "ep_reward": 269.4864501953125, "reward": 0.32723110914230347, "action": 0.18554896116256714}
{"mode": "train", "epochs": 1, "timestep": 429, "ep_reward": 269.6990661621094, "reward": 0.21262043714523315, "action": -1.5969305038452148}
{"mode": "train", "epochs": 1, "timestep": 430, "ep_reward": 269.77728271484375, "reward": 0.0782020092010498, "action": -1.4044783115386963}
{"mode": "train", "epochs": 1, "timestep": 431, "ep_reward": 269.8169250488281, "reward": 0.039643049240112305, "action": -1.026963710784912}
{"mode": "train", "epochs": 1, "timestep": 432, "ep_reward": 269.99609375, "reward": 0.17916405200958252, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 433, "ep_reward": 270.3029479980469, "reward": 0.30686259269714355, "action": -0.286238431930542}
{"mode": "train", "epochs": 1, "timestep": 434, "ep_reward": 270.756103515625, "reward": 0.45315271615982056, "action": -0.10286301374435425}
{"mode": "train", "epochs": 1, "timestep": 435, "ep_reward": 271.34027099609375, "reward": 0.5841799974441528, "action": -0.691016435623169}
{"mode": "train", "epochs": 1, "timestep": 436, "ep_reward": 272.02587890625, "reward": 0.6856150031089783, "action": -0.27271413803100586}
{"mode": "train", "epochs": 1, "timestep": 437, "ep_reward": 272.7935485839844, "reward": 0.7676669359207153, "action": -1.2181869745254517}
{"mode": "train", "epochs": 1, "timestep": 438, "ep_reward": 273.61285400390625, "reward": 0.8192944526672363, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 439, "ep_reward": 274.4597473144531, "reward": 0.8469049334526062, "action": -1.3164770603179932}
{"mode": "train", "epochs": 1, "timestep": 440, "ep_reward": 275.323974609375, "reward": 0.8642174005508423, "action": -0.31017524003982544}
{"mode": "train", "epochs": 1, "timestep": 441, "ep_reward": 276.1977844238281, "reward": 0.8738067150115967, "action": -1.3855031728744507}
{"mode": "train", "epochs": 1, "timestep": 442, "ep_reward": 277.0559997558594, "reward": 0.8582159280776978, "action": -0.12129110097885132}
{"mode": "train", "epochs": 1, "timestep": 443, "ep_reward": 277.8912658691406, "reward": 0.8352715969085693, "action": -1.2724106311798096}
{"mode": "train", "epochs": 1, "timestep": 444, "ep_reward": 278.67059326171875, "reward": 0.7793301343917847, "action": -1.0171923637390137}
{"mode": "train", "epochs": 1, "timestep": 445, "ep_reward": 279.36712646484375, "reward": 0.6965186595916748, "action": -0.877183198928833}
{"mode": "train", "epochs": 1, "timestep": 446, "ep_reward": 279.946533203125, "reward": 0.5794014930725098, "action": -1.4349223375320435}
{"mode": "train", "epochs": 1, "timestep": 447, "ep_reward": 280.3594665527344, "reward": 0.41294825077056885, "action": -0.37342512607574463}
{"mode": "train", "epochs": 1, "timestep": 448, "ep_reward": 280.65728759765625, "reward": 0.29782235622406006, "action": -1.1237863302230835}
{"mode": "train", "epochs": 1, "timestep": 449, "ep_reward": 280.835205078125, "reward": 0.17792004346847534, "action": -0.9318709373474121}
{"mode": "train", "epochs": 1, "timestep": 450, "ep_reward": 280.8731994628906, "reward": 0.03799313306808472, "action": -0.9319664239883423}
{"mode": "train", "epochs": 1, "timestep": 451, "ep_reward": 280.953125, "reward": 0.07992452383041382, "action": 0.15576672554016113}
{"mode": "train", "epochs": 1, "timestep": 452, "ep_reward": 281.18505859375, "reward": 0.23193669319152832, "action": 0.15986782312393188}
{"mode": "train", "epochs": 1, "timestep": 453, "ep_reward": 281.5673828125, "reward": 0.3823131322860718, "action": -1.6197634935379028}
{"mode": "train", "epochs": 1, "timestep": 454, "ep_reward": 282.06939697265625, "reward": 0.5020103454589844, "action": -0.3389386534690857}
{"mode": "train", "epochs": 1, "timestep": 455, "ep_reward": 282.69091796875, "reward": 0.6215132474899292, "action": -0.7053492069244385}
{"mode": "train", "epochs": 1, "timestep": 456, "ep_reward": 283.4063720703125, "reward": 0.7154473066329956, "action": -0.8610178232192993}
{"mode": "train", "epochs": 1, "timestep": 457, "ep_reward": 284.19305419921875, "reward": 0.7866960763931274, "action": -0.3664841651916504}
{"mode": "train", "epochs": 1, "timestep": 458, "ep_reward": 285.0355224609375, "reward": 0.842476487159729, "action": -1.5980762243270874}
{"mode": "train", "epochs": 1, "timestep": 459, "ep_reward": 285.90802001953125, "reward": 0.8724837303161621, "action": -1.0373932123184204}
{"mode": "train", "epochs": 1, "timestep": 460, "ep_reward": 286.8013916015625, "reward": 0.8933662176132202, "action": -1.1009773015975952}
{"mode": "train", "epochs": 1, "timestep": 461, "ep_reward": 287.702880859375, "reward": 0.9014764428138733, "action": -1.1237354278564453}
{"mode": "train", "epochs": 1, "timestep": 462, "ep_reward": 288.6001892089844, "reward": 0.8973055481910706, "action": -0.637000560760498}
{"mode": "train", "epochs": 1, "timestep": 463, "ep_reward": 289.48358154296875, "reward": 0.8833940029144287, "action": -1.3691139221191406}
{"mode": "train", "epochs": 1, "timestep": 464, "ep_reward": 290.3309326171875, "reward": 0.8473644256591797, "action": -1.5447323322296143}
{"mode": "train", "epochs": 1, "timestep": 465, "ep_reward": 291.1184387207031, "reward": 0.787514328956604, "action": -0.6484179496765137}
{"mode": "train", "epochs": 1, "timestep": 466, "ep_reward": 291.8268737792969, "reward": 0.7084405422210693, "action": -0.7926372289657593}
{"mode": "train", "epochs": 1, "timestep": 467, "ep_reward": 292.4210205078125, "reward": 0.594147801399231, "action": -1.22184157371521}
{"mode": "train", "epochs": 1, "timestep": 468, "ep_reward": 292.8558044433594, "reward": 0.43479079008102417, "action": -0.8856087923049927}
{"mode": "train", "epochs": 1, "timestep": 469, "ep_reward": 293.15106201171875, "reward": 0.2952727675437927, "action": -1.5718835592269897}
{"mode": "train", "epochs": 1, "timestep": 470, "ep_reward": 293.3260498046875, "reward": 0.17497533559799194, "action": -1.100836992263794}
{"mode": "train", "epochs": 1, "timestep": 471, "ep_reward": 293.3604736328125, "reward": 0.03442502021789551, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 472, "ep_reward": 293.443603515625, "reward": 0.08314508199691772, "action": -0.4967274069786072}
{"mode": "train", "epochs": 1, "timestep": 473, "ep_reward": 293.6707763671875, "reward": 0.22716540098190308, "action": -0.8416197299957275}
{"mode": "train", "epochs": 1, "timestep": 474, "ep_reward": 294.0381774902344, "reward": 0.36739128828048706, "action": -1.154353141784668}
{"mode": "train", "epochs": 1, "timestep": 475, "ep_reward": 294.53399658203125, "reward": 0.4958159923553467, "action": -0.5983805656433105}
{"mode": "train", "epochs": 1, "timestep": 476, "ep_reward": 295.1483154296875, "reward": 0.6143193244934082, "action": -0.6928493976593018}
{"mode": "train", "epochs": 1, "timestep": 477, "ep_reward": 295.85760498046875, "reward": 0.709294319152832, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 478, "ep_reward": 296.6275329589844, "reward": 0.7699382901191711, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 479, "ep_reward": 297.4393005371094, "reward": 0.811761736869812, "action": -1.8970173597335815}
{"mode": "train", "epochs": 1, "timestep": 480, "ep_reward": 298.2758483886719, "reward": 0.836536169052124, "action": -0.4975653886795044}
{"mode": "train", "epochs": 1, "timestep": 481, "ep_reward": 299.13140869140625, "reward": 0.8555675148963928, "action": -1.3203375339508057}
{"mode": "train", "epochs": 1, "timestep": 482, "ep_reward": 299.9807434082031, "reward": 0.8493491411209106, "action": -1.3653477430343628}
{"mode": "train", "epochs": 1, "timestep": 483, "ep_reward": 300.80352783203125, "reward": 0.8227934241294861, "action": -1.1344857215881348}
{"mode": "train", "epochs": 1, "timestep": 484, "ep_reward": 301.5778503417969, "reward": 0.774307906627655, "action": -0.492300808429718}
{"mode": "train", "epochs": 1, "timestep": 485, "ep_reward": 302.2813720703125, "reward": 0.7035191655158997, "action": -0.5668115615844727}
{"mode": "train", "epochs": 1, "timestep": 486, "ep_reward": 302.8785400390625, "reward": 0.5971823334693909, "action": -1.0494800806045532}
{"mode": "train", "epochs": 1, "timestep": 487, "ep_reward": 303.3220520019531, "reward": 0.4435235261917114, "action": -1.021189570426941}
{"mode": "train", "epochs": 1, "timestep": 488, "ep_reward": 303.6463928222656, "reward": 0.3243477940559387, "action": -0.646923303604126}
{"mode": "train", "epochs": 1, "timestep": 489, "ep_reward": 303.85565185546875, "reward": 0.2092583179473877, "action": -1.3595725297927856}
{"mode": "train", "epochs": 1, "timestep": 490, "ep_reward": 303.92987060546875, "reward": 0.0742182731628418, "action": -1.5776344537734985}
{"mode": "train", "epochs": 1, "timestep": 491, "ep_reward": 303.9736328125, "reward": 0.0437626838684082, "action": -0.6462724208831787}
{"mode": "train", "epochs": 1, "timestep": 492, "ep_reward": 304.1581726074219, "reward": 0.1845412254333496, "action": -1.769892930984497}
{"mode": "train", "epochs": 1, "timestep": 493, "ep_reward": 304.4728698730469, "reward": 0.3147088289260864, "action": -1.4594151973724365}
{"mode": "train", "epochs": 1, "timestep": 494, "ep_reward": 304.91845703125, "reward": 0.44558775424957275, "action": -1.3566272258758545}
{"mode": "train", "epochs": 1, "timestep": 495, "ep_reward": 305.48236083984375, "reward": 0.5639015436172485, "action": -1.7568260431289673}
{"mode": "train", "epochs": 1, "timestep": 496, "ep_reward": 306.1396789550781, "reward": 0.6573107242584229, "action": -0.6611472368240356}
{"mode": "train", "epochs": 1, "timestep": 497, "ep_reward": 306.8787841796875, "reward": 0.7390927076339722, "action": -1.0938019752502441}
{"mode": "train", "epochs": 1, "timestep": 498, "ep_reward": 307.6710205078125, "reward": 0.7922435998916626, "action": -0.4715368151664734}
{"mode": "train", "epochs": 1, "timestep": 499, "ep_reward": 308.50042724609375, "reward": 0.8294062614440918, "action": -1.1430935859680176}
{"mode": "train", "epochs": 1, "timestep": 500, "ep_reward": 309.34063720703125, "reward": 0.8402167558670044, "action": -1.0372682809829712}
{"mode": "train", "epochs": 1, "timestep": 501, "ep_reward": 310.1728515625, "reward": 0.8322043418884277, "action": -0.6473577618598938}
{"mode": "train", "epochs": 1, "timestep": 502, "ep_reward": 310.9789123535156, "reward": 0.8060693740844727, "action": -1.6112210750579834}
{"mode": "train", "epochs": 1, "timestep": 503, "ep_reward": 311.7225341796875, "reward": 0.7436176538467407, "action": 0.011169910430908203}
{"mode": "train", "epochs": 1, "timestep": 504, "ep_reward": 312.389892578125, "reward": 0.6673588752746582, "action": -0.5908316373825073}
{"mode": "train", "epochs": 1, "timestep": 505, "ep_reward": 312.9367980957031, "reward": 0.546905517578125, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 506, "ep_reward": 313.32696533203125, "reward": 0.39016491174697876, "action": 0.30363911390304565}
{"mode": "train", "epochs": 1, "timestep": 507, "ep_reward": 313.6154479980469, "reward": 0.2884678244590759, "action": -1.1916953325271606}
{"mode": "train", "epochs": 1, "timestep": 508, "ep_reward": 313.78216552734375, "reward": 0.16670948266983032, "action": -1.9293358325958252}
{"mode": "train", "epochs": 1, "timestep": 509, "ep_reward": 313.8074645996094, "reward": 0.025305986404418945, "action": -0.5938069820404053}
{"mode": "train", "epochs": 1, "timestep": 510, "ep_reward": 313.8992919921875, "reward": 0.09182119369506836, "action": -1.7974481582641602}
{"mode": "train", "epochs": 1, "timestep": 511, "ep_reward": 314.12384033203125, "reward": 0.22455531358718872, "action": -0.45066845417022705}
{"mode": "train", "epochs": 1, "timestep": 512, "ep_reward": 314.4954833984375, "reward": 0.3716333508491516, "action": -1.6198655366897583}
{"mode": "train", "epochs": 1, "timestep": 513, "ep_reward": 314.9903259277344, "reward": 0.4948357343673706, "action": -1.2647624015808105}
{"mode": "train", "epochs": 1, "timestep": 514, "ep_reward": 315.5967712402344, "reward": 0.6064499616622925, "action": -1.704859733581543}
{"mode": "train", "epochs": 1, "timestep": 515, "ep_reward": 316.28887939453125, "reward": 0.6921125650405884, "action": -0.4753926396369934}
{"mode": "train", "epochs": 1, "timestep": 516, "ep_reward": 317.0564270019531, "reward": 0.7675445675849915, "action": -0.8689397573471069}
{"mode": "train", "epochs": 1, "timestep": 517, "ep_reward": 317.87255859375, "reward": 0.8161205053329468, "action": -1.3790394067764282}
{"mode": "train", "epochs": 1, "timestep": 518, "ep_reward": 318.71295166015625, "reward": 0.8403791785240173, "action": -0.7722286581993103}
{"mode": "train", "epochs": 1, "timestep": 519, "ep_reward": 319.5646057128906, "reward": 0.8516669869422913, "action": -0.5008623003959656}
{"mode": "train", "epochs": 1, "timestep": 520, "ep_reward": 320.4114685058594, "reward": 0.8468573689460754, "action": -1.3450809717178345}
{"mode": "train", "epochs": 1, "timestep": 521, "ep_reward": 321.2253723144531, "reward": 0.8138992786407471, "action": -1.0460478067398071}
{"mode": "train", "epochs": 1, "timestep": 522, "ep_reward": 321.98388671875, "reward": 0.7585037350654602, "action": -0.6310526728630066}
{"mode": "train", "epochs": 1, "timestep": 523, "ep_reward": 322.6605224609375, "reward": 0.676639199256897, "action": -1.4851197004318237}
{"mode": "train", "epochs": 1, "timestep": 524, "ep_reward": 323.2061767578125, "reward": 0.5456665754318237, "action": -1.4277368783950806}
{"mode": "train", "epochs": 1, "timestep": 525, "ep_reward": 323.59747314453125, "reward": 0.39128577709198, "action": -0.5987773537635803}
{"mode": "train", "epochs": 1, "timestep": 526, "ep_reward": 323.88720703125, "reward": 0.28974586725234985, "action": -1.7739505767822266}
{"mode": "train", "epochs": 1, "timestep": 527, "ep_reward": 324.0556945800781, "reward": 0.16850155591964722, "action": -1.098486304283142}
{"mode": "train", "epochs": 1, "timestep": 528, "ep_reward": 324.08282470703125, "reward": 0.027134180068969727, "action": -1.1110212802886963}
{"mode": "train", "epochs": 1, "timestep": 529, "ep_reward": 324.17303466796875, "reward": 0.09021449089050293, "action": -0.7452176809310913}
{"mode": "train", "epochs": 1, "timestep": 530, "ep_reward": 324.4042053222656, "reward": 0.2311609387397766, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 531, "ep_reward": 324.761962890625, "reward": 0.35774606466293335, "action": -0.11018556356430054}
{"mode": "train", "epochs": 1, "timestep": 532, "ep_reward": 325.2630615234375, "reward": 0.5010851621627808, "action": -0.335734486579895}
{"mode": "train", "epochs": 1, "timestep": 533, "ep_reward": 325.884765625, "reward": 0.6217033863067627, "action": -0.6246401071548462}
{"mode": "train", "epochs": 1, "timestep": 534, "ep_reward": 326.60064697265625, "reward": 0.7158817052841187, "action": -0.43863606452941895}
{"mode": "train", "epochs": 1, "timestep": 535, "ep_reward": 327.3892517089844, "reward": 0.7886085510253906, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 536, "ep_reward": 328.2170715332031, "reward": 0.8278082609176636, "action": -1.1581931114196777}
{"mode": "train", "epochs": 1, "timestep": 537, "ep_reward": 329.07452392578125, "reward": 0.8574439287185669, "action": -0.6071246266365051}
{"mode": "train", "epochs": 1, "timestep": 538, "ep_reward": 329.95001220703125, "reward": 0.8754771947860718, "action": -1.0381609201431274}
{"mode": "train", "epochs": 1, "timestep": 539, "ep_reward": 330.8246765136719, "reward": 0.8746589422225952, "action": -1.4281798601150513}
{"mode": "train", "epochs": 1, "timestep": 540, "ep_reward": 331.6788635253906, "reward": 0.8541892170906067, "action": -0.9406483769416809}
{"mode": "train", "epochs": 1, "timestep": 541, "ep_reward": 332.4969177246094, "reward": 0.8180602788925171, "action": -1.5842854976654053}
{"mode": "train", "epochs": 1, "timestep": 542, "ep_reward": 333.2471008300781, "reward": 0.7501792311668396, "action": -1.087550401687622}
{"mode": "train", "epochs": 1, "timestep": 543, "ep_reward": 333.9017028808594, "reward": 0.6545993685722351, "action": -0.9416958689689636}
{"mode": "train", "epochs": 1, "timestep": 544, "ep_reward": 334.42340087890625, "reward": 0.5217024087905884, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 545, "ep_reward": 334.7904357910156, "reward": 0.36704015731811523, "action": -1.5105228424072266}
{"mode": "train", "epochs": 1, "timestep": 546, "ep_reward": 335.05108642578125, "reward": 0.2606462240219116, "action": -0.742155909538269}
{"mode": "train", "epochs": 1, "timestep": 547, "ep_reward": 335.1851806640625, "reward": 0.13409876823425293, "action": -1.1295526027679443}
{"mode": "train", "epochs": 1, "timestep": 548, "ep_reward": 335.17279052734375, "reward": -0.012399673461914062, "action": -1.1037943363189697}
{"mode": "train", "epochs": 1, "timestep": 549, "ep_reward": 335.2990417480469, "reward": 0.12625432014465332, "action": -0.3766777515411377}
{"mode": "train", "epochs": 1, "timestep": 550, "ep_reward": 335.57196044921875, "reward": 0.2729174494743347, "action": -1.1359528303146362}
{"mode": "train", "epochs": 1, "timestep": 551, "ep_reward": 335.9796447753906, "reward": 0.4076891541481018, "action": -1.0737051963806152}
{"mode": "train", "epochs": 1, "timestep": 552, "ep_reward": 336.51251220703125, "reward": 0.5328741073608398, "action": -1.4536089897155762}
{"mode": "train", "epochs": 1, "timestep": 553, "ep_reward": 337.1485595703125, "reward": 0.6360360383987427, "action": -1.4087833166122437}
{"mode": "train", "epochs": 1, "timestep": 554, "ep_reward": 337.8673095703125, "reward": 0.7187612056732178, "action": -1.6067605018615723}
{"mode": "train", "epochs": 1, "timestep": 555, "ep_reward": 338.6455078125, "reward": 0.7781847715377808, "action": -0.523940920829773}
{"mode": "train", "epochs": 1, "timestep": 556, "ep_reward": 339.47235107421875, "reward": 0.8268389701843262, "action": -1.8781436681747437}
{"mode": "train", "epochs": 1, "timestep": 557, "ep_reward": 340.3168029785156, "reward": 0.8444614410400391, "action": -1.6023168563842773}
{"mode": "train", "epochs": 1, "timestep": 558, "ep_reward": 341.16351318359375, "reward": 0.8466953635215759, "action": -0.5229744911193848}
{"mode": "train", "epochs": 1, "timestep": 559, "ep_reward": 342.00311279296875, "reward": 0.8396098017692566, "action": -1.2055933475494385}
{"mode": "train", "epochs": 1, "timestep": 560, "ep_reward": 342.8079833984375, "reward": 0.8048769235610962, "action": 0.08789342641830444}
{"mode": "train", "epochs": 1, "timestep": 561, "ep_reward": 343.5661926269531, "reward": 0.7582226991653442, "action": -1.3599793910980225}
{"mode": "train", "epochs": 1, "timestep": 562, "ep_reward": 344.23101806640625, "reward": 0.6648180484771729, "action": -0.8565822839736938}
{"mode": "train", "epochs": 1, "timestep": 563, "ep_reward": 344.76947021484375, "reward": 0.5384382009506226, "action": -1.5993199348449707}
{"mode": "train", "epochs": 1, "timestep": 564, "ep_reward": 345.1519775390625, "reward": 0.3825013041496277, "action": -1.561605453491211}
{"mode": "train", "epochs": 1, "timestep": 565, "ep_reward": 345.4313659667969, "reward": 0.2793906331062317, "action": -0.597858726978302}
{"mode": "train", "epochs": 1, "timestep": 566, "ep_reward": 345.58740234375, "reward": 0.15603786706924438, "action": -1.4666656255722046}
{"mode": "train", "epochs": 1, "timestep": 567, "ep_reward": 345.6002502441406, "reward": 0.012861669063568115, "action": -1.0586791038513184}
{"mode": "train", "epochs": 1, "timestep": 568, "ep_reward": 345.7037658691406, "reward": 0.10350924730300903, "action": -0.8028609752655029}
{"mode": "train", "epochs": 1, "timestep": 569, "ep_reward": 345.94793701171875, "reward": 0.24417030811309814, "action": -1.8207640647888184}
{"mode": "train", "epochs": 1, "timestep": 570, "ep_reward": 346.3204650878906, "reward": 0.3725327253341675, "action": -1.4588985443115234}
{"mode": "train", "epochs": 1, "timestep": 571, "ep_reward": 346.8187255859375, "reward": 0.4982721209526062, "action": -1.1792415380477905}
{"mode": "train", "epochs": 1, "timestep": 572, "ep_reward": 347.42919921875, "reward": 0.610487163066864, "action": -0.12122154235839844}
{"mode": "train", "epochs": 1, "timestep": 573, "ep_reward": 348.1402282714844, "reward": 0.7110251188278198, "action": -0.31901782751083374}
{"mode": "train", "epochs": 1, "timestep": 574, "ep_reward": 348.924072265625, "reward": 0.7838405966758728, "action": -1.9228562116622925}
{"mode": "train", "epochs": 1, "timestep": 575, "ep_reward": 349.7447509765625, "reward": 0.8206785917282104, "action": -0.9738659262657166}
{"mode": "train", "epochs": 1, "timestep": 576, "ep_reward": 350.5924377441406, "reward": 0.8476814031600952, "action": -0.3066672086715698}
{"mode": "train", "epochs": 1, "timestep": 577, "ep_reward": 351.455078125, "reward": 0.8626343011856079, "action": -0.9149142503738403}
{"mode": "train", "epochs": 1, "timestep": 578, "ep_reward": 352.31005859375, "reward": 0.8549950122833252, "action": -0.7860280275344849}
{"mode": "train", "epochs": 1, "timestep": 579, "ep_reward": 353.1394958496094, "reward": 0.8294265866279602, "action": -1.5460631847381592}
{"mode": "train", "epochs": 1, "timestep": 580, "ep_reward": 353.9125061035156, "reward": 0.7730170488357544, "action": -0.35816049575805664}
{"mode": "train", "epochs": 1, "timestep": 581, "ep_reward": 354.6122131347656, "reward": 0.6997212171554565, "action": -0.7608422040939331}
{"mode": "train", "epochs": 1, "timestep": 582, "ep_reward": 355.1990966796875, "reward": 0.5868841409683228, "action": -1.450434923171997}
{"mode": "train", "epochs": 1, "timestep": 583, "ep_reward": 355.6217956542969, "reward": 0.42269963026046753, "action": -1.7526650428771973}
{"mode": "train", "epochs": 1, "timestep": 584, "ep_reward": 355.9305725097656, "reward": 0.30876433849334717, "action": -1.1121257543563843}
{"mode": "train", "epochs": 1, "timestep": 585, "ep_reward": 356.1214294433594, "reward": 0.19085878133773804, "action": -1.0182738304138184}
{"mode": "train", "epochs": 1, "timestep": 586, "ep_reward": 356.17431640625, "reward": 0.05290013551712036, "action": -1.298919439315796}
{"mode": "train", "epochs": 1, "timestep": 587, "ep_reward": 356.2396545410156, "reward": 0.06532806158065796, "action": -0.4012603163719177}
{"mode": "train", "epochs": 1, "timestep": 588, "ep_reward": 356.4496154785156, "reward": 0.209974467754364, "action": -0.9396509528160095}
{"mode": "train", "epochs": 1, "timestep": 589, "ep_reward": 356.7989501953125, "reward": 0.34934550523757935, "action": -0.7563462853431702}
{"mode": "train", "epochs": 1, "timestep": 590, "ep_reward": 357.28302001953125, "reward": 0.4840576648712158, "action": -0.8562600612640381}
{"mode": "train", "epochs": 1, "timestep": 591, "ep_reward": 357.8845520019531, "reward": 0.6015252470970154, "action": -0.14856266975402832}
{"mode": "train", "epochs": 1, "timestep": 592, "ep_reward": 358.5892639160156, "reward": 0.7047065496444702, "action": -1.1794637441635132}
{"mode": "train", "epochs": 1, "timestep": 593, "ep_reward": 359.3640441894531, "reward": 0.7747684121131897, "action": -1.291215181350708}
{"mode": "train", "epochs": 1, "timestep": 594, "ep_reward": 360.1883544921875, "reward": 0.8243127465248108, "action": -1.5666813850402832}
{"mode": "train", "epochs": 1, "timestep": 595, "ep_reward": 361.0428771972656, "reward": 0.8545081615447998, "action": -0.6329973936080933}
{"mode": "train", "epochs": 1, "timestep": 596, "ep_reward": 361.91937255859375, "reward": 0.8764930963516235, "action": -1.3755924701690674}
{"mode": "train", "epochs": 1, "timestep": 597, "ep_reward": 362.79705810546875, "reward": 0.8776842355728149, "action": -1.0315215587615967}
{"mode": "train", "epochs": 1, "timestep": 598, "ep_reward": 363.6631774902344, "reward": 0.8661048412322998, "action": -1.1421347856521606}
{"mode": "train", "epochs": 1, "timestep": 599, "ep_reward": 364.4986572265625, "reward": 0.8354677557945251, "action": -1.4145334959030151}
{"mode": "train", "epochs": 1, "timestep": 600, "ep_reward": 365.27777099609375, "reward": 0.7791224122047424, "action": -1.3608222007751465}
{"mode": "train", "epochs": 1, "timestep": 601, "ep_reward": 365.970703125, "reward": 0.6929302215576172, "action": -1.1476614475250244}
{"mode": "train", "epochs": 1, "timestep": 602, "ep_reward": 366.54241943359375, "reward": 0.5717271566390991, "action": -0.6956872940063477}
{"mode": "train", "epochs": 1, "timestep": 603, "ep_reward": 366.95782470703125, "reward": 0.4153934717178345, "action": -0.22573816776275635}
{"mode": "train", "epochs": 1, "timestep": 604, "ep_reward": 367.25750732421875, "reward": 0.29968392848968506, "action": -1.1530768871307373}
{"mode": "train", "epochs": 1, "timestep": 605, "ep_reward": 367.4376525878906, "reward": 0.1801580786705017, "action": -0.5932621955871582}
{"mode": "train", "epochs": 1, "timestep": 606, "ep_reward": 367.47808837890625, "reward": 0.04044830799102783, "action": -1.5229387283325195}
{"mode": "train", "epochs": 1, "timestep": 607, "ep_reward": 367.5555419921875, "reward": 0.0774490237236023, "action": -0.5962296724319458}
{"mode": "train", "epochs": 1, "timestep": 608, "ep_reward": 367.7755126953125, "reward": 0.21996355056762695, "action": -1.5234931707382202}
{"mode": "train", "epochs": 1, "timestep": 609, "ep_reward": 368.1278076171875, "reward": 0.35228490829467773, "action": -1.4091166257858276}
{"mode": "train", "epochs": 1, "timestep": 610, "ep_reward": 368.60784912109375, "reward": 0.48005563020706177, "action": -1.2830480337142944}
{"mode": "train", "epochs": 1, "timestep": 611, "ep_reward": 369.2018127441406, "reward": 0.593957781791687, "action": -1.0887469053268433}
{"mode": "train", "epochs": 1, "timestep": 612, "ep_reward": 369.89019775390625, "reward": 0.6883957982063293, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 613, "ep_reward": 370.64105224609375, "reward": 0.7508504390716553, "action": -0.8567357063293457}
{"mode": "train", "epochs": 1, "timestep": 614, "ep_reward": 371.44390869140625, "reward": 0.802860677242279, "action": -0.9938822388648987}
{"mode": "train", "epochs": 1, "timestep": 615, "ep_reward": 372.2763366699219, "reward": 0.8324360847473145, "action": -0.6930296421051025}
{"mode": "train", "epochs": 1, "timestep": 616, "ep_reward": 373.12158203125, "reward": 0.8452574014663696, "action": 0.1740483045578003}
{"mode": "train", "epochs": 1, "timestep": 617, "ep_reward": 373.96856689453125, "reward": 0.846980631351471, "action": -0.35661083459854126}
{"mode": "train", "epochs": 1, "timestep": 618, "ep_reward": 374.792724609375, "reward": 0.8241645097732544, "action": -1.0656087398529053}
{"mode": "train", "epochs": 1, "timestep": 619, "ep_reward": 375.56378173828125, "reward": 0.7710541486740112, "action": -0.33526140451431274}
{"mode": "train", "epochs": 1, "timestep": 620, "ep_reward": 376.2604675292969, "reward": 0.6966880559921265, "action": -0.7504841685295105}
{"mode": "train", "epochs": 1, "timestep": 621, "ep_reward": 376.8430480957031, "reward": 0.5825847387313843, "action": -1.1386356353759766}
{"mode": "train", "epochs": 1, "timestep": 622, "ep_reward": 377.2651672363281, "reward": 0.42211365699768066, "action": -0.9737343192100525}
{"mode": "train", "epochs": 1, "timestep": 623, "ep_reward": 377.5699768066406, "reward": 0.30480051040649414, "action": -0.7907311320304871}
{"mode": "train", "epochs": 1, "timestep": 624, "ep_reward": 377.7561340332031, "reward": 0.18615394830703735, "action": -0.6674529314041138}
{"mode": "train", "epochs": 1, "timestep": 625, "ep_reward": 377.8035583496094, "reward": 0.047427356243133545, "action": -1.2424569129943848}
{"mode": "train", "epochs": 1, "timestep": 626, "ep_reward": 377.874267578125, "reward": 0.07071566581726074, "action": -0.5001840591430664}
{"mode": "train", "epochs": 1, "timestep": 627, "ep_reward": 378.0885925292969, "reward": 0.21432465314865112, "action": -0.7320013642311096}
{"mode": "train", "epochs": 1, "timestep": 628, "ep_reward": 378.4448547363281, "reward": 0.35626304149627686, "action": -1.1977919340133667}
{"mode": "train", "epochs": 1, "timestep": 629, "ep_reward": 378.9298400878906, "reward": 0.48498040437698364, "action": -1.5892415046691895}
{"mode": "train", "epochs": 1, "timestep": 630, "ep_reward": 379.5241394042969, "reward": 0.5943037867546082, "action": -1.8759140968322754}
{"mode": "train", "epochs": 1, "timestep": 631, "ep_reward": 380.2054748535156, "reward": 0.6813499927520752, "action": -0.8287800550460815}
{"mode": "train", "epochs": 1, "timestep": 632, "ep_reward": 380.962890625, "reward": 0.7574093341827393, "action": -0.6788979768753052}
{"mode": "train", "epochs": 1, "timestep": 633, "ep_reward": 381.7751159667969, "reward": 0.8122225403785706, "action": -1.0931360721588135}
{"mode": "train", "epochs": 1, "timestep": 634, "ep_reward": 382.6184997558594, "reward": 0.8433791399002075, "action": -0.10944908857345581}
{"mode": "train", "epochs": 1, "timestep": 635, "ep_reward": 383.4836120605469, "reward": 0.8651080131530762, "action": -1.077186107635498}
{"mode": "train", "epochs": 1, "timestep": 636, "ep_reward": 384.34527587890625, "reward": 0.8616741895675659, "action": -0.9535055756568909}
{"mode": "train", "epochs": 1, "timestep": 637, "ep_reward": 385.1864929199219, "reward": 0.8412280082702637, "action": -1.5738105773925781}
{"mode": "train", "epochs": 1, "timestep": 638, "ep_reward": 385.9794616699219, "reward": 0.7929694056510925, "action": -1.2170517444610596}
{"mode": "train", "epochs": 1, "timestep": 639, "ep_reward": 386.6990966796875, "reward": 0.7196247577667236, "action": -1.1073760986328125}
{"mode": "train", "epochs": 1, "timestep": 640, "ep_reward": 387.31109619140625, "reward": 0.6120098829269409, "action": -1.1332930326461792}
{"mode": "train", "epochs": 1, "timestep": 641, "ep_reward": 387.7733459472656, "reward": 0.46224528551101685, "action": -1.0644510984420776}
{"mode": "train", "epochs": 1, "timestep": 642, "ep_reward": 388.1114807128906, "reward": 0.3381236791610718, "action": -1.4744902849197388}
{"mode": "train", "epochs": 1, "timestep": 643, "ep_reward": 388.3372497558594, "reward": 0.22576844692230225, "action": -1.6471450328826904}
{"mode": "train", "epochs": 1, "timestep": 644, "ep_reward": 388.43084716796875, "reward": 0.0935940146446228, "action": -0.5965991616249084}
{"mode": "train", "epochs": 1, "timestep": 645, "ep_reward": 388.454345703125, "reward": 0.02348881959915161, "action": -1.509462833404541}
{"mode": "train", "epochs": 1, "timestep": 646, "ep_reward": 388.6197814941406, "reward": 0.1654490828514099, "action": -0.5739649534225464}
{"mode": "train", "epochs": 1, "timestep": 647, "ep_reward": 388.93035888671875, "reward": 0.310577929019928, "action": -0.7656695246696472}
{"mode": "train", "epochs": 1, "timestep": 648, "ep_reward": 389.3785705566406, "reward": 0.4482209086418152, "action": -1.0623804330825806}
{"mode": "train", "epochs": 1, "timestep": 649, "ep_reward": 389.9471740722656, "reward": 0.5685913562774658, "action": -0.5051206350326538}
{"mode": "train", "epochs": 1, "timestep": 650, "ep_reward": 390.6221923828125, "reward": 0.6750217080116272, "action": -0.7486778497695923}
{"mode": "train", "epochs": 1, "timestep": 651, "ep_reward": 391.3777770996094, "reward": 0.7555954456329346, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 652, "ep_reward": 392.1820373535156, "reward": 0.8042629957199097, "action": -0.71927809715271}
{"mode": "train", "epochs": 1, "timestep": 653, "ep_reward": 393.0280456542969, "reward": 0.8460215330123901, "action": -0.9387351870536804}
{"mode": "train", "epochs": 1, "timestep": 654, "ep_reward": 393.8967590332031, "reward": 0.8687220215797424, "action": -1.472668170928955}
{"mode": "train", "epochs": 1, "timestep": 655, "ep_reward": 394.7684020996094, "reward": 0.8716530203819275, "action": -0.7371110916137695}
{"mode": "train", "epochs": 1, "timestep": 656, "ep_reward": 395.6330261230469, "reward": 0.8646160364151001, "action": -1.2808218002319336}
{"mode": "train", "epochs": 1, "timestep": 657, "ep_reward": 396.46771240234375, "reward": 0.8346827030181885, "action": -1.5080631971359253}
{"mode": "train", "epochs": 1, "timestep": 658, "ep_reward": 397.2468566894531, "reward": 0.7791429758071899, "action": -1.715019941329956}
{"mode": "train", "epochs": 1, "timestep": 659, "ep_reward": 397.93719482421875, "reward": 0.6903464794158936, "action": -0.27889126539230347}
{"mode": "train", "epochs": 1, "timestep": 660, "ep_reward": 398.5191345214844, "reward": 0.5819263458251953, "action": -1.4656635522842407}
{"mode": "train", "epochs": 1, "timestep": 661, "ep_reward": 398.9352111816406, "reward": 0.416067898273468, "action": -1.565279483795166}
{"mode": "train", "epochs": 1, "timestep": 662, "ep_reward": 399.2413635253906, "reward": 0.3061444163322449, "action": -0.8788155913352966}
{"mode": "train", "epochs": 1, "timestep": 663, "ep_reward": 399.428955078125, "reward": 0.18760353326797485, "action": -1.7001233100891113}
{"mode": "train", "epochs": 1, "timestep": 664, "ep_reward": 399.4783020019531, "reward": 0.04935503005981445, "action": -0.5740900039672852}
{"mode": "train", "epochs": 1, "timestep": 665, "ep_reward": 399.5471496582031, "reward": 0.06885480880737305, "action": -0.9871445894241333}
{"mode": "train", "epochs": 1, "timestep": 666, "ep_reward": 399.75347900390625, "reward": 0.20633000135421753, "action": -0.9300017356872559}
{"mode": "train", "epochs": 1, "timestep": 667, "ep_reward": 400.1005554199219, "reward": 0.3470853567123413, "action": -1.695418357849121}
{"mode": "train", "epochs": 1, "timestep": 668, "ep_reward": 400.5723876953125, "reward": 0.47182077169418335, "action": -0.5512107014656067}
{"mode": "train", "epochs": 1, "timestep": 669, "ep_reward": 401.1676330566406, "reward": 0.5952357649803162, "action": -0.481556236743927}
{"mode": "train", "epochs": 1, "timestep": 670, "ep_reward": 401.8636169433594, "reward": 0.6959854364395142, "action": -1.7463021278381348}
{"mode": "train", "epochs": 1, "timestep": 671, "ep_reward": 402.62432861328125, "reward": 0.7607053518295288, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 672, "ep_reward": 403.4273681640625, "reward": 0.8030360341072083, "action": -0.8980510830879211}
{"mode": "train", "epochs": 1, "timestep": 673, "ep_reward": 404.263427734375, "reward": 0.836066722869873, "action": -0.149652898311615}
{"mode": "train", "epochs": 1, "timestep": 674, "ep_reward": 405.1199951171875, "reward": 0.8565816283226013, "action": -1.9346702098846436}
{"mode": "train", "epochs": 1, "timestep": 675, "ep_reward": 405.9631652832031, "reward": 0.8431590795516968, "action": -1.3019139766693115}
{"mode": "train", "epochs": 1, "timestep": 676, "ep_reward": 406.77777099609375, "reward": 0.8146048784255981, "action": -0.45021653175354004}
{"mode": "train", "epochs": 1, "timestep": 677, "ep_reward": 407.5478820800781, "reward": 0.7701082825660706, "action": -0.35051482915878296}
{"mode": "train", "epochs": 1, "timestep": 678, "ep_reward": 408.2458801269531, "reward": 0.6980121731758118, "action": -0.8382249474525452}
{"mode": "train", "epochs": 1, "timestep": 679, "ep_reward": 408.83074951171875, "reward": 0.5848797559738159, "action": -0.42680007219314575}
{"mode": "train", "epochs": 1, "timestep": 680, "ep_reward": 409.2679138183594, "reward": 0.437172532081604, "action": -1.2287830114364624}
{"mode": "train", "epochs": 1, "timestep": 681, "ep_reward": 409.5826721191406, "reward": 0.3147734999656677, "action": -1.6253595352172852}
{"mode": "train", "epochs": 1, "timestep": 682, "ep_reward": 409.7807922363281, "reward": 0.1981337070465088, "action": -0.5959232449531555}
{"mode": "train", "epochs": 1, "timestep": 683, "ep_reward": 409.84210205078125, "reward": 0.061303555965423584, "action": -1.0533031225204468}
{"mode": "train", "epochs": 1, "timestep": 684, "ep_reward": 409.8990783691406, "reward": 0.05697774887084961, "action": -0.625564694404602}
{"mode": "train", "epochs": 1, "timestep": 685, "ep_reward": 410.09765625, "reward": 0.1985759139060974, "action": -0.9623429775238037}
{"mode": "train", "epochs": 1, "timestep": 686, "ep_reward": 410.4361572265625, "reward": 0.33849966526031494, "action": -0.1949988603591919}
{"mode": "train", "epochs": 1, "timestep": 687, "ep_reward": 410.91729736328125, "reward": 0.48113638162612915, "action": -0.39778709411621094}
{"mode": "train", "epochs": 1, "timestep": 688, "ep_reward": 411.5210876464844, "reward": 0.6037790775299072, "action": 0.12240099906921387}
{"mode": "train", "epochs": 1, "timestep": 689, "ep_reward": 412.2302551269531, "reward": 0.7091526389122009, "action": -0.9261681437492371}
{"mode": "train", "epochs": 1, "timestep": 690, "ep_reward": 413.0114440917969, "reward": 0.781201183795929, "action": -1.4844688177108765}
{"mode": "train", "epochs": 1, "timestep": 691, "ep_reward": 413.8410949707031, "reward": 0.8296475410461426, "action": -1.1203783750534058}
{"mode": "train", "epochs": 1, "timestep": 692, "ep_reward": 414.7058410644531, "reward": 0.8647547960281372, "action": -1.5086870193481445}
{"mode": "train", "epochs": 1, "timestep": 693, "ep_reward": 415.5884094238281, "reward": 0.8825613856315613, "action": -0.4642102122306824}
{"mode": "train", "epochs": 1, "timestep": 694, "ep_reward": 416.4832458496094, "reward": 0.8948268294334412, "action": -0.8647980093955994}
{"mode": "train", "epochs": 1, "timestep": 695, "ep_reward": 417.3741455078125, "reward": 0.8909032344818115, "action": -0.9190034866333008}
{"mode": "train", "epochs": 1, "timestep": 696, "ep_reward": 418.246337890625, "reward": 0.8722059726715088, "action": -1.0689964294433594}
{"mode": "train", "epochs": 1, "timestep": 697, "ep_reward": 419.0809631347656, "reward": 0.834633469581604, "action": -1.1013779640197754}
{"mode": "train", "epochs": 1, "timestep": 698, "ep_reward": 419.854736328125, "reward": 0.7737650871276855, "action": -0.9904606342315674}
{"mode": "train", "epochs": 1, "timestep": 699, "ep_reward": 420.5391845703125, "reward": 0.6844577789306641, "action": -0.7563945055007935}
{"mode": "train", "epochs": 1, "timestep": 700, "ep_reward": 421.1015319824219, "reward": 0.5623503923416138, "action": -0.198907732963562}
{"mode": "train", "epochs": 1, "timestep": 701, "ep_reward": 421.51190185546875, "reward": 0.4103715419769287, "action": -0.7714620232582092}
{"mode": "train", "epochs": 1, "timestep": 702, "ep_reward": 421.7857666015625, "reward": 0.273855984210968, "action": -0.1939084529876709}
{"mode": "train", "epochs": 1, "timestep": 703, "ep_reward": 421.9353942871094, "reward": 0.1496160626411438, "action": -0.6218069791793823}
{"mode": "train", "epochs": 1, "timestep": 704, "ep_reward": 421.94073486328125, "reward": 0.005351006984710693, "action": -1.0648483037948608}
{"mode": "train", "epochs": 1, "timestep": 705, "ep_reward": 422.051025390625, "reward": 0.1103021502494812, "action": -1.313575267791748}
{"mode": "train", "epochs": 1, "timestep": 706, "ep_reward": 422.29595947265625, "reward": 0.24493306875228882, "action": -1.109653353691101}
{"mode": "train", "epochs": 1, "timestep": 707, "ep_reward": 422.678955078125, "reward": 0.38300246000289917, "action": -1.2903594970703125}
{"mode": "train", "epochs": 1, "timestep": 708, "ep_reward": 423.1884460449219, "reward": 0.5094945430755615, "action": -0.5611754059791565}
{"mode": "train", "epochs": 1, "timestep": 709, "ep_reward": 423.8147277832031, "reward": 0.6262835264205933, "action": -1.8054924011230469}
{"mode": "train", "epochs": 1, "timestep": 710, "ep_reward": 424.521728515625, "reward": 0.7070039510726929, "action": -0.11189156770706177}
{"mode": "train", "epochs": 1, "timestep": 711, "ep_reward": 425.3040466308594, "reward": 0.7823041677474976, "action": 0.26753127574920654}
{"mode": "train", "epochs": 1, "timestep": 712, "ep_reward": 426.1417541503906, "reward": 0.8377144932746887, "action": -1.2620021104812622}
{"mode": "train", "epochs": 1, "timestep": 713, "ep_reward": 427.0028076171875, "reward": 0.861045777797699, "action": -1.3236134052276611}
{"mode": "train", "epochs": 1, "timestep": 714, "ep_reward": 427.8705139160156, "reward": 0.867711067199707, "action": -1.9749349355697632}
{"mode": "train", "epochs": 1, "timestep": 715, "ep_reward": 428.7227783203125, "reward": 0.852250874042511, "action": -0.4367336630821228}
{"mode": "train", "epochs": 1, "timestep": 716, "ep_reward": 429.5539855957031, "reward": 0.8312007188796997, "action": -0.4077168107032776}
{"mode": "train", "epochs": 1, "timestep": 717, "ep_reward": 430.3425598144531, "reward": 0.7885710000991821, "action": -0.8803178668022156}
{"mode": "train", "epochs": 1, "timestep": 718, "ep_reward": 431.0562744140625, "reward": 0.7137256860733032, "action": -0.6332366466522217}
{"mode": "train", "epochs": 1, "timestep": 719, "ep_reward": 431.663818359375, "reward": 0.6075398921966553, "action": -1.6299996376037598}
{"mode": "train", "epochs": 1, "timestep": 720, "ep_reward": 432.1109313964844, "reward": 0.4471026062965393, "action": 0.2223135232925415}
{"mode": "train", "epochs": 1, "timestep": 721, "ep_reward": 432.4322814941406, "reward": 0.3213508129119873, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 722, "ep_reward": 432.6383361816406, "reward": 0.20606666803359985, "action": -0.322807252407074}
{"mode": "train", "epochs": 1, "timestep": 723, "ep_reward": 432.7088623046875, "reward": 0.0705367922782898, "action": -0.37140578031539917}
{"mode": "train", "epochs": 1, "timestep": 724, "ep_reward": 432.7565612792969, "reward": 0.04771357774734497, "action": -0.03707385063171387}
{"mode": "train", "epochs": 1, "timestep": 725, "ep_reward": 432.9529113769531, "reward": 0.19634777307510376, "action": -0.5987545251846313}
{"mode": "train", "epochs": 1, "timestep": 726, "ep_reward": 433.2922668457031, "reward": 0.33935779333114624, "action": -0.579811692237854}
{"mode": "train", "epochs": 1, "timestep": 727, "ep_reward": 433.76824951171875, "reward": 0.47597259283065796, "action": -0.7081726789474487}
{"mode": "train", "epochs": 1, "timestep": 728, "ep_reward": 434.3639221191406, "reward": 0.5956840515136719, "action": -0.27524030208587646}
{"mode": "train", "epochs": 1, "timestep": 729, "ep_reward": 435.06280517578125, "reward": 0.6988906264305115, "action": -1.2681617736816406}
{"mode": "train", "epochs": 1, "timestep": 730, "ep_reward": 435.8333435058594, "reward": 0.7705368995666504, "action": -0.7456717491149902}
{"mode": "train", "epochs": 1, "timestep": 731, "ep_reward": 436.66070556640625, "reward": 0.8273698687553406, "action": -1.371949315071106}
{"mode": "train", "epochs": 1, "timestep": 732, "ep_reward": 437.52276611328125, "reward": 0.862068235874176, "action": -0.6979254484176636}
{"mode": "train", "epochs": 1, "timestep": 733, "ep_reward": 438.4101257324219, "reward": 0.8873451948165894, "action": -0.8950729370117188}
{"mode": "train", "epochs": 1, "timestep": 734, "ep_reward": 439.30810546875, "reward": 0.8979786038398743, "action": -0.5949727296829224}
{"mode": "train", "epochs": 1, "timestep": 735, "ep_reward": 440.2063903808594, "reward": 0.8982980251312256, "action": -0.9596812129020691}
{"mode": "train", "epochs": 1, "timestep": 736, "ep_reward": 441.0889892578125, "reward": 0.8826125860214233, "action": -1.0373941659927368}
{"mode": "train", "epochs": 1, "timestep": 737, "ep_reward": 441.939208984375, "reward": 0.8502121567726135, "action": -0.4070463180541992}
{"mode": "train", "epochs": 1, "timestep": 738, "ep_reward": 442.7424621582031, "reward": 0.8032526969909668, "action": -1.0664384365081787}
{"mode": "train", "epochs": 1, "timestep": 739, "ep_reward": 443.4665832519531, "reward": 0.7241357564926147, "action": -0.7375370860099792}
{"mode": "train", "epochs": 1, "timestep": 740, "ep_reward": 444.08233642578125, "reward": 0.6157436370849609, "action": -1.2790476083755493}
{"mode": "train", "epochs": 1, "timestep": 741, "ep_reward": 444.5440979003906, "reward": 0.4617704153060913, "action": -1.653712511062622}
{"mode": "train", "epochs": 1, "timestep": 742, "ep_reward": 444.85247802734375, "reward": 0.30837780237197876, "action": -0.7265253067016602}
{"mode": "train", "epochs": 1, "timestep": 743, "ep_reward": 445.04278564453125, "reward": 0.19029951095581055, "action": -1.3433918952941895}
{"mode": "train", "epochs": 1, "timestep": 744, "ep_reward": 445.0951843261719, "reward": 0.052400052547454834, "action": -0.46718525886535645}
{"mode": "train", "epochs": 1, "timestep": 745, "ep_reward": 445.16107177734375, "reward": 0.06587737798690796, "action": -0.8607475757598877}
{"mode": "train", "epochs": 1, "timestep": 746, "ep_reward": 445.3659362792969, "reward": 0.20487827062606812, "action": -0.3981279134750366}
{"mode": "train", "epochs": 1, "timestep": 747, "ep_reward": 445.7179260253906, "reward": 0.3519969582557678, "action": -1.084172248840332}
{"mode": "train", "epochs": 1, "timestep": 748, "ep_reward": 446.2005310058594, "reward": 0.4826194643974304, "action": 0.4693864583969116}
{"mode": "train", "epochs": 1, "timestep": 749, "ep_reward": 446.8150634765625, "reward": 0.6145317554473877, "action": -0.5050204992294312}
{"mode": "train", "epochs": 1, "timestep": 750, "ep_reward": 447.52679443359375, "reward": 0.711719274520874, "action": -0.9998816847801208}
{"mode": "train", "epochs": 1, "timestep": 751, "ep_reward": 448.30914306640625, "reward": 0.7823469042778015, "action": -1.130942702293396}
{"mode": "train", "epochs": 1, "timestep": 752, "ep_reward": 449.141845703125, "reward": 0.8326927423477173, "action": -1.4627596139907837}
{"mode": "train", "epochs": 1, "timestep": 753, "ep_reward": 450.0058288574219, "reward": 0.863972544670105, "action": -1.540090799331665}
{"mode": "train", "epochs": 1, "timestep": 754, "ep_reward": 450.8861083984375, "reward": 0.8802670836448669, "action": -1.6944741010665894}
{"mode": "train", "epochs": 1, "timestep": 755, "ep_reward": 451.7677001953125, "reward": 0.8815786242485046, "action": -1.176347255706787}
{"mode": "train", "epochs": 1, "timestep": 756, "ep_reward": 452.6397705078125, "reward": 0.8720718622207642, "action": -1.2520989179611206}
{"mode": "train", "epochs": 1, "timestep": 757, "ep_reward": 453.4844665527344, "reward": 0.8447080850601196, "action": -0.974956214427948}
{"mode": "train", "epochs": 1, "timestep": 758, "ep_reward": 454.2829284667969, "reward": 0.7984697818756104, "action": -1.0174206495285034}
{"mode": "train", "epochs": 1, "timestep": 759, "ep_reward": 455.0076599121094, "reward": 0.7247323989868164, "action": -1.0559008121490479}
{"mode": "train", "epochs": 1, "timestep": 760, "ep_reward": 455.6240539550781, "reward": 0.6164066791534424, "action": -0.5346493721008301}
{"mode": "train", "epochs": 1, "timestep": 761, "ep_reward": 456.099853515625, "reward": 0.475800096988678, "action": -1.1953142881393433}
{"mode": "train", "epochs": 1, "timestep": 762, "ep_reward": 456.4298095703125, "reward": 0.32995283603668213, "action": -0.08778876066207886}
{"mode": "train", "epochs": 1, "timestep": 763, "ep_reward": 456.645751953125, "reward": 0.21594500541687012, "action": -1.1015820503234863}
{"mode": "train", "epochs": 1, "timestep": 764, "ep_reward": 456.7278137207031, "reward": 0.08206403255462646, "action": -0.6210365295410156}
{"mode": "train", "epochs": 1, "timestep": 765, "ep_reward": 456.76361083984375, "reward": 0.03579521179199219, "action": -0.12240540981292725}
{"mode": "train", "epochs": 1, "timestep": 766, "ep_reward": 456.9465637207031, "reward": 0.18293887376785278, "action": -1.1444820165634155}
{"mode": "train", "epochs": 1, "timestep": 767, "ep_reward": 457.2663879394531, "reward": 0.3198096752166748, "action": -0.6043915152549744}
{"mode": "train", "epochs": 1, "timestep": 768, "ep_reward": 457.7251892089844, "reward": 0.458803653717041, "action": -1.0713804960250854}
{"mode": "train", "epochs": 1, "timestep": 769, "ep_reward": 458.3025817871094, "reward": 0.5773893594741821, "action": -1.7880911827087402}
{"mode": "train", "epochs": 1, "timestep": 770, "ep_reward": 458.9714660644531, "reward": 0.6688957214355469, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 771, "ep_reward": 459.7096252441406, "reward": 0.7381531000137329, "action": 0.23231995105743408}
{"mode": "train", "epochs": 1, "timestep": 772, "ep_reward": 460.5169982910156, "reward": 0.807363748550415, "action": -0.46760112047195435}
{"mode": "train", "epochs": 1, "timestep": 773, "ep_reward": 461.36553955078125, "reward": 0.8485279083251953, "action": -0.915378212928772}
{"mode": "train", "epochs": 1, "timestep": 774, "ep_reward": 462.2341003417969, "reward": 0.8685472011566162, "action": -0.8158807754516602}
{"mode": "train", "epochs": 1, "timestep": 775, "ep_reward": 463.1077575683594, "reward": 0.8736529350280762, "action": -0.8911795020103455}
{"mode": "train", "epochs": 1, "timestep": 776, "ep_reward": 463.9697265625, "reward": 0.8619832396507263, "action": -1.521298885345459}
{"mode": "train", "epochs": 1, "timestep": 777, "ep_reward": 464.7955627441406, "reward": 0.8258252143859863, "action": -1.7372496128082275}
{"mode": "train", "epochs": 1, "timestep": 778, "ep_reward": 465.5580139160156, "reward": 0.762461245059967, "action": -0.8419800400733948}
{"mode": "train", "epochs": 1, "timestep": 779, "ep_reward": 466.2350158691406, "reward": 0.6769939661026001, "action": -1.0633043050765991}
{"mode": "train", "epochs": 1, "timestep": 780, "ep_reward": 466.78607177734375, "reward": 0.551047682762146, "action": -1.849095106124878}
{"mode": "train", "epochs": 1, "timestep": 781, "ep_reward": 467.1728820800781, "reward": 0.38681817054748535, "action": -0.3496326208114624}
{"mode": "train", "epochs": 1, "timestep": 782, "ep_reward": 467.45733642578125, "reward": 0.284468412399292, "action": -0.49566370248794556}
{"mode": "train", "epochs": 1, "timestep": 783, "ep_reward": 467.6193542480469, "reward": 0.1620299220085144, "action": -1.337093472480774}
{"mode": "train", "epochs": 1, "timestep": 784, "ep_reward": 467.63897705078125, "reward": 0.019633352756500244, "action": -1.6296091079711914}
{"mode": "train", "epochs": 1, "timestep": 785, "ep_reward": 467.7361145019531, "reward": 0.09714502096176147, "action": -0.8996965289115906}
{"mode": "train", "epochs": 1, "timestep": 786, "ep_reward": 467.9726257324219, "reward": 0.23650425672531128, "action": -1.405109167098999}
{"mode": "train", "epochs": 1, "timestep": 787, "ep_reward": 468.3431396484375, "reward": 0.37050312757492065, "action": -0.5840035080909729}
{"mode": "train", "epochs": 1, "timestep": 788, "ep_reward": 468.8494567871094, "reward": 0.5063081979751587, "action": -1.3029494285583496}
{"mode": "train", "epochs": 1, "timestep": 789, "ep_reward": 469.46514892578125, "reward": 0.6156923770904541, "action": -0.5942713618278503}
{"mode": "train", "epochs": 1, "timestep": 790, "ep_reward": 470.17608642578125, "reward": 0.7109237313270569, "action": -1.3374500274658203}
{"mode": "train", "epochs": 1, "timestep": 791, "ep_reward": 470.9518737792969, "reward": 0.7758021354675293, "action": -0.4267149567604065}
{"mode": "train", "epochs": 1, "timestep": 792, "ep_reward": 471.7799072265625, "reward": 0.8280439376831055, "action": -1.9995617866516113}
{"mode": "train", "epochs": 1, "timestep": 793, "ep_reward": 472.6281433105469, "reward": 0.8482359647750854, "action": -0.41160714626312256}
{"mode": "train", "epochs": 1, "timestep": 794, "ep_reward": 473.4930419921875, "reward": 0.8649100065231323, "action": -1.9430465698242188}
{"mode": "train", "epochs": 1, "timestep": 795, "ep_reward": 474.344482421875, "reward": 0.8514401912689209, "action": -1.0970414876937866}
{"mode": "train", "epochs": 1, "timestep": 796, "ep_reward": 475.1701354980469, "reward": 0.8256460428237915, "action": -1.4767142534255981}
{"mode": "train", "epochs": 1, "timestep": 797, "ep_reward": 475.94219970703125, "reward": 0.7720606923103333, "action": -0.7619528770446777}
{"mode": "train", "epochs": 1, "timestep": 798, "ep_reward": 476.6379089355469, "reward": 0.695697009563446, "action": -1.778520107269287}
{"mode": "train", "epochs": 1, "timestep": 799, "ep_reward": 477.206787109375, "reward": 0.568874716758728, "action": -1.432060956954956}
{"mode": "train", "epochs": 1, "timestep": 800, "ep_reward": 477.61517333984375, "reward": 0.4083816409111023, "action": -1.6081475019454956}
{"mode": "train", "epochs": 1, "timestep": 801, "ep_reward": 477.9260559082031, "reward": 0.31089168787002563, "action": -1.4946844577789307}
{"mode": "train", "epochs": 1, "timestep": 802, "ep_reward": 478.11956787109375, "reward": 0.193500816822052, "action": -0.5433241128921509}
{"mode": "train", "epochs": 1, "timestep": 803, "ep_reward": 478.17547607421875, "reward": 0.0559079647064209, "action": -1.2587813138961792}
{"mode": "train", "epochs": 1, "timestep": 804, "ep_reward": 478.2378234863281, "reward": 0.06234860420227051, "action": -0.4823344349861145}
{"mode": "train", "epochs": 1, "timestep": 805, "ep_reward": 478.4437561035156, "reward": 0.20594459772109985, "action": -0.36942213773727417}
{"mode": "train", "epochs": 1, "timestep": 806, "ep_reward": 478.7962341308594, "reward": 0.35248178243637085, "action": -1.070999026298523}
{"mode": "train", "epochs": 1, "timestep": 807, "ep_reward": 479.27886962890625, "reward": 0.4826410412788391, "action": -0.53300541639328}
{"mode": "train", "epochs": 1, "timestep": 808, "ep_reward": 479.88250732421875, "reward": 0.603652834892273, "action": -0.42639613151550293}
{"mode": "train", "epochs": 1, "timestep": 809, "ep_reward": 480.5862121582031, "reward": 0.7037122249603271, "action": -1.5296597480773926}
{"mode": "train", "epochs": 1, "timestep": 810, "ep_reward": 481.3573913574219, "reward": 0.7711670398712158, "action": -1.4951789379119873}
{"mode": "train", "epochs": 1, "timestep": 811, "ep_reward": 482.1775207519531, "reward": 0.8201425075531006, "action": -0.8485228419303894}
{"mode": "train", "epochs": 1, "timestep": 812, "ep_reward": 483.03448486328125, "reward": 0.8569785356521606, "action": -1.4564613103866577}
{"mode": "train", "epochs": 1, "timestep": 813, "ep_reward": 483.9075012207031, "reward": 0.8730247616767883, "action": -1.6468772888183594}
{"mode": "train", "epochs": 1, "timestep": 814, "ep_reward": 484.7802429199219, "reward": 0.8727405071258545, "action": -0.3343677520751953}
{"mode": "train", "epochs": 1, "timestep": 815, "ep_reward": 485.6476745605469, "reward": 0.867445170879364, "action": -0.9008346796035767}
{"mode": "train", "epochs": 1, "timestep": 816, "ep_reward": 486.487548828125, "reward": 0.8398646116256714, "action": -0.6220611929893494}
{"mode": "train", "epochs": 1, "timestep": 817, "ep_reward": 487.2808837890625, "reward": 0.7933492660522461, "action": -1.6660664081573486}
{"mode": "train", "epochs": 1, "timestep": 818, "ep_reward": 487.9889221191406, "reward": 0.7080318927764893, "action": -0.5103883743286133}
{"mode": "train", "epochs": 1, "timestep": 819, "ep_reward": 488.5896301269531, "reward": 0.6006996631622314, "action": -0.4732484221458435}
{"mode": "train", "epochs": 1, "timestep": 820, "ep_reward": 489.0455017089844, "reward": 0.4558616876602173, "action": -1.1014714241027832}
{"mode": "train", "epochs": 1, "timestep": 821, "ep_reward": 489.36004638671875, "reward": 0.3145456314086914, "action": -0.15198743343353271}
{"mode": "train", "epochs": 1, "timestep": 822, "ep_reward": 489.5574951171875, "reward": 0.1974409818649292, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 823, "ep_reward": 489.6182861328125, "reward": 0.06077700853347778, "action": -0.9614598155021667}
{"mode": "train", "epochs": 1, "timestep": 824, "ep_reward": 489.6757507324219, "reward": 0.05747115612030029, "action": -1.0672736167907715}
{"mode": "train", "epochs": 1, "timestep": 825, "ep_reward": 489.8704528808594, "reward": 0.19470542669296265, "action": -1.501023769378662}
{"mode": "train", "epochs": 1, "timestep": 826, "ep_reward": 490.1992492675781, "reward": 0.3287851810455322, "action": -0.9096609354019165}
{"mode": "train", "epochs": 1, "timestep": 827, "ep_reward": 490.6644592285156, "reward": 0.4652109742164612, "action": -0.6763297319412231}
{"mode": "train", "epochs": 1, "timestep": 828, "ep_reward": 491.25244140625, "reward": 0.5879777669906616, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 829, "ep_reward": 491.9272155761719, "reward": 0.6747658848762512, "action": -1.2996253967285156}
{"mode": "train", "epochs": 1, "timestep": 830, "ep_reward": 492.674560546875, "reward": 0.7473528385162354, "action": -0.6449664235115051}
{"mode": "train", "epochs": 1, "timestep": 831, "ep_reward": 493.47821044921875, "reward": 0.8036472797393799, "action": -0.7811923623085022}
{"mode": "train", "epochs": 1, "timestep": 832, "ep_reward": 494.31573486328125, "reward": 0.8375183939933777, "action": -0.9453907012939453}
{"mode": "train", "epochs": 1, "timestep": 833, "ep_reward": 495.1667785644531, "reward": 0.8510445952415466, "action": -1.0237958431243896}
{"mode": "train", "epochs": 1, "timestep": 834, "ep_reward": 496.01220703125, "reward": 0.8454296588897705, "action": -1.1097087860107422}
{"mode": "train", "epochs": 1, "timestep": 835, "ep_reward": 496.8309020996094, "reward": 0.8186981081962585, "action": -1.159854531288147}
{"mode": "train", "epochs": 1, "timestep": 836, "ep_reward": 497.5976257324219, "reward": 0.7667129039764404, "action": -1.543062686920166}
{"mode": "train", "epochs": 1, "timestep": 837, "ep_reward": 498.2762451171875, "reward": 0.6786078810691833, "action": -1.672637939453125}
{"mode": "train", "epochs": 1, "timestep": 838, "ep_reward": 498.8242492675781, "reward": 0.5480098724365234, "action": -1.102817416191101}
{"mode": "train", "epochs": 1, "timestep": 839, "ep_reward": 499.2261047363281, "reward": 0.4018663763999939, "action": -1.6089308261871338}
{"mode": "train", "epochs": 1, "timestep": 840, "ep_reward": 499.5290832519531, "reward": 0.3029770851135254, "action": -1.0007524490356445}
{"mode": "train", "epochs": 1, "timestep": 841, "ep_reward": 499.7130126953125, "reward": 0.18394160270690918, "action": -1.3233959674835205}
{"mode": "train", "epochs": 1, "timestep": 842, "ep_reward": 499.758056640625, "reward": 0.045029401779174805, "action": -0.7255831360816956}
{"mode": "train", "epochs": 1, "timestep": 843, "ep_reward": 499.8311767578125, "reward": 0.0731351375579834, "action": 0.012613892555236816}
{"mode": "train", "epochs": 1, "timestep": 844, "ep_reward": 500.0543518066406, "reward": 0.22318017482757568, "action": -0.3468291163444519}
{"mode": "train", "epochs": 1, "timestep": 845, "ep_reward": 500.4226989746094, "reward": 0.36834466457366943, "action": -0.6710906028747559}
{"mode": "train", "epochs": 1, "timestep": 846, "ep_reward": 500.92340087890625, "reward": 0.5006963014602661, "action": -1.3593592643737793}
{"mode": "train", "epochs": 1, "timestep": 847, "ep_reward": 501.5330505371094, "reward": 0.6096489429473877, "action": -1.2021316289901733}
{"mode": "train", "epochs": 1, "timestep": 848, "ep_reward": 502.2342529296875, "reward": 0.7011922597885132, "action": -0.38753533363342285}
{"mode": "train", "epochs": 1, "timestep": 849, "ep_reward": 503.01324462890625, "reward": 0.778994083404541, "action": -1.2329272031784058}
{"mode": "train", "epochs": 1, "timestep": 850, "ep_reward": 503.8421630859375, "reward": 0.828907310962677, "action": -0.18357622623443604}
{"mode": "train", "epochs": 1, "timestep": 851, "ep_reward": 504.712158203125, "reward": 0.8700075149536133, "action": -1.0352182388305664}
{"mode": "train", "epochs": 1, "timestep": 852, "ep_reward": 505.60162353515625, "reward": 0.8894721269607544, "action": -1.0385737419128418}
{"mode": "train", "epochs": 1, "timestep": 853, "ep_reward": 506.4976501464844, "reward": 0.8960373401641846, "action": -0.3485448956489563}
{"mode": "train", "epochs": 1, "timestep": 854, "ep_reward": 507.39251708984375, "reward": 0.894866943359375, "action": -1.2638417482376099}
{"mode": "train", "epochs": 1, "timestep": 855, "ep_reward": 508.2652587890625, "reward": 0.8727543950080872, "action": -0.18951177597045898}
{"mode": "train", "epochs": 1, "timestep": 856, "ep_reward": 509.10784912109375, "reward": 0.842602550983429, "action": -0.24147671461105347}
{"mode": "train", "epochs": 1, "timestep": 857, "ep_reward": 509.89971923828125, "reward": 0.7918696999549866, "action": -1.4926936626434326}
{"mode": "train", "epochs": 1, "timestep": 858, "ep_reward": 510.60113525390625, "reward": 0.7014056444168091, "action": -0.31176960468292236}
{"mode": "train", "epochs": 1, "timestep": 859, "ep_reward": 511.19140625, "reward": 0.5902706384658813, "action": -1.1133110523223877}
{"mode": "train", "epochs": 1, "timestep": 860, "ep_reward": 511.6226806640625, "reward": 0.431272029876709, "action": -0.6026536822319031}
{"mode": "train", "epochs": 1, "timestep": 861, "ep_reward": 511.9067077636719, "reward": 0.2840399742126465, "action": -0.9407834410667419}
{"mode": "train", "epochs": 1, "timestep": 862, "ep_reward": 512.068359375, "reward": 0.16164922714233398, "action": -0.7461109161376953}
{"mode": "train", "epochs": 1, "timestep": 863, "ep_reward": 512.0875244140625, "reward": 0.01918208599090576, "action": -1.203152060508728}
{"mode": "train", "epochs": 1, "timestep": 864, "ep_reward": 512.1851196289062, "reward": 0.09762072563171387, "action": -1.020621657371521}
{"mode": "train", "epochs": 1, "timestep": 865, "ep_reward": 512.420654296875, "reward": 0.2355213761329651, "action": -1.207417368888855}
{"mode": "train", "epochs": 1, "timestep": 866, "ep_reward": 512.792724609375, "reward": 0.372093141078949, "action": -1.5232484340667725}
{"mode": "train", "epochs": 1, "timestep": 867, "ep_reward": 513.2894897460938, "reward": 0.49675554037094116, "action": -1.0126347541809082}
{"mode": "train", "epochs": 1, "timestep": 868, "ep_reward": 513.9004516601562, "reward": 0.6109572649002075, "action": -1.1256505250930786}
{"mode": "train", "epochs": 1, "timestep": 869, "ep_reward": 514.6019287109375, "reward": 0.7014767527580261, "action": -1.2807656526565552}
{"mode": "train", "epochs": 1, "timestep": 870, "ep_reward": 515.3692626953125, "reward": 0.7673294544219971, "action": -1.7457441091537476}
{"mode": "train", "epochs": 1, "timestep": 871, "ep_reward": 516.1768188476562, "reward": 0.8075306415557861, "action": -0.7559899091720581}
{"mode": "train", "epochs": 1, "timestep": 872, "ep_reward": 517.0137329101562, "reward": 0.836919367313385, "action": -0.9063851833343506}
{"mode": "train", "epochs": 1, "timestep": 873, "ep_reward": 517.859375, "reward": 0.8456452488899231, "action": -0.1554545760154724}
{"mode": "train", "epochs": 1, "timestep": 874, "ep_reward": 518.7014770507812, "reward": 0.8420793414115906, "action": -1.058721661567688}
{"mode": "train", "epochs": 1, "timestep": 875, "ep_reward": 519.5108032226562, "reward": 0.8093170523643494, "action": -0.46921348571777344}
{"mode": "train", "epochs": 1, "timestep": 876, "ep_reward": 520.2682495117188, "reward": 0.7574597597122192, "action": -0.4388408064842224}
{"mode": "train", "epochs": 1, "timestep": 877, "ep_reward": 520.9442138671875, "reward": 0.6759535074234009, "action": -1.3440381288528442}
{"mode": "train", "epochs": 1, "timestep": 878, "ep_reward": 521.489990234375, "reward": 0.5457608103752136, "action": -0.2948974370956421}
{"mode": "train", "epochs": 1, "timestep": 879, "ep_reward": 521.878662109375, "reward": 0.38869524002075195, "action": -1.1003702878952026}
{"mode": "train", "epochs": 1, "timestep": 880, "ep_reward": 522.1621704101562, "reward": 0.2834855318069458, "action": -0.7624839544296265}
{"mode": "train", "epochs": 1, "timestep": 881, "ep_reward": 522.3231811523438, "reward": 0.16100341081619263, "action": -0.28906750679016113}
{"mode": "train", "epochs": 1, "timestep": 882, "ep_reward": 522.3416748046875, "reward": 0.018473803997039795, "action": -0.5854753255844116}
{"mode": "train", "epochs": 1, "timestep": 883, "ep_reward": 522.4400634765625, "reward": 0.09839755296707153, "action": -0.41515713930130005}
{"mode": "train", "epochs": 1, "timestep": 884, "ep_reward": 522.6837768554688, "reward": 0.2436935305595398, "action": -1.899972915649414}
{"mode": "train", "epochs": 1, "timestep": 885, "ep_reward": 523.0541381835938, "reward": 0.370367169380188, "action": -1.451658010482788}
{"mode": "train", "epochs": 1, "timestep": 886, "ep_reward": 523.5502319335938, "reward": 0.4961189031600952, "action": -0.9358609914779663}
{"mode": "train", "epochs": 1, "timestep": 887, "ep_reward": 524.1615600585938, "reward": 0.6113035678863525, "action": -0.8525487780570984}
{"mode": "train", "epochs": 1, "timestep": 888, "ep_reward": 524.8660888671875, "reward": 0.7045483589172363, "action": -1.4538382291793823}
{"mode": "train", "epochs": 1, "timestep": 889, "ep_reward": 525.634765625, "reward": 0.7686498761177063, "action": -0.8243093490600586}
{"mode": "train", "epochs": 1, "timestep": 890, "ep_reward": 526.4521484375, "reward": 0.8173829317092896, "action": -1.256082534790039}
{"mode": "train", "epochs": 1, "timestep": 891, "ep_reward": 527.2946166992188, "reward": 0.8424884080886841, "action": -1.1969592571258545}
{"mode": "train", "epochs": 1, "timestep": 892, "ep_reward": 528.1444702148438, "reward": 0.8498567342758179, "action": -1.1620138883590698}
{"mode": "train", "epochs": 1, "timestep": 893, "ep_reward": 528.9832153320312, "reward": 0.838762640953064, "action": 0.22328251600265503}
{"mode": "train", "epochs": 1, "timestep": 894, "ep_reward": 529.803466796875, "reward": 0.8202723860740662, "action": -1.2093147039413452}
{"mode": "train", "epochs": 1, "timestep": 895, "ep_reward": 530.5673828125, "reward": 0.7638928890228271, "action": -0.7445549964904785}
{"mode": "train", "epochs": 1, "timestep": 896, "ep_reward": 531.2492065429688, "reward": 0.6818224191665649, "action": -0.8204729557037354}
{"mode": "train", "epochs": 1, "timestep": 897, "ep_reward": 531.811279296875, "reward": 0.5621012449264526, "action": -0.23810803890228271}
{"mode": "train", "epochs": 1, "timestep": 898, "ep_reward": 532.2218627929688, "reward": 0.41056954860687256, "action": -0.6233479976654053}
{"mode": "train", "epochs": 1, "timestep": 899, "ep_reward": 532.51708984375, "reward": 0.295243501663208, "action": -0.9560675024986267}
{"mode": "train", "epochs": 1, "timestep": 900, "ep_reward": 532.6919555664062, "reward": 0.17488282918930054, "action": -0.5387768149375916}
{"mode": "train", "epochs": 1, "timestep": 901, "ep_reward": 532.7263793945312, "reward": 0.03443664312362671, "action": -1.0162372589111328}
{"mode": "train", "epochs": 1, "timestep": 902, "ep_reward": 532.8096313476562, "reward": 0.08327656984329224, "action": -0.9018523693084717}
{"mode": "train", "epochs": 1, "timestep": 903, "ep_reward": 533.0317993164062, "reward": 0.22216469049453735, "action": -1.559217929840088}
{"mode": "train", "epochs": 1, "timestep": 904, "ep_reward": 533.386474609375, "reward": 0.35470277070999146, "action": -0.7702460289001465}
{"mode": "train", "epochs": 1, "timestep": 905, "ep_reward": 533.876708984375, "reward": 0.4902322292327881, "action": -0.8928565979003906}
{"mode": "train", "epochs": 1, "timestep": 906, "ep_reward": 534.4833984375, "reward": 0.6066843271255493, "action": -1.367518663406372}
{"mode": "train", "epochs": 1, "timestep": 907, "ep_reward": 535.1796264648438, "reward": 0.6962171792984009, "action": -0.6243206858634949}
{"mode": "train", "epochs": 1, "timestep": 908, "ep_reward": 535.9501342773438, "reward": 0.7705316543579102, "action": -1.220228672027588}
{"mode": "train", "epochs": 1, "timestep": 909, "ep_reward": 536.767578125, "reward": 0.8174437284469604, "action": -0.2675928473472595}
{"mode": "train", "epochs": 1, "timestep": 910, "ep_reward": 537.62109375, "reward": 0.8535184860229492, "action": -0.9248819351196289}
{"mode": "train", "epochs": 1, "timestep": 911, "ep_reward": 538.4876098632812, "reward": 0.8665114641189575, "action": -1.0479313135147095}
{"mode": "train", "epochs": 1, "timestep": 912, "ep_reward": 539.3494873046875, "reward": 0.8618891835212708, "action": -1.5847113132476807}
{"mode": "train", "epochs": 1, "timestep": 913, "ep_reward": 540.18359375, "reward": 0.8341353535652161, "action": -1.2047967910766602}
{"mode": "train", "epochs": 1, "timestep": 914, "ep_reward": 540.9705200195312, "reward": 0.7869415879249573, "action": -0.4977981448173523}
{"mode": "train", "epochs": 1, "timestep": 915, "ep_reward": 541.6897583007812, "reward": 0.7192299365997314, "action": -1.0747216939926147}
{"mode": "train", "epochs": 1, "timestep": 916, "ep_reward": 542.30029296875, "reward": 0.6105542182922363, "action": -1.3746238946914673}
{"mode": "train", "epochs": 1, "timestep": 917, "ep_reward": 542.7562255859375, "reward": 0.4559023380279541, "action": -1.0802124738693237}
{"mode": "train", "epochs": 1, "timestep": 918, "ep_reward": 543.088134765625, "reward": 0.33192330598831177, "action": -1.7587237358093262}
{"mode": "train", "epochs": 1, "timestep": 919, "ep_reward": 543.3067016601562, "reward": 0.2185693383216858, "action": -0.7404962778091431}
{"mode": "train", "epochs": 1, "timestep": 920, "ep_reward": 543.3916625976562, "reward": 0.0849732756614685, "action": -1.3738622665405273}
{"mode": "train", "epochs": 1, "timestep": 921, "ep_reward": 543.4242553710938, "reward": 0.03256303071975708, "action": -1.1788914203643799}
{"mode": "train", "epochs": 1, "timestep": 922, "ep_reward": 543.5974731445312, "reward": 0.17319554090499878, "action": -1.2501697540283203}
{"mode": "train", "epochs": 1, "timestep": 923, "ep_reward": 543.9075927734375, "reward": 0.3101039528846741, "action": -0.7935506105422974}
{"mode": "train", "epochs": 1, "timestep": 924, "ep_reward": 544.3562622070312, "reward": 0.4486667513847351, "action": -1.1667144298553467}
{"mode": "train", "epochs": 1, "timestep": 925, "ep_reward": 544.9246215820312, "reward": 0.5683320760726929, "action": -0.5057843327522278}
{"mode": "train", "epochs": 1, "timestep": 926, "ep_reward": 545.5993041992188, "reward": 0.67470383644104, "action": -0.6096541881561279}
{"mode": "train", "epochs": 1, "timestep": 927, "ep_reward": 546.355224609375, "reward": 0.7559184432029724, "action": -0.924004316329956}
{"mode": "train", "epochs": 1, "timestep": 928, "ep_reward": 547.1671142578125, "reward": 0.8118659853935242, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 929, "ep_reward": 548.007080078125, "reward": 0.8399488925933838, "action": -0.38072991371154785}
{"mode": "train", "epochs": 1, "timestep": 930, "ep_reward": 548.8718872070312, "reward": 0.8648294806480408, "action": -0.6588555574417114}
{"mode": "train", "epochs": 1, "timestep": 931, "ep_reward": 549.7427368164062, "reward": 0.8708740472793579, "action": -0.689201295375824}
{"mode": "train", "epochs": 1, "timestep": 932, "ep_reward": 550.60302734375, "reward": 0.8602923154830933, "action": -0.8685662746429443}
{"mode": "train", "epochs": 1, "timestep": 933, "ep_reward": 551.4324951171875, "reward": 0.8294907212257385, "action": -1.7159454822540283}
{"mode": "train", "epochs": 1, "timestep": 934, "ep_reward": 552.1991577148438, "reward": 0.7666504383087158, "action": -0.2057664394378662}
{"mode": "train", "epochs": 1, "timestep": 935, "ep_reward": 552.8889770507812, "reward": 0.6898269057273865, "action": -1.156983494758606}
{"mode": "train", "epochs": 1, "timestep": 936, "ep_reward": 553.455078125, "reward": 0.5661020278930664, "action": -0.6914972066879272}
{"mode": "train", "epochs": 1, "timestep": 937, "ep_reward": 553.8627319335938, "reward": 0.40762555599212646, "action": -1.7919763326644897}
{"mode": "train", "epochs": 1, "timestep": 938, "ep_reward": 554.152587890625, "reward": 0.2898697257041931, "action": -1.681051254272461}
{"mode": "train", "epochs": 1, "timestep": 939, "ep_reward": 554.3212280273438, "reward": 0.16867005825042725, "action": -0.7068260908126831}
{"mode": "train", "epochs": 1, "timestep": 940, "ep_reward": 554.3485107421875, "reward": 0.02727377414703369, "action": -1.153749942779541}
{"mode": "train", "epochs": 1, "timestep": 941, "ep_reward": 554.4384765625, "reward": 0.08999431133270264, "action": -1.3579190969467163}
{"mode": "train", "epochs": 1, "timestep": 942, "ep_reward": 554.6619873046875, "reward": 0.22348374128341675, "action": -1.0271939039230347}
{"mode": "train", "epochs": 1, "timestep": 943, "ep_reward": 555.0255126953125, "reward": 0.3635008931159973, "action": -0.5343922972679138}
{"mode": "train", "epochs": 1, "timestep": 944, "ep_reward": 555.5263061523438, "reward": 0.5008057355880737, "action": -0.8794405460357666}
{"mode": "train", "epochs": 1, "timestep": 945, "ep_reward": 556.1419677734375, "reward": 0.61568284034729, "action": -0.451138436794281}
{"mode": "train", "epochs": 1, "timestep": 946, "ep_reward": 556.8544921875, "reward": 0.7125264406204224, "action": -1.2634031772613525}
{"mode": "train", "epochs": 1, "timestep": 947, "ep_reward": 557.6328735351562, "reward": 0.7783704996109009, "action": -0.8131833672523499}
{"mode": "train", "epochs": 1, "timestep": 948, "ep_reward": 558.4609375, "reward": 0.8280816078186035, "action": -0.3482586741447449}
{"mode": "train", "epochs": 1, "timestep": 949, "ep_reward": 559.3240356445312, "reward": 0.863122284412384, "action": -1.2569503784179688}
{"mode": "train", "epochs": 1, "timestep": 950, "ep_reward": 560.19873046875, "reward": 0.8747141361236572, "action": -0.3987605571746826}
{"mode": "train", "epochs": 1, "timestep": 951, "ep_reward": 561.076904296875, "reward": 0.8781688213348389, "action": -0.424410343170166}
{"mode": "train", "epochs": 1, "timestep": 952, "ep_reward": 561.9427490234375, "reward": 0.8658400774002075, "action": -1.1978302001953125}
{"mode": "train", "epochs": 1, "timestep": 953, "ep_reward": 562.771484375, "reward": 0.828738808631897, "action": -0.8663641810417175}
{"mode": "train", "epochs": 1, "timestep": 954, "ep_reward": 563.5426025390625, "reward": 0.7711275815963745, "action": -1.9095137119293213}
{"mode": "train", "epochs": 1, "timestep": 955, "ep_reward": 564.2137451171875, "reward": 0.6711697578430176, "action": -1.1348540782928467}
{"mode": "train", "epochs": 1, "timestep": 956, "ep_reward": 564.7545166015625, "reward": 0.5408006906509399, "action": -1.044425129890442}
{"mode": "train", "epochs": 1, "timestep": 957, "ep_reward": 565.1295776367188, "reward": 0.3750684857368469, "action": -1.596738576889038}
{"mode": "train", "epochs": 1, "timestep": 958, "ep_reward": 565.3999633789062, "reward": 0.2703702449798584, "action": -0.7894618511199951}
{"mode": "train", "epochs": 1, "timestep": 959, "ep_reward": 565.5455322265625, "reward": 0.14556467533111572, "action": -0.6522156000137329}
{"mode": "train", "epochs": 1, "timestep": 960, "ep_reward": 565.5462036132812, "reward": 0.0006716251373291016, "action": -1.2801728248596191}
{"mode": "train", "epochs": 1, "timestep": 961, "ep_reward": 565.6608276367188, "reward": 0.11460608243942261, "action": -0.1606999635696411}
{"mode": "train", "epochs": 1, "timestep": 962, "ep_reward": 565.9244384765625, "reward": 0.2635829448699951, "action": -1.4151381254196167}
{"mode": "train", "epochs": 1, "timestep": 963, "ep_reward": 566.3194580078125, "reward": 0.3950181007385254, "action": -0.7041503190994263}
{"mode": "train", "epochs": 1, "timestep": 964, "ep_reward": 566.845458984375, "reward": 0.5259780883789062, "action": -0.28202152252197266}
{"mode": "train", "epochs": 1, "timestep": 965, "ep_reward": 567.4879760742188, "reward": 0.6425260305404663, "action": -1.2291499376296997}
{"mode": "train", "epochs": 1, "timestep": 966, "ep_reward": 568.214599609375, "reward": 0.7266184091567993, "action": -1.47389554977417}
{"mode": "train", "epochs": 1, "timestep": 967, "ep_reward": 569.0025024414062, "reward": 0.7878884077072144, "action": -1.0663540363311768}
{"mode": "train", "epochs": 1, "timestep": 968, "ep_reward": 569.836181640625, "reward": 0.8337070345878601, "action": -1.1812447309494019}
{"mode": "train", "epochs": 1, "timestep": 969, "ep_reward": 570.6974487304688, "reward": 0.8612897396087646, "action": -0.2249872088432312}
{"mode": "train", "epochs": 1, "timestep": 970, "ep_reward": 571.5781860351562, "reward": 0.8807446956634521, "action": -1.425687551498413}
{"mode": "train", "epochs": 1, "timestep": 971, "ep_reward": 572.453857421875, "reward": 0.8756424784660339, "action": -1.4569960832595825}
{"mode": "train", "epochs": 1, "timestep": 972, "ep_reward": 573.3077392578125, "reward": 0.853851854801178, "action": -0.3841668367385864}
{"mode": "train", "epochs": 1, "timestep": 973, "ep_reward": 574.1297607421875, "reward": 0.822028636932373, "action": -1.5046038627624512}
{"mode": "train", "epochs": 1, "timestep": 974, "ep_reward": 574.8848266601562, "reward": 0.7550920248031616, "action": -0.33401983976364136}
{"mode": "train", "epochs": 1, "timestep": 975, "ep_reward": 575.5546264648438, "reward": 0.6698125004768372, "action": -1.108266830444336}
{"mode": "train", "epochs": 1, "timestep": 976, "ep_reward": 576.0929565429688, "reward": 0.5383447408676147, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 977, "ep_reward": 576.46240234375, "reward": 0.36944466829299927, "action": -0.7470968961715698}
{"mode": "train", "epochs": 1, "timestep": 978, "ep_reward": 576.7257080078125, "reward": 0.2632836103439331, "action": -1.6617426872253418}
{"mode": "train", "epochs": 1, "timestep": 979, "ep_reward": 576.863037109375, "reward": 0.13731956481933594, "action": -1.3499689102172852}
{"mode": "train", "epochs": 1, "timestep": 980, "ep_reward": 576.8543090820312, "reward": -0.008750557899475098, "action": -1.6091707944869995}
{"mode": "train", "epochs": 1, "timestep": 981, "ep_reward": 576.9772338867188, "reward": 0.12290507555007935, "action": -0.9819320440292358}
{"mode": "train", "epochs": 1, "timestep": 982, "ep_reward": 577.2391967773438, "reward": 0.26195228099823, "action": -1.445068359375}
{"mode": "train", "epochs": 1, "timestep": 983, "ep_reward": 577.6338500976562, "reward": 0.3946530818939209, "action": -0.979378879070282}
{"mode": "train", "epochs": 1, "timestep": 984, "ep_reward": 578.1572265625, "reward": 0.5233548879623413, "action": -1.3295456171035767}
{"mode": "train", "epochs": 1, "timestep": 985, "ep_reward": 578.7868041992188, "reward": 0.629554271697998, "action": -0.8520278334617615}
{"mode": "train", "epochs": 1, "timestep": 986, "ep_reward": 579.5054321289062, "reward": 0.7186412811279297, "action": -1.1590783596038818}
{"mode": "train", "epochs": 1, "timestep": 987, "ep_reward": 580.286865234375, "reward": 0.7814476490020752, "action": -1.601812720298767}
{"mode": "train", "epochs": 1, "timestep": 988, "ep_reward": 581.1062622070312, "reward": 0.8194119930267334, "action": -1.4521547555923462}
{"mode": "train", "epochs": 1, "timestep": 989, "ep_reward": 581.9459838867188, "reward": 0.8397151827812195, "action": -1.4143903255462646}
{"mode": "train", "epochs": 1, "timestep": 990, "ep_reward": 582.7875366210938, "reward": 0.8415583968162537, "action": -1.0636060237884521}
{"mode": "train", "epochs": 1, "timestep": 991, "ep_reward": 583.6140747070312, "reward": 0.826531171798706, "action": -1.036346197128296}
{"mode": "train", "epochs": 1, "timestep": 992, "ep_reward": 584.4027709960938, "reward": 0.7887071371078491, "action": -0.6536654233932495}
{"mode": "train", "epochs": 1, "timestep": 993, "ep_reward": 585.1298217773438, "reward": 0.7270627617835999, "action": -1.3785749673843384}
{"mode": "train", "epochs": 1, "timestep": 994, "ep_reward": 585.7518310546875, "reward": 0.6220241189002991, "action": -1.489389419555664}
{"mode": "train", "epochs": 1, "timestep": 995, "ep_reward": 586.2236938476562, "reward": 0.47183698415756226, "action": -1.594102144241333}
{"mode": "train", "epochs": 1, "timestep": 996, "ep_reward": 586.580078125, "reward": 0.3564063310623169, "action": -1.2156238555908203}
{"mode": "train", "epochs": 1, "timestep": 997, "ep_reward": 586.827880859375, "reward": 0.2478088140487671, "action": 0.0278550386428833}
{"mode": "train", "epochs": 1, "timestep": 998, "ep_reward": 586.947021484375, "reward": 0.11911219358444214, "action": -0.3452383875846863}
{"mode": "train", "epochs": 1, "timestep": 999, "ep_reward": 586.9426879882812, "reward": -0.004354953765869141, "action": -1.2235757112503052}
{"mode": "train", "epochs": 1, "timestep": 1000, "ep_reward": 587.083740234375, "reward": 0.14104831218719482, "action": -1.583810806274414}
{"mode": "train", "epochs": 1, "timestep": 1001, "ep_reward": 587.3568725585938, "reward": 0.2731415033340454, "action": -0.8623981475830078}
{"mode": "train", "epochs": 1, "timestep": 1002, "ep_reward": 587.7704467773438, "reward": 0.41356009244918823, "action": -1.076409101486206}
{"mode": "train", "epochs": 1, "timestep": 1003, "ep_reward": 588.3095092773438, "reward": 0.5390462279319763, "action": -0.5292558670043945}
{"mode": "train", "epochs": 1, "timestep": 1004, "ep_reward": 588.96044921875, "reward": 0.6509352922439575, "action": 0.23300600051879883}
{"mode": "train", "epochs": 1, "timestep": 1005, "ep_reward": 589.7063598632812, "reward": 0.7459172010421753, "action": -0.5886132121086121}
{"mode": "train", "epochs": 1, "timestep": 1006, "ep_reward": 590.5152587890625, "reward": 0.8088892102241516, "action": -0.7835512161254883}
{"mode": "train", "epochs": 1, "timestep": 1007, "ep_reward": 591.3659057617188, "reward": 0.8506768345832825, "action": -1.0291250944137573}
{"mode": "train", "epochs": 1, "timestep": 1008, "ep_reward": 592.2399291992188, "reward": 0.8740195631980896, "action": -1.5520753860473633}
{"mode": "train", "epochs": 1, "timestep": 1009, "ep_reward": 593.1184692382812, "reward": 0.878559947013855, "action": -1.6867702007293701}
{"mode": "train", "epochs": 1, "timestep": 1010, "ep_reward": 593.9852905273438, "reward": 0.8668079972267151, "action": -0.8769643902778625}
{"mode": "train", "epochs": 1, "timestep": 1011, "ep_reward": 594.82958984375, "reward": 0.8442843556404114, "action": -0.6882108449935913}
{"mode": "train", "epochs": 1, "timestep": 1012, "ep_reward": 595.6322631835938, "reward": 0.8026568293571472, "action": -1.2901002168655396}
{"mode": "train", "epochs": 1, "timestep": 1013, "ep_reward": 596.3605346679688, "reward": 0.7283008098602295, "action": -1.044126272201538}
{"mode": "train", "epochs": 1, "timestep": 1014, "ep_reward": 596.9828491210938, "reward": 0.6223018169403076, "action": -0.9570231437683105}
{"mode": "train", "epochs": 1, "timestep": 1015, "ep_reward": 597.4602661132812, "reward": 0.47742754220962524, "action": -0.8476086854934692}
{"mode": "train", "epochs": 1, "timestep": 1016, "ep_reward": 597.7965698242188, "reward": 0.3362988233566284, "action": -1.3115923404693604}
{"mode": "train", "epochs": 1, "timestep": 1017, "ep_reward": 598.0203247070312, "reward": 0.22372502088546753, "action": -0.08446687459945679}
{"mode": "train", "epochs": 1, "timestep": 1018, "ep_reward": 598.1113891601562, "reward": 0.09104496240615845, "action": -0.0693521499633789}
{"mode": "train", "epochs": 1, "timestep": 1019, "ep_reward": 598.1377563476562, "reward": 0.02635502815246582, "action": -0.391133189201355}
{"mode": "train", "epochs": 1, "timestep": 1020, "ep_reward": 598.3076782226562, "reward": 0.16994106769561768, "action": 0.18803143501281738}
{"mode": "train", "epochs": 1, "timestep": 1021, "ep_reward": 598.6315307617188, "reward": 0.3238411545753479, "action": -1.521842122077942}
{"mode": "train", "epochs": 1, "timestep": 1022, "ep_reward": 599.081787109375, "reward": 0.45025551319122314, "action": -0.9911083579063416}
{"mode": "train", "epochs": 1, "timestep": 1023, "ep_reward": 599.6527709960938, "reward": 0.5709736943244934, "action": -0.6165287494659424}
{"mode": "train", "epochs": 1, "timestep": 1024, "ep_reward": 600.32861328125, "reward": 0.6758242845535278, "action": -0.7719947695732117}
{"mode": "train", "epochs": 1, "timestep": 1025, "ep_reward": 601.0848388671875, "reward": 0.7562194466590881, "action": -1.7168949842453003}
{"mode": "train", "epochs": 1, "timestep": 1026, "ep_reward": 601.8922729492188, "reward": 0.8074391484260559, "action": -1.3491430282592773}
{"mode": "train", "epochs": 1, "timestep": 1027, "ep_reward": 602.7363891601562, "reward": 0.8441394567489624, "action": -0.7127596139907837}
{"mode": "train", "epochs": 1, "timestep": 1028, "ep_reward": 603.6058959960938, "reward": 0.8694779872894287, "action": -0.20281147956848145}
{"mode": "train", "epochs": 1, "timestep": 1029, "ep_reward": 604.4893188476562, "reward": 0.8834235072135925, "action": -0.0423811674118042}
{"mode": "train", "epochs": 1, "timestep": 1030, "ep_reward": 605.373291015625, "reward": 0.8839955925941467, "action": -1.2776663303375244}
{"mode": "train", "epochs": 1, "timestep": 1031, "ep_reward": 606.232421875, "reward": 0.85910964012146, "action": -1.5638906955718994}
{"mode": "train", "epochs": 1, "timestep": 1032, "ep_reward": 607.0440063476562, "reward": 0.8116071224212646, "action": -0.5697858333587646}
{"mode": "train", "epochs": 1, "timestep": 1033, "ep_reward": 607.792236328125, "reward": 0.7482486963272095, "action": -0.7342987060546875}
{"mode": "train", "epochs": 1, "timestep": 1034, "ep_reward": 608.4446411132812, "reward": 0.6524117588996887, "action": -0.26125335693359375}
{"mode": "train", "epochs": 1, "timestep": 1035, "ep_reward": 608.9713134765625, "reward": 0.5266768932342529, "action": -1.1369833946228027}
{"mode": "train", "epochs": 1, "timestep": 1036, "ep_reward": 609.32275390625, "reward": 0.3514500856399536, "action": 0.4148848056793213}
{"mode": "train", "epochs": 1, "timestep": 1037, "ep_reward": 609.5645141601562, "reward": 0.24175333976745605, "action": 0.1736011505126953}
{"mode": "train", "epochs": 1, "timestep": 1038, "ep_reward": 609.6764526367188, "reward": 0.1119532585144043, "action": -1.2458412647247314}
{"mode": "train", "epochs": 1, "timestep": 1039, "ep_reward": 609.679931640625, "reward": 0.003498077392578125, "action": -1.328148365020752}
{"mode": "train", "epochs": 1, "timestep": 1040, "ep_reward": 609.827880859375, "reward": 0.14794468879699707, "action": -1.353270411491394}
{"mode": "train", "epochs": 1, "timestep": 1041, "ep_reward": 610.1110229492188, "reward": 0.28311288356781006, "action": -0.30886930227279663}
{"mode": "train", "epochs": 1, "timestep": 1042, "ep_reward": 610.540283203125, "reward": 0.42922985553741455, "action": -1.0775505304336548}
{"mode": "train", "epochs": 1, "timestep": 1043, "ep_reward": 611.09228515625, "reward": 0.5520119667053223, "action": -1.3791003227233887}
{"mode": "train", "epochs": 1, "timestep": 1044, "ep_reward": 611.7449340820312, "reward": 0.6526411771774292, "action": -0.0018478631973266602}
{"mode": "train", "epochs": 1, "timestep": 1045, "ep_reward": 612.48974609375, "reward": 0.7447815537452698, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1046, "ep_reward": 613.28515625, "reward": 0.7953861951828003, "action": -1.0213165283203125}
{"mode": "train", "epochs": 1, "timestep": 1047, "ep_reward": 614.1210327148438, "reward": 0.8358830213546753, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1048, "ep_reward": 614.9713134765625, "reward": 0.8502650260925293, "action": -1.6192712783813477}
{"mode": "train", "epochs": 1, "timestep": 1049, "ep_reward": 615.8219604492188, "reward": 0.8506622314453125, "action": -0.4708362817764282}
{"mode": "train", "epochs": 1, "timestep": 1050, "ep_reward": 616.6646728515625, "reward": 0.84270179271698, "action": -0.8227524757385254}
{"mode": "train", "epochs": 1, "timestep": 1051, "ep_reward": 617.4755249023438, "reward": 0.8108659982681274, "action": -0.749849796295166}
{"mode": "train", "epochs": 1, "timestep": 1052, "ep_reward": 618.2301635742188, "reward": 0.7546578645706177, "action": -1.2596710920333862}
{"mode": "train", "epochs": 1, "timestep": 1053, "ep_reward": 618.8910522460938, "reward": 0.6609170436859131, "action": -0.43864887952804565}
{"mode": "train", "epochs": 1, "timestep": 1054, "ep_reward": 619.4302368164062, "reward": 0.5392063856124878, "action": -1.2667673826217651}
{"mode": "train", "epochs": 1, "timestep": 1055, "ep_reward": 619.809814453125, "reward": 0.37955623865127563, "action": -1.090125322341919}
{"mode": "train", "epochs": 1, "timestep": 1056, "ep_reward": 620.08544921875, "reward": 0.2756553888320923, "action": -1.1987968683242798}
{"mode": "train", "epochs": 1, "timestep": 1057, "ep_reward": 620.2372436523438, "reward": 0.15181094408035278, "action": -0.8902513980865479}
{"mode": "train", "epochs": 1, "timestep": 1058, "ep_reward": 620.2451782226562, "reward": 0.007947921752929688, "action": -0.6752017736434937}
{"mode": "train", "epochs": 1, "timestep": 1059, "ep_reward": 620.3530883789062, "reward": 0.10793161392211914, "action": -1.561960220336914}
{"mode": "train", "epochs": 1, "timestep": 1060, "ep_reward": 620.5924682617188, "reward": 0.23940497636795044, "action": -1.017431378364563}
{"mode": "train", "epochs": 1, "timestep": 1061, "ep_reward": 620.9718627929688, "reward": 0.37938398122787476, "action": -0.8537214994430542}
{"mode": "train", "epochs": 1, "timestep": 1062, "ep_reward": 621.4833374023438, "reward": 0.5114949345588684, "action": -0.8916661739349365}
{"mode": "train", "epochs": 1, "timestep": 1063, "ep_reward": 622.1077880859375, "reward": 0.6244684457778931, "action": -1.0420691967010498}
{"mode": "train", "epochs": 1, "timestep": 1064, "ep_reward": 622.8209838867188, "reward": 0.7131795883178711, "action": -0.8271355628967285}
{"mode": "train", "epochs": 1, "timestep": 1065, "ep_reward": 623.6021118164062, "reward": 0.7811205387115479, "action": -0.6470981240272522}
{"mode": "train", "epochs": 1, "timestep": 1066, "ep_reward": 624.4313354492188, "reward": 0.8292039036750793, "action": -1.3734121322631836}
{"mode": "train", "epochs": 1, "timestep": 1067, "ep_reward": 625.2836303710938, "reward": 0.8523196578025818, "action": -1.1522893905639648}
{"mode": "train", "epochs": 1, "timestep": 1068, "ep_reward": 626.1439819335938, "reward": 0.860328733921051, "action": -1.0872657299041748}
{"mode": "train", "epochs": 1, "timestep": 1069, "ep_reward": 626.995361328125, "reward": 0.8513940572738647, "action": -1.3859562873840332}
{"mode": "train", "epochs": 1, "timestep": 1070, "ep_reward": 627.8151245117188, "reward": 0.8197541236877441, "action": -1.5636026859283447}
{"mode": "train", "epochs": 1, "timestep": 1071, "ep_reward": 628.5762329101562, "reward": 0.7610791325569153, "action": -0.30172181129455566}
{"mode": "train", "epochs": 1, "timestep": 1072, "ep_reward": 629.2615356445312, "reward": 0.6853060722351074, "action": -1.5055603981018066}
{"mode": "train", "epochs": 1, "timestep": 1073, "ep_reward": 629.8189697265625, "reward": 0.5574558973312378, "action": -0.6704075336456299}
{"mode": "train", "epochs": 1, "timestep": 1074, "ep_reward": 630.2169799804688, "reward": 0.3980230689048767, "action": 0.384044885635376}
{"mode": "train", "epochs": 1, "timestep": 1075, "ep_reward": 630.5145874023438, "reward": 0.2976042628288269, "action": -0.3223809599876404}
{"mode": "train", "epochs": 1, "timestep": 1076, "ep_reward": 630.692138671875, "reward": 0.17755591869354248, "action": -1.1101036071777344}
{"mode": "train", "epochs": 1, "timestep": 1077, "ep_reward": 630.7296752929688, "reward": 0.03754347562789917, "action": -1.339505910873413}
{"mode": "train", "epochs": 1, "timestep": 1078, "ep_reward": 630.8098754882812, "reward": 0.08022648096084595, "action": -1.090583324432373}
{"mode": "train", "epochs": 1, "timestep": 1079, "ep_reward": 631.0266723632812, "reward": 0.2167959213256836, "action": -0.6126794815063477}
{"mode": "train", "epochs": 1, "timestep": 1080, "ep_reward": 631.38818359375, "reward": 0.361480712890625, "action": -0.9821231961250305}
{"mode": "train", "epochs": 1, "timestep": 1081, "ep_reward": 631.8810424804688, "reward": 0.4928668141365051, "action": -1.319636344909668}
{"mode": "train", "epochs": 1, "timestep": 1082, "ep_reward": 632.4852294921875, "reward": 0.6041793823242188, "action": -0.7154619693756104}
{"mode": "train", "epochs": 1, "timestep": 1083, "ep_reward": 633.1860961914062, "reward": 0.7008680701255798, "action": -1.2218906879425049}
{"mode": "train", "epochs": 1, "timestep": 1084, "ep_reward": 633.9556884765625, "reward": 0.7695884108543396, "action": -0.7125828266143799}
{"mode": "train", "epochs": 1, "timestep": 1085, "ep_reward": 634.7777099609375, "reward": 0.8220173120498657, "action": -1.1117205619812012}
{"mode": "train", "epochs": 1, "timestep": 1086, "ep_reward": 635.6298217773438, "reward": 0.8521021008491516, "action": 0.00229644775390625}
{"mode": "train", "epochs": 1, "timestep": 1087, "ep_reward": 636.50439453125, "reward": 0.8745570778846741, "action": -1.3267682790756226}
{"mode": "train", "epochs": 1, "timestep": 1088, "ep_reward": 637.374755859375, "reward": 0.8703564405441284, "action": -0.7804250121116638}
{"mode": "train", "epochs": 1, "timestep": 1089, "ep_reward": 638.2286376953125, "reward": 0.8539095520973206, "action": -1.503970980644226}
{"mode": "train", "epochs": 1, "timestep": 1090, "ep_reward": 639.0394897460938, "reward": 0.8108712434768677, "action": -0.8816965818405151}
{"mode": "train", "epochs": 1, "timestep": 1091, "ep_reward": 639.7875366210938, "reward": 0.7480186820030212, "action": -0.6872563362121582}
{"mode": "train", "epochs": 1, "timestep": 1092, "ep_reward": 640.4434204101562, "reward": 0.6558692455291748, "action": -0.6890225410461426}
{"mode": "train", "epochs": 1, "timestep": 1093, "ep_reward": 640.9697875976562, "reward": 0.5263831615447998, "action": -1.6302077770233154}
{"mode": "train", "epochs": 1, "timestep": 1094, "ep_reward": 641.3330688476562, "reward": 0.3632988929748535, "action": -1.424472689628601}
{"mode": "train", "epochs": 1, "timestep": 1095, "ep_reward": 641.5892333984375, "reward": 0.2561485767364502, "action": 0.13670337200164795}
{"mode": "train", "epochs": 1, "timestep": 1096, "ep_reward": 641.718017578125, "reward": 0.12877905368804932, "action": -1.2350375652313232}
{"mode": "train", "epochs": 1, "timestep": 1097, "ep_reward": 641.7025756835938, "reward": -0.015418171882629395, "action": -1.3623874187469482}
{"mode": "train", "epochs": 1, "timestep": 1098, "ep_reward": 641.8340454101562, "reward": 0.1314811110496521, "action": -1.2464475631713867}
{"mode": "train", "epochs": 1, "timestep": 1099, "ep_reward": 642.1014404296875, "reward": 0.26740753650665283, "action": -1.7182880640029907}
{"mode": "train", "epochs": 1, "timestep": 1100, "ep_reward": 642.4984130859375, "reward": 0.3969835042953491, "action": -1.381590485572815}
{"mode": "train", "epochs": 1, "timestep": 1101, "ep_reward": 643.0197143554688, "reward": 0.5213245153427124, "action": -0.5894153118133545}
{"mode": "train", "epochs": 1, "timestep": 1102, "ep_reward": 643.6555786132812, "reward": 0.6358658671379089, "action": -0.4428672790527344}
{"mode": "train", "epochs": 1, "timestep": 1103, "ep_reward": 644.3827514648438, "reward": 0.7271592617034912, "action": -1.452977180480957}
{"mode": "train", "epochs": 1, "timestep": 1104, "ep_reward": 645.1676635742188, "reward": 0.7849118709564209, "action": -0.9694957733154297}
{"mode": "train", "epochs": 1, "timestep": 1105, "ep_reward": 645.9943237304688, "reward": 0.8266651034355164, "action": -0.2950040102005005}
{"mode": "train", "epochs": 1, "timestep": 1106, "ep_reward": 646.8494873046875, "reward": 0.8551686406135559, "action": -0.39646100997924805}
{"mode": "train", "epochs": 1, "timestep": 1107, "ep_reward": 647.7144775390625, "reward": 0.8649975657463074, "action": -1.535905122756958}
{"mode": "train", "epochs": 1, "timestep": 1108, "ep_reward": 648.5621337890625, "reward": 0.847649335861206, "action": -0.46721696853637695}
{"mode": "train", "epochs": 1, "timestep": 1109, "ep_reward": 649.382080078125, "reward": 0.8199378848075867, "action": -0.8195530772209167}
{"mode": "train", "epochs": 1, "timestep": 1110, "ep_reward": 650.1470947265625, "reward": 0.7650073170661926, "action": -0.9728277921676636}
{"mode": "train", "epochs": 1, "timestep": 1111, "ep_reward": 650.8250732421875, "reward": 0.6779732704162598, "action": -1.24038827419281}
{"mode": "train", "epochs": 1, "timestep": 1112, "ep_reward": 651.3746948242188, "reward": 0.5496248602867126, "action": -0.7456395626068115}
{"mode": "train", "epochs": 1, "timestep": 1113, "ep_reward": 651.760498046875, "reward": 0.38581883907318115, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1114, "ep_reward": 652.0433959960938, "reward": 0.28287529945373535, "action": -0.8377254605293274}
{"mode": "train", "epochs": 1, "timestep": 1115, "ep_reward": 652.2036743164062, "reward": 0.16029632091522217, "action": -0.28269094228744507}
{"mode": "train", "epochs": 1, "timestep": 1116, "ep_reward": 652.2213134765625, "reward": 0.017657160758972168, "action": -0.6566941738128662}
{"mode": "train", "epochs": 1, "timestep": 1117, "ep_reward": 652.3203735351562, "reward": 0.09905946254730225, "action": -1.258352279663086}
{"mode": "train", "epochs": 1, "timestep": 1118, "ep_reward": 652.554443359375, "reward": 0.23403984308242798, "action": -1.1998306512832642}
{"mode": "train", "epochs": 1, "timestep": 1119, "ep_reward": 652.92578125, "reward": 0.37131667137145996, "action": -1.071489691734314}
{"mode": "train", "epochs": 1, "timestep": 1120, "ep_reward": 653.4273071289062, "reward": 0.5015430450439453, "action": -1.3930363655090332}
{"mode": "train", "epochs": 1, "timestep": 1121, "ep_reward": 654.0379638671875, "reward": 0.6106778383255005, "action": -1.5473787784576416}
{"mode": "train", "epochs": 1, "timestep": 1122, "ep_reward": 654.7347412109375, "reward": 0.6967992782592773, "action": -1.2743057012557983}
{"mode": "train", "epochs": 1, "timestep": 1123, "ep_reward": 655.4978637695312, "reward": 0.7631357908248901, "action": -0.7438807487487793}
{"mode": "train", "epochs": 1, "timestep": 1124, "ep_reward": 656.3101196289062, "reward": 0.8122634887695312, "action": -0.9232006669044495}
{"mode": "train", "epochs": 1, "timestep": 1125, "ep_reward": 657.1489868164062, "reward": 0.8388838768005371, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1126, "ep_reward": 657.9856567382812, "reward": 0.8366726636886597, "action": -1.337841510772705}
{"mode": "train", "epochs": 1, "timestep": 1127, "ep_reward": 658.8055419921875, "reward": 0.8198888301849365, "action": -0.5144137144088745}
{"mode": "train", "epochs": 1, "timestep": 1128, "ep_reward": 659.5932006835938, "reward": 0.7876513004302979, "action": -1.4868779182434082}
{"mode": "train", "epochs": 1, "timestep": 1129, "ep_reward": 660.3094482421875, "reward": 0.7162642478942871, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1130, "ep_reward": 660.9097900390625, "reward": 0.6003201603889465, "action": -0.5910820960998535}
{"mode": "train", "epochs": 1, "timestep": 1131, "ep_reward": 661.3687133789062, "reward": 0.45890891551971436, "action": -1.0507020950317383}
{"mode": "train", "epochs": 1, "timestep": 1132, "ep_reward": 661.7213134765625, "reward": 0.3525813817977905, "action": -0.827464759349823}
{"mode": "train", "epochs": 1, "timestep": 1133, "ep_reward": 661.96435546875, "reward": 0.24306941032409668, "action": -1.1514253616333008}
{"mode": "train", "epochs": 1, "timestep": 1134, "ep_reward": 662.0780029296875, "reward": 0.11363387107849121, "action": -0.8672057390213013}
{"mode": "train", "epochs": 1, "timestep": 1135, "ep_reward": 662.0797729492188, "reward": 0.0017545819282531738, "action": -0.8783164620399475}
{"mode": "train", "epochs": 1, "timestep": 1136, "ep_reward": 662.2261352539062, "reward": 0.14636147022247314, "action": -1.4182618856430054}
{"mode": "train", "epochs": 1, "timestep": 1137, "ep_reward": 662.5067138671875, "reward": 0.28057944774627686, "action": -1.3288748264312744}
{"mode": "train", "epochs": 1, "timestep": 1138, "ep_reward": 662.9213256835938, "reward": 0.4146324396133423, "action": -1.237220048904419}
{"mode": "train", "epochs": 1, "timestep": 1139, "ep_reward": 663.4595947265625, "reward": 0.5382694005966187, "action": -1.3957560062408447}
{"mode": "train", "epochs": 1, "timestep": 1140, "ep_reward": 664.1005249023438, "reward": 0.6409518718719482, "action": -0.5417728424072266}
{"mode": "train", "epochs": 1, "timestep": 1141, "ep_reward": 664.830078125, "reward": 0.7295787334442139, "action": -1.38988196849823}
{"mode": "train", "epochs": 1, "timestep": 1142, "ep_reward": 665.6161499023438, "reward": 0.7860795855522156, "action": -0.5794402360916138}
{"mode": "train", "epochs": 1, "timestep": 1143, "ep_reward": 666.4452514648438, "reward": 0.8290863037109375, "action": -0.9452956914901733}
{"mode": "train", "epochs": 1, "timestep": 1144, "ep_reward": 667.2945556640625, "reward": 0.849309504032135, "action": -0.7982515692710876}
{"mode": "train", "epochs": 1, "timestep": 1145, "ep_reward": 668.1472778320312, "reward": 0.8527275323867798, "action": -0.12324732542037964}
{"mode": "train", "epochs": 1, "timestep": 1146, "ep_reward": 668.990966796875, "reward": 0.8436979055404663, "action": -1.1502715349197388}
{"mode": "train", "epochs": 1, "timestep": 1147, "ep_reward": 669.7953491210938, "reward": 0.8043788075447083, "action": -0.5988868474960327}
{"mode": "train", "epochs": 1, "timestep": 1148, "ep_reward": 670.5401000976562, "reward": 0.7447261214256287, "action": -0.22105157375335693}
{"mode": "train", "epochs": 1, "timestep": 1149, "ep_reward": 671.19873046875, "reward": 0.6586447954177856, "action": -0.9182799458503723}
{"mode": "train", "epochs": 1, "timestep": 1150, "ep_reward": 671.7257080078125, "reward": 0.5269566774368286, "action": -1.3868893384933472}
{"mode": "train", "epochs": 1, "timestep": 1151, "ep_reward": 672.0918579101562, "reward": 0.36613351106643677, "action": -1.3251333236694336}
{"mode": "train", "epochs": 1, "timestep": 1152, "ep_reward": 672.3513793945312, "reward": 0.2595332860946655, "action": -0.4885561466217041}
{"mode": "train", "epochs": 1, "timestep": 1153, "ep_reward": 672.4841918945312, "reward": 0.1328136920928955, "action": -0.8016334772109985}
{"mode": "train", "epochs": 1, "timestep": 1154, "ep_reward": 672.4702758789062, "reward": -0.013899803161621094, "action": -0.978492021560669}
{"mode": "train", "epochs": 1, "timestep": 1155, "ep_reward": 672.5978393554688, "reward": 0.12757223844528198, "action": -0.580127477645874}
{"mode": "train", "epochs": 1, "timestep": 1156, "ep_reward": 672.8696899414062, "reward": 0.2718347907066345, "action": -0.341084361076355}
{"mode": "train", "epochs": 1, "timestep": 1157, "ep_reward": 673.2862548828125, "reward": 0.416548490524292, "action": -0.6619799137115479}
{"mode": "train", "epochs": 1, "timestep": 1158, "ep_reward": 673.8308715820312, "reward": 0.5446425080299377, "action": -1.6343204975128174}
{"mode": "train", "epochs": 1, "timestep": 1159, "ep_reward": 674.4747314453125, "reward": 0.643879234790802, "action": -1.368546485900879}
{"mode": "train", "epochs": 1, "timestep": 1160, "ep_reward": 675.2007446289062, "reward": 0.7260382175445557, "action": -1.1742442846298218}
{"mode": "train", "epochs": 1, "timestep": 1161, "ep_reward": 675.9898071289062, "reward": 0.7890914678573608, "action": -0.9736276268959045}
{"mode": "train", "epochs": 1, "timestep": 1162, "ep_reward": 676.823974609375, "reward": 0.8341495990753174, "action": -0.9632997512817383}
{"mode": "train", "epochs": 1, "timestep": 1163, "ep_reward": 677.685546875, "reward": 0.8615702390670776, "action": -1.0153721570968628}
{"mode": "train", "epochs": 1, "timestep": 1164, "ep_reward": 678.5580444335938, "reward": 0.8725249171257019, "action": -1.1921722888946533}
{"mode": "train", "epochs": 1, "timestep": 1165, "ep_reward": 679.4241943359375, "reward": 0.8661456108093262, "action": -1.533074140548706}
{"mode": "train", "epochs": 1, "timestep": 1166, "ep_reward": 680.2630615234375, "reward": 0.8388778567314148, "action": -1.2739251852035522}
{"mode": "train", "epochs": 1, "timestep": 1167, "ep_reward": 681.0545654296875, "reward": 0.7914807796478271, "action": -1.0663864612579346}
{"mode": "train", "epochs": 1, "timestep": 1168, "ep_reward": 681.7724609375, "reward": 0.7179129123687744, "action": -0.8440607786178589}
{"mode": "train", "epochs": 1, "timestep": 1169, "ep_reward": 682.3846435546875, "reward": 0.6121950149536133, "action": -0.7497386932373047}
{"mode": "train", "epochs": 1, "timestep": 1170, "ep_reward": 682.8525390625, "reward": 0.46788084506988525, "action": -0.16962409019470215}
{"mode": "train", "epochs": 1, "timestep": 1171, "ep_reward": 683.1863403320312, "reward": 0.3338073492050171, "action": -0.5405968427658081}
{"mode": "train", "epochs": 1, "timestep": 1172, "ep_reward": 683.4069213867188, "reward": 0.22057658433914185, "action": -1.0329294204711914}
{"mode": "train", "epochs": 1, "timestep": 1173, "ep_reward": 683.4943237304688, "reward": 0.08742761611938477, "action": -0.7373709082603455}
{"mode": "train", "epochs": 1, "timestep": 1174, "ep_reward": 683.5244750976562, "reward": 0.030152618885040283, "action": -0.2381073236465454}
{"mode": "train", "epochs": 1, "timestep": 1175, "ep_reward": 683.7000732421875, "reward": 0.17562073469161987, "action": -1.5036792755126953}
{"mode": "train", "epochs": 1, "timestep": 1176, "ep_reward": 684.008544921875, "reward": 0.3084802031517029, "action": -0.4215136170387268}
{"mode": "train", "epochs": 1, "timestep": 1177, "ep_reward": 684.4598388671875, "reward": 0.45130985975265503, "action": -1.3874635696411133}
{"mode": "train", "epochs": 1, "timestep": 1178, "ep_reward": 685.0274658203125, "reward": 0.5676218271255493, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1179, "ep_reward": 685.6862182617188, "reward": 0.6587223410606384, "action": -0.6504902243614197}
{"mode": "train", "epochs": 1, "timestep": 1180, "ep_reward": 686.4286499023438, "reward": 0.7424533367156982, "action": -0.6606284976005554}
{"mode": "train", "epochs": 1, "timestep": 1181, "ep_reward": 687.2313842773438, "reward": 0.8027061223983765, "action": -0.6727265119552612}
{"mode": "train", "epochs": 1, "timestep": 1182, "ep_reward": 688.0734252929688, "reward": 0.8420453071594238, "action": -1.7195873260498047}
{"mode": "train", "epochs": 1, "timestep": 1183, "ep_reward": 688.9280395507812, "reward": 0.8546338081359863, "action": -0.6654455661773682}
{"mode": "train", "epochs": 1, "timestep": 1184, "ep_reward": 689.7871704101562, "reward": 0.8591296672821045, "action": -0.8705382943153381}
{"mode": "train", "epochs": 1, "timestep": 1185, "ep_reward": 690.6309204101562, "reward": 0.8437564373016357, "action": -1.2057087421417236}
{"mode": "train", "epochs": 1, "timestep": 1186, "ep_reward": 691.4351196289062, "reward": 0.8041779398918152, "action": -1.056734561920166}
{"mode": "train", "epochs": 1, "timestep": 1187, "ep_reward": 692.1744995117188, "reward": 0.7393912076950073, "action": -1.2080998420715332}
{"mode": "train", "epochs": 1, "timestep": 1188, "ep_reward": 692.8135986328125, "reward": 0.6391083002090454, "action": -1.3695018291473389}
{"mode": "train", "epochs": 1, "timestep": 1189, "ep_reward": 693.3087768554688, "reward": 0.49516427516937256, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1190, "ep_reward": 693.6687622070312, "reward": 0.35999858379364014, "action": -1.536156415939331}
{"mode": "train", "epochs": 1, "timestep": 1191, "ep_reward": 693.9209594726562, "reward": 0.2521904706954956, "action": -0.3479192852973938}
{"mode": "train", "epochs": 1, "timestep": 1192, "ep_reward": 694.045166015625, "reward": 0.12421387434005737, "action": -0.766810953617096}
{"mode": "train", "epochs": 1, "timestep": 1193, "ep_reward": 694.0350341796875, "reward": -0.010123014450073242, "action": -1.1364660263061523}
{"mode": "train", "epochs": 1, "timestep": 1194, "ep_reward": 694.1712036132812, "reward": 0.13616400957107544, "action": -0.177808940410614}
{"mode": "train", "epochs": 1, "timestep": 1195, "ep_reward": 694.456787109375, "reward": 0.2855857014656067, "action": -0.3217986226081848}
{"mode": "train", "epochs": 1, "timestep": 1196, "ep_reward": 694.8858032226562, "reward": 0.428999125957489, "action": -0.7460999488830566}
{"mode": "train", "epochs": 1, "timestep": 1197, "ep_reward": 695.440185546875, "reward": 0.5543749928474426, "action": -0.6505913138389587}
{"mode": "train", "epochs": 1, "timestep": 1198, "ep_reward": 696.1018676757812, "reward": 0.6616517901420593, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1199, "ep_reward": 696.8368530273438, "reward": 0.7350131869316101, "action": -0.0511401891708374}
{"mode": "train", "epochs": 1, "timestep": 1200, "ep_reward": 697.6433715820312, "reward": 0.80649334192276, "action": -0.8959993720054626}
{"mode": "train", "epochs": 1, "timestep": 1201, "ep_reward": 698.494140625, "reward": 0.8507521152496338, "action": -1.069091558456421}
{"mode": "train", "epochs": 1, "timestep": 1202, "ep_reward": 699.3719482421875, "reward": 0.8778241276741028, "action": -1.3980278968811035}
{"mode": "train", "epochs": 1, "timestep": 1203, "ep_reward": 700.2606811523438, "reward": 0.888761043548584, "action": -0.7814695835113525}
{"mode": "train", "epochs": 1, "timestep": 1204, "ep_reward": 701.1517333984375, "reward": 0.8910571336746216, "action": -0.9598628282546997}
{"mode": "train", "epochs": 1, "timestep": 1205, "ep_reward": 702.0296630859375, "reward": 0.8779435157775879, "action": -1.060682773590088}
{"mode": "train", "epochs": 1, "timestep": 1206, "ep_reward": 702.8770751953125, "reward": 0.8474071621894836, "action": -1.046037197113037}
{"mode": "train", "epochs": 1, "timestep": 1207, "ep_reward": 703.6729125976562, "reward": 0.7958111763000488, "action": -1.009549617767334}
{"mode": "train", "epochs": 1, "timestep": 1208, "ep_reward": 704.39013671875, "reward": 0.7172142267227173, "action": -0.9840293526649475}
{"mode": "train", "epochs": 1, "timestep": 1209, "ep_reward": 704.994873046875, "reward": 0.6047101020812988, "action": -0.7845795750617981}
{"mode": "train", "epochs": 1, "timestep": 1210, "ep_reward": 705.45068359375, "reward": 0.45578861236572266, "action": -0.46880680322647095}
{"mode": "train", "epochs": 1, "timestep": 1211, "ep_reward": 705.7615966796875, "reward": 0.3109009861946106, "action": -0.7021223306655884}
{"mode": "train", "epochs": 1, "timestep": 1212, "ep_reward": 705.9550170898438, "reward": 0.19339406490325928, "action": -0.3904574513435364}
{"mode": "train", "epochs": 1, "timestep": 1213, "ep_reward": 706.0108642578125, "reward": 0.05583161115646362, "action": -0.8430549502372742}
{"mode": "train", "epochs": 1, "timestep": 1214, "ep_reward": 706.0732421875, "reward": 0.06237435340881348, "action": -1.3635883331298828}
{"mode": "train", "epochs": 1, "timestep": 1215, "ep_reward": 706.2723388671875, "reward": 0.19910377264022827, "action": -0.4889755845069885}
{"mode": "train", "epochs": 1, "timestep": 1216, "ep_reward": 706.617919921875, "reward": 0.345564603805542, "action": -1.7964493036270142}
{"mode": "train", "epochs": 1, "timestep": 1217, "ep_reward": 707.0865478515625, "reward": 0.46861445903778076, "action": -1.7720040082931519}
{"mode": "train", "epochs": 1, "timestep": 1218, "ep_reward": 707.6652221679688, "reward": 0.5786640644073486, "action": -1.631935477256775}
{"mode": "train", "epochs": 1, "timestep": 1219, "ep_reward": 708.3357543945312, "reward": 0.6705602407455444, "action": -1.355062484741211}
{"mode": "train", "epochs": 1, "timestep": 1220, "ep_reward": 709.078369140625, "reward": 0.7426437139511108, "action": -0.7965806126594543}
{"mode": "train", "epochs": 1, "timestep": 1221, "ep_reward": 709.8754272460938, "reward": 0.797052800655365, "action": -1.3216489553451538}
{"mode": "train", "epochs": 1, "timestep": 1222, "ep_reward": 710.7002563476562, "reward": 0.8248192071914673, "action": -1.1163278818130493}
{"mode": "train", "epochs": 1, "timestep": 1223, "ep_reward": 711.5346069335938, "reward": 0.834324836730957, "action": -1.1077361106872559}
{"mode": "train", "epochs": 1, "timestep": 1224, "ep_reward": 712.3577880859375, "reward": 0.8231915235519409, "action": -0.8773608207702637}
{"mode": "train", "epochs": 1, "timestep": 1225, "ep_reward": 713.14892578125, "reward": 0.7911430597305298, "action": -0.8039454221725464}
{"mode": "train", "epochs": 1, "timestep": 1226, "ep_reward": 713.8811645507812, "reward": 0.7322343587875366, "action": -1.4280120134353638}
{"mode": "train", "epochs": 1, "timestep": 1227, "ep_reward": 714.5123901367188, "reward": 0.6312052011489868, "action": -1.1026971340179443}
{"mode": "train", "epochs": 1, "timestep": 1228, "ep_reward": 715.0040283203125, "reward": 0.49164003133773804, "action": -1.6023409366607666}
{"mode": "train", "epochs": 1, "timestep": 1229, "ep_reward": 715.3744506835938, "reward": 0.3704236149787903, "action": -0.5389608144760132}
{"mode": "train", "epochs": 1, "timestep": 1230, "ep_reward": 715.6389770507812, "reward": 0.2645305395126343, "action": -1.1902862787246704}
{"mode": "train", "epochs": 1, "timestep": 1231, "ep_reward": 715.7776489257812, "reward": 0.1386779546737671, "action": -1.379998803138733}
{"mode": "train", "epochs": 1, "timestep": 1232, "ep_reward": 715.7705078125, "reward": -0.007161617279052734, "action": -1.4812958240509033}
{"mode": "train", "epochs": 1, "timestep": 1233, "ep_reward": 715.8920288085938, "reward": 0.12151730060577393, "action": -0.9900312423706055}
{"mode": "train", "epochs": 1, "timestep": 1234, "ep_reward": 716.1524658203125, "reward": 0.26046222448349, "action": -1.2356860637664795}
{"mode": "train", "epochs": 1, "timestep": 1235, "ep_reward": 716.5482788085938, "reward": 0.39578771591186523, "action": -0.9057643413543701}
{"mode": "train", "epochs": 1, "timestep": 1236, "ep_reward": 717.0732421875, "reward": 0.5249873995780945, "action": -1.4293365478515625}
{"mode": "train", "epochs": 1, "timestep": 1237, "ep_reward": 717.7030639648438, "reward": 0.6298197507858276, "action": -1.0475865602493286}
{"mode": "train", "epochs": 1, "timestep": 1238, "ep_reward": 718.4202270507812, "reward": 0.7171459794044495, "action": -0.5197399854660034}
{"mode": "train", "epochs": 1, "timestep": 1239, "ep_reward": 719.2067260742188, "reward": 0.7864837050437927, "action": -0.9975726008415222}
{"mode": "train", "epochs": 1, "timestep": 1240, "ep_reward": 720.0367431640625, "reward": 0.830024778842926, "action": 0.2985450029373169}
{"mode": "train", "epochs": 1, "timestep": 1241, "ep_reward": 720.9027099609375, "reward": 0.8659891486167908, "action": -0.836944580078125}
{"mode": "train", "epochs": 1, "timestep": 1242, "ep_reward": 721.7786254882812, "reward": 0.8758912086486816, "action": -0.530537486076355}
{"mode": "train", "epochs": 1, "timestep": 1243, "ep_reward": 722.6514892578125, "reward": 0.8728898167610168, "action": -0.9439173340797424}
{"mode": "train", "epochs": 1, "timestep": 1244, "ep_reward": 723.501220703125, "reward": 0.8497213125228882, "action": -1.0848528146743774}
{"mode": "train", "epochs": 1, "timestep": 1245, "ep_reward": 724.305908203125, "reward": 0.8046888113021851, "action": -0.9843776226043701}
{"mode": "train", "epochs": 1, "timestep": 1246, "ep_reward": 725.0401611328125, "reward": 0.7342244386672974, "action": -1.0144314765930176}
{"mode": "train", "epochs": 1, "timestep": 1247, "ep_reward": 725.6702270507812, "reward": 0.6300909519195557, "action": -1.4605255126953125}
{"mode": "train", "epochs": 1, "timestep": 1248, "ep_reward": 726.1497802734375, "reward": 0.4795781970024109, "action": -1.4952285289764404}
{"mode": "train", "epochs": 1, "timestep": 1249, "ep_reward": 726.4879150390625, "reward": 0.3381408452987671, "action": -0.7320050001144409}
{"mode": "train", "epochs": 1, "timestep": 1250, "ep_reward": 726.7135009765625, "reward": 0.22558844089508057, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1251, "ep_reward": 726.8067626953125, "reward": 0.09328895807266235, "action": -1.8510668277740479}
{"mode": "train", "epochs": 1, "timestep": 1252, "ep_reward": 726.830322265625, "reward": 0.02356332540512085, "action": -1.724135160446167}
{"mode": "train", "epochs": 1, "timestep": 1253, "ep_reward": 726.9957885742188, "reward": 0.16544800996780396, "action": -1.3938243389129639}
{"mode": "train", "epochs": 1, "timestep": 1254, "ep_reward": 727.2962646484375, "reward": 0.30046558380126953, "action": -0.4091259241104126}
{"mode": "train", "epochs": 1, "timestep": 1255, "ep_reward": 727.7406616210938, "reward": 0.4443851113319397, "action": -1.6178842782974243}
{"mode": "train", "epochs": 1, "timestep": 1256, "ep_reward": 728.300048828125, "reward": 0.5593726634979248, "action": -0.9771385788917542}
{"mode": "train", "epochs": 1, "timestep": 1257, "ep_reward": 728.9625854492188, "reward": 0.6625592708587646, "action": -1.090303659439087}
{"mode": "train", "epochs": 1, "timestep": 1258, "ep_reward": 729.7041625976562, "reward": 0.7415602207183838, "action": -0.9682981371879578}
{"mode": "train", "epochs": 1, "timestep": 1259, "ep_reward": 730.503662109375, "reward": 0.799470067024231, "action": -0.9213019609451294}
{"mode": "train", "epochs": 1, "timestep": 1260, "ep_reward": 731.3410034179688, "reward": 0.8373647332191467, "action": -1.5925778150558472}
{"mode": "train", "epochs": 1, "timestep": 1261, "ep_reward": 732.1923217773438, "reward": 0.8513318300247192, "action": -0.8818380832672119}
{"mode": "train", "epochs": 1, "timestep": 1262, "ep_reward": 733.046142578125, "reward": 0.8538320064544678, "action": -1.0572001934051514}
{"mode": "train", "epochs": 1, "timestep": 1263, "ep_reward": 733.882080078125, "reward": 0.835944652557373, "action": -1.1464500427246094}
{"mode": "train", "epochs": 1, "timestep": 1264, "ep_reward": 734.677001953125, "reward": 0.7948994636535645, "action": -1.8888914585113525}
{"mode": "train", "epochs": 1, "timestep": 1265, "ep_reward": 735.39404296875, "reward": 0.7170344591140747, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1266, "ep_reward": 735.9929809570312, "reward": 0.5989136695861816, "action": -0.8167999982833862}
{"mode": "train", "epochs": 1, "timestep": 1267, "ep_reward": 736.445068359375, "reward": 0.4520631432533264, "action": -1.3341965675354004}
{"mode": "train", "epochs": 1, "timestep": 1268, "ep_reward": 736.7890625, "reward": 0.3439728021621704, "action": -1.1178760528564453}
{"mode": "train", "epochs": 1, "timestep": 1269, "ep_reward": 737.0217895507812, "reward": 0.23272383213043213, "action": -1.5286577939987183}
{"mode": "train", "epochs": 1, "timestep": 1270, "ep_reward": 737.1234130859375, "reward": 0.10164809226989746, "action": -0.8138691186904907}
{"mode": "train", "epochs": 1, "timestep": 1271, "ep_reward": 737.1383056640625, "reward": 0.014908432960510254, "action": -0.7967662811279297}
{"mode": "train", "epochs": 1, "timestep": 1272, "ep_reward": 737.2962036132812, "reward": 0.1579234004020691, "action": 0.03857314586639404}
{"mode": "train", "epochs": 1, "timestep": 1273, "ep_reward": 737.6066284179688, "reward": 0.3104318380355835, "action": -0.6203385591506958}
{"mode": "train", "epochs": 1, "timestep": 1274, "ep_reward": 738.0551147460938, "reward": 0.44848811626434326, "action": -1.7228333950042725}
{"mode": "train", "epochs": 1, "timestep": 1275, "ep_reward": 738.615966796875, "reward": 0.5608587265014648, "action": -1.538055658340454}
{"mode": "train", "epochs": 1, "timestep": 1276, "ep_reward": 739.2741088867188, "reward": 0.6581254601478577, "action": -1.67647385597229}
{"mode": "train", "epochs": 1, "timestep": 1277, "ep_reward": 740.0076293945312, "reward": 0.7335237860679626, "action": -0.08296024799346924}
{"mode": "train", "epochs": 1, "timestep": 1278, "ep_reward": 740.8101806640625, "reward": 0.8025715947151184, "action": -0.5700792074203491}
{"mode": "train", "epochs": 1, "timestep": 1279, "ep_reward": 741.6561279296875, "reward": 0.8459317088127136, "action": -1.4550726413726807}
{"mode": "train", "epochs": 1, "timestep": 1280, "ep_reward": 742.52099609375, "reward": 0.8648623824119568, "action": 0.4177941679954529}
{"mode": "train", "epochs": 1, "timestep": 1281, "ep_reward": 743.4044189453125, "reward": 0.8834173679351807, "action": -1.224486231803894}
{"mode": "train", "epochs": 1, "timestep": 1282, "ep_reward": 744.278076171875, "reward": 0.8736741542816162, "action": -0.9974169731140137}
{"mode": "train", "epochs": 1, "timestep": 1283, "ep_reward": 745.1270141601562, "reward": 0.8489176034927368, "action": -1.3078984022140503}
{"mode": "train", "epochs": 1, "timestep": 1284, "ep_reward": 745.9273681640625, "reward": 0.8003669381141663, "action": -0.741667628288269}
{"mode": "train", "epochs": 1, "timestep": 1285, "ep_reward": 746.6578369140625, "reward": 0.7304843068122864, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1286, "ep_reward": 747.2691040039062, "reward": 0.6112737655639648, "action": -1.0808138847351074}
{"mode": "train", "epochs": 1, "timestep": 1287, "ep_reward": 747.730224609375, "reward": 0.4611056447029114, "action": -0.3334527611732483}
{"mode": "train", "epochs": 1, "timestep": 1288, "ep_reward": 748.0596923828125, "reward": 0.3294820189476013, "action": -0.4441547989845276}
{"mode": "train", "epochs": 1, "timestep": 1289, "ep_reward": 748.275146484375, "reward": 0.21545040607452393, "action": -0.6392017602920532}
{"mode": "train", "epochs": 1, "timestep": 1290, "ep_reward": 748.3563842773438, "reward": 0.08126658201217651, "action": -1.7503598928451538}
{"mode": "train", "epochs": 1, "timestep": 1291, "ep_reward": 748.392822265625, "reward": 0.03644156455993652, "action": -0.3783564567565918}
{"mode": "train", "epochs": 1, "timestep": 1292, "ep_reward": 748.5733032226562, "reward": 0.18050092458724976, "action": -0.3943282961845398}
{"mode": "train", "epochs": 1, "timestep": 1293, "ep_reward": 748.9004516601562, "reward": 0.3271210193634033, "action": -1.1194298267364502}
{"mode": "train", "epochs": 1, "timestep": 1294, "ep_reward": 749.3591918945312, "reward": 0.4587211012840271, "action": -1.3236515522003174}
{"mode": "train", "epochs": 1, "timestep": 1295, "ep_reward": 749.9337768554688, "reward": 0.574608325958252, "action": -1.5429296493530273}
{"mode": "train", "epochs": 1, "timestep": 1296, "ep_reward": 750.6028442382812, "reward": 0.6690750122070312, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1297, "ep_reward": 751.3409423828125, "reward": 0.7381136417388916, "action": -1.5362825393676758}
{"mode": "train", "epochs": 1, "timestep": 1298, "ep_reward": 752.1319580078125, "reward": 0.7910455465316772, "action": -0.8366624116897583}
{"mode": "train", "epochs": 1, "timestep": 1299, "ep_reward": 752.9619140625, "reward": 0.829984188079834, "action": -0.8810850977897644}
{"mode": "train", "epochs": 1, "timestep": 1300, "ep_reward": 753.8112182617188, "reward": 0.8492912650108337, "action": -0.11893528699874878}
{"mode": "train", "epochs": 1, "timestep": 1301, "ep_reward": 754.6683959960938, "reward": 0.8571856617927551, "action": -0.5077188014984131}
{"mode": "train", "epochs": 1, "timestep": 1302, "ep_reward": 755.5118408203125, "reward": 0.8434284329414368, "action": -0.05895650386810303}
{"mode": "train", "epochs": 1, "timestep": 1303, "ep_reward": 756.32568359375, "reward": 0.8138723373413086, "action": -0.67768394947052}
{"mode": "train", "epochs": 1, "timestep": 1304, "ep_reward": 757.0798950195312, "reward": 0.7542109489440918, "action": -1.0981791019439697}
{"mode": "train", "epochs": 1, "timestep": 1305, "ep_reward": 757.7384643554688, "reward": 0.6585782766342163, "action": -1.3187808990478516}
{"mode": "train", "epochs": 1, "timestep": 1306, "ep_reward": 758.2593383789062, "reward": 0.5208920240402222, "action": -0.8786004781723022}
{"mode": "train", "epochs": 1, "timestep": 1307, "ep_reward": 758.6241455078125, "reward": 0.36478179693222046, "action": -1.2481645345687866}
{"mode": "train", "epochs": 1, "timestep": 1308, "ep_reward": 758.8820190429688, "reward": 0.25789958238601685, "action": -0.2161695957183838}
{"mode": "train", "epochs": 1, "timestep": 1309, "ep_reward": 759.012939453125, "reward": 0.13091528415679932, "action": -0.4209645986557007}
{"mode": "train", "epochs": 1, "timestep": 1310, "ep_reward": 758.996826171875, "reward": -0.016109228134155273, "action": -0.9807857275009155}
{"mode": "train", "epochs": 1, "timestep": 1311, "ep_reward": 759.1262817382812, "reward": 0.12948542833328247, "action": -0.8208938241004944}
{"mode": "train", "epochs": 1, "timestep": 1312, "ep_reward": 759.3970336914062, "reward": 0.270755410194397, "action": -1.058272361755371}
{"mode": "train", "epochs": 1, "timestep": 1313, "ep_reward": 759.804443359375, "reward": 0.40743082761764526, "action": -1.0662977695465088}
{"mode": "train", "epochs": 1, "timestep": 1314, "ep_reward": 760.337646484375, "reward": 0.5332081913948059, "action": -0.7094268798828125}
{"mode": "train", "epochs": 1, "timestep": 1315, "ep_reward": 760.9817504882812, "reward": 0.6441141366958618, "action": -1.5900800228118896}
{"mode": "train", "epochs": 1, "timestep": 1316, "ep_reward": 761.7053833007812, "reward": 0.7236277461051941, "action": -0.5578757524490356}
{"mode": "train", "epochs": 1, "timestep": 1317, "ep_reward": 762.496826171875, "reward": 0.7914245128631592, "action": -1.6176807880401611}
{"mode": "train", "epochs": 1, "timestep": 1318, "ep_reward": 763.3259887695312, "reward": 0.829135000705719, "action": -1.0111252069473267}
{"mode": "train", "epochs": 1, "timestep": 1319, "ep_reward": 764.18017578125, "reward": 0.8541811108589172, "action": -1.7115747928619385}
{"mode": "train", "epochs": 1, "timestep": 1320, "ep_reward": 765.0363159179688, "reward": 0.8561511039733887, "action": -1.3072495460510254}
{"mode": "train", "epochs": 1, "timestep": 1321, "ep_reward": 765.8798828125, "reward": 0.843537449836731, "action": -1.010156512260437}
{"mode": "train", "epochs": 1, "timestep": 1322, "ep_reward": 766.6926879882812, "reward": 0.8127837181091309, "action": -1.4952340126037598}
{"mode": "train", "epochs": 1, "timestep": 1323, "ep_reward": 767.4440307617188, "reward": 0.7513339519500732, "action": -0.6852090358734131}
{"mode": "train", "epochs": 1, "timestep": 1324, "ep_reward": 768.1105346679688, "reward": 0.6664823293685913, "action": -1.0029820203781128}
{"mode": "train", "epochs": 1, "timestep": 1325, "ep_reward": 768.6498413085938, "reward": 0.5393095016479492, "action": -1.0021958351135254}
{"mode": "train", "epochs": 1, "timestep": 1326, "ep_reward": 769.0364990234375, "reward": 0.3866780400276184, "action": -0.6312211751937866}
{"mode": "train", "epochs": 1, "timestep": 1327, "ep_reward": 769.32080078125, "reward": 0.2843036651611328, "action": -0.7243790626525879}
{"mode": "train", "epochs": 1, "timestep": 1328, "ep_reward": 769.4827270507812, "reward": 0.16194826364517212, "action": -0.5982725620269775}
{"mode": "train", "epochs": 1, "timestep": 1329, "ep_reward": 769.502197265625, "reward": 0.019467592239379883, "action": -1.4847519397735596}
{"mode": "train", "epochs": 1, "timestep": 1330, "ep_reward": 769.5994262695312, "reward": 0.09721428155899048, "action": -1.59598708152771}
{"mode": "train", "epochs": 1, "timestep": 1331, "ep_reward": 769.8284912109375, "reward": 0.2290511131286621, "action": -1.344001293182373}
{"mode": "train", "epochs": 1, "timestep": 1332, "ep_reward": 770.1936645507812, "reward": 0.36514919996261597, "action": -1.5226649045944214}
{"mode": "train", "epochs": 1, "timestep": 1333, "ep_reward": 770.6848754882812, "reward": 0.4911906123161316, "action": -0.7817034721374512}
{"mode": "train", "epochs": 1, "timestep": 1334, "ep_reward": 771.2937622070312, "reward": 0.6089144945144653, "action": -1.4905768632888794}
{"mode": "train", "epochs": 1, "timestep": 1335, "ep_reward": 771.989501953125, "reward": 0.6957321166992188, "action": -1.0278528928756714}
{"mode": "train", "epochs": 1, "timestep": 1336, "ep_reward": 772.753662109375, "reward": 0.764183521270752, "action": -0.8604680299758911}
{"mode": "train", "epochs": 1, "timestep": 1337, "ep_reward": 773.565185546875, "reward": 0.8115395903587341, "action": -0.9362670183181763}
{"mode": "train", "epochs": 1, "timestep": 1338, "ep_reward": 774.4027099609375, "reward": 0.8375486731529236, "action": -0.6530149579048157}
{"mode": "train", "epochs": 1, "timestep": 1339, "ep_reward": 775.24951171875, "reward": 0.8467828035354614, "action": -1.5041027069091797}
{"mode": "train", "epochs": 1, "timestep": 1340, "ep_reward": 776.0780639648438, "reward": 0.8285440802574158, "action": -1.3020459413528442}
{"mode": "train", "epochs": 1, "timestep": 1341, "ep_reward": 776.8671264648438, "reward": 0.7890428900718689, "action": -0.5224511623382568}
{"mode": "train", "epochs": 1, "timestep": 1342, "ep_reward": 777.5971069335938, "reward": 0.7299946546554565, "action": 0.051957130432128906}
{"mode": "train", "epochs": 1, "timestep": 1343, "ep_reward": 778.242919921875, "reward": 0.645835816860199, "action": -0.4210173487663269}
{"mode": "train", "epochs": 1, "timestep": 1344, "ep_reward": 778.7619018554688, "reward": 0.5189552307128906, "action": -0.8934364914894104}
{"mode": "train", "epochs": 1, "timestep": 1345, "ep_reward": 779.1290893554688, "reward": 0.36721307039260864, "action": -1.2670433521270752}
{"mode": "train", "epochs": 1, "timestep": 1346, "ep_reward": 779.389892578125, "reward": 0.2608076333999634, "action": -0.7187038660049438}
{"mode": "train", "epochs": 1, "timestep": 1347, "ep_reward": 779.5241088867188, "reward": 0.13422423601150513, "action": -1.5119295120239258}
{"mode": "train", "epochs": 1, "timestep": 1348, "ep_reward": 779.511962890625, "reward": -0.012156248092651367, "action": -0.9041496515274048}
{"mode": "train", "epochs": 1, "timestep": 1349, "ep_reward": 779.6378784179688, "reward": 0.12592899799346924, "action": -1.4970295429229736}
{"mode": "train", "epochs": 1, "timestep": 1350, "ep_reward": 779.8964233398438, "reward": 0.2585442066192627, "action": -1.9107857942581177}
{"mode": "train", "epochs": 1, "timestep": 1351, "ep_reward": 780.2830200195312, "reward": 0.3865942358970642, "action": -1.1995919942855835}
{"mode": "train", "epochs": 1, "timestep": 1352, "ep_reward": 780.797607421875, "reward": 0.5145823955535889, "action": -1.2484484910964966}
{"mode": "train", "epochs": 1, "timestep": 1353, "ep_reward": 781.4207153320312, "reward": 0.62308669090271, "action": -0.5636109113693237}
{"mode": "train", "epochs": 1, "timestep": 1354, "ep_reward": 782.1361083984375, "reward": 0.7154166102409363, "action": -0.9779545068740845}
{"mode": "train", "epochs": 1, "timestep": 1355, "ep_reward": 782.9148559570312, "reward": 0.7787317037582397, "action": -1.3506896495819092}
{"mode": "train", "epochs": 1, "timestep": 1356, "ep_reward": 783.7314453125, "reward": 0.8166137337684631, "action": -1.2822074890136719}
{"mode": "train", "epochs": 1, "timestep": 1357, "ep_reward": 784.5665893554688, "reward": 0.8351635336875916, "action": -0.9967634081840515}
{"mode": "train", "epochs": 1, "timestep": 1358, "ep_reward": 785.4031982421875, "reward": 0.8366231918334961, "action": -0.9283666014671326}
{"mode": "train", "epochs": 1, "timestep": 1359, "ep_reward": 786.2210693359375, "reward": 0.8178476691246033, "action": -0.293401837348938}
{"mode": "train", "epochs": 1, "timestep": 1360, "ep_reward": 787.0029296875, "reward": 0.7818818092346191, "action": -0.46109944581985474}
{"mode": "train", "epochs": 1, "timestep": 1361, "ep_reward": 787.719482421875, "reward": 0.7165690660476685, "action": -0.25113803148269653}
{"mode": "train", "epochs": 1, "timestep": 1362, "ep_reward": 788.340087890625, "reward": 0.6205866932868958, "action": -1.1367292404174805}
{"mode": "train", "epochs": 1, "timestep": 1363, "ep_reward": 788.8134765625, "reward": 0.4734049439430237, "action": -0.5530953407287598}
{"mode": "train", "epochs": 1, "timestep": 1364, "ep_reward": 789.1559448242188, "reward": 0.3424667716026306, "action": -1.429504632949829}
{"mode": "train", "epochs": 1, "timestep": 1365, "ep_reward": 789.3870239257812, "reward": 0.23109817504882812, "action": -0.6680138111114502}
{"mode": "train", "epochs": 1, "timestep": 1366, "ep_reward": 789.4866943359375, "reward": 0.09965205192565918, "action": -0.31422358751296997}
{"mode": "train", "epochs": 1, "timestep": 1367, "ep_reward": 789.5037231445312, "reward": 0.01705700159072876, "action": -1.1859130859375}
{"mode": "train", "epochs": 1, "timestep": 1368, "ep_reward": 789.6635131835938, "reward": 0.15981894731521606, "action": -0.4690214991569519}
{"mode": "train", "epochs": 1, "timestep": 1369, "ep_reward": 789.969482421875, "reward": 0.30598050355911255, "action": -1.7695122957229614}
{"mode": "train", "epochs": 1, "timestep": 1370, "ep_reward": 790.4012451171875, "reward": 0.43178874254226685, "action": -1.2819076776504517}
{"mode": "train", "epochs": 1, "timestep": 1371, "ep_reward": 790.9535522460938, "reward": 0.5523343086242676, "action": -1.5919907093048096}
{"mode": "train", "epochs": 1, "timestep": 1372, "ep_reward": 791.6038818359375, "reward": 0.6503267288208008, "action": -1.37054443359375}
{"mode": "train", "epochs": 1, "timestep": 1373, "ep_reward": 792.3327026367188, "reward": 0.7288230657577515, "action": -0.654865026473999}
{"mode": "train", "epochs": 1, "timestep": 1374, "ep_reward": 793.1241455078125, "reward": 0.7914555072784424, "action": -1.328336477279663}
{"mode": "train", "epochs": 1, "timestep": 1375, "ep_reward": 793.9505615234375, "reward": 0.8264031410217285, "action": -0.3590559959411621}
{"mode": "train", "epochs": 1, "timestep": 1376, "ep_reward": 794.8013305664062, "reward": 0.8507965207099915, "action": -1.1462079286575317}
{"mode": "train", "epochs": 1, "timestep": 1377, "ep_reward": 795.651123046875, "reward": 0.8498079776763916, "action": -0.9347312450408936}
{"mode": "train", "epochs": 1, "timestep": 1378, "ep_reward": 796.4824829101562, "reward": 0.8313372135162354, "action": -1.4498471021652222}
{"mode": "train", "epochs": 1, "timestep": 1379, "ep_reward": 797.2672119140625, "reward": 0.7847485542297363, "action": -1.8328129053115845}
{"mode": "train", "epochs": 1, "timestep": 1380, "ep_reward": 797.9708862304688, "reward": 0.7036870718002319, "action": -0.2513214945793152}
{"mode": "train", "epochs": 1, "timestep": 1381, "ep_reward": 798.5758056640625, "reward": 0.6049442291259766, "action": -1.334110975265503}
{"mode": "train", "epochs": 1, "timestep": 1382, "ep_reward": 799.0260620117188, "reward": 0.45023036003112793, "action": -1.612025260925293}
{"mode": "train", "epochs": 1, "timestep": 1383, "ep_reward": 799.363525390625, "reward": 0.33746618032455444, "action": -1.3511345386505127}
{"mode": "train", "epochs": 1, "timestep": 1384, "ep_reward": 799.588623046875, "reward": 0.22509050369262695, "action": -0.7778626084327698}
{"mode": "train", "epochs": 1, "timestep": 1385, "ep_reward": 799.6812133789062, "reward": 0.09259927272796631, "action": -1.1141653060913086}
{"mode": "train", "epochs": 1, "timestep": 1386, "ep_reward": 799.705810546875, "reward": 0.024585723876953125, "action": -0.8377218842506409}
{"mode": "train", "epochs": 1, "timestep": 1387, "ep_reward": 799.8720703125, "reward": 0.16623961925506592, "action": -1.2283897399902344}
{"mode": "train", "epochs": 1, "timestep": 1388, "ep_reward": 800.1752319335938, "reward": 0.3031572103500366, "action": -1.7047839164733887}
{"mode": "train", "epochs": 1, "timestep": 1389, "ep_reward": 800.6064453125, "reward": 0.4312371611595154, "action": -0.33383452892303467}
{"mode": "train", "epochs": 1, "timestep": 1390, "ep_reward": 801.169677734375, "reward": 0.5632304549217224, "action": -1.0195648670196533}
{"mode": "train", "epochs": 1, "timestep": 1391, "ep_reward": 801.8349609375, "reward": 0.6652590036392212, "action": -0.8943373560905457}
{"mode": "train", "epochs": 1, "timestep": 1392, "ep_reward": 802.5804443359375, "reward": 0.7454716563224792, "action": -1.3064866065979004}
{"mode": "train", "epochs": 1, "timestep": 1393, "ep_reward": 803.3800048828125, "reward": 0.799585223197937, "action": -0.8370268940925598}
{"mode": "train", "epochs": 1, "timestep": 1394, "ep_reward": 804.218017578125, "reward": 0.8380178213119507, "action": -1.0415366888046265}
{"mode": "train", "epochs": 1, "timestep": 1395, "ep_reward": 805.074462890625, "reward": 0.856441855430603, "action": -0.6421219706535339}
{"mode": "train", "epochs": 1, "timestep": 1396, "ep_reward": 805.9354858398438, "reward": 0.8610113859176636, "action": -1.3045454025268555}
{"mode": "train", "epochs": 1, "timestep": 1397, "ep_reward": 806.77734375, "reward": 0.8418510556221008, "action": -0.3388240933418274}
{"mode": "train", "epochs": 1, "timestep": 1398, "ep_reward": 807.5882568359375, "reward": 0.8109415173530579, "action": -0.3251832127571106}
{"mode": "train", "epochs": 1, "timestep": 1399, "ep_reward": 808.3441772460938, "reward": 0.7558999061584473, "action": -1.9375605583190918}
{"mode": "train", "epochs": 1, "timestep": 1400, "ep_reward": 808.9950561523438, "reward": 0.6508532762527466, "action": -1.3937664031982422}
{"mode": "train", "epochs": 1, "timestep": 1401, "ep_reward": 809.505615234375, "reward": 0.510553240776062, "action": 0.29304039478302}
{"mode": "train", "epochs": 1, "timestep": 1402, "ep_reward": 809.8717651367188, "reward": 0.3661489486694336, "action": -1.65719735622406}
{"mode": "train", "epochs": 1, "timestep": 1403, "ep_reward": 810.13134765625, "reward": 0.25960034132003784, "action": -0.8118740916252136}
{"mode": "train", "epochs": 1, "timestep": 1404, "ep_reward": 810.26416015625, "reward": 0.13283944129943848, "action": -1.4072142839431763}
{"mode": "train", "epochs": 1, "timestep": 1405, "ep_reward": 810.2504272460938, "reward": -0.013733386993408203, "action": -0.5471488833427429}
{"mode": "train", "epochs": 1, "timestep": 1406, "ep_reward": 810.3778686523438, "reward": 0.12745028734207153, "action": -0.72660231590271}
{"mode": "train", "epochs": 1, "timestep": 1407, "ep_reward": 810.6477661132812, "reward": 0.26989710330963135, "action": -0.3728201389312744}
{"mode": "train", "epochs": 1, "timestep": 1408, "ep_reward": 811.0623779296875, "reward": 0.41460657119750977, "action": -0.9970465302467346}
{"mode": "train", "epochs": 1, "timestep": 1409, "ep_reward": 811.6019287109375, "reward": 0.5395604372024536, "action": -0.587372899055481}
{"mode": "train", "epochs": 1, "timestep": 1410, "ep_reward": 812.25244140625, "reward": 0.6505131721496582, "action": -1.201329231262207}
{"mode": "train", "epochs": 1, "timestep": 1411, "ep_reward": 812.985595703125, "reward": 0.7331314086914062, "action": -0.7688276767730713}
{"mode": "train", "epochs": 1, "timestep": 1412, "ep_reward": 813.7843017578125, "reward": 0.7987284660339355, "action": -0.8998719453811646}
{"mode": "train", "epochs": 1, "timestep": 1413, "ep_reward": 814.6279907226562, "reward": 0.8436757922172546, "action": -0.8000047206878662}
{"mode": "train", "epochs": 1, "timestep": 1414, "ep_reward": 815.5005493164062, "reward": 0.8725688457489014, "action": -1.713197946548462}
{"mode": "train", "epochs": 1, "timestep": 1415, "ep_reward": 816.3803100585938, "reward": 0.8797412514686584, "action": -1.3425685167312622}
{"mode": "train", "epochs": 1, "timestep": 1416, "ep_reward": 817.2555541992188, "reward": 0.8752572536468506, "action": -0.8759809732437134}
{"mode": "train", "epochs": 1, "timestep": 1417, "ep_reward": 818.1139526367188, "reward": 0.8584152460098267, "action": -0.9942861199378967}
{"mode": "train", "epochs": 1, "timestep": 1418, "ep_reward": 818.9351806640625, "reward": 0.8212466239929199, "action": -1.8011283874511719}
{"mode": "train", "epochs": 1, "timestep": 1419, "ep_reward": 819.6859741210938, "reward": 0.7508102059364319, "action": -1.2403401136398315}
{"mode": "train", "epochs": 1, "timestep": 1420, "ep_reward": 820.3386840820312, "reward": 0.6527001857757568, "action": -1.577986478805542}
{"mode": "train", "epochs": 1, "timestep": 1421, "ep_reward": 820.84814453125, "reward": 0.5094669461250305, "action": -1.6759121417999268}
{"mode": "train", "epochs": 1, "timestep": 1422, "ep_reward": 821.211669921875, "reward": 0.3635004758834839, "action": -0.4371405243873596}
{"mode": "train", "epochs": 1, "timestep": 1423, "ep_reward": 821.4678955078125, "reward": 0.25622302293777466, "action": -0.7064769268035889}
{"mode": "train", "epochs": 1, "timestep": 1424, "ep_reward": 821.5968017578125, "reward": 0.1289331316947937, "action": -1.007749080657959}
{"mode": "train", "epochs": 1, "timestep": 1425, "ep_reward": 821.5812377929688, "reward": -0.015593886375427246, "action": -1.5593233108520508}
{"mode": "train", "epochs": 1, "timestep": 1426, "ep_reward": 821.7125244140625, "reward": 0.13129228353500366, "action": -1.619866967201233}
{"mode": "train", "epochs": 1, "timestep": 1427, "ep_reward": 821.9752807617188, "reward": 0.26273053884506226, "action": -0.49091899394989014}
{"mode": "train", "epochs": 1, "timestep": 1428, "ep_reward": 822.383544921875, "reward": 0.40826523303985596, "action": -0.844804048538208}
{"mode": "train", "epochs": 1, "timestep": 1429, "ep_reward": 822.9202270507812, "reward": 0.5366960763931274, "action": -0.8910191655158997}
{"mode": "train", "epochs": 1, "timestep": 1430, "ep_reward": 823.5653686523438, "reward": 0.6451704502105713, "action": -0.923835813999176}
{"mode": "train", "epochs": 1, "timestep": 1431, "ep_reward": 824.2958984375, "reward": 0.7305153608322144, "action": -1.8312995433807373}
{"mode": "train", "epochs": 1, "timestep": 1432, "ep_reward": 825.081298828125, "reward": 0.7854019403457642, "action": -1.5689280033111572}
{"mode": "train", "epochs": 1, "timestep": 1433, "ep_reward": 825.9046630859375, "reward": 0.8233890533447266, "action": -0.8113722205162048}
{"mode": "train", "epochs": 1, "timestep": 1434, "ep_reward": 826.754150390625, "reward": 0.8494781255722046, "action": -0.5011008381843567}
{"mode": "train", "epochs": 1, "timestep": 1435, "ep_reward": 827.6143798828125, "reward": 0.8602485656738281, "action": -1.6729581356048584}
{"mode": "train", "epochs": 1, "timestep": 1436, "ep_reward": 828.4570922851562, "reward": 0.8426908254623413, "action": -1.7867908477783203}
{"mode": "train", "epochs": 1, "timestep": 1437, "ep_reward": 829.2592163085938, "reward": 0.8021160364151001, "action": -1.6144262552261353}
{"mode": "train", "epochs": 1, "timestep": 1438, "ep_reward": 829.9942626953125, "reward": 0.7350714206695557, "action": -1.2930831909179688}
{"mode": "train", "epochs": 1, "timestep": 1439, "ep_reward": 830.6305541992188, "reward": 0.6363133788108826, "action": -0.663076639175415}
{"mode": "train", "epochs": 1, "timestep": 1440, "ep_reward": 831.1354370117188, "reward": 0.5048913955688477, "action": 0.02078425884246826}
{"mode": "train", "epochs": 1, "timestep": 1441, "ep_reward": 831.50732421875, "reward": 0.3719055652618408, "action": -0.10770285129547119}
{"mode": "train", "epochs": 1, "timestep": 1442, "ep_reward": 831.7736206054688, "reward": 0.26630109548568726, "action": -1.1906747817993164}
{"mode": "train", "epochs": 1, "timestep": 1443, "ep_reward": 831.9143676757812, "reward": 0.14075195789337158, "action": -1.3960208892822266}
{"mode": "train", "epochs": 1, "timestep": 1444, "ep_reward": 831.90966796875, "reward": -0.004696369171142578, "action": -0.9368554949760437}
{"mode": "train", "epochs": 1, "timestep": 1445, "ep_reward": 832.029052734375, "reward": 0.1193799376487732, "action": -1.1224309206008911}
{"mode": "train", "epochs": 1, "timestep": 1446, "ep_reward": 832.2857055664062, "reward": 0.2566419839859009, "action": -1.1113784313201904}
{"mode": "train", "epochs": 1, "timestep": 1447, "ep_reward": 832.6795043945312, "reward": 0.39381176233291626, "action": -1.4508522748947144}
{"mode": "train", "epochs": 1, "timestep": 1448, "ep_reward": 833.196533203125, "reward": 0.5170126557350159, "action": -1.1414977312088013}
{"mode": "train", "epochs": 1, "timestep": 1449, "ep_reward": 833.8229370117188, "reward": 0.6263927221298218, "action": -0.09973514080047607}
{"mode": "train", "epochs": 1, "timestep": 1450, "ep_reward": 834.5465698242188, "reward": 0.7236335277557373, "action": -1.087112545967102}
{"mode": "train", "epochs": 1, "timestep": 1451, "ep_reward": 835.3333129882812, "reward": 0.786772608757019, "action": -1.482128381729126}
{"mode": "train", "epochs": 1, "timestep": 1452, "ep_reward": 836.1594848632812, "reward": 0.8261607885360718, "action": -0.7953746318817139}
{"mode": "train", "epochs": 1, "timestep": 1453, "ep_reward": 837.0126953125, "reward": 0.8532088398933411, "action": -1.153464436531067}
{"mode": "train", "epochs": 1, "timestep": 1454, "ep_reward": 837.8724975585938, "reward": 0.8598249554634094, "action": -0.9968357682228088}
{"mode": "train", "epochs": 1, "timestep": 1455, "ep_reward": 838.72265625, "reward": 0.8501524925231934, "action": -1.4390945434570312}
{"mode": "train", "epochs": 1, "timestep": 1456, "ep_reward": 839.5390014648438, "reward": 0.8163363933563232, "action": 0.4956396222114563}
{"mode": "train", "epochs": 1, "timestep": 1457, "ep_reward": 840.3171997070312, "reward": 0.7782074213027954, "action": -1.5268774032592773}
{"mode": "train", "epochs": 1, "timestep": 1458, "ep_reward": 841.0072631835938, "reward": 0.6900933384895325, "action": -0.5105159878730774}
{"mode": "train", "epochs": 1, "timestep": 1459, "ep_reward": 841.58447265625, "reward": 0.5771805047988892, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1460, "ep_reward": 841.9854736328125, "reward": 0.40101736783981323, "action": -1.2880419492721558}
{"mode": "train", "epochs": 1, "timestep": 1461, "ep_reward": 842.28466796875, "reward": 0.29920583963394165, "action": -0.461009681224823}
{"mode": "train", "epochs": 1, "timestep": 1462, "ep_reward": 842.4641723632812, "reward": 0.17952018976211548, "action": -0.47281765937805176}
{"mode": "train", "epochs": 1, "timestep": 1463, "ep_reward": 842.5038452148438, "reward": 0.039676785469055176, "action": -1.6636948585510254}
{"mode": "train", "epochs": 1, "timestep": 1464, "ep_reward": 842.5819091796875, "reward": 0.07809406518936157, "action": -1.2214939594268799}
{"mode": "train", "epochs": 1, "timestep": 1465, "ep_reward": 842.794921875, "reward": 0.21298521757125854, "action": -0.2843315005302429}
{"mode": "train", "epochs": 1, "timestep": 1466, "ep_reward": 843.1569213867188, "reward": 0.3620198965072632, "action": -1.5260024070739746}
{"mode": "train", "epochs": 1, "timestep": 1467, "ep_reward": 843.6438598632812, "reward": 0.48691797256469727, "action": 0.1761406660079956}
{"mode": "train", "epochs": 1, "timestep": 1468, "ep_reward": 844.25927734375, "reward": 0.6154334545135498, "action": -0.8113114833831787}
{"mode": "train", "epochs": 1, "timestep": 1469, "ep_reward": 844.9683837890625, "reward": 0.7090867161750793, "action": -1.9186193943023682}
{"mode": "train", "epochs": 1, "timestep": 1470, "ep_reward": 845.7391967773438, "reward": 0.7708109617233276, "action": -0.1849774718284607}
{"mode": "train", "epochs": 1, "timestep": 1471, "ep_reward": 846.5677490234375, "reward": 0.8285505175590515, "action": -0.25067198276519775}
{"mode": "train", "epochs": 1, "timestep": 1472, "ep_reward": 847.4342041015625, "reward": 0.8664478659629822, "action": -0.43498778343200684}
{"mode": "train", "epochs": 1, "timestep": 1473, "ep_reward": 848.3211059570312, "reward": 0.8868916630744934, "action": -1.5239577293395996}
{"mode": "train", "epochs": 1, "timestep": 1474, "ep_reward": 849.206298828125, "reward": 0.8851799964904785, "action": -0.8456493616104126}
{"mode": "train", "epochs": 1, "timestep": 1475, "ep_reward": 850.080322265625, "reward": 0.8740277290344238, "action": -1.6968235969543457}
{"mode": "train", "epochs": 1, "timestep": 1476, "ep_reward": 850.91845703125, "reward": 0.8381496667861938, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1477, "ep_reward": 851.69384765625, "reward": 0.7753812670707703, "action": -0.6472315788269043}
{"mode": "train", "epochs": 1, "timestep": 1478, "ep_reward": 852.39013671875, "reward": 0.6963100433349609, "action": -1.5508357286453247}
{"mode": "train", "epochs": 1, "timestep": 1479, "ep_reward": 852.9599609375, "reward": 0.569817304611206, "action": -0.0323030948638916}
{"mode": "train", "epochs": 1, "timestep": 1480, "ep_reward": 853.3834228515625, "reward": 0.42348164319992065, "action": -1.3740168809890747}
{"mode": "train", "epochs": 1, "timestep": 1481, "ep_reward": 853.6817626953125, "reward": 0.29834163188934326, "action": -0.9827731251716614}
{"mode": "train", "epochs": 1, "timestep": 1482, "ep_reward": 853.8602905273438, "reward": 0.1785062551498413, "action": -0.9951622486114502}
{"mode": "train", "epochs": 1, "timestep": 1483, "ep_reward": 853.8989868164062, "reward": 0.03871256113052368, "action": -0.5961184501647949}
{"mode": "train", "epochs": 1, "timestep": 1484, "ep_reward": 853.9782104492188, "reward": 0.07920616865158081, "action": -0.9471601247787476}
{"mode": "train", "epochs": 1, "timestep": 1485, "ep_reward": 854.1956787109375, "reward": 0.21746569871902466, "action": -1.2285794019699097}
{"mode": "train", "epochs": 1, "timestep": 1486, "ep_reward": 854.5499267578125, "reward": 0.35426265001296997, "action": -1.0439190864562988}
{"mode": "train", "epochs": 1, "timestep": 1487, "ep_reward": 855.0362548828125, "reward": 0.48629939556121826, "action": -0.608646035194397}
{"mode": "train", "epochs": 1, "timestep": 1488, "ep_reward": 855.642822265625, "reward": 0.6065574884414673, "action": -0.8374669551849365}
{"mode": "train", "epochs": 1, "timestep": 1489, "ep_reward": 856.3442993164062, "reward": 0.7014683485031128, "action": -1.7197275161743164}
{"mode": "train", "epochs": 1, "timestep": 1490, "ep_reward": 857.109619140625, "reward": 0.7653494477272034, "action": -0.8942641019821167}
{"mode": "train", "epochs": 1, "timestep": 1491, "ep_reward": 857.926025390625, "reward": 0.8164340853691101, "action": -1.2699609994888306}
{"mode": "train", "epochs": 1, "timestep": 1492, "ep_reward": 858.7708740234375, "reward": 0.844824492931366, "action": -1.4609670639038086}
{"mode": "train", "epochs": 1, "timestep": 1493, "ep_reward": 859.6249389648438, "reward": 0.8540541529655457, "action": -0.5992828011512756}
{"mode": "train", "epochs": 1, "timestep": 1494, "ep_reward": 860.47802734375, "reward": 0.8530820608139038, "action": -0.8187376856803894}
{"mode": "train", "epochs": 1, "timestep": 1495, "ep_reward": 861.30908203125, "reward": 0.831034779548645, "action": -1.3663181066513062}
{"mode": "train", "epochs": 1, "timestep": 1496, "ep_reward": 862.0897216796875, "reward": 0.7806491851806641, "action": -0.9467514157295227}
{"mode": "train", "epochs": 1, "timestep": 1497, "ep_reward": 862.794921875, "reward": 0.705182671546936, "action": -1.036497712135315}
{"mode": "train", "epochs": 1, "timestep": 1498, "ep_reward": 863.3873901367188, "reward": 0.592487096786499, "action": -1.3502349853515625}
{"mode": "train", "epochs": 1, "timestep": 1499, "ep_reward": 863.8201293945312, "reward": 0.4327569007873535, "action": -0.31804394721984863}
{"mode": "train", "epochs": 1, "timestep": 1500, "ep_reward": 864.1421508789062, "reward": 0.32203078269958496, "action": -1.0269416570663452}
{"mode": "train", "epochs": 1, "timestep": 1501, "ep_reward": 864.3487548828125, "reward": 0.2066187858581543, "action": -0.8644447326660156}
{"mode": "train", "epochs": 1, "timestep": 1502, "ep_reward": 864.4199829101562, "reward": 0.07120692729949951, "action": -0.6693345904350281}
{"mode": "train", "epochs": 1, "timestep": 1503, "ep_reward": 864.4669799804688, "reward": 0.04699939489364624, "action": -0.32846689224243164}
{"mode": "train", "epochs": 1, "timestep": 1504, "ep_reward": 864.6589965820312, "reward": 0.19201797246932983, "action": -0.46790313720703125}
{"mode": "train", "epochs": 1, "timestep": 1505, "ep_reward": 864.996337890625, "reward": 0.3373507857322693, "action": -1.129673957824707}
{"mode": "train", "epochs": 1, "timestep": 1506, "ep_reward": 865.4644165039062, "reward": 0.46808958053588867, "action": -0.5975490808486938}
{"mode": "train", "epochs": 1, "timestep": 1507, "ep_reward": 866.0548706054688, "reward": 0.590435266494751, "action": -1.8659100532531738}
{"mode": "train", "epochs": 1, "timestep": 1508, "ep_reward": 866.7338256835938, "reward": 0.6789840459823608, "action": -1.3800615072250366}
{"mode": "train", "epochs": 1, "timestep": 1509, "ep_reward": 867.4859619140625, "reward": 0.7521650791168213, "action": -1.5911767482757568}
{"mode": "train", "epochs": 1, "timestep": 1510, "ep_reward": 868.2888793945312, "reward": 0.8029122352600098, "action": -0.20439177751541138}
{"mode": "train", "epochs": 1, "timestep": 1511, "ep_reward": 869.1353759765625, "reward": 0.8465080261230469, "action": -1.439908504486084}
{"mode": "train", "epochs": 1, "timestep": 1512, "ep_reward": 869.9971313476562, "reward": 0.8617681860923767, "action": -1.3578702211380005}
{"mode": "train", "epochs": 1, "timestep": 1513, "ep_reward": 870.8583374023438, "reward": 0.8612047433853149, "action": -1.5215303897857666}
{"mode": "train", "epochs": 1, "timestep": 1514, "ep_reward": 871.6995849609375, "reward": 0.8412443399429321, "action": -0.5481114387512207}
{"mode": "train", "epochs": 1, "timestep": 1515, "ep_reward": 872.5087280273438, "reward": 0.8091446161270142, "action": -1.4799892902374268}
{"mode": "train", "epochs": 1, "timestep": 1516, "ep_reward": 873.2504272460938, "reward": 0.7417123317718506, "action": -0.5307139158248901}
{"mode": "train", "epochs": 1, "timestep": 1517, "ep_reward": 873.9024658203125, "reward": 0.6520268321037292, "action": -1.093888759613037}
{"mode": "train", "epochs": 1, "timestep": 1518, "ep_reward": 874.4191284179688, "reward": 0.5166327357292175, "action": -0.765149712562561}
{"mode": "train", "epochs": 1, "timestep": 1519, "ep_reward": 874.7868041992188, "reward": 0.3677058219909668, "action": -0.4126628637313843}
{"mode": "train", "epochs": 1, "timestep": 1520, "ep_reward": 875.0479736328125, "reward": 0.26119357347488403, "action": -1.4594008922576904}
{"mode": "train", "epochs": 1, "timestep": 1521, "ep_reward": 875.182861328125, "reward": 0.13488280773162842, "action": -0.9355206489562988}
{"mode": "train", "epochs": 1, "timestep": 1522, "ep_reward": 875.1712646484375, "reward": -0.011585593223571777, "action": -1.4665329456329346}
{"mode": "train", "epochs": 1, "timestep": 1523, "ep_reward": 875.2967529296875, "reward": 0.12546616792678833, "action": -0.6586930751800537}
{"mode": "train", "epochs": 1, "timestep": 1524, "ep_reward": 875.5653686523438, "reward": 0.26862210035324097, "action": -1.198095440864563}
{"mode": "train", "epochs": 1, "timestep": 1525, "ep_reward": 875.9685668945312, "reward": 0.4032125473022461, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1526, "ep_reward": 876.4873046875, "reward": 0.5187246799468994, "action": -1.040783166885376}
{"mode": "train", "epochs": 1, "timestep": 1527, "ep_reward": 877.1161499023438, "reward": 0.6288528442382812, "action": -0.7603384256362915}
{"mode": "train", "epochs": 1, "timestep": 1528, "ep_reward": 877.8350219726562, "reward": 0.7188853025436401, "action": -1.2179187536239624}
{"mode": "train", "epochs": 1, "timestep": 1529, "ep_reward": 878.6160278320312, "reward": 0.7810027003288269, "action": -1.2960474491119385}
{"mode": "train", "epochs": 1, "timestep": 1530, "ep_reward": 879.4376220703125, "reward": 0.8216017484664917, "action": -0.6472951173782349}
{"mode": "train", "epochs": 1, "timestep": 1531, "ep_reward": 880.2862548828125, "reward": 0.848652720451355, "action": -1.6903865337371826}
{"mode": "train", "epochs": 1, "timestep": 1532, "ep_reward": 881.1345825195312, "reward": 0.8483405113220215, "action": -1.373267412185669}
{"mode": "train", "epochs": 1, "timestep": 1533, "ep_reward": 881.9658813476562, "reward": 0.8313285112380981, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1534, "ep_reward": 882.7507934570312, "reward": 0.7849051356315613, "action": 0.13312506675720215}
{"mode": "train", "epochs": 1, "timestep": 1535, "ep_reward": 883.4837646484375, "reward": 0.7329548001289368, "action": -1.2301472425460815}
{"mode": "train", "epochs": 1, "timestep": 1536, "ep_reward": 884.1159057617188, "reward": 0.6321388483047485, "action": -1.2120426893234253}
{"mode": "train", "epochs": 1, "timestep": 1537, "ep_reward": 884.6055908203125, "reward": 0.48965513706207275, "action": -0.5200618505477905}
{"mode": "train", "epochs": 1, "timestep": 1538, "ep_reward": 884.9679565429688, "reward": 0.3623512387275696, "action": -1.13447904586792}
{"mode": "train", "epochs": 1, "timestep": 1539, "ep_reward": 885.222900390625, "reward": 0.25491780042648315, "action": -0.7346025109291077}
{"mode": "train", "epochs": 1, "timestep": 1540, "ep_reward": 885.3502807617188, "reward": 0.12739670276641846, "action": -1.0977081060409546}
{"mode": "train", "epochs": 1, "timestep": 1541, "ep_reward": 885.3365478515625, "reward": -0.013752937316894531, "action": -0.9046626091003418}
{"mode": "train", "epochs": 1, "timestep": 1542, "ep_reward": 885.469482421875, "reward": 0.1329614520072937, "action": -0.4545465111732483}
{"mode": "train", "epochs": 1, "timestep": 1543, "ep_reward": 885.748291015625, "reward": 0.2788194417953491, "action": -1.2002971172332764}
{"mode": "train", "epochs": 1, "timestep": 1544, "ep_reward": 886.160888671875, "reward": 0.4126071333885193, "action": -1.7303441762924194}
{"mode": "train", "epochs": 1, "timestep": 1545, "ep_reward": 886.69091796875, "reward": 0.5300357341766357, "action": -0.7439684867858887}
{"mode": "train", "epochs": 1, "timestep": 1546, "ep_reward": 887.332275390625, "reward": 0.6413318514823914, "action": -0.39779555797576904}
{"mode": "train", "epochs": 1, "timestep": 1547, "ep_reward": 888.0648193359375, "reward": 0.7325602769851685, "action": -1.5092958211898804}
{"mode": "train", "epochs": 1, "timestep": 1548, "ep_reward": 888.855224609375, "reward": 0.7904000878334045, "action": -0.47608768939971924}
{"mode": "train", "epochs": 1, "timestep": 1549, "ep_reward": 889.69287109375, "reward": 0.837661623954773, "action": -1.4078547954559326}
{"mode": "train", "epochs": 1, "timestep": 1550, "ep_reward": 890.5519409179688, "reward": 0.8590476512908936, "action": -0.16194254159927368}
{"mode": "train", "epochs": 1, "timestep": 1551, "ep_reward": 891.4264526367188, "reward": 0.8745302557945251, "action": -1.1424927711486816}
{"mode": "train", "epochs": 1, "timestep": 1552, "ep_reward": 892.2923583984375, "reward": 0.8659211993217468, "action": -1.2661488056182861}
{"mode": "train", "epochs": 1, "timestep": 1553, "ep_reward": 893.1306762695312, "reward": 0.8383051156997681, "action": -0.8993650674819946}
{"mode": "train", "epochs": 1, "timestep": 1554, "ep_reward": 893.9227294921875, "reward": 0.7920533418655396, "action": -0.41910892724990845}
{"mode": "train", "epochs": 1, "timestep": 1555, "ep_reward": 894.6465454101562, "reward": 0.7238200902938843, "action": -1.7866370677947998}
{"mode": "train", "epochs": 1, "timestep": 1556, "ep_reward": 895.251708984375, "reward": 0.6051647663116455, "action": -0.8482263684272766}
{"mode": "train", "epochs": 1, "timestep": 1557, "ep_reward": 895.7083740234375, "reward": 0.4566444754600525, "action": -1.1196037530899048}
{"mode": "train", "epochs": 1, "timestep": 1558, "ep_reward": 896.033935546875, "reward": 0.3255460262298584, "action": -0.6316031217575073}
{"mode": "train", "epochs": 1, "timestep": 1559, "ep_reward": 896.2446899414062, "reward": 0.21075022220611572, "action": -0.9004452228546143}
{"mode": "train", "epochs": 1, "timestep": 1560, "ep_reward": 896.3207397460938, "reward": 0.0760260820388794, "action": -0.2930474877357483}
{"mode": "train", "epochs": 1, "timestep": 1561, "ep_reward": 896.36279296875, "reward": 0.04206639528274536, "action": -0.448070228099823}
{"mode": "train", "epochs": 1, "timestep": 1562, "ep_reward": 896.548095703125, "reward": 0.1852746605873108, "action": -1.6868689060211182}
{"mode": "train", "epochs": 1, "timestep": 1563, "ep_reward": 896.8642578125, "reward": 0.3161585330963135, "action": -0.4968069791793823}
{"mode": "train", "epochs": 1, "timestep": 1564, "ep_reward": 897.3223876953125, "reward": 0.4581264853477478, "action": -0.7759801745414734}
{"mode": "train", "epochs": 1, "timestep": 1565, "ep_reward": 897.903076171875, "reward": 0.5806883573532104, "action": -0.8646230697631836}
{"mode": "train", "epochs": 1, "timestep": 1566, "ep_reward": 898.583984375, "reward": 0.6809154748916626, "action": -1.3885027170181274}
{"mode": "train", "epochs": 1, "timestep": 1567, "ep_reward": 899.3374633789062, "reward": 0.7534793019294739, "action": -0.7805906534194946}
{"mode": "train", "epochs": 1, "timestep": 1568, "ep_reward": 900.1480712890625, "reward": 0.8105980157852173, "action": -1.1865657567977905}
{"mode": "train", "epochs": 1, "timestep": 1569, "ep_reward": 900.9927368164062, "reward": 0.8446757793426514, "action": -0.9980021715164185}
{"mode": "train", "epochs": 1, "timestep": 1570, "ep_reward": 901.8558349609375, "reward": 0.8631225824356079, "action": -1.3269864320755005}
{"mode": "train", "epochs": 1, "timestep": 1571, "ep_reward": 902.7182006835938, "reward": 0.8623416423797607, "action": -0.8003358840942383}
{"mode": "train", "epochs": 1, "timestep": 1572, "ep_reward": 903.5667724609375, "reward": 0.8485531806945801, "action": -0.9512302875518799}
{"mode": "train", "epochs": 1, "timestep": 1573, "ep_reward": 904.3798828125, "reward": 0.8131405115127563, "action": -1.3355541229248047}
{"mode": "train", "epochs": 1, "timestep": 1574, "ep_reward": 905.1281127929688, "reward": 0.7482383847236633, "action": -0.7377420663833618}
{"mode": "train", "epochs": 1, "timestep": 1575, "ep_reward": 905.78564453125, "reward": 0.6575546264648438, "action": -1.190649390220642}
{"mode": "train", "epochs": 1, "timestep": 1576, "ep_reward": 906.3080444335938, "reward": 0.522379994392395, "action": -1.1890461444854736}
{"mode": "train", "epochs": 1, "timestep": 1577, "ep_reward": 906.67822265625, "reward": 0.3701951503753662, "action": -0.6231192350387573}
{"mode": "train", "epochs": 1, "timestep": 1578, "ep_reward": 906.9425659179688, "reward": 0.2643476128578186, "action": -0.20667600631713867}
{"mode": "train", "epochs": 1, "timestep": 1579, "ep_reward": 907.080810546875, "reward": 0.13823187351226807, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1580, "ep_reward": 907.0732421875, "reward": -0.007551908493041992, "action": -1.628727912902832}
{"mode": "train", "epochs": 1, "timestep": 1581, "ep_reward": 907.1950073242188, "reward": 0.12175995111465454, "action": -1.494179129600525}
{"mode": "train", "epochs": 1, "timestep": 1582, "ep_reward": 907.4494018554688, "reward": 0.25436514616012573, "action": -1.6107120513916016}
{"mode": "train", "epochs": 1, "timestep": 1583, "ep_reward": 907.8356323242188, "reward": 0.3862369656562805, "action": -1.4729238748550415}
{"mode": "train", "epochs": 1, "timestep": 1584, "ep_reward": 908.3464965820312, "reward": 0.5108661651611328, "action": -0.40426909923553467}
{"mode": "train", "epochs": 1, "timestep": 1585, "ep_reward": 908.9757690429688, "reward": 0.6293001770973206, "action": -1.144226312637329}
{"mode": "train", "epochs": 1, "timestep": 1586, "ep_reward": 909.69091796875, "reward": 0.7151325345039368, "action": -1.012104868888855}
{"mode": "train", "epochs": 1, "timestep": 1587, "ep_reward": 910.469970703125, "reward": 0.7790447473526001, "action": -1.1280741691589355}
{"mode": "train", "epochs": 1, "timestep": 1588, "ep_reward": 911.2901000976562, "reward": 0.8201538920402527, "action": -1.4387905597686768}
{"mode": "train", "epochs": 1, "timestep": 1589, "ep_reward": 912.12890625, "reward": 0.8388314247131348, "action": -1.377676010131836}
{"mode": "train", "epochs": 1, "timestep": 1590, "ep_reward": 912.9677124023438, "reward": 0.8387975692749023, "action": -1.9636609554290771}
{"mode": "train", "epochs": 1, "timestep": 1591, "ep_reward": 913.7799072265625, "reward": 0.8122037053108215, "action": -1.0217814445495605}
{"mode": "train", "epochs": 1, "timestep": 1592, "ep_reward": 914.5494995117188, "reward": 0.7695754766464233, "action": -0.6630864143371582}
{"mode": "train", "epochs": 1, "timestep": 1593, "ep_reward": 915.2503662109375, "reward": 0.7008829712867737, "action": -0.382448673248291}
{"mode": "train", "epochs": 1, "timestep": 1594, "ep_reward": 915.8505859375, "reward": 0.6002167463302612, "action": -0.8917731046676636}
{"mode": "train", "epochs": 1, "timestep": 1595, "ep_reward": 916.3021240234375, "reward": 0.45154017210006714, "action": -1.5613794326782227}
{"mode": "train", "epochs": 1, "timestep": 1596, "ep_reward": 916.640625, "reward": 0.33853018283843994, "action": -0.8657255172729492}
{"mode": "train", "epochs": 1, "timestep": 1597, "ep_reward": 916.866943359375, "reward": 0.22630125284194946, "action": -0.5449169874191284}
{"mode": "train", "epochs": 1, "timestep": 1598, "ep_reward": 916.9609985351562, "reward": 0.0940285325050354, "action": -0.7446389198303223}
{"mode": "train", "epochs": 1, "timestep": 1599, "ep_reward": 916.9840698242188, "reward": 0.023063838481903076, "action": -1.1826534271240234}
{"mode": "train", "epochs": 1, "timestep": 1600, "ep_reward": 917.1491088867188, "reward": 0.16504377126693726, "action": -0.32603323459625244}
{"mode": "train", "epochs": 1, "timestep": 1601, "ep_reward": 917.4622802734375, "reward": 0.3131682872772217, "action": -1.1057440042495728}
{"mode": "train", "epochs": 1, "timestep": 1602, "ep_reward": 917.9085083007812, "reward": 0.44625788927078247, "action": -0.702705979347229}
{"mode": "train", "epochs": 1, "timestep": 1603, "ep_reward": 918.4793701171875, "reward": 0.570855975151062, "action": -0.9932964444160461}
{"mode": "train", "epochs": 1, "timestep": 1604, "ep_reward": 919.1513061523438, "reward": 0.6719319224357605, "action": -0.841599702835083}
{"mode": "train", "epochs": 1, "timestep": 1605, "ep_reward": 919.90380859375, "reward": 0.7524802684783936, "action": -0.5939843654632568}
{"mode": "train", "epochs": 1, "timestep": 1606, "ep_reward": 920.717529296875, "reward": 0.813703179359436, "action": -0.4825783967971802}
{"mode": "train", "epochs": 1, "timestep": 1607, "ep_reward": 921.5740966796875, "reward": 0.8565662503242493, "action": -0.47348499298095703}
{"mode": "train", "epochs": 1, "timestep": 1608, "ep_reward": 922.4570922851562, "reward": 0.8830222487449646, "action": -1.569143295288086}
{"mode": "train", "epochs": 1, "timestep": 1609, "ep_reward": 923.3442993164062, "reward": 0.8872195482254028, "action": -1.3226110935211182}
{"mode": "train", "epochs": 1, "timestep": 1610, "ep_reward": 924.2236328125, "reward": 0.8793479204177856, "action": -0.2060227394104004}
{"mode": "train", "epochs": 1, "timestep": 1611, "ep_reward": 925.0885009765625, "reward": 0.864886999130249, "action": -1.8127487897872925}
{"mode": "train", "epochs": 1, "timestep": 1612, "ep_reward": 925.90625, "reward": 0.8177334666252136, "action": -1.12811279296875}
{"mode": "train", "epochs": 1, "timestep": 1613, "ep_reward": 926.6573486328125, "reward": 0.7511217594146729, "action": -1.2608699798583984}
{"mode": "train", "epochs": 1, "timestep": 1614, "ep_reward": 927.3079223632812, "reward": 0.6505468487739563, "action": -1.371323823928833}
{"mode": "train", "epochs": 1, "timestep": 1615, "ep_reward": 927.8165283203125, "reward": 0.5086268782615662, "action": -0.9788631200790405}
{"mode": "train", "epochs": 1, "timestep": 1616, "ep_reward": 928.1713256835938, "reward": 0.35480237007141113, "action": -0.2205880880355835}
{"mode": "train", "epochs": 1, "timestep": 1617, "ep_reward": 928.4169921875, "reward": 0.2456427812576294, "action": -1.443037986755371}
{"mode": "train", "epochs": 1, "timestep": 1618, "ep_reward": 928.5336303710938, "reward": 0.1166638731956482, "action": -1.1122946739196777}
{"mode": "train", "epochs": 1, "timestep": 1619, "ep_reward": 928.531982421875, "reward": -0.0016297101974487305, "action": -0.6717171669006348}
{"mode": "train", "epochs": 1, "timestep": 1620, "ep_reward": 928.6754760742188, "reward": 0.14348310232162476, "action": -0.7930940389633179}
{"mode": "train", "epochs": 1, "timestep": 1621, "ep_reward": 928.9608154296875, "reward": 0.2853374481201172, "action": -1.6417829990386963}
{"mode": "train", "epochs": 1, "timestep": 1622, "ep_reward": 929.3751220703125, "reward": 0.4143083095550537, "action": -0.8428121209144592}
{"mode": "train", "epochs": 1, "timestep": 1623, "ep_reward": 929.9173583984375, "reward": 0.5422570109367371, "action": -1.2294843196868896}
{"mode": "train", "epochs": 1, "timestep": 1624, "ep_reward": 930.5634765625, "reward": 0.6461073160171509, "action": -1.0138962268829346}
{"mode": "train", "epochs": 1, "timestep": 1625, "ep_reward": 931.2933959960938, "reward": 0.7299163341522217, "action": -0.47449231147766113}
{"mode": "train", "epochs": 1, "timestep": 1626, "ep_reward": 932.08935546875, "reward": 0.7959585189819336, "action": -0.9722399115562439}
{"mode": "train", "epochs": 1, "timestep": 1627, "ep_reward": 932.92578125, "reward": 0.8364424705505371, "action": -1.1232126951217651}
{"mode": "train", "epochs": 1, "timestep": 1628, "ep_reward": 933.7835083007812, "reward": 0.8577245473861694, "action": -0.6606539487838745}
{"mode": "train", "epochs": 1, "timestep": 1629, "ep_reward": 934.6495971679688, "reward": 0.8660805225372314, "action": -1.3652349710464478}
{"mode": "train", "epochs": 1, "timestep": 1630, "ep_reward": 935.5009155273438, "reward": 0.8513014316558838, "action": -0.903713047504425}
{"mode": "train", "epochs": 1, "timestep": 1631, "ep_reward": 936.32177734375, "reward": 0.8208357691764832, "action": -0.6537901759147644}
{"mode": "train", "epochs": 1, "timestep": 1632, "ep_reward": 937.0908203125, "reward": 0.7690319418907166, "action": -0.9381279945373535}
{"mode": "train", "epochs": 1, "timestep": 1633, "ep_reward": 937.7752685546875, "reward": 0.684454619884491, "action": -0.7359984517097473}
{"mode": "train", "epochs": 1, "timestep": 1634, "ep_reward": 938.3411865234375, "reward": 0.5658907890319824, "action": -0.06367826461791992}
{"mode": "train", "epochs": 1, "timestep": 1635, "ep_reward": 938.759033203125, "reward": 0.41785889863967896, "action": -0.9730638265609741}
{"mode": "train", "epochs": 1, "timestep": 1636, "ep_reward": 939.0524291992188, "reward": 0.2934238910675049, "action": -0.7361912727355957}
{"mode": "train", "epochs": 1, "timestep": 1637, "ep_reward": 939.2250366210938, "reward": 0.17263191938400269, "action": -1.2349315881729126}
{"mode": "train", "epochs": 1, "timestep": 1638, "ep_reward": 939.2570190429688, "reward": 0.031977713108062744, "action": -0.5597968101501465}
{"mode": "train", "epochs": 1, "timestep": 1639, "ep_reward": 939.3426513671875, "reward": 0.08563482761383057, "action": -1.115101933479309}
{"mode": "train", "epochs": 1, "timestep": 1640, "ep_reward": 939.5645751953125, "reward": 0.2219257950782776, "action": -1.6355292797088623}
{"mode": "train", "epochs": 1, "timestep": 1641, "ep_reward": 939.9185791015625, "reward": 0.3539924621582031, "action": -0.19180500507354736}
{"mode": "train", "epochs": 1, "timestep": 1642, "ep_reward": 940.415283203125, "reward": 0.4967341423034668, "action": -1.1410144567489624}
{"mode": "train", "epochs": 1, "timestep": 1643, "ep_reward": 941.0247192382812, "reward": 0.6094444990158081, "action": -0.7161041498184204}
{"mode": "train", "epochs": 1, "timestep": 1644, "ep_reward": 941.7296752929688, "reward": 0.704935610294342, "action": -0.9030157327651978}
{"mode": "train", "epochs": 1, "timestep": 1645, "ep_reward": 942.5049438476562, "reward": 0.7752987742424011, "action": -0.7313268184661865}
{"mode": "train", "epochs": 1, "timestep": 1646, "ep_reward": 943.3309326171875, "reward": 0.8259767293930054, "action": -1.1139323711395264}
{"mode": "train", "epochs": 1, "timestep": 1647, "ep_reward": 944.1857299804688, "reward": 0.8548011779785156, "action": 0.4199839234352112}
{"mode": "train", "epochs": 1, "timestep": 1648, "ep_reward": 945.0654296875, "reward": 0.879709005355835, "action": -0.5936704277992249}
{"mode": "train", "epochs": 1, "timestep": 1649, "ep_reward": 945.946533203125, "reward": 0.8810952305793762, "action": -0.23045337200164795}
{"mode": "train", "epochs": 1, "timestep": 1650, "ep_reward": 946.8168334960938, "reward": 0.8702999949455261, "action": -1.2776604890823364}
{"mode": "train", "epochs": 1, "timestep": 1651, "ep_reward": 947.64990234375, "reward": 0.8330491781234741, "action": -1.2184906005859375}
{"mode": "train", "epochs": 1, "timestep": 1652, "ep_reward": 948.4227294921875, "reward": 0.7728420495986938, "action": -0.9529263973236084}
{"mode": "train", "epochs": 1, "timestep": 1653, "ep_reward": 949.1082153320312, "reward": 0.6854966878890991, "action": -0.9256191849708557}
{"mode": "train", "epochs": 1, "timestep": 1654, "ep_reward": 949.6702880859375, "reward": 0.5620708465576172, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1655, "ep_reward": 950.051025390625, "reward": 0.3807397484779358, "action": -1.5915601253509521}
{"mode": "train", "epochs": 1, "timestep": 1656, "ep_reward": 950.3275756835938, "reward": 0.27653801441192627, "action": -1.677807331085205}
{"mode": "train", "epochs": 1, "timestep": 1657, "ep_reward": 950.4805297851562, "reward": 0.15295207500457764, "action": -0.8710624575614929}
{"mode": "train", "epochs": 1, "timestep": 1658, "ep_reward": 950.48974609375, "reward": 0.009244918823242188, "action": -0.8075052499771118}
{"mode": "train", "epochs": 1, "timestep": 1659, "ep_reward": 950.5966186523438, "reward": 0.10685992240905762, "action": -0.6853277683258057}
{"mode": "train", "epochs": 1, "timestep": 1660, "ep_reward": 950.8458251953125, "reward": 0.24922949075698853, "action": -0.8803430795669556}
{"mode": "train", "epochs": 1, "timestep": 1661, "ep_reward": 951.2344360351562, "reward": 0.38863110542297363, "action": -1.170411467552185}
{"mode": "train", "epochs": 1, "timestep": 1662, "ep_reward": 951.7494506835938, "reward": 0.514999508857727, "action": -0.41845130920410156}
{"mode": "train", "epochs": 1, "timestep": 1663, "ep_reward": 952.3817138671875, "reward": 0.6322724223136902, "action": -0.7282742261886597}
{"mode": "train", "epochs": 1, "timestep": 1664, "ep_reward": 953.104736328125, "reward": 0.7230337858200073, "action": -1.5853300094604492}
{"mode": "train", "epochs": 1, "timestep": 1665, "ep_reward": 953.8887329101562, "reward": 0.7839940190315247, "action": -0.6664224863052368}
{"mode": "train", "epochs": 1, "timestep": 1666, "ep_reward": 954.7225341796875, "reward": 0.8337806463241577, "action": 0.03029412031173706}
{"mode": "train", "epochs": 1, "timestep": 1667, "ep_reward": 955.5935668945312, "reward": 0.8710047602653503, "action": -0.7835330963134766}
{"mode": "train", "epochs": 1, "timestep": 1668, "ep_reward": 956.479736328125, "reward": 0.8861573934555054, "action": -0.5690991878509521}
{"mode": "train", "epochs": 1, "timestep": 1669, "ep_reward": 957.368896484375, "reward": 0.8891356587409973, "action": -0.2894517183303833}
{"mode": "train", "epochs": 1, "timestep": 1670, "ep_reward": 958.2492065429688, "reward": 0.880290687084198, "action": -0.5771879553794861}
{"mode": "train", "epochs": 1, "timestep": 1671, "ep_reward": 959.1026611328125, "reward": 0.8534367084503174, "action": -0.6808938384056091}
{"mode": "train", "epochs": 1, "timestep": 1672, "ep_reward": 959.90869140625, "reward": 0.8060082197189331, "action": -1.3572077751159668}
{"mode": "train", "epochs": 1, "timestep": 1673, "ep_reward": 960.6343994140625, "reward": 0.7257214784622192, "action": -0.6398977041244507}
{"mode": "train", "epochs": 1, "timestep": 1674, "ep_reward": 961.2545776367188, "reward": 0.6201798915863037, "action": -0.6726932525634766}
{"mode": "train", "epochs": 1, "timestep": 1675, "ep_reward": 961.7317504882812, "reward": 0.4772002696990967, "action": -0.8134080767631531}
{"mode": "train", "epochs": 1, "timestep": 1676, "ep_reward": 962.0484008789062, "reward": 0.31664127111434937, "action": -0.4711053967475891}
{"mode": "train", "epochs": 1, "timestep": 1677, "ep_reward": 962.2484741210938, "reward": 0.2000986933708191, "action": -1.2523658275604248}
{"mode": "train", "epochs": 1, "timestep": 1678, "ep_reward": 962.3121337890625, "reward": 0.0636795163154602, "action": -0.9749670028686523}
{"mode": "train", "epochs": 1, "timestep": 1679, "ep_reward": 962.3665771484375, "reward": 0.05445986986160278, "action": -1.5937201976776123}
{"mode": "train", "epochs": 1, "timestep": 1680, "ep_reward": 962.5587768554688, "reward": 0.19217610359191895, "action": -1.4987432956695557}
{"mode": "train", "epochs": 1, "timestep": 1681, "ep_reward": 962.8848876953125, "reward": 0.32609182596206665, "action": -1.8523348569869995}
{"mode": "train", "epochs": 1, "timestep": 1682, "ep_reward": 963.3362426757812, "reward": 0.45135414600372314, "action": -0.8262242674827576}
{"mode": "train", "epochs": 1, "timestep": 1683, "ep_reward": 963.9114379882812, "reward": 0.5751962661743164, "action": -0.3142683506011963}
{"mode": "train", "epochs": 1, "timestep": 1684, "ep_reward": 964.593017578125, "reward": 0.6816056370735168, "action": -1.3261775970458984}
{"mode": "train", "epochs": 1, "timestep": 1685, "ep_reward": 965.3458251953125, "reward": 0.7527788281440735, "action": -0.5967647433280945}
{"mode": "train", "epochs": 1, "timestep": 1686, "ep_reward": 966.1546020507812, "reward": 0.8087942600250244, "action": 0.11605894565582275}
{"mode": "train", "epochs": 1, "timestep": 1687, "ep_reward": 967.0048217773438, "reward": 0.8502139449119568, "action": -0.8978783488273621}
{"mode": "train", "epochs": 1, "timestep": 1688, "ep_reward": 967.8695678710938, "reward": 0.8647211194038391, "action": -0.8531507253646851}
{"mode": "train", "epochs": 1, "timestep": 1689, "ep_reward": 968.7325439453125, "reward": 0.8629804849624634, "action": -1.1287288665771484}
{"mode": "train", "epochs": 1, "timestep": 1690, "ep_reward": 969.573486328125, "reward": 0.8409574031829834, "action": -0.8054222464561462}
{"mode": "train", "epochs": 1, "timestep": 1691, "ep_reward": 970.3740844726562, "reward": 0.8005899786949158, "action": -0.4512348175048828}
{"mode": "train", "epochs": 1, "timestep": 1692, "ep_reward": 971.112060546875, "reward": 0.7379865646362305, "action": -1.0164415836334229}
{"mode": "train", "epochs": 1, "timestep": 1693, "ep_reward": 971.748779296875, "reward": 0.636733889579773, "action": -0.8520524501800537}
{"mode": "train", "epochs": 1, "timestep": 1694, "ep_reward": 972.2471923828125, "reward": 0.4984229803085327, "action": -0.8659132122993469}
{"mode": "train", "epochs": 1, "timestep": 1695, "ep_reward": 972.595947265625, "reward": 0.3487420678138733, "action": -0.6326943635940552}
{"mode": "train", "epochs": 1, "timestep": 1696, "ep_reward": 972.83447265625, "reward": 0.2384992241859436, "action": -0.6122666597366333}
{"mode": "train", "epochs": 1, "timestep": 1697, "ep_reward": 972.9426879882812, "reward": 0.10823923349380493, "action": -0.7961554527282715}
{"mode": "train", "epochs": 1, "timestep": 1698, "ep_reward": 972.9503173828125, "reward": 0.007601439952850342, "action": -1.6061056852340698}
{"mode": "train", "epochs": 1, "timestep": 1699, "ep_reward": 973.1017456054688, "reward": 0.15142452716827393, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1700, "ep_reward": 973.3801879882812, "reward": 0.27841252088546753, "action": -1.7466726303100586}
{"mode": "train", "epochs": 1, "timestep": 1701, "ep_reward": 973.7886352539062, "reward": 0.40847569704055786, "action": -1.107094407081604}
{"mode": "train", "epochs": 1, "timestep": 1702, "ep_reward": 974.32373046875, "reward": 0.5351189970970154, "action": -1.3995561599731445}
{"mode": "train", "epochs": 1, "timestep": 1703, "ep_reward": 974.9615478515625, "reward": 0.6378465294837952, "action": -1.5288121700286865}
{"mode": "train", "epochs": 1, "timestep": 1704, "ep_reward": 975.6773071289062, "reward": 0.7157466411590576, "action": -1.5570883750915527}
{"mode": "train", "epochs": 1, "timestep": 1705, "ep_reward": 976.4470825195312, "reward": 0.7697471380233765, "action": -0.8682911992073059}
{"mode": "train", "epochs": 1, "timestep": 1706, "ep_reward": 977.2546997070312, "reward": 0.8076009750366211, "action": -0.8187382221221924}
{"mode": "train", "epochs": 1, "timestep": 1707, "ep_reward": 978.0784301757812, "reward": 0.8237481713294983, "action": -0.6250947713851929}
{"mode": "train", "epochs": 1, "timestep": 1708, "ep_reward": 978.8984375, "reward": 0.8200110197067261, "action": -0.7525679469108582}
{"mode": "train", "epochs": 1, "timestep": 1709, "ep_reward": 979.6901245117188, "reward": 0.7916696071624756, "action": -1.2210795879364014}
{"mode": "train", "epochs": 1, "timestep": 1710, "ep_reward": 980.4205932617188, "reward": 0.7304450273513794, "action": -1.005863070487976}
{"mode": "train", "epochs": 1, "timestep": 1711, "ep_reward": 981.0571899414062, "reward": 0.6366270780563354, "action": -1.7417957782745361}
{"mode": "train", "epochs": 1, "timestep": 1712, "ep_reward": 981.5469360351562, "reward": 0.489718496799469, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1713, "ep_reward": 981.92333984375, "reward": 0.37640565633773804, "action": -0.7911846041679382}
{"mode": "train", "epochs": 1, "timestep": 1714, "ep_reward": 982.1951293945312, "reward": 0.27181410789489746, "action": -1.0516059398651123}
{"mode": "train", "epochs": 1, "timestep": 1715, "ep_reward": 982.3424072265625, "reward": 0.14729130268096924, "action": -0.7046260833740234}
{"mode": "train", "epochs": 1, "timestep": 1716, "ep_reward": 982.3450927734375, "reward": 0.002707540988922119, "action": -0.9340641498565674}
{"mode": "train", "epochs": 1, "timestep": 1717, "ep_reward": 982.4578857421875, "reward": 0.11279898881912231, "action": -0.5098830461502075}
{"mode": "train", "epochs": 1, "timestep": 1718, "ep_reward": 982.71533203125, "reward": 0.25745099782943726, "action": -1.2958215475082397}
{"mode": "train", "epochs": 1, "timestep": 1719, "ep_reward": 983.1066284179688, "reward": 0.39127200841903687, "action": 0.08447861671447754}
{"mode": "train", "epochs": 1, "timestep": 1720, "ep_reward": 983.638427734375, "reward": 0.5318129062652588, "action": -0.5937926769256592}
{"mode": "train", "epochs": 1, "timestep": 1721, "ep_reward": 984.282470703125, "reward": 0.644047737121582, "action": -0.3632832169532776}
{"mode": "train", "epochs": 1, "timestep": 1722, "ep_reward": 985.0186157226562, "reward": 0.7361295223236084, "action": -0.3020002841949463}
{"mode": "train", "epochs": 1, "timestep": 1723, "ep_reward": 985.8248291015625, "reward": 0.8061947822570801, "action": -0.926697313785553}
{"mode": "train", "epochs": 1, "timestep": 1724, "ep_reward": 986.6766967773438, "reward": 0.8518427610397339, "action": -0.7401067018508911}
{"mode": "train", "epochs": 1, "timestep": 1725, "ep_reward": 987.56005859375, "reward": 0.8833411931991577, "action": -1.3000736236572266}
{"mode": "train", "epochs": 1, "timestep": 1726, "ep_reward": 988.4576416015625, "reward": 0.8976048827171326, "action": -1.550694227218628}
{"mode": "train", "epochs": 1, "timestep": 1727, "ep_reward": 989.3557739257812, "reward": 0.8981473445892334, "action": -0.4903656244277954}
{"mode": "train", "epochs": 1, "timestep": 1728, "ep_reward": 990.2495727539062, "reward": 0.8937988877296448, "action": -1.0014482736587524}
{"mode": "train", "epochs": 1, "timestep": 1729, "ep_reward": 991.1207885742188, "reward": 0.8712285757064819, "action": -1.9834380149841309}
{"mode": "train", "epochs": 1, "timestep": 1730, "ep_reward": 991.9424438476562, "reward": 0.8216666579246521, "action": -0.07754242420196533}
{"mode": "train", "epochs": 1, "timestep": 1731, "ep_reward": 992.7083740234375, "reward": 0.7659041881561279, "action": -0.586513876914978}
{"mode": "train", "epochs": 1, "timestep": 1732, "ep_reward": 993.38525390625, "reward": 0.6768513321876526, "action": -0.29023826122283936}
{"mode": "train", "epochs": 1, "timestep": 1733, "ep_reward": 993.94287109375, "reward": 0.5576411485671997, "action": -0.1470797061920166}
{"mode": "train", "epochs": 1, "timestep": 1734, "ep_reward": 994.3480834960938, "reward": 0.4051821231842041, "action": -0.13272219896316528}
{"mode": "train", "epochs": 1, "timestep": 1735, "ep_reward": 994.607666015625, "reward": 0.2595697045326233, "action": -1.0833264589309692}
{"mode": "train", "epochs": 1, "timestep": 1736, "ep_reward": 994.740478515625, "reward": 0.13280367851257324, "action": -1.606426477432251}
{"mode": "train", "epochs": 1, "timestep": 1737, "ep_reward": 994.7267456054688, "reward": -0.013729691505432129, "action": -0.5236083269119263}
{"mode": "train", "epochs": 1, "timestep": 1738, "ep_reward": 994.8541259765625, "reward": 0.1273823380470276, "action": -1.2593088150024414}
{"mode": "train", "epochs": 1, "timestep": 1739, "ep_reward": 995.1173095703125, "reward": 0.2631925344467163, "action": -0.759903609752655}
{"mode": "train", "epochs": 1, "timestep": 1740, "ep_reward": 995.5220336914062, "reward": 0.40474146604537964, "action": -0.4369487762451172}
{"mode": "train", "epochs": 1, "timestep": 1741, "ep_reward": 996.0601196289062, "reward": 0.5381163954734802, "action": -0.7371296882629395}
{"mode": "train", "epochs": 1, "timestep": 1742, "ep_reward": 996.7080688476562, "reward": 0.6479405164718628, "action": -0.5087639093399048}
{"mode": "train", "epochs": 1, "timestep": 1743, "ep_reward": 997.4453125, "reward": 0.7372415065765381, "action": -1.0852246284484863}
{"mode": "train", "epochs": 1, "timestep": 1744, "ep_reward": 998.2442626953125, "reward": 0.798959493637085, "action": -0.7093770503997803}
{"mode": "train", "epochs": 1, "timestep": 1745, "ep_reward": 999.0889892578125, "reward": 0.8447418212890625, "action": -0.19381928443908691}
{"mode": "train", "epochs": 1, "timestep": 1746, "ep_reward": 999.9663696289062, "reward": 0.8774023652076721, "action": -1.4278390407562256}
{"mode": "train", "epochs": 1, "timestep": 1747, "ep_reward": 1000.8522338867188, "reward": 0.8858909606933594, "action": -1.3376941680908203}
{"mode": "train", "epochs": 1, "timestep": 1748, "ep_reward": 1001.7333374023438, "reward": 0.8811122179031372, "action": -1.2739434242248535}
{"mode": "train", "epochs": 1, "timestep": 1749, "ep_reward": 1002.5945434570312, "reward": 0.861197292804718, "action": -0.505835235118866}
{"mode": "train", "epochs": 1, "timestep": 1750, "ep_reward": 1003.4239501953125, "reward": 0.8293846845626831, "action": -0.8433860540390015}
{"mode": "train", "epochs": 1, "timestep": 1751, "ep_reward": 1004.1956176757812, "reward": 0.7716798186302185, "action": -1.0839167833328247}
{"mode": "train", "epochs": 1, "timestep": 1752, "ep_reward": 1004.8773803710938, "reward": 0.6817556619644165, "action": -0.8494083881378174}
{"mode": "train", "epochs": 1, "timestep": 1753, "ep_reward": 1005.4354248046875, "reward": 0.558037281036377, "action": -1.6791682243347168}
{"mode": "train", "epochs": 1, "timestep": 1754, "ep_reward": 1005.816162109375, "reward": 0.3807528614997864, "action": -1.6852610111236572}
{"mode": "train", "epochs": 1, "timestep": 1755, "ep_reward": 1006.0892333984375, "reward": 0.27306675910949707, "action": -0.7761364579200745}
{"mode": "train", "epochs": 1, "timestep": 1756, "ep_reward": 1006.2378540039062, "reward": 0.1486300826072693, "action": -1.4241769313812256}
{"mode": "train", "epochs": 1, "timestep": 1757, "ep_reward": 1006.2421875, "reward": 0.0043601393699646, "action": -0.8933227062225342}
{"mode": "train", "epochs": 1, "timestep": 1758, "ep_reward": 1006.3534545898438, "reward": 0.11128932237625122, "action": -0.7532438039779663}
{"mode": "train", "epochs": 1, "timestep": 1759, "ep_reward": 1006.6064453125, "reward": 0.2529885768890381, "action": -0.08732467889785767}
{"mode": "train", "epochs": 1, "timestep": 1760, "ep_reward": 1007.0083618164062, "reward": 0.4018932580947876, "action": -1.0648093223571777}
{"mode": "train", "epochs": 1, "timestep": 1761, "ep_reward": 1007.5355834960938, "reward": 0.5272161960601807, "action": -0.681320309638977}
{"mode": "train", "epochs": 1, "timestep": 1762, "ep_reward": 1008.1749267578125, "reward": 0.6393630504608154, "action": -0.7324206829071045}
{"mode": "train", "epochs": 1, "timestep": 1763, "ep_reward": 1008.9037475585938, "reward": 0.7288410663604736, "action": -1.5005640983581543}
{"mode": "train", "epochs": 1, "timestep": 1764, "ep_reward": 1009.6937255859375, "reward": 0.7899908423423767, "action": -0.980800211429596}
{"mode": "train", "epochs": 1, "timestep": 1765, "ep_reward": 1010.53076171875, "reward": 0.8370070457458496, "action": -0.9271894693374634}
{"mode": "train", "epochs": 1, "timestep": 1766, "ep_reward": 1011.398193359375, "reward": 0.8674561381340027, "action": -0.10065609216690063}
{"mode": "train", "epochs": 1, "timestep": 1767, "ep_reward": 1012.2872924804688, "reward": 0.8890955448150635, "action": -1.3499754667282104}
{"mode": "train", "epochs": 1, "timestep": 1768, "ep_reward": 1013.1746826171875, "reward": 0.8873648643493652, "action": -1.0325944423675537}
{"mode": "train", "epochs": 1, "timestep": 1769, "ep_reward": 1014.0481567382812, "reward": 0.8734995126724243, "action": -1.4757821559906006}
{"mode": "train", "epochs": 1, "timestep": 1770, "ep_reward": 1014.8865356445312, "reward": 0.8383713364601135, "action": -1.3407305479049683}
{"mode": "train", "epochs": 1, "timestep": 1771, "ep_reward": 1015.6679077148438, "reward": 0.7813434600830078, "action": -1.3201621770858765}
{"mode": "train", "epochs": 1, "timestep": 1772, "ep_reward": 1016.3624267578125, "reward": 0.6945143938064575, "action": -1.5287717580795288}
{"mode": "train", "epochs": 1, "timestep": 1773, "ep_reward": 1016.9295654296875, "reward": 0.567168116569519, "action": -1.4998290538787842}
{"mode": "train", "epochs": 1, "timestep": 1774, "ep_reward": 1017.3255004882812, "reward": 0.3959386944770813, "action": -1.7973805665969849}
{"mode": "train", "epochs": 1, "timestep": 1775, "ep_reward": 1017.6172485351562, "reward": 0.29171937704086304, "action": -0.7747287750244141}
{"mode": "train", "epochs": 1, "timestep": 1776, "ep_reward": 1017.7879028320312, "reward": 0.1706249713897705, "action": -1.230661392211914}
{"mode": "train", "epochs": 1, "timestep": 1777, "ep_reward": 1017.8173828125, "reward": 0.029464900493621826, "action": -1.8676016330718994}
{"mode": "train", "epochs": 1, "timestep": 1778, "ep_reward": 1017.9052734375, "reward": 0.08790862560272217, "action": -0.15639275312423706}
{"mode": "train", "epochs": 1, "timestep": 1779, "ep_reward": 1018.1416015625, "reward": 0.23630023002624512, "action": -0.5475253462791443}
{"mode": "train", "epochs": 1, "timestep": 1780, "ep_reward": 1018.5206298828125, "reward": 0.3790503740310669, "action": -0.5492749214172363}
{"mode": "train", "epochs": 1, "timestep": 1781, "ep_reward": 1019.032958984375, "reward": 0.5122998952865601, "action": -0.872226357460022}
{"mode": "train", "epochs": 1, "timestep": 1782, "ep_reward": 1019.6575927734375, "reward": 0.6246638298034668, "action": -0.9004673957824707}
{"mode": "train", "epochs": 1, "timestep": 1783, "ep_reward": 1020.3735961914062, "reward": 0.7160173654556274, "action": -0.8281539678573608}
{"mode": "train", "epochs": 1, "timestep": 1784, "ep_reward": 1021.1602783203125, "reward": 0.7866989374160767, "action": -1.1040732860565186}
{"mode": "train", "epochs": 1, "timestep": 1785, "ep_reward": 1021.9957885742188, "reward": 0.8355062007904053, "action": -1.7366561889648438}
{"mode": "train", "epochs": 1, "timestep": 1786, "ep_reward": 1022.8587646484375, "reward": 0.86295485496521, "action": -1.755331039428711}
{"mode": "train", "epochs": 1, "timestep": 1787, "ep_reward": 1023.7346801757812, "reward": 0.8759089112281799, "action": -1.1115291118621826}
{"mode": "train", "epochs": 1, "timestep": 1788, "ep_reward": 1024.6141357421875, "reward": 0.8794909715652466, "action": -0.9992157816886902}
{"mode": "train", "epochs": 1, "timestep": 1789, "ep_reward": 1025.4827880859375, "reward": 0.868675172328949, "action": -1.1754697561264038}
{"mode": "train", "epochs": 1, "timestep": 1790, "ep_reward": 1026.3214111328125, "reward": 0.8386631011962891, "action": -0.9469154477119446}
{"mode": "train", "epochs": 1, "timestep": 1791, "ep_reward": 1027.1099853515625, "reward": 0.788621723651886, "action": -0.8623596429824829}
{"mode": "train", "epochs": 1, "timestep": 1792, "ep_reward": 1027.821533203125, "reward": 0.7115198373794556, "action": -1.487602710723877}
{"mode": "train", "epochs": 1, "timestep": 1793, "ep_reward": 1028.412841796875, "reward": 0.5913416147232056, "action": -1.4038852453231812}
{"mode": "train", "epochs": 1, "timestep": 1794, "ep_reward": 1028.8421630859375, "reward": 0.42927271127700806, "action": -0.4749034643173218}
{"mode": "train", "epochs": 1, "timestep": 1795, "ep_reward": 1029.151611328125, "reward": 0.30950647592544556, "action": -1.7833386659622192}
{"mode": "train", "epochs": 1, "timestep": 1796, "ep_reward": 1029.343505859375, "reward": 0.19187235832214355, "action": -1.1091196537017822}
{"mode": "train", "epochs": 1, "timestep": 1797, "ep_reward": 1029.3975830078125, "reward": 0.05410778522491455, "action": -1.1726181507110596}
{"mode": "train", "epochs": 1, "timestep": 1798, "ep_reward": 1029.461669921875, "reward": 0.06413573026657104, "action": -0.622715950012207}
{"mode": "train", "epochs": 1, "timestep": 1799, "ep_reward": 1029.6676025390625, "reward": 0.20594489574432373, "action": -1.3355958461761475}
{"mode": "train", "epochs": 1, "timestep": 1800, "ep_reward": 1030.0086669921875, "reward": 0.34104591608047485, "action": -1.0291378498077393}
{"mode": "train", "epochs": 1, "timestep": 1801, "ep_reward": 1030.4827880859375, "reward": 0.4740949273109436, "action": -1.5913230180740356}
{"mode": "train", "epochs": 1, "timestep": 1802, "ep_reward": 1031.068115234375, "reward": 0.5852808356285095, "action": -1.5538725852966309}
{"mode": "train", "epochs": 1, "timestep": 1803, "ep_reward": 1031.7452392578125, "reward": 0.677096962928772, "action": -0.4810681939125061}
{"mode": "train", "epochs": 1, "timestep": 1804, "ep_reward": 1032.502197265625, "reward": 0.7570046782493591, "action": -1.168289065361023}
{"mode": "train", "epochs": 1, "timestep": 1805, "ep_reward": 1033.3094482421875, "reward": 0.8072484731674194, "action": -0.5242031812667847}
{"mode": "train", "epochs": 1, "timestep": 1806, "ep_reward": 1034.1527099609375, "reward": 0.8432357907295227, "action": -0.5528033375740051}
{"mode": "train", "epochs": 1, "timestep": 1807, "ep_reward": 1035.01318359375, "reward": 0.8604819178581238, "action": -1.0938875675201416}
{"mode": "train", "epochs": 1, "timestep": 1808, "ep_reward": 1035.868896484375, "reward": 0.855740487575531, "action": -0.6630891561508179}
{"mode": "train", "epochs": 1, "timestep": 1809, "ep_reward": 1036.705078125, "reward": 0.8362303972244263, "action": -0.5612530708312988}
{"mode": "train", "epochs": 1, "timestep": 1810, "ep_reward": 1037.501220703125, "reward": 0.7961341142654419, "action": -1.3490777015686035}
{"mode": "train", "epochs": 1, "timestep": 1811, "ep_reward": 1038.2215576171875, "reward": 0.7203905582427979, "action": -1.8757543563842773}
{"mode": "train", "epochs": 1, "timestep": 1812, "ep_reward": 1038.822998046875, "reward": 0.6015000343322754, "action": -0.273105263710022}
{"mode": "train", "epochs": 1, "timestep": 1813, "ep_reward": 1039.2850341796875, "reward": 0.4620823264122009, "action": -1.153804898262024}
{"mode": "train", "epochs": 1, "timestep": 1814, "ep_reward": 1039.618408203125, "reward": 0.33333224058151245, "action": -0.26596879959106445}
{"mode": "train", "epochs": 1, "timestep": 1815, "ep_reward": 1039.83837890625, "reward": 0.22002124786376953, "action": -0.7836213111877441}
{"mode": "train", "epochs": 1, "timestep": 1816, "ep_reward": 1039.9251708984375, "reward": 0.08674222230911255, "action": -0.8094539642333984}
{"mode": "train", "epochs": 1, "timestep": 1817, "ep_reward": 1039.9559326171875, "reward": 0.030803442001342773, "action": -1.0400359630584717}
{"mode": "train", "epochs": 1, "timestep": 1818, "ep_reward": 1040.127685546875, "reward": 0.1717236042022705, "action": -0.6535700559616089}
{"mode": "train", "epochs": 1, "timestep": 1819, "ep_reward": 1040.443603515625, "reward": 0.3159012794494629, "action": -1.3697837591171265}
{"mode": "train", "epochs": 1, "timestep": 1820, "ep_reward": 1040.889892578125, "reward": 0.4462331533432007, "action": -1.1670864820480347}
{"mode": "train", "epochs": 1, "timestep": 1821, "ep_reward": 1041.4560546875, "reward": 0.5661895871162415, "action": -0.5803124308586121}
{"mode": "train", "epochs": 1, "timestep": 1822, "ep_reward": 1042.1282958984375, "reward": 0.6722061634063721, "action": -0.954953134059906}
{"mode": "train", "epochs": 1, "timestep": 1823, "ep_reward": 1042.879150390625, "reward": 0.7507970333099365, "action": -0.8660280108451843}
{"mode": "train", "epochs": 1, "timestep": 1824, "ep_reward": 1043.6875, "reward": 0.8083892464637756, "action": -0.7993021011352539}
{"mode": "train", "epochs": 1, "timestep": 1825, "ep_reward": 1044.5345458984375, "reward": 0.8470088243484497, "action": -0.46847474575042725}
{"mode": "train", "epochs": 1, "timestep": 1826, "ep_reward": 1045.4056396484375, "reward": 0.871074914932251, "action": -0.958755373954773}
{"mode": "train", "epochs": 1, "timestep": 1827, "ep_reward": 1046.2811279296875, "reward": 0.8755242228507996, "action": -0.4804123640060425}
{"mode": "train", "epochs": 1, "timestep": 1828, "ep_reward": 1047.1494140625, "reward": 0.8683264255523682, "action": -0.33930307626724243}
{"mode": "train", "epochs": 1, "timestep": 1829, "ep_reward": 1047.9947509765625, "reward": 0.845345139503479, "action": -0.870080292224884}
{"mode": "train", "epochs": 1, "timestep": 1830, "ep_reward": 1048.791748046875, "reward": 0.7969796657562256, "action": -0.3980267643928528}
{"mode": "train", "epochs": 1, "timestep": 1831, "ep_reward": 1049.5191650390625, "reward": 0.7273574471473694, "action": -0.5499095916748047}
{"mode": "train", "epochs": 1, "timestep": 1832, "ep_reward": 1050.1435546875, "reward": 0.6243376731872559, "action": -1.7846498489379883}
{"mode": "train", "epochs": 1, "timestep": 1833, "ep_reward": 1050.609375, "reward": 0.465779185295105, "action": -1.5911651849746704}
{"mode": "train", "epochs": 1, "timestep": 1834, "ep_reward": 1050.930419921875, "reward": 0.32101690769195557, "action": -1.1513005495071411}
{"mode": "train", "epochs": 1, "timestep": 1835, "ep_reward": 1051.1358642578125, "reward": 0.2054169774055481, "action": -1.001168131828308}
{"mode": "train", "epochs": 1, "timestep": 1836, "ep_reward": 1051.2056884765625, "reward": 0.0697927474975586, "action": -1.0381855964660645}
{"mode": "train", "epochs": 1, "timestep": 1837, "ep_reward": 1051.2540283203125, "reward": 0.048344314098358154, "action": -1.0274242162704468}
{"mode": "train", "epochs": 1, "timestep": 1838, "ep_reward": 1051.4407958984375, "reward": 0.18681365251541138, "action": -1.4580352306365967}
{"mode": "train", "epochs": 1, "timestep": 1839, "ep_reward": 1051.7620849609375, "reward": 0.32124239206314087, "action": -1.5363187789916992}
{"mode": "train", "epochs": 1, "timestep": 1840, "ep_reward": 1052.2125244140625, "reward": 0.4504377841949463, "action": -1.7296253442764282}
{"mode": "train", "epochs": 1, "timestep": 1841, "ep_reward": 1052.7764892578125, "reward": 0.5639175176620483, "action": -0.6080302000045776}
{"mode": "train", "epochs": 1, "timestep": 1842, "ep_reward": 1053.4459228515625, "reward": 0.6694779396057129, "action": -0.902975857257843}
{"mode": "train", "epochs": 1, "timestep": 1843, "ep_reward": 1054.192626953125, "reward": 0.7467176914215088, "action": -1.5107957124710083}
{"mode": "train", "epochs": 1, "timestep": 1844, "ep_reward": 1054.9876708984375, "reward": 0.7950465083122253, "action": -0.8706563711166382}
{"mode": "train", "epochs": 1, "timestep": 1845, "ep_reward": 1055.816162109375, "reward": 0.828477680683136, "action": -1.1783503293991089}
{"mode": "train", "epochs": 1, "timestep": 1846, "ep_reward": 1056.6552734375, "reward": 0.8391529321670532, "action": -1.1451157331466675}
{"mode": "train", "epochs": 1, "timestep": 1847, "ep_reward": 1057.4854736328125, "reward": 0.83017498254776, "action": -0.7901120185852051}
{"mode": "train", "epochs": 1, "timestep": 1848, "ep_reward": 1058.2879638671875, "reward": 0.8024588823318481, "action": -1.08319890499115}
{"mode": "train", "epochs": 1, "timestep": 1849, "ep_reward": 1059.0330810546875, "reward": 0.7451199889183044, "action": -1.8988800048828125}
{"mode": "train", "epochs": 1, "timestep": 1850, "ep_reward": 1059.6767578125, "reward": 0.6436792612075806, "action": -1.5270776748657227}
{"mode": "train", "epochs": 1, "timestep": 1851, "ep_reward": 1060.1798095703125, "reward": 0.5030390024185181, "action": -0.6678502559661865}
{"mode": "train", "epochs": 1, "timestep": 1852, "ep_reward": 1060.5618896484375, "reward": 0.3820599913597107, "action": -1.0507283210754395}
{"mode": "train", "epochs": 1, "timestep": 1853, "ep_reward": 1060.840576171875, "reward": 0.27870386838912964, "action": -1.0846407413482666}
{"mode": "train", "epochs": 1, "timestep": 1854, "ep_reward": 1060.995849609375, "reward": 0.1553184986114502, "action": -1.3141605854034424}
{"mode": "train", "epochs": 1, "timestep": 1855, "ep_reward": 1061.0078125, "reward": 0.011950492858886719, "action": -1.4177780151367188}
{"mode": "train", "epochs": 1, "timestep": 1856, "ep_reward": 1061.112060546875, "reward": 0.1042662262916565, "action": -1.036816954612732}
{"mode": "train", "epochs": 1, "timestep": 1857, "ep_reward": 1061.354248046875, "reward": 0.2422134280204773, "action": -0.7710223197937012}
{"mode": "train", "epochs": 1, "timestep": 1858, "ep_reward": 1061.73828125, "reward": 0.3840312957763672, "action": -0.23384499549865723}
{"mode": "train", "epochs": 1, "timestep": 1859, "ep_reward": 1062.2601318359375, "reward": 0.5218181014060974, "action": -0.8148875832557678}
