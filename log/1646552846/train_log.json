{"mode": "train", "epochs": 1, "timestep": 1, "ep_reward": 0.58258056640625, "reward": 0.58258056640625, "action": 0.5476126670837402}
{"mode": "train", "epochs": 1, "timestep": 2, "ep_reward": 1.1617238521575928, "reward": 0.5791433453559875, "action": 0.7606295347213745}
{"mode": "train", "epochs": 1, "timestep": 3, "ep_reward": 1.7319605350494385, "reward": 0.5702366828918457, "action": -0.10710437595844269}
{"mode": "train", "epochs": 1, "timestep": 4, "ep_reward": 2.2845005989074707, "reward": 0.5525400638580322, "action": 1.1620665788650513}
{"mode": "train", "epochs": 1, "timestep": 5, "ep_reward": 2.8175859451293945, "reward": 0.5330852270126343, "action": -0.39096295833587646}
{"mode": "train", "epochs": 1, "timestep": 6, "ep_reward": 3.3206710815429688, "reward": 0.5030851364135742, "action": 1.3163542747497559}
{"mode": "train", "epochs": 1, "timestep": 7, "ep_reward": 3.7966346740722656, "reward": 0.47596365213394165, "action": 0.7789449095726013}
{"mode": "train", "epochs": 1, "timestep": 8, "ep_reward": 4.242452621459961, "reward": 0.4458181858062744, "action": 0.15749047696590424}
{"mode": "train", "epochs": 1, "timestep": 9, "ep_reward": 4.654006481170654, "reward": 0.4115539789199829, "action": -0.30363088846206665}
{"mode": "train", "epochs": 1, "timestep": 10, "ep_reward": 5.027406215667725, "reward": 0.373399555683136, "action": 0.31609371304512024}
{"mode": "train", "epochs": 1, "timestep": 11, "ep_reward": 5.414053916931152, "reward": 0.38664746284484863, "action": -0.050242602825164795}
{"mode": "train", "epochs": 1, "timestep": 12, "ep_reward": 5.83514404296875, "reward": 0.4210900664329529, "action": 0.013292372226715088}
{"mode": "train", "epochs": 1, "timestep": 13, "ep_reward": 6.289200782775879, "reward": 0.454056978225708, "action": 0.24301666021347046}
{"mode": "train", "epochs": 1, "timestep": 14, "ep_reward": 6.7732834815979, "reward": 0.4840826988220215, "action": 0.23902103304862976}
{"mode": "train", "epochs": 1, "timestep": 15, "ep_reward": 7.282447814941406, "reward": 0.5091642141342163, "action": -0.27576714754104614}
{"mode": "train", "epochs": 1, "timestep": 16, "ep_reward": 7.8111467361450195, "reward": 0.5286991000175476, "action": 0.10463821887969971}
{"mode": "train", "epochs": 1, "timestep": 17, "ep_reward": 8.353911399841309, "reward": 0.5427650213241577, "action": 0.1544787883758545}
{"mode": "train", "epochs": 1, "timestep": 18, "ep_reward": 8.903701782226562, "reward": 0.5497902631759644, "action": 0.18596294522285461}
{"mode": "train", "epochs": 1, "timestep": 19, "ep_reward": 9.452960014343262, "reward": 0.5492578148841858, "action": 0.05222618579864502}
{"mode": "train", "epochs": 1, "timestep": 20, "ep_reward": 9.994468688964844, "reward": 0.5415091514587402, "action": 0.20329731702804565}
{"mode": "train", "epochs": 1, "timestep": 21, "ep_reward": 10.520709037780762, "reward": 0.5262407064437866, "action": 0.6341842412948608}
{"mode": "train", "epochs": 1, "timestep": 22, "ep_reward": 11.022756576538086, "reward": 0.502047061920166, "action": -0.42141392827033997}
{"mode": "train", "epochs": 1, "timestep": 23, "ep_reward": 11.498486518859863, "reward": 0.47572994232177734, "action": -0.33177971839904785}
{"mode": "train", "epochs": 1, "timestep": 24, "ep_reward": 11.944707870483398, "reward": 0.4462212920188904, "action": 0.19549338519573212}
{"mode": "train", "epochs": 1, "timestep": 25, "ep_reward": 12.356529235839844, "reward": 0.41182100772857666, "action": -0.01306634396314621}
{"mode": "train", "epochs": 1, "timestep": 26, "ep_reward": 12.733067512512207, "reward": 0.3765382170677185, "action": -0.06832996755838394}
{"mode": "train", "epochs": 1, "timestep": 27, "ep_reward": 13.118742942810059, "reward": 0.38567566871643066, "action": 0.3313947021961212}
{"mode": "train", "epochs": 1, "timestep": 28, "ep_reward": 13.537818908691406, "reward": 0.4190756678581238, "action": 0.1462697684764862}
{"mode": "train", "epochs": 1, "timestep": 29, "ep_reward": 13.989766120910645, "reward": 0.45194751024246216, "action": -0.2779642343521118}
{"mode": "train", "epochs": 1, "timestep": 30, "ep_reward": 14.472274780273438, "reward": 0.4825083017349243, "action": 0.006539583206176758}
{"mode": "train", "epochs": 1, "timestep": 31, "ep_reward": 14.980422973632812, "reward": 0.5081479549407959, "action": -0.15342065691947937}
{"mode": "train", "epochs": 1, "timestep": 32, "ep_reward": 15.509012222290039, "reward": 0.5285890102386475, "action": -0.3500969111919403}
{"mode": "train", "epochs": 1, "timestep": 33, "ep_reward": 16.05124855041504, "reward": 0.5422365665435791, "action": -0.7365043759346008}
{"mode": "train", "epochs": 1, "timestep": 34, "ep_reward": 16.598482131958008, "reward": 0.5472341775894165, "action": -0.5999047160148621}
{"mode": "train", "epochs": 1, "timestep": 35, "ep_reward": 17.141395568847656, "reward": 0.5429128408432007, "action": -0.6777160167694092}
{"mode": "train", "epochs": 1, "timestep": 36, "ep_reward": 17.6706485748291, "reward": 0.5292521715164185, "action": 0.09950130432844162}
{"mode": "train", "epochs": 1, "timestep": 37, "ep_reward": 18.18076515197754, "reward": 0.510116457939148, "action": -0.009448796510696411}
{"mode": "train", "epochs": 1, "timestep": 38, "ep_reward": 18.666048049926758, "reward": 0.4852825999259949, "action": -0.033506765961647034}
{"mode": "train", "epochs": 1, "timestep": 39, "ep_reward": 19.121782302856445, "reward": 0.45573359727859497, "action": 0.42035144567489624}
{"mode": "train", "epochs": 1, "timestep": 40, "ep_reward": 19.54714584350586, "reward": 0.42536407709121704, "action": 0.3699148893356323}
{"mode": "train", "epochs": 1, "timestep": 41, "ep_reward": 19.941186904907227, "reward": 0.3940403461456299, "action": -0.3705478012561798}
{"mode": "train", "epochs": 1, "timestep": 42, "ep_reward": 20.31249237060547, "reward": 0.37130630016326904, "action": 0.8250864744186401}
{"mode": "train", "epochs": 1, "timestep": 43, "ep_reward": 20.71683120727539, "reward": 0.4043388366699219, "action": 0.18521592020988464}
{"mode": "train", "epochs": 1, "timestep": 44, "ep_reward": 21.15066146850586, "reward": 0.43382948637008667, "action": -0.06428368389606476}
{"mode": "train", "epochs": 1, "timestep": 45, "ep_reward": 21.611377716064453, "reward": 0.4607168436050415, "action": 0.040351882576942444}
{"mode": "train", "epochs": 1, "timestep": 46, "ep_reward": 22.095964431762695, "reward": 0.484586238861084, "action": 0.8623827695846558}
{"mode": "train", "epochs": 1, "timestep": 47, "ep_reward": 22.5994873046875, "reward": 0.5035220384597778, "action": 0.2926216423511505}
{"mode": "train", "epochs": 1, "timestep": 48, "ep_reward": 23.114797592163086, "reward": 0.5153111219406128, "action": -0.286576509475708}
{"mode": "train", "epochs": 1, "timestep": 49, "ep_reward": 23.63665199279785, "reward": 0.5218542814254761, "action": -0.7188587784767151}
{"mode": "train", "epochs": 1, "timestep": 50, "ep_reward": 24.161476135253906, "reward": 0.5248247981071472, "action": -0.2281375229358673}
{"mode": "train", "epochs": 1, "timestep": 51, "ep_reward": 24.684524536132812, "reward": 0.5230478048324585, "action": 0.7782842516899109}
{"mode": "train", "epochs": 1, "timestep": 52, "ep_reward": 25.197467803955078, "reward": 0.512944221496582, "action": -0.04806175082921982}
{"mode": "train", "epochs": 1, "timestep": 53, "ep_reward": 25.695222854614258, "reward": 0.4977550506591797, "action": 0.5660520792007446}
{"mode": "train", "epochs": 1, "timestep": 54, "ep_reward": 26.17028045654297, "reward": 0.4750579595565796, "action": 0.28849953413009644}
{"mode": "train", "epochs": 1, "timestep": 55, "ep_reward": 26.617977142333984, "reward": 0.447695791721344, "action": 0.010121025145053864}
{"mode": "train", "epochs": 1, "timestep": 56, "ep_reward": 27.035879135131836, "reward": 0.41790252923965454, "action": -0.9509560465812683}
{"mode": "train", "epochs": 1, "timestep": 57, "ep_reward": 27.427839279174805, "reward": 0.39195942878723145, "action": 0.2803990840911865}
{"mode": "train", "epochs": 1, "timestep": 58, "ep_reward": 27.804927825927734, "reward": 0.3770875930786133, "action": -0.40953245759010315}
{"mode": "train", "epochs": 1, "timestep": 59, "ep_reward": 28.210712432861328, "reward": 0.4057839512825012, "action": -0.30757129192352295}
{"mode": "train", "epochs": 1, "timestep": 60, "ep_reward": 28.642988204956055, "reward": 0.4322749376296997, "action": -0.11468425393104553}
{"mode": "train", "epochs": 1, "timestep": 61, "ep_reward": 29.098901748657227, "reward": 0.4559134840965271, "action": 0.017030656337738037}
{"mode": "train", "epochs": 1, "timestep": 62, "ep_reward": 29.575227737426758, "reward": 0.4763256907463074, "action": 0.9437191486358643}
{"mode": "train", "epochs": 1, "timestep": 63, "ep_reward": 30.069324493408203, "reward": 0.49409645795822144, "action": -0.19365352392196655}
{"mode": "train", "epochs": 1, "timestep": 64, "ep_reward": 30.578332901000977, "reward": 0.5090087652206421, "action": 0.3009946346282959}
{"mode": "train", "epochs": 1, "timestep": 65, "ep_reward": 31.097347259521484, "reward": 0.5190150737762451, "action": 0.20358392596244812}
{"mode": "train", "epochs": 1, "timestep": 66, "ep_reward": 31.62167739868164, "reward": 0.524329423904419, "action": 0.3652734160423279}
{"mode": "train", "epochs": 1, "timestep": 67, "ep_reward": 32.14669418334961, "reward": 0.5250161290168762, "action": 0.1464327722787857}
{"mode": "train", "epochs": 1, "timestep": 68, "ep_reward": 32.66713333129883, "reward": 0.5204397439956665, "action": 0.8220625519752502}
{"mode": "train", "epochs": 1, "timestep": 69, "ep_reward": 33.18014907836914, "reward": 0.5130169987678528, "action": 1.0861384868621826}
{"mode": "train", "epochs": 1, "timestep": 70, "ep_reward": 33.68415832519531, "reward": 0.5040110349655151, "action": -0.36174339056015015}
{"mode": "train", "epochs": 1, "timestep": 71, "ep_reward": 34.171932220458984, "reward": 0.4877723455429077, "action": 0.24366101622581482}
{"mode": "train", "epochs": 1, "timestep": 72, "ep_reward": 34.640472412109375, "reward": 0.46854132413864136, "action": 0.2435186803340912}
{"mode": "train", "epochs": 1, "timestep": 73, "ep_reward": 35.086952209472656, "reward": 0.44648152589797974, "action": 0.19042208790779114}
{"mode": "train", "epochs": 1, "timestep": 74, "ep_reward": 35.509159088134766, "reward": 0.4222067594528198, "action": -0.2035832554101944}
{"mode": "train", "epochs": 1, "timestep": 75, "ep_reward": 35.90385055541992, "reward": 0.3946916460990906, "action": 0.09393937885761261}
{"mode": "train", "epochs": 1, "timestep": 76, "ep_reward": 36.27919006347656, "reward": 0.375339150428772, "action": 0.13975870609283447}
{"mode": "train", "epochs": 1, "timestep": 77, "ep_reward": 36.680973052978516, "reward": 0.4017826318740845, "action": -0.1753586232662201}
{"mode": "train", "epochs": 1, "timestep": 78, "ep_reward": 37.108070373535156, "reward": 0.42709898948669434, "action": 0.5364537239074707}
{"mode": "train", "epochs": 1, "timestep": 79, "ep_reward": 37.558868408203125, "reward": 0.45079970359802246, "action": -0.17690734565258026}
{"mode": "train", "epochs": 1, "timestep": 80, "ep_reward": 38.02951431274414, "reward": 0.47064685821533203, "action": 0.5969851016998291}
{"mode": "train", "epochs": 1, "timestep": 81, "ep_reward": 38.51620101928711, "reward": 0.48668503761291504, "action": 0.2810741662979126}
{"mode": "train", "epochs": 1, "timestep": 82, "ep_reward": 39.0131721496582, "reward": 0.4969692826271057, "action": 0.8467313647270203}
{"mode": "train", "epochs": 1, "timestep": 83, "ep_reward": 39.513580322265625, "reward": 0.5004062652587891, "action": 0.6616512537002563}
{"mode": "train", "epochs": 1, "timestep": 84, "ep_reward": 40.01005172729492, "reward": 0.4964727759361267, "action": -0.36896055936813354}
{"mode": "train", "epochs": 1, "timestep": 85, "ep_reward": 40.499107360839844, "reward": 0.4890550374984741, "action": 0.37786200642585754}
{"mode": "train", "epochs": 1, "timestep": 86, "ep_reward": 40.97476577758789, "reward": 0.47565823793411255, "action": 0.6786421537399292}
{"mode": "train", "epochs": 1, "timestep": 87, "ep_reward": 41.43050003051758, "reward": 0.45573586225509644, "action": -0.24738410115242004}
{"mode": "train", "epochs": 1, "timestep": 88, "ep_reward": 41.865272521972656, "reward": 0.43477362394332886, "action": 0.22373640537261963}
{"mode": "train", "epochs": 1, "timestep": 89, "ep_reward": 42.27528381347656, "reward": 0.4100101590156555, "action": 0.2802637815475464}
{"mode": "train", "epochs": 1, "timestep": 90, "ep_reward": 42.65822982788086, "reward": 0.38294684886932373, "action": 0.5130639672279358}
{"mode": "train", "epochs": 1, "timestep": 91, "ep_reward": 43.04587936401367, "reward": 0.38764822483062744, "action": -0.19333305954933167}
{"mode": "train", "epochs": 1, "timestep": 92, "ep_reward": 43.460323333740234, "reward": 0.41444551944732666, "action": 1.315211534500122}
{"mode": "train", "epochs": 1, "timestep": 93, "ep_reward": 43.90022277832031, "reward": 0.43989837169647217, "action": -0.7264619469642639}
{"mode": "train", "epochs": 1, "timestep": 94, "ep_reward": 44.36653518676758, "reward": 0.4663124084472656, "action": 0.46250468492507935}
{"mode": "train", "epochs": 1, "timestep": 95, "ep_reward": 44.85430145263672, "reward": 0.48776543140411377, "action": 0.209746852517128}
{"mode": "train", "epochs": 1, "timestep": 96, "ep_reward": 45.36054992675781, "reward": 0.5062465667724609, "action": -0.7174420356750488}
{"mode": "train", "epochs": 1, "timestep": 97, "ep_reward": 45.87975311279297, "reward": 0.5192012786865234, "action": 0.2083534598350525}
{"mode": "train", "epochs": 1, "timestep": 98, "ep_reward": 46.405601501464844, "reward": 0.5258494019508362, "action": -0.43822091817855835}
{"mode": "train", "epochs": 1, "timestep": 99, "ep_reward": 46.93136215209961, "reward": 0.5257620811462402, "action": -0.11855021864175797}
{"mode": "train", "epochs": 1, "timestep": 100, "ep_reward": 47.450504302978516, "reward": 0.5191419124603271, "action": 0.5215154886245728}
{"mode": "train", "epochs": 1, "timestep": 101, "ep_reward": 47.959312438964844, "reward": 0.5088083148002625, "action": -0.19756796956062317}
{"mode": "train", "epochs": 1, "timestep": 102, "ep_reward": 48.45136642456055, "reward": 0.4920528531074524, "action": -0.22775663435459137}
{"mode": "train", "epochs": 1, "timestep": 103, "ep_reward": 48.92113494873047, "reward": 0.469768226146698, "action": -0.5082204341888428}
{"mode": "train", "epochs": 1, "timestep": 104, "ep_reward": 49.362579345703125, "reward": 0.44144338369369507, "action": 0.37177935242652893}
{"mode": "train", "epochs": 1, "timestep": 105, "ep_reward": 49.776161193847656, "reward": 0.4135836958885193, "action": 0.5071027874946594}
{"mode": "train", "epochs": 1, "timestep": 106, "ep_reward": 50.16236114501953, "reward": 0.3862003684043884, "action": 0.6571934819221497}
{"mode": "train", "epochs": 1, "timestep": 107, "ep_reward": 50.544776916503906, "reward": 0.38241469860076904, "action": -0.08209200203418732}
{"mode": "train", "epochs": 1, "timestep": 108, "ep_reward": 50.95319366455078, "reward": 0.40841740369796753, "action": -0.760437548160553}
{"mode": "train", "epochs": 1, "timestep": 109, "ep_reward": 51.38701629638672, "reward": 0.4338243007659912, "action": 0.6860228776931763}
{"mode": "train", "epochs": 1, "timestep": 110, "ep_reward": 51.845890045166016, "reward": 0.4588753581047058, "action": 0.22701483964920044}
{"mode": "train", "epochs": 1, "timestep": 111, "ep_reward": 52.324851989746094, "reward": 0.47896242141723633, "action": 0.19473668932914734}
{"mode": "train", "epochs": 1, "timestep": 112, "ep_reward": 52.819339752197266, "reward": 0.49448782205581665, "action": -0.10815851390361786}
{"mode": "train", "epochs": 1, "timestep": 113, "ep_reward": 53.324710845947266, "reward": 0.5053716897964478, "action": -0.22574365139007568}
{"mode": "train", "epochs": 1, "timestep": 114, "ep_reward": 53.83665084838867, "reward": 0.5119399428367615, "action": 0.13580210506916046}
{"mode": "train", "epochs": 1, "timestep": 115, "ep_reward": 54.34980392456055, "reward": 0.513151228427887, "action": 0.31421107053756714}
{"mode": "train", "epochs": 1, "timestep": 116, "ep_reward": 54.85780334472656, "reward": 0.5079993009567261, "action": -0.011767365038394928}
{"mode": "train", "epochs": 1, "timestep": 117, "ep_reward": 55.355506896972656, "reward": 0.49770307540893555, "action": -0.2521611750125885}
{"mode": "train", "epochs": 1, "timestep": 118, "ep_reward": 55.839111328125, "reward": 0.48360466957092285, "action": 0.7586868405342102}
{"mode": "train", "epochs": 1, "timestep": 119, "ep_reward": 56.30076217651367, "reward": 0.461651086807251, "action": 0.17552393674850464}
{"mode": "train", "epochs": 1, "timestep": 120, "ep_reward": 56.73720932006836, "reward": 0.4364472031593323, "action": -0.6737381219863892}
{"mode": "train", "epochs": 1, "timestep": 121, "ep_reward": 57.150028228759766, "reward": 0.4128175973892212, "action": -0.17654478549957275}
{"mode": "train", "epochs": 1, "timestep": 122, "ep_reward": 57.53727722167969, "reward": 0.38724827766418457, "action": 0.4310738444328308}
{"mode": "train", "epochs": 1, "timestep": 123, "ep_reward": 57.92095947265625, "reward": 0.38368093967437744, "action": 0.2480686604976654}
{"mode": "train", "epochs": 1, "timestep": 124, "ep_reward": 58.331233978271484, "reward": 0.41027599573135376, "action": 0.3265478014945984}
{"mode": "train", "epochs": 1, "timestep": 125, "ep_reward": 58.7677001953125, "reward": 0.4364652633666992, "action": -0.1475679576396942}
{"mode": "train", "epochs": 1, "timestep": 126, "ep_reward": 59.228973388671875, "reward": 0.4612719416618347, "action": -0.6482722759246826}
{"mode": "train", "epochs": 1, "timestep": 127, "ep_reward": 59.7110710144043, "reward": 0.4820980429649353, "action": -0.029602043330669403}
{"mode": "train", "epochs": 1, "timestep": 128, "ep_reward": 60.20845413208008, "reward": 0.4973812699317932, "action": 1.2350749969482422}
{"mode": "train", "epochs": 1, "timestep": 129, "ep_reward": 60.718505859375, "reward": 0.5100528597831726, "action": 0.07587272673845291}
{"mode": "train", "epochs": 1, "timestep": 130, "ep_reward": 61.2380256652832, "reward": 0.5195208787918091, "action": -0.7528071403503418}
{"mode": "train", "epochs": 1, "timestep": 131, "ep_reward": 61.75983810424805, "reward": 0.521811306476593, "action": 0.3609275817871094}
{"mode": "train", "epochs": 1, "timestep": 132, "ep_reward": 62.27873229980469, "reward": 0.518893837928772, "action": 0.2160218358039856}
{"mode": "train", "epochs": 1, "timestep": 133, "ep_reward": 62.78987503051758, "reward": 0.511142373085022, "action": 0.21222332119941711}
{"mode": "train", "epochs": 1, "timestep": 134, "ep_reward": 63.28865432739258, "reward": 0.49877744913101196, "action": -0.6555211544036865}
{"mode": "train", "epochs": 1, "timestep": 135, "ep_reward": 63.7672119140625, "reward": 0.47855865955352783, "action": 0.18242061138153076}
{"mode": "train", "epochs": 1, "timestep": 136, "ep_reward": 64.2231216430664, "reward": 0.4559100270271301, "action": 0.46466490626335144}
{"mode": "train", "epochs": 1, "timestep": 137, "ep_reward": 64.6552963256836, "reward": 0.432171106338501, "action": -0.23298363387584686}
{"mode": "train", "epochs": 1, "timestep": 138, "ep_reward": 65.05931091308594, "reward": 0.4040178060531616, "action": 0.5221753120422363}
{"mode": "train", "epochs": 1, "timestep": 139, "ep_reward": 65.43757629394531, "reward": 0.3782673478126526, "action": 0.27644073963165283}
{"mode": "train", "epochs": 1, "timestep": 140, "ep_reward": 65.82910919189453, "reward": 0.3915293216705322, "action": 0.4018768072128296}
{"mode": "train", "epochs": 1, "timestep": 141, "ep_reward": 66.24555206298828, "reward": 0.41643935441970825, "action": -0.08158504962921143}
{"mode": "train", "epochs": 1, "timestep": 142, "ep_reward": 66.6845932006836, "reward": 0.4390428066253662, "action": 0.6082416772842407}
{"mode": "train", "epochs": 1, "timestep": 143, "ep_reward": 67.14369201660156, "reward": 0.4590991735458374, "action": -0.18153320252895355}
{"mode": "train", "epochs": 1, "timestep": 144, "ep_reward": 67.61875915527344, "reward": 0.4750633239746094, "action": -0.6777575612068176}
{"mode": "train", "epochs": 1, "timestep": 145, "ep_reward": 68.10747528076172, "reward": 0.48871278762817383, "action": -0.29128164052963257}
{"mode": "train", "epochs": 1, "timestep": 146, "ep_reward": 68.6071548461914, "reward": 0.4996771812438965, "action": 0.407553493976593}
{"mode": "train", "epochs": 1, "timestep": 147, "ep_reward": 69.11259460449219, "reward": 0.5054371356964111, "action": 1.0409361124038696}
{"mode": "train", "epochs": 1, "timestep": 148, "ep_reward": 69.61566925048828, "reward": 0.5030757188796997, "action": -0.11987770348787308}
{"mode": "train", "epochs": 1, "timestep": 149, "ep_reward": 70.11139678955078, "reward": 0.49573034048080444, "action": 1.0376770496368408}
{"mode": "train", "epochs": 1, "timestep": 150, "ep_reward": 70.59110260009766, "reward": 0.479702353477478, "action": -0.5623018145561218}
{"mode": "train", "epochs": 1, "timestep": 151, "ep_reward": 71.05403900146484, "reward": 0.4629354476928711, "action": 0.16915184259414673}
{"mode": "train", "epochs": 1, "timestep": 152, "ep_reward": 71.4952163696289, "reward": 0.4411754012107849, "action": -0.8419058918952942}
{"mode": "train", "epochs": 1, "timestep": 153, "ep_reward": 71.91661071777344, "reward": 0.4213917851448059, "action": 0.7167121171951294}
{"mode": "train", "epochs": 1, "timestep": 154, "ep_reward": 72.31131744384766, "reward": 0.39470893144607544, "action": -0.04966599494218826}
{"mode": "train", "epochs": 1, "timestep": 155, "ep_reward": 72.68782806396484, "reward": 0.3765110373497009, "action": -0.38679325580596924}
{"mode": "train", "epochs": 1, "timestep": 156, "ep_reward": 73.0890121459961, "reward": 0.40118467807769775, "action": -0.2611686587333679}
{"mode": "train", "epochs": 1, "timestep": 157, "ep_reward": 73.51300048828125, "reward": 0.42398661375045776, "action": 0.2841585576534271}
{"mode": "train", "epochs": 1, "timestep": 158, "ep_reward": 73.957763671875, "reward": 0.4447617530822754, "action": 0.7904634475708008}
{"mode": "train", "epochs": 1, "timestep": 159, "ep_reward": 74.42220306396484, "reward": 0.4644398093223572, "action": 0.4207950532436371}
{"mode": "train", "epochs": 1, "timestep": 160, "ep_reward": 74.90513610839844, "reward": 0.48293012380599976, "action": -0.5394769310951233}
{"mode": "train", "epochs": 1, "timestep": 161, "ep_reward": 75.4027099609375, "reward": 0.4975760579109192, "action": 0.4769289493560791}
{"mode": "train", "epochs": 1, "timestep": 162, "ep_reward": 75.91023254394531, "reward": 0.5075212717056274, "action": 0.6780763864517212}
{"mode": "train", "epochs": 1, "timestep": 163, "ep_reward": 76.42471313476562, "reward": 0.5144779682159424, "action": 0.42191094160079956}
{"mode": "train", "epochs": 1, "timestep": 164, "ep_reward": 76.9425048828125, "reward": 0.5177880525588989, "action": -0.16289690136909485}
{"mode": "train", "epochs": 1, "timestep": 165, "ep_reward": 77.45792388916016, "reward": 0.5154203176498413, "action": 0.10595010221004486}
{"mode": "train", "epochs": 1, "timestep": 166, "ep_reward": 77.9657974243164, "reward": 0.5078729391098022, "action": 0.6895721554756165}
{"mode": "train", "epochs": 1, "timestep": 167, "ep_reward": 78.46353912353516, "reward": 0.4977394938468933, "action": 0.23315861821174622}
{"mode": "train", "epochs": 1, "timestep": 168, "ep_reward": 78.94684600830078, "reward": 0.483303964138031, "action": 0.26300477981567383}
{"mode": "train", "epochs": 1, "timestep": 169, "ep_reward": 79.41242218017578, "reward": 0.46557873487472534, "action": -0.4115522503852844}
{"mode": "train", "epochs": 1, "timestep": 170, "ep_reward": 79.85443878173828, "reward": 0.442019522190094, "action": -0.34251275658607483}
{"mode": "train", "epochs": 1, "timestep": 171, "ep_reward": 80.26923370361328, "reward": 0.4147982597351074, "action": 0.35639235377311707}
{"mode": "train", "epochs": 1, "timestep": 172, "ep_reward": 80.65799713134766, "reward": 0.38876664638519287, "action": 0.582599401473999}
{"mode": "train", "epochs": 1, "timestep": 173, "ep_reward": 81.03913879394531, "reward": 0.38114142417907715, "action": 0.08384309709072113}
{"mode": "train", "epochs": 1, "timestep": 174, "ep_reward": 81.44479370117188, "reward": 0.40565651655197144, "action": 1.0420743227005005}
{"mode": "train", "epochs": 1, "timestep": 175, "ep_reward": 81.8731689453125, "reward": 0.428378164768219, "action": -0.3757534325122833}
{"mode": "train", "epochs": 1, "timestep": 176, "ep_reward": 82.32049560546875, "reward": 0.4473283290863037, "action": -0.3457413911819458}
{"mode": "train", "epochs": 1, "timestep": 177, "ep_reward": 82.78536224365234, "reward": 0.46487027406692505, "action": -0.1040804535150528}
{"mode": "train", "epochs": 1, "timestep": 178, "ep_reward": 83.2652816772461, "reward": 0.4799211621284485, "action": 0.7580229043960571}
{"mode": "train", "epochs": 1, "timestep": 179, "ep_reward": 83.75531768798828, "reward": 0.4900345802307129, "action": -0.07807496935129166}
{"mode": "train", "epochs": 1, "timestep": 180, "ep_reward": 84.25032043457031, "reward": 0.49500638246536255, "action": 0.516572117805481}
{"mode": "train", "epochs": 1, "timestep": 181, "ep_reward": 84.74446868896484, "reward": 0.4941501021385193, "action": 0.3909258544445038}
{"mode": "train", "epochs": 1, "timestep": 182, "ep_reward": 85.23175048828125, "reward": 0.48728400468826294, "action": 0.6422722935676575}
{"mode": "train", "epochs": 1, "timestep": 183, "ep_reward": 85.70553588867188, "reward": 0.47378289699554443, "action": 0.1260736882686615}
{"mode": "train", "epochs": 1, "timestep": 184, "ep_reward": 86.16193389892578, "reward": 0.456400990486145, "action": 0.18399812281131744}
{"mode": "train", "epochs": 1, "timestep": 185, "ep_reward": 86.5971450805664, "reward": 0.43520915508270264, "action": 0.3707889914512634}
{"mode": "train", "epochs": 1, "timestep": 186, "ep_reward": 87.00735473632812, "reward": 0.4102100133895874, "action": 0.04429824650287628}
{"mode": "train", "epochs": 1, "timestep": 187, "ep_reward": 87.39176940917969, "reward": 0.38441407680511475, "action": -0.7922810316085815}
{"mode": "train", "epochs": 1, "timestep": 188, "ep_reward": 87.77774047851562, "reward": 0.38596808910369873, "action": -0.9061580896377563}
{"mode": "train", "epochs": 1, "timestep": 189, "ep_reward": 88.18555450439453, "reward": 0.40781259536743164, "action": -1.1811989545822144}
{"mode": "train", "epochs": 1, "timestep": 190, "ep_reward": 88.61100006103516, "reward": 0.4254433512687683, "action": -0.7793540358543396}
{"mode": "train", "epochs": 1, "timestep": 191, "ep_reward": 89.04905700683594, "reward": 0.43805330991744995, "action": 0.7621681094169617}
{"mode": "train", "epochs": 1, "timestep": 192, "ep_reward": 89.4979019165039, "reward": 0.4488416314125061, "action": -0.6994308233261108}
{"mode": "train", "epochs": 1, "timestep": 193, "ep_reward": 89.9544677734375, "reward": 0.4565665125846863, "action": 0.42539310455322266}
{"mode": "train", "epochs": 1, "timestep": 194, "ep_reward": 90.41615295410156, "reward": 0.46168529987335205, "action": 0.3065018057823181}
{"mode": "train", "epochs": 1, "timestep": 195, "ep_reward": 90.88091278076172, "reward": 0.4647563695907593, "action": 0.4310433268547058}
{"mode": "train", "epochs": 1, "timestep": 196, "ep_reward": 91.34684753417969, "reward": 0.4659312963485718, "action": -0.12202505022287369}
{"mode": "train", "epochs": 1, "timestep": 197, "ep_reward": 91.81043243408203, "reward": 0.4635844826698303, "action": -0.2532491087913513}
{"mode": "train", "epochs": 1, "timestep": 198, "ep_reward": 92.2676010131836, "reward": 0.4571684002876282, "action": 0.16164599359035492}
{"mode": "train", "epochs": 1, "timestep": 199, "ep_reward": 92.71601104736328, "reward": 0.44841259717941284, "action": 0.39400359988212585}
{"mode": "train", "epochs": 1, "timestep": 200, "ep_reward": 93.15443420410156, "reward": 0.4384268522262573, "action": -0.5677603483200073}
{"mode": "train", "epochs": 1, "timestep": 201, "ep_reward": 93.57804107666016, "reward": 0.4236077666282654, "action": -0.06372493505477905}
{"mode": "train", "epochs": 1, "timestep": 202, "ep_reward": 93.9854507446289, "reward": 0.4074069857597351, "action": 0.3563830852508545}
{"mode": "train", "epochs": 1, "timestep": 203, "ep_reward": 94.37732696533203, "reward": 0.39187556505203247, "action": -0.04824964702129364}
{"mode": "train", "epochs": 1, "timestep": 204, "ep_reward": 94.75968170166016, "reward": 0.38235265016555786, "action": 0.22361746430397034}
{"mode": "train", "epochs": 1, "timestep": 205, "ep_reward": 95.15787506103516, "reward": 0.39819663763046265, "action": -0.893968939781189}
{"mode": "train", "epochs": 1, "timestep": 206, "ep_reward": 95.57223510742188, "reward": 0.4143572449684143, "action": -0.0027140825986862183}
{"mode": "train", "epochs": 1, "timestep": 207, "ep_reward": 96.00289154052734, "reward": 0.4306577444076538, "action": -0.6690238118171692}
{"mode": "train", "epochs": 1, "timestep": 208, "ep_reward": 96.44894409179688, "reward": 0.4460487365722656, "action": 0.22382068634033203}
{"mode": "train", "epochs": 1, "timestep": 209, "ep_reward": 96.90864562988281, "reward": 0.459700345993042, "action": -0.42163407802581787}
{"mode": "train", "epochs": 1, "timestep": 210, "ep_reward": 97.37938690185547, "reward": 0.4707421660423279, "action": 0.10979300737380981}
{"mode": "train", "epochs": 1, "timestep": 211, "ep_reward": 97.85800170898438, "reward": 0.47861742973327637, "action": 0.4622015953063965}
{"mode": "train", "epochs": 1, "timestep": 212, "ep_reward": 98.33946990966797, "reward": 0.48146939277648926, "action": 0.42870673537254333}
{"mode": "train", "epochs": 1, "timestep": 213, "ep_reward": 98.81829071044922, "reward": 0.47881942987442017, "action": 0.5821781158447266}
{"mode": "train", "epochs": 1, "timestep": 214, "ep_reward": 99.28852844238281, "reward": 0.4702357053756714, "action": 0.6744696497917175}
{"mode": "train", "epochs": 1, "timestep": 215, "ep_reward": 99.74415588378906, "reward": 0.45563048124313354, "action": -0.6205884218215942}
{"mode": "train", "epochs": 1, "timestep": 216, "ep_reward": 100.18543243408203, "reward": 0.44127774238586426, "action": 0.43160805106163025}
{"mode": "train", "epochs": 1, "timestep": 217, "ep_reward": 100.60723114013672, "reward": 0.4217994213104248, "action": 0.14642733335494995}
{"mode": "train", "epochs": 1, "timestep": 218, "ep_reward": 101.00782012939453, "reward": 0.4005891680717468, "action": 0.020314902067184448}
{"mode": "train", "epochs": 1, "timestep": 219, "ep_reward": 101.38654327392578, "reward": 0.3787260055541992, "action": -0.24271024763584137}
{"mode": "train", "epochs": 1, "timestep": 220, "ep_reward": 101.78030395507812, "reward": 0.39376258850097656, "action": 0.6170442700386047}
{"mode": "train", "epochs": 1, "timestep": 221, "ep_reward": 102.19476318359375, "reward": 0.4144575595855713, "action": 0.14275744557380676}
{"mode": "train", "epochs": 1, "timestep": 222, "ep_reward": 102.6300277709961, "reward": 0.4352651834487915, "action": 0.023509837687015533}
{"mode": "train", "epochs": 1, "timestep": 223, "ep_reward": 103.08435821533203, "reward": 0.45432722568511963, "action": 0.26020747423171997}
{"mode": "train", "epochs": 1, "timestep": 224, "ep_reward": 103.55529022216797, "reward": 0.470928430557251, "action": 0.310974657535553}
{"mode": "train", "epochs": 1, "timestep": 225, "ep_reward": 104.04024505615234, "reward": 0.4849531650543213, "action": 0.3420085310935974}
{"mode": "train", "epochs": 1, "timestep": 226, "ep_reward": 104.53623962402344, "reward": 0.49599164724349976, "action": 0.25343838334083557}
{"mode": "train", "epochs": 1, "timestep": 227, "ep_reward": 105.03971099853516, "reward": 0.5034682750701904, "action": -0.24191835522651672}
{"mode": "train", "epochs": 1, "timestep": 228, "ep_reward": 105.54547119140625, "reward": 0.505760908126831, "action": 0.24236850440502167}
{"mode": "train", "epochs": 1, "timestep": 229, "ep_reward": 106.0490493774414, "reward": 0.5035766363143921, "action": 0.7119134664535522}
{"mode": "train", "epochs": 1, "timestep": 230, "ep_reward": 106.5478744506836, "reward": 0.49882566928863525, "action": -0.7103662490844727}
{"mode": "train", "epochs": 1, "timestep": 231, "ep_reward": 107.03450775146484, "reward": 0.48663681745529175, "action": -0.155543252825737}
{"mode": "train", "epochs": 1, "timestep": 232, "ep_reward": 107.50434875488281, "reward": 0.4698418378829956, "action": -0.059094592928886414}
{"mode": "train", "epochs": 1, "timestep": 233, "ep_reward": 107.95359802246094, "reward": 0.4492495656013489, "action": 0.6638619303703308}
{"mode": "train", "epochs": 1, "timestep": 234, "ep_reward": 108.3827896118164, "reward": 0.42918890714645386, "action": 0.4252573549747467}
{"mode": "train", "epochs": 1, "timestep": 235, "ep_reward": 108.7907943725586, "reward": 0.408006489276886, "action": 0.8155434131622314}
{"mode": "train", "epochs": 1, "timestep": 236, "ep_reward": 109.17979431152344, "reward": 0.38900262117385864, "action": 0.25209200382232666}
{"mode": "train", "epochs": 1, "timestep": 237, "ep_reward": 109.56387329101562, "reward": 0.3840793967247009, "action": 0.1301906555891037}
{"mode": "train", "epochs": 1, "timestep": 238, "ep_reward": 109.96737670898438, "reward": 0.40350162982940674, "action": 0.27003058791160583}
{"mode": "train", "epochs": 1, "timestep": 239, "ep_reward": 110.388916015625, "reward": 0.4215376377105713, "action": -0.45821690559387207}
{"mode": "train", "epochs": 1, "timestep": 240, "ep_reward": 110.82706451416016, "reward": 0.43814682960510254, "action": 0.4825981855392456}
{"mode": "train", "epochs": 1, "timestep": 241, "ep_reward": 111.27978515625, "reward": 0.4527205228805542, "action": -0.28801029920578003}
{"mode": "train", "epochs": 1, "timestep": 242, "ep_reward": 111.74406433105469, "reward": 0.46427953243255615, "action": 0.24146375060081482}
{"mode": "train", "epochs": 1, "timestep": 243, "ep_reward": 112.21659851074219, "reward": 0.4725324511528015, "action": -0.475748747587204}
{"mode": "train", "epochs": 1, "timestep": 244, "ep_reward": 112.69467163085938, "reward": 0.4780740737915039, "action": -0.02914394438266754}
{"mode": "train", "epochs": 1, "timestep": 245, "ep_reward": 113.17491149902344, "reward": 0.48024171590805054, "action": 0.6151825189590454}
{"mode": "train", "epochs": 1, "timestep": 246, "ep_reward": 113.65165710449219, "reward": 0.4767448902130127, "action": 0.1211199015378952}
{"mode": "train", "epochs": 1, "timestep": 247, "ep_reward": 114.12061309814453, "reward": 0.46895742416381836, "action": 0.134123295545578}
{"mode": "train", "epochs": 1, "timestep": 248, "ep_reward": 114.57781219482422, "reward": 0.45720094442367554, "action": -0.12893307209014893}
{"mode": "train", "epochs": 1, "timestep": 249, "ep_reward": 115.02079772949219, "reward": 0.4429819583892822, "action": 0.9069302082061768}
{"mode": "train", "epochs": 1, "timestep": 250, "ep_reward": 115.44293212890625, "reward": 0.4221341013908386, "action": 0.47599926590919495}
{"mode": "train", "epochs": 1, "timestep": 251, "ep_reward": 115.84148406982422, "reward": 0.39855533838272095, "action": 0.3420237600803375}
{"mode": "train", "epochs": 1, "timestep": 252, "ep_reward": 116.21564483642578, "reward": 0.37415820360183716, "action": -1.1329556703567505}
{"mode": "train", "epochs": 1, "timestep": 253, "ep_reward": 116.61280059814453, "reward": 0.3971524238586426, "action": 0.24210461974143982}
{"mode": "train", "epochs": 1, "timestep": 254, "ep_reward": 117.03006744384766, "reward": 0.41726505756378174, "action": -0.389680415391922}
{"mode": "train", "epochs": 1, "timestep": 255, "ep_reward": 117.46617889404297, "reward": 0.43610960245132446, "action": 0.1728040874004364}
{"mode": "train", "epochs": 1, "timestep": 256, "ep_reward": 117.91851043701172, "reward": 0.4523323178291321, "action": -0.2828410863876343}
{"mode": "train", "epochs": 1, "timestep": 257, "ep_reward": 118.3841781616211, "reward": 0.46567046642303467, "action": -0.835004448890686}
{"mode": "train", "epochs": 1, "timestep": 258, "ep_reward": 118.85794830322266, "reward": 0.4737725257873535, "action": 0.0913957878947258}
{"mode": "train", "epochs": 1, "timestep": 259, "ep_reward": 119.33549499511719, "reward": 0.47754859924316406, "action": -0.06609925627708435}
{"mode": "train", "epochs": 1, "timestep": 260, "ep_reward": 119.81291961669922, "reward": 0.47742146253585815, "action": 0.38524553179740906}
{"mode": "train", "epochs": 1, "timestep": 261, "ep_reward": 120.28759002685547, "reward": 0.47467148303985596, "action": 0.11157914996147156}
{"mode": "train", "epochs": 1, "timestep": 262, "ep_reward": 120.75618743896484, "reward": 0.46859365701675415, "action": -0.26167231798171997}
{"mode": "train", "epochs": 1, "timestep": 263, "ep_reward": 121.21424102783203, "reward": 0.458051860332489, "action": 0.4055650234222412}
{"mode": "train", "epochs": 1, "timestep": 264, "ep_reward": 121.66047668457031, "reward": 0.4462352395057678, "action": 0.06035971641540527}
{"mode": "train", "epochs": 1, "timestep": 265, "ep_reward": 122.09217834472656, "reward": 0.43170464038848877, "action": -0.05694881081581116}
{"mode": "train", "epochs": 1, "timestep": 266, "ep_reward": 122.50700378417969, "reward": 0.4148240089416504, "action": -0.621565043926239}
{"mode": "train", "epochs": 1, "timestep": 267, "ep_reward": 122.90081024169922, "reward": 0.39380866289138794, "action": -0.44794198870658875}
{"mode": "train", "epochs": 1, "timestep": 268, "ep_reward": 123.28096008300781, "reward": 0.38015300035476685, "action": 0.0392918661236763}
{"mode": "train", "epochs": 1, "timestep": 269, "ep_reward": 123.68230438232422, "reward": 0.40134578943252563, "action": 0.13851116597652435}
{"mode": "train", "epochs": 1, "timestep": 270, "ep_reward": 124.10383605957031, "reward": 0.4215353727340698, "action": 0.7476650476455688}
{"mode": "train", "epochs": 1, "timestep": 271, "ep_reward": 124.54295349121094, "reward": 0.4391191005706787, "action": -0.14762616157531738}
{"mode": "train", "epochs": 1, "timestep": 272, "ep_reward": 124.99629211425781, "reward": 0.4533398151397705, "action": -0.3944920003414154}
{"mode": "train", "epochs": 1, "timestep": 273, "ep_reward": 125.46196746826172, "reward": 0.4656764268875122, "action": -0.2605457901954651}
{"mode": "train", "epochs": 1, "timestep": 274, "ep_reward": 125.93773651123047, "reward": 0.4757688641548157, "action": 0.24374094605445862}
{"mode": "train", "epochs": 1, "timestep": 275, "ep_reward": 126.4197006225586, "reward": 0.4819605350494385, "action": 0.6100631356239319}
{"mode": "train", "epochs": 1, "timestep": 276, "ep_reward": 126.9021224975586, "reward": 0.48242372274398804, "action": 0.026479560881853104}
{"mode": "train", "epochs": 1, "timestep": 277, "ep_reward": 127.38062286376953, "reward": 0.4785034656524658, "action": 0.21841691434383392}
{"mode": "train", "epochs": 1, "timestep": 278, "ep_reward": 127.8505630493164, "reward": 0.4699411392211914, "action": -0.4995690584182739}
{"mode": "train", "epochs": 1, "timestep": 279, "ep_reward": 128.31039428710938, "reward": 0.4598318934440613, "action": -0.44406580924987793}
{"mode": "train", "epochs": 1, "timestep": 280, "ep_reward": 128.75839233398438, "reward": 0.44799280166625977, "action": 0.22591403126716614}
{"mode": "train", "epochs": 1, "timestep": 281, "ep_reward": 129.1905059814453, "reward": 0.43211251497268677, "action": -0.39389920234680176}
{"mode": "train", "epochs": 1, "timestep": 282, "ep_reward": 129.60671997070312, "reward": 0.41621947288513184, "action": -0.3690226674079895}
{"mode": "train", "epochs": 1, "timestep": 283, "ep_reward": 130.00677490234375, "reward": 0.4000593423843384, "action": 0.13155293464660645}
{"mode": "train", "epochs": 1, "timestep": 284, "ep_reward": 130.38877868652344, "reward": 0.3820050358772278, "action": -0.04783383756875992}
{"mode": "train", "epochs": 1, "timestep": 285, "ep_reward": 130.78054809570312, "reward": 0.39177125692367554, "action": 0.17940324544906616}
{"mode": "train", "epochs": 1, "timestep": 286, "ep_reward": 131.18955993652344, "reward": 0.40901076793670654, "action": 0.7091310620307922}
{"mode": "train", "epochs": 1, "timestep": 287, "ep_reward": 131.615966796875, "reward": 0.42640602588653564, "action": -0.2826707065105438}
{"mode": "train", "epochs": 1, "timestep": 288, "ep_reward": 132.0589599609375, "reward": 0.44298893213272095, "action": 0.04667508974671364}
{"mode": "train", "epochs": 1, "timestep": 289, "ep_reward": 132.51576232910156, "reward": 0.4568004608154297, "action": 0.0991085022687912}
{"mode": "train", "epochs": 1, "timestep": 290, "ep_reward": 132.9837188720703, "reward": 0.46795302629470825, "action": -0.17980925738811493}
{"mode": "train", "epochs": 1, "timestep": 291, "ep_reward": 133.45919799804688, "reward": 0.4754813313484192, "action": 0.7900564074516296}
{"mode": "train", "epochs": 1, "timestep": 292, "ep_reward": 133.94021606445312, "reward": 0.48101580142974854, "action": -0.31789159774780273}
{"mode": "train", "epochs": 1, "timestep": 293, "ep_reward": 134.422607421875, "reward": 0.4823841452598572, "action": 0.676828145980835}
{"mode": "train", "epochs": 1, "timestep": 294, "ep_reward": 134.90419006347656, "reward": 0.4815880060195923, "action": 0.44161146879196167}
{"mode": "train", "epochs": 1, "timestep": 295, "ep_reward": 135.3824920654297, "reward": 0.4783064126968384, "action": 0.08451861143112183}
{"mode": "train", "epochs": 1, "timestep": 296, "ep_reward": 135.8539276123047, "reward": 0.4714335799217224, "action": 0.07830236852169037}
{"mode": "train", "epochs": 1, "timestep": 297, "ep_reward": 136.3151397705078, "reward": 0.4612112045288086, "action": 0.5193555355072021}
{"mode": "train", "epochs": 1, "timestep": 298, "ep_reward": 136.7649688720703, "reward": 0.449826717376709, "action": -0.06561779975891113}
{"mode": "train", "epochs": 1, "timestep": 299, "ep_reward": 137.19989013671875, "reward": 0.4349212646484375, "action": -0.7584617137908936}
{"mode": "train", "epochs": 1, "timestep": 300, "ep_reward": 137.6144561767578, "reward": 0.41457194089889526, "action": -0.1922379732131958}
{"mode": "train", "epochs": 1, "timestep": 301, "ep_reward": 138.00747680664062, "reward": 0.39301908016204834, "action": -0.3513392210006714}
{"mode": "train", "epochs": 1, "timestep": 302, "ep_reward": 138.38790893554688, "reward": 0.3804377317428589, "action": -0.15862390398979187}
{"mode": "train", "epochs": 1, "timestep": 303, "ep_reward": 138.79049682617188, "reward": 0.4025918245315552, "action": 0.5793789625167847}
{"mode": "train", "epochs": 1, "timestep": 304, "ep_reward": 139.2143096923828, "reward": 0.42381811141967773, "action": 0.010153258219361305}
{"mode": "train", "epochs": 1, "timestep": 305, "ep_reward": 139.656494140625, "reward": 0.4421843886375427, "action": 0.39882710576057434}
{"mode": "train", "epochs": 1, "timestep": 306, "ep_reward": 140.1141815185547, "reward": 0.45769035816192627, "action": 0.43132641911506653}
{"mode": "train", "epochs": 1, "timestep": 307, "ep_reward": 140.5829315185547, "reward": 0.46875107288360596, "action": -1.4067083597183228}
{"mode": "train", "epochs": 1, "timestep": 308, "ep_reward": 141.06163024902344, "reward": 0.4787025451660156, "action": 0.04182019829750061}
{"mode": "train", "epochs": 1, "timestep": 309, "ep_reward": 141.54791259765625, "reward": 0.4862855076789856, "action": -0.2287919819355011}
{"mode": "train", "epochs": 1, "timestep": 310, "ep_reward": 142.03814697265625, "reward": 0.4902399778366089, "action": 0.12540121376514435}
{"mode": "train", "epochs": 1, "timestep": 311, "ep_reward": 142.52783203125, "reward": 0.48969149589538574, "action": -0.3269805908203125}
{"mode": "train", "epochs": 1, "timestep": 312, "ep_reward": 143.01364135742188, "reward": 0.48580628633499146, "action": -0.2578972280025482}
{"mode": "train", "epochs": 1, "timestep": 313, "ep_reward": 143.49224853515625, "reward": 0.47860366106033325, "action": -0.3687005341053009}
{"mode": "train", "epochs": 1, "timestep": 314, "ep_reward": 143.96099853515625, "reward": 0.46874547004699707, "action": 0.808404803276062}
{"mode": "train", "epochs": 1, "timestep": 315, "ep_reward": 144.41285705566406, "reward": 0.45185422897338867, "action": -0.18999703228473663}
{"mode": "train", "epochs": 1, "timestep": 316, "ep_reward": 144.8466033935547, "reward": 0.4337422847747803, "action": -0.5670114159584045}
{"mode": "train", "epochs": 1, "timestep": 317, "ep_reward": 145.2624969482422, "reward": 0.4158939719200134, "action": 0.33689916133880615}
{"mode": "train", "epochs": 1, "timestep": 318, "ep_reward": 145.65658569335938, "reward": 0.394081711769104, "action": -0.2534376084804535}
{"mode": "train", "epochs": 1, "timestep": 319, "ep_reward": 146.03543090820312, "reward": 0.3788456916809082, "action": -0.1615680456161499}
{"mode": "train", "epochs": 1, "timestep": 320, "ep_reward": 146.43447875976562, "reward": 0.3990435004234314, "action": -1.1181714534759521}
{"mode": "train", "epochs": 1, "timestep": 321, "ep_reward": 146.8515625, "reward": 0.41707921028137207, "action": 0.6239911913871765}
{"mode": "train", "epochs": 1, "timestep": 322, "ep_reward": 147.2841796875, "reward": 0.43262314796447754, "action": -0.12108469009399414}
{"mode": "train", "epochs": 1, "timestep": 323, "ep_reward": 147.73121643066406, "reward": 0.44703352451324463, "action": -0.327138751745224}
{"mode": "train", "epochs": 1, "timestep": 324, "ep_reward": 148.18942260742188, "reward": 0.45820218324661255, "action": -0.22258275747299194}
{"mode": "train", "epochs": 1, "timestep": 325, "ep_reward": 148.6549530029297, "reward": 0.4655378460884094, "action": -0.1836143434047699}
{"mode": "train", "epochs": 1, "timestep": 326, "ep_reward": 149.12384033203125, "reward": 0.4688943028450012, "action": -1.0180991888046265}
{"mode": "train", "epochs": 1, "timestep": 327, "ep_reward": 149.5897216796875, "reward": 0.4658889174461365, "action": -0.2078142762184143}
{"mode": "train", "epochs": 1, "timestep": 328, "ep_reward": 150.04833984375, "reward": 0.4586229920387268, "action": -0.5443809628486633}
{"mode": "train", "epochs": 1, "timestep": 329, "ep_reward": 150.49464416503906, "reward": 0.44630420207977295, "action": -0.6406438946723938}
{"mode": "train", "epochs": 1, "timestep": 330, "ep_reward": 150.92373657226562, "reward": 0.429098904132843, "action": 0.45249468088150024}
{"mode": "train", "epochs": 1, "timestep": 331, "ep_reward": 151.3365020751953, "reward": 0.41276341676712036, "action": -0.5542358160018921}
{"mode": "train", "epochs": 1, "timestep": 332, "ep_reward": 151.7284393310547, "reward": 0.39193201065063477, "action": -0.2040177583694458}
{"mode": "train", "epochs": 1, "timestep": 333, "ep_reward": 152.1102752685547, "reward": 0.3818292021751404, "action": 0.09637510776519775}
{"mode": "train", "epochs": 1, "timestep": 334, "ep_reward": 152.5123748779297, "reward": 0.4020935297012329, "action": -0.23141449689865112}
{"mode": "train", "epochs": 1, "timestep": 335, "ep_reward": 152.93392944335938, "reward": 0.4215477705001831, "action": -1.0435879230499268}
{"mode": "train", "epochs": 1, "timestep": 336, "ep_reward": 153.37481689453125, "reward": 0.4408923387527466, "action": -1.3534915447235107}
{"mode": "train", "epochs": 1, "timestep": 337, "ep_reward": 153.8359375, "reward": 0.4611205458641052, "action": -1.4853676557540894}
{"mode": "train", "epochs": 1, "timestep": 338, "ep_reward": 154.31825256347656, "reward": 0.48230910301208496, "action": -0.11836481094360352}
{"mode": "train", "epochs": 1, "timestep": 339, "ep_reward": 154.82107543945312, "reward": 0.502829909324646, "action": -1.590909719467163}
{"mode": "train", "epochs": 1, "timestep": 340, "ep_reward": 155.34153747558594, "reward": 0.520466148853302, "action": -1.2300277948379517}
{"mode": "train", "epochs": 1, "timestep": 341, "ep_reward": 155.87867736816406, "reward": 0.537146806716919, "action": -0.6338317394256592}
{"mode": "train", "epochs": 1, "timestep": 342, "ep_reward": 156.4293975830078, "reward": 0.5507183074951172, "action": -1.348989486694336}
{"mode": "train", "epochs": 1, "timestep": 343, "ep_reward": 156.99029541015625, "reward": 0.5608971118927002, "action": -0.86240553855896}
{"mode": "train", "epochs": 1, "timestep": 344, "ep_reward": 157.55767822265625, "reward": 0.5673816204071045, "action": -0.5653507113456726}
{"mode": "train", "epochs": 1, "timestep": 345, "ep_reward": 158.126220703125, "reward": 0.5685348510742188, "action": -0.8962544202804565}
{"mode": "train", "epochs": 1, "timestep": 346, "ep_reward": 158.69125366210938, "reward": 0.5650321245193481, "action": -0.466576486825943}
{"mode": "train", "epochs": 1, "timestep": 347, "ep_reward": 159.24685668945312, "reward": 0.5556005835533142, "action": -0.5491233468055725}
{"mode": "train", "epochs": 1, "timestep": 348, "ep_reward": 159.78770446777344, "reward": 0.5408485531806946, "action": -0.7652422785758972}
{"mode": "train", "epochs": 1, "timestep": 349, "ep_reward": 160.30999755859375, "reward": 0.5222889184951782, "action": -0.0011596083641052246}
{"mode": "train", "epochs": 1, "timestep": 350, "ep_reward": 160.80648803710938, "reward": 0.4964938759803772, "action": -1.311835527420044}
{"mode": "train", "epochs": 1, "timestep": 351, "ep_reward": 161.2792510986328, "reward": 0.47276437282562256, "action": -0.808394730091095}
{"mode": "train", "epochs": 1, "timestep": 352, "ep_reward": 161.72557067871094, "reward": 0.4463213086128235, "action": -1.9609476327896118}
{"mode": "train", "epochs": 1, "timestep": 353, "ep_reward": 162.15164184570312, "reward": 0.42606592178344727, "action": -1.1356316804885864}
{"mode": "train", "epochs": 1, "timestep": 354, "ep_reward": 162.55679321289062, "reward": 0.405146062374115, "action": -0.9655476808547974}
{"mode": "train", "epochs": 1, "timestep": 355, "ep_reward": 162.94244384765625, "reward": 0.3856571316719055, "action": -0.8297444581985474}
{"mode": "train", "epochs": 1, "timestep": 356, "ep_reward": 163.32891845703125, "reward": 0.38648027181625366, "action": -0.03579831123352051}
{"mode": "train", "epochs": 1, "timestep": 357, "ep_reward": 163.73388671875, "reward": 0.4049662947654724, "action": -0.7208951711654663}
{"mode": "train", "epochs": 1, "timestep": 358, "ep_reward": 164.155517578125, "reward": 0.4216366410255432, "action": -0.5344526767730713}
{"mode": "train", "epochs": 1, "timestep": 359, "ep_reward": 164.59027099609375, "reward": 0.43474847078323364, "action": -0.5155991315841675}
{"mode": "train", "epochs": 1, "timestep": 360, "ep_reward": 165.03436279296875, "reward": 0.4440956711769104, "action": -0.9017358422279358}
{"mode": "train", "epochs": 1, "timestep": 361, "ep_reward": 165.48260498046875, "reward": 0.4482496380805969, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 362, "ep_reward": 165.9262237548828, "reward": 0.4436177611351013, "action": -1.2926770448684692}
{"mode": "train", "epochs": 1, "timestep": 363, "ep_reward": 166.3577880859375, "reward": 0.431562602519989, "action": -1.2108728885650635}
{"mode": "train", "epochs": 1, "timestep": 364, "ep_reward": 166.77088928222656, "reward": 0.41309505701065063, "action": -1.7815423011779785}
{"mode": "train", "epochs": 1, "timestep": 365, "ep_reward": 167.1573028564453, "reward": 0.386407732963562, "action": -1.0505986213684082}
{"mode": "train", "epochs": 1, "timestep": 366, "ep_reward": 167.54345703125, "reward": 0.3861514925956726, "action": -0.8119446635246277}
{"mode": "train", "epochs": 1, "timestep": 367, "ep_reward": 167.9556427001953, "reward": 0.41218745708465576, "action": -1.471571683883667}
{"mode": "train", "epochs": 1, "timestep": 368, "ep_reward": 168.39500427246094, "reward": 0.43935930728912354, "action": -0.4753001928329468}
{"mode": "train", "epochs": 1, "timestep": 369, "ep_reward": 168.86312866210938, "reward": 0.4681186079978943, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 370, "ep_reward": 169.35812377929688, "reward": 0.4950026869773865, "action": -1.0620932579040527}
{"mode": "train", "epochs": 1, "timestep": 371, "ep_reward": 169.88136291503906, "reward": 0.5232424736022949, "action": -0.24841296672821045}
{"mode": "train", "epochs": 1, "timestep": 372, "ep_reward": 170.43032836914062, "reward": 0.5489615201950073, "action": -1.1714015007019043}
{"mode": "train", "epochs": 1, "timestep": 373, "ep_reward": 170.99951171875, "reward": 0.5691878795623779, "action": -1.7363595962524414}
{"mode": "train", "epochs": 1, "timestep": 374, "ep_reward": 171.5858612060547, "reward": 0.5863471627235413, "action": -0.90756756067276}
{"mode": "train", "epochs": 1, "timestep": 375, "ep_reward": 172.18576049804688, "reward": 0.5999011993408203, "action": -1.3438160419464111}
{"mode": "train", "epochs": 1, "timestep": 376, "ep_reward": 172.7943115234375, "reward": 0.6085525751113892, "action": -1.031670093536377}
{"mode": "train", "epochs": 1, "timestep": 377, "ep_reward": 173.4061737060547, "reward": 0.6118560433387756, "action": -1.6618273258209229}
{"mode": "train", "epochs": 1, "timestep": 378, "ep_reward": 174.01744079589844, "reward": 0.6112694144248962, "action": 0.060166001319885254}
{"mode": "train", "epochs": 1, "timestep": 379, "ep_reward": 174.61891174316406, "reward": 0.6014654636383057, "action": -0.7399019002914429}
{"mode": "train", "epochs": 1, "timestep": 380, "ep_reward": 175.2042236328125, "reward": 0.5853093862533569, "action": -0.5262168645858765}
{"mode": "train", "epochs": 1, "timestep": 381, "ep_reward": 175.7661590576172, "reward": 0.5619378089904785, "action": -1.5994014739990234}
{"mode": "train", "epochs": 1, "timestep": 382, "ep_reward": 176.30447387695312, "reward": 0.5383153557777405, "action": -0.27027440071105957}
{"mode": "train", "epochs": 1, "timestep": 383, "ep_reward": 176.81019592285156, "reward": 0.5057225227355957, "action": -1.3147495985031128}
{"mode": "train", "epochs": 1, "timestep": 384, "ep_reward": 177.2849884033203, "reward": 0.4747908115386963, "action": -0.699812114238739}
{"mode": "train", "epochs": 1, "timestep": 385, "ep_reward": 177.7250213623047, "reward": 0.4400373697280884, "action": -0.9976301193237305}
{"mode": "train", "epochs": 1, "timestep": 386, "ep_reward": 178.13174438476562, "reward": 0.4067251682281494, "action": -0.3142696022987366}
{"mode": "train", "epochs": 1, "timestep": 387, "ep_reward": 178.50254821777344, "reward": 0.3708067536354065, "action": -0.35701805353164673}
{"mode": "train", "epochs": 1, "timestep": 388, "ep_reward": 178.8920135498047, "reward": 0.3894706964492798, "action": -0.09543460607528687}
{"mode": "train", "epochs": 1, "timestep": 389, "ep_reward": 179.31544494628906, "reward": 0.4234369397163391, "action": -1.2619041204452515}
{"mode": "train", "epochs": 1, "timestep": 390, "ep_reward": 179.77113342285156, "reward": 0.4556819796562195, "action": -0.3218051791191101}
{"mode": "train", "epochs": 1, "timestep": 391, "ep_reward": 180.25204467773438, "reward": 0.480915367603302, "action": -0.4698432683944702}
{"mode": "train", "epochs": 1, "timestep": 392, "ep_reward": 180.75299072265625, "reward": 0.5009433031082153, "action": -0.9012343883514404}
{"mode": "train", "epochs": 1, "timestep": 393, "ep_reward": 181.26687622070312, "reward": 0.5138851404190063, "action": -1.0679265260696411}
{"mode": "train", "epochs": 1, "timestep": 394, "ep_reward": 181.7846221923828, "reward": 0.5177503228187561, "action": -0.8219001889228821}
{"mode": "train", "epochs": 1, "timestep": 395, "ep_reward": 182.29725646972656, "reward": 0.512628436088562, "action": -1.188612461090088}
{"mode": "train", "epochs": 1, "timestep": 396, "ep_reward": 182.7948455810547, "reward": 0.49759113788604736, "action": -0.9925304651260376}
{"mode": "train", "epochs": 1, "timestep": 397, "ep_reward": 183.26881408691406, "reward": 0.4739697575569153, "action": 0.12010419368743896}
{"mode": "train", "epochs": 1, "timestep": 398, "ep_reward": 183.71719360351562, "reward": 0.44837456941604614, "action": -0.5624355673789978}
{"mode": "train", "epochs": 1, "timestep": 399, "ep_reward": 184.13365173339844, "reward": 0.4164566993713379, "action": -1.149040937423706}
{"mode": "train", "epochs": 1, "timestep": 400, "ep_reward": 184.51112365722656, "reward": 0.3774675726890564, "action": -0.44988930225372314}
{"mode": "train", "epochs": 1, "timestep": 401, "ep_reward": 184.89517211914062, "reward": 0.38404327630996704, "action": -1.0000919103622437}
{"mode": "train", "epochs": 1, "timestep": 402, "ep_reward": 185.31381225585938, "reward": 0.4186345934867859, "action": -1.3071999549865723}
{"mode": "train", "epochs": 1, "timestep": 403, "ep_reward": 185.76792907714844, "reward": 0.45411455631256104, "action": -0.9102262258529663}
{"mode": "train", "epochs": 1, "timestep": 404, "ep_reward": 186.2586212158203, "reward": 0.4906994700431824, "action": -0.4060046672821045}
{"mode": "train", "epochs": 1, "timestep": 405, "ep_reward": 186.7845916748047, "reward": 0.5259699821472168, "action": -0.7544105052947998}
{"mode": "train", "epochs": 1, "timestep": 406, "ep_reward": 187.34092712402344, "reward": 0.5563417673110962, "action": -1.8233485221862793}
{"mode": "train", "epochs": 1, "timestep": 407, "ep_reward": 187.92315673828125, "reward": 0.5822250843048096, "action": -0.051957905292510986}
{"mode": "train", "epochs": 1, "timestep": 408, "ep_reward": 188.52845764160156, "reward": 0.6053017377853394, "action": -1.271458387374878}
{"mode": "train", "epochs": 1, "timestep": 409, "ep_reward": 189.1491241455078, "reward": 0.6206606030464172, "action": -0.7709611654281616}
{"mode": "train", "epochs": 1, "timestep": 410, "ep_reward": 189.7791290283203, "reward": 0.6300100088119507, "action": -0.6447584629058838}
{"mode": "train", "epochs": 1, "timestep": 411, "ep_reward": 190.4108428955078, "reward": 0.6317155361175537, "action": -0.7457870244979858}
{"mode": "train", "epochs": 1, "timestep": 412, "ep_reward": 191.0365447998047, "reward": 0.6257063150405884, "action": -1.321436882019043}
{"mode": "train", "epochs": 1, "timestep": 413, "ep_reward": 191.6509552001953, "reward": 0.6144177317619324, "action": -1.0181546211242676}
{"mode": "train", "epochs": 1, "timestep": 414, "ep_reward": 192.24771118164062, "reward": 0.5967566967010498, "action": -1.0662001371383667}
{"mode": "train", "epochs": 1, "timestep": 415, "ep_reward": 192.8214111328125, "reward": 0.5736989378929138, "action": -1.29252290725708}
{"mode": "train", "epochs": 1, "timestep": 416, "ep_reward": 193.36871337890625, "reward": 0.5473011136054993, "action": -0.22285997867584229}
{"mode": "train", "epochs": 1, "timestep": 417, "ep_reward": 193.88050842285156, "reward": 0.5118024349212646, "action": -0.6766241788864136}
{"mode": "train", "epochs": 1, "timestep": 418, "ep_reward": 194.35440063476562, "reward": 0.47388696670532227, "action": -0.6944133043289185}
{"mode": "train", "epochs": 1, "timestep": 419, "ep_reward": 194.788330078125, "reward": 0.43393242359161377, "action": -1.029266595840454}
{"mode": "train", "epochs": 1, "timestep": 420, "ep_reward": 195.1841278076172, "reward": 0.3958011865615845, "action": -1.4293023347854614}
{"mode": "train", "epochs": 1, "timestep": 421, "ep_reward": 195.54672241210938, "reward": 0.3625882863998413, "action": -0.7993791699409485}
{"mode": "train", "epochs": 1, "timestep": 422, "ep_reward": 195.94239807128906, "reward": 0.39567136764526367, "action": -0.9671621322631836}
{"mode": "train", "epochs": 1, "timestep": 423, "ep_reward": 196.3721160888672, "reward": 0.4297196865081787, "action": -1.643263816833496}
{"mode": "train", "epochs": 1, "timestep": 424, "ep_reward": 196.83065795898438, "reward": 0.4585392475128174, "action": -1.1252752542495728}
{"mode": "train", "epochs": 1, "timestep": 425, "ep_reward": 197.30947875976562, "reward": 0.4788161516189575, "action": -0.6141297817230225}
{"mode": "train", "epochs": 1, "timestep": 426, "ep_reward": 197.8014373779297, "reward": 0.49195152521133423, "action": -0.27933788299560547}
{"mode": "train", "epochs": 1, "timestep": 427, "ep_reward": 198.30055236816406, "reward": 0.49910968542099, "action": -1.1735970973968506}
{"mode": "train", "epochs": 1, "timestep": 428, "ep_reward": 198.79885864257812, "reward": 0.49831342697143555, "action": -0.8281956911087036}
{"mode": "train", "epochs": 1, "timestep": 429, "ep_reward": 199.2882537841797, "reward": 0.48939788341522217, "action": -1.280398964881897}
{"mode": "train", "epochs": 1, "timestep": 430, "ep_reward": 199.75921630859375, "reward": 0.47096139192581177, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 431, "ep_reward": 200.19969177246094, "reward": 0.44047093391418457, "action": -0.9643776416778564}
{"mode": "train", "epochs": 1, "timestep": 432, "ep_reward": 200.6050567626953, "reward": 0.4053701162338257, "action": -1.1463862657546997}
{"mode": "train", "epochs": 1, "timestep": 433, "ep_reward": 200.96957397460938, "reward": 0.36451196670532227, "action": -0.7020421028137207}
{"mode": "train", "epochs": 1, "timestep": 434, "ep_reward": 201.3639373779297, "reward": 0.3943679928779602, "action": -1.2351176738739014}
{"mode": "train", "epochs": 1, "timestep": 435, "ep_reward": 201.7942657470703, "reward": 0.43032222986221313, "action": -0.7339162826538086}
{"mode": "train", "epochs": 1, "timestep": 436, "ep_reward": 202.2623748779297, "reward": 0.468106210231781, "action": -0.6329488754272461}
{"mode": "train", "epochs": 1, "timestep": 437, "ep_reward": 202.7670135498047, "reward": 0.5046416521072388, "action": 0.2812119722366333}
{"mode": "train", "epochs": 1, "timestep": 438, "ep_reward": 203.30567932128906, "reward": 0.5386612415313721, "action": -0.3637509346008301}
{"mode": "train", "epochs": 1, "timestep": 439, "ep_reward": 203.8707275390625, "reward": 0.5650540590286255, "action": -1.6752527952194214}
{"mode": "train", "epochs": 1, "timestep": 440, "ep_reward": 204.4567413330078, "reward": 0.5860067009925842, "action": -0.777008593082428}
{"mode": "train", "epochs": 1, "timestep": 441, "ep_reward": 205.0602569580078, "reward": 0.6035091876983643, "action": -0.3301684260368347}
{"mode": "train", "epochs": 1, "timestep": 442, "ep_reward": 205.67417907714844, "reward": 0.6139194369316101, "action": -1.5601507425308228}
{"mode": "train", "epochs": 1, "timestep": 443, "ep_reward": 206.2927703857422, "reward": 0.6185948848724365, "action": -1.6954576969146729}
{"mode": "train", "epochs": 1, "timestep": 444, "ep_reward": 206.91224670410156, "reward": 0.6194837689399719, "action": -0.905573308467865}
{"mode": "train", "epochs": 1, "timestep": 445, "ep_reward": 207.52645874023438, "reward": 0.6142187118530273, "action": 0.02791297435760498}
{"mode": "train", "epochs": 1, "timestep": 446, "ep_reward": 208.1253662109375, "reward": 0.5989053249359131, "action": -1.6233071088790894}
{"mode": "train", "epochs": 1, "timestep": 447, "ep_reward": 208.70692443847656, "reward": 0.5815606117248535, "action": -1.3840746879577637}
{"mode": "train", "epochs": 1, "timestep": 448, "ep_reward": 209.26707458496094, "reward": 0.5601528882980347, "action": -0.8130378723144531}
{"mode": "train", "epochs": 1, "timestep": 449, "ep_reward": 209.79969787597656, "reward": 0.5326284170150757, "action": -1.6609153747558594}
{"mode": "train", "epochs": 1, "timestep": 450, "ep_reward": 210.30581665039062, "reward": 0.5061185956001282, "action": -0.919801652431488}
{"mode": "train", "epochs": 1, "timestep": 451, "ep_reward": 210.78102111816406, "reward": 0.4751981496810913, "action": -0.6721527576446533}
{"mode": "train", "epochs": 1, "timestep": 452, "ep_reward": 211.22259521484375, "reward": 0.4415704011917114, "action": -0.7615236639976501}
{"mode": "train", "epochs": 1, "timestep": 453, "ep_reward": 211.6304931640625, "reward": 0.40789228677749634, "action": -0.5834965705871582}
{"mode": "train", "epochs": 1, "timestep": 454, "ep_reward": 212.0045623779297, "reward": 0.37406283617019653, "action": -0.9870681762695312}
{"mode": "train", "epochs": 1, "timestep": 455, "ep_reward": 212.39247131347656, "reward": 0.3879151940345764, "action": -0.374057412147522}
{"mode": "train", "epochs": 1, "timestep": 456, "ep_reward": 212.8115234375, "reward": 0.4190453290939331, "action": -1.1800261735916138}
{"mode": "train", "epochs": 1, "timestep": 457, "ep_reward": 213.25875854492188, "reward": 0.4472348690032959, "action": -1.7543003559112549}
{"mode": "train", "epochs": 1, "timestep": 458, "ep_reward": 213.7271728515625, "reward": 0.46841222047805786, "action": 0.009290695190429688}
{"mode": "train", "epochs": 1, "timestep": 459, "ep_reward": 214.2093505859375, "reward": 0.48218125104904175, "action": -1.440034031867981}
{"mode": "train", "epochs": 1, "timestep": 460, "ep_reward": 214.69862365722656, "reward": 0.4892774820327759, "action": -1.4758272171020508}
{"mode": "train", "epochs": 1, "timestep": 461, "ep_reward": 215.18502807617188, "reward": 0.486411988735199, "action": -1.6527223587036133}
{"mode": "train", "epochs": 1, "timestep": 462, "ep_reward": 215.65809631347656, "reward": 0.47307461500167847, "action": -0.6114481091499329}
{"mode": "train", "epochs": 1, "timestep": 463, "ep_reward": 216.11209106445312, "reward": 0.4539930820465088, "action": -1.44607412815094}
{"mode": "train", "epochs": 1, "timestep": 464, "ep_reward": 216.5377655029297, "reward": 0.42567187547683716, "action": -0.759467601776123}
{"mode": "train", "epochs": 1, "timestep": 465, "ep_reward": 216.93148803710938, "reward": 0.39372432231903076, "action": -1.5595362186431885}
{"mode": "train", "epochs": 1, "timestep": 466, "ep_reward": 217.30499267578125, "reward": 0.3735015392303467, "action": -1.5618609189987183}
{"mode": "train", "epochs": 1, "timestep": 467, "ep_reward": 217.71148681640625, "reward": 0.40649598836898804, "action": -0.17042821645736694}
{"mode": "train", "epochs": 1, "timestep": 468, "ep_reward": 218.15501403808594, "reward": 0.4435206651687622, "action": -0.7433463335037231}
{"mode": "train", "epochs": 1, "timestep": 469, "ep_reward": 218.63308715820312, "reward": 0.47807782888412476, "action": -1.0429911613464355}
{"mode": "train", "epochs": 1, "timestep": 470, "ep_reward": 219.1439208984375, "reward": 0.510827898979187, "action": -0.6852353811264038}
{"mode": "train", "epochs": 1, "timestep": 471, "ep_reward": 219.68545532226562, "reward": 0.5415387153625488, "action": -1.8307335376739502}
{"mode": "train", "epochs": 1, "timestep": 472, "ep_reward": 220.25350952148438, "reward": 0.5680590867996216, "action": -0.46407097578048706}
{"mode": "train", "epochs": 1, "timestep": 473, "ep_reward": 220.84608459472656, "reward": 0.5925712585449219, "action": -1.2408956289291382}
{"mode": "train", "epochs": 1, "timestep": 474, "ep_reward": 221.45668029785156, "reward": 0.6105939149856567, "action": -1.6242587566375732}
{"mode": "train", "epochs": 1, "timestep": 475, "ep_reward": 222.0806427001953, "reward": 0.6239678263664246, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 476, "ep_reward": 222.7144775390625, "reward": 0.6338398456573486, "action": -1.1463855504989624}
{"mode": "train", "epochs": 1, "timestep": 477, "ep_reward": 223.35304260253906, "reward": 0.638566255569458, "action": -1.6598225831985474}
{"mode": "train", "epochs": 1, "timestep": 478, "ep_reward": 223.9913787841797, "reward": 0.638338565826416, "action": -1.247835397720337}
{"mode": "train", "epochs": 1, "timestep": 479, "ep_reward": 224.6234893798828, "reward": 0.6321119070053101, "action": -1.6864726543426514}
{"mode": "train", "epochs": 1, "timestep": 480, "ep_reward": 225.24522399902344, "reward": 0.6217384338378906, "action": -0.7068055868148804}
{"mode": "train", "epochs": 1, "timestep": 481, "ep_reward": 225.84825134277344, "reward": 0.6030235886573792, "action": -1.5594350099563599}
{"mode": "train", "epochs": 1, "timestep": 482, "ep_reward": 226.42977905273438, "reward": 0.5815320014953613, "action": -1.1414625644683838}
{"mode": "train", "epochs": 1, "timestep": 483, "ep_reward": 226.98439025878906, "reward": 0.5546098351478577, "action": -0.5259586572647095}
{"mode": "train", "epochs": 1, "timestep": 484, "ep_reward": 227.50474548339844, "reward": 0.5203501582145691, "action": -1.1431941986083984}
{"mode": "train", "epochs": 1, "timestep": 485, "ep_reward": 227.9901580810547, "reward": 0.48541057109832764, "action": -1.0210649967193604}
{"mode": "train", "epochs": 1, "timestep": 486, "ep_reward": 228.43878173828125, "reward": 0.4486224055290222, "action": -0.9801183938980103}
{"mode": "train", "epochs": 1, "timestep": 487, "ep_reward": 228.85044860839844, "reward": 0.4116630554199219, "action": -0.4060593247413635}
{"mode": "train", "epochs": 1, "timestep": 488, "ep_reward": 229.22267150878906, "reward": 0.37222182750701904, "action": -1.0869898796081543}
{"mode": "train", "epochs": 1, "timestep": 489, "ep_reward": 229.60595703125, "reward": 0.38329267501831055, "action": -1.0215449333190918}
{"mode": "train", "epochs": 1, "timestep": 490, "ep_reward": 230.02549743652344, "reward": 0.4195373058319092, "action": -0.9741737842559814}
{"mode": "train", "epochs": 1, "timestep": 491, "ep_reward": 230.4761962890625, "reward": 0.45069700479507446, "action": -1.76955246925354}
{"mode": "train", "epochs": 1, "timestep": 492, "ep_reward": 230.9517059326172, "reward": 0.4755125641822815, "action": -0.1521579623222351}
{"mode": "train", "epochs": 1, "timestep": 493, "ep_reward": 231.4435272216797, "reward": 0.491827130317688, "action": -1.5471833944320679}
{"mode": "train", "epochs": 1, "timestep": 494, "ep_reward": 231.94448852539062, "reward": 0.5009653568267822, "action": -0.7323592901229858}
{"mode": "train", "epochs": 1, "timestep": 495, "ep_reward": 232.4457550048828, "reward": 0.5012621879577637, "action": -1.6783294677734375}
{"mode": "train", "epochs": 1, "timestep": 496, "ep_reward": 232.93670654296875, "reward": 0.4909511208534241, "action": -1.0880213975906372}
{"mode": "train", "epochs": 1, "timestep": 497, "ep_reward": 233.40846252441406, "reward": 0.4717521667480469, "action": -1.9446781873703003}
{"mode": "train", "epochs": 1, "timestep": 498, "ep_reward": 233.84890747070312, "reward": 0.44044387340545654, "action": -1.3518033027648926}
{"mode": "train", "epochs": 1, "timestep": 499, "ep_reward": 234.25108337402344, "reward": 0.4021819233894348, "action": -1.7168502807617188}
{"mode": "train", "epochs": 1, "timestep": 500, "ep_reward": 234.61056518554688, "reward": 0.35948461294174194, "action": -1.40614652633667}
{"mode": "train", "epochs": 1, "timestep": 501, "ep_reward": 235.0075225830078, "reward": 0.3969539403915405, "action": -1.0354348421096802}
{"mode": "train", "epochs": 1, "timestep": 502, "ep_reward": 235.44496154785156, "reward": 0.43744611740112305, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 503, "ep_reward": 235.92205810546875, "reward": 0.477091908454895, "action": -0.46017372608184814}
{"mode": "train", "epochs": 1, "timestep": 504, "ep_reward": 236.4427490234375, "reward": 0.5206849575042725, "action": -1.4377431869506836}
{"mode": "train", "epochs": 1, "timestep": 505, "ep_reward": 237.0015106201172, "reward": 0.5587636232376099, "action": -0.24820637702941895}
{"mode": "train", "epochs": 1, "timestep": 506, "ep_reward": 237.5967254638672, "reward": 0.5952200889587402, "action": -0.570273756980896}
{"mode": "train", "epochs": 1, "timestep": 507, "ep_reward": 238.2200469970703, "reward": 0.6233253479003906, "action": -1.9159164428710938}
{"mode": "train", "epochs": 1, "timestep": 508, "ep_reward": 238.8642120361328, "reward": 0.6441639065742493, "action": -1.181999683380127}
{"mode": "train", "epochs": 1, "timestep": 509, "ep_reward": 239.52462768554688, "reward": 0.66041499376297, "action": -0.7479605078697205}
{"mode": "train", "epochs": 1, "timestep": 510, "ep_reward": 240.19351196289062, "reward": 0.6688838005065918, "action": -1.7138340473175049}
{"mode": "train", "epochs": 1, "timestep": 511, "ep_reward": 240.86431884765625, "reward": 0.6708096861839294, "action": -1.2008358240127563}
{"mode": "train", "epochs": 1, "timestep": 512, "ep_reward": 241.53004455566406, "reward": 0.6657201051712036, "action": -1.2786083221435547}
{"mode": "train", "epochs": 1, "timestep": 513, "ep_reward": 242.1837921142578, "reward": 0.6537480354309082, "action": -0.6021491289138794}
{"mode": "train", "epochs": 1, "timestep": 514, "ep_reward": 242.81588745117188, "reward": 0.6320973038673401, "action": -0.7781891822814941}
{"mode": "train", "epochs": 1, "timestep": 515, "ep_reward": 243.41854858398438, "reward": 0.602665901184082, "action": -0.6924819946289062}
{"mode": "train", "epochs": 1, "timestep": 516, "ep_reward": 243.98403930664062, "reward": 0.5654940605163574, "action": -1.337180495262146}
{"mode": "train", "epochs": 1, "timestep": 517, "ep_reward": 244.510498046875, "reward": 0.5264662504196167, "action": -0.8961217999458313}
{"mode": "train", "epochs": 1, "timestep": 518, "ep_reward": 244.99244689941406, "reward": 0.4819455146789551, "action": -1.207963466644287}
{"mode": "train", "epochs": 1, "timestep": 519, "ep_reward": 245.43017578125, "reward": 0.4377242922782898, "action": -0.7611894011497498}
{"mode": "train", "epochs": 1, "timestep": 520, "ep_reward": 245.8211669921875, "reward": 0.3909945487976074, "action": -0.8048743009567261}
{"mode": "train", "epochs": 1, "timestep": 521, "ep_reward": 246.170166015625, "reward": 0.34899377822875977, "action": -0.7750672698020935}
{"mode": "train", "epochs": 1, "timestep": 522, "ep_reward": 246.566162109375, "reward": 0.3959982395172119, "action": -1.6867197751998901}
{"mode": "train", "epochs": 1, "timestep": 523, "ep_reward": 247.00709533691406, "reward": 0.4409297704696655, "action": -0.7449424266815186}
{"mode": "train", "epochs": 1, "timestep": 524, "ep_reward": 247.4838104248047, "reward": 0.4767146110534668, "action": -1.8071757555007935}
{"mode": "train", "epochs": 1, "timestep": 525, "ep_reward": 247.98989868164062, "reward": 0.5060817003250122, "action": -0.5374647378921509}
{"mode": "train", "epochs": 1, "timestep": 526, "ep_reward": 248.5144500732422, "reward": 0.5245516300201416, "action": -1.0256483554840088}
{"mode": "train", "epochs": 1, "timestep": 527, "ep_reward": 249.04888916015625, "reward": 0.5344430804252625, "action": -0.9423699378967285}
{"mode": "train", "epochs": 1, "timestep": 528, "ep_reward": 249.5831756591797, "reward": 0.5342806577682495, "action": -0.9521352052688599}
{"mode": "train", "epochs": 1, "timestep": 529, "ep_reward": 250.10719299316406, "reward": 0.5240185856819153, "action": -1.2489763498306274}
{"mode": "train", "epochs": 1, "timestep": 530, "ep_reward": 250.60989379882812, "reward": 0.5027005672454834, "action": -1.4293692111968994}
{"mode": "train", "epochs": 1, "timestep": 531, "ep_reward": 251.08010864257812, "reward": 0.4702085256576538, "action": -1.3169126510620117}
{"mode": "train", "epochs": 1, "timestep": 532, "ep_reward": 251.5088348388672, "reward": 0.4287300109863281, "action": -0.8558534383773804}
{"mode": "train", "epochs": 1, "timestep": 533, "ep_reward": 251.8917694091797, "reward": 0.3829391598701477, "action": -0.5689737796783447}
{"mode": "train", "epochs": 1, "timestep": 534, "ep_reward": 252.2598876953125, "reward": 0.3681248426437378, "action": -1.6295729875564575}
{"mode": "train", "epochs": 1, "timestep": 535, "ep_reward": 252.66824340820312, "reward": 0.40835362672805786, "action": -1.3003166913986206}
{"mode": "train", "epochs": 1, "timestep": 536, "ep_reward": 253.12013244628906, "reward": 0.45189058780670166, "action": -1.5111441612243652}
{"mode": "train", "epochs": 1, "timestep": 537, "ep_reward": 253.61563110351562, "reward": 0.4954955577850342, "action": -1.8275699615478516}
{"mode": "train", "epochs": 1, "timestep": 538, "ep_reward": 254.15383911132812, "reward": 0.5382068157196045, "action": -0.3097638487815857}
{"mode": "train", "epochs": 1, "timestep": 539, "ep_reward": 254.73631286621094, "reward": 0.5824699401855469, "action": -0.3870154023170471}
{"mode": "train", "epochs": 1, "timestep": 540, "ep_reward": 255.35533142089844, "reward": 0.6190152764320374, "action": -1.5979362726211548}
{"mode": "train", "epochs": 1, "timestep": 541, "ep_reward": 256.00201416015625, "reward": 0.6466750502586365, "action": -1.1820400953292847}
{"mode": "train", "epochs": 1, "timestep": 542, "ep_reward": 256.67095947265625, "reward": 0.6689599752426147, "action": -1.4949504137039185}
{"mode": "train", "epochs": 1, "timestep": 543, "ep_reward": 257.3551330566406, "reward": 0.6841772794723511, "action": -1.5513116121292114}
{"mode": "train", "epochs": 1, "timestep": 544, "ep_reward": 258.0479736328125, "reward": 0.6928463578224182, "action": -1.371492624282837}
{"mode": "train", "epochs": 1, "timestep": 545, "ep_reward": 258.74237060546875, "reward": 0.6944049596786499, "action": -1.3794374465942383}
{"mode": "train", "epochs": 1, "timestep": 546, "ep_reward": 259.4309387207031, "reward": 0.6885673999786377, "action": -1.220192313194275}
{"mode": "train", "epochs": 1, "timestep": 547, "ep_reward": 260.10577392578125, "reward": 0.6748332381248474, "action": -0.763802170753479}
{"mode": "train", "epochs": 1, "timestep": 548, "ep_reward": 260.7569885253906, "reward": 0.6512264013290405, "action": -1.4351487159729004}
{"mode": "train", "epochs": 1, "timestep": 549, "ep_reward": 261.3794250488281, "reward": 0.6224286556243896, "action": -0.6594123840332031}
{"mode": "train", "epochs": 1, "timestep": 550, "ep_reward": 261.9627685546875, "reward": 0.5833450555801392, "action": -0.2672507166862488}
{"mode": "train", "epochs": 1, "timestep": 551, "ep_reward": 262.4971008300781, "reward": 0.5343232154846191, "action": -0.23987042903900146}
{"mode": "train", "epochs": 1, "timestep": 552, "ep_reward": 262.97509765625, "reward": 0.477996289730072, "action": -1.5693718194961548}
{"mode": "train", "epochs": 1, "timestep": 553, "ep_reward": 263.40301513671875, "reward": 0.427920401096344, "action": -1.226387858390808}
{"mode": "train", "epochs": 1, "timestep": 554, "ep_reward": 263.7799377441406, "reward": 0.3769339919090271, "action": -1.8793306350708008}
{"mode": "train", "epochs": 1, "timestep": 555, "ep_reward": 264.130615234375, "reward": 0.35066407918930054, "action": -0.24993306398391724}
{"mode": "train", "epochs": 1, "timestep": 556, "ep_reward": 264.53057861328125, "reward": 0.3999677896499634, "action": -0.7464249134063721}
{"mode": "train", "epochs": 1, "timestep": 557, "ep_reward": 264.9789123535156, "reward": 0.44832587242126465, "action": -0.29963362216949463}
{"mode": "train", "epochs": 1, "timestep": 558, "ep_reward": 265.4696044921875, "reward": 0.4906957745552063, "action": -0.9203665256500244}
{"mode": "train", "epochs": 1, "timestep": 559, "ep_reward": 265.9975280761719, "reward": 0.5279252529144287, "action": -0.7064746618270874}
{"mode": "train", "epochs": 1, "timestep": 560, "ep_reward": 266.5531921386719, "reward": 0.555651068687439, "action": -0.34379422664642334}
{"mode": "train", "epochs": 1, "timestep": 561, "ep_reward": 267.12689208984375, "reward": 0.5737087726593018, "action": -1.251062035560608}
{"mode": "train", "epochs": 1, "timestep": 562, "ep_reward": 267.7077941894531, "reward": 0.5809158682823181, "action": -1.065948247909546}
{"mode": "train", "epochs": 1, "timestep": 563, "ep_reward": 268.2828674316406, "reward": 0.5750705003738403, "action": -1.0581251382827759}
{"mode": "train", "epochs": 1, "timestep": 564, "ep_reward": 268.8394470214844, "reward": 0.5565845966339111, "action": -0.8118743896484375}
{"mode": "train", "epochs": 1, "timestep": 565, "ep_reward": 269.36669921875, "reward": 0.5272400379180908, "action": -0.7924381494522095}
{"mode": "train", "epochs": 1, "timestep": 566, "ep_reward": 269.8548278808594, "reward": 0.4881237745285034, "action": -0.46665775775909424}
{"mode": "train", "epochs": 1, "timestep": 567, "ep_reward": 270.2976989746094, "reward": 0.4428566098213196, "action": -1.1903506517410278}
{"mode": "train", "epochs": 1, "timestep": 568, "ep_reward": 270.6850891113281, "reward": 0.3873804211616516, "action": -1.3558529615402222}
{"mode": "train", "epochs": 1, "timestep": 569, "ep_reward": 271.0325012207031, "reward": 0.3474265933036804, "action": -1.0247952938079834}
{"mode": "train", "epochs": 1, "timestep": 570, "ep_reward": 271.4298400878906, "reward": 0.3973405361175537, "action": -0.25270169973373413}
{"mode": "train", "epochs": 1, "timestep": 571, "ep_reward": 271.880615234375, "reward": 0.4507797956466675, "action": -1.0800857543945312}
{"mode": "train", "epochs": 1, "timestep": 572, "ep_reward": 272.38055419921875, "reward": 0.4999345541000366, "action": -0.3676900863647461}
{"mode": "train", "epochs": 1, "timestep": 573, "ep_reward": 272.92926025390625, "reward": 0.548708975315094, "action": -0.9990835785865784}
{"mode": "train", "epochs": 1, "timestep": 574, "ep_reward": 273.519775390625, "reward": 0.5905182361602783, "action": -0.6129000186920166}
{"mode": "train", "epochs": 1, "timestep": 575, "ep_reward": 274.1470642089844, "reward": 0.6273026466369629, "action": -0.7717635631561279}
{"mode": "train", "epochs": 1, "timestep": 576, "ep_reward": 274.802978515625, "reward": 0.6559076309204102, "action": -1.2198065519332886}
{"mode": "train", "epochs": 1, "timestep": 577, "ep_reward": 275.47918701171875, "reward": 0.6762080788612366, "action": -1.539273738861084}
{"mode": "train", "epochs": 1, "timestep": 578, "ep_reward": 276.1686706542969, "reward": 0.6894947290420532, "action": -1.1770989894866943}
{"mode": "train", "epochs": 1, "timestep": 579, "ep_reward": 276.86407470703125, "reward": 0.6953960657119751, "action": -1.7511558532714844}
{"mode": "train", "epochs": 1, "timestep": 580, "ep_reward": 277.5587158203125, "reward": 0.6946315765380859, "action": -1.5519859790802002}
{"mode": "train", "epochs": 1, "timestep": 581, "ep_reward": 278.24591064453125, "reward": 0.6871802806854248, "action": -0.9212989807128906}
{"mode": "train", "epochs": 1, "timestep": 582, "ep_reward": 278.9163818359375, "reward": 0.6704697608947754, "action": -1.3208587169647217}
{"mode": "train", "epochs": 1, "timestep": 583, "ep_reward": 279.56329345703125, "reward": 0.6468992233276367, "action": -1.3630863428115845}
{"mode": "train", "epochs": 1, "timestep": 584, "ep_reward": 280.1800231933594, "reward": 0.616716742515564, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 585, "ep_reward": 280.7649230957031, "reward": 0.5849066972732544, "action": -0.7717635631561279}
{"mode": "train", "epochs": 1, "timestep": 586, "ep_reward": 281.3075866699219, "reward": 0.5426514148712158, "action": -1.0995442867279053}
{"mode": "train", "epochs": 1, "timestep": 587, "ep_reward": 281.8051452636719, "reward": 0.4975709915161133, "action": -1.3367347717285156}
{"mode": "train", "epochs": 1, "timestep": 588, "ep_reward": 282.25732421875, "reward": 0.45218324661254883, "action": -0.9343950152397156}
{"mode": "train", "epochs": 1, "timestep": 589, "ep_reward": 282.6615905761719, "reward": 0.4042596220970154, "action": -1.115011215209961}
{"mode": "train", "epochs": 1, "timestep": 590, "ep_reward": 283.02044677734375, "reward": 0.3588566184043884, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 591, "ep_reward": 283.4025573730469, "reward": 0.3821021318435669, "action": -0.5476058721542358}
{"mode": "train", "epochs": 1, "timestep": 592, "ep_reward": 283.8268737792969, "reward": 0.42432016134262085, "action": -0.2035110592842102}
{"mode": "train", "epochs": 1, "timestep": 593, "ep_reward": 284.2895202636719, "reward": 0.46265435218811035, "action": 0.026530146598815918}
{"mode": "train", "epochs": 1, "timestep": 594, "ep_reward": 284.7862548828125, "reward": 0.4967423677444458, "action": -1.3977397680282593}
{"mode": "train", "epochs": 1, "timestep": 595, "ep_reward": 285.31256103515625, "reward": 0.5263175964355469, "action": -0.8027290105819702}
{"mode": "train", "epochs": 1, "timestep": 596, "ep_reward": 285.8575439453125, "reward": 0.5449765920639038, "action": -1.3652455806732178}
{"mode": "train", "epochs": 1, "timestep": 597, "ep_reward": 286.41046142578125, "reward": 0.5529097318649292, "action": -0.7067558765411377}
{"mode": "train", "epochs": 1, "timestep": 598, "ep_reward": 286.96044921875, "reward": 0.5499800443649292, "action": -0.9113049507141113}
{"mode": "train", "epochs": 1, "timestep": 599, "ep_reward": 287.49688720703125, "reward": 0.536441445350647, "action": -1.1215060949325562}
{"mode": "train", "epochs": 1, "timestep": 600, "ep_reward": 288.00860595703125, "reward": 0.5117148756980896, "action": -0.6459570527076721}
{"mode": "train", "epochs": 1, "timestep": 601, "ep_reward": 288.4878234863281, "reward": 0.4792090654373169, "action": -1.366152048110962}
{"mode": "train", "epochs": 1, "timestep": 602, "ep_reward": 288.9231872558594, "reward": 0.4353625178337097, "action": -1.298059105873108}
{"mode": "train", "epochs": 1, "timestep": 603, "ep_reward": 289.30712890625, "reward": 0.38394594192504883, "action": -0.9781405925750732}
{"mode": "train", "epochs": 1, "timestep": 604, "ep_reward": 289.66705322265625, "reward": 0.35992568731307983, "action": -0.42212843894958496}
{"mode": "train", "epochs": 1, "timestep": 605, "ep_reward": 290.0735778808594, "reward": 0.40653473138809204, "action": -0.8476623296737671}
{"mode": "train", "epochs": 1, "timestep": 606, "ep_reward": 290.5257263183594, "reward": 0.4521365761756897, "action": -1.4008564949035645}
{"mode": "train", "epochs": 1, "timestep": 607, "ep_reward": 291.021728515625, "reward": 0.49600666761398315, "action": -1.5904994010925293}
{"mode": "train", "epochs": 1, "timestep": 608, "ep_reward": 291.5605163574219, "reward": 0.5387899875640869, "action": -1.3748440742492676}
{"mode": "train", "epochs": 1, "timestep": 609, "ep_reward": 292.14068603515625, "reward": 0.5801664590835571, "action": -1.2937461137771606}
{"mode": "train", "epochs": 1, "timestep": 610, "ep_reward": 292.758544921875, "reward": 0.6178532838821411, "action": -0.3753235936164856}
{"mode": "train", "epochs": 1, "timestep": 611, "ep_reward": 293.40924072265625, "reward": 0.6506921052932739, "action": -1.395934820175171}
{"mode": "train", "epochs": 1, "timestep": 612, "ep_reward": 294.0832214355469, "reward": 0.6739686727523804, "action": -0.414006769657135}
{"mode": "train", "epochs": 1, "timestep": 613, "ep_reward": 294.7729187011719, "reward": 0.689709484577179, "action": -0.8480885624885559}
{"mode": "train", "epochs": 1, "timestep": 614, "ep_reward": 295.4681396484375, "reward": 0.6952335834503174, "action": -1.6747376918792725}
{"mode": "train", "epochs": 1, "timestep": 615, "ep_reward": 296.1617431640625, "reward": 0.6936146020889282, "action": -1.2260385751724243}
{"mode": "train", "epochs": 1, "timestep": 616, "ep_reward": 296.84588623046875, "reward": 0.6841486096382141, "action": -1.1158636808395386}
{"mode": "train", "epochs": 1, "timestep": 617, "ep_reward": 297.5122985839844, "reward": 0.6664226651191711, "action": -0.5903403759002686}
{"mode": "train", "epochs": 1, "timestep": 618, "ep_reward": 298.1504821777344, "reward": 0.6381760239601135, "action": 0.3019009828567505}
{"mode": "train", "epochs": 1, "timestep": 619, "ep_reward": 298.7456970214844, "reward": 0.5952161550521851, "action": -1.0662623643875122}
{"mode": "train", "epochs": 1, "timestep": 620, "ep_reward": 299.2957458496094, "reward": 0.5500606894493103, "action": -0.5723724961280823}
{"mode": "train", "epochs": 1, "timestep": 621, "ep_reward": 299.79229736328125, "reward": 0.4965381622314453, "action": -0.690895676612854}
{"mode": "train", "epochs": 1, "timestep": 622, "ep_reward": 300.2320251464844, "reward": 0.43973273038864136, "action": -0.16665011644363403}
{"mode": "train", "epochs": 1, "timestep": 623, "ep_reward": 300.6091003417969, "reward": 0.3770812153816223, "action": -0.770397961139679}
{"mode": "train", "epochs": 1, "timestep": 624, "ep_reward": 300.94140625, "reward": 0.3323017358779907, "action": -1.0428564548492432}
{"mode": "train", "epochs": 1, "timestep": 625, "ep_reward": 301.33447265625, "reward": 0.3930763602256775, "action": -0.9049875736236572}
{"mode": "train", "epochs": 1, "timestep": 626, "ep_reward": 301.78375244140625, "reward": 0.4492703080177307, "action": -0.5388257503509521}
{"mode": "train", "epochs": 1, "timestep": 627, "ep_reward": 302.2823181152344, "reward": 0.49858057498931885, "action": -1.1036808490753174}
{"mode": "train", "epochs": 1, "timestep": 628, "ep_reward": 302.823974609375, "reward": 0.5416693687438965, "action": -0.6007548570632935}
{"mode": "train", "epochs": 1, "timestep": 629, "ep_reward": 303.3974304199219, "reward": 0.5734446048736572, "action": -1.5702886581420898}
{"mode": "train", "epochs": 1, "timestep": 630, "ep_reward": 303.99169921875, "reward": 0.5942661166191101, "action": -1.2635818719863892}
{"mode": "train", "epochs": 1, "timestep": 631, "ep_reward": 304.591796875, "reward": 0.6000947952270508, "action": -0.7996221780776978}
{"mode": "train", "epochs": 1, "timestep": 632, "ep_reward": 305.1844482421875, "reward": 0.5926572680473328, "action": -1.3517801761627197}
{"mode": "train", "epochs": 1, "timestep": 633, "ep_reward": 305.7550048828125, "reward": 0.5705535411834717, "action": -1.2131609916687012}
{"mode": "train", "epochs": 1, "timestep": 634, "ep_reward": 306.289794921875, "reward": 0.5347922444343567, "action": -1.7149739265441895}
{"mode": "train", "epochs": 1, "timestep": 635, "ep_reward": 306.7732849121094, "reward": 0.4834996461868286, "action": -1.3125654458999634}
{"mode": "train", "epochs": 1, "timestep": 636, "ep_reward": 307.19586181640625, "reward": 0.42258840799331665, "action": -1.303054928779602}
{"mode": "train", "epochs": 1, "timestep": 637, "ep_reward": 307.5496826171875, "reward": 0.35380756855010986, "action": -0.38223928213119507}
{"mode": "train", "epochs": 1, "timestep": 638, "ep_reward": 307.9056701660156, "reward": 0.35599637031555176, "action": -0.5459664463996887}
{"mode": "train", "epochs": 1, "timestep": 639, "ep_reward": 308.3192138671875, "reward": 0.4135374426841736, "action": -0.36401689052581787}
{"mode": "train", "epochs": 1, "timestep": 640, "ep_reward": 308.7903137207031, "reward": 0.47110217809677124, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 641, "ep_reward": 309.3115234375, "reward": 0.5212217569351196, "action": -0.715720534324646}
{"mode": "train", "epochs": 1, "timestep": 642, "ep_reward": 309.8860168457031, "reward": 0.5744838118553162, "action": -1.2521953582763672}
{"mode": "train", "epochs": 1, "timestep": 643, "ep_reward": 310.5064392089844, "reward": 0.6204314827919006, "action": -1.4151787757873535}
{"mode": "train", "epochs": 1, "timestep": 644, "ep_reward": 311.1666564941406, "reward": 0.6602197885513306, "action": -0.7948960661888123}
{"mode": "train", "epochs": 1, "timestep": 645, "ep_reward": 311.8606262207031, "reward": 0.6939624547958374, "action": -1.0479708909988403}
{"mode": "train", "epochs": 1, "timestep": 646, "ep_reward": 312.5784912109375, "reward": 0.7178516387939453, "action": -1.631569266319275}
{"mode": "train", "epochs": 1, "timestep": 647, "ep_reward": 313.3114318847656, "reward": 0.7329416871070862, "action": -1.1288881301879883}
{"mode": "train", "epochs": 1, "timestep": 648, "ep_reward": 314.0512390136719, "reward": 0.7398136258125305, "action": -0.9113006591796875}
{"mode": "train", "epochs": 1, "timestep": 649, "ep_reward": 314.78790283203125, "reward": 0.7366591691970825, "action": -1.0010524988174438}
{"mode": "train", "epochs": 1, "timestep": 650, "ep_reward": 315.5113525390625, "reward": 0.7234616875648499, "action": -0.7577765583992004}
{"mode": "train", "epochs": 1, "timestep": 651, "ep_reward": 316.2105407714844, "reward": 0.6991981267929077, "action": -0.4159401059150696}
{"mode": "train", "epochs": 1, "timestep": 652, "ep_reward": 316.8727722167969, "reward": 0.6622422933578491, "action": -1.049647569656372}
{"mode": "train", "epochs": 1, "timestep": 653, "ep_reward": 317.4908447265625, "reward": 0.6180812120437622, "action": -0.636379063129425}
{"mode": "train", "epochs": 1, "timestep": 654, "ep_reward": 318.053955078125, "reward": 0.5631148815155029, "action": 0.26928675174713135}
{"mode": "train", "epochs": 1, "timestep": 655, "ep_reward": 318.5469970703125, "reward": 0.49305081367492676, "action": -0.021299660205841064}
{"mode": "train", "epochs": 1, "timestep": 656, "ep_reward": 318.9642333984375, "reward": 0.41723406314849854, "action": -0.8272758722305298}
{"mode": "train", "epochs": 1, "timestep": 657, "ep_reward": 319.3099365234375, "reward": 0.34570157527923584, "action": -0.5167403817176819}
{"mode": "train", "epochs": 1, "timestep": 658, "ep_reward": 319.63323974609375, "reward": 0.3232969641685486, "action": -1.3350253105163574}
{"mode": "train", "epochs": 1, "timestep": 659, "ep_reward": 320.03155517578125, "reward": 0.3983212113380432, "action": -1.6252331733703613}
{"mode": "train", "epochs": 1, "timestep": 660, "ep_reward": 320.4999084472656, "reward": 0.4683442711830139, "action": -1.7776846885681152}
{"mode": "train", "epochs": 1, "timestep": 661, "ep_reward": 321.028564453125, "reward": 0.5286572575569153, "action": -0.952699601650238}
{"mode": "train", "epochs": 1, "timestep": 662, "ep_reward": 321.602783203125, "reward": 0.5742179155349731, "action": -0.7001234889030457}
{"mode": "train", "epochs": 1, "timestep": 663, "ep_reward": 322.2104187011719, "reward": 0.6076408624649048, "action": -0.41929876804351807}
{"mode": "train", "epochs": 1, "timestep": 664, "ep_reward": 322.8392028808594, "reward": 0.6287896037101746, "action": -1.210121750831604}
{"mode": "train", "epochs": 1, "timestep": 665, "ep_reward": 323.47589111328125, "reward": 0.6366920471191406, "action": -0.5151228904724121}
{"mode": "train", "epochs": 1, "timestep": 666, "ep_reward": 324.1063232421875, "reward": 0.6304324865341187, "action": -1.56972074508667}
{"mode": "train", "epochs": 1, "timestep": 667, "ep_reward": 324.7134704589844, "reward": 0.6071395874023438, "action": -0.702447772026062}
{"mode": "train", "epochs": 1, "timestep": 668, "ep_reward": 325.28472900390625, "reward": 0.5712437629699707, "action": -1.0001400709152222}
{"mode": "train", "epochs": 1, "timestep": 669, "ep_reward": 325.80609130859375, "reward": 0.5213527679443359, "action": -1.418531060218811}
{"mode": "train", "epochs": 1, "timestep": 670, "ep_reward": 326.2628479003906, "reward": 0.4567713141441345, "action": -1.5987250804901123}
{"mode": "train", "epochs": 1, "timestep": 671, "ep_reward": 326.6429138183594, "reward": 0.38007432222366333, "action": -0.9885161519050598}
{"mode": "train", "epochs": 1, "timestep": 672, "ep_reward": 326.953125, "reward": 0.3102072477340698, "action": -1.7252001762390137}
{"mode": "train", "epochs": 1, "timestep": 673, "ep_reward": 327.3236083984375, "reward": 0.3704696297645569, "action": -0.336944580078125}
{"mode": "train", "epochs": 1, "timestep": 674, "ep_reward": 327.7640075683594, "reward": 0.4403872489929199, "action": -0.13860750198364258}
{"mode": "train", "epochs": 1, "timestep": 675, "ep_reward": 328.2725830078125, "reward": 0.5085791945457458, "action": -1.9649288654327393}
{"mode": "train", "epochs": 1, "timestep": 676, "ep_reward": 328.8373107910156, "reward": 0.5647189021110535, "action": -1.2217285633087158}
{"mode": "train", "epochs": 1, "timestep": 677, "ep_reward": 329.4583435058594, "reward": 0.6210188865661621, "action": -0.7154086828231812}
{"mode": "train", "epochs": 1, "timestep": 678, "ep_reward": 330.1302795410156, "reward": 0.6719287633895874, "action": -1.7023473978042603}
{"mode": "train", "epochs": 1, "timestep": 679, "ep_reward": 330.8414306640625, "reward": 0.7111449837684631, "action": -1.5651016235351562}
{"mode": "train", "epochs": 1, "timestep": 680, "ep_reward": 331.58477783203125, "reward": 0.7433328628540039, "action": -0.36161887645721436}
{"mode": "train", "epochs": 1, "timestep": 681, "ep_reward": 332.35235595703125, "reward": 0.7675888538360596, "action": -0.5865334868431091}
{"mode": "train", "epochs": 1, "timestep": 682, "ep_reward": 333.13134765625, "reward": 0.7789859175682068, "action": -0.7444092035293579}
{"mode": "train", "epochs": 1, "timestep": 683, "ep_reward": 333.90985107421875, "reward": 0.7785123586654663, "action": -0.006948709487915039}
{"mode": "train", "epochs": 1, "timestep": 684, "ep_reward": 334.6736755371094, "reward": 0.7638319730758667, "action": -0.4847761392593384}
{"mode": "train", "epochs": 1, "timestep": 685, "ep_reward": 335.4100036621094, "reward": 0.736329197883606, "action": -0.561235785484314}
{"mode": "train", "epochs": 1, "timestep": 686, "ep_reward": 336.1062316894531, "reward": 0.6962375640869141, "action": -0.1907026171684265}
{"mode": "train", "epochs": 1, "timestep": 687, "ep_reward": 336.7472229003906, "reward": 0.6409980058670044, "action": -1.0425204038619995}
{"mode": "train", "epochs": 1, "timestep": 688, "ep_reward": 337.3270263671875, "reward": 0.5798181891441345, "action": -0.8469655513763428}
{"mode": "train", "epochs": 1, "timestep": 689, "ep_reward": 337.8363037109375, "reward": 0.5092805027961731, "action": -1.170479416847229}
{"mode": "train", "epochs": 1, "timestep": 690, "ep_reward": 338.2727966308594, "reward": 0.43649643659591675, "action": -0.7816474437713623}
{"mode": "train", "epochs": 1, "timestep": 691, "ep_reward": 338.6315612792969, "reward": 0.35875290632247925, "action": -1.6650173664093018}
{"mode": "train", "epochs": 1, "timestep": 692, "ep_reward": 338.9254150390625, "reward": 0.29384827613830566, "action": -1.413712739944458}
{"mode": "train", "epochs": 1, "timestep": 693, "ep_reward": 339.2975769042969, "reward": 0.3721521496772766, "action": -0.8654817342758179}
{"mode": "train", "epochs": 1, "timestep": 694, "ep_reward": 339.7409362792969, "reward": 0.4433524012565613, "action": -0.35023707151412964}
{"mode": "train", "epochs": 1, "timestep": 695, "ep_reward": 340.2476501464844, "reward": 0.5067281723022461, "action": -0.356792151927948}
{"mode": "train", "epochs": 1, "timestep": 696, "ep_reward": 340.81072998046875, "reward": 0.5630761384963989, "action": -0.3430357575416565}
{"mode": "train", "epochs": 1, "timestep": 697, "ep_reward": 341.4205627441406, "reward": 0.6098414659500122, "action": -1.4715582132339478}
{"mode": "train", "epochs": 1, "timestep": 698, "ep_reward": 342.0667419433594, "reward": 0.6461931467056274, "action": -1.2211487293243408}
{"mode": "train", "epochs": 1, "timestep": 699, "ep_reward": 342.7318420410156, "reward": 0.6651116609573364, "action": -0.4573681950569153}
{"mode": "train", "epochs": 1, "timestep": 700, "ep_reward": 343.4001159667969, "reward": 0.6682825088500977, "action": -1.1807827949523926}
{"mode": "train", "epochs": 1, "timestep": 701, "ep_reward": 344.0552062988281, "reward": 0.655097484588623, "action": -1.2427953481674194}
{"mode": "train", "epochs": 1, "timestep": 702, "ep_reward": 344.6794128417969, "reward": 0.6242057085037231, "action": -1.8488781452178955}
{"mode": "train", "epochs": 1, "timestep": 703, "ep_reward": 345.2521667480469, "reward": 0.5727606415748596, "action": -1.0157253742218018}
{"mode": "train", "epochs": 1, "timestep": 704, "ep_reward": 345.7613525390625, "reward": 0.509181797504425, "action": -0.8821218609809875}
{"mode": "train", "epochs": 1, "timestep": 705, "ep_reward": 346.1962585449219, "reward": 0.434920072555542, "action": -0.8277148008346558}
{"mode": "train", "epochs": 1, "timestep": 706, "ep_reward": 346.5494079589844, "reward": 0.35315024852752686, "action": -1.7045707702636719}
{"mode": "train", "epochs": 1, "timestep": 707, "ep_reward": 346.8573913574219, "reward": 0.3079691529273987, "action": 0.1840956211090088}
{"mode": "train", "epochs": 1, "timestep": 708, "ep_reward": 347.241943359375, "reward": 0.3845369219779968, "action": -1.0179768800735474}
{"mode": "train", "epochs": 1, "timestep": 709, "ep_reward": 347.69580078125, "reward": 0.45386648178100586, "action": -1.4712218046188354}
{"mode": "train", "epochs": 1, "timestep": 710, "ep_reward": 348.2159423828125, "reward": 0.5201451182365417, "action": -1.3224736452102661}
{"mode": "train", "epochs": 1, "timestep": 711, "ep_reward": 348.80059814453125, "reward": 0.5846477746963501, "action": -1.0554203987121582}
{"mode": "train", "epochs": 1, "timestep": 712, "ep_reward": 349.4453125, "reward": 0.6447247266769409, "action": -1.2808337211608887}
{"mode": "train", "epochs": 1, "timestep": 713, "ep_reward": 350.14111328125, "reward": 0.6958008408546448, "action": -1.4219114780426025}
{"mode": "train", "epochs": 1, "timestep": 714, "ep_reward": 350.87890625, "reward": 0.7378050088882446, "action": -0.7366615533828735}
{"mode": "train", "epochs": 1, "timestep": 715, "ep_reward": 351.65057373046875, "reward": 0.7716799974441528, "action": -0.677586555480957}
{"mode": "train", "epochs": 1, "timestep": 716, "ep_reward": 352.4443359375, "reward": 0.793769359588623, "action": -0.6347615122795105}
{"mode": "train", "epochs": 1, "timestep": 717, "ep_reward": 353.2480163574219, "reward": 0.8036928176879883, "action": -1.4280717372894287}
{"mode": "train", "epochs": 1, "timestep": 718, "ep_reward": 354.05120849609375, "reward": 0.8032000064849854, "action": -0.9321476221084595}
{"mode": "train", "epochs": 1, "timestep": 719, "ep_reward": 354.8431396484375, "reward": 0.7919462323188782, "action": -0.7536711692810059}
{"mode": "train", "epochs": 1, "timestep": 720, "ep_reward": 355.6116638183594, "reward": 0.7685191631317139, "action": -1.2425421476364136}
{"mode": "train", "epochs": 1, "timestep": 721, "ep_reward": 356.34698486328125, "reward": 0.7353233098983765, "action": -1.9430468082427979}
{"mode": "train", "epochs": 1, "timestep": 722, "ep_reward": 357.04339599609375, "reward": 0.6964184045791626, "action": -1.2020808458328247}
{"mode": "train", "epochs": 1, "timestep": 723, "ep_reward": 357.6881408691406, "reward": 0.6447317600250244, "action": -1.2734788656234741}
{"mode": "train", "epochs": 1, "timestep": 724, "ep_reward": 358.2727966308594, "reward": 0.5846434831619263, "action": -0.6448816657066345}
{"mode": "train", "epochs": 1, "timestep": 725, "ep_reward": 358.78460693359375, "reward": 0.5118102431297302, "action": -1.4074300527572632}
{"mode": "train", "epochs": 1, "timestep": 726, "ep_reward": 359.2247009277344, "reward": 0.44008976221084595, "action": -0.7970288991928101}
{"mode": "train", "epochs": 1, "timestep": 727, "ep_reward": 359.5865173339844, "reward": 0.3618190288543701, "action": -0.9265735745429993}
{"mode": "train", "epochs": 1, "timestep": 728, "ep_reward": 359.8727722167969, "reward": 0.28624624013900757, "action": -0.9203985929489136}
{"mode": "train", "epochs": 1, "timestep": 729, "ep_reward": 360.23687744140625, "reward": 0.36409711837768555, "action": -0.7920220494270325}
{"mode": "train", "epochs": 1, "timestep": 730, "ep_reward": 360.67657470703125, "reward": 0.4396843910217285, "action": -0.8352412581443787}
{"mode": "train", "epochs": 1, "timestep": 731, "ep_reward": 361.1860046386719, "reward": 0.5094354152679443, "action": -1.2549152374267578}
{"mode": "train", "epochs": 1, "timestep": 732, "ep_reward": 361.7572021484375, "reward": 0.5712043642997742, "action": -0.8704880475997925}
{"mode": "train", "epochs": 1, "timestep": 733, "ep_reward": 362.3758239746094, "reward": 0.6186273097991943, "action": -1.506920576095581}
{"mode": "train", "epochs": 1, "timestep": 734, "ep_reward": 363.0284423828125, "reward": 0.6526280641555786, "action": 0.062468111515045166}
{"mode": "train", "epochs": 1, "timestep": 735, "ep_reward": 363.6982421875, "reward": 0.6697986125946045, "action": -1.2786364555358887}
{"mode": "train", "epochs": 1, "timestep": 736, "ep_reward": 364.37109375, "reward": 0.6728513240814209, "action": -0.5315130949020386}
{"mode": "train", "epochs": 1, "timestep": 737, "ep_reward": 365.0312194824219, "reward": 0.6601403951644897, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 738, "ep_reward": 365.65740966796875, "reward": 0.6262032985687256, "action": -1.6017954349517822}
{"mode": "train", "epochs": 1, "timestep": 739, "ep_reward": 366.231201171875, "reward": 0.5737906694412231, "action": -1.0729501247406006}
{"mode": "train", "epochs": 1, "timestep": 740, "ep_reward": 366.73931884765625, "reward": 0.5081247091293335, "action": -0.47040778398513794}
{"mode": "train", "epochs": 1, "timestep": 741, "ep_reward": 367.1748352050781, "reward": 0.43551433086395264, "action": -0.9119143486022949}
{"mode": "train", "epochs": 1, "timestep": 742, "ep_reward": 367.5272521972656, "reward": 0.3524196147918701, "action": -1.4464948177337646}
{"mode": "train", "epochs": 1, "timestep": 743, "ep_reward": 367.8343200683594, "reward": 0.3070595860481262, "action": -0.9898402094841003}
{"mode": "train", "epochs": 1, "timestep": 744, "ep_reward": 368.21221923828125, "reward": 0.377895712852478, "action": -1.7740899324417114}
{"mode": "train", "epochs": 1, "timestep": 745, "ep_reward": 368.65875244140625, "reward": 0.44653135538101196, "action": -1.1525543928146362}
{"mode": "train", "epochs": 1, "timestep": 746, "ep_reward": 369.1778869628906, "reward": 0.5191495418548584, "action": -1.6812927722930908}
{"mode": "train", "epochs": 1, "timestep": 747, "ep_reward": 369.7636413574219, "reward": 0.5857556462287903, "action": -1.185857892036438}
{"mode": "train", "epochs": 1, "timestep": 748, "ep_reward": 370.4134216308594, "reward": 0.649779736995697, "action": -0.959261417388916}
{"mode": "train", "epochs": 1, "timestep": 749, "ep_reward": 371.1195983886719, "reward": 0.7061684131622314, "action": -0.8392881155014038}
{"mode": "train", "epochs": 1, "timestep": 750, "ep_reward": 371.8719177246094, "reward": 0.7523233890533447, "action": -0.3909537196159363}
{"mode": "train", "epochs": 1, "timestep": 751, "ep_reward": 372.6594543457031, "reward": 0.7875359058380127, "action": -0.6912912130355835}
{"mode": "train", "epochs": 1, "timestep": 752, "ep_reward": 373.4687805175781, "reward": 0.8093141913414001, "action": -0.8315243721008301}
{"mode": "train", "epochs": 1, "timestep": 753, "ep_reward": 374.2879638671875, "reward": 0.8191917538642883, "action": -1.1402723789215088}
{"mode": "train", "epochs": 1, "timestep": 754, "ep_reward": 375.10626220703125, "reward": 0.8183082342147827, "action": -1.3536427021026611}
{"mode": "train", "epochs": 1, "timestep": 755, "ep_reward": 375.91400146484375, "reward": 0.8077362775802612, "action": -1.7447175979614258}
{"mode": "train", "epochs": 1, "timestep": 756, "ep_reward": 376.7032165527344, "reward": 0.7892126441001892, "action": -0.6930081844329834}
{"mode": "train", "epochs": 1, "timestep": 757, "ep_reward": 377.4598693847656, "reward": 0.7566670179367065, "action": -0.7677698135375977}
{"mode": "train", "epochs": 1, "timestep": 758, "ep_reward": 378.1715393066406, "reward": 0.7116770148277283, "action": -0.2292882204055786}
{"mode": "train", "epochs": 1, "timestep": 759, "ep_reward": 378.8213806152344, "reward": 0.6498321294784546, "action": -1.3440576791763306}
{"mode": "train", "epochs": 1, "timestep": 760, "ep_reward": 379.4052734375, "reward": 0.5838996171951294, "action": -1.1959538459777832}
{"mode": "train", "epochs": 1, "timestep": 761, "ep_reward": 379.9144287109375, "reward": 0.5091561079025269, "action": -0.9205349683761597}
{"mode": "train", "epochs": 1, "timestep": 762, "ep_reward": 380.3410949707031, "reward": 0.426674485206604, "action": -0.39832931756973267}
{"mode": "train", "epochs": 1, "timestep": 763, "ep_reward": 380.6775207519531, "reward": 0.3364105820655823, "action": -0.8739450573921204}
{"mode": "train", "epochs": 1, "timestep": 764, "ep_reward": 380.95184326171875, "reward": 0.27431344985961914, "action": -1.7411811351776123}
{"mode": "train", "epochs": 1, "timestep": 765, "ep_reward": 381.3183288574219, "reward": 0.3664824366569519, "action": -0.8523865938186646}
{"mode": "train", "epochs": 1, "timestep": 766, "ep_reward": 381.766357421875, "reward": 0.4480407238006592, "action": -0.9540587067604065}
{"mode": "train", "epochs": 1, "timestep": 767, "ep_reward": 382.2895202636719, "reward": 0.5231585502624512, "action": -1.3506380319595337}
{"mode": "train", "epochs": 1, "timestep": 768, "ep_reward": 382.8784484863281, "reward": 0.5889150500297546, "action": -1.442191481590271}
{"mode": "train", "epochs": 1, "timestep": 769, "ep_reward": 383.51812744140625, "reward": 0.6396671533584595, "action": -1.789391279220581}
{"mode": "train", "epochs": 1, "timestep": 770, "ep_reward": 384.1912536621094, "reward": 0.6731259822845459, "action": -1.3142086267471313}
{"mode": "train", "epochs": 1, "timestep": 771, "ep_reward": 384.8780212402344, "reward": 0.6867671012878418, "action": -0.24491506814956665}
{"mode": "train", "epochs": 1, "timestep": 772, "ep_reward": 385.56243896484375, "reward": 0.6844174861907959, "action": -1.1047722101211548}
{"mode": "train", "epochs": 1, "timestep": 773, "ep_reward": 386.2275085449219, "reward": 0.6650680303573608, "action": -1.4257220029830933}
{"mode": "train", "epochs": 1, "timestep": 774, "ep_reward": 386.85406494140625, "reward": 0.6265507936477661, "action": -0.2840287685394287}
{"mode": "train", "epochs": 1, "timestep": 775, "ep_reward": 387.4312744140625, "reward": 0.5772020816802979, "action": -1.1781411170959473}
{"mode": "train", "epochs": 1, "timestep": 776, "ep_reward": 387.94091796875, "reward": 0.5096587538719177, "action": -0.4952799081802368}
{"mode": "train", "epochs": 1, "timestep": 777, "ep_reward": 388.3761291503906, "reward": 0.435202956199646, "action": -1.2556788921356201}
{"mode": "train", "epochs": 1, "timestep": 778, "ep_reward": 388.7231140136719, "reward": 0.34698688983917236, "action": -0.9627960324287415}
{"mode": "train", "epochs": 1, "timestep": 779, "ep_reward": 389.0279541015625, "reward": 0.3048367500305176, "action": -0.9601585865020752}
{"mode": "train", "epochs": 1, "timestep": 780, "ep_reward": 389.4048767089844, "reward": 0.3769323229789734, "action": -0.6251929402351379}
{"mode": "train", "epochs": 1, "timestep": 781, "ep_reward": 389.85711669921875, "reward": 0.4522451162338257, "action": -0.8568136692047119}
{"mode": "train", "epochs": 1, "timestep": 782, "ep_reward": 390.3812255859375, "reward": 0.5241032838821411, "action": -1.6208243370056152}
{"mode": "train", "epochs": 1, "timestep": 783, "ep_reward": 390.9694519042969, "reward": 0.5882127285003662, "action": -0.9498539566993713}
{"mode": "train", "epochs": 1, "timestep": 784, "ep_reward": 391.6196594238281, "reward": 0.6501946449279785, "action": -0.97279292345047}
{"mode": "train", "epochs": 1, "timestep": 785, "ep_reward": 392.32281494140625, "reward": 0.7031500339508057, "action": -0.7405812740325928}
{"mode": "train", "epochs": 1, "timestep": 786, "ep_reward": 393.06915283203125, "reward": 0.7463482618331909, "action": -1.2465673685073853}
{"mode": "train", "epochs": 1, "timestep": 787, "ep_reward": 393.84649658203125, "reward": 0.7773412466049194, "action": -1.0504660606384277}
{"mode": "train", "epochs": 1, "timestep": 788, "ep_reward": 394.6449890136719, "reward": 0.7984927892684937, "action": -0.7104692459106445}
{"mode": "train", "epochs": 1, "timestep": 789, "ep_reward": 395.4537353515625, "reward": 0.8087534308433533, "action": 0.5257925391197205}
{"mode": "train", "epochs": 1, "timestep": 790, "ep_reward": 396.2579040527344, "reward": 0.8041823506355286, "action": -1.7279417514801025}
{"mode": "train", "epochs": 1, "timestep": 791, "ep_reward": 397.0485534667969, "reward": 0.7906392812728882, "action": -0.8905539512634277}
{"mode": "train", "epochs": 1, "timestep": 792, "ep_reward": 397.81341552734375, "reward": 0.7648696899414062, "action": 0.2845037579536438}
{"mode": "train", "epochs": 1, "timestep": 793, "ep_reward": 398.5334777832031, "reward": 0.7200711965560913, "action": -1.7853336334228516}
{"mode": "train", "epochs": 1, "timestep": 794, "ep_reward": 399.2068786621094, "reward": 0.6734137535095215, "action": -0.8092494606971741}
{"mode": "train", "epochs": 1, "timestep": 795, "ep_reward": 399.8177490234375, "reward": 0.6108710765838623, "action": -1.810778260231018}
{"mode": "train", "epochs": 1, "timestep": 796, "ep_reward": 400.3652648925781, "reward": 0.5475026965141296, "action": -1.009037733078003}
{"mode": "train", "epochs": 1, "timestep": 797, "ep_reward": 400.8377990722656, "reward": 0.4725291132926941, "action": -1.2454191446304321}
{"mode": "train", "epochs": 1, "timestep": 798, "ep_reward": 401.2342834472656, "reward": 0.39648985862731934, "action": -1.4883307218551636}
{"mode": "train", "epochs": 1, "timestep": 799, "ep_reward": 401.55841064453125, "reward": 0.32412445545196533, "action": -1.0083985328674316}
{"mode": "train", "epochs": 1, "timestep": 800, "ep_reward": 401.8841857910156, "reward": 0.3257734775543213, "action": -1.1984667778015137}
{"mode": "train", "epochs": 1, "timestep": 801, "ep_reward": 402.28863525390625, "reward": 0.40445905923843384, "action": -0.8355912566184998}
{"mode": "train", "epochs": 1, "timestep": 802, "ep_reward": 402.7645263671875, "reward": 0.4758836030960083, "action": -1.4005295038223267}
{"mode": "train", "epochs": 1, "timestep": 803, "ep_reward": 403.3057861328125, "reward": 0.5412477254867554, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 804, "ep_reward": 403.90081787109375, "reward": 0.5950443744659424, "action": -0.9028089642524719}
{"mode": "train", "epochs": 1, "timestep": 805, "ep_reward": 404.531005859375, "reward": 0.6301969289779663, "action": -1.197522521018982}
{"mode": "train", "epochs": 1, "timestep": 806, "ep_reward": 405.18182373046875, "reward": 0.6508310437202454, "action": -1.4436912536621094}
{"mode": "train", "epochs": 1, "timestep": 807, "ep_reward": 405.8363342285156, "reward": 0.6544954776763916, "action": -1.0439565181732178}
{"mode": "train", "epochs": 1, "timestep": 808, "ep_reward": 406.4777526855469, "reward": 0.6414119005203247, "action": -0.9732344150543213}
{"mode": "train", "epochs": 1, "timestep": 809, "ep_reward": 407.0903625488281, "reward": 0.6126004457473755, "action": -1.3830140829086304}
{"mode": "train", "epochs": 1, "timestep": 810, "ep_reward": 407.6568603515625, "reward": 0.5664904713630676, "action": -0.3908231258392334}
{"mode": "train", "epochs": 1, "timestep": 811, "ep_reward": 408.1689147949219, "reward": 0.5120651721954346, "action": -0.5037040710449219}
{"mode": "train", "epochs": 1, "timestep": 812, "ep_reward": 408.616943359375, "reward": 0.4480206370353699, "action": -0.6227403283119202}
{"mode": "train", "epochs": 1, "timestep": 813, "ep_reward": 408.99346923828125, "reward": 0.37652909755706787, "action": -0.9159110188484192}
{"mode": "train", "epochs": 1, "timestep": 814, "ep_reward": 409.3082580566406, "reward": 0.31479859352111816, "action": -0.07603418827056885}
{"mode": "train", "epochs": 1, "timestep": 815, "ep_reward": 409.68939208984375, "reward": 0.3811236023902893, "action": -0.7801934480667114}
{"mode": "train", "epochs": 1, "timestep": 816, "ep_reward": 410.1336669921875, "reward": 0.4442744851112366, "action": -0.4038901925086975}
{"mode": "train", "epochs": 1, "timestep": 817, "ep_reward": 410.6414794921875, "reward": 0.5077986717224121, "action": -0.41494864225387573}
{"mode": "train", "epochs": 1, "timestep": 818, "ep_reward": 411.2080993652344, "reward": 0.5666332244873047, "action": 0.4856049418449402}
{"mode": "train", "epochs": 1, "timestep": 819, "ep_reward": 411.8287658691406, "reward": 0.6206774115562439, "action": -0.44961094856262207}
{"mode": "train", "epochs": 1, "timestep": 820, "ep_reward": 412.4897155761719, "reward": 0.6609527468681335, "action": -0.2743048667907715}
{"mode": "train", "epochs": 1, "timestep": 821, "ep_reward": 413.1809997558594, "reward": 0.6912736892700195, "action": -0.28564566373825073}
{"mode": "train", "epochs": 1, "timestep": 822, "ep_reward": 413.8909912109375, "reward": 0.7099961042404175, "action": -0.5415147542953491}
{"mode": "train", "epochs": 1, "timestep": 823, "ep_reward": 414.6080017089844, "reward": 0.717005729675293, "action": -1.2779552936553955}
{"mode": "train", "epochs": 1, "timestep": 824, "ep_reward": 415.3226623535156, "reward": 0.7146734595298767, "action": -1.3440303802490234}
{"mode": "train", "epochs": 1, "timestep": 825, "ep_reward": 416.0268859863281, "reward": 0.7042259573936462, "action": -0.7165393829345703}
{"mode": "train", "epochs": 1, "timestep": 826, "ep_reward": 416.7097473144531, "reward": 0.6828683018684387, "action": -1.8077588081359863}
{"mode": "train", "epochs": 1, "timestep": 827, "ep_reward": 417.36688232421875, "reward": 0.6571221351623535, "action": -1.1567707061767578}
{"mode": "train", "epochs": 1, "timestep": 828, "ep_reward": 417.9888000488281, "reward": 0.6219136714935303, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 829, "ep_reward": 418.5743103027344, "reward": 0.5855069160461426, "action": -0.8961198925971985}
{"mode": "train", "epochs": 1, "timestep": 830, "ep_reward": 419.1130065917969, "reward": 0.5386990904808044, "action": -0.9845839738845825}
{"mode": "train", "epochs": 1, "timestep": 831, "ep_reward": 419.60064697265625, "reward": 0.4876406788825989, "action": -1.8045152425765991}
{"mode": "train", "epochs": 1, "timestep": 832, "ep_reward": 420.0415344238281, "reward": 0.4408726096153259, "action": -0.9851794242858887}
{"mode": "train", "epochs": 1, "timestep": 833, "ep_reward": 420.4314270019531, "reward": 0.38988959789276123, "action": 0.020264089107513428}
{"mode": "train", "epochs": 1, "timestep": 834, "ep_reward": 420.7677917480469, "reward": 0.3363611698150635, "action": -0.36044132709503174}
{"mode": "train", "epochs": 1, "timestep": 835, "ep_reward": 421.15838623046875, "reward": 0.39058440923690796, "action": -1.5580995082855225}
{"mode": "train", "epochs": 1, "timestep": 836, "ep_reward": 421.6039123535156, "reward": 0.44553834199905396, "action": -0.5768686532974243}
{"mode": "train", "epochs": 1, "timestep": 837, "ep_reward": 422.09466552734375, "reward": 0.49074602127075195, "action": -0.587613046169281}
{"mode": "train", "epochs": 1, "timestep": 838, "ep_reward": 422.6238708496094, "reward": 0.5292102098464966, "action": -1.5136576890945435}
{"mode": "train", "epochs": 1, "timestep": 839, "ep_reward": 423.1831970214844, "reward": 0.5593113899230957, "action": -1.89527428150177}
{"mode": "train", "epochs": 1, "timestep": 840, "ep_reward": 423.7586975097656, "reward": 0.5755101442337036, "action": -1.0383902788162231}
{"mode": "train", "epochs": 1, "timestep": 841, "ep_reward": 424.3360900878906, "reward": 0.5773926973342896, "action": -1.3098844289779663}
{"mode": "train", "epochs": 1, "timestep": 842, "ep_reward": 424.9019775390625, "reward": 0.5658832788467407, "action": -0.8945498466491699}
{"mode": "train", "epochs": 1, "timestep": 843, "ep_reward": 425.4447326660156, "reward": 0.5427464842796326, "action": -0.6066786050796509}
{"mode": "train", "epochs": 1, "timestep": 844, "ep_reward": 425.9550476074219, "reward": 0.5103200078010559, "action": -0.7071048021316528}
{"mode": "train", "epochs": 1, "timestep": 845, "ep_reward": 426.42401123046875, "reward": 0.46895378828048706, "action": -0.7529333829879761}
{"mode": "train", "epochs": 1, "timestep": 846, "ep_reward": 426.8442687988281, "reward": 0.420271098613739, "action": -0.6456835269927979}
{"mode": "train", "epochs": 1, "timestep": 847, "ep_reward": 427.2115478515625, "reward": 0.3672783374786377, "action": -0.9951493144035339}
{"mode": "train", "epochs": 1, "timestep": 848, "ep_reward": 427.5807800292969, "reward": 0.36924153566360474, "action": -0.7556758522987366}
{"mode": "train", "epochs": 1, "timestep": 849, "ep_reward": 427.9986572265625, "reward": 0.41788607835769653, "action": -0.0329856276512146}
{"mode": "train", "epochs": 1, "timestep": 850, "ep_reward": 428.46697998046875, "reward": 0.46832549571990967, "action": -1.1972699165344238}
{"mode": "train", "epochs": 1, "timestep": 851, "ep_reward": 428.97991943359375, "reward": 0.5129431486129761, "action": -0.44413745403289795}
{"mode": "train", "epochs": 1, "timestep": 852, "ep_reward": 429.5368347167969, "reward": 0.5569249987602234, "action": -0.6610954403877258}
{"mode": "train", "epochs": 1, "timestep": 853, "ep_reward": 430.13140869140625, "reward": 0.5945685505867004, "action": -1.684116244316101}
{"mode": "train", "epochs": 1, "timestep": 854, "ep_reward": 430.75653076171875, "reward": 0.6251212358474731, "action": -0.34017622470855713}
{"mode": "train", "epochs": 1, "timestep": 855, "ep_reward": 431.40802001953125, "reward": 0.6515018939971924, "action": -1.2647470235824585}
{"mode": "train", "epochs": 1, "timestep": 856, "ep_reward": 432.07684326171875, "reward": 0.6688113212585449, "action": -0.26662200689315796}
{"mode": "train", "epochs": 1, "timestep": 857, "ep_reward": 432.75457763671875, "reward": 0.6777210235595703, "action": 0.09066230058670044}
{"mode": "train", "epochs": 1, "timestep": 858, "ep_reward": 433.4291076660156, "reward": 0.6745181083679199, "action": -1.3187276124954224}
{"mode": "train", "epochs": 1, "timestep": 859, "ep_reward": 434.0928039550781, "reward": 0.6636844873428345, "action": -1.4175450801849365}
{"mode": "train", "epochs": 1, "timestep": 860, "ep_reward": 434.7392578125, "reward": 0.6464463472366333, "action": -0.9953799843788147}
{"mode": "train", "epochs": 1, "timestep": 861, "ep_reward": 435.3603210449219, "reward": 0.621070921421051, "action": -0.6952547430992126}
{"mode": "train", "epochs": 1, "timestep": 862, "ep_reward": 435.94732666015625, "reward": 0.5869920253753662, "action": -1.2449415922164917}
{"mode": "train", "epochs": 1, "timestep": 863, "ep_reward": 436.496826171875, "reward": 0.5495114326477051, "action": -0.2947097420692444}
{"mode": "train", "epochs": 1, "timestep": 864, "ep_reward": 436.9986877441406, "reward": 0.5018476247787476, "action": -1.090872049331665}
{"mode": "train", "epochs": 1, "timestep": 865, "ep_reward": 437.4537048339844, "reward": 0.4550122618675232, "action": -0.7604491710662842}
{"mode": "train", "epochs": 1, "timestep": 866, "ep_reward": 437.8590087890625, "reward": 0.4053192138671875, "action": -0.4902014136314392}
{"mode": "train", "epochs": 1, "timestep": 867, "ep_reward": 438.21319580078125, "reward": 0.3541818857192993, "action": -0.8163913488388062}
{"mode": "train", "epochs": 1, "timestep": 868, "ep_reward": 438.5921630859375, "reward": 0.37897592782974243, "action": -0.8868656158447266}
{"mode": "train", "epochs": 1, "timestep": 869, "ep_reward": 439.0202331542969, "reward": 0.42806434631347656, "action": -1.6119924783706665}
{"mode": "train", "epochs": 1, "timestep": 870, "ep_reward": 439.4933776855469, "reward": 0.47313934564590454, "action": -0.2791503071784973}
{"mode": "train", "epochs": 1, "timestep": 871, "ep_reward": 440.0011901855469, "reward": 0.5078247785568237, "action": -0.3444235920906067}
{"mode": "train", "epochs": 1, "timestep": 872, "ep_reward": 440.5374755859375, "reward": 0.5362840890884399, "action": -1.105228304862976}
{"mode": "train", "epochs": 1, "timestep": 873, "ep_reward": 441.0941162109375, "reward": 0.5566440224647522, "action": -0.2395516037940979}
{"mode": "train", "epochs": 1, "timestep": 874, "ep_reward": 441.66094970703125, "reward": 0.5668221116065979, "action": -0.45356160402297974}
{"mode": "train", "epochs": 1, "timestep": 875, "ep_reward": 442.22882080078125, "reward": 0.5678824186325073, "action": -1.0150386095046997}
{"mode": "train", "epochs": 1, "timestep": 876, "ep_reward": 442.786376953125, "reward": 0.5575454235076904, "action": -0.8586075901985168}
{"mode": "train", "epochs": 1, "timestep": 877, "ep_reward": 443.32257080078125, "reward": 0.5362051725387573, "action": -0.5483543276786804}
{"mode": "train", "epochs": 1, "timestep": 878, "ep_reward": 443.8287658691406, "reward": 0.5061846375465393, "action": -0.7470186948776245}
{"mode": "train", "epochs": 1, "timestep": 879, "ep_reward": 444.2958679199219, "reward": 0.46709144115448, "action": -1.5298821926116943}
{"mode": "train", "epochs": 1, "timestep": 880, "ep_reward": 444.7117919921875, "reward": 0.4159136414527893, "action": -0.40919047594070435}
{"mode": "train", "epochs": 1, "timestep": 881, "ep_reward": 445.07659912109375, "reward": 0.36479347944259644, "action": -1.8327443599700928}
{"mode": "train", "epochs": 1, "timestep": 882, "ep_reward": 445.44842529296875, "reward": 0.37181639671325684, "action": -1.125158667564392}
{"mode": "train", "epochs": 1, "timestep": 883, "ep_reward": 445.86907958984375, "reward": 0.42065292596817017, "action": -1.5651605129241943}
{"mode": "train", "epochs": 1, "timestep": 884, "ep_reward": 446.33856201171875, "reward": 0.4694975018501282, "action": -1.234389066696167}
{"mode": "train", "epochs": 1, "timestep": 885, "ep_reward": 446.8581237792969, "reward": 0.5195704698562622, "action": -1.6648287773132324}
{"mode": "train", "epochs": 1, "timestep": 886, "ep_reward": 447.4245910644531, "reward": 0.5664743781089783, "action": -0.8322471976280212}
{"mode": "train", "epochs": 1, "timestep": 887, "ep_reward": 448.03692626953125, "reward": 0.6123442649841309, "action": -1.100559949874878}
{"mode": "train", "epochs": 1, "timestep": 888, "ep_reward": 448.687744140625, "reward": 0.6508127450942993, "action": -1.2906508445739746}
{"mode": "train", "epochs": 1, "timestep": 889, "ep_reward": 449.3695373535156, "reward": 0.6817847490310669, "action": -1.5019034147262573}
{"mode": "train", "epochs": 1, "timestep": 890, "ep_reward": 450.0748291015625, "reward": 0.7053037881851196, "action": -0.9490631818771362}
{"mode": "train", "epochs": 1, "timestep": 891, "ep_reward": 450.7959289550781, "reward": 0.7211049795150757, "action": -1.0322613716125488}
{"mode": "train", "epochs": 1, "timestep": 892, "ep_reward": 451.5233154296875, "reward": 0.7273958921432495, "action": -0.5552149415016174}
{"mode": "train", "epochs": 1, "timestep": 893, "ep_reward": 452.2461242675781, "reward": 0.7228177785873413, "action": -1.167622447013855}
{"mode": "train", "epochs": 1, "timestep": 894, "ep_reward": 452.95513916015625, "reward": 0.70902419090271, "action": -0.8481200933456421}
{"mode": "train", "epochs": 1, "timestep": 895, "ep_reward": 453.63995361328125, "reward": 0.6848241090774536, "action": -0.512858510017395}
{"mode": "train", "epochs": 1, "timestep": 896, "ep_reward": 454.2886962890625, "reward": 0.6487458944320679, "action": -1.52054762840271}
{"mode": "train", "epochs": 1, "timestep": 897, "ep_reward": 454.8974304199219, "reward": 0.6087215542793274, "action": -1.8713934421539307}
{"mode": "train", "epochs": 1, "timestep": 898, "ep_reward": 455.46331787109375, "reward": 0.5658942461013794, "action": -1.2707669734954834}
{"mode": "train", "epochs": 1, "timestep": 899, "ep_reward": 455.9792175292969, "reward": 0.515906572341919, "action": -1.0469871759414673}
{"mode": "train", "epochs": 1, "timestep": 900, "ep_reward": 456.4406433105469, "reward": 0.4614366292953491, "action": -0.923435628414154}
{"mode": "train", "epochs": 1, "timestep": 901, "ep_reward": 456.84539794921875, "reward": 0.4047393798828125, "action": -1.3373994827270508}
{"mode": "train", "epochs": 1, "timestep": 902, "ep_reward": 457.19793701171875, "reward": 0.35253798961639404, "action": -0.9965417981147766}
{"mode": "train", "epochs": 1, "timestep": 903, "ep_reward": 457.5658264160156, "reward": 0.367878794670105, "action": -0.8536452651023865}
{"mode": "train", "epochs": 1, "timestep": 904, "ep_reward": 457.9882507324219, "reward": 0.4224247932434082, "action": -0.8141393065452576}
{"mode": "train", "epochs": 1, "timestep": 905, "ep_reward": 458.4603576660156, "reward": 0.47209763526916504, "action": -1.1125377416610718}
{"mode": "train", "epochs": 1, "timestep": 906, "ep_reward": 458.9757080078125, "reward": 0.5153427124023438, "action": -1.3316221237182617}
{"mode": "train", "epochs": 1, "timestep": 907, "ep_reward": 459.52459716796875, "reward": 0.5489001274108887, "action": -0.8279577493667603}
{"mode": "train", "epochs": 1, "timestep": 908, "ep_reward": 460.09515380859375, "reward": 0.570553719997406, "action": -0.3238369822502136}
{"mode": "train", "epochs": 1, "timestep": 909, "ep_reward": 460.6769714355469, "reward": 0.5818129777908325, "action": -1.0206762552261353}
{"mode": "train", "epochs": 1, "timestep": 910, "ep_reward": 461.2588806152344, "reward": 0.5819032788276672, "action": -0.24021941423416138}
{"mode": "train", "epochs": 1, "timestep": 911, "ep_reward": 461.830810546875, "reward": 0.571940541267395, "action": -0.7898245453834534}
{"mode": "train", "epochs": 1, "timestep": 912, "ep_reward": 462.3813781738281, "reward": 0.5505707263946533, "action": -0.6722391247749329}
{"mode": "train", "epochs": 1, "timestep": 913, "ep_reward": 462.90045166015625, "reward": 0.5190685987472534, "action": -1.0962672233581543}
{"mode": "train", "epochs": 1, "timestep": 914, "ep_reward": 463.3764953613281, "reward": 0.47605758905410767, "action": -0.43543165922164917}
{"mode": "train", "epochs": 1, "timestep": 915, "ep_reward": 463.80499267578125, "reward": 0.42850780487060547, "action": -0.9638399481773376}
{"mode": "train", "epochs": 1, "timestep": 916, "ep_reward": 464.1778564453125, "reward": 0.3728504180908203, "action": -0.5194877982139587}
{"mode": "train", "epochs": 1, "timestep": 917, "ep_reward": 464.5396728515625, "reward": 0.3618287444114685, "action": -1.2816470861434937}
{"mode": "train", "epochs": 1, "timestep": 918, "ep_reward": 464.9488525390625, "reward": 0.40916740894317627, "action": -1.9549278020858765}
{"mode": "train", "epochs": 1, "timestep": 919, "ep_reward": 465.40557861328125, "reward": 0.4567330479621887, "action": -1.290634274482727}
{"mode": "train", "epochs": 1, "timestep": 920, "ep_reward": 465.91357421875, "reward": 0.5079824924468994, "action": -0.2125636339187622}
{"mode": "train", "epochs": 1, "timestep": 921, "ep_reward": 466.4737548828125, "reward": 0.5601694583892822, "action": -0.9145129323005676}
{"mode": "train", "epochs": 1, "timestep": 922, "ep_reward": 467.0777282714844, "reward": 0.6039878129959106, "action": -0.8106803297996521}
{"mode": "train", "epochs": 1, "timestep": 923, "ep_reward": 467.7193298339844, "reward": 0.641606330871582, "action": -0.9770277738571167}
{"mode": "train", "epochs": 1, "timestep": 924, "ep_reward": 468.3905029296875, "reward": 0.6711845397949219, "action": -1.081687331199646}
{"mode": "train", "epochs": 1, "timestep": 925, "ep_reward": 469.0830383300781, "reward": 0.6925309896469116, "action": -1.2709159851074219}
{"mode": "train", "epochs": 1, "timestep": 926, "ep_reward": 469.7887268066406, "reward": 0.7056773900985718, "action": -1.0579822063446045}
{"mode": "train", "epochs": 1, "timestep": 927, "ep_reward": 470.4991760253906, "reward": 0.7104355096817017, "action": -0.0790756344795227}
{"mode": "train", "epochs": 1, "timestep": 928, "ep_reward": 471.2025451660156, "reward": 0.7033820152282715, "action": -0.8653931021690369}
{"mode": "train", "epochs": 1, "timestep": 929, "ep_reward": 471.8888244628906, "reward": 0.6862711310386658, "action": -1.8170862197875977}
{"mode": "train", "epochs": 1, "timestep": 930, "ep_reward": 472.5531311035156, "reward": 0.6642960906028748, "action": -1.2203665971755981}
{"mode": "train", "epochs": 1, "timestep": 931, "ep_reward": 473.1866760253906, "reward": 0.6335554122924805, "action": -1.050980567932129}
{"mode": "train", "epochs": 1, "timestep": 932, "ep_reward": 473.78155517578125, "reward": 0.5948746204376221, "action": -1.028775691986084}
{"mode": "train", "epochs": 1, "timestep": 933, "ep_reward": 474.331298828125, "reward": 0.5497563481330872, "action": -0.746380090713501}
{"mode": "train", "epochs": 1, "timestep": 934, "ep_reward": 474.8291015625, "reward": 0.49780845642089844, "action": -0.10232114791870117}
{"mode": "train", "epochs": 1, "timestep": 935, "ep_reward": 475.2659606933594, "reward": 0.4368727207183838, "action": -1.422806739807129}
{"mode": "train", "epochs": 1, "timestep": 936, "ep_reward": 475.64984130859375, "reward": 0.3838943839073181, "action": -0.9848737120628357}
{"mode": "train", "epochs": 1, "timestep": 937, "ep_reward": 475.9832458496094, "reward": 0.33341389894485474, "action": -1.2774100303649902}
{"mode": "train", "epochs": 1, "timestep": 938, "ep_reward": 476.3743591308594, "reward": 0.3911280632019043, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 939, "ep_reward": 476.8196716308594, "reward": 0.44531506299972534, "action": -1.4929585456848145}
{"mode": "train", "epochs": 1, "timestep": 940, "ep_reward": 477.3085632324219, "reward": 0.4888906478881836, "action": -0.8458459973335266}
{"mode": "train", "epochs": 1, "timestep": 941, "ep_reward": 477.8307800292969, "reward": 0.5222107768058777, "action": -0.859351634979248}
{"mode": "train", "epochs": 1, "timestep": 942, "ep_reward": 478.37738037109375, "reward": 0.5465975403785706, "action": -0.6630520820617676}
{"mode": "train", "epochs": 1, "timestep": 943, "ep_reward": 478.9385070800781, "reward": 0.5611253976821899, "action": -0.6995300054550171}
{"mode": "train", "epochs": 1, "timestep": 944, "ep_reward": 479.50408935546875, "reward": 0.5655807256698608, "action": -0.7737898230552673}
{"mode": "train", "epochs": 1, "timestep": 945, "ep_reward": 480.0633850097656, "reward": 0.559284508228302, "action": -1.4176063537597656}
{"mode": "train", "epochs": 1, "timestep": 946, "ep_reward": 480.6031494140625, "reward": 0.5397647619247437, "action": -1.474871039390564}
{"mode": "train", "epochs": 1, "timestep": 947, "ep_reward": 481.1103210449219, "reward": 0.5071747899055481, "action": -0.45562779903411865}
{"mode": "train", "epochs": 1, "timestep": 948, "ep_reward": 481.5790100097656, "reward": 0.4687013626098633, "action": -1.5692644119262695}
{"mode": "train", "epochs": 1, "timestep": 949, "ep_reward": 481.9959411621094, "reward": 0.4169454574584961, "action": -1.2373398542404175}
{"mode": "train", "epochs": 1, "timestep": 950, "ep_reward": 482.3553771972656, "reward": 0.3594321608543396, "action": -0.5649423003196716}
{"mode": "train", "epochs": 1, "timestep": 951, "ep_reward": 482.7290954589844, "reward": 0.37372565269470215, "action": -0.792413055896759}
{"mode": "train", "epochs": 1, "timestep": 952, "ep_reward": 483.15167236328125, "reward": 0.4225618243217468, "action": -0.9687820076942444}
{"mode": "train", "epochs": 1, "timestep": 953, "ep_reward": 483.6228942871094, "reward": 0.47122740745544434, "action": -0.8442459106445312}
{"mode": "train", "epochs": 1, "timestep": 954, "ep_reward": 484.1419982910156, "reward": 0.519099235534668, "action": -0.7245445847511292}
{"mode": "train", "epochs": 1, "timestep": 955, "ep_reward": 484.7059631347656, "reward": 0.5639510154724121, "action": -0.6809121370315552}
{"mode": "train", "epochs": 1, "timestep": 956, "ep_reward": 485.30950927734375, "reward": 0.6035490036010742, "action": 0.17614030838012695}
{"mode": "train", "epochs": 1, "timestep": 957, "ep_reward": 485.9462585449219, "reward": 0.6367455720901489, "action": -0.21216845512390137}
{"mode": "train", "epochs": 1, "timestep": 958, "ep_reward": 486.6048278808594, "reward": 0.6585545539855957, "action": -1.4240827560424805}
{"mode": "train", "epochs": 1, "timestep": 959, "ep_reward": 487.2760925292969, "reward": 0.6712762713432312, "action": -1.176798939704895}
{"mode": "train", "epochs": 1, "timestep": 960, "ep_reward": 487.95306396484375, "reward": 0.6769706010818481, "action": -1.7171695232391357}
{"mode": "train", "epochs": 1, "timestep": 961, "ep_reward": 488.6296691894531, "reward": 0.6766198873519897, "action": -0.5579925775527954}
{"mode": "train", "epochs": 1, "timestep": 962, "ep_reward": 489.2965393066406, "reward": 0.6668824553489685, "action": -0.3233027458190918}
{"mode": "train", "epochs": 1, "timestep": 963, "ep_reward": 489.9427795410156, "reward": 0.646247923374176, "action": -1.0654702186584473}
{"mode": "train", "epochs": 1, "timestep": 964, "ep_reward": 490.56182861328125, "reward": 0.6190392971038818, "action": -1.2950963973999023}
{"mode": "train", "epochs": 1, "timestep": 965, "ep_reward": 491.1483459472656, "reward": 0.586513876914978, "action": -1.0000861883163452}
{"mode": "train", "epochs": 1, "timestep": 966, "ep_reward": 491.6957092285156, "reward": 0.5473743677139282, "action": -0.5467911958694458}
{"mode": "train", "epochs": 1, "timestep": 967, "ep_reward": 492.1963806152344, "reward": 0.500684916973114, "action": -0.708196759223938}
{"mode": "train", "epochs": 1, "timestep": 968, "ep_reward": 492.64727783203125, "reward": 0.4508870244026184, "action": -1.7099602222442627}
{"mode": "train", "epochs": 1, "timestep": 969, "ep_reward": 493.0547790527344, "reward": 0.407509446144104, "action": -0.5266169309616089}
{"mode": "train", "epochs": 1, "timestep": 970, "ep_reward": 493.413330078125, "reward": 0.3585358262062073, "action": 0.23143607378005981}
{"mode": "train", "epochs": 1, "timestep": 971, "ep_reward": 493.790283203125, "reward": 0.3769558072090149, "action": -1.1551308631896973}
{"mode": "train", "epochs": 1, "timestep": 972, "ep_reward": 494.21820068359375, "reward": 0.4279038906097412, "action": -1.1575653553009033}
{"mode": "train", "epochs": 1, "timestep": 973, "ep_reward": 494.69110107421875, "reward": 0.4729135036468506, "action": -0.5757378339767456}
{"mode": "train", "epochs": 1, "timestep": 974, "ep_reward": 495.2006530761719, "reward": 0.509557843208313, "action": -0.8770542740821838}
{"mode": "train", "epochs": 1, "timestep": 975, "ep_reward": 495.739501953125, "reward": 0.5388640761375427, "action": -0.760105311870575}
{"mode": "train", "epochs": 1, "timestep": 976, "ep_reward": 496.2979736328125, "reward": 0.5584568977355957, "action": -0.5044680833816528}
{"mode": "train", "epochs": 1, "timestep": 977, "ep_reward": 496.86614990234375, "reward": 0.5681754946708679, "action": -1.0388078689575195}
{"mode": "train", "epochs": 1, "timestep": 978, "ep_reward": 497.4330139160156, "reward": 0.5668521523475647, "action": -0.97086501121521}
{"mode": "train", "epochs": 1, "timestep": 979, "ep_reward": 497.98675537109375, "reward": 0.5537371635437012, "action": -0.5727618336677551}
{"mode": "train", "epochs": 1, "timestep": 980, "ep_reward": 498.5177001953125, "reward": 0.5309462547302246, "action": -1.2897733449935913}
{"mode": "train", "epochs": 1, "timestep": 981, "ep_reward": 499.0132141113281, "reward": 0.4955140948295593, "action": -0.8704919815063477}
{"mode": "train", "epochs": 1, "timestep": 982, "ep_reward": 499.4653625488281, "reward": 0.45215243101119995, "action": -0.8266017436981201}
{"mode": "train", "epochs": 1, "timestep": 983, "ep_reward": 499.8675537109375, "reward": 0.4021897315979004, "action": -0.9000879526138306}
{"mode": "train", "epochs": 1, "timestep": 984, "ep_reward": 500.2147521972656, "reward": 0.3472002148628235, "action": -0.41158825159072876}
{"mode": "train", "epochs": 1, "timestep": 985, "ep_reward": 500.60296630859375, "reward": 0.3882090449333191, "action": 0.15475386381149292}
{"mode": "train", "epochs": 1, "timestep": 986, "ep_reward": 501.0401916503906, "reward": 0.43721288442611694, "action": -0.442321240901947}
{"mode": "train", "epochs": 1, "timestep": 987, "ep_reward": 501.52239990234375, "reward": 0.48221319913864136, "action": -0.6249481439590454}
{"mode": "train", "epochs": 1, "timestep": 988, "ep_reward": 502.04644775390625, "reward": 0.5240494012832642, "action": -0.6671690940856934}
{"mode": "train", "epochs": 1, "timestep": 989, "ep_reward": 502.60821533203125, "reward": 0.5617712140083313, "action": -1.52907395362854}
{"mode": "train", "epochs": 1, "timestep": 990, "ep_reward": 503.20196533203125, "reward": 0.5937645435333252, "action": -0.08473718166351318}
{"mode": "train", "epochs": 1, "timestep": 991, "ep_reward": 503.824462890625, "reward": 0.6225050687789917, "action": -0.20107519626617432}
{"mode": "train", "epochs": 1, "timestep": 992, "ep_reward": 504.4659118652344, "reward": 0.6414607763290405, "action": -1.5256588459014893}
{"mode": "train", "epochs": 1, "timestep": 993, "ep_reward": 505.1181945800781, "reward": 0.6522954106330872, "action": -1.8419086933135986}
{"mode": "train", "epochs": 1, "timestep": 994, "ep_reward": 505.77655029296875, "reward": 0.6583576202392578, "action": -0.9148269295692444}
{"mode": "train", "epochs": 1, "timestep": 995, "ep_reward": 506.4340515136719, "reward": 0.6574982404708862, "action": -0.7717586755752563}
{"mode": "train", "epochs": 1, "timestep": 996, "ep_reward": 507.08221435546875, "reward": 0.648174524307251, "action": -1.2608522176742554}
{"mode": "train", "epochs": 1, "timestep": 997, "ep_reward": 507.71484375, "reward": 0.6326324939727783, "action": -0.20705056190490723}
{"mode": "train", "epochs": 1, "timestep": 998, "ep_reward": 508.3207702636719, "reward": 0.6059415340423584, "action": -0.9578092098236084}
{"mode": "train", "epochs": 1, "timestep": 999, "ep_reward": 508.89495849609375, "reward": 0.574191689491272, "action": -0.0539669394493103}
{"mode": "train", "epochs": 1, "timestep": 1000, "ep_reward": 509.4263000488281, "reward": 0.5313494801521301, "action": -0.9114155173301697}
{"mode": "train", "epochs": 1, "timestep": 1001, "ep_reward": 509.91363525390625, "reward": 0.48734521865844727, "action": -0.08269256353378296}
{"mode": "train", "epochs": 1, "timestep": 1002, "ep_reward": 510.3485107421875, "reward": 0.43486499786376953, "action": -1.537517786026001}
{"mode": "train", "epochs": 1, "timestep": 1003, "ep_reward": 510.7393798828125, "reward": 0.39088350534439087, "action": -0.8337101936340332}
{"mode": "train", "epochs": 1, "timestep": 1004, "ep_reward": 511.08660888671875, "reward": 0.34722405672073364, "action": -0.046260952949523926}
{"mode": "train", "epochs": 1, "timestep": 1005, "ep_reward": 511.48046875, "reward": 0.39385509490966797, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1006, "ep_reward": 511.9231262207031, "reward": 0.44265955686569214, "action": -0.5047683715820312}
{"mode": "train", "epochs": 1, "timestep": 1007, "ep_reward": 512.4036254882812, "reward": 0.4805229902267456, "action": -0.6197202205657959}
{"mode": "train", "epochs": 1, "timestep": 1008, "ep_reward": 512.9161376953125, "reward": 0.5125174522399902, "action": -1.4010449647903442}
{"mode": "train", "epochs": 1, "timestep": 1009, "ep_reward": 513.45263671875, "reward": 0.5365049242973328, "action": -1.5440294742584229}
{"mode": "train", "epochs": 1, "timestep": 1010, "ep_reward": 514.0010986328125, "reward": 0.5484572649002075, "action": -0.6033343076705933}
{"mode": "train", "epochs": 1, "timestep": 1011, "ep_reward": 514.5505981445312, "reward": 0.549527108669281, "action": -0.6181230545043945}
{"mode": "train", "epochs": 1, "timestep": 1012, "ep_reward": 515.091796875, "reward": 0.5411839485168457, "action": -1.0534971952438354}
{"mode": "train", "epochs": 1, "timestep": 1013, "ep_reward": 515.61376953125, "reward": 0.5219663381576538, "action": -0.37580400705337524}
{"mode": "train", "epochs": 1, "timestep": 1014, "ep_reward": 516.1094970703125, "reward": 0.4957466721534729, "action": -0.9413374662399292}
{"mode": "train", "epochs": 1, "timestep": 1015, "ep_reward": 516.5694580078125, "reward": 0.4599440097808838, "action": 0.26011598110198975}
{"mode": "train", "epochs": 1, "timestep": 1016, "ep_reward": 516.9938354492188, "reward": 0.4243757128715515, "action": 0.04973381757736206}
{"mode": "train", "epochs": 1, "timestep": 1017, "ep_reward": 517.3800048828125, "reward": 0.3861890435218811, "action": -0.7063801288604736}
{"mode": "train", "epochs": 1, "timestep": 1018, "ep_reward": 517.7516479492188, "reward": 0.37166517972946167, "action": -0.6172600984573364}
{"mode": "train", "epochs": 1, "timestep": 1019, "ep_reward": 518.1617431640625, "reward": 0.41007810831069946, "action": 0.09879571199417114}
{"mode": "train", "epochs": 1, "timestep": 1020, "ep_reward": 518.6113891601562, "reward": 0.449649453163147, "action": -0.41290831565856934}
{"mode": "train", "epochs": 1, "timestep": 1021, "ep_reward": 519.0970458984375, "reward": 0.4856511950492859, "action": -0.8053151369094849}
{"mode": "train", "epochs": 1, "timestep": 1022, "ep_reward": 519.6155395507812, "reward": 0.5185185074806213, "action": -0.06892532110214233}
{"mode": "train", "epochs": 1, "timestep": 1023, "ep_reward": 520.1640625, "reward": 0.5485184192657471, "action": -1.0062510967254639}
{"mode": "train", "epochs": 1, "timestep": 1024, "ep_reward": 520.7362060546875, "reward": 0.5721270442008972, "action": -1.3217113018035889}
{"mode": "train", "epochs": 1, "timestep": 1025, "ep_reward": 521.3277587890625, "reward": 0.5915828943252563, "action": -1.2893362045288086}
{"mode": "train", "epochs": 1, "timestep": 1026, "ep_reward": 521.9347534179688, "reward": 0.6070196628570557, "action": -0.7662147879600525}
{"mode": "train", "epochs": 1, "timestep": 1027, "ep_reward": 522.5517578125, "reward": 0.616991400718689, "action": -0.6138203144073486}
{"mode": "train", "epochs": 1, "timestep": 1028, "ep_reward": 523.1715087890625, "reward": 0.619760274887085, "action": -0.7075177431106567}
{"mode": "train", "epochs": 1, "timestep": 1029, "ep_reward": 523.7866821289062, "reward": 0.6151987314224243, "action": -0.9426100850105286}
{"mode": "train", "epochs": 1, "timestep": 1030, "ep_reward": 524.3910522460938, "reward": 0.6043415665626526, "action": -0.8129321336746216}
{"mode": "train", "epochs": 1, "timestep": 1031, "ep_reward": 524.9779052734375, "reward": 0.5868508815765381, "action": -1.4887139797210693}
{"mode": "train", "epochs": 1, "timestep": 1032, "ep_reward": 525.544677734375, "reward": 0.5667511224746704, "action": -0.9058911800384521}
{"mode": "train", "epochs": 1, "timestep": 1033, "ep_reward": 526.0855102539062, "reward": 0.540810227394104, "action": -0.5264599919319153}
{"mode": "train", "epochs": 1, "timestep": 1034, "ep_reward": 526.5943603515625, "reward": 0.5088387131690979, "action": -0.6723315715789795}
{"mode": "train", "epochs": 1, "timestep": 1035, "ep_reward": 527.0679931640625, "reward": 0.47364115715026855, "action": -1.671008586883545}
{"mode": "train", "epochs": 1, "timestep": 1036, "ep_reward": 527.5108642578125, "reward": 0.442842960357666, "action": -0.937427818775177}
{"mode": "train", "epochs": 1, "timestep": 1037, "ep_reward": 527.9204711914062, "reward": 0.40963631868362427, "action": -1.2234312295913696}
{"mode": "train", "epochs": 1, "timestep": 1038, "ep_reward": 528.2999877929688, "reward": 0.37950563430786133, "action": -1.960895299911499}
{"mode": "train", "epochs": 1, "timestep": 1039, "ep_reward": 528.6839599609375, "reward": 0.38398683071136475, "action": -1.796353816986084}
{"mode": "train", "epochs": 1, "timestep": 1040, "ep_reward": 529.0941162109375, "reward": 0.41016948223114014, "action": -0.17991036176681519}
{"mode": "train", "epochs": 1, "timestep": 1041, "ep_reward": 529.5247192382812, "reward": 0.4305729269981384, "action": -0.8670984506607056}
{"mode": "train", "epochs": 1, "timestep": 1042, "ep_reward": 529.9724731445312, "reward": 0.44773173332214355, "action": -0.9682221412658691}
{"mode": "train", "epochs": 1, "timestep": 1043, "ep_reward": 530.431640625, "reward": 0.45917707681655884, "action": -1.1331735849380493}
{"mode": "train", "epochs": 1, "timestep": 1044, "ep_reward": 530.8954467773438, "reward": 0.463805615901947, "action": -1.2230827808380127}
{"mode": "train", "epochs": 1, "timestep": 1045, "ep_reward": 531.3561401367188, "reward": 0.46068090200424194, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1046, "ep_reward": 531.803466796875, "reward": 0.44731366634368896, "action": -0.7487102746963501}
{"mode": "train", "epochs": 1, "timestep": 1047, "ep_reward": 532.2324829101562, "reward": 0.4290313720703125, "action": -0.7737457156181335}
{"mode": "train", "epochs": 1, "timestep": 1048, "ep_reward": 532.6385498046875, "reward": 0.40608692169189453, "action": -0.5800221562385559}
{"mode": "train", "epochs": 1, "timestep": 1049, "ep_reward": 533.0189819335938, "reward": 0.3804086446762085, "action": -0.9178430438041687}
{"mode": "train", "epochs": 1, "timestep": 1050, "ep_reward": 533.4104614257812, "reward": 0.39146530628204346, "action": -1.0924574136734009}
{"mode": "train", "epochs": 1, "timestep": 1051, "ep_reward": 533.8281860351562, "reward": 0.4177399277687073, "action": -1.0169813632965088}
{"mode": "train", "epochs": 1, "timestep": 1052, "ep_reward": 534.2737426757812, "reward": 0.44555985927581787, "action": -0.45316052436828613}
{"mode": "train", "epochs": 1, "timestep": 1053, "ep_reward": 534.7474975585938, "reward": 0.4737585186958313, "action": -0.5329962968826294}
{"mode": "train", "epochs": 1, "timestep": 1054, "ep_reward": 535.2472534179688, "reward": 0.49973446130752563, "action": -0.14134180545806885}
{"mode": "train", "epochs": 1, "timestep": 1055, "ep_reward": 535.769775390625, "reward": 0.5225192308425903, "action": 0.02688044309616089}
{"mode": "train", "epochs": 1, "timestep": 1056, "ep_reward": 536.3096313476562, "reward": 0.5398370027542114, "action": -1.2670769691467285}
{"mode": "train", "epochs": 1, "timestep": 1057, "ep_reward": 536.8621826171875, "reward": 0.5525546073913574, "action": -1.1684329509735107}
{"mode": "train", "epochs": 1, "timestep": 1058, "ep_reward": 537.4246215820312, "reward": 0.5624290108680725, "action": -0.8545516133308411}
{"mode": "train", "epochs": 1, "timestep": 1059, "ep_reward": 537.9929809570312, "reward": 0.5683292150497437, "action": 0.11594480276107788}
{"mode": "train", "epochs": 1, "timestep": 1060, "ep_reward": 538.56005859375, "reward": 0.5670986175537109, "action": 0.21153759956359863}
{"mode": "train", "epochs": 1, "timestep": 1061, "ep_reward": 539.1173706054688, "reward": 0.5572940111160278, "action": -0.9441465735435486}
{"mode": "train", "epochs": 1, "timestep": 1062, "ep_reward": 539.6611328125, "reward": 0.5437713861465454, "action": -1.7010265588760376}
{"mode": "train", "epochs": 1, "timestep": 1063, "ep_reward": 540.1911010742188, "reward": 0.5299886465072632, "action": -1.3481898307800293}
{"mode": "train", "epochs": 1, "timestep": 1064, "ep_reward": 540.7050170898438, "reward": 0.5139443278312683, "action": -1.1803683042526245}
{"mode": "train", "epochs": 1, "timestep": 1065, "ep_reward": 541.2009887695312, "reward": 0.49598050117492676, "action": -1.008148431777954}
{"mode": "train", "epochs": 1, "timestep": 1066, "ep_reward": 541.6771850585938, "reward": 0.4761960506439209, "action": -1.0556221008300781}
{"mode": "train", "epochs": 1, "timestep": 1067, "ep_reward": 542.1329956054688, "reward": 0.4558369517326355, "action": -1.4501230716705322}
{"mode": "train", "epochs": 1, "timestep": 1068, "ep_reward": 542.5707397460938, "reward": 0.4377208352088928, "action": -0.4933650493621826}
{"mode": "train", "epochs": 1, "timestep": 1069, "ep_reward": 542.9876098632812, "reward": 0.4168747067451477, "action": -0.8067158460617065}
{"mode": "train", "epochs": 1, "timestep": 1070, "ep_reward": 543.3851928710938, "reward": 0.3975819945335388, "action": -1.2523748874664307}
{"mode": "train", "epochs": 1, "timestep": 1071, "ep_reward": 543.767333984375, "reward": 0.38215547800064087, "action": -0.9254060387611389}
{"mode": "train", "epochs": 1, "timestep": 1072, "ep_reward": 544.1575317382812, "reward": 0.39022618532180786, "action": -1.6124351024627686}
{"mode": "train", "epochs": 1, "timestep": 1073, "ep_reward": 544.5593872070312, "reward": 0.401832640171051, "action": -1.627808928489685}
{"mode": "train", "epochs": 1, "timestep": 1074, "ep_reward": 544.9666137695312, "reward": 0.40725278854370117, "action": -0.7348656058311462}
{"mode": "train", "epochs": 1, "timestep": 1075, "ep_reward": 545.375, "reward": 0.40839070081710815, "action": -1.6148244142532349}
{"mode": "train", "epochs": 1, "timestep": 1076, "ep_reward": 545.778564453125, "reward": 0.4035871624946594, "action": -0.6668230891227722}
{"mode": "train", "epochs": 1, "timestep": 1077, "ep_reward": 546.17431640625, "reward": 0.3957294821739197, "action": -0.3869118094444275}
{"mode": "train", "epochs": 1, "timestep": 1078, "ep_reward": 546.560546875, "reward": 0.3862230181694031, "action": -0.9234755635261536}
{"mode": "train", "epochs": 1, "timestep": 1079, "ep_reward": 546.9487915039062, "reward": 0.38825756311416626, "action": -0.8593652844429016}
{"mode": "train", "epochs": 1, "timestep": 1080, "ep_reward": 547.3501586914062, "reward": 0.40137362480163574, "action": -0.7036743760108948}
{"mode": "train", "epochs": 1, "timestep": 1081, "ep_reward": 547.7660522460938, "reward": 0.41591018438339233, "action": -0.15571051836013794}
{"mode": "train", "epochs": 1, "timestep": 1082, "ep_reward": 548.1964111328125, "reward": 0.43036162853240967, "action": -0.6790026426315308}
{"mode": "train", "epochs": 1, "timestep": 1083, "ep_reward": 548.640625, "reward": 0.44420140981674194, "action": -1.070685625076294}
{"mode": "train", "epochs": 1, "timestep": 1084, "ep_reward": 549.098876953125, "reward": 0.458266019821167, "action": -0.9047071933746338}
{"mode": "train", "epochs": 1, "timestep": 1085, "ep_reward": 549.5712280273438, "reward": 0.4723343849182129, "action": 0.21810704469680786}
{"mode": "train", "epochs": 1, "timestep": 1086, "ep_reward": 550.0550537109375, "reward": 0.48379814624786377, "action": -1.2452569007873535}
{"mode": "train", "epochs": 1, "timestep": 1087, "ep_reward": 550.5484619140625, "reward": 0.49339473247528076, "action": -0.7935996055603027}
{"mode": "train", "epochs": 1, "timestep": 1088, "ep_reward": 551.050048828125, "reward": 0.5015785694122314, "action": -0.44149503111839294}
{"mode": "train", "epochs": 1, "timestep": 1089, "ep_reward": 551.5568237304688, "reward": 0.5067769289016724, "action": -0.8456552624702454}
{"mode": "train", "epochs": 1, "timestep": 1090, "ep_reward": 552.0662841796875, "reward": 0.5094841718673706, "action": -0.7586442232131958}
{"mode": "train", "epochs": 1, "timestep": 1091, "ep_reward": 552.5757446289062, "reward": 0.5094881057739258, "action": -1.5992240905761719}
{"mode": "train", "epochs": 1, "timestep": 1092, "ep_reward": 553.0851440429688, "reward": 0.5093755722045898, "action": -1.2348530292510986}
{"mode": "train", "epochs": 1, "timestep": 1093, "ep_reward": 553.59326171875, "reward": 0.5080913305282593, "action": -0.6984906792640686}
{"mode": "train", "epochs": 1, "timestep": 1094, "ep_reward": 554.0972290039062, "reward": 0.5039617419242859, "action": -1.083962082862854}
{"mode": "train", "epochs": 1, "timestep": 1095, "ep_reward": 554.5957641601562, "reward": 0.49854475259780884, "action": -0.7765285968780518}
{"mode": "train", "epochs": 1, "timestep": 1096, "ep_reward": 555.0863647460938, "reward": 0.49062275886535645, "action": -1.8893921375274658}
{"mode": "train", "epochs": 1, "timestep": 1097, "ep_reward": 555.5714721679688, "reward": 0.4850807189941406, "action": -0.6435301899909973}
{"mode": "train", "epochs": 1, "timestep": 1098, "ep_reward": 556.0478515625, "reward": 0.4763644337654114, "action": -1.8534393310546875}
{"mode": "train", "epochs": 1, "timestep": 1099, "ep_reward": 556.5184326171875, "reward": 0.4705809950828552, "action": -0.9193502068519592}
{"mode": "train", "epochs": 1, "timestep": 1100, "ep_reward": 556.981689453125, "reward": 0.4632517099380493, "action": -1.40977942943573}
{"mode": "train", "epochs": 1, "timestep": 1101, "ep_reward": 557.4389038085938, "reward": 0.4571956992149353, "action": -1.9513156414031982}
{"mode": "train", "epochs": 1, "timestep": 1102, "ep_reward": 557.8931884765625, "reward": 0.4543112516403198, "action": -1.156858205795288}
{"mode": "train", "epochs": 1, "timestep": 1103, "ep_reward": 558.3446655273438, "reward": 0.4515041708946228, "action": -0.9461005926132202}
{"mode": "train", "epochs": 1, "timestep": 1104, "ep_reward": 558.7932739257812, "reward": 0.4486297369003296, "action": -1.6745383739471436}
{"mode": "train", "epochs": 1, "timestep": 1105, "ep_reward": 559.24169921875, "reward": 0.44843047857284546, "action": -0.42714083194732666}
{"mode": "train", "epochs": 1, "timestep": 1106, "ep_reward": 559.6884155273438, "reward": 0.4467097520828247, "action": -0.3360646963119507}
{"mode": "train", "epochs": 1, "timestep": 1107, "ep_reward": 560.1318969726562, "reward": 0.44346290826797485, "action": -1.1281894445419312}
{"mode": "train", "epochs": 1, "timestep": 1108, "ep_reward": 560.5733642578125, "reward": 0.4414892792701721, "action": -0.7038523554801941}
{"mode": "train", "epochs": 1, "timestep": 1109, "ep_reward": 561.0125732421875, "reward": 0.43922948837280273, "action": 0.32753705978393555}
{"mode": "train", "epochs": 1, "timestep": 1110, "ep_reward": 561.4461059570312, "reward": 0.4335561990737915, "action": -0.6548481583595276}
{"mode": "train", "epochs": 1, "timestep": 1111, "ep_reward": 561.8743286132812, "reward": 0.4282172918319702, "action": -1.0380253791809082}
{"mode": "train", "epochs": 1, "timestep": 1112, "ep_reward": 562.2987060546875, "reward": 0.4243999719619751, "action": -0.8477131724357605}
{"mode": "train", "epochs": 1, "timestep": 1113, "ep_reward": 562.7200927734375, "reward": 0.421370267868042, "action": -0.37419575452804565}
{"mode": "train", "epochs": 1, "timestep": 1114, "ep_reward": 563.1377563476562, "reward": 0.4176809787750244, "action": -1.407711386680603}
{"mode": "train", "epochs": 1, "timestep": 1115, "ep_reward": 563.554931640625, "reward": 0.4171612858772278, "action": -0.8809000253677368}
{"mode": "train", "epochs": 1, "timestep": 1116, "ep_reward": 563.9725952148438, "reward": 0.4176812767982483, "action": 0.010486960411071777}
{"mode": "train", "epochs": 1, "timestep": 1117, "ep_reward": 564.3892822265625, "reward": 0.416698157787323, "action": -1.4630550146102905}
{"mode": "train", "epochs": 1, "timestep": 1118, "ep_reward": 564.8079833984375, "reward": 0.41872668266296387, "action": -1.5175974369049072}
{"mode": "train", "epochs": 1, "timestep": 1119, "ep_reward": 565.2315063476562, "reward": 0.4235486388206482, "action": -0.9292722344398499}
{"mode": "train", "epochs": 1, "timestep": 1120, "ep_reward": 565.6610107421875, "reward": 0.42952388525009155, "action": -1.0811102390289307}
{"mode": "train", "epochs": 1, "timestep": 1121, "ep_reward": 566.0977172851562, "reward": 0.4366796016693115, "action": -1.2989451885223389}
{"mode": "train", "epochs": 1, "timestep": 1122, "ep_reward": 566.5430908203125, "reward": 0.4453992247581482, "action": -0.09593474864959717}
{"mode": "train", "epochs": 1, "timestep": 1123, "ep_reward": 566.9960327148438, "reward": 0.4529648423194885, "action": -0.6854134202003479}
{"mode": "train", "epochs": 1, "timestep": 1124, "ep_reward": 567.455322265625, "reward": 0.45928114652633667, "action": -1.6676009893417358}
{"mode": "train", "epochs": 1, "timestep": 1125, "ep_reward": 567.92236328125, "reward": 0.4670392870903015, "action": -0.24400758743286133}
{"mode": "train", "epochs": 1, "timestep": 1126, "ep_reward": 568.3955688476562, "reward": 0.47323542833328247, "action": -1.0462677478790283}
{"mode": "train", "epochs": 1, "timestep": 1127, "ep_reward": 568.8740234375, "reward": 0.47846853733062744, "action": -1.5211081504821777}
{"mode": "train", "epochs": 1, "timestep": 1128, "ep_reward": 569.3583984375, "reward": 0.4843452572822571, "action": -0.5919442176818848}
{"mode": "train", "epochs": 1, "timestep": 1129, "ep_reward": 569.8469848632812, "reward": 0.48856520652770996, "action": -0.9226781129837036}
{"mode": "train", "epochs": 1, "timestep": 1130, "ep_reward": 570.3383178710938, "reward": 0.49131762981414795, "action": -1.0041407346725464}
{"mode": "train", "epochs": 1, "timestep": 1131, "ep_reward": 570.8310546875, "reward": 0.49273622035980225, "action": -1.8110771179199219}
{"mode": "train", "epochs": 1, "timestep": 1132, "ep_reward": 571.3262939453125, "reward": 0.4952270984649658, "action": -1.1279891729354858}
{"mode": "train", "epochs": 1, "timestep": 1133, "ep_reward": 571.8231201171875, "reward": 0.49684619903564453, "action": -0.7570856213569641}
{"mode": "train", "epochs": 1, "timestep": 1134, "ep_reward": 572.3195190429688, "reward": 0.4964078664779663, "action": -0.8211765885353088}
{"mode": "train", "epochs": 1, "timestep": 1135, "ep_reward": 572.8135375976562, "reward": 0.4939892888069153, "action": -1.277032494544983}
{"mode": "train", "epochs": 1, "timestep": 1136, "ep_reward": 573.3048095703125, "reward": 0.49124521017074585, "action": -0.7477254271507263}
{"mode": "train", "epochs": 1, "timestep": 1137, "ep_reward": 573.7911987304688, "reward": 0.4864000678062439, "action": -0.7014264464378357}
{"mode": "train", "epochs": 1, "timestep": 1138, "ep_reward": 574.270751953125, "reward": 0.47958338260650635, "action": -1.065744161605835}
{"mode": "train", "epochs": 1, "timestep": 1139, "ep_reward": 574.7431030273438, "reward": 0.4723699688911438, "action": -1.4099533557891846}
{"mode": "train", "epochs": 1, "timestep": 1140, "ep_reward": 575.2092895507812, "reward": 0.4662044644355774, "action": -0.34748393297195435}
{"mode": "train", "epochs": 1, "timestep": 1141, "ep_reward": 575.6663818359375, "reward": 0.4570823907852173, "action": -0.32171958684921265}
{"mode": "train", "epochs": 1, "timestep": 1142, "ep_reward": 576.1121215820312, "reward": 0.4457573890686035, "action": -1.9366463422775269}
{"mode": "train", "epochs": 1, "timestep": 1143, "ep_reward": 576.5514526367188, "reward": 0.43934738636016846, "action": -1.529829502105713}
{"mode": "train", "epochs": 1, "timestep": 1144, "ep_reward": 576.986083984375, "reward": 0.43463873863220215, "action": -0.7303317785263062}
{"mode": "train", "epochs": 1, "timestep": 1145, "ep_reward": 577.41552734375, "reward": 0.429412841796875, "action": -1.2260162830352783}
{"mode": "train", "epochs": 1, "timestep": 1146, "ep_reward": 577.8416137695312, "reward": 0.42606550455093384, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1147, "ep_reward": 578.2686157226562, "reward": 0.42701268196105957, "action": -1.430335521697998}
{"mode": "train", "epochs": 1, "timestep": 1148, "ep_reward": 578.6985473632812, "reward": 0.4299577474594116, "action": -1.1861974000930786}
{"mode": "train", "epochs": 1, "timestep": 1149, "ep_reward": 579.133056640625, "reward": 0.4344823360443115, "action": -0.5988727807998657}
{"mode": "train", "epochs": 1, "timestep": 1150, "ep_reward": 579.572021484375, "reward": 0.4389927387237549, "action": 0.23970544338226318}
{"mode": "train", "epochs": 1, "timestep": 1151, "ep_reward": 580.0130004882812, "reward": 0.44099360704421997, "action": -0.6719610691070557}
{"mode": "train", "epochs": 1, "timestep": 1152, "ep_reward": 580.4553833007812, "reward": 0.4423915147781372, "action": -1.4954569339752197}
{"mode": "train", "epochs": 1, "timestep": 1153, "ep_reward": 580.9010009765625, "reward": 0.44561731815338135, "action": -1.9832994937896729}
{"mode": "train", "epochs": 1, "timestep": 1154, "ep_reward": 581.3527221679688, "reward": 0.4517475366592407, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1155, "ep_reward": 581.8134765625, "reward": 0.46077919006347656, "action": -0.35537248849868774}
{"mode": "train", "epochs": 1, "timestep": 1156, "ep_reward": 582.2825927734375, "reward": 0.4691007733345032, "action": -0.8718201518058777}
{"mode": "train", "epochs": 1, "timestep": 1157, "ep_reward": 582.7588500976562, "reward": 0.4762498736381531, "action": -1.0450434684753418}
{"mode": "train", "epochs": 1, "timestep": 1158, "ep_reward": 583.24169921875, "reward": 0.482837438583374, "action": -0.5805755853652954}
{"mode": "train", "epochs": 1, "timestep": 1159, "ep_reward": 583.7293090820312, "reward": 0.48763352632522583, "action": -0.6570844054222107}
{"mode": "train", "epochs": 1, "timestep": 1160, "ep_reward": 584.2194213867188, "reward": 0.4901033639907837, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1161, "ep_reward": 584.7135620117188, "reward": 0.4941213130950928, "action": -0.7026002407073975}
{"mode": "train", "epochs": 1, "timestep": 1162, "ep_reward": 585.2097778320312, "reward": 0.49618643522262573, "action": -1.5884859561920166}
{"mode": "train", "epochs": 1, "timestep": 1163, "ep_reward": 585.708251953125, "reward": 0.4984590411186218, "action": -1.046705722808838}
{"mode": "train", "epochs": 1, "timestep": 1164, "ep_reward": 586.2075805664062, "reward": 0.4993451237678528, "action": -1.794800877571106}
{"mode": "train", "epochs": 1, "timestep": 1165, "ep_reward": 586.7085571289062, "reward": 0.5009657144546509, "action": -1.669764518737793}
{"mode": "train", "epochs": 1, "timestep": 1166, "ep_reward": 587.21142578125, "reward": 0.5028587579727173, "action": -1.722686529159546}
{"mode": "train", "epochs": 1, "timestep": 1167, "ep_reward": 587.7166137695312, "reward": 0.5052132606506348, "action": -1.2113131284713745}
{"mode": "train", "epochs": 1, "timestep": 1168, "ep_reward": 588.22314453125, "reward": 0.5065006613731384, "action": -1.319401741027832}
{"mode": "train", "epochs": 1, "timestep": 1169, "ep_reward": 588.7301635742188, "reward": 0.5070277452468872, "action": -0.5622127056121826}
{"mode": "train", "epochs": 1, "timestep": 1170, "ep_reward": 589.2345581054688, "reward": 0.5043649673461914, "action": -1.551163673400879}
{"mode": "train", "epochs": 1, "timestep": 1171, "ep_reward": 589.7364501953125, "reward": 0.5019009113311768, "action": -0.8100652694702148}
{"mode": "train", "epochs": 1, "timestep": 1172, "ep_reward": 590.2334594726562, "reward": 0.49702274799346924, "action": -0.9133241176605225}
{"mode": "train", "epochs": 1, "timestep": 1173, "ep_reward": 590.7239990234375, "reward": 0.4905462861061096, "action": -0.2683675289154053}
{"mode": "train", "epochs": 1, "timestep": 1174, "ep_reward": 591.2041015625, "reward": 0.4801257252693176, "action": -1.5313644409179688}
{"mode": "train", "epochs": 1, "timestep": 1175, "ep_reward": 591.6756591796875, "reward": 0.47157108783721924, "action": -1.4672186374664307}
{"mode": "train", "epochs": 1, "timestep": 1176, "ep_reward": 592.1395263671875, "reward": 0.4638713002204895, "action": -0.41677939891815186}
{"mode": "train", "epochs": 1, "timestep": 1177, "ep_reward": 592.5926513671875, "reward": 0.4531448483467102, "action": -1.7151143550872803}
{"mode": "train", "epochs": 1, "timestep": 1178, "ep_reward": 593.0387573242188, "reward": 0.44612324237823486, "action": -0.7203490734100342}
{"mode": "train", "epochs": 1, "timestep": 1179, "ep_reward": 593.4765014648438, "reward": 0.43775081634521484, "action": -0.9546617865562439}
{"mode": "train", "epochs": 1, "timestep": 1180, "ep_reward": 593.9067993164062, "reward": 0.43028682470321655, "action": -0.7483134865760803}
{"mode": "train", "epochs": 1, "timestep": 1181, "ep_reward": 594.3297729492188, "reward": 0.42300206422805786, "action": -0.8336034417152405}
{"mode": "train", "epochs": 1, "timestep": 1182, "ep_reward": 594.7464599609375, "reward": 0.41670650243759155, "action": -0.35942620038986206}
{"mode": "train", "epochs": 1, "timestep": 1183, "ep_reward": 595.15625, "reward": 0.40976476669311523, "action": -1.1202523708343506}
{"mode": "train", "epochs": 1, "timestep": 1184, "ep_reward": 595.561767578125, "reward": 0.4055258631706238, "action": -1.3122568130493164}
{"mode": "train", "epochs": 1, "timestep": 1185, "ep_reward": 595.9657592773438, "reward": 0.40399372577667236, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1186, "ep_reward": 596.373046875, "reward": 0.40731292963027954, "action": -1.1970707178115845}
{"mode": "train", "epochs": 1, "timestep": 1187, "ep_reward": 596.7857666015625, "reward": 0.41271138191223145, "action": -1.3911563158035278}
{"mode": "train", "epochs": 1, "timestep": 1188, "ep_reward": 597.2064819335938, "reward": 0.42071884870529175, "action": -0.9362072944641113}
{"mode": "train", "epochs": 1, "timestep": 1189, "ep_reward": 597.6366577148438, "reward": 0.4301764965057373, "action": -0.5063360929489136}
{"mode": "train", "epochs": 1, "timestep": 1190, "ep_reward": 598.0762939453125, "reward": 0.4396112561225891, "action": -1.1305568218231201}
{"mode": "train", "epochs": 1, "timestep": 1191, "ep_reward": 598.52587890625, "reward": 0.4496096968650818, "action": -0.9287428259849548}
{"mode": "train", "epochs": 1, "timestep": 1192, "ep_reward": 598.9857788085938, "reward": 0.4598907232284546, "action": -1.148503065109253}
{"mode": "train", "epochs": 1, "timestep": 1193, "ep_reward": 599.4560546875, "reward": 0.4702951908111572, "action": -1.4025864601135254}
{"mode": "train", "epochs": 1, "timestep": 1194, "ep_reward": 599.9373168945312, "reward": 0.48124802112579346, "action": -0.15834063291549683}
{"mode": "train", "epochs": 1, "timestep": 1195, "ep_reward": 600.4273071289062, "reward": 0.49001771211624146, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1196, "ep_reward": 600.9263916015625, "reward": 0.49905693531036377, "action": -0.6162614822387695}
{"mode": "train", "epochs": 1, "timestep": 1197, "ep_reward": 601.4329223632812, "reward": 0.5065432786941528, "action": -1.416338562965393}
{"mode": "train", "epochs": 1, "timestep": 1198, "ep_reward": 601.9458618164062, "reward": 0.5129563808441162, "action": -0.5634302496910095}
{"mode": "train", "epochs": 1, "timestep": 1199, "ep_reward": 602.46240234375, "reward": 0.5165399312973022, "action": -1.2715195417404175}
{"mode": "train", "epochs": 1, "timestep": 1200, "ep_reward": 602.98095703125, "reward": 0.5185552835464478, "action": -0.31561362743377686}
{"mode": "train", "epochs": 1, "timestep": 1201, "ep_reward": 603.4974365234375, "reward": 0.516451358795166, "action": -0.7683279514312744}
{"mode": "train", "epochs": 1, "timestep": 1202, "ep_reward": 604.0088500976562, "reward": 0.5114332437515259, "action": -0.7470656633377075}
{"mode": "train", "epochs": 1, "timestep": 1203, "ep_reward": 604.5125122070312, "reward": 0.5036449432373047, "action": -0.575685977935791}
{"mode": "train", "epochs": 1, "timestep": 1204, "ep_reward": 605.0051879882812, "reward": 0.4926804304122925, "action": -0.9735146760940552}
{"mode": "train", "epochs": 1, "timestep": 1205, "ep_reward": 605.48583984375, "reward": 0.4806744456291199, "action": -1.1569896936416626}
{"mode": "train", "epochs": 1, "timestep": 1206, "ep_reward": 605.9544067382812, "reward": 0.4685763716697693, "action": -0.26836562156677246}
{"mode": "train", "epochs": 1, "timestep": 1207, "ep_reward": 606.406982421875, "reward": 0.4525803327560425, "action": -1.866034984588623}
{"mode": "train", "epochs": 1, "timestep": 1208, "ep_reward": 606.8487548828125, "reward": 0.4417688846588135, "action": -0.686984658241272}
{"mode": "train", "epochs": 1, "timestep": 1209, "ep_reward": 607.2776489257812, "reward": 0.42887359857559204, "action": -1.2559715509414673}
{"mode": "train", "epochs": 1, "timestep": 1210, "ep_reward": 607.6961059570312, "reward": 0.4184473752975464, "action": -1.8708888292312622}
{"mode": "train", "epochs": 1, "timestep": 1211, "ep_reward": 608.1087646484375, "reward": 0.4126574993133545, "action": -1.1727932691574097}
{"mode": "train", "epochs": 1, "timestep": 1212, "ep_reward": 608.516845703125, "reward": 0.4081045389175415, "action": -1.5144367218017578}
{"mode": "train", "epochs": 1, "timestep": 1213, "ep_reward": 608.923828125, "reward": 0.40697574615478516, "action": -1.2608416080474854}
{"mode": "train", "epochs": 1, "timestep": 1214, "ep_reward": 609.33203125, "reward": 0.4082300066947937, "action": -0.9910671710968018}
{"mode": "train", "epochs": 1, "timestep": 1215, "ep_reward": 609.7432250976562, "reward": 0.4112110137939453, "action": -0.982971727848053}
{"mode": "train", "epochs": 1, "timestep": 1216, "ep_reward": 610.1591186523438, "reward": 0.41589033603668213, "action": -0.6412043571472168}
{"mode": "train", "epochs": 1, "timestep": 1217, "ep_reward": 610.5803833007812, "reward": 0.421273410320282, "action": -0.39156055450439453}
{"mode": "train", "epochs": 1, "timestep": 1218, "ep_reward": 611.0067749023438, "reward": 0.4263771176338196, "action": -1.3053666353225708}
{"mode": "train", "epochs": 1, "timestep": 1219, "ep_reward": 611.4400024414062, "reward": 0.4332333207130432, "action": -0.2762981057167053}
{"mode": "train", "epochs": 1, "timestep": 1220, "ep_reward": 611.8794555664062, "reward": 0.43945741653442383, "action": -1.3682799339294434}
{"mode": "train", "epochs": 1, "timestep": 1221, "ep_reward": 612.3263549804688, "reward": 0.44691556692123413, "action": -0.5396835803985596}
{"mode": "train", "epochs": 1, "timestep": 1222, "ep_reward": 612.7803955078125, "reward": 0.4540320038795471, "action": -0.6255308389663696}
{"mode": "train", "epochs": 1, "timestep": 1223, "ep_reward": 613.2405395507812, "reward": 0.46016430854797363, "action": -1.215815544128418}
{"mode": "train", "epochs": 1, "timestep": 1224, "ep_reward": 613.7071533203125, "reward": 0.4666193723678589, "action": -0.5600778460502625}
{"mode": "train", "epochs": 1, "timestep": 1225, "ep_reward": 614.1788330078125, "reward": 0.4717012643814087, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1226, "ep_reward": 614.657470703125, "reward": 0.47862982749938965, "action": -0.4567430913448334}
{"mode": "train", "epochs": 1, "timestep": 1227, "ep_reward": 615.1415405273438, "reward": 0.4840630292892456, "action": -1.1329270601272583}
{"mode": "train", "epochs": 1, "timestep": 1228, "ep_reward": 615.630126953125, "reward": 0.48860639333724976, "action": -0.9862158894538879}
{"mode": "train", "epochs": 1, "timestep": 1229, "ep_reward": 616.1222534179688, "reward": 0.49211597442626953, "action": -0.7610450387001038}
{"mode": "train", "epochs": 1, "timestep": 1230, "ep_reward": 616.615966796875, "reward": 0.4937039017677307, "action": -1.4142311811447144}
{"mode": "train", "epochs": 1, "timestep": 1231, "ep_reward": 617.1111450195312, "reward": 0.4952051639556885, "action": -0.5205405950546265}
{"mode": "train", "epochs": 1, "timestep": 1232, "ep_reward": 617.6051635742188, "reward": 0.4940364360809326, "action": -0.7445583343505859}
{"mode": "train", "epochs": 1, "timestep": 1233, "ep_reward": 618.095947265625, "reward": 0.49080508947372437, "action": -0.6612582206726074}
{"mode": "train", "epochs": 1, "timestep": 1234, "ep_reward": 618.581298828125, "reward": 0.48537182807922363, "action": -0.3806058168411255}
{"mode": "train", "epochs": 1, "timestep": 1235, "ep_reward": 619.0582275390625, "reward": 0.4769511818885803, "action": -0.10353302955627441}
{"mode": "train", "epochs": 1, "timestep": 1236, "ep_reward": 619.5230102539062, "reward": 0.4647669196128845, "action": -1.3725576400756836}
{"mode": "train", "epochs": 1, "timestep": 1237, "ep_reward": 619.977783203125, "reward": 0.45474356412887573, "action": -1.3977863788604736}
{"mode": "train", "epochs": 1, "timestep": 1238, "ep_reward": 620.423828125, "reward": 0.44604504108428955, "action": -0.9162551760673523}
{"mode": "train", "epochs": 1, "timestep": 1239, "ep_reward": 620.86083984375, "reward": 0.437041699886322, "action": -1.0008482933044434}
{"mode": "train", "epochs": 1, "timestep": 1240, "ep_reward": 621.2898559570312, "reward": 0.4289894104003906, "action": -0.5370627045631409}
{"mode": "train", "epochs": 1, "timestep": 1241, "ep_reward": 621.7101440429688, "reward": 0.4203103184700012, "action": -0.6282593011856079}
{"mode": "train", "epochs": 1, "timestep": 1242, "ep_reward": 622.1221923828125, "reward": 0.4120657444000244, "action": -1.1334271430969238}
{"mode": "train", "epochs": 1, "timestep": 1243, "ep_reward": 622.5286254882812, "reward": 0.4064542055130005, "action": -0.5063816905021667}
{"mode": "train", "epochs": 1, "timestep": 1244, "ep_reward": 622.929443359375, "reward": 0.40081071853637695, "action": -1.337066411972046}
{"mode": "train", "epochs": 1, "timestep": 1245, "ep_reward": 623.3282470703125, "reward": 0.39879775047302246, "action": -1.130287766456604}
{"mode": "train", "epochs": 1, "timestep": 1246, "ep_reward": 623.7274169921875, "reward": 0.3991585969924927, "action": -0.7385077476501465}
{"mode": "train", "epochs": 1, "timestep": 1247, "ep_reward": 624.1282348632812, "reward": 0.40083205699920654, "action": -1.065123200416565}
{"mode": "train", "epochs": 1, "timestep": 1248, "ep_reward": 624.532958984375, "reward": 0.40474480390548706, "action": -1.2530324459075928}
{"mode": "train", "epochs": 1, "timestep": 1249, "ep_reward": 624.944091796875, "reward": 0.4111616015434265, "action": -1.3619624376296997}
{"mode": "train", "epochs": 1, "timestep": 1250, "ep_reward": 625.3642578125, "reward": 0.4201804995536804, "action": -0.7176947593688965}
{"mode": "train", "epochs": 1, "timestep": 1251, "ep_reward": 625.7944946289062, "reward": 0.4302218556404114, "action": -0.9333046674728394}
{"mode": "train", "epochs": 1, "timestep": 1252, "ep_reward": 626.2352905273438, "reward": 0.4407801628112793, "action": -1.799034595489502}
{"mode": "train", "epochs": 1, "timestep": 1253, "ep_reward": 626.6886596679688, "reward": 0.4533652663230896, "action": -1.1455652713775635}
{"mode": "train", "epochs": 1, "timestep": 1254, "ep_reward": 627.1558227539062, "reward": 0.4671655297279358, "action": -1.1650606393814087}
{"mode": "train", "epochs": 1, "timestep": 1255, "ep_reward": 627.636962890625, "reward": 0.4811245799064636, "action": -0.589304506778717}
{"mode": "train", "epochs": 1, "timestep": 1256, "ep_reward": 628.1306762695312, "reward": 0.4937225580215454, "action": -1.6482367515563965}
{"mode": "train", "epochs": 1, "timestep": 1257, "ep_reward": 628.6363525390625, "reward": 0.5056917667388916, "action": -0.5830795764923096}
{"mode": "train", "epochs": 1, "timestep": 1258, "ep_reward": 629.1522827148438, "reward": 0.5159184336662292, "action": -1.137920618057251}
{"mode": "train", "epochs": 1, "timestep": 1259, "ep_reward": 629.6761474609375, "reward": 0.523881733417511, "action": -0.6161348819732666}
{"mode": "train", "epochs": 1, "timestep": 1260, "ep_reward": 630.204833984375, "reward": 0.5286849737167358, "action": -0.8300349712371826}
{"mode": "train", "epochs": 1, "timestep": 1261, "ep_reward": 630.7350463867188, "reward": 0.5302380323410034, "action": -0.24395710229873657}
{"mode": "train", "epochs": 1, "timestep": 1262, "ep_reward": 631.2619018554688, "reward": 0.5268394351005554, "action": -0.7095497250556946}
{"mode": "train", "epochs": 1, "timestep": 1263, "ep_reward": 631.7817993164062, "reward": 0.5198904275894165, "action": -1.048757553100586}
{"mode": "train", "epochs": 1, "timestep": 1264, "ep_reward": 632.2926635742188, "reward": 0.5108774900436401, "action": -1.3609384298324585}
{"mode": "train", "epochs": 1, "timestep": 1265, "ep_reward": 632.7938232421875, "reward": 0.5011780261993408, "action": -1.5126264095306396}
{"mode": "train", "epochs": 1, "timestep": 1266, "ep_reward": 633.2854614257812, "reward": 0.491627037525177, "action": -0.3426631689071655}
{"mode": "train", "epochs": 1, "timestep": 1267, "ep_reward": 633.7630004882812, "reward": 0.4775102734565735, "action": -1.3677705526351929}
{"mode": "train", "epochs": 1, "timestep": 1268, "ep_reward": 634.22802734375, "reward": 0.46504223346710205, "action": -1.069443702697754}
{"mode": "train", "epochs": 1, "timestep": 1269, "ep_reward": 634.6800537109375, "reward": 0.45204126834869385, "action": -1.368141531944275}
{"mode": "train", "epochs": 1, "timestep": 1270, "ep_reward": 635.120849609375, "reward": 0.4408016800880432, "action": -0.7700033783912659}
{"mode": "train", "epochs": 1, "timestep": 1271, "ep_reward": 635.5494995117188, "reward": 0.42864346504211426, "action": -1.5809285640716553}
{"mode": "train", "epochs": 1, "timestep": 1272, "ep_reward": 635.9698486328125, "reward": 0.4203638434410095, "action": -0.7437790632247925}
{"mode": "train", "epochs": 1, "timestep": 1273, "ep_reward": 636.3814086914062, "reward": 0.41156429052352905, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1274, "ep_reward": 636.7899780273438, "reward": 0.40856534242630005, "action": -1.068953037261963}
{"mode": "train", "epochs": 1, "timestep": 1275, "ep_reward": 637.196533203125, "reward": 0.40654873847961426, "action": -1.8930795192718506}
{"mode": "train", "epochs": 1, "timestep": 1276, "ep_reward": 637.605712890625, "reward": 0.4091796278953552, "action": -0.936346709728241}
{"mode": "train", "epochs": 1, "timestep": 1277, "ep_reward": 638.0189819335938, "reward": 0.41324275732040405, "action": -0.3068976402282715}
{"mode": "train", "epochs": 1, "timestep": 1278, "ep_reward": 638.4361572265625, "reward": 0.4171885848045349, "action": -0.8678671717643738}
{"mode": "train", "epochs": 1, "timestep": 1279, "ep_reward": 638.8583374023438, "reward": 0.4221755266189575, "action": -0.5757862329483032}
{"mode": "train", "epochs": 1, "timestep": 1280, "ep_reward": 639.2855834960938, "reward": 0.4272257685661316, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1281, "ep_reward": 639.7212524414062, "reward": 0.43566232919692993, "action": -1.0872992277145386}
{"mode": "train", "epochs": 1, "timestep": 1282, "ep_reward": 640.1668701171875, "reward": 0.44564270973205566, "action": 0.2535025477409363}
{"mode": "train", "epochs": 1, "timestep": 1283, "ep_reward": 640.62060546875, "reward": 0.45372962951660156, "action": -0.9014984369277954}
{"mode": "train", "epochs": 1, "timestep": 1284, "ep_reward": 641.0814208984375, "reward": 0.46079492568969727, "action": -0.8564212322235107}
{"mode": "train", "epochs": 1, "timestep": 1285, "ep_reward": 641.5488891601562, "reward": 0.4674694538116455, "action": -0.4677445888519287}
{"mode": "train", "epochs": 1, "timestep": 1286, "ep_reward": 642.0213012695312, "reward": 0.47240716218948364, "action": -1.6685208082199097}
{"mode": "train", "epochs": 1, "timestep": 1287, "ep_reward": 642.4995727539062, "reward": 0.4782772660255432, "action": -1.0026310682296753}
{"mode": "train", "epochs": 1, "timestep": 1288, "ep_reward": 642.9832763671875, "reward": 0.48371946811676025, "action": -1.1270545721054077}
{"mode": "train", "epochs": 1, "timestep": 1289, "ep_reward": 643.4718627929688, "reward": 0.48861533403396606, "action": -0.6576566696166992}
{"mode": "train", "epochs": 1, "timestep": 1290, "ep_reward": 643.9635009765625, "reward": 0.49164432287216187, "action": -0.7691255807876587}
{"mode": "train", "epochs": 1, "timestep": 1291, "ep_reward": 644.456298828125, "reward": 0.4927840828895569, "action": 0.2704322934150696}
{"mode": "train", "epochs": 1, "timestep": 1292, "ep_reward": 644.9451904296875, "reward": 0.48888182640075684, "action": -1.0101828575134277}
{"mode": "train", "epochs": 1, "timestep": 1293, "ep_reward": 645.4292602539062, "reward": 0.48408299684524536, "action": -0.8048877120018005}
{"mode": "train", "epochs": 1, "timestep": 1294, "ep_reward": 645.906982421875, "reward": 0.4777058959007263, "action": -0.5103219747543335}
{"mode": "train", "epochs": 1, "timestep": 1295, "ep_reward": 646.3758544921875, "reward": 0.46889209747314453, "action": -1.401892900466919}
{"mode": "train", "epochs": 1, "timestep": 1296, "ep_reward": 646.8374633789062, "reward": 0.46161383390426636, "action": -1.2939857244491577}
{"mode": "train", "epochs": 1, "timestep": 1297, "ep_reward": 647.2924194335938, "reward": 0.45494985580444336, "action": -1.2294806241989136}
{"mode": "train", "epochs": 1, "timestep": 1298, "ep_reward": 647.7412719726562, "reward": 0.4488629698753357, "action": -1.9638786315917969}
{"mode": "train", "epochs": 1, "timestep": 1299, "ep_reward": 648.187744140625, "reward": 0.4464987516403198, "action": -0.5334948301315308}
{"mode": "train", "epochs": 1, "timestep": 1300, "ep_reward": 648.6301879882812, "reward": 0.4424442648887634, "action": -0.7837726473808289}
{"mode": "train", "epochs": 1, "timestep": 1301, "ep_reward": 649.0687255859375, "reward": 0.4385629892349243, "action": -0.24432390928268433}
{"mode": "train", "epochs": 1, "timestep": 1302, "ep_reward": 649.501708984375, "reward": 0.4329987168312073, "action": -1.006675124168396}
{"mode": "train", "epochs": 1, "timestep": 1303, "ep_reward": 649.9306030273438, "reward": 0.4288855791091919, "action": -0.770140528678894}
{"mode": "train", "epochs": 1, "timestep": 1304, "ep_reward": 650.3555908203125, "reward": 0.42501479387283325, "action": -1.5267550945281982}
{"mode": "train", "epochs": 1, "timestep": 1305, "ep_reward": 650.7798461914062, "reward": 0.4242584705352783, "action": -1.1767648458480835}
{"mode": "train", "epochs": 1, "timestep": 1306, "ep_reward": 651.2048950195312, "reward": 0.42505669593811035, "action": -1.0973798036575317}
{"mode": "train", "epochs": 1, "timestep": 1307, "ep_reward": 651.6322631835938, "reward": 0.42736566066741943, "action": -0.7218020558357239}
{"mode": "train", "epochs": 1, "timestep": 1308, "ep_reward": 652.0623779296875, "reward": 0.4300878047943115, "action": -0.78807133436203}
{"mode": "train", "epochs": 1, "timestep": 1309, "ep_reward": 652.4957275390625, "reward": 0.4333292841911316, "action": -0.29085445404052734}
{"mode": "train", "epochs": 1, "timestep": 1310, "ep_reward": 652.9313354492188, "reward": 0.4356222152709961, "action": -0.8333057165145874}
{"mode": "train", "epochs": 1, "timestep": 1311, "ep_reward": 653.36962890625, "reward": 0.43827706575393677, "action": -0.2229735255241394}
{"mode": "train", "epochs": 1, "timestep": 1312, "ep_reward": 653.8092651367188, "reward": 0.43961256742477417, "action": -0.5910162329673767}
{"mode": "train", "epochs": 1, "timestep": 1313, "ep_reward": 654.249755859375, "reward": 0.4404960870742798, "action": -0.3564016819000244}
{"mode": "train", "epochs": 1, "timestep": 1314, "ep_reward": 654.68994140625, "reward": 0.44017601013183594, "action": -1.2850381135940552}
{"mode": "train", "epochs": 1, "timestep": 1315, "ep_reward": 655.1314086914062, "reward": 0.44146084785461426, "action": -1.0930863618850708}
{"mode": "train", "epochs": 1, "timestep": 1316, "ep_reward": 655.5750122070312, "reward": 0.4436103105545044, "action": -1.157342791557312}
{"mode": "train", "epochs": 1, "timestep": 1317, "ep_reward": 656.021728515625, "reward": 0.4467126131057739, "action": -1.3949713706970215}
{"mode": "train", "epochs": 1, "timestep": 1318, "ep_reward": 656.47314453125, "reward": 0.45140063762664795, "action": -0.194208562374115}
{"mode": "train", "epochs": 1, "timestep": 1319, "ep_reward": 656.927490234375, "reward": 0.4543445110321045, "action": -1.6294901371002197}
{"mode": "train", "epochs": 1, "timestep": 1320, "ep_reward": 657.386474609375, "reward": 0.4589728116989136, "action": -0.568353533744812}
{"mode": "train", "epochs": 1, "timestep": 1321, "ep_reward": 657.84912109375, "reward": 0.4626697301864624, "action": -0.9774873852729797}
{"mode": "train", "epochs": 1, "timestep": 1322, "ep_reward": 658.315185546875, "reward": 0.46605050563812256, "action": -1.0158896446228027}
{"mode": "train", "epochs": 1, "timestep": 1323, "ep_reward": 658.7844848632812, "reward": 0.46927380561828613, "action": -0.5447983741760254}
{"mode": "train", "epochs": 1, "timestep": 1324, "ep_reward": 659.2551879882812, "reward": 0.47073090076446533, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1325, "ep_reward": 659.7297973632812, "reward": 0.4745871424674988, "action": -0.406311571598053}
{"mode": "train", "epochs": 1, "timestep": 1326, "ep_reward": 660.2060546875, "reward": 0.47625523805618286, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1327, "ep_reward": 660.6860961914062, "reward": 0.4800342917442322, "action": -0.6285783052444458}
{"mode": "train", "epochs": 1, "timestep": 1328, "ep_reward": 661.1683349609375, "reward": 0.48222386837005615, "action": -0.8330998420715332}
{"mode": "train", "epochs": 1, "timestep": 1329, "ep_reward": 661.6511840820312, "reward": 0.4828518033027649, "action": -1.9030938148498535}
{"mode": "train", "epochs": 1, "timestep": 1330, "ep_reward": 662.136474609375, "reward": 0.4852667450904846, "action": -0.8765291571617126}
{"mode": "train", "epochs": 1, "timestep": 1331, "ep_reward": 662.622802734375, "reward": 0.4863353371620178, "action": -1.4535359144210815}
{"mode": "train", "epochs": 1, "timestep": 1332, "ep_reward": 663.1105346679688, "reward": 0.48774415254592896, "action": -0.7389423251152039}
{"mode": "train", "epochs": 1, "timestep": 1333, "ep_reward": 663.597900390625, "reward": 0.4873543977737427, "action": -1.0274684429168701}
{"mode": "train", "epochs": 1, "timestep": 1334, "ep_reward": 664.0838623046875, "reward": 0.4859778881072998, "action": -1.2577030658721924}
{"mode": "train", "epochs": 1, "timestep": 1335, "ep_reward": 664.568115234375, "reward": 0.4842722415924072, "action": -1.8632078170776367}
{"mode": "train", "epochs": 1, "timestep": 1336, "ep_reward": 665.052490234375, "reward": 0.48436111211776733, "action": -0.6974093914031982}
{"mode": "train", "epochs": 1, "timestep": 1337, "ep_reward": 665.534912109375, "reward": 0.4824312925338745, "action": -0.8221964240074158}
{"mode": "train", "epochs": 1, "timestep": 1338, "ep_reward": 666.0140991210938, "reward": 0.4791710376739502, "action": -0.4645506739616394}
{"mode": "train", "epochs": 1, "timestep": 1339, "ep_reward": 666.4874877929688, "reward": 0.47337979078292847, "action": -1.3244668245315552}
{"mode": "train", "epochs": 1, "timestep": 1340, "ep_reward": 666.9560546875, "reward": 0.46855342388153076, "action": 0.05038106441497803}
{"mode": "train", "epochs": 1, "timestep": 1341, "ep_reward": 667.41552734375, "reward": 0.4594595432281494, "action": -0.7081918716430664}
{"mode": "train", "epochs": 1, "timestep": 1342, "ep_reward": 667.865478515625, "reward": 0.4499574303627014, "action": -1.170896291732788}
{"mode": "train", "epochs": 1, "timestep": 1343, "ep_reward": 668.3072509765625, "reward": 0.44174492359161377, "action": -1.0934232473373413}
{"mode": "train", "epochs": 1, "timestep": 1344, "ep_reward": 668.7415771484375, "reward": 0.4343481659889221, "action": -1.073606252670288}
{"mode": "train", "epochs": 1, "timestep": 1345, "ep_reward": 669.1696166992188, "reward": 0.42803382873535156, "action": -1.1374588012695312}
{"mode": "train", "epochs": 1, "timestep": 1346, "ep_reward": 669.5928955078125, "reward": 0.42330747842788696, "action": -0.9114956259727478}
{"mode": "train", "epochs": 1, "timestep": 1347, "ep_reward": 670.0123291015625, "reward": 0.4194505214691162, "action": -1.2078629732131958}
{"mode": "train", "epochs": 1, "timestep": 1348, "ep_reward": 670.43017578125, "reward": 0.4178524613380432, "action": -0.1693236231803894}
{"mode": "train", "epochs": 1, "timestep": 1349, "ep_reward": 670.8452758789062, "reward": 0.41508030891418457, "action": 0.32782477140426636}
{"mode": "train", "epochs": 1, "timestep": 1350, "ep_reward": 671.2552490234375, "reward": 0.4099680185317993, "action": -0.21306836605072021}
{"mode": "train", "epochs": 1, "timestep": 1351, "ep_reward": 671.6597900390625, "reward": 0.40456074476242065, "action": -1.1560014486312866}
{"mode": "train", "epochs": 1, "timestep": 1352, "ep_reward": 672.0619506835938, "reward": 0.40215814113616943, "action": -1.138143539428711}
{"mode": "train", "epochs": 1, "timestep": 1353, "ep_reward": 672.464111328125, "reward": 0.40218585729599, "action": -0.4910043478012085}
{"mode": "train", "epochs": 1, "timestep": 1354, "ep_reward": 672.8667602539062, "reward": 0.40264713764190674, "action": -1.2665388584136963}
{"mode": "train", "epochs": 1, "timestep": 1355, "ep_reward": 673.2727661132812, "reward": 0.4059789776802063, "action": -0.9515011310577393}
{"mode": "train", "epochs": 1, "timestep": 1356, "ep_reward": 673.6838989257812, "reward": 0.4111090302467346, "action": 0.3208438754081726}
{"mode": "train", "epochs": 1, "timestep": 1357, "ep_reward": 674.0985717773438, "reward": 0.4146993160247803, "action": -1.1184600591659546}
{"mode": "train", "epochs": 1, "timestep": 1358, "ep_reward": 674.5183715820312, "reward": 0.41979414224624634, "action": -1.002989411354065}
{"mode": "train", "epochs": 1, "timestep": 1359, "ep_reward": 674.9447021484375, "reward": 0.42633718252182007, "action": -0.8763895034790039}
{"mode": "train", "epochs": 1, "timestep": 1360, "ep_reward": 675.3784790039062, "reward": 0.43380510807037354, "action": -0.6472841501235962}
{"mode": "train", "epochs": 1, "timestep": 1361, "ep_reward": 675.8198852539062, "reward": 0.441378116607666, "action": -0.5663345456123352}
{"mode": "train", "epochs": 1, "timestep": 1362, "ep_reward": 676.2681274414062, "reward": 0.4482349753379822, "action": -1.966585397720337}
{"mode": "train", "epochs": 1, "timestep": 1363, "ep_reward": 676.7255249023438, "reward": 0.45739710330963135, "action": -1.0814199447631836}
{"mode": "train", "epochs": 1, "timestep": 1364, "ep_reward": 677.1929321289062, "reward": 0.4673924446105957, "action": -1.0721174478530884}
{"mode": "train", "epochs": 1, "timestep": 1365, "ep_reward": 677.6702270507812, "reward": 0.4773194193840027, "action": -0.7681467533111572}
{"mode": "train", "epochs": 1, "timestep": 1366, "ep_reward": 678.1563110351562, "reward": 0.48607826232910156, "action": -1.6245710849761963}
{"mode": "train", "epochs": 1, "timestep": 1367, "ep_reward": 678.6513061523438, "reward": 0.4950050711631775, "action": -0.663873016834259}
{"mode": "train", "epochs": 1, "timestep": 1368, "ep_reward": 679.1537475585938, "reward": 0.5024679899215698, "action": 0.10061752796173096}
{"mode": "train", "epochs": 1, "timestep": 1369, "ep_reward": 679.6593017578125, "reward": 0.505536675453186, "action": 0.10196906328201294}
{"mode": "train", "epochs": 1, "timestep": 1370, "ep_reward": 680.1625366210938, "reward": 0.5032588839530945, "action": -0.25498658418655396}
{"mode": "train", "epochs": 1, "timestep": 1371, "ep_reward": 680.6593627929688, "reward": 0.49683743715286255, "action": -0.8455511927604675}
{"mode": "train", "epochs": 1, "timestep": 1372, "ep_reward": 681.1481323242188, "reward": 0.4887692928314209, "action": -0.6750383377075195}
{"mode": "train", "epochs": 1, "timestep": 1373, "ep_reward": 681.6265258789062, "reward": 0.4784056544303894, "action": -1.1844323873519897}
{"mode": "train", "epochs": 1, "timestep": 1374, "ep_reward": 682.0948486328125, "reward": 0.46830928325653076, "action": -1.313741683959961}
{"mode": "train", "epochs": 1, "timestep": 1375, "ep_reward": 682.5538330078125, "reward": 0.45898568630218506, "action": 0.0938684344291687}
{"mode": "train", "epochs": 1, "timestep": 1376, "ep_reward": 682.998779296875, "reward": 0.4449223279953003, "action": -0.6652339696884155}
{"mode": "train", "epochs": 1, "timestep": 1377, "ep_reward": 683.429931640625, "reward": 0.4311668276786804, "action": -1.3966444730758667}
{"mode": "train", "epochs": 1, "timestep": 1378, "ep_reward": 683.8505249023438, "reward": 0.4205790162086487, "action": -1.3538609743118286}
{"mode": "train", "epochs": 1, "timestep": 1379, "ep_reward": 684.2628173828125, "reward": 0.4122638702392578, "action": -1.1271743774414062}
{"mode": "train", "epochs": 1, "timestep": 1380, "ep_reward": 684.66845703125, "reward": 0.4056239128112793, "action": -1.5089607238769531}
{"mode": "train", "epochs": 1, "timestep": 1381, "ep_reward": 685.0711669921875, "reward": 0.4026978611946106, "action": -0.22264975309371948}
{"mode": "train", "epochs": 1, "timestep": 1382, "ep_reward": 685.4697875976562, "reward": 0.3986324071884155, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1383, "ep_reward": 685.8703002929688, "reward": 0.40049248933792114, "action": -0.24169373512268066}
{"mode": "train", "epochs": 1, "timestep": 1384, "ep_reward": 686.272216796875, "reward": 0.4018867015838623, "action": -1.016658067703247}
{"mode": "train", "epochs": 1, "timestep": 1385, "ep_reward": 686.6775512695312, "reward": 0.40531426668167114, "action": -1.508076786994934}
{"mode": "train", "epochs": 1, "timestep": 1386, "ep_reward": 687.0894165039062, "reward": 0.4118647575378418, "action": -1.4916049242019653}
{"mode": "train", "epochs": 1, "timestep": 1387, "ep_reward": 687.5107421875, "reward": 0.4213259816169739, "action": -0.78968745470047}
{"mode": "train", "epochs": 1, "timestep": 1388, "ep_reward": 687.9428100585938, "reward": 0.43205755949020386, "action": -0.40358224511146545}
{"mode": "train", "epochs": 1, "timestep": 1389, "ep_reward": 688.3853149414062, "reward": 0.4424954652786255, "action": -0.32425105571746826}
{"mode": "train", "epochs": 1, "timestep": 1390, "ep_reward": 688.8369750976562, "reward": 0.4516637921333313, "action": -0.8881294131278992}
{"mode": "train", "epochs": 1, "timestep": 1391, "ep_reward": 689.2973022460938, "reward": 0.4603232741355896, "action": -0.7692105770111084}
{"mode": "train", "epochs": 1, "timestep": 1392, "ep_reward": 689.7656860351562, "reward": 0.4684123396873474, "action": -0.5373563766479492}
{"mode": "train", "epochs": 1, "timestep": 1393, "ep_reward": 690.2406005859375, "reward": 0.47494369745254517, "action": -1.2487725019454956}
{"mode": "train", "epochs": 1, "timestep": 1394, "ep_reward": 690.7218627929688, "reward": 0.48125165700912476, "action": -0.26718759536743164}
{"mode": "train", "epochs": 1, "timestep": 1395, "ep_reward": 691.2069702148438, "reward": 0.48510807752609253, "action": -1.2361819744110107}
{"mode": "train", "epochs": 1, "timestep": 1396, "ep_reward": 691.6953125, "reward": 0.4883624315261841, "action": 0.2857906222343445}
{"mode": "train", "epochs": 1, "timestep": 1397, "ep_reward": 692.1824340820312, "reward": 0.48713308572769165, "action": -0.6351107358932495}
{"mode": "train", "epochs": 1, "timestep": 1398, "ep_reward": 692.6659545898438, "reward": 0.48354434967041016, "action": -1.2337279319763184}
{"mode": "train", "epochs": 1, "timestep": 1399, "ep_reward": 693.1459350585938, "reward": 0.4799594283103943, "action": -0.9467929601669312}
{"mode": "train", "epochs": 1, "timestep": 1400, "ep_reward": 693.6212158203125, "reward": 0.4752820134162903, "action": -1.264406442642212}
{"mode": "train", "epochs": 1, "timestep": 1401, "ep_reward": 694.0922241210938, "reward": 0.471008837223053, "action": -0.5061332583427429}
{"mode": "train", "epochs": 1, "timestep": 1402, "ep_reward": 694.556640625, "reward": 0.46442246437072754, "action": -1.0524296760559082}
{"mode": "train", "epochs": 1, "timestep": 1403, "ep_reward": 695.0148315429688, "reward": 0.4581916332244873, "action": -0.4464198350906372}
{"mode": "train", "epochs": 1, "timestep": 1404, "ep_reward": 695.4647827148438, "reward": 0.4499680995941162, "action": -0.6455239057540894}
{"mode": "train", "epochs": 1, "timestep": 1405, "ep_reward": 695.906005859375, "reward": 0.4412444233894348, "action": 0.18351954221725464}
{"mode": "train", "epochs": 1, "timestep": 1406, "ep_reward": 696.3348999023438, "reward": 0.4289158582687378, "action": -1.0016391277313232}
{"mode": "train", "epochs": 1, "timestep": 1407, "ep_reward": 696.75390625, "reward": 0.4189962148666382, "action": -0.8116430044174194}
{"mode": "train", "epochs": 1, "timestep": 1408, "ep_reward": 697.1637573242188, "reward": 0.4098254442214966, "action": -0.5673878192901611}
{"mode": "train", "epochs": 1, "timestep": 1409, "ep_reward": 697.5646362304688, "reward": 0.40088993310928345, "action": -1.5216656923294067}
{"mode": "train", "epochs": 1, "timestep": 1410, "ep_reward": 697.9611206054688, "reward": 0.39651334285736084, "action": -1.0074799060821533}
{"mode": "train", "epochs": 1, "timestep": 1411, "ep_reward": 698.3549194335938, "reward": 0.3938012719154358, "action": -1.608788013458252}
{"mode": "train", "epochs": 1, "timestep": 1412, "ep_reward": 698.7503051757812, "reward": 0.3953738808631897, "action": -0.7965683937072754}
{"mode": "train", "epochs": 1, "timestep": 1413, "ep_reward": 699.1486206054688, "reward": 0.3983129858970642, "action": -1.581431269645691}
{"mode": "train", "epochs": 1, "timestep": 1414, "ep_reward": 699.5535278320312, "reward": 0.4048959016799927, "action": -1.0499107837677002}
{"mode": "train", "epochs": 1, "timestep": 1415, "ep_reward": 699.9672241210938, "reward": 0.4136732220649719, "action": 0.3424045443534851}
{"mode": "train", "epochs": 1, "timestep": 1416, "ep_reward": 700.388427734375, "reward": 0.42118602991104126, "action": -1.808296799659729}
{"mode": "train", "epochs": 1, "timestep": 1417, "ep_reward": 700.8193359375, "reward": 0.430902361869812, "action": -1.1526943445205688}
{"mode": "train", "epochs": 1, "timestep": 1418, "ep_reward": 701.26171875, "reward": 0.44237715005874634, "action": -1.2121782302856445}
{"mode": "train", "epochs": 1, "timestep": 1419, "ep_reward": 701.7164916992188, "reward": 0.4547573924064636, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1420, "ep_reward": 702.1856079101562, "reward": 0.4690927267074585, "action": -1.2411549091339111}
{"mode": "train", "epochs": 1, "timestep": 1421, "ep_reward": 702.6702270507812, "reward": 0.4846072196960449, "action": -1.1715891361236572}
{"mode": "train", "epochs": 1, "timestep": 1422, "ep_reward": 703.1699829101562, "reward": 0.49978363513946533, "action": -0.6612197160720825}
{"mode": "train", "epochs": 1, "timestep": 1423, "ep_reward": 703.6831665039062, "reward": 0.5132137537002563, "action": -0.7950665950775146}
{"mode": "train", "epochs": 1, "timestep": 1424, "ep_reward": 704.2069702148438, "reward": 0.5237897634506226, "action": -0.932201623916626}
{"mode": "train", "epochs": 1, "timestep": 1425, "ep_reward": 704.7385864257812, "reward": 0.531611442565918, "action": -0.5351794958114624}
{"mode": "train", "epochs": 1, "timestep": 1426, "ep_reward": 705.274169921875, "reward": 0.5355687737464905, "action": -0.9971516728401184}
{"mode": "train", "epochs": 1, "timestep": 1427, "ep_reward": 705.810546875, "reward": 0.5363820791244507, "action": -0.7597898244857788}
{"mode": "train", "epochs": 1, "timestep": 1428, "ep_reward": 706.3441162109375, "reward": 0.5335770845413208, "action": -0.5833866596221924}
{"mode": "train", "epochs": 1, "timestep": 1429, "ep_reward": 706.8706665039062, "reward": 0.526570200920105, "action": -0.5887010097503662}
{"mode": "train", "epochs": 1, "timestep": 1430, "ep_reward": 707.3861694335938, "reward": 0.5154796242713928, "action": -1.6308403015136719}
{"mode": "train", "epochs": 1, "timestep": 1431, "ep_reward": 707.8912963867188, "reward": 0.5051096677780151, "action": -1.2744059562683105}
{"mode": "train", "epochs": 1, "timestep": 1432, "ep_reward": 708.3845825195312, "reward": 0.4933140277862549, "action": -1.38369882106781}
{"mode": "train", "epochs": 1, "timestep": 1433, "ep_reward": 708.8660888671875, "reward": 0.48148953914642334, "action": -0.9430934190750122}
{"mode": "train", "epochs": 1, "timestep": 1434, "ep_reward": 709.3341064453125, "reward": 0.4679974317550659, "action": -1.2692760229110718}
{"mode": "train", "epochs": 1, "timestep": 1435, "ep_reward": 709.789306640625, "reward": 0.45520448684692383, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1436, "ep_reward": 710.2357788085938, "reward": 0.44647490978240967, "action": -0.9027606248855591}
{"mode": "train", "epochs": 1, "timestep": 1437, "ep_reward": 710.6721801757812, "reward": 0.43642497062683105, "action": -1.2267115116119385}
{"mode": "train", "epochs": 1, "timestep": 1438, "ep_reward": 711.100341796875, "reward": 0.42818206548690796, "action": -1.3263659477233887}
{"mode": "train", "epochs": 1, "timestep": 1439, "ep_reward": 711.5224609375, "reward": 0.4221043586730957, "action": -0.7471252679824829}
{"mode": "train", "epochs": 1, "timestep": 1440, "ep_reward": 711.9385986328125, "reward": 0.4161374568939209, "action": -1.0584146976470947}
{"mode": "train", "epochs": 1, "timestep": 1441, "ep_reward": 712.3507080078125, "reward": 0.4121397137641907, "action": -1.0618759393692017}
{"mode": "train", "epochs": 1, "timestep": 1442, "ep_reward": 712.7607421875, "reward": 0.4100342392921448, "action": -0.7790931463241577}
{"mode": "train", "epochs": 1, "timestep": 1443, "ep_reward": 713.1696166992188, "reward": 0.4088985323905945, "action": -1.415224313735962}
{"mode": "train", "epochs": 1, "timestep": 1444, "ep_reward": 713.58056640625, "reward": 0.4109247922897339, "action": -0.8838610053062439}
{"mode": "train", "epochs": 1, "timestep": 1445, "ep_reward": 713.9948120117188, "reward": 0.41426223516464233, "action": -1.0576623678207397}
{"mode": "train", "epochs": 1, "timestep": 1446, "ep_reward": 714.4141845703125, "reward": 0.41937750577926636, "action": -0.6591858863830566}
{"mode": "train", "epochs": 1, "timestep": 1447, "ep_reward": 714.8392944335938, "reward": 0.42510998249053955, "action": -0.893291711807251}
{"mode": "train", "epochs": 1, "timestep": 1448, "ep_reward": 715.27099609375, "reward": 0.43171125650405884, "action": -0.6785996556282043}
{"mode": "train", "epochs": 1, "timestep": 1449, "ep_reward": 715.7095947265625, "reward": 0.4385707974433899, "action": -0.2820645570755005}
{"mode": "train", "epochs": 1, "timestep": 1450, "ep_reward": 716.1538696289062, "reward": 0.4442597031593323, "action": -1.6104518175125122}
{"mode": "train", "epochs": 1, "timestep": 1451, "ep_reward": 716.60546875, "reward": 0.45158910751342773, "action": -1.0431238412857056}
{"mode": "train", "epochs": 1, "timestep": 1452, "ep_reward": 717.0650024414062, "reward": 0.4595479965209961, "action": -1.2361023426055908}
{"mode": "train", "epochs": 1, "timestep": 1453, "ep_reward": 717.5330810546875, "reward": 0.46809154748916626, "action": 0.1328526735305786}
{"mode": "train", "epochs": 1, "timestep": 1454, "ep_reward": 718.0072021484375, "reward": 0.47411131858825684, "action": -0.4907067120075226}
{"mode": "train", "epochs": 1, "timestep": 1455, "ep_reward": 718.484619140625, "reward": 0.4774433374404907, "action": -1.7099850177764893}
{"mode": "train", "epochs": 1, "timestep": 1456, "ep_reward": 718.96630859375, "reward": 0.48168087005615234, "action": -1.8192410469055176}
{"mode": "train", "epochs": 1, "timestep": 1457, "ep_reward": 719.4536743164062, "reward": 0.48734545707702637, "action": -1.1470870971679688}
{"mode": "train", "epochs": 1, "timestep": 1458, "ep_reward": 719.9463500976562, "reward": 0.4926493167877197, "action": -1.0909405946731567}
{"mode": "train", "epochs": 1, "timestep": 1459, "ep_reward": 720.443359375, "reward": 0.49702250957489014, "action": -0.9832015037536621}
{"mode": "train", "epochs": 1, "timestep": 1460, "ep_reward": 720.9434204101562, "reward": 0.5000394582748413, "action": -0.5214241743087769}
{"mode": "train", "epochs": 1, "timestep": 1461, "ep_reward": 721.443603515625, "reward": 0.5001842975616455, "action": -1.23165762424469}
{"mode": "train", "epochs": 1, "timestep": 1462, "ep_reward": 721.943115234375, "reward": 0.4994913339614868, "action": -0.5061542987823486}
{"mode": "train", "epochs": 1, "timestep": 1463, "ep_reward": 722.4387817382812, "reward": 0.495694637298584, "action": -1.1894314289093018}
{"mode": "train", "epochs": 1, "timestep": 1464, "ep_reward": 722.9299926757812, "reward": 0.4912211298942566, "action": -1.4923056364059448}
{"mode": "train", "epochs": 1, "timestep": 1465, "ep_reward": 723.417236328125, "reward": 0.48723888397216797, "action": 0.11579352617263794}
{"mode": "train", "epochs": 1, "timestep": 1466, "ep_reward": 723.895263671875, "reward": 0.4780210256576538, "action": -1.067556381225586}
{"mode": "train", "epochs": 1, "timestep": 1467, "ep_reward": 724.3643798828125, "reward": 0.4690935015678406, "action": -0.7991456389427185}
{"mode": "train", "epochs": 1, "timestep": 1468, "ep_reward": 724.8233642578125, "reward": 0.45895546674728394, "action": -0.7137618064880371}
{"mode": "train", "epochs": 1, "timestep": 1469, "ep_reward": 725.2711791992188, "reward": 0.4478023052215576, "action": -1.4354195594787598}
{"mode": "train", "epochs": 1, "timestep": 1470, "ep_reward": 725.7102661132812, "reward": 0.43908578157424927, "action": -1.5564820766448975}
{"mode": "train", "epochs": 1, "timestep": 1471, "ep_reward": 726.1428833007812, "reward": 0.43260687589645386, "action": -1.9222990274429321}
{"mode": "train", "epochs": 1, "timestep": 1472, "ep_reward": 726.5728149414062, "reward": 0.4299513101577759, "action": -0.8029620051383972}
{"mode": "train", "epochs": 1, "timestep": 1473, "ep_reward": 726.9998168945312, "reward": 0.42697250843048096, "action": -1.2965692281723022}
{"mode": "train", "epochs": 1, "timestep": 1474, "ep_reward": 727.4259643554688, "reward": 0.4261186122894287, "action": -1.6930855512619019}
{"mode": "train", "epochs": 1, "timestep": 1475, "ep_reward": 727.8543701171875, "reward": 0.42842936515808105, "action": -1.2084376811981201}
{"mode": "train", "epochs": 1, "timestep": 1476, "ep_reward": 728.2866821289062, "reward": 0.43228238821029663, "action": -1.2046023607254028}
{"mode": "train", "epochs": 1, "timestep": 1477, "ep_reward": 728.724365234375, "reward": 0.4376985430717468, "action": -0.567622184753418}
{"mode": "train", "epochs": 1, "timestep": 1478, "ep_reward": 729.1671752929688, "reward": 0.4428331255912781, "action": -1.4924860000610352}
{"mode": "train", "epochs": 1, "timestep": 1479, "ep_reward": 729.6167602539062, "reward": 0.44960731267929077, "action": -0.8701412081718445}
{"mode": "train", "epochs": 1, "timestep": 1480, "ep_reward": 730.0734252929688, "reward": 0.45667970180511475, "action": -0.7135513424873352}
{"mode": "train", "epochs": 1, "timestep": 1481, "ep_reward": 730.5364990234375, "reward": 0.4630674123764038, "action": -1.3536852598190308}
{"mode": "train", "epochs": 1, "timestep": 1482, "ep_reward": 731.0065307617188, "reward": 0.4700409770011902, "action": -0.32266026735305786}
{"mode": "train", "epochs": 1, "timestep": 1483, "ep_reward": 731.4818115234375, "reward": 0.4752655029296875, "action": -1.0032479763031006}
{"mode": "train", "epochs": 1, "timestep": 1484, "ep_reward": 731.9613647460938, "reward": 0.47957682609558105, "action": -0.714846134185791}
{"mode": "train", "epochs": 1, "timestep": 1485, "ep_reward": 732.4437866210938, "reward": 0.48240143060684204, "action": -1.0717589855194092}
{"mode": "train", "epochs": 1, "timestep": 1486, "ep_reward": 732.9283447265625, "reward": 0.4845445156097412, "action": -0.4692021608352661}
{"mode": "train", "epochs": 1, "timestep": 1487, "ep_reward": 733.4126586914062, "reward": 0.4843176603317261, "action": -0.5087405443191528}
{"mode": "train", "epochs": 1, "timestep": 1488, "ep_reward": 733.8941650390625, "reward": 0.4815346598625183, "action": -1.610412836074829}
{"mode": "train", "epochs": 1, "timestep": 1489, "ep_reward": 734.3741455078125, "reward": 0.47998249530792236, "action": -1.3320766687393188}
{"mode": "train", "epochs": 1, "timestep": 1490, "ep_reward": 734.8526611328125, "reward": 0.47853195667266846, "action": -0.9344260096549988}
{"mode": "train", "epochs": 1, "timestep": 1491, "ep_reward": 735.3287353515625, "reward": 0.47604382038116455, "action": -1.2303776741027832}
{"mode": "train", "epochs": 1, "timestep": 1492, "ep_reward": 735.8024291992188, "reward": 0.47370338439941406, "action": -1.0791773796081543}
{"mode": "train", "epochs": 1, "timestep": 1493, "ep_reward": 736.2734375, "reward": 0.47102171182632446, "action": -0.9347477555274963}
{"mode": "train", "epochs": 1, "timestep": 1494, "ep_reward": 736.7411499023438, "reward": 0.4677296280860901, "action": -0.1989452838897705}
{"mode": "train", "epochs": 1, "timestep": 1495, "ep_reward": 737.20263671875, "reward": 0.46151047945022583, "action": -0.34232139587402344}
{"mode": "train", "epochs": 1, "timestep": 1496, "ep_reward": 737.6558837890625, "reward": 0.4532482624053955, "action": -0.9833078384399414}
{"mode": "train", "epochs": 1, "timestep": 1497, "ep_reward": 738.1015625, "reward": 0.44569873809814453, "action": -0.46965062618255615}
{"mode": "train", "epochs": 1, "timestep": 1498, "ep_reward": 738.5380859375, "reward": 0.43653059005737305, "action": -1.7346713542938232}
{"mode": "train", "epochs": 1, "timestep": 1499, "ep_reward": 738.9696044921875, "reward": 0.43150240182876587, "action": -1.1694644689559937}
{"mode": "train", "epochs": 1, "timestep": 1500, "ep_reward": 739.3970947265625, "reward": 0.42746859788894653, "action": 0.056621015071868896}
{"mode": "train", "epochs": 1, "timestep": 1501, "ep_reward": 739.8179931640625, "reward": 0.42088472843170166, "action": -0.7271473407745361}
{"mode": "train", "epochs": 1, "timestep": 1502, "ep_reward": 740.2332763671875, "reward": 0.41526126861572266, "action": -1.7935645580291748}
{"mode": "train", "epochs": 1, "timestep": 1503, "ep_reward": 740.6474609375, "reward": 0.4141994118690491, "action": -1.0894986391067505}
{"mode": "train", "epochs": 1, "timestep": 1504, "ep_reward": 741.0618896484375, "reward": 0.4144149422645569, "action": -1.788806676864624}
{"mode": "train", "epochs": 1, "timestep": 1505, "ep_reward": 741.4804077148438, "reward": 0.4185072183609009, "action": -0.9351499080657959}
{"mode": "train", "epochs": 1, "timestep": 1506, "ep_reward": 741.9042358398438, "reward": 0.42384248971939087, "action": -1.1299165487289429}
{"mode": "train", "epochs": 1, "timestep": 1507, "ep_reward": 742.3349609375, "reward": 0.43072450160980225, "action": -1.0452423095703125}
{"mode": "train", "epochs": 1, "timestep": 1508, "ep_reward": 742.7737426757812, "reward": 0.438787043094635, "action": -0.9218956232070923}
{"mode": "train", "epochs": 1, "timestep": 1509, "ep_reward": 743.2211303710938, "reward": 0.44740843772888184, "action": -1.2022249698638916}
{"mode": "train", "epochs": 1, "timestep": 1510, "ep_reward": 743.677978515625, "reward": 0.45687174797058105, "action": -0.25099217891693115}
{"mode": "train", "epochs": 1, "timestep": 1511, "ep_reward": 744.14306640625, "reward": 0.4650880694389343, "action": -0.7841337323188782}
{"mode": "train", "epochs": 1, "timestep": 1512, "ep_reward": 744.614990234375, "reward": 0.4719167947769165, "action": -1.5915796756744385}
{"mode": "train", "epochs": 1, "timestep": 1513, "ep_reward": 745.094482421875, "reward": 0.4794995188713074, "action": -1.0477930307388306}
{"mode": "train", "epochs": 1, "timestep": 1514, "ep_reward": 745.581298828125, "reward": 0.4867955446243286, "action": -1.0841532945632935}
{"mode": "train", "epochs": 1, "timestep": 1515, "ep_reward": 746.0745239257812, "reward": 0.4932260513305664, "action": -1.4858579635620117}
{"mode": "train", "epochs": 1, "timestep": 1516, "ep_reward": 746.573974609375, "reward": 0.49945884943008423, "action": -1.8071542978286743}
{"mode": "train", "epochs": 1, "timestep": 1517, "ep_reward": 747.0801391601562, "reward": 0.5061909556388855, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1518, "ep_reward": 747.5941162109375, "reward": 0.5139734148979187, "action": -0.7509291768074036}
{"mode": "train", "epochs": 1, "timestep": 1519, "ep_reward": 748.1138916015625, "reward": 0.5197968482971191, "action": -1.3860416412353516}
{"mode": "train", "epochs": 1, "timestep": 1520, "ep_reward": 748.6380004882812, "reward": 0.5240921974182129, "action": -1.3319730758666992}
{"mode": "train", "epochs": 1, "timestep": 1521, "ep_reward": 749.1649780273438, "reward": 0.5269749760627747, "action": -1.1994919776916504}
{"mode": "train", "epochs": 1, "timestep": 1522, "ep_reward": 749.6929931640625, "reward": 0.5279892683029175, "action": -0.8752061724662781}
{"mode": "train", "epochs": 1, "timestep": 1523, "ep_reward": 750.2190551757812, "reward": 0.5260368585586548, "action": -1.2120083570480347}
{"mode": "train", "epochs": 1, "timestep": 1524, "ep_reward": 750.7412719726562, "reward": 0.5222435593605042, "action": -1.0211148262023926}
{"mode": "train", "epochs": 1, "timestep": 1525, "ep_reward": 751.25732421875, "reward": 0.5160448551177979, "action": -1.0626287460327148}
{"mode": "train", "epochs": 1, "timestep": 1526, "ep_reward": 751.76513671875, "reward": 0.5078330039978027, "action": -1.36176598072052}
{"mode": "train", "epochs": 1, "timestep": 1527, "ep_reward": 752.2642822265625, "reward": 0.4991708993911743, "action": 0.07460498809814453}
{"mode": "train", "epochs": 1, "timestep": 1528, "ep_reward": 752.7486572265625, "reward": 0.4843764901161194, "action": -0.44599950313568115}
{"mode": "train", "epochs": 1, "timestep": 1529, "ep_reward": 753.2158813476562, "reward": 0.46725034713745117, "action": -1.374578833580017}
{"mode": "train", "epochs": 1, "timestep": 1530, "ep_reward": 753.6682739257812, "reward": 0.45237189531326294, "action": -0.8246846199035645}
{"mode": "train", "epochs": 1, "timestep": 1531, "ep_reward": 754.1045532226562, "reward": 0.43628793954849243, "action": -0.5750948786735535}
{"mode": "train", "epochs": 1, "timestep": 1532, "ep_reward": 754.52392578125, "reward": 0.4193466901779175, "action": -0.976103663444519}
{"mode": "train", "epochs": 1, "timestep": 1533, "ep_reward": 754.928466796875, "reward": 0.4045141339302063, "action": -0.5923632979393005}
{"mode": "train", "epochs": 1, "timestep": 1534, "ep_reward": 755.318359375, "reward": 0.3898909091949463, "action": -0.624656081199646}
{"mode": "train", "epochs": 1, "timestep": 1535, "ep_reward": 755.7014770507812, "reward": 0.38313788175582886, "action": -1.5095322132110596}
{"mode": "train", "epochs": 1, "timestep": 1536, "ep_reward": 756.0953979492188, "reward": 0.39390599727630615, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1537, "ep_reward": 756.4935913085938, "reward": 0.3982217311859131, "action": -0.5864291191101074}
{"mode": "train", "epochs": 1, "timestep": 1538, "ep_reward": 756.8925170898438, "reward": 0.3989318609237671, "action": -0.23251330852508545}
{"mode": "train", "epochs": 1, "timestep": 1539, "ep_reward": 757.2907104492188, "reward": 0.39819252490997314, "action": -0.7891339063644409}
{"mode": "train", "epochs": 1, "timestep": 1540, "ep_reward": 757.6851806640625, "reward": 0.3944544792175293, "action": -0.4088442325592041}
{"mode": "train", "epochs": 1, "timestep": 1541, "ep_reward": 758.0740966796875, "reward": 0.3889455199241638, "action": -1.1370898485183716}
{"mode": "train", "epochs": 1, "timestep": 1542, "ep_reward": 758.45849609375, "reward": 0.3843696117401123, "action": -0.25274163484573364}
{"mode": "train", "epochs": 1, "timestep": 1543, "ep_reward": 758.85205078125, "reward": 0.3935839533805847, "action": -0.5710383653640747}
{"mode": "train", "epochs": 1, "timestep": 1544, "ep_reward": 759.2557983398438, "reward": 0.40375226736068726, "action": -0.4074941873550415}
{"mode": "train", "epochs": 1, "timestep": 1545, "ep_reward": 759.6702270507812, "reward": 0.41443127393722534, "action": -0.524897575378418}
{"mode": "train", "epochs": 1, "timestep": 1546, "ep_reward": 760.0955200195312, "reward": 0.42529040575027466, "action": -0.7768352627754211}
{"mode": "train", "epochs": 1, "timestep": 1547, "ep_reward": 760.5320434570312, "reward": 0.4365314841270447, "action": -0.578096866607666}
{"mode": "train", "epochs": 1, "timestep": 1548, "ep_reward": 760.9796142578125, "reward": 0.4475599527359009, "action": -1.1736907958984375}
{"mode": "train", "epochs": 1, "timestep": 1549, "ep_reward": 761.4385986328125, "reward": 0.4589555859565735, "action": -0.2879413366317749}
{"mode": "train", "epochs": 1, "timestep": 1550, "ep_reward": 761.9078369140625, "reward": 0.4692569971084595, "action": -0.7362304925918579}
{"mode": "train", "epochs": 1, "timestep": 1551, "ep_reward": 762.3856811523438, "reward": 0.4778464436531067, "action": -1.5670692920684814}
{"mode": "train", "epochs": 1, "timestep": 1552, "ep_reward": 762.8724975585938, "reward": 0.48680245876312256, "action": 0.011312305927276611}
{"mode": "train", "epochs": 1, "timestep": 1553, "ep_reward": 763.3655395507812, "reward": 0.4930267930030823, "action": -1.2999851703643799}
{"mode": "train", "epochs": 1, "timestep": 1554, "ep_reward": 763.8635864257812, "reward": 0.4980429410934448, "action": -0.46510839462280273}
{"mode": "train", "epochs": 1, "timestep": 1555, "ep_reward": 764.3639526367188, "reward": 0.5003629922866821, "action": -1.2757025957107544}
{"mode": "train", "epochs": 1, "timestep": 1556, "ep_reward": 764.86572265625, "reward": 0.5017761588096619, "action": -0.7737547159194946}
{"mode": "train", "epochs": 1, "timestep": 1557, "ep_reward": 765.3667602539062, "reward": 0.5010143518447876, "action": -0.6420259475708008}
{"mode": "train", "epochs": 1, "timestep": 1558, "ep_reward": 765.8643798828125, "reward": 0.49759364128112793, "action": -0.7477133274078369}
{"mode": "train", "epochs": 1, "timestep": 1559, "ep_reward": 766.3563232421875, "reward": 0.4919707775115967, "action": -0.8958280682563782}
{"mode": "train", "epochs": 1, "timestep": 1560, "ep_reward": 766.8411865234375, "reward": 0.48486167192459106, "action": -0.9690714478492737}
{"mode": "train", "epochs": 1, "timestep": 1561, "ep_reward": 767.3177490234375, "reward": 0.4765487313270569, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1562, "ep_reward": 767.7890625, "reward": 0.47134095430374146, "action": -1.6164181232452393}
{"mode": "train", "epochs": 1, "timestep": 1563, "ep_reward": 768.2561645507812, "reward": 0.4670805335044861, "action": -0.7584073543548584}
{"mode": "train", "epochs": 1, "timestep": 1564, "ep_reward": 768.7174682617188, "reward": 0.46129196882247925, "action": -0.7952890992164612}
{"mode": "train", "epochs": 1, "timestep": 1565, "ep_reward": 769.1723022460938, "reward": 0.4548579454421997, "action": -0.8978753685951233}
{"mode": "train", "epochs": 1, "timestep": 1566, "ep_reward": 769.62060546875, "reward": 0.44830894470214844, "action": -1.3683714866638184}
{"mode": "train", "epochs": 1, "timestep": 1567, "ep_reward": 770.0642700195312, "reward": 0.4436541199684143, "action": -0.001839756965637207}
{"mode": "train", "epochs": 1, "timestep": 1568, "ep_reward": 770.5000610351562, "reward": 0.4358159303665161, "action": -0.6961320638656616}
{"mode": "train", "epochs": 1, "timestep": 1569, "ep_reward": 770.928466796875, "reward": 0.4284166693687439, "action": -1.0213136672973633}
{"mode": "train", "epochs": 1, "timestep": 1570, "ep_reward": 771.3508911132812, "reward": 0.4224233031272888, "action": -1.4594110250473022}
{"mode": "train", "epochs": 1, "timestep": 1571, "ep_reward": 771.7702026367188, "reward": 0.419314444065094, "action": -1.5248548984527588}
{"mode": "train", "epochs": 1, "timestep": 1572, "ep_reward": 772.1892700195312, "reward": 0.4190855622291565, "action": -0.797285795211792}
{"mode": "train", "epochs": 1, "timestep": 1573, "ep_reward": 772.6087036132812, "reward": 0.41940468549728394, "action": -1.4268574714660645}
{"mode": "train", "epochs": 1, "timestep": 1574, "ep_reward": 773.0311889648438, "reward": 0.422473669052124, "action": -0.6462787389755249}
{"mode": "train", "epochs": 1, "timestep": 1575, "ep_reward": 773.45703125, "reward": 0.4258502721786499, "action": -1.3656437397003174}
{"mode": "train", "epochs": 1, "timestep": 1576, "ep_reward": 773.8883056640625, "reward": 0.43128907680511475, "action": -1.230677843093872}
{"mode": "train", "epochs": 1, "timestep": 1577, "ep_reward": 774.32666015625, "reward": 0.438368558883667, "action": -0.9942018389701843}
{"mode": "train", "epochs": 1, "timestep": 1578, "ep_reward": 774.7728271484375, "reward": 0.4461830258369446, "action": -1.6388812065124512}
{"mode": "train", "epochs": 1, "timestep": 1579, "ep_reward": 775.2286376953125, "reward": 0.45583009719848633, "action": -0.9439374804496765}
{"mode": "train", "epochs": 1, "timestep": 1580, "ep_reward": 775.6945190429688, "reward": 0.46586644649505615, "action": -1.5435576438903809}
{"mode": "train", "epochs": 1, "timestep": 1581, "ep_reward": 776.1712036132812, "reward": 0.476667582988739, "action": -0.8954158425331116}
{"mode": "train", "epochs": 1, "timestep": 1582, "ep_reward": 776.6583862304688, "reward": 0.48717498779296875, "action": -0.6679623126983643}
{"mode": "train", "epochs": 1, "timestep": 1583, "ep_reward": 777.1541137695312, "reward": 0.49569785594940186, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1584, "ep_reward": 777.6588745117188, "reward": 0.5047652721405029, "action": -0.6468328237533569}
{"mode": "train", "epochs": 1, "timestep": 1585, "ep_reward": 778.171142578125, "reward": 0.5122451186180115, "action": -0.687143087387085}
{"mode": "train", "epochs": 1, "timestep": 1586, "ep_reward": 778.6879272460938, "reward": 0.5167644023895264, "action": -0.5160279870033264}
{"mode": "train", "epochs": 1, "timestep": 1587, "ep_reward": 779.2056274414062, "reward": 0.5177234411239624, "action": -0.41735219955444336}
{"mode": "train", "epochs": 1, "timestep": 1588, "ep_reward": 779.7201538085938, "reward": 0.5145165324211121, "action": -1.5264054536819458}
{"mode": "train", "epochs": 1, "timestep": 1589, "ep_reward": 780.231201171875, "reward": 0.5110715627670288, "action": -0.821439266204834}
{"mode": "train", "epochs": 1, "timestep": 1590, "ep_reward": 780.7359619140625, "reward": 0.5047358274459839, "action": -1.6095473766326904}
{"mode": "train", "epochs": 1, "timestep": 1591, "ep_reward": 781.2349853515625, "reward": 0.49903547763824463, "action": -0.6402225494384766}
{"mode": "train", "epochs": 1, "timestep": 1592, "ep_reward": 781.72509765625, "reward": 0.4900985360145569, "action": -0.7028021812438965}
{"mode": "train", "epochs": 1, "timestep": 1593, "ep_reward": 782.2041625976562, "reward": 0.4790719747543335, "action": -1.0724984407424927}
{"mode": "train", "epochs": 1, "timestep": 1594, "ep_reward": 782.6720581054688, "reward": 0.46790462732315063, "action": -0.6896389722824097}
{"mode": "train", "epochs": 1, "timestep": 1595, "ep_reward": 783.1270751953125, "reward": 0.45504671335220337, "action": -0.49404093623161316}
{"mode": "train", "epochs": 1, "timestep": 1596, "ep_reward": 783.567626953125, "reward": 0.4405370354652405, "action": -1.0047105550765991}
{"mode": "train", "epochs": 1, "timestep": 1597, "ep_reward": 783.9949951171875, "reward": 0.4273694157600403, "action": -1.428252935409546}
{"mode": "train", "epochs": 1, "timestep": 1598, "ep_reward": 784.4122314453125, "reward": 0.41725683212280273, "action": -0.3051741123199463}
{"mode": "train", "epochs": 1, "timestep": 1599, "ep_reward": 784.8174438476562, "reward": 0.4052072763442993, "action": -0.9756288528442383}
{"mode": "train", "epochs": 1, "timestep": 1600, "ep_reward": 785.2133178710938, "reward": 0.39584654569625854, "action": -1.3744597434997559}
{"mode": "train", "epochs": 1, "timestep": 1601, "ep_reward": 785.603515625, "reward": 0.3901926875114441, "action": -1.4031645059585571}
{"mode": "train", "epochs": 1, "timestep": 1602, "ep_reward": 785.9915771484375, "reward": 0.3880733251571655, "action": -0.542207658290863}
{"mode": "train", "epochs": 1, "timestep": 1603, "ep_reward": 786.3783569335938, "reward": 0.38677042722702026, "action": -0.07099413871765137}
{"mode": "train", "epochs": 1, "timestep": 1604, "ep_reward": 786.763671875, "reward": 0.3853221535682678, "action": -1.2905282974243164}
{"mode": "train", "epochs": 1, "timestep": 1605, "ep_reward": 787.1513671875, "reward": 0.38767552375793457, "action": -0.8615562915802002}
{"mode": "train", "epochs": 1, "timestep": 1606, "ep_reward": 787.54345703125, "reward": 0.39207160472869873, "action": -1.1138098239898682}
{"mode": "train", "epochs": 1, "timestep": 1607, "ep_reward": 787.9425048828125, "reward": 0.39905476570129395, "action": -1.11989426612854}
{"mode": "train", "epochs": 1, "timestep": 1608, "ep_reward": 788.3508911132812, "reward": 0.40840500593185425, "action": -1.1371171474456787}
{"mode": "train", "epochs": 1, "timestep": 1609, "ep_reward": 788.7706909179688, "reward": 0.4197882413864136, "action": -1.412093162536621}
{"mode": "train", "epochs": 1, "timestep": 1610, "ep_reward": 789.2040405273438, "reward": 0.43337947130203247, "action": -0.7511410713195801}
{"mode": "train", "epochs": 1, "timestep": 1611, "ep_reward": 789.6519775390625, "reward": 0.4479603171348572, "action": -0.7651445865631104}
{"mode": "train", "epochs": 1, "timestep": 1612, "ep_reward": 790.1141967773438, "reward": 0.46222156286239624, "action": -1.0511456727981567}
{"mode": "train", "epochs": 1, "timestep": 1613, "ep_reward": 790.59033203125, "reward": 0.47613805532455444, "action": -0.699088454246521}
{"mode": "train", "epochs": 1, "timestep": 1614, "ep_reward": 791.079345703125, "reward": 0.48901963233947754, "action": -0.8491315841674805}
{"mode": "train", "epochs": 1, "timestep": 1615, "ep_reward": 791.5795288085938, "reward": 0.5001928210258484, "action": -0.35252612829208374}
{"mode": "train", "epochs": 1, "timestep": 1616, "ep_reward": 792.0878295898438, "reward": 0.5083092451095581, "action": -1.637467384338379}
{"mode": "train", "epochs": 1, "timestep": 1617, "ep_reward": 792.603271484375, "reward": 0.5154715776443481, "action": -0.7428785562515259}
{"mode": "train", "epochs": 1, "timestep": 1618, "ep_reward": 793.1236572265625, "reward": 0.5203613042831421, "action": -1.1209391355514526}
{"mode": "train", "epochs": 1, "timestep": 1619, "ep_reward": 793.6468505859375, "reward": 0.5231691002845764, "action": -0.4192747473716736}
{"mode": "train", "epochs": 1, "timestep": 1620, "ep_reward": 794.168701171875, "reward": 0.5218707919120789, "action": -1.650395154953003}
{"mode": "train", "epochs": 1, "timestep": 1621, "ep_reward": 794.6889038085938, "reward": 0.5202171802520752, "action": -1.0650898218154907}
{"mode": "train", "epochs": 1, "timestep": 1622, "ep_reward": 795.2052001953125, "reward": 0.516291618347168, "action": -1.2666358947753906}
{"mode": "train", "epochs": 1, "timestep": 1623, "ep_reward": 795.7163696289062, "reward": 0.5111580491065979, "action": -0.28475427627563477}
{"mode": "train", "epochs": 1, "timestep": 1624, "ep_reward": 796.2177124023438, "reward": 0.5013667345046997, "action": -0.3260399103164673}
{"mode": "train", "epochs": 1, "timestep": 1625, "ep_reward": 796.7054443359375, "reward": 0.48773181438446045, "action": -1.070109248161316}
{"mode": "train", "epochs": 1, "timestep": 1626, "ep_reward": 797.1795043945312, "reward": 0.47404396533966064, "action": -0.7587565183639526}
{"mode": "train", "epochs": 1, "timestep": 1627, "ep_reward": 797.6381225585938, "reward": 0.45862406492233276, "action": -0.4360753893852234}
{"mode": "train", "epochs": 1, "timestep": 1628, "ep_reward": 798.0791015625, "reward": 0.44095778465270996, "action": -1.0463483333587646}
{"mode": "train", "epochs": 1, "timestep": 1629, "ep_reward": 798.5042114257812, "reward": 0.425088107585907, "action": -1.0105572938919067}
{"mode": "train", "epochs": 1, "timestep": 1630, "ep_reward": 798.9144897460938, "reward": 0.4102969169616699, "action": -1.6537728309631348}
{"mode": "train", "epochs": 1, "timestep": 1631, "ep_reward": 799.314697265625, "reward": 0.4002154469490051, "action": -0.6292667984962463}
{"mode": "train", "epochs": 1, "timestep": 1632, "ep_reward": 799.704345703125, "reward": 0.3896564245223999, "action": -1.2444705963134766}
{"mode": "train", "epochs": 1, "timestep": 1633, "ep_reward": 800.0874633789062, "reward": 0.3831052780151367, "action": -0.1627524495124817}
{"mode": "train", "epochs": 1, "timestep": 1634, "ep_reward": 800.47607421875, "reward": 0.3886038661003113, "action": -0.35091036558151245}
{"mode": "train", "epochs": 1, "timestep": 1635, "ep_reward": 800.870849609375, "reward": 0.39478135108947754, "action": -0.7168979644775391}
{"mode": "train", "epochs": 1, "timestep": 1636, "ep_reward": 801.2693481445312, "reward": 0.3985070586204529, "action": -0.9862169623374939}
{"mode": "train", "epochs": 1, "timestep": 1637, "ep_reward": 801.66796875, "reward": 0.3986462950706482, "action": -0.5482993721961975}
{"mode": "train", "epochs": 1, "timestep": 1638, "ep_reward": 802.064208984375, "reward": 0.3962501883506775, "action": -1.019692063331604}
{"mode": "train", "epochs": 1, "timestep": 1639, "ep_reward": 802.4542846679688, "reward": 0.39009833335876465, "action": -0.4408192038536072}
{"mode": "train", "epochs": 1, "timestep": 1640, "ep_reward": 802.83642578125, "reward": 0.3821709156036377, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1641, "ep_reward": 803.229736328125, "reward": 0.3933400511741638, "action": 0.22034978866577148}
{"mode": "train", "epochs": 1, "timestep": 1642, "ep_reward": 803.6354370117188, "reward": 0.405714750289917, "action": -0.7972772121429443}
{"mode": "train", "epochs": 1, "timestep": 1643, "ep_reward": 804.0537109375, "reward": 0.4182945489883423, "action": -0.9626114368438721}
{"mode": "train", "epochs": 1, "timestep": 1644, "ep_reward": 804.485595703125, "reward": 0.43190228939056396, "action": -1.6450411081314087}
{"mode": "train", "epochs": 1, "timestep": 1645, "ep_reward": 804.9329833984375, "reward": 0.44737768173217773, "action": -0.8349547386169434}
{"mode": "train", "epochs": 1, "timestep": 1646, "ep_reward": 805.3968505859375, "reward": 0.4638369083404541, "action": -1.3192026615142822}
{"mode": "train", "epochs": 1, "timestep": 1647, "ep_reward": 805.8771362304688, "reward": 0.4802793264389038, "action": -0.5157678127288818}
{"mode": "train", "epochs": 1, "timestep": 1648, "ep_reward": 806.3729248046875, "reward": 0.495802104473114, "action": -0.9017998576164246}
{"mode": "train", "epochs": 1, "timestep": 1649, "ep_reward": 806.8819580078125, "reward": 0.5090183019638062, "action": -1.1385637521743774}
{"mode": "train", "epochs": 1, "timestep": 1650, "ep_reward": 807.40234375, "reward": 0.5204116106033325, "action": -1.3870024681091309}
{"mode": "train", "epochs": 1, "timestep": 1651, "ep_reward": 807.9327392578125, "reward": 0.5304111242294312, "action": -0.9375676512718201}
{"mode": "train", "epochs": 1, "timestep": 1652, "ep_reward": 808.4706420898438, "reward": 0.5379040241241455, "action": -1.6710125207901}
{"mode": "train", "epochs": 1, "timestep": 1653, "ep_reward": 809.0145874023438, "reward": 0.543933093547821, "action": -1.014096975326538}
{"mode": "train", "epochs": 1, "timestep": 1654, "ep_reward": 809.5618286132812, "reward": 0.5472617745399475, "action": -0.7908108234405518}
{"mode": "train", "epochs": 1, "timestep": 1655, "ep_reward": 810.1083984375, "reward": 0.5465717315673828, "action": -1.5951387882232666}
{"mode": "train", "epochs": 1, "timestep": 1656, "ep_reward": 810.65283203125, "reward": 0.5444061756134033, "action": -0.9204636216163635}
{"mode": "train", "epochs": 1, "timestep": 1657, "ep_reward": 811.19140625, "reward": 0.538580060005188, "action": -1.2179995775222778}
{"mode": "train", "epochs": 1, "timestep": 1658, "ep_reward": 811.721923828125, "reward": 0.5305195450782776, "action": -0.9920160174369812}
{"mode": "train", "epochs": 1, "timestep": 1659, "ep_reward": 812.2412109375, "reward": 0.5193116664886475, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1660, "ep_reward": 812.7511596679688, "reward": 0.5099451541900635, "action": -0.872194766998291}
{"mode": "train", "epochs": 1, "timestep": 1661, "ep_reward": 813.248046875, "reward": 0.49687379598617554, "action": -1.3037444353103638}
{"mode": "train", "epochs": 1, "timestep": 1662, "ep_reward": 813.7318115234375, "reward": 0.4837941527366638, "action": -0.9167852997779846}
{"mode": "train", "epochs": 1, "timestep": 1663, "ep_reward": 814.2008056640625, "reward": 0.46897727251052856, "action": -0.6054675579071045}
{"mode": "train", "epochs": 1, "timestep": 1664, "ep_reward": 814.6528930664062, "reward": 0.45210540294647217, "action": -0.6341904401779175}
{"mode": "train", "epochs": 1, "timestep": 1665, "ep_reward": 815.0872802734375, "reward": 0.43439602851867676, "action": -0.7972689270973206}
{"mode": "train", "epochs": 1, "timestep": 1666, "ep_reward": 815.5045776367188, "reward": 0.4173106551170349, "action": 0.05444931983947754}
{"mode": "train", "epochs": 1, "timestep": 1667, "ep_reward": 815.901611328125, "reward": 0.39704883098602295, "action": -1.4386024475097656}
{"mode": "train", "epochs": 1, "timestep": 1668, "ep_reward": 816.2847900390625, "reward": 0.3831554651260376, "action": -1.0107544660568237}
{"mode": "train", "epochs": 1, "timestep": 1669, "ep_reward": 816.6740112304688, "reward": 0.3891913890838623, "action": -1.065021276473999}
{"mode": "train", "epochs": 1, "timestep": 1670, "ep_reward": 817.0742797851562, "reward": 0.40026211738586426, "action": -0.7411555647850037}
{"mode": "train", "epochs": 1, "timestep": 1671, "ep_reward": 817.4819946289062, "reward": 0.4077313542366028, "action": -1.682206630706787}
{"mode": "train", "epochs": 1, "timestep": 1672, "ep_reward": 817.8916625976562, "reward": 0.40963876247406006, "action": -0.8272993564605713}
{"mode": "train", "epochs": 1, "timestep": 1673, "ep_reward": 818.298828125, "reward": 0.40717756748199463, "action": -1.009726643562317}
{"mode": "train", "epochs": 1, "timestep": 1674, "ep_reward": 818.69921875, "reward": 0.4003872871398926, "action": -1.3311400413513184}
{"mode": "train", "epochs": 1, "timestep": 1675, "ep_reward": 819.0875244140625, "reward": 0.38832688331604004, "action": -1.2500168085098267}
{"mode": "train", "epochs": 1, "timestep": 1676, "ep_reward": 819.474609375, "reward": 0.38706618547439575, "action": -1.3532648086547852}
{"mode": "train", "epochs": 1, "timestep": 1677, "ep_reward": 819.8779907226562, "reward": 0.4033702611923218, "action": -1.3081529140472412}
{"mode": "train", "epochs": 1, "timestep": 1678, "ep_reward": 820.3002319335938, "reward": 0.42224013805389404, "action": -1.6045093536376953}
{"mode": "train", "epochs": 1, "timestep": 1679, "ep_reward": 820.7435913085938, "reward": 0.44336676597595215, "action": -0.7760056257247925}
{"mode": "train", "epochs": 1, "timestep": 1680, "ep_reward": 821.2095336914062, "reward": 0.4659426808357239, "action": -1.3532159328460693}
{"mode": "train", "epochs": 1, "timestep": 1681, "ep_reward": 821.697509765625, "reward": 0.4879545569419861, "action": -0.6572401523590088}
{"mode": "train", "epochs": 1, "timestep": 1682, "ep_reward": 822.2067260742188, "reward": 0.5091995000839233, "action": -1.882650375366211}
{"mode": "train", "epochs": 1, "timestep": 1683, "ep_reward": 822.7352905273438, "reward": 0.528549075126648, "action": -1.2115086317062378}
{"mode": "train", "epochs": 1, "timestep": 1684, "ep_reward": 823.2825317382812, "reward": 0.5472171902656555, "action": -1.0486077070236206}
{"mode": "train", "epochs": 1, "timestep": 1685, "ep_reward": 823.8455200195312, "reward": 0.5630098581314087, "action": -0.9400042295455933}
{"mode": "train", "epochs": 1, "timestep": 1686, "ep_reward": 824.42041015625, "reward": 0.5748800039291382, "action": -0.5695140361785889}
{"mode": "train", "epochs": 1, "timestep": 1687, "ep_reward": 825.0017700195312, "reward": 0.58137446641922, "action": -1.1758265495300293}
{"mode": "train", "epochs": 1, "timestep": 1688, "ep_reward": 825.5849609375, "reward": 0.5831916332244873, "action": -1.278947353363037}
{"mode": "train", "epochs": 1, "timestep": 1689, "ep_reward": 826.1661376953125, "reward": 0.5811785459518433, "action": -0.7625963091850281}
{"mode": "train", "epochs": 1, "timestep": 1690, "ep_reward": 826.7396850585938, "reward": 0.5735534429550171, "action": -1.5935044288635254}
{"mode": "train", "epochs": 1, "timestep": 1691, "ep_reward": 827.3035888671875, "reward": 0.5638883113861084, "action": -0.4507461190223694}
{"mode": "train", "epochs": 1, "timestep": 1692, "ep_reward": 827.8508911132812, "reward": 0.5473076105117798, "action": -0.6838361620903015}
{"mode": "train", "epochs": 1, "timestep": 1693, "ep_reward": 828.3772583007812, "reward": 0.5263539552688599, "action": 0.35363006591796875}
{"mode": "train", "epochs": 1, "timestep": 1694, "ep_reward": 828.873291015625, "reward": 0.49605226516723633, "action": 1.3492119312286377}
{"mode": "train", "epochs": 1, "timestep": 1695, "ep_reward": 829.3265991210938, "reward": 0.4532930850982666, "action": 1.0991061925888062}
{"mode": "train", "epochs": 1, "timestep": 1696, "ep_reward": 829.7298583984375, "reward": 0.4032689332962036, "action": 1.529295563697815}
{"mode": "train", "epochs": 1, "timestep": 1697, "ep_reward": 830.0742797851562, "reward": 0.3444454073905945, "action": 1.2234059572219849}
{"mode": "train", "epochs": 1, "timestep": 1698, "ep_reward": 830.4608764648438, "reward": 0.38659149408340454, "action": 1.5658727884292603}
{"mode": "train", "epochs": 1, "timestep": 1699, "ep_reward": 830.8956298828125, "reward": 0.4347308874130249, "action": 1.1098053455352783}
{"mode": "train", "epochs": 1, "timestep": 1700, "ep_reward": 831.3812255859375, "reward": 0.4856041669845581, "action": 1.6736633777618408}
{"mode": "train", "epochs": 1, "timestep": 1701, "ep_reward": 831.9151000976562, "reward": 0.5338519215583801, "action": 0.8469718098640442}
{"mode": "train", "epochs": 1, "timestep": 1702, "ep_reward": 832.49755859375, "reward": 0.5824698805809021, "action": 0.9279219508171082}
{"mode": "train", "epochs": 1, "timestep": 1703, "ep_reward": 833.1226196289062, "reward": 0.6250802874565125, "action": 1.1659412384033203}
{"mode": "train", "epochs": 1, "timestep": 1704, "ep_reward": 833.7830200195312, "reward": 0.6604244709014893, "action": 0.5903781652450562}
{"mode": "train", "epochs": 1, "timestep": 1705, "ep_reward": 834.4716796875, "reward": 0.6886419057846069, "action": 0.9565897583961487}
{"mode": "train", "epochs": 1, "timestep": 1706, "ep_reward": 835.1785888671875, "reward": 0.7068874835968018, "action": -0.11974942684173584}
{"mode": "train", "epochs": 1, "timestep": 1707, "ep_reward": 835.8927612304688, "reward": 0.7141432762145996, "action": -1.3182700872421265}
{"mode": "train", "epochs": 1, "timestep": 1708, "ep_reward": 836.5968017578125, "reward": 0.7040402293205261, "action": -0.058399200439453125}
{"mode": "train", "epochs": 1, "timestep": 1709, "ep_reward": 837.2764892578125, "reward": 0.6796705722808838, "action": -1.175769329071045}
{"mode": "train", "epochs": 1, "timestep": 1710, "ep_reward": 837.9119873046875, "reward": 0.6355221271514893, "action": -0.4533122181892395}
{"mode": "train", "epochs": 1, "timestep": 1711, "ep_reward": 838.4905395507812, "reward": 0.5785568952560425, "action": -0.8733115196228027}
{"mode": "train", "epochs": 1, "timestep": 1712, "ep_reward": 838.9959106445312, "reward": 0.5053759813308716, "action": 0.4230809807777405}
{"mode": "train", "epochs": 1, "timestep": 1713, "ep_reward": 839.4284057617188, "reward": 0.4324914813041687, "action": -0.605907678604126}
{"mode": "train", "epochs": 1, "timestep": 1714, "ep_reward": 839.7748413085938, "reward": 0.346416711807251, "action": -1.1777966022491455}
{"mode": "train", "epochs": 1, "timestep": 1715, "ep_reward": 840.0723876953125, "reward": 0.29757511615753174, "action": -1.6711313724517822}
{"mode": "train", "epochs": 1, "timestep": 1716, "ep_reward": 840.440185546875, "reward": 0.36781615018844604, "action": -1.4313095808029175}
{"mode": "train", "epochs": 1, "timestep": 1717, "ep_reward": 840.8829956054688, "reward": 0.44282066822052, "action": -0.37923580408096313}
{"mode": "train", "epochs": 1, "timestep": 1718, "ep_reward": 841.406494140625, "reward": 0.5235112905502319, "action": -0.6355523467063904}
{"mode": "train", "epochs": 1, "timestep": 1719, "ep_reward": 842.0030517578125, "reward": 0.5965431928634644, "action": -0.560289204120636}
{"mode": "train", "epochs": 1, "timestep": 1720, "ep_reward": 842.664306640625, "reward": 0.6612728238105774, "action": -1.3211222887039185}
{"mode": "train", "epochs": 1, "timestep": 1721, "ep_reward": 843.3771362304688, "reward": 0.7128095030784607, "action": -1.100614309310913}
{"mode": "train", "epochs": 1, "timestep": 1722, "ep_reward": 844.1326904296875, "reward": 0.7555243968963623, "action": -1.382704734802246}
{"mode": "train", "epochs": 1, "timestep": 1723, "ep_reward": 844.9201049804688, "reward": 0.7874166965484619, "action": -0.4631536602973938}
{"mode": "train", "epochs": 1, "timestep": 1724, "ep_reward": 845.7301025390625, "reward": 0.8099838495254517, "action": -1.1823464632034302}
{"mode": "train", "epochs": 1, "timestep": 1725, "ep_reward": 846.5504760742188, "reward": 0.8203612565994263, "action": -0.5081983804702759}
{"mode": "train", "epochs": 1, "timestep": 1726, "ep_reward": 847.36962890625, "reward": 0.819153904914856, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1727, "ep_reward": 848.1796875, "reward": 0.8100820779800415, "action": -1.2546173334121704}
{"mode": "train", "epochs": 1, "timestep": 1728, "ep_reward": 848.9703369140625, "reward": 0.7906366586685181, "action": 0.9038938283920288}
{"mode": "train", "epochs": 1, "timestep": 1729, "ep_reward": 849.719482421875, "reward": 0.7491618394851685, "action": 1.3674012422561646}
{"mode": "train", "epochs": 1, "timestep": 1730, "ep_reward": 850.4032592773438, "reward": 0.6837595105171204, "action": 0.2207741141319275}
{"mode": "train", "epochs": 1, "timestep": 1731, "ep_reward": 851.0087280273438, "reward": 0.6054842472076416, "action": 0.04155468940734863}
{"mode": "train", "epochs": 1, "timestep": 1732, "ep_reward": 851.5218505859375, "reward": 0.5131140947341919, "action": 0.9082363843917847}
{"mode": "train", "epochs": 1, "timestep": 1733, "ep_reward": 851.9209594726562, "reward": 0.3990848660469055, "action": 0.15163910388946533}
{"mode": "train", "epochs": 1, "timestep": 1734, "ep_reward": 852.2051391601562, "reward": 0.28414976596832275, "action": 0.8229637145996094}
{"mode": "train", "epochs": 1, "timestep": 1735, "ep_reward": 852.4298706054688, "reward": 0.22474771738052368, "action": 0.14632397890090942}
{"mode": "train", "epochs": 1, "timestep": 1736, "ep_reward": 852.7574462890625, "reward": 0.3275720477104187, "action": 0.5580036044120789}
{"mode": "train", "epochs": 1, "timestep": 1737, "ep_reward": 853.184814453125, "reward": 0.42738163471221924, "action": 1.394552230834961}
{"mode": "train", "epochs": 1, "timestep": 1738, "ep_reward": 853.702880859375, "reward": 0.5180456638336182, "action": 1.4006249904632568}
{"mode": "train", "epochs": 1, "timestep": 1739, "ep_reward": 854.3065185546875, "reward": 0.6036293506622314, "action": 1.457633137702942}
{"mode": "train", "epochs": 1, "timestep": 1740, "ep_reward": 854.9868774414062, "reward": 0.6803368330001831, "action": 0.25142931938171387}
{"mode": "train", "epochs": 1, "timestep": 1741, "ep_reward": 855.7393798828125, "reward": 0.7524765729904175, "action": 1.2050210237503052}
{"mode": "train", "epochs": 1, "timestep": 1742, "ep_reward": 856.5444946289062, "reward": 0.8051403760910034, "action": 0.6027982234954834}
{"mode": "train", "epochs": 1, "timestep": 1743, "ep_reward": 857.3925170898438, "reward": 0.8480116128921509, "action": 0.5150383710861206}
{"mode": "train", "epochs": 1, "timestep": 1744, "ep_reward": 858.2710571289062, "reward": 0.8785294890403748, "action": 0.8276286125183105}
{"mode": "train", "epochs": 1, "timestep": 1745, "ep_reward": 859.16845703125, "reward": 0.897429347038269, "action": 0.6972677707672119}
{"mode": "train", "epochs": 1, "timestep": 1746, "ep_reward": 860.0755004882812, "reward": 0.9070309996604919, "action": 0.8424729704856873}
{"mode": "train", "epochs": 1, "timestep": 1747, "ep_reward": 860.9832153320312, "reward": 0.9077084064483643, "action": -1.1551395654678345}
{"mode": "train", "epochs": 1, "timestep": 1748, "ep_reward": 861.8775634765625, "reward": 0.8943577408790588, "action": -1.5173442363739014}
{"mode": "train", "epochs": 1, "timestep": 1749, "ep_reward": 862.7394409179688, "reward": 0.8618968725204468, "action": -0.4926198720932007}
{"mode": "train", "epochs": 1, "timestep": 1750, "ep_reward": 863.5537109375, "reward": 0.8142481446266174, "action": -1.3302795886993408}
{"mode": "train", "epochs": 1, "timestep": 1751, "ep_reward": 864.2939453125, "reward": 0.7402545213699341, "action": -0.36985349655151367}
{"mode": "train", "epochs": 1, "timestep": 1752, "ep_reward": 864.9434204101562, "reward": 0.6494802236557007, "action": -1.5229406356811523}
{"mode": "train", "epochs": 1, "timestep": 1753, "ep_reward": 865.4663696289062, "reward": 0.5229313969612122, "action": -1.1805047988891602}
{"mode": "train", "epochs": 1, "timestep": 1754, "ep_reward": 865.8414916992188, "reward": 0.3751033544540405, "action": -1.0166243314743042}
{"mode": "train", "epochs": 1, "timestep": 1755, "ep_reward": 866.0538330078125, "reward": 0.2123546600341797, "action": -1.2335803508758545}
{"mode": "train", "epochs": 1, "timestep": 1756, "ep_reward": 866.1260375976562, "reward": 0.07222181558609009, "action": -0.7021973133087158}
{"mode": "train", "epochs": 1, "timestep": 1757, "ep_reward": 866.3247680664062, "reward": 0.19872409105300903, "action": -0.7314283847808838}
{"mode": "train", "epochs": 1, "timestep": 1758, "ep_reward": 866.6541137695312, "reward": 0.32934415340423584, "action": -1.081429362297058}
{"mode": "train", "epochs": 1, "timestep": 1759, "ep_reward": 867.1078491210938, "reward": 0.45372647047042847, "action": -0.47718656063079834}
{"mode": "train", "epochs": 1, "timestep": 1760, "ep_reward": 867.6825561523438, "reward": 0.574725329875946, "action": -0.14553076028823853}
{"mode": "train", "epochs": 1, "timestep": 1761, "ep_reward": 868.3637084960938, "reward": 0.6811298727989197, "action": -1.3463730812072754}
{"mode": "train", "epochs": 1, "timestep": 1762, "ep_reward": 869.12109375, "reward": 0.7574033141136169, "action": -0.28643280267715454}
{"mode": "train", "epochs": 1, "timestep": 1763, "ep_reward": 869.9456176757812, "reward": 0.8245463967323303, "action": -0.5207376480102539}
{"mode": "train", "epochs": 1, "timestep": 1764, "ep_reward": 870.8186645507812, "reward": 0.8730316758155823, "action": -0.2032676339149475}
{"mode": "train", "epochs": 1, "timestep": 1765, "ep_reward": 871.728515625, "reward": 0.9098516702651978, "action": -0.254111647605896}
{"mode": "train", "epochs": 1, "timestep": 1766, "ep_reward": 872.6640014648438, "reward": 0.9354977607727051, "action": -1.3495863676071167}
{"mode": "train", "epochs": 1, "timestep": 1767, "ep_reward": 873.612548828125, "reward": 0.9485493898391724, "action": -1.448661208152771}
{"mode": "train", "epochs": 1, "timestep": 1768, "ep_reward": 874.5684814453125, "reward": 0.9559323191642761, "action": -1.3686219453811646}
{"mode": "train", "epochs": 1, "timestep": 1769, "ep_reward": 875.5274658203125, "reward": 0.9589912295341492, "action": -0.11694467067718506}
{"mode": "train", "epochs": 1, "timestep": 1770, "ep_reward": 876.4901123046875, "reward": 0.9626397490501404, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1771, "ep_reward": 877.4428100585938, "reward": 0.9527155756950378, "action": -1.172863483428955}
{"mode": "train", "epochs": 1, "timestep": 1772, "ep_reward": 878.3825073242188, "reward": 0.9397138357162476, "action": -0.9595884680747986}
{"mode": "train", "epochs": 1, "timestep": 1773, "ep_reward": 879.3014526367188, "reward": 0.9189606308937073, "action": -0.37550193071365356}
{"mode": "train", "epochs": 1, "timestep": 1774, "ep_reward": 880.1918334960938, "reward": 0.8904109001159668, "action": -0.9409107565879822}
{"mode": "train", "epochs": 1, "timestep": 1775, "ep_reward": 881.0341186523438, "reward": 0.8422859907150269, "action": -0.8555198907852173}
{"mode": "train", "epochs": 1, "timestep": 1776, "ep_reward": 881.8071899414062, "reward": 0.7730682492256165, "action": -1.612119436264038}
{"mode": "train", "epochs": 1, "timestep": 1777, "ep_reward": 882.4743041992188, "reward": 0.6671217679977417, "action": -0.2678269147872925}
{"mode": "train", "epochs": 1, "timestep": 1778, "ep_reward": 883.0169067382812, "reward": 0.5425980091094971, "action": -0.4344977140426636}
{"mode": "train", "epochs": 1, "timestep": 1779, "ep_reward": 883.4002075195312, "reward": 0.383303701877594, "action": -1.0065637826919556}
{"mode": "train", "epochs": 1, "timestep": 1780, "ep_reward": 883.6162109375, "reward": 0.21597731113433838, "action": -1.533825397491455}
{"mode": "train", "epochs": 1, "timestep": 1781, "ep_reward": 883.6983642578125, "reward": 0.08216613531112671, "action": -0.828965961933136}
{"mode": "train", "epochs": 1, "timestep": 1782, "ep_reward": 883.7340087890625, "reward": 0.03561621904373169, "action": -0.9208933711051941}
{"mode": "train", "epochs": 1, "timestep": 1783, "ep_reward": 883.909912109375, "reward": 0.17588555812835693, "action": -0.6621485948562622}
{"mode": "train", "epochs": 1, "timestep": 1784, "ep_reward": 884.22998046875, "reward": 0.3200874924659729, "action": -0.9171168208122253}
{"mode": "train", "epochs": 1, "timestep": 1785, "ep_reward": 884.685546875, "reward": 0.4555474519729614, "action": -1.0180708169937134}
{"mode": "train", "epochs": 1, "timestep": 1786, "ep_reward": 885.2611083984375, "reward": 0.575533390045166, "action": -1.2529993057250977}
{"mode": "train", "epochs": 1, "timestep": 1787, "ep_reward": 885.93408203125, "reward": 0.6729846000671387, "action": -0.44065648317337036}
{"mode": "train", "epochs": 1, "timestep": 1788, "ep_reward": 886.6903076171875, "reward": 0.7562391757965088, "action": -0.5006388425827026}
{"mode": "train", "epochs": 1, "timestep": 1789, "ep_reward": 887.5064697265625, "reward": 0.8161474466323853, "action": -1.3393266201019287}
{"mode": "train", "epochs": 1, "timestep": 1790, "ep_reward": 888.3563232421875, "reward": 0.8498715162277222, "action": 0.2782902717590332}
{"mode": "train", "epochs": 1, "timestep": 1791, "ep_reward": 889.2365112304688, "reward": 0.8801872730255127, "action": -1.5778074264526367}
{"mode": "train", "epochs": 1, "timestep": 1792, "ep_reward": 890.1174926757812, "reward": 0.8809781074523926, "action": -0.407515287399292}
{"mode": "train", "epochs": 1, "timestep": 1793, "ep_reward": 890.9938354492188, "reward": 0.8763152360916138, "action": -0.7785638570785522}
{"mode": "train", "epochs": 1, "timestep": 1794, "ep_reward": 891.84619140625, "reward": 0.852334201335907, "action": -1.132534146308899}
{"mode": "train", "epochs": 1, "timestep": 1795, "ep_reward": 892.651123046875, "reward": 0.8049144148826599, "action": -0.9673492908477783}
{"mode": "train", "epochs": 1, "timestep": 1796, "ep_reward": 893.3839111328125, "reward": 0.7327595949172974, "action": -0.20667588710784912}
{"mode": "train", "epochs": 1, "timestep": 1797, "ep_reward": 894.021484375, "reward": 0.6375432014465332, "action": -1.1812198162078857}
{"mode": "train", "epochs": 1, "timestep": 1798, "ep_reward": 894.5142822265625, "reward": 0.4928274154663086, "action": -0.6821379661560059}
{"mode": "train", "epochs": 1, "timestep": 1799, "ep_reward": 894.8487548828125, "reward": 0.3344462513923645, "action": -1.301639199256897}
{"mode": "train", "epochs": 1, "timestep": 1800, "ep_reward": 895.0702514648438, "reward": 0.22146928310394287, "action": -0.7975535988807678}
{"mode": "train", "epochs": 1, "timestep": 1801, "ep_reward": 895.1586303710938, "reward": 0.08836561441421509, "action": -1.266885757446289}
{"mode": "train", "epochs": 1, "timestep": 1802, "ep_reward": 895.1875, "reward": 0.02884829044342041, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1803, "ep_reward": 895.357666015625, "reward": 0.17014241218566895, "action": -1.0740419626235962}
{"mode": "train", "epochs": 1, "timestep": 1804, "ep_reward": 895.6668090820312, "reward": 0.3091621994972229, "action": -0.9736220240592957}
{"mode": "train", "epochs": 1, "timestep": 1805, "ep_reward": 896.112060546875, "reward": 0.44527965784072876, "action": -1.4427516460418701}
{"mode": "train", "epochs": 1, "timestep": 1806, "ep_reward": 896.6743774414062, "reward": 0.56229567527771, "action": -0.5844453573226929}
{"mode": "train", "epochs": 1, "timestep": 1807, "ep_reward": 897.3433227539062, "reward": 0.6689157485961914, "action": -1.4394503831863403}
{"mode": "train", "epochs": 1, "timestep": 1808, "ep_reward": 898.0866088867188, "reward": 0.743268609046936, "action": -1.0928303003311157}
{"mode": "train", "epochs": 1, "timestep": 1809, "ep_reward": 898.885986328125, "reward": 0.7993669509887695, "action": -1.4518765211105347}
{"mode": "train", "epochs": 1, "timestep": 1810, "ep_reward": 899.71826171875, "reward": 0.8322604894638062, "action": -0.21804040670394897}
{"mode": "train", "epochs": 1, "timestep": 1811, "ep_reward": 900.5757446289062, "reward": 0.8574994802474976, "action": -1.202008605003357}
{"mode": "train", "epochs": 1, "timestep": 1812, "ep_reward": 901.432373046875, "reward": 0.8566111922264099, "action": -0.4133889079093933}
{"mode": "train", "epochs": 1, "timestep": 1813, "ep_reward": 902.2769165039062, "reward": 0.8445577621459961, "action": -0.772225558757782}
{"mode": "train", "epochs": 1, "timestep": 1814, "ep_reward": 903.0856323242188, "reward": 0.8087260723114014, "action": -1.1172014474868774}
{"mode": "train", "epochs": 1, "timestep": 1815, "ep_reward": 903.8292846679688, "reward": 0.74367755651474, "action": -0.7081422805786133}
{"mode": "train", "epochs": 1, "timestep": 1816, "ep_reward": 904.4800415039062, "reward": 0.6507599353790283, "action": -1.3550447225570679}
{"mode": "train", "epochs": 1, "timestep": 1817, "ep_reward": 904.9903564453125, "reward": 0.5102975964546204, "action": -1.265568733215332}
{"mode": "train", "epochs": 1, "timestep": 1818, "ep_reward": 905.35302734375, "reward": 0.3626747727394104, "action": -0.3260021209716797}
{"mode": "train", "epochs": 1, "timestep": 1819, "ep_reward": 905.6080322265625, "reward": 0.2550008296966553, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1820, "ep_reward": 905.73583984375, "reward": 0.12781333923339844, "action": 0.3307582139968872}
{"mode": "train", "epochs": 1, "timestep": 1821, "ep_reward": 905.7216186523438, "reward": -0.014223933219909668, "action": -1.428048014640808}
{"mode": "train", "epochs": 1, "timestep": 1822, "ep_reward": 905.8541870117188, "reward": 0.13259369134902954, "action": -0.7828838229179382}
{"mode": "train", "epochs": 1, "timestep": 1823, "ep_reward": 906.1286010742188, "reward": 0.27441316843032837, "action": -1.05511474609375}
{"mode": "train", "epochs": 1, "timestep": 1824, "ep_reward": 906.5394287109375, "reward": 0.4108229875564575, "action": -1.4658215045928955}
{"mode": "train", "epochs": 1, "timestep": 1825, "ep_reward": 907.0709838867188, "reward": 0.5315403938293457, "action": -1.3969049453735352}
{"mode": "train", "epochs": 1, "timestep": 1826, "ep_reward": 907.7063598632812, "reward": 0.635373592376709, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1827, "ep_reward": 908.4180297851562, "reward": 0.711677074432373, "action": -0.974554717540741}
{"mode": "train", "epochs": 1, "timestep": 1828, "ep_reward": 909.1942749023438, "reward": 0.7762734889984131, "action": -1.8977086544036865}
{"mode": "train", "epochs": 1, "timestep": 1829, "ep_reward": 910.0045776367188, "reward": 0.8102888464927673, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1830, "ep_reward": 910.8280029296875, "reward": 0.8234525918960571, "action": -0.6453012228012085}
{"mode": "train", "epochs": 1, "timestep": 1831, "ep_reward": 911.6565551757812, "reward": 0.8285719156265259, "action": -1.8533763885498047}
{"mode": "train", "epochs": 1, "timestep": 1832, "ep_reward": 912.4560546875, "reward": 0.7994734644889832, "action": -1.2456145286560059}
{"mode": "train", "epochs": 1, "timestep": 1833, "ep_reward": 913.2052001953125, "reward": 0.7491527795791626, "action": -1.4685307741165161}
{"mode": "train", "epochs": 1, "timestep": 1834, "ep_reward": 913.8675537109375, "reward": 0.6623606085777283, "action": -1.0131864547729492}
{"mode": "train", "epochs": 1, "timestep": 1835, "ep_reward": 914.4076538085938, "reward": 0.5400832891464233, "action": -0.0927460789680481}
{"mode": "train", "epochs": 1, "timestep": 1836, "ep_reward": 914.8163452148438, "reward": 0.40869396924972534, "action": -0.6077581644058228}
{"mode": "train", "epochs": 1, "timestep": 1837, "ep_reward": 915.1275024414062, "reward": 0.31115633249282837, "action": -1.1932960748672485}
{"mode": "train", "epochs": 1, "timestep": 1838, "ep_reward": 915.321044921875, "reward": 0.19356530904769897, "action": -1.8259239196777344}
{"mode": "train", "epochs": 1, "timestep": 1839, "ep_reward": 915.3773193359375, "reward": 0.05625736713409424, "action": -0.8459246754646301}
{"mode": "train", "epochs": 1, "timestep": 1840, "ep_reward": 915.4393310546875, "reward": 0.06198185682296753, "action": -1.1811230182647705}
{"mode": "train", "epochs": 1, "timestep": 1841, "ep_reward": 915.6380004882812, "reward": 0.1986931562423706, "action": -1.0075284242630005}
{"mode": "train", "epochs": 1, "timestep": 1842, "ep_reward": 915.9768676757812, "reward": 0.33889609575271606, "action": -1.1215355396270752}
{"mode": "train", "epochs": 1, "timestep": 1843, "ep_reward": 916.4481811523438, "reward": 0.4712929129600525, "action": -0.8261138200759888}
{"mode": "train", "epochs": 1, "timestep": 1844, "ep_reward": 917.0396728515625, "reward": 0.5914849042892456, "action": -1.3161431550979614}
{"mode": "train", "epochs": 1, "timestep": 1845, "ep_reward": 917.7244262695312, "reward": 0.68477463722229, "action": -0.8214628100395203}
{"mode": "train", "epochs": 1, "timestep": 1846, "ep_reward": 918.48486328125, "reward": 0.7604629397392273, "action": -1.201848030090332}
{"mode": "train", "epochs": 1, "timestep": 1847, "ep_reward": 919.29541015625, "reward": 0.8105454444885254, "action": -1.3061206340789795}
{"mode": "train", "epochs": 1, "timestep": 1848, "ep_reward": 920.1358642578125, "reward": 0.840440034866333, "action": -0.3048834800720215}
{"mode": "train", "epochs": 1, "timestep": 1849, "ep_reward": 920.9969482421875, "reward": 0.8610613346099854, "action": -0.7653450965881348}
{"mode": "train", "epochs": 1, "timestep": 1850, "ep_reward": 921.857421875, "reward": 0.8604733347892761, "action": -0.4191739559173584}
{"mode": "train", "epochs": 1, "timestep": 1851, "ep_reward": 922.7025756835938, "reward": 0.8451321125030518, "action": -0.7860237956047058}
{"mode": "train", "epochs": 1, "timestep": 1852, "ep_reward": 923.5084228515625, "reward": 0.8058745861053467, "action": -1.5289969444274902}
{"mode": "train", "epochs": 1, "timestep": 1853, "ep_reward": 924.24072265625, "reward": 0.7323014736175537, "action": -1.6812372207641602}
{"mode": "train", "epochs": 1, "timestep": 1854, "ep_reward": 924.86181640625, "reward": 0.6210846900939941, "action": -0.7353876829147339}
{"mode": "train", "epochs": 1, "timestep": 1855, "ep_reward": 925.3424072265625, "reward": 0.48060834407806396, "action": -0.6939829587936401}
{"mode": "train", "epochs": 1, "timestep": 1856, "ep_reward": 925.6881713867188, "reward": 0.34574270248413086, "action": -0.3909555673599243}
{"mode": "train", "epochs": 1, "timestep": 1857, "ep_reward": 925.9230346679688, "reward": 0.23486804962158203, "action": -0.7776169776916504}
{"mode": "train", "epochs": 1, "timestep": 1858, "ep_reward": 926.0270385742188, "reward": 0.1040034294128418, "action": -0.9447072744369507}
{"mode": "train", "epochs": 1, "timestep": 1859, "ep_reward": 926.0392456054688, "reward": 0.012211740016937256, "action": -1.6286301612854004}
{"mode": "train", "epochs": 1, "timestep": 1860, "ep_reward": 926.1947021484375, "reward": 0.1554793119430542, "action": -1.840772032737732}
{"mode": "train", "epochs": 1, "timestep": 1861, "ep_reward": 926.4791870117188, "reward": 0.28450560569763184, "action": -1.916579008102417}
{"mode": "train", "epochs": 1, "timestep": 1862, "ep_reward": 926.8910522460938, "reward": 0.41185903549194336, "action": -1.3867990970611572}
{"mode": "train", "epochs": 1, "timestep": 1863, "ep_reward": 927.42578125, "reward": 0.5347425937652588, "action": -1.5689775943756104}
{"mode": "train", "epochs": 1, "timestep": 1864, "ep_reward": 928.0614013671875, "reward": 0.635602593421936, "action": -0.9052776098251343}
{"mode": "train", "epochs": 1, "timestep": 1865, "ep_reward": 928.7813720703125, "reward": 0.7199992537498474, "action": -0.19712239503860474}
{"mode": "train", "epochs": 1, "timestep": 1866, "ep_reward": 929.5674438476562, "reward": 0.7861013412475586, "action": -1.8030527830123901}
{"mode": "train", "epochs": 1, "timestep": 1867, "ep_reward": 930.3812255859375, "reward": 0.81376713514328, "action": -0.3949110507965088}
{"mode": "train", "epochs": 1, "timestep": 1868, "ep_reward": 931.2152709960938, "reward": 0.834023654460907, "action": -1.147995948791504}
{"mode": "train", "epochs": 1, "timestep": 1869, "ep_reward": 932.0415649414062, "reward": 0.8262936472892761, "action": -1.5122175216674805}
{"mode": "train", "epochs": 1, "timestep": 1870, "ep_reward": 932.8333740234375, "reward": 0.7917807102203369, "action": -1.6926655769348145}
{"mode": "train", "epochs": 1, "timestep": 1871, "ep_reward": 933.5596923828125, "reward": 0.7263092994689941, "action": -0.7251166105270386}
{"mode": "train", "epochs": 1, "timestep": 1872, "ep_reward": 934.1962280273438, "reward": 0.6365231275558472, "action": -1.363297939300537}
{"mode": "train", "epochs": 1, "timestep": 1873, "ep_reward": 934.6925659179688, "reward": 0.49632179737091064, "action": 0.15343940258026123}
{"mode": "train", "epochs": 1, "timestep": 1874, "ep_reward": 935.0721435546875, "reward": 0.3796076774597168, "action": -1.0199192762374878}
{"mode": "train", "epochs": 1, "timestep": 1875, "ep_reward": 935.347900390625, "reward": 0.2757585048675537, "action": -0.7555124759674072}
{"mode": "train", "epochs": 1, "timestep": 1876, "ep_reward": 935.499755859375, "reward": 0.15182620286941528, "action": -1.1957900524139404}
{"mode": "train", "epochs": 1, "timestep": 1877, "ep_reward": 935.5076904296875, "reward": 0.007925748825073242, "action": -1.332643985748291}
{"mode": "train", "epochs": 1, "timestep": 1878, "ep_reward": 935.6155395507812, "reward": 0.10786712169647217, "action": -1.6228268146514893}
{"mode": "train", "epochs": 1, "timestep": 1879, "ep_reward": 935.8541870117188, "reward": 0.2386389970779419, "action": 0.006318569183349609}
{"mode": "train", "epochs": 1, "timestep": 1880, "ep_reward": 936.2454223632812, "reward": 0.3912053108215332, "action": -1.4527065753936768}
{"mode": "train", "epochs": 1, "timestep": 1881, "ep_reward": 936.759521484375, "reward": 0.514089822769165, "action": -1.1412413120269775}
{"mode": "train", "epochs": 1, "timestep": 1882, "ep_reward": 937.3834838867188, "reward": 0.6239519119262695, "action": -0.1070907711982727}
{"mode": "train", "epochs": 1, "timestep": 1883, "ep_reward": 938.1056518554688, "reward": 0.7221602201461792, "action": -0.768465518951416}
{"mode": "train", "epochs": 1, "timestep": 1884, "ep_reward": 938.8955078125, "reward": 0.7898319959640503, "action": -0.4194631576538086}
{"mode": "train", "epochs": 1, "timestep": 1885, "ep_reward": 939.7354736328125, "reward": 0.8399685621261597, "action": -0.6464968323707581}
{"mode": "train", "epochs": 1, "timestep": 1886, "ep_reward": 940.6058959960938, "reward": 0.8704033493995667, "action": -0.3195013403892517}
{"mode": "train", "epochs": 1, "timestep": 1887, "ep_reward": 941.4940795898438, "reward": 0.8881872296333313, "action": -0.7280651926994324}
{"mode": "train", "epochs": 1, "timestep": 1888, "ep_reward": 942.3829345703125, "reward": 0.8888440132141113, "action": -1.4744882583618164}
{"mode": "train", "epochs": 1, "timestep": 1889, "ep_reward": 943.2518920898438, "reward": 0.8689707517623901, "action": -1.2892866134643555}
{"mode": "train", "epochs": 1, "timestep": 1890, "ep_reward": 944.0841674804688, "reward": 0.8322798013687134, "action": -0.9424533247947693}
{"mode": "train", "epochs": 1, "timestep": 1891, "ep_reward": 944.8598022460938, "reward": 0.7756649255752563, "action": -0.22540730237960815}
{"mode": "train", "epochs": 1, "timestep": 1892, "ep_reward": 945.558349609375, "reward": 0.6985445022583008, "action": -1.2651419639587402}
{"mode": "train", "epochs": 1, "timestep": 1893, "ep_reward": 946.1328735351562, "reward": 0.5745010375976562, "action": -1.6024084091186523}
{"mode": "train", "epochs": 1, "timestep": 1894, "ep_reward": 946.5363159179688, "reward": 0.403425931930542, "action": -0.8964020609855652}
{"mode": "train", "epochs": 1, "timestep": 1895, "ep_reward": 946.8216552734375, "reward": 0.2853153944015503, "action": -1.6858561038970947}
{"mode": "train", "epochs": 1, "timestep": 1896, "ep_reward": 946.9849243164062, "reward": 0.16328006982803345, "action": -0.899728536605835}
{"mode": "train", "epochs": 1, "timestep": 1897, "ep_reward": 947.005859375, "reward": 0.02091825008392334, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1898, "ep_reward": 947.101806640625, "reward": 0.09591835737228394, "action": -0.15331202745437622}
{"mode": "train", "epochs": 1, "timestep": 1899, "ep_reward": 947.3463134765625, "reward": 0.24451375007629395, "action": -1.1472405195236206}
{"mode": "train", "epochs": 1, "timestep": 1900, "ep_reward": 947.7261352539062, "reward": 0.37982308864593506, "action": -0.5908019542694092}
{"mode": "train", "epochs": 1, "timestep": 1901, "ep_reward": 948.2394409179688, "reward": 0.513330340385437, "action": -0.7801743745803833}
{"mode": "train", "epochs": 1, "timestep": 1902, "ep_reward": 948.8662719726562, "reward": 0.6268214583396912, "action": -0.1559683084487915}
{"mode": "train", "epochs": 1, "timestep": 1903, "ep_reward": 949.5908813476562, "reward": 0.7245793342590332, "action": -0.5537505149841309}
{"mode": "train", "epochs": 1, "timestep": 1904, "ep_reward": 950.3863525390625, "reward": 0.7954825162887573, "action": -0.7149217128753662}
{"mode": "train", "epochs": 1, "timestep": 1905, "ep_reward": 951.2317504882812, "reward": 0.8453977108001709, "action": -0.5631688833236694}
{"mode": "train", "epochs": 1, "timestep": 1906, "ep_reward": 952.11181640625, "reward": 0.8800458908081055, "action": -0.8171759247779846}
{"mode": "train", "epochs": 1, "timestep": 1907, "ep_reward": 953.0108642578125, "reward": 0.8990554213523865, "action": -1.2576252222061157}
{"mode": "train", "epochs": 1, "timestep": 1908, "ep_reward": 953.9138793945312, "reward": 0.9030182361602783, "action": -0.9449377655982971}
{"mode": "train", "epochs": 1, "timestep": 1909, "ep_reward": 954.8109741210938, "reward": 0.897113561630249, "action": -0.930504322052002}
{"mode": "train", "epochs": 1, "timestep": 1910, "ep_reward": 955.6885986328125, "reward": 0.877618670463562, "action": -1.2590714693069458}
{"mode": "train", "epochs": 1, "timestep": 1911, "ep_reward": 956.5269165039062, "reward": 0.8383278846740723, "action": -0.36885255575180054}
{"mode": "train", "epochs": 1, "timestep": 1912, "ep_reward": 957.3120727539062, "reward": 0.7851450443267822, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1913, "ep_reward": 957.9984130859375, "reward": 0.686311662197113, "action": -1.0857833623886108}
{"mode": "train", "epochs": 1, "timestep": 1914, "ep_reward": 958.558349609375, "reward": 0.5599258542060852, "action": -1.144648551940918}
{"mode": "train", "epochs": 1, "timestep": 1915, "ep_reward": 958.9503784179688, "reward": 0.39202308654785156, "action": 0.14480876922607422}
{"mode": "train", "epochs": 1, "timestep": 1916, "ep_reward": 959.221435546875, "reward": 0.2710820436477661, "action": -0.8572410345077515}
{"mode": "train", "epochs": 1, "timestep": 1917, "ep_reward": 959.3677978515625, "reward": 0.14638066291809082, "action": -0.9127403497695923}
{"mode": "train", "epochs": 1, "timestep": 1918, "ep_reward": 959.369384765625, "reward": 0.0015902519226074219, "action": -1.534088134765625}
{"mode": "train", "epochs": 1, "timestep": 1919, "ep_reward": 959.4829711914062, "reward": 0.1135941743850708, "action": -1.54087233543396}
{"mode": "train", "epochs": 1, "timestep": 1920, "ep_reward": 959.728515625, "reward": 0.24555569887161255, "action": -0.03430265188217163}
{"mode": "train", "epochs": 1, "timestep": 1921, "ep_reward": 960.1256713867188, "reward": 0.3971613645553589, "action": -1.3629200458526611}
{"mode": "train", "epochs": 1, "timestep": 1922, "ep_reward": 960.6460571289062, "reward": 0.5204035043716431, "action": -1.0497010946273804}
{"mode": "train", "epochs": 1, "timestep": 1923, "ep_reward": 961.2761840820312, "reward": 0.630096971988678, "action": -0.8790155649185181}
{"mode": "train", "epochs": 1, "timestep": 1924, "ep_reward": 961.99560546875, "reward": 0.7194499969482422, "action": -1.0529006719589233}
{"mode": "train", "epochs": 1, "timestep": 1925, "ep_reward": 962.7802124023438, "reward": 0.7845805883407593, "action": -0.6529834270477295}
{"mode": "train", "epochs": 1, "timestep": 1926, "ep_reward": 963.6129760742188, "reward": 0.8327441811561584, "action": -0.2039545774459839}
{"mode": "train", "epochs": 1, "timestep": 1927, "ep_reward": 964.4791259765625, "reward": 0.8661548495292664, "action": -0.02066904306411743}
{"mode": "train", "epochs": 1, "timestep": 1928, "ep_reward": 965.3639526367188, "reward": 0.8847994208335876, "action": -0.001398324966430664}
{"mode": "train", "epochs": 1, "timestep": 1929, "ep_reward": 966.2530517578125, "reward": 0.8891281485557556, "action": -0.8420442938804626}
{"mode": "train", "epochs": 1, "timestep": 1930, "ep_reward": 967.12548828125, "reward": 0.872416615486145, "action": -0.9457749128341675}
{"mode": "train", "epochs": 1, "timestep": 1931, "ep_reward": 967.9629516601562, "reward": 0.8374653458595276, "action": -1.1319326162338257}
{"mode": "train", "epochs": 1, "timestep": 1932, "ep_reward": 968.7412109375, "reward": 0.7782518267631531, "action": -1.16640043258667}
{"mode": "train", "epochs": 1, "timestep": 1933, "ep_reward": 969.4303588867188, "reward": 0.6891191005706787, "action": -0.9577678442001343}
{"mode": "train", "epochs": 1, "timestep": 1934, "ep_reward": 969.9965209960938, "reward": 0.5661340951919556, "action": -1.2346748113632202}
{"mode": "train", "epochs": 1, "timestep": 1935, "ep_reward": 970.3950805664062, "reward": 0.398554265499115, "action": -0.6431881189346313}
{"mode": "train", "epochs": 1, "timestep": 1936, "ep_reward": 970.67333984375, "reward": 0.27827227115631104, "action": -1.4413539171218872}
{"mode": "train", "epochs": 1, "timestep": 1937, "ep_reward": 970.8282470703125, "reward": 0.15492242574691772, "action": -0.9789062738418579}
{"mode": "train", "epochs": 1, "timestep": 1938, "ep_reward": 970.8397216796875, "reward": 0.011481285095214844, "action": -1.1396822929382324}
{"mode": "train", "epochs": 1, "timestep": 1939, "ep_reward": 970.9444580078125, "reward": 0.10473352670669556, "action": -1.0879603624343872}
{"mode": "train", "epochs": 1, "timestep": 1940, "ep_reward": 971.1863403320312, "reward": 0.24190396070480347, "action": -1.7471835613250732}
{"mode": "train", "epochs": 1, "timestep": 1941, "ep_reward": 971.5582275390625, "reward": 0.37189561128616333, "action": -0.6452672481536865}
{"mode": "train", "epochs": 1, "timestep": 1942, "ep_reward": 972.065673828125, "reward": 0.5074625015258789, "action": -1.358196496963501}
{"mode": "train", "epochs": 1, "timestep": 1943, "ep_reward": 972.6817626953125, "reward": 0.6160591840744019, "action": -1.099888563156128}
{"mode": "train", "epochs": 1, "timestep": 1944, "ep_reward": 973.387451171875, "reward": 0.7056587338447571, "action": -1.032509446144104}
{"mode": "train", "epochs": 1, "timestep": 1945, "ep_reward": 974.1602172851562, "reward": 0.7727372646331787, "action": -0.9615892767906189}
{"mode": "train", "epochs": 1, "timestep": 1946, "ep_reward": 974.9788818359375, "reward": 0.8186866641044617, "action": -1.2204298973083496}
{"mode": "train", "epochs": 1, "timestep": 1947, "ep_reward": 975.8216552734375, "reward": 0.8427589535713196, "action": -0.7185102701187134}
{"mode": "train", "epochs": 1, "timestep": 1948, "ep_reward": 976.6746215820312, "reward": 0.8529380559921265, "action": -0.9029029607772827}
{"mode": "train", "epochs": 1, "timestep": 1949, "ep_reward": 977.5174560546875, "reward": 0.8428113460540771, "action": -1.7325024604797363}
{"mode": "train", "epochs": 1, "timestep": 1950, "ep_reward": 978.3211059570312, "reward": 0.8036316633224487, "action": -0.5863189697265625}
{"mode": "train", "epochs": 1, "timestep": 1951, "ep_reward": 979.0706787109375, "reward": 0.7495707273483276, "action": -1.0861258506774902}
{"mode": "train", "epochs": 1, "timestep": 1952, "ep_reward": 979.728515625, "reward": 0.6578191518783569, "action": -1.0856937170028687}
{"mode": "train", "epochs": 1, "timestep": 1953, "ep_reward": 980.2548217773438, "reward": 0.5263227224349976, "action": -0.49337655305862427}
{"mode": "train", "epochs": 1, "timestep": 1954, "ep_reward": 980.63525390625, "reward": 0.38041937351226807, "action": -0.5454869270324707}
{"mode": "train", "epochs": 1, "timestep": 1955, "ep_reward": 980.9119262695312, "reward": 0.2766798138618469, "action": -0.8278259038925171}
{"mode": "train", "epochs": 1, "timestep": 1956, "ep_reward": 981.0647583007812, "reward": 0.1528283953666687, "action": -1.6910585165023804}
{"mode": "train", "epochs": 1, "timestep": 1957, "ep_reward": 981.0739135742188, "reward": 0.009150564670562744, "action": -1.5016539096832275}
{"mode": "train", "epochs": 1, "timestep": 1958, "ep_reward": 981.1807250976562, "reward": 0.10681915283203125, "action": -1.0381369590759277}
{"mode": "train", "epochs": 1, "timestep": 1959, "ep_reward": 981.4255981445312, "reward": 0.24484366178512573, "action": -0.5081862211227417}
{"mode": "train", "epochs": 1, "timestep": 1960, "ep_reward": 981.8153076171875, "reward": 0.3897175192832947, "action": -0.6703879833221436}
{"mode": "train", "epochs": 1, "timestep": 1961, "ep_reward": 982.3369750976562, "reward": 0.5216384530067444, "action": -0.4283332824707031}
{"mode": "train", "epochs": 1, "timestep": 1962, "ep_reward": 982.9744262695312, "reward": 0.637458086013794, "action": -0.9749419093132019}
{"mode": "train", "epochs": 1, "timestep": 1963, "ep_reward": 983.6994018554688, "reward": 0.7249516844749451, "action": -1.7642920017242432}
{"mode": "train", "epochs": 1, "timestep": 1964, "ep_reward": 984.4835815429688, "reward": 0.784203827381134, "action": -1.3803277015686035}
{"mode": "train", "epochs": 1, "timestep": 1965, "ep_reward": 985.3118286132812, "reward": 0.8282746076583862, "action": -0.9200156331062317}
{"mode": "train", "epochs": 1, "timestep": 1966, "ep_reward": 986.17041015625, "reward": 0.8586055040359497, "action": -1.3691949844360352}
{"mode": "train", "epochs": 1, "timestep": 1967, "ep_reward": 987.03955078125, "reward": 0.8691223859786987, "action": -0.7425292730331421}
{"mode": "train", "epochs": 1, "timestep": 1968, "ep_reward": 987.9083251953125, "reward": 0.8687984347343445, "action": -1.850635051727295}
{"mode": "train", "epochs": 1, "timestep": 1969, "ep_reward": 988.7499389648438, "reward": 0.8416085243225098, "action": -0.14879542589187622}
{"mode": "train", "epochs": 1, "timestep": 1970, "ep_reward": 989.5588989257812, "reward": 0.8089540600776672, "action": -1.3159699440002441}
{"mode": "train", "epochs": 1, "timestep": 1971, "ep_reward": 990.2979736328125, "reward": 0.739072322845459, "action": -1.6078181266784668}
{"mode": "train", "epochs": 1, "timestep": 1972, "ep_reward": 990.92919921875, "reward": 0.6312038898468018, "action": -0.5537718534469604}
{"mode": "train", "epochs": 1, "timestep": 1973, "ep_reward": 991.4257202148438, "reward": 0.49649280309677124, "action": -1.175153374671936}
{"mode": "train", "epochs": 1, "timestep": 1974, "ep_reward": 991.7769775390625, "reward": 0.35127580165863037, "action": -1.351015329360962}
{"mode": "train", "epochs": 1, "timestep": 1975, "ep_reward": 992.0184936523438, "reward": 0.24150407314300537, "action": -1.6184148788452148}
{"mode": "train", "epochs": 1, "timestep": 1976, "ep_reward": 992.1303100585938, "reward": 0.11181902885437012, "action": -1.4227068424224854}
{"mode": "train", "epochs": 1, "timestep": 1977, "ep_reward": 992.1339721679688, "reward": 0.003651857376098633, "action": -1.097964882850647}
{"mode": "train", "epochs": 1, "timestep": 1978, "ep_reward": 992.2821044921875, "reward": 0.1481567621231079, "action": -0.36603426933288574}
{"mode": "train", "epochs": 1, "timestep": 1979, "ep_reward": 992.57763671875, "reward": 0.2955350875854492, "action": -0.26581817865371704}
{"mode": "train", "epochs": 1, "timestep": 1980, "ep_reward": 993.01708984375, "reward": 0.4394379258155823, "action": -1.1717474460601807}
{"mode": "train", "epochs": 1, "timestep": 1981, "ep_reward": 993.576171875, "reward": 0.5590934157371521, "action": -0.5566733479499817}
{"mode": "train", "epochs": 1, "timestep": 1982, "ep_reward": 994.2427368164062, "reward": 0.6665686368942261, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1983, "ep_reward": 994.9808959960938, "reward": 0.7381547093391418, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1984, "ep_reward": 995.7718505859375, "reward": 0.7909556031227112, "action": -0.7317675352096558}
{"mode": "train", "epochs": 1, "timestep": 1985, "ep_reward": 996.6080932617188, "reward": 0.8362671732902527, "action": -0.6275085806846619}
{"mode": "train", "epochs": 1, "timestep": 1986, "ep_reward": 997.4724731445312, "reward": 0.8643839359283447, "action": -0.27545100450515747}
{"mode": "train", "epochs": 1, "timestep": 1987, "ep_reward": 998.3516845703125, "reward": 0.8791937232017517, "action": -1.1914899349212646}
{"mode": "train", "epochs": 1, "timestep": 1988, "ep_reward": 999.2229614257812, "reward": 0.8712878227233887, "action": -1.0795135498046875}
{"mode": "train", "epochs": 1, "timestep": 1989, "ep_reward": 1000.0701904296875, "reward": 0.8472394943237305, "action": -0.864315390586853}
{"mode": "train", "epochs": 1, "timestep": 1990, "ep_reward": 1000.8745727539062, "reward": 0.8044015169143677, "action": -0.886610746383667}
{"mode": "train", "epochs": 1, "timestep": 1991, "ep_reward": 1001.6099243164062, "reward": 0.7353405952453613, "action": -0.1881985068321228}
{"mode": "train", "epochs": 1, "timestep": 1992, "ep_reward": 1002.252685546875, "reward": 0.6427392959594727, "action": -0.8626622557640076}
{"mode": "train", "epochs": 1, "timestep": 1993, "ep_reward": 1002.7576293945312, "reward": 0.5049499869346619, "action": -1.4218926429748535}
{"mode": "train", "epochs": 1, "timestep": 1994, "ep_reward": 1003.1013793945312, "reward": 0.3437543511390686, "action": -1.2518389225006104}
{"mode": "train", "epochs": 1, "timestep": 1995, "ep_reward": 1003.3339233398438, "reward": 0.23252630233764648, "action": -1.2868136167526245}
{"mode": "train", "epochs": 1, "timestep": 1996, "ep_reward": 1003.4352416992188, "reward": 0.10132193565368652, "action": -1.166926622390747}
{"mode": "train", "epochs": 1, "timestep": 1997, "ep_reward": 1003.450439453125, "reward": 0.015226960182189941, "action": -0.6949248313903809}
{"mode": "train", "epochs": 1, "timestep": 1998, "ep_reward": 1003.608642578125, "reward": 0.15817660093307495, "action": -0.5360527038574219}
{"mode": "train", "epochs": 1, "timestep": 1999, "ep_reward": 1003.9121704101562, "reward": 0.3035372495651245, "action": -1.4822994470596313}
{"mode": "train", "epochs": 1, "timestep": 2000, "ep_reward": 1004.3452758789062, "reward": 0.43308156728744507, "action": 0.6436853408813477}
{"mode": "train", "epochs": 2, "timestep": 2001, "ep_reward": 0.995476245880127, "reward": 0.995476245880127, "action": -1.188956379890442}
{"mode": "train", "epochs": 2, "timestep": 2002, "ep_reward": 1.9909530878067017, "reward": 0.9954768419265747, "action": -1.4948046207427979}
{"mode": "train", "epochs": 2, "timestep": 2003, "ep_reward": 2.985470771789551, "reward": 0.9945176243782043, "action": -1.7662444114685059}
{"mode": "train", "epochs": 2, "timestep": 2004, "ep_reward": 3.9777777194976807, "reward": 0.9923068881034851, "action": -0.9285199046134949}
{"mode": "train", "epochs": 2, "timestep": 2005, "ep_reward": 4.967901229858398, "reward": 0.9901233911514282, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 2006, "ep_reward": 5.951564788818359, "reward": 0.9836633205413818, "action": -0.4795415997505188}
{"mode": "train", "epochs": 2, "timestep": 2007, "ep_reward": 6.929926872253418, "reward": 0.9783620238304138, "action": -1.1885433197021484}
{"mode": "train", "epochs": 2, "timestep": 2008, "ep_reward": 7.896965980529785, "reward": 0.9670390486717224, "action": -0.7909125089645386}
{"mode": "train", "epochs": 2, "timestep": 2009, "ep_reward": 8.84842300415039, "reward": 0.9514572024345398, "action": -1.3257840871810913}
{"mode": "train", "epochs": 2, "timestep": 2010, "ep_reward": 9.773229598999023, "reward": 0.9248064756393433, "action": -1.7008728981018066}
{"mode": "train", "epochs": 2, "timestep": 2011, "ep_reward": 10.655782699584961, "reward": 0.882552981376648, "action": -0.5751721858978271}
{"mode": "train", "epochs": 2, "timestep": 2012, "ep_reward": 11.486017227172852, "reward": 0.8302340507507324, "action": -0.768986165523529}
{"mode": "train", "epochs": 2, "timestep": 2013, "ep_reward": 12.240381240844727, "reward": 0.7543635964393616, "action": -0.44879448413848877}
{"mode": "train", "epochs": 2, "timestep": 2014, "ep_reward": 12.894586563110352, "reward": 0.6542055606842041, "action": -1.4361597299575806}
{"mode": "train", "epochs": 2, "timestep": 2015, "ep_reward": 13.404411315917969, "reward": 0.5098246932029724, "action": -1.126734733581543}
{"mode": "train", "epochs": 2, "timestep": 2016, "ep_reward": 13.738908767700195, "reward": 0.33449727296829224, "action": -0.35501986742019653}
{"mode": "train", "epochs": 2, "timestep": 2017, "ep_reward": 13.910564422607422, "reward": 0.17165613174438477, "action": -0.5739755034446716}
{"mode": "train", "epochs": 2, "timestep": 2018, "ep_reward": 13.941344261169434, "reward": 0.03078007698059082, "action": -0.24613797664642334}
{"mode": "train", "epochs": 2, "timestep": 2019, "ep_reward": 14.028059959411621, "reward": 0.08671581745147705, "action": -1.5607109069824219}
{"mode": "train", "epochs": 2, "timestep": 2020, "ep_reward": 14.24809741973877, "reward": 0.22003740072250366, "action": -1.248007893562317}
{"mode": "train", "epochs": 2, "timestep": 2021, "ep_reward": 14.605484962463379, "reward": 0.3573874831199646, "action": -1.1430472135543823}
{"mode": "train", "epochs": 2, "timestep": 2022, "ep_reward": 15.093918800354004, "reward": 0.4884336590766907, "action": -1.0560317039489746}
{"mode": "train", "epochs": 2, "timestep": 2023, "ep_reward": 15.697515487670898, "reward": 0.6035971641540527, "action": -0.7257267236709595}
{"mode": "train", "epochs": 2, "timestep": 2024, "ep_reward": 16.397279739379883, "reward": 0.6997638940811157, "action": -1.2682373523712158}
{"mode": "train", "epochs": 2, "timestep": 2025, "ep_reward": 17.163944244384766, "reward": 0.7666642069816589, "action": -1.6785805225372314}
{"mode": "train", "epochs": 2, "timestep": 2026, "ep_reward": 17.97245216369629, "reward": 0.8085076808929443, "action": -1.2413991689682007}
{"mode": "train", "epochs": 2, "timestep": 2027, "ep_reward": 18.807209014892578, "reward": 0.8347565531730652, "action": -0.8216288089752197}
{"mode": "train", "epochs": 2, "timestep": 2028, "ep_reward": 19.65291976928711, "reward": 0.8457100987434387, "action": 0.1969062089920044}
{"mode": "train", "epochs": 2, "timestep": 2029, "ep_reward": 20.49994659423828, "reward": 0.8470264673233032, "action": -0.2679483890533447}
{"mode": "train", "epochs": 2, "timestep": 2030, "ep_reward": 21.324392318725586, "reward": 0.8244462013244629, "action": -1.2565754652023315}
{"mode": "train", "epochs": 2, "timestep": 2031, "ep_reward": 22.092941284179688, "reward": 0.7685495615005493, "action": -1.696089267730713}
{"mode": "train", "epochs": 2, "timestep": 2032, "ep_reward": 22.76889991760254, "reward": 0.6759586930274963, "action": -1.0249632596969604}
{"mode": "train", "epochs": 2, "timestep": 2033, "ep_reward": 23.320934295654297, "reward": 0.5520346760749817, "action": -0.9780734777450562}
{"mode": "train", "epochs": 2, "timestep": 2034, "ep_reward": 23.71468162536621, "reward": 0.3937472701072693, "action": -0.2771047353744507}
{"mode": "train", "epochs": 2, "timestep": 2035, "ep_reward": 24.007566452026367, "reward": 0.2928849458694458, "action": -0.7815556526184082}
{"mode": "train", "epochs": 2, "timestep": 2036, "ep_reward": 24.179624557495117, "reward": 0.17205899953842163, "action": -0.7509827613830566}
{"mode": "train", "epochs": 2, "timestep": 2037, "ep_reward": 24.210813522338867, "reward": 0.031189382076263428, "action": -1.1026116609573364}
{"mode": "train", "epochs": 2, "timestep": 2038, "ep_reward": 24.297117233276367, "reward": 0.08630388975143433, "action": -1.3069605827331543}
{"mode": "train", "epochs": 2, "timestep": 2039, "ep_reward": 24.51749610900879, "reward": 0.22037869691848755, "action": -0.295213520526886}
{"mode": "train", "epochs": 2, "timestep": 2040, "ep_reward": 24.886821746826172, "reward": 0.3693253993988037, "action": -0.914179801940918}
{"mode": "train", "epochs": 2, "timestep": 2041, "ep_reward": 25.387483596801758, "reward": 0.5006617307662964, "action": -0.8181352615356445}
{"mode": "train", "epochs": 2, "timestep": 2042, "ep_reward": 26.003376007080078, "reward": 0.6158922910690308, "action": -1.785322666168213}
{"mode": "train", "epochs": 2, "timestep": 2043, "ep_reward": 26.703140258789062, "reward": 0.6997634172439575, "action": -1.4706610441207886}
{"mode": "train", "epochs": 2, "timestep": 2044, "ep_reward": 27.46921730041504, "reward": 0.7660779356956482, "action": 0.19251537322998047}
{"mode": "train", "epochs": 2, "timestep": 2045, "ep_reward": 28.295576095581055, "reward": 0.8263590931892395, "action": -1.2864394187927246}
{"mode": "train", "epochs": 2, "timestep": 2046, "ep_reward": 29.149425506591797, "reward": 0.8538495302200317, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 2047, "ep_reward": 30.008485794067383, "reward": 0.8590594530105591, "action": -0.7778497338294983}
{"mode": "train", "epochs": 2, "timestep": 2048, "ep_reward": 30.8662109375, "reward": 0.8577254414558411, "action": -0.5088940858840942}
{"mode": "train", "epochs": 2, "timestep": 2049, "ep_reward": 31.7067813873291, "reward": 0.8405700325965881, "action": -0.6927816271781921}
{"mode": "train", "epochs": 2, "timestep": 2050, "ep_reward": 32.50740432739258, "reward": 0.8006247878074646, "action": -1.510718822479248}
{"mode": "train", "epochs": 2, "timestep": 2051, "ep_reward": 33.23233413696289, "reward": 0.7249311208724976, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 2052, "ep_reward": 33.83863067626953, "reward": 0.6062982082366943, "action": -1.446098804473877}
{"mode": "train", "epochs": 2, "timestep": 2053, "ep_reward": 34.28871536254883, "reward": 0.45008283853530884, "action": -0.48253899812698364}
{"mode": "train", "epochs": 2, "timestep": 2054, "ep_reward": 34.62471008300781, "reward": 0.3359951376914978, "action": -1.1346409320831299}
{"mode": "train", "epochs": 2, "timestep": 2055, "ep_reward": 34.84797668457031, "reward": 0.22326600551605225, "action": -1.000761866569519}
{"mode": "train", "epochs": 2, "timestep": 2056, "ep_reward": 34.93851852416992, "reward": 0.09054088592529297, "action": -0.8078054189682007}
{"mode": "train", "epochs": 2, "timestep": 2057, "ep_reward": 34.9653434753418, "reward": 0.02682626247406006, "action": -0.7200711965560913}
{"mode": "train", "epochs": 2, "timestep": 2058, "ep_reward": 35.13359832763672, "reward": 0.1682559847831726, "action": -0.49165308475494385}
{"mode": "train", "epochs": 2, "timestep": 2059, "ep_reward": 35.448036193847656, "reward": 0.31443870067596436, "action": -0.8365655541419983}
{"mode": "train", "epochs": 2, "timestep": 2060, "ep_reward": 35.898887634277344, "reward": 0.45085281133651733, "action": -1.19511079788208}
{"mode": "train", "epochs": 2, "timestep": 2061, "ep_reward": 36.46826171875, "reward": 0.5693755745887756, "action": -0.9127998948097229}
{"mode": "train", "epochs": 2, "timestep": 2062, "ep_reward": 37.139713287353516, "reward": 0.6714531183242798, "action": -1.2235139608383179}
{"mode": "train", "epochs": 2, "timestep": 2063, "ep_reward": 37.88794708251953, "reward": 0.7482343912124634, "action": 0.07658076286315918}
{"mode": "train", "epochs": 2, "timestep": 2064, "ep_reward": 38.70310592651367, "reward": 0.8151569962501526, "action": -1.6290112733840942}
{"mode": "train", "epochs": 2, "timestep": 2065, "ep_reward": 39.55085372924805, "reward": 0.8477495312690735, "action": -0.28385627269744873}
{"mode": "train", "epochs": 2, "timestep": 2066, "ep_reward": 40.425926208496094, "reward": 0.875071108341217, "action": -1.2710245847702026}
{"mode": "train", "epochs": 2, "timestep": 2067, "ep_reward": 41.305179595947266, "reward": 0.8792536854743958, "action": -1.715482234954834}
{"mode": "train", "epochs": 2, "timestep": 2068, "ep_reward": 42.169681549072266, "reward": 0.864500880241394, "action": -0.6238332986831665}
{"mode": "train", "epochs": 2, "timestep": 2069, "ep_reward": 43.01082992553711, "reward": 0.8411465287208557, "action": -0.5576416254043579}
{"mode": "train", "epochs": 2, "timestep": 2070, "ep_reward": 43.80828857421875, "reward": 0.7974599003791809, "action": -1.0743087530136108}
{"mode": "train", "epochs": 2, "timestep": 2071, "ep_reward": 44.53007507324219, "reward": 0.7217849493026733, "action": -0.9691647291183472}
{"mode": "train", "epochs": 2, "timestep": 2072, "ep_reward": 45.143043518066406, "reward": 0.6129666566848755, "action": -1.386113166809082}
{"mode": "train", "epochs": 2, "timestep": 2073, "ep_reward": 45.60076904296875, "reward": 0.4577239751815796, "action": -1.644710659980774}
{"mode": "train", "epochs": 2, "timestep": 2074, "ep_reward": 45.924293518066406, "reward": 0.32352548837661743, "action": -1.3555727005004883}
{"mode": "train", "epochs": 2, "timestep": 2075, "ep_reward": 46.13267135620117, "reward": 0.20837914943695068, "action": -1.394027590751648}
{"mode": "train", "epochs": 2, "timestep": 2076, "ep_reward": 46.20596694946289, "reward": 0.07329702377319336, "action": -1.0112876892089844}
{"mode": "train", "epochs": 2, "timestep": 2077, "ep_reward": 46.25068283081055, "reward": 0.044717609882354736, "action": -1.339464783668518}
{"mode": "train", "epochs": 2, "timestep": 2078, "ep_reward": 46.434452056884766, "reward": 0.18376833200454712, "action": -1.136821985244751}
{"mode": "train", "epochs": 2, "timestep": 2079, "ep_reward": 46.75658416748047, "reward": 0.32213294506073, "action": -1.5403915643692017}
{"mode": "train", "epochs": 2, "timestep": 2080, "ep_reward": 47.207427978515625, "reward": 0.45084232091903687, "action": -1.122469186782837}
{"mode": "train", "epochs": 2, "timestep": 2081, "ep_reward": 47.7784538269043, "reward": 0.5710275769233704, "action": -0.9074894189834595}
{"mode": "train", "epochs": 2, "timestep": 2082, "ep_reward": 48.450809478759766, "reward": 0.6723545789718628, "action": -1.325921654701233}
{"mode": "train", "epochs": 2, "timestep": 2083, "ep_reward": 49.1966667175293, "reward": 0.7458559274673462, "action": -1.1974225044250488}
{"mode": "train", "epochs": 2, "timestep": 2084, "ep_reward": 49.995155334472656, "reward": 0.7984891533851624, "action": -1.0865097045898438}
{"mode": "train", "epochs": 2, "timestep": 2085, "ep_reward": 50.82676315307617, "reward": 0.8316063284873962, "action": -0.40454912185668945}
{"mode": "train", "epochs": 2, "timestep": 2086, "ep_reward": 51.67842483520508, "reward": 0.851660430431366, "action": -0.734562337398529}
{"mode": "train", "epochs": 2, "timestep": 2087, "ep_reward": 52.52873229980469, "reward": 0.8503067493438721, "action": -1.262346863746643}
{"mode": "train", "epochs": 2, "timestep": 2088, "ep_reward": 53.35315704345703, "reward": 0.8244242072105408, "action": -1.5864861011505127}
{"mode": "train", "epochs": 2, "timestep": 2089, "ep_reward": 54.12413787841797, "reward": 0.7709826827049255, "action": -0.06165516376495361}
{"mode": "train", "epochs": 2, "timestep": 2090, "ep_reward": 54.82867431640625, "reward": 0.7045361399650574, "action": -1.0656105279922485}
{"mode": "train", "epochs": 2, "timestep": 2091, "ep_reward": 55.419822692871094, "reward": 0.5911482572555542, "action": -1.3762832880020142}
{"mode": "train", "epochs": 2, "timestep": 2092, "ep_reward": 55.85015869140625, "reward": 0.43033671379089355, "action": -1.980762004852295}
{"mode": "train", "epochs": 2, "timestep": 2093, "ep_reward": 56.17127227783203, "reward": 0.3211151957511902, "action": -0.8084145188331604}
{"mode": "train", "epochs": 2, "timestep": 2094, "ep_reward": 56.37657165527344, "reward": 0.20529961585998535, "action": -1.9804186820983887}
{"mode": "train", "epochs": 2, "timestep": 2095, "ep_reward": 56.446441650390625, "reward": 0.06987011432647705, "action": -1.0072003602981567}
{"mode": "train", "epochs": 2, "timestep": 2096, "ep_reward": 56.49476623535156, "reward": 0.04832535982131958, "action": -0.43964195251464844}
{"mode": "train", "epochs": 2, "timestep": 2097, "ep_reward": 56.68659973144531, "reward": 0.19183486700057983, "action": -1.6984026432037354}
{"mode": "train", "epochs": 2, "timestep": 2098, "ep_reward": 57.00904083251953, "reward": 0.3224416971206665, "action": -0.3562774062156677}
{"mode": "train", "epochs": 2, "timestep": 2099, "ep_reward": 57.4744758605957, "reward": 0.4654356837272644, "action": -1.3149433135986328}
{"mode": "train", "epochs": 2, "timestep": 2100, "ep_reward": 58.05527877807617, "reward": 0.5808045864105225, "action": -1.5055453777313232}
{"mode": "train", "epochs": 2, "timestep": 2101, "ep_reward": 58.72959899902344, "reward": 0.6743190288543701, "action": -1.3988500833511353}
{"mode": "train", "epochs": 2, "timestep": 2102, "ep_reward": 59.47666931152344, "reward": 0.7470718622207642, "action": -1.5422496795654297}
{"mode": "train", "epochs": 2, "timestep": 2103, "ep_reward": 60.27359390258789, "reward": 0.7969248294830322, "action": -1.1099764108657837}
{"mode": "train", "epochs": 2, "timestep": 2104, "ep_reward": 61.10407638549805, "reward": 0.8304818868637085, "action": -1.6455504894256592}
{"mode": "train", "epochs": 2, "timestep": 2105, "ep_reward": 61.94407653808594, "reward": 0.8399987816810608, "action": -1.516526699066162}
{"mode": "train", "epochs": 2, "timestep": 2106, "ep_reward": 62.77521896362305, "reward": 0.8311408162117004, "action": -0.23705661296844482}
{"mode": "train", "epochs": 2, "timestep": 2107, "ep_reward": 63.588226318359375, "reward": 0.8130068778991699, "action": -0.9692349433898926}
{"mode": "train", "epochs": 2, "timestep": 2108, "ep_reward": 64.35112762451172, "reward": 0.7629026174545288, "action": -0.37482333183288574}
{"mode": "train", "epochs": 2, "timestep": 2109, "ep_reward": 65.04035949707031, "reward": 0.6892296075820923, "action": -0.8996368050575256}
{"mode": "train", "epochs": 2, "timestep": 2110, "ep_reward": 65.61324310302734, "reward": 0.5728859901428223, "action": -1.0598502159118652}
{"mode": "train", "epochs": 2, "timestep": 2111, "ep_reward": 66.02499389648438, "reward": 0.41174912452697754, "action": -0.8249901533126831}
{"mode": "train", "epochs": 2, "timestep": 2112, "ep_reward": 66.33426666259766, "reward": 0.3092707395553589, "action": -0.24783360958099365}
{"mode": "train", "epochs": 2, "timestep": 2113, "ep_reward": 66.52568817138672, "reward": 0.19142407178878784, "action": -0.4387991428375244}
{"mode": "train", "epochs": 2, "timestep": 2114, "ep_reward": 66.57926940917969, "reward": 0.05357933044433594, "action": -0.5406277179718018}
{"mode": "train", "epochs": 2, "timestep": 2115, "ep_reward": 66.64386749267578, "reward": 0.06459838151931763, "action": -1.5743600130081177}
{"mode": "train", "epochs": 2, "timestep": 2116, "ep_reward": 66.84490203857422, "reward": 0.20103561878204346, "action": -0.7859621644020081}
{"mode": "train", "epochs": 2, "timestep": 2117, "ep_reward": 67.18897247314453, "reward": 0.3440677523612976, "action": 0.02770411968231201}
{"mode": "train", "epochs": 2, "timestep": 2118, "ep_reward": 67.67806243896484, "reward": 0.4890907406806946, "action": -1.1523561477661133}
{"mode": "train", "epochs": 2, "timestep": 2119, "ep_reward": 68.2804946899414, "reward": 0.602428674697876, "action": -1.2272447347640991}
{"mode": "train", "epochs": 2, "timestep": 2120, "ep_reward": 68.9753646850586, "reward": 0.6948714256286621, "action": -0.9363893270492554}
{"mode": "train", "epochs": 2, "timestep": 2121, "ep_reward": 69.743896484375, "reward": 0.7685308456420898, "action": -0.543369710445404}
{"mode": "train", "epochs": 2, "timestep": 2122, "ep_reward": 70.56851959228516, "reward": 0.8246234655380249, "action": -0.7437514066696167}
{"mode": "train", "epochs": 2, "timestep": 2123, "ep_reward": 71.42878723144531, "reward": 0.860266923904419, "action": -1.1122372150421143}
{"mode": "train", "epochs": 2, "timestep": 2124, "ep_reward": 72.30599975585938, "reward": 0.8772114515304565, "action": -0.31860923767089844}
{"mode": "train", "epochs": 2, "timestep": 2125, "ep_reward": 73.19184875488281, "reward": 0.885852575302124, "action": -0.6861270666122437}
{"mode": "train", "epochs": 2, "timestep": 2126, "ep_reward": 74.0688705444336, "reward": 0.8770182132720947, "action": -1.2223896980285645}
{"mode": "train", "epochs": 2, "timestep": 2127, "ep_reward": 74.91598510742188, "reward": 0.8471150398254395, "action": -1.3546926975250244}
{"mode": "train", "epochs": 2, "timestep": 2128, "ep_reward": 75.71041107177734, "reward": 0.7944235801696777, "action": 0.24242615699768066}
{"mode": "train", "epochs": 2, "timestep": 2129, "ep_reward": 76.44242095947266, "reward": 0.7320098280906677, "action": -0.2120751142501831}
{"mode": "train", "epochs": 2, "timestep": 2130, "ep_reward": 77.07733917236328, "reward": 0.6349146366119385, "action": -1.3648488521575928}
{"mode": "train", "epochs": 2, "timestep": 2131, "ep_reward": 77.56336212158203, "reward": 0.48601943254470825, "action": -1.0085023641586304}
{"mode": "train", "epochs": 2, "timestep": 2132, "ep_reward": 77.8896255493164, "reward": 0.32626062631607056, "action": -0.3010822534561157}
{"mode": "train", "epochs": 2, "timestep": 2133, "ep_reward": 78.10121154785156, "reward": 0.21158266067504883, "action": -0.8391517400741577}
{"mode": "train", "epochs": 2, "timestep": 2134, "ep_reward": 78.17819213867188, "reward": 0.07697969675064087, "action": -0.340329110622406}
{"mode": "train", "epochs": 2, "timestep": 2135, "ep_reward": 78.21924591064453, "reward": 0.04105144739151001, "action": -0.8339256048202515}
{"mode": "train", "epochs": 2, "timestep": 2136, "ep_reward": 78.39981842041016, "reward": 0.1805717945098877, "action": -0.8343746662139893}
{"mode": "train", "epochs": 2, "timestep": 2137, "ep_reward": 78.72252655029297, "reward": 0.3227091431617737, "action": -1.0289747714996338}
{"mode": "train", "epochs": 2, "timestep": 2138, "ep_reward": 79.17949676513672, "reward": 0.4569682478904724, "action": -1.1494789123535156}
{"mode": "train", "epochs": 2, "timestep": 2139, "ep_reward": 79.75498962402344, "reward": 0.575496256351471, "action": -1.2555949687957764}
{"mode": "train", "epochs": 2, "timestep": 2140, "ep_reward": 80.42768096923828, "reward": 0.6726906895637512, "action": -1.167783498764038}
{"mode": "train", "epochs": 2, "timestep": 2141, "ep_reward": 81.1761474609375, "reward": 0.7484687566757202, "action": -1.1839343309402466}
{"mode": "train", "epochs": 2, "timestep": 2142, "ep_reward": 81.9784927368164, "reward": 0.8023486733436584, "action": -0.5993068814277649}
{"mode": "train", "epochs": 2, "timestep": 2143, "ep_reward": 82.81974029541016, "reward": 0.8412483334541321, "action": -1.8360474109649658}
{"mode": "train", "epochs": 2, "timestep": 2144, "ep_reward": 83.67107391357422, "reward": 0.8513321876525879, "action": -1.173941731452942}
{"mode": "train", "epochs": 2, "timestep": 2145, "ep_reward": 84.52045440673828, "reward": 0.8493784070014954, "action": -1.1443802118301392}
{"mode": "train", "epochs": 2, "timestep": 2146, "ep_reward": 85.34854888916016, "reward": 0.8280972838401794, "action": -1.3461922407150269}
{"mode": "train", "epochs": 2, "timestep": 2147, "ep_reward": 86.12991333007812, "reward": 0.7813674211502075, "action": -1.003567099571228}
{"mode": "train", "epochs": 2, "timestep": 2148, "ep_reward": 86.83872985839844, "reward": 0.7088181972503662, "action": -0.5151324272155762}
{"mode": "train", "epochs": 2, "timestep": 2149, "ep_reward": 87.44571685791016, "reward": 0.6069860458374023, "action": -0.14826816320419312}
{"mode": "train", "epochs": 2, "timestep": 2150, "ep_reward": 87.91699981689453, "reward": 0.4712802767753601, "action": -1.6787916421890259}
{"mode": "train", "epochs": 2, "timestep": 2151, "ep_reward": 88.25526428222656, "reward": 0.3382669687271118, "action": -1.3564627170562744}
{"mode": "train", "epochs": 2, "timestep": 2152, "ep_reward": 88.4813232421875, "reward": 0.2260611653327942, "action": -0.6078041195869446}
{"mode": "train", "epochs": 2, "timestep": 2153, "ep_reward": 88.5750503540039, "reward": 0.0937265157699585, "action": -0.9797284007072449}
{"mode": "train", "epochs": 2, "timestep": 2154, "ep_reward": 88.59840393066406, "reward": 0.023356854915618896, "action": -1.2187342643737793}
{"mode": "train", "epochs": 2, "timestep": 2155, "ep_reward": 88.76362609863281, "reward": 0.1652202010154724, "action": -1.211972951889038}
{"mode": "train", "epochs": 2, "timestep": 2156, "ep_reward": 89.0660629272461, "reward": 0.30243825912475586, "action": -1.0174450874328613}
{"mode": "train", "epochs": 2, "timestep": 2157, "ep_reward": 89.5046157836914, "reward": 0.4385528564453125, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 2158, "ep_reward": 90.05461120605469, "reward": 0.5499987602233887, "action": -1.9789515733718872}
{"mode": "train", "epochs": 2, "timestep": 2159, "ep_reward": 90.6985855102539, "reward": 0.6439769268035889, "action": -0.8905209302902222}
{"mode": "train", "epochs": 2, "timestep": 2160, "ep_reward": 91.42574310302734, "reward": 0.7271583080291748, "action": -1.767890453338623}
{"mode": "train", "epochs": 2, "timestep": 2161, "ep_reward": 92.20338439941406, "reward": 0.7776405215263367, "action": -1.1328253746032715}
{"mode": "train", "epochs": 2, "timestep": 2162, "ep_reward": 93.01583099365234, "reward": 0.8124476075172424, "action": -1.0226300954818726}
{"mode": "train", "epochs": 2, "timestep": 2163, "ep_reward": 93.84278869628906, "reward": 0.8269575238227844, "action": -0.8052922487258911}
{"mode": "train", "epochs": 2, "timestep": 2164, "ep_reward": 94.66502380371094, "reward": 0.8222339153289795, "action": -0.8679273724555969}
{"mode": "train", "epochs": 2, "timestep": 2165, "ep_reward": 95.45875549316406, "reward": 0.7937344312667847, "action": -1.3769457340240479}
{"mode": "train", "epochs": 2, "timestep": 2166, "ep_reward": 96.19075775146484, "reward": 0.7320054769515991, "action": 0.14941585063934326}
{"mode": "train", "epochs": 2, "timestep": 2167, "ep_reward": 96.84573364257812, "reward": 0.6549782156944275, "action": -1.468029499053955}
{"mode": "train", "epochs": 2, "timestep": 2168, "ep_reward": 97.36381530761719, "reward": 0.5180836915969849, "action": -0.04714834690093994}
{"mode": "train", "epochs": 2, "timestep": 2169, "ep_reward": 97.74773406982422, "reward": 0.383916437625885, "action": -1.6997458934783936}
{"mode": "train", "epochs": 2, "timestep": 2170, "ep_reward": 98.02888488769531, "reward": 0.2811526656150818, "action": -0.4593297839164734}
{"mode": "train", "epochs": 2, "timestep": 2171, "ep_reward": 98.18693542480469, "reward": 0.1580517292022705, "action": -1.7099392414093018}
{"mode": "train", "epochs": 2, "timestep": 2172, "ep_reward": 98.20220947265625, "reward": 0.015272557735443115, "action": -0.6983128786087036}
{"mode": "train", "epochs": 2, "timestep": 2173, "ep_reward": 98.3035659790039, "reward": 0.10135602951049805, "action": -0.37072211503982544}
{"mode": "train", "epochs": 2, "timestep": 2174, "ep_reward": 98.55097198486328, "reward": 0.24740290641784668, "action": -1.3050527572631836}
{"mode": "train", "epochs": 2, "timestep": 2175, "ep_reward": 98.93211364746094, "reward": 0.3811401128768921, "action": -0.922343373298645}
{"mode": "train", "epochs": 2, "timestep": 2176, "ep_reward": 99.44329071044922, "reward": 0.5111775398254395, "action": -1.0915638208389282}
{"mode": "train", "epochs": 2, "timestep": 2177, "ep_reward": 100.06514739990234, "reward": 0.6218596696853638, "action": -1.3577224016189575}
{"mode": "train", "epochs": 2, "timestep": 2178, "ep_reward": 100.77377319335938, "reward": 0.7086292505264282, "action": -0.47086524963378906}
{"mode": "train", "epochs": 2, "timestep": 2179, "ep_reward": 101.55570220947266, "reward": 0.7819278836250305, "action": -0.7356384992599487}
{"mode": "train", "epochs": 2, "timestep": 2180, "ep_reward": 102.38688659667969, "reward": 0.8311880826950073, "action": -1.5473055839538574}
{"mode": "train", "epochs": 2, "timestep": 2181, "ep_reward": 103.24248504638672, "reward": 0.8555977940559387, "action": -1.5055577754974365}
{"mode": "train", "epochs": 2, "timestep": 2182, "ep_reward": 104.10673522949219, "reward": 0.8642472624778748, "action": -1.0006102323532104}
{"mode": "train", "epochs": 2, "timestep": 2183, "ep_reward": 104.96731567382812, "reward": 0.8605828285217285, "action": -0.9865390658378601}
{"mode": "train", "epochs": 2, "timestep": 2184, "ep_reward": 105.8061752319336, "reward": 0.8388609290122986, "action": -0.8862076997756958}
{"mode": "train", "epochs": 2, "timestep": 2185, "ep_reward": 106.60257720947266, "reward": 0.7964049577713013, "action": -0.9437819719314575}
{"mode": "train", "epochs": 2, "timestep": 2186, "ep_reward": 107.32868957519531, "reward": 0.7261090278625488, "action": -1.742672085762024}
{"mode": "train", "epochs": 2, "timestep": 2187, "ep_reward": 107.93976593017578, "reward": 0.6110767126083374, "action": -0.5836374759674072}
{"mode": "train", "epochs": 2, "timestep": 2188, "ep_reward": 108.40931701660156, "reward": 0.4695543050765991, "action": -0.8490407466888428}
{"mode": "train", "epochs": 2, "timestep": 2189, "ep_reward": 108.7469482421875, "reward": 0.33763331174850464, "action": -1.2722722291946411}
{"mode": "train", "epochs": 2, "timestep": 2190, "ep_reward": 108.97222900390625, "reward": 0.22527730464935303, "action": -0.7265462875366211}
{"mode": "train", "epochs": 2, "timestep": 2191, "ep_reward": 109.06507110595703, "reward": 0.09284472465515137, "action": -0.8125648498535156}
{"mode": "train", "epochs": 2, "timestep": 2192, "ep_reward": 109.08944702148438, "reward": 0.0243796706199646, "action": -0.6938011646270752}
{"mode": "train", "epochs": 2, "timestep": 2193, "ep_reward": 109.25557708740234, "reward": 0.16612845659255981, "action": -0.5250107049942017}
{"mode": "train", "epochs": 2, "timestep": 2194, "ep_reward": 109.56730651855469, "reward": 0.3117331266403198, "action": -1.6766691207885742}
{"mode": "train", "epochs": 2, "timestep": 2195, "ep_reward": 110.00580596923828, "reward": 0.4384990930557251, "action": -0.7512041330337524}
{"mode": "train", "epochs": 2, "timestep": 2196, "ep_reward": 110.56990051269531, "reward": 0.5640963315963745, "action": -1.719543218612671}
{"mode": "train", "epochs": 2, "timestep": 2197, "ep_reward": 111.22872924804688, "reward": 0.658826470375061, "action": -0.16843277215957642}
{"mode": "train", "epochs": 2, "timestep": 2198, "ep_reward": 111.9762191772461, "reward": 0.7474913597106934, "action": -0.5706329345703125}
{"mode": "train", "epochs": 2, "timestep": 2199, "ep_reward": 112.7845458984375, "reward": 0.808330237865448, "action": -1.508753776550293}
{"mode": "train", "epochs": 2, "timestep": 2200, "ep_reward": 113.62588500976562, "reward": 0.8413425087928772, "action": 0.2559014558792114}
{"mode": "train", "epochs": 2, "timestep": 2201, "ep_reward": 114.4977798461914, "reward": 0.8718979358673096, "action": -1.2637450695037842}
{"mode": "train", "epochs": 2, "timestep": 2202, "ep_reward": 115.37178039550781, "reward": 0.8740032911300659, "action": -0.6982311010360718}
{"mode": "train", "epochs": 2, "timestep": 2203, "ep_reward": 116.23648071289062, "reward": 0.8647018671035767, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 2204, "ep_reward": 117.06175994873047, "reward": 0.8252829313278198, "action": -1.643784999847412}
{"mode": "train", "epochs": 2, "timestep": 2205, "ep_reward": 117.82537078857422, "reward": 0.7636101841926575, "action": -1.4546921253204346}
{"mode": "train", "epochs": 2, "timestep": 2206, "ep_reward": 118.49667358398438, "reward": 0.6713061332702637, "action": -1.2997972965240479}
{"mode": "train", "epochs": 2, "timestep": 2207, "ep_reward": 119.03764343261719, "reward": 0.5409731864929199, "action": -1.1103713512420654}
{"mode": "train", "epochs": 2, "timestep": 2208, "ep_reward": 119.42474365234375, "reward": 0.3870996832847595, "action": -1.2492181062698364}
{"mode": "train", "epochs": 2, "timestep": 2209, "ep_reward": 119.70954895019531, "reward": 0.2848048210144043, "action": -1.4464881420135498}
{"mode": "train", "epochs": 2, "timestep": 2210, "ep_reward": 119.87220001220703, "reward": 0.16265279054641724, "action": -0.5815633535385132}
{"mode": "train", "epochs": 2, "timestep": 2211, "ep_reward": 119.89252471923828, "reward": 0.02032405138015747, "action": -1.1869933605194092}
{"mode": "train", "epochs": 2, "timestep": 2212, "ep_reward": 119.989013671875, "reward": 0.09649050235748291, "action": -1.4666402339935303}
{"mode": "train", "epochs": 2, "timestep": 2213, "ep_reward": 120.2177963256836, "reward": 0.22878146171569824, "action": -1.2746479511260986}
{"mode": "train", "epochs": 2, "timestep": 2214, "ep_reward": 120.58358764648438, "reward": 0.36578911542892456, "action": -0.6701552867889404}
{"mode": "train", "epochs": 2, "timestep": 2215, "ep_reward": 121.08528137207031, "reward": 0.5016941428184509, "action": -0.9595993757247925}
{"mode": "train", "epochs": 2, "timestep": 2216, "ep_reward": 121.70085144042969, "reward": 0.6155699491500854, "action": -1.322735071182251}
{"mode": "train", "epochs": 2, "timestep": 2217, "ep_reward": 122.40428161621094, "reward": 0.7034338712692261, "action": -0.49878525733947754}
{"mode": "train", "epochs": 2, "timestep": 2218, "ep_reward": 123.180908203125, "reward": 0.7766285538673401, "action": -0.8046603798866272}
{"mode": "train", "epochs": 2, "timestep": 2219, "ep_reward": 124.00568389892578, "reward": 0.8247758150100708, "action": -0.9993417263031006}
{"mode": "train", "epochs": 2, "timestep": 2220, "ep_reward": 124.85777282714844, "reward": 0.8520887494087219, "action": -1.8893648386001587}
{"mode": "train", "epochs": 2, "timestep": 2221, "ep_reward": 125.71244812011719, "reward": 0.8546732068061829, "action": -1.1790577173233032}
{"mode": "train", "epochs": 2, "timestep": 2222, "ep_reward": 126.55786895751953, "reward": 0.8454216122627258, "action": -0.9054498672485352}
{"mode": "train", "epochs": 2, "timestep": 2223, "ep_reward": 127.37615966796875, "reward": 0.8182942867279053, "action": -1.449550747871399}
{"mode": "train", "epochs": 2, "timestep": 2224, "ep_reward": 128.13693237304688, "reward": 0.7607696056365967, "action": -1.2859987020492554}
{"mode": "train", "epochs": 2, "timestep": 2225, "ep_reward": 128.80960083007812, "reward": 0.6726728081703186, "action": -0.11845886707305908}
{"mode": "train", "epochs": 2, "timestep": 2226, "ep_reward": 129.3714599609375, "reward": 0.5618557929992676, "action": -0.25303369760513306}
{"mode": "train", "epochs": 2, "timestep": 2227, "ep_reward": 129.78170776367188, "reward": 0.4102506637573242, "action": -1.0574185848236084}
{"mode": "train", "epochs": 2, "timestep": 2228, "ep_reward": 130.0802459716797, "reward": 0.29853445291519165, "action": -0.5387805700302124}
{"mode": "train", "epochs": 2, "timestep": 2229, "ep_reward": 130.2589874267578, "reward": 0.17873752117156982, "action": -0.3125736117362976}
{"mode": "train", "epochs": 2, "timestep": 2230, "ep_reward": 130.2978973388672, "reward": 0.03891080617904663, "action": -0.6156899929046631}
{"mode": "train", "epochs": 2, "timestep": 2231, "ep_reward": 130.37692260742188, "reward": 0.0790184736251831, "action": -0.9314295649528503}
{"mode": "train", "epochs": 2, "timestep": 2232, "ep_reward": 130.59432983398438, "reward": 0.21740460395812988, "action": -1.5834871530532837}
{"mode": "train", "epochs": 2, "timestep": 2233, "ep_reward": 130.9439697265625, "reward": 0.34964048862457275, "action": -1.9272029399871826}
{"mode": "train", "epochs": 2, "timestep": 2234, "ep_reward": 131.416015625, "reward": 0.4720475673675537, "action": -0.04172956943511963}
{"mode": "train", "epochs": 2, "timestep": 2235, "ep_reward": 132.0173797607422, "reward": 0.6013671159744263, "action": -0.9805460572242737}
{"mode": "train", "epochs": 2, "timestep": 2236, "ep_reward": 132.7130584716797, "reward": 0.6956760883331299, "action": -0.5847936272621155}
{"mode": "train", "epochs": 2, "timestep": 2237, "ep_reward": 133.48326110839844, "reward": 0.7701995968818665, "action": -1.7790775299072266}
{"mode": "train", "epochs": 2, "timestep": 2238, "ep_reward": 134.29505920410156, "reward": 0.8117952346801758, "action": -1.346009612083435}
{"mode": "train", "epochs": 2, "timestep": 2239, "ep_reward": 135.1334686279297, "reward": 0.8384151458740234, "action": -0.6002236604690552}
{"mode": "train", "epochs": 2, "timestep": 2240, "ep_reward": 135.98651123046875, "reward": 0.8530436158180237, "action": -1.7231248617172241}
{"mode": "train", "epochs": 2, "timestep": 2241, "ep_reward": 136.82562255859375, "reward": 0.8391115665435791, "action": -0.922989547252655}
{"mode": "train", "epochs": 2, "timestep": 2242, "ep_reward": 137.6370086669922, "reward": 0.8113868236541748, "action": -0.5280888080596924}
{"mode": "train", "epochs": 2, "timestep": 2243, "ep_reward": 138.3997344970703, "reward": 0.762730598449707, "action": -1.8426214456558228}
{"mode": "train", "epochs": 2, "timestep": 2244, "ep_reward": 139.06735229492188, "reward": 0.6676169633865356, "action": -1.3594492673873901}
{"mode": "train", "epochs": 2, "timestep": 2245, "ep_reward": 139.60443115234375, "reward": 0.5370804667472839, "action": 0.060982346534729004}
{"mode": "train", "epochs": 2, "timestep": 2246, "ep_reward": 139.99752807617188, "reward": 0.39310288429260254, "action": -0.43289005756378174}
{"mode": "train", "epochs": 2, "timestep": 2247, "ep_reward": 140.28961181640625, "reward": 0.29207730293273926, "action": -1.0399343967437744}
{"mode": "train", "epochs": 2, "timestep": 2248, "ep_reward": 140.460693359375, "reward": 0.17108756303787231, "action": -1.1827384233474731}
{"mode": "train", "epochs": 2, "timestep": 2249, "ep_reward": 140.49090576171875, "reward": 0.03020477294921875, "action": -0.046733319759368896}
{"mode": "train", "epochs": 2, "timestep": 2250, "ep_reward": 140.5782928466797, "reward": 0.08738189935684204, "action": -0.7606801390647888}
{"mode": "train", "epochs": 2, "timestep": 2251, "ep_reward": 140.8065643310547, "reward": 0.22827869653701782, "action": -0.619888424873352}
{"mode": "train", "epochs": 2, "timestep": 2252, "ep_reward": 141.1781768798828, "reward": 0.37161731719970703, "action": -1.793725848197937}
{"mode": "train", "epochs": 2, "timestep": 2253, "ep_reward": 141.67041015625, "reward": 0.49223703145980835, "action": -1.2955851554870605}
{"mode": "train", "epochs": 2, "timestep": 2254, "ep_reward": 142.2742462158203, "reward": 0.6038413047790527, "action": -1.8244867324829102}
{"mode": "train", "epochs": 2, "timestep": 2255, "ep_reward": 142.96334838867188, "reward": 0.6890976428985596, "action": -0.9145723581314087}
{"mode": "train", "epochs": 2, "timestep": 2256, "ep_reward": 143.72491455078125, "reward": 0.7615607380867004, "action": -0.9909510016441345}
{"mode": "train", "epochs": 2, "timestep": 2257, "ep_reward": 144.5355987548828, "reward": 0.8106774687767029, "action": -1.773119568824768}
{"mode": "train", "epochs": 2, "timestep": 2258, "ep_reward": 145.36834716796875, "reward": 0.8327454924583435, "action": -1.1215935945510864}
{"mode": "train", "epochs": 2, "timestep": 2259, "ep_reward": 146.2100830078125, "reward": 0.8417314291000366, "action": -0.8916850686073303}
{"mode": "train", "epochs": 2, "timestep": 2260, "ep_reward": 147.04324340820312, "reward": 0.8331558704376221, "action": -0.30468207597732544}
{"mode": "train", "epochs": 2, "timestep": 2261, "ep_reward": 147.85202026367188, "reward": 0.8087711334228516, "action": -1.0716631412506104}
{"mode": "train", "epochs": 2, "timestep": 2262, "ep_reward": 148.60330200195312, "reward": 0.7512864470481873, "action": -0.8369798064231873}
{"mode": "train", "epochs": 2, "timestep": 2263, "ep_reward": 149.26763916015625, "reward": 0.6643341779708862, "action": -0.6828522086143494}
{"mode": "train", "epochs": 2, "timestep": 2264, "ep_reward": 149.80885314941406, "reward": 0.5412195920944214, "action": -1.2011480331420898}
{"mode": "train", "epochs": 2, "timestep": 2265, "ep_reward": 150.19508361816406, "reward": 0.38622957468032837, "action": -0.42101800441741943}
{"mode": "train", "epochs": 2, "timestep": 2266, "ep_reward": 150.47879028320312, "reward": 0.28371185064315796, "action": -0.9809014201164246}
{"mode": "train", "epochs": 2, "timestep": 2267, "ep_reward": 150.6399383544922, "reward": 0.16114920377731323, "action": -1.5698513984680176}
{"mode": "train", "epochs": 2, "timestep": 2268, "ep_reward": 150.65869140625, "reward": 0.018751084804534912, "action": -1.1535753011703491}
{"mode": "train", "epochs": 2, "timestep": 2269, "ep_reward": 150.75660705566406, "reward": 0.09791803359985352, "action": -1.6745975017547607}
{"mode": "train", "epochs": 2, "timestep": 2270, "ep_reward": 150.98631286621094, "reward": 0.22970598936080933, "action": -1.121171236038208}
{"mode": "train", "epochs": 2, "timestep": 2271, "ep_reward": 151.35484313964844, "reward": 0.3685343861579895, "action": -1.648068904876709}
{"mode": "train", "epochs": 2, "timestep": 2272, "ep_reward": 151.8473358154297, "reward": 0.49248743057250977, "action": -1.1764189004898071}
{"mode": "train", "epochs": 2, "timestep": 2273, "ep_reward": 152.45297241210938, "reward": 0.6056381464004517, "action": -1.1730221509933472}
{"mode": "train", "epochs": 2, "timestep": 2274, "ep_reward": 153.1492462158203, "reward": 0.6962807178497314, "action": -0.5829705595970154}
{"mode": "train", "epochs": 2, "timestep": 2275, "ep_reward": 153.9180908203125, "reward": 0.7688515186309814, "action": -1.3147716522216797}
{"mode": "train", "epochs": 2, "timestep": 2276, "ep_reward": 154.7296142578125, "reward": 0.8115251064300537, "action": -1.4841952323913574}
{"mode": "train", "epochs": 2, "timestep": 2277, "ep_reward": 155.56227111816406, "reward": 0.8326559066772461, "action": -0.8621026277542114}
{"mode": "train", "epochs": 2, "timestep": 2278, "ep_reward": 156.40216064453125, "reward": 0.8398885130882263, "action": -1.4709275960922241}
{"mode": "train", "epochs": 2, "timestep": 2279, "ep_reward": 157.2230987548828, "reward": 0.820944607257843, "action": -0.8526057600975037}
{"mode": "train", "epochs": 2, "timestep": 2280, "ep_reward": 158.00741577148438, "reward": 0.784321665763855, "action": -0.5401864051818848}
{"mode": "train", "epochs": 2, "timestep": 2281, "ep_reward": 158.73036193847656, "reward": 0.7229441404342651, "action": -1.5205943584442139}
{"mode": "train", "epochs": 2, "timestep": 2282, "ep_reward": 159.34503173828125, "reward": 0.6146701574325562, "action": -0.828486442565918}
{"mode": "train", "epochs": 2, "timestep": 2283, "ep_reward": 159.81781005859375, "reward": 0.4727851152420044, "action": -1.002300500869751}
{"mode": "train", "epochs": 2, "timestep": 2284, "ep_reward": 160.17202758789062, "reward": 0.3542219400405884, "action": -0.9501175284385681}
{"mode": "train", "epochs": 2, "timestep": 2285, "ep_reward": 160.41714477539062, "reward": 0.24512159824371338, "action": -0.5007567405700684}
{"mode": "train", "epochs": 2, "timestep": 2286, "ep_reward": 160.5330810546875, "reward": 0.11594021320343018, "action": -0.9449090957641602}
{"mode": "train", "epochs": 2, "timestep": 2287, "ep_reward": 160.53228759765625, "reward": -0.0007951259613037109, "action": -0.6630162000656128}
{"mode": "train", "epochs": 2, "timestep": 2288, "ep_reward": 160.67648315429688, "reward": 0.14419275522232056, "action": -0.9671124219894409}
{"mode": "train", "epochs": 2, "timestep": 2289, "ep_reward": 160.96043395996094, "reward": 0.28394681215286255, "action": -1.4310113191604614}
{"mode": "train", "epochs": 2, "timestep": 2290, "ep_reward": 161.37611389160156, "reward": 0.4156770706176758, "action": -1.7956269979476929}
{"mode": "train", "epochs": 2, "timestep": 2291, "ep_reward": 161.9086151123047, "reward": 0.5325028896331787, "action": -1.2907947301864624}
{"mode": "train", "epochs": 2, "timestep": 2292, "ep_reward": 162.5458526611328, "reward": 0.6372435688972473, "action": -1.4454081058502197}
{"mode": "train", "epochs": 2, "timestep": 2293, "ep_reward": 163.26351928710938, "reward": 0.7176718711853027, "action": -0.6063076257705688}
{"mode": "train", "epochs": 2, "timestep": 2294, "ep_reward": 164.0466766357422, "reward": 0.7831610441207886, "action": -1.2203269004821777}
{"mode": "train", "epochs": 2, "timestep": 2295, "ep_reward": 164.86717224121094, "reward": 0.8204923868179321, "action": -1.1696587800979614}
{"mode": "train", "epochs": 2, "timestep": 2296, "ep_reward": 165.7054901123047, "reward": 0.8383117914199829, "action": -1.775148868560791}
{"mode": "train", "epochs": 2, "timestep": 2297, "ep_reward": 166.5364532470703, "reward": 0.8309580683708191, "action": -0.8027640581130981}
{"mode": "train", "epochs": 2, "timestep": 2298, "ep_reward": 167.3476104736328, "reward": 0.8111620545387268, "action": -0.6572964191436768}
{"mode": "train", "epochs": 2, "timestep": 2299, "ep_reward": 168.11570739746094, "reward": 0.7680952548980713, "action": -0.9645469784736633}
{"mode": "train", "epochs": 2, "timestep": 2300, "ep_reward": 168.80711364746094, "reward": 0.6913994550704956, "action": -1.0482141971588135}
{"mode": "train", "epochs": 2, "timestep": 2301, "ep_reward": 169.38308715820312, "reward": 0.5759707093238831, "action": -1.012354850769043}
{"mode": "train", "epochs": 2, "timestep": 2302, "ep_reward": 169.80067443847656, "reward": 0.41758984327316284, "action": -0.4123138189315796}
{"mode": "train", "epochs": 2, "timestep": 2303, "ep_reward": 170.12088012695312, "reward": 0.320201575756073, "action": -1.2015820741653442}
{"mode": "train", "epochs": 2, "timestep": 2304, "ep_reward": 170.32533264160156, "reward": 0.20444762706756592, "action": -1.0492748022079468}
{"mode": "train", "epochs": 2, "timestep": 2305, "ep_reward": 170.39402770996094, "reward": 0.06870156526565552, "action": -0.7939549684524536}
{"mode": "train", "epochs": 2, "timestep": 2306, "ep_reward": 170.4434814453125, "reward": 0.049456655979156494, "action": -1.2448934316635132}
{"mode": "train", "epochs": 2, "timestep": 2307, "ep_reward": 170.63124084472656, "reward": 0.1877596378326416, "action": -1.690242052078247}
{"mode": "train", "epochs": 2, "timestep": 2308, "ep_reward": 170.9505615234375, "reward": 0.3193241357803345, "action": -1.4492155313491821}
{"mode": "train", "epochs": 2, "timestep": 2309, "ep_reward": 171.4008026123047, "reward": 0.45023614168167114, "action": 0.12150740623474121}
{"mode": "train", "epochs": 2, "timestep": 2310, "ep_reward": 171.98562622070312, "reward": 0.5848259925842285, "action": -0.6113560795783997}
{"mode": "train", "epochs": 2, "timestep": 2311, "ep_reward": 172.67233276367188, "reward": 0.6867125034332275, "action": 0.153112530708313}
{"mode": "train", "epochs": 2, "timestep": 2312, "ep_reward": 173.444091796875, "reward": 0.7717624306678772, "action": -0.37275123596191406}
{"mode": "train", "epochs": 2, "timestep": 2313, "ep_reward": 174.27288818359375, "reward": 0.8287920951843262, "action": -0.2695162296295166}
{"mode": "train", "epochs": 2, "timestep": 2314, "ep_reward": 175.14077758789062, "reward": 0.8678953647613525, "action": 0.08394753932952881}
{"mode": "train", "epochs": 2, "timestep": 2315, "ep_reward": 176.03472900390625, "reward": 0.8939514756202698, "action": -0.6472861170768738}
{"mode": "train", "epochs": 2, "timestep": 2316, "ep_reward": 176.9359130859375, "reward": 0.9011876583099365, "action": -1.8348350524902344}
{"mode": "train", "epochs": 2, "timestep": 2317, "ep_reward": 177.82296752929688, "reward": 0.8870596289634705, "action": -0.5214107036590576}
{"mode": "train", "epochs": 2, "timestep": 2318, "ep_reward": 178.6908721923828, "reward": 0.8678995370864868, "action": -1.9704205989837646}
{"mode": "train", "epochs": 2, "timestep": 2319, "ep_reward": 179.50843811035156, "reward": 0.8175642490386963, "action": -0.9528406262397766}
{"mode": "train", "epochs": 2, "timestep": 2320, "ep_reward": 180.2593994140625, "reward": 0.7509617805480957, "action": -0.31429189443588257}
{"mode": "train", "epochs": 2, "timestep": 2321, "ep_reward": 180.9204559326172, "reward": 0.6610617637634277, "action": -1.113908290863037}
{"mode": "train", "epochs": 2, "timestep": 2322, "ep_reward": 181.4456329345703, "reward": 0.5251728296279907, "action": -0.7817896604537964}
{"mode": "train", "epochs": 2, "timestep": 2323, "ep_reward": 181.79954528808594, "reward": 0.3539067506790161, "action": -1.3220093250274658}
{"mode": "train", "epochs": 2, "timestep": 2324, "ep_reward": 182.04251098632812, "reward": 0.24297022819519043, "action": -0.48816537857055664}
{"mode": "train", "epochs": 2, "timestep": 2325, "ep_reward": 182.1559295654297, "reward": 0.11341720819473267, "action": -1.0276283025741577}
{"mode": "train", "epochs": 2, "timestep": 2326, "ep_reward": 182.1578826904297, "reward": 0.0019562244415283203, "action": -1.0491116046905518}
{"mode": "train", "epochs": 2, "timestep": 2327, "ep_reward": 182.3044891357422, "reward": 0.14660096168518066, "action": -1.1470357179641724}
{"mode": "train", "epochs": 2, "timestep": 2328, "ep_reward": 182.5887451171875, "reward": 0.28424882888793945, "action": -0.9663582444190979}
{"mode": "train", "epochs": 2, "timestep": 2329, "ep_reward": 183.01075744628906, "reward": 0.42201024293899536, "action": -1.1351138353347778}
{"mode": "train", "epochs": 2, "timestep": 2330, "ep_reward": 183.5561981201172, "reward": 0.5454397201538086, "action": -1.1607110500335693}
{"mode": "train", "epochs": 2, "timestep": 2331, "ep_reward": 184.20565795898438, "reward": 0.6494593620300293, "action": -0.7498632669448853}
{"mode": "train", "epochs": 2, "timestep": 2332, "ep_reward": 184.94068908691406, "reward": 0.7350253462791443, "action": -1.3993322849273682}
{"mode": "train", "epochs": 2, "timestep": 2333, "ep_reward": 185.7324676513672, "reward": 0.7917789220809937, "action": -0.9437534809112549}
{"mode": "train", "epochs": 2, "timestep": 2334, "ep_reward": 186.56504821777344, "reward": 0.8325840830802917, "action": -1.3823579549789429}
{"mode": "train", "epochs": 2, "timestep": 2335, "ep_reward": 187.41622924804688, "reward": 0.8511748313903809, "action": -0.8994855284690857}
{"mode": "train", "epochs": 2, "timestep": 2336, "ep_reward": 188.27268981933594, "reward": 0.8564582467079163, "action": -0.7069740295410156}
{"mode": "train", "epochs": 2, "timestep": 2337, "ep_reward": 189.1180419921875, "reward": 0.8453471064567566, "action": -0.4379064440727234}
{"mode": "train", "epochs": 2, "timestep": 2338, "ep_reward": 189.93455505371094, "reward": 0.8165091276168823, "action": -1.7951030731201172}
{"mode": "train", "epochs": 2, "timestep": 2339, "ep_reward": 190.68341064453125, "reward": 0.7488512992858887, "action": -1.063798189163208}
{"mode": "train", "epochs": 2, "timestep": 2340, "ep_reward": 191.33880615234375, "reward": 0.6553996801376343, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 2341, "ep_reward": 191.84722900390625, "reward": 0.5084195137023926, "action": -0.6612027883529663}
{"mode": "train", "epochs": 2, "timestep": 2342, "ep_reward": 192.22018432617188, "reward": 0.3729504942893982, "action": -1.558815598487854}
{"mode": "train", "epochs": 2, "timestep": 2343, "ep_reward": 192.4879608154297, "reward": 0.2677805423736572, "action": -0.9278227090835571}
{"mode": "train", "epochs": 2, "timestep": 2344, "ep_reward": 192.63034057617188, "reward": 0.14237701892852783, "action": -1.7397806644439697}
{"mode": "train", "epochs": 2, "timestep": 2345, "ep_reward": 192.62754821777344, "reward": -0.0027980804443359375, "action": -1.2396392822265625}
{"mode": "train", "epochs": 2, "timestep": 2346, "ep_reward": 192.74502563476562, "reward": 0.11747932434082031, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 2347, "ep_reward": 192.99160766601562, "reward": 0.24658817052841187, "action": -0.7266900539398193}
{"mode": "train", "epochs": 2, "timestep": 2348, "ep_reward": 193.38192749023438, "reward": 0.39032119512557983, "action": -0.6334333419799805}
{"mode": "train", "epochs": 2, "timestep": 2349, "ep_reward": 193.90560913085938, "reward": 0.5236854553222656, "action": -0.8118762373924255}
{"mode": "train", "epochs": 2, "timestep": 2350, "ep_reward": 194.541015625, "reward": 0.635400116443634, "action": -0.319726824760437}
{"mode": "train", "epochs": 2, "timestep": 2351, "ep_reward": 195.2699432373047, "reward": 0.7289345264434814, "action": -1.0078293085098267}
{"mode": "train", "epochs": 2, "timestep": 2352, "ep_reward": 196.06239318847656, "reward": 0.7924440503120422, "action": -1.4887362718582153}
{"mode": "train", "epochs": 2, "timestep": 2353, "ep_reward": 196.8944091796875, "reward": 0.83202064037323, "action": -1.5417203903198242}
{"mode": "train", "epochs": 2, "timestep": 2354, "ep_reward": 197.7483367919922, "reward": 0.8539320230484009, "action": -0.305442750453949}
{"mode": "train", "epochs": 2, "timestep": 2355, "ep_reward": 198.61798095703125, "reward": 0.8696452379226685, "action": -0.6030932664871216}
{"mode": "train", "epochs": 2, "timestep": 2356, "ep_reward": 199.48434448242188, "reward": 0.8663579225540161, "action": -1.8039441108703613}
{"mode": "train", "epochs": 2, "timestep": 2357, "ep_reward": 200.31907653808594, "reward": 0.8347347974777222, "action": -0.5779273509979248}
{"mode": "train", "epochs": 2, "timestep": 2358, "ep_reward": 201.1110382080078, "reward": 0.7919561266899109, "action": -1.3939462900161743}
{"mode": "train", "epochs": 2, "timestep": 2359, "ep_reward": 201.8238983154297, "reward": 0.7128560543060303, "action": -0.2980254888534546}
{"mode": "train", "epochs": 2, "timestep": 2360, "ep_reward": 202.4359893798828, "reward": 0.6120885014533997, "action": -0.10992509126663208}
{"mode": "train", "epochs": 2, "timestep": 2361, "ep_reward": 202.9128875732422, "reward": 0.47690320014953613, "action": -1.3599426746368408}
{"mode": "train", "epochs": 2, "timestep": 2362, "ep_reward": 203.2421417236328, "reward": 0.32925504446029663, "action": -0.8186436891555786}
{"mode": "train", "epochs": 2, "timestep": 2363, "ep_reward": 203.45718383789062, "reward": 0.21503692865371704, "action": -1.7947783470153809}
{"mode": "train", "epochs": 2, "timestep": 2364, "ep_reward": 203.53834533691406, "reward": 0.08116626739501953, "action": -0.4583780765533447}
{"mode": "train", "epochs": 2, "timestep": 2365, "ep_reward": 203.57501220703125, "reward": 0.03667086362838745, "action": -1.0801937580108643}
{"mode": "train", "epochs": 2, "timestep": 2366, "ep_reward": 203.75180053710938, "reward": 0.17678505182266235, "action": -0.980167031288147}
{"mode": "train", "epochs": 2, "timestep": 2367, "ep_reward": 204.06881713867188, "reward": 0.31702136993408203, "action": -1.3367100954055786}
{"mode": "train", "epochs": 2, "timestep": 2368, "ep_reward": 204.5170135498047, "reward": 0.448195219039917, "action": -1.3600594997406006}
{"mode": "train", "epochs": 2, "timestep": 2369, "ep_reward": 205.0828857421875, "reward": 0.5658766031265259, "action": -0.8742058873176575}
{"mode": "train", "epochs": 2, "timestep": 2370, "ep_reward": 205.75157165527344, "reward": 0.6686892509460449, "action": -1.3670036792755127}
{"mode": "train", "epochs": 2, "timestep": 2371, "ep_reward": 206.49472045898438, "reward": 0.7431451082229614, "action": -0.7029174566268921}
{"mode": "train", "epochs": 2, "timestep": 2372, "ep_reward": 207.29649353027344, "reward": 0.8017764091491699, "action": -1.1389880180358887}
{"mode": "train", "epochs": 2, "timestep": 2373, "ep_reward": 208.13221740722656, "reward": 0.8357276320457458, "action": -0.9940220713615417}
{"mode": "train", "epochs": 2, "timestep": 2374, "ep_reward": 208.98472595214844, "reward": 0.8525151014328003, "action": -0.9754616618156433}
{"mode": "train", "epochs": 2, "timestep": 2375, "ep_reward": 209.83627319335938, "reward": 0.8515537977218628, "action": -0.5046718716621399}
{"mode": "train", "epochs": 2, "timestep": 2376, "ep_reward": 210.6721954345703, "reward": 0.8359274864196777, "action": -0.7702464461326599}
{"mode": "train", "epochs": 2, "timestep": 2377, "ep_reward": 211.46817016601562, "reward": 0.7959796190261841, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 2378, "ep_reward": 212.18280029296875, "reward": 0.7146344184875488, "action": -1.718971610069275}
{"mode": "train", "epochs": 2, "timestep": 2379, "ep_reward": 212.7804718017578, "reward": 0.5976713299751282, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 2380, "ep_reward": 213.2108612060547, "reward": 0.43039369583129883, "action": -0.7281758785247803}
{"mode": "train", "epochs": 2, "timestep": 2381, "ep_reward": 213.54531860351562, "reward": 0.33446305990219116, "action": -0.1989675760269165}
{"mode": "train", "epochs": 2, "timestep": 2382, "ep_reward": 213.76663208007812, "reward": 0.2213125228881836, "action": -1.2164636850357056}
{"mode": "train", "epochs": 2, "timestep": 2383, "ep_reward": 213.8549041748047, "reward": 0.088276207447052, "action": -1.044082760810852}
{"mode": "train", "epochs": 2, "timestep": 2384, "ep_reward": 213.884033203125, "reward": 0.02913612127304077, "action": -1.2091389894485474}
{"mode": "train", "epochs": 2, "timestep": 2385, "ep_reward": 214.0542449951172, "reward": 0.17021524906158447, "action": -1.3370347023010254}
{"mode": "train", "epochs": 2, "timestep": 2386, "ep_reward": 214.3602752685547, "reward": 0.3060336709022522, "action": -0.21992886066436768}
{"mode": "train", "epochs": 2, "timestep": 2387, "ep_reward": 214.8121337890625, "reward": 0.45185863971710205, "action": -0.9447245001792908}
{"mode": "train", "epochs": 2, "timestep": 2388, "ep_reward": 215.38519287109375, "reward": 0.5730551481246948, "action": -1.7468016147613525}
{"mode": "train", "epochs": 2, "timestep": 2389, "ep_reward": 216.05104064941406, "reward": 0.6658511161804199, "action": -1.317291259765625}
{"mode": "train", "epochs": 2, "timestep": 2390, "ep_reward": 216.7931671142578, "reward": 0.7421294450759888, "action": -0.6580826640129089}
{"mode": "train", "epochs": 2, "timestep": 2391, "ep_reward": 217.59584045410156, "reward": 0.8026775121688843, "action": -1.3249189853668213}
{"mode": "train", "epochs": 2, "timestep": 2392, "ep_reward": 218.43276977539062, "reward": 0.8369223475456238, "action": -1.1701362133026123}
{"mode": "train", "epochs": 2, "timestep": 2393, "ep_reward": 219.28738403320312, "reward": 0.8546203374862671, "action": -1.2671446800231934}
{"mode": "train", "epochs": 2, "timestep": 2394, "ep_reward": 220.14132690429688, "reward": 0.8539441823959351, "action": -1.5187196731567383}
{"mode": "train", "epochs": 2, "timestep": 2395, "ep_reward": 220.97337341308594, "reward": 0.8320468068122864, "action": -0.613673210144043}
{"mode": "train", "epochs": 2, "timestep": 2396, "ep_reward": 221.76976013183594, "reward": 0.7963942289352417, "action": -1.0566288232803345}
{"mode": "train", "epochs": 2, "timestep": 2397, "ep_reward": 222.4989013671875, "reward": 0.7291381359100342, "action": -0.7399076223373413}
{"mode": "train", "epochs": 2, "timestep": 2398, "ep_reward": 223.13059997558594, "reward": 0.6317054033279419, "action": -0.7068434953689575}
{"mode": "train", "epochs": 2, "timestep": 2399, "ep_reward": 223.6260528564453, "reward": 0.49544602632522583, "action": -0.8246027827262878}
{"mode": "train", "epochs": 2, "timestep": 2400, "ep_reward": 223.9811553955078, "reward": 0.3551025390625, "action": -0.38603538274765015}
{"mode": "train", "epochs": 2, "timestep": 2401, "ep_reward": 224.2272186279297, "reward": 0.24606472253799438, "action": -1.1069092750549316}
{"mode": "train", "epochs": 2, "timestep": 2402, "ep_reward": 224.3443145751953, "reward": 0.11709630489349365, "action": -1.0957523584365845}
{"mode": "train", "epochs": 2, "timestep": 2403, "ep_reward": 224.3419952392578, "reward": -0.002319812774658203, "action": -1.9520354270935059}
{"mode": "train", "epochs": 2, "timestep": 2404, "ep_reward": 224.48486328125, "reward": 0.14286571741104126, "action": -1.9534428119659424}
{"mode": "train", "epochs": 2, "timestep": 2405, "ep_reward": 224.75523376464844, "reward": 0.27036964893341064, "action": -0.9619290232658386}
{"mode": "train", "epochs": 2, "timestep": 2406, "ep_reward": 225.1656036376953, "reward": 0.4103657603263855, "action": -1.442674994468689}
{"mode": "train", "epochs": 2, "timestep": 2407, "ep_reward": 225.69776916503906, "reward": 0.5321617126464844, "action": -1.971953272819519}
{"mode": "train", "epochs": 2, "timestep": 2408, "ep_reward": 226.3272705078125, "reward": 0.629494309425354, "action": -0.8664859533309937}
{"mode": "train", "epochs": 2, "timestep": 2409, "ep_reward": 227.04380798339844, "reward": 0.7165325880050659, "action": -1.2540080547332764}
{"mode": "train", "epochs": 2, "timestep": 2410, "ep_reward": 227.81895446777344, "reward": 0.7751531600952148, "action": -0.5412615537643433}
{"mode": "train", "epochs": 2, "timestep": 2411, "ep_reward": 228.636962890625, "reward": 0.8180124759674072, "action": -1.4394588470458984}
{"mode": "train", "epochs": 2, "timestep": 2412, "ep_reward": 229.46841430664062, "reward": 0.8314509391784668, "action": -1.3726816177368164}
{"mode": "train", "epochs": 2, "timestep": 2413, "ep_reward": 230.2933807373047, "reward": 0.8249656558036804, "action": -1.0574281215667725}
{"mode": "train", "epochs": 2, "timestep": 2414, "ep_reward": 231.09219360351562, "reward": 0.7988170981407166, "action": -0.22379976511001587}
{"mode": "train", "epochs": 2, "timestep": 2415, "ep_reward": 231.8475799560547, "reward": 0.7553912401199341, "action": -0.7951670289039612}
{"mode": "train", "epochs": 2, "timestep": 2416, "ep_reward": 232.52224731445312, "reward": 0.6746599674224854, "action": -0.8620092272758484}
{"mode": "train", "epochs": 2, "timestep": 2417, "ep_reward": 233.07717895507812, "reward": 0.5549302101135254, "action": -0.5609357357025146}
{"mode": "train", "epochs": 2, "timestep": 2418, "ep_reward": 233.47906494140625, "reward": 0.40188145637512207, "action": -1.9490821361541748}
{"mode": "train", "epochs": 2, "timestep": 2419, "ep_reward": 233.78216552734375, "reward": 0.3031071424484253, "action": -0.8549462556838989}
{"mode": "train", "epochs": 2, "timestep": 2420, "ep_reward": 233.96630859375, "reward": 0.18413764238357544, "action": -0.8925756216049194}
{"mode": "train", "epochs": 2, "timestep": 2421, "ep_reward": 234.01141357421875, "reward": 0.045108914375305176, "action": -1.3488258123397827}
{"mode": "train", "epochs": 2, "timestep": 2422, "ep_reward": 234.08438110351562, "reward": 0.07296407222747803, "action": -0.43901872634887695}
{"mode": "train", "epochs": 2, "timestep": 2423, "ep_reward": 234.3016357421875, "reward": 0.21726036071777344, "action": -1.6574041843414307}
{"mode": "train", "epochs": 2, "timestep": 2424, "ep_reward": 234.64944458007812, "reward": 0.34781384468078613, "action": -0.017965734004974365}
{"mode": "train", "epochs": 2, "timestep": 2425, "ep_reward": 235.1417694091797, "reward": 0.49231868982315063, "action": -0.596815824508667}
{"mode": "train", "epochs": 2, "timestep": 2426, "ep_reward": 235.7530517578125, "reward": 0.6112858057022095, "action": -0.04200160503387451}
{"mode": "train", "epochs": 2, "timestep": 2427, "ep_reward": 236.46656799316406, "reward": 0.7135111093521118, "action": 0.1421891450881958}
{"mode": "train", "epochs": 2, "timestep": 2428, "ep_reward": 237.25958251953125, "reward": 0.7930070161819458, "action": -1.5977768898010254}
{"mode": "train", "epochs": 2, "timestep": 2429, "ep_reward": 238.0972137451172, "reward": 0.8376372456550598, "action": -0.44619160890579224}
{"mode": "train", "epochs": 2, "timestep": 2430, "ep_reward": 238.9726104736328, "reward": 0.8754033446311951, "action": -1.3172860145568848}
{"mode": "train", "epochs": 2, "timestep": 2431, "ep_reward": 239.86521911621094, "reward": 0.8926143646240234, "action": -1.0819669961929321}
{"mode": "train", "epochs": 2, "timestep": 2432, "ep_reward": 240.7643585205078, "reward": 0.8991376161575317, "action": -1.1364045143127441}
{"mode": "train", "epochs": 2, "timestep": 2433, "ep_reward": 241.656982421875, "reward": 0.8926212787628174, "action": -1.33542001247406}
{"mode": "train", "epochs": 2, "timestep": 2434, "ep_reward": 242.52713012695312, "reward": 0.8701506853103638, "action": -0.6155043840408325}
{"mode": "train", "epochs": 2, "timestep": 2435, "ep_reward": 243.36300659179688, "reward": 0.8358811736106873, "action": -1.4146559238433838}
{"mode": "train", "epochs": 2, "timestep": 2436, "ep_reward": 244.13442993164062, "reward": 0.7714177370071411, "action": -1.320921540260315}
{"mode": "train", "epochs": 2, "timestep": 2437, "ep_reward": 244.81143188476562, "reward": 0.6770060062408447, "action": -0.6343157291412354}
{"mode": "train", "epochs": 2, "timestep": 2438, "ep_reward": 245.36575317382812, "reward": 0.5543287992477417, "action": -0.47377318143844604}
{"mode": "train", "epochs": 2, "timestep": 2439, "ep_reward": 245.76150512695312, "reward": 0.39574557542800903, "action": -1.1251274347305298}
{"mode": "train", "epochs": 2, "timestep": 2440, "ep_reward": 246.02955627441406, "reward": 0.2680533528327942, "action": -0.8347549438476562}
{"mode": "train", "epochs": 2, "timestep": 2441, "ep_reward": 246.17234802246094, "reward": 0.14279747009277344, "action": -1.1275877952575684}
{"mode": "train", "epochs": 2, "timestep": 2442, "ep_reward": 246.1699981689453, "reward": -0.002354860305786133, "action": -0.4461844563484192}
{"mode": "train", "epochs": 2, "timestep": 2443, "ep_reward": 246.2872772216797, "reward": 0.11727923154830933, "action": -1.418108582496643}
{"mode": "train", "epochs": 2, "timestep": 2444, "ep_reward": 246.53814697265625, "reward": 0.25086474418640137, "action": -0.42816776037216187}
{"mode": "train", "epochs": 2, "timestep": 2445, "ep_reward": 246.93533325195312, "reward": 0.3971848487854004, "action": -1.4312138557434082}
{"mode": "train", "epochs": 2, "timestep": 2446, "ep_reward": 247.4552764892578, "reward": 0.5199484825134277, "action": -0.6146369576454163}
{"mode": "train", "epochs": 2, "timestep": 2447, "ep_reward": 248.0896453857422, "reward": 0.6343725919723511, "action": -1.045907974243164}
{"mode": "train", "epochs": 2, "timestep": 2448, "ep_reward": 248.81085205078125, "reward": 0.7212061882019043, "action": -0.43674904108047485}
{"mode": "train", "epochs": 2, "timestep": 2449, "ep_reward": 249.60198974609375, "reward": 0.7911404967308044, "action": -1.5600192546844482}
{"mode": "train", "epochs": 2, "timestep": 2450, "ep_reward": 250.4324493408203, "reward": 0.8304553627967834, "action": -0.2572833299636841}
{"mode": "train", "epochs": 2, "timestep": 2451, "ep_reward": 251.29547119140625, "reward": 0.8630214333534241, "action": -1.6820554733276367}
{"mode": "train", "epochs": 2, "timestep": 2452, "ep_reward": 252.16299438476562, "reward": 0.8675229549407959, "action": 0.04378163814544678}
{"mode": "train", "epochs": 2, "timestep": 2453, "ep_reward": 253.033447265625, "reward": 0.8704556226730347, "action": -0.06309318542480469}
{"mode": "train", "epochs": 2, "timestep": 2454, "ep_reward": 253.8895263671875, "reward": 0.856080174446106, "action": -0.31482553482055664}
{"mode": "train", "epochs": 2, "timestep": 2455, "ep_reward": 254.7105255126953, "reward": 0.8209925889968872, "action": -0.6796777248382568}
{"mode": "train", "epochs": 2, "timestep": 2456, "ep_reward": 255.4697265625, "reward": 0.7592067718505859, "action": 0.07989239692687988}
{"mode": "train", "epochs": 2, "timestep": 2457, "ep_reward": 256.1470031738281, "reward": 0.6772739887237549, "action": -0.5217301845550537}
{"mode": "train", "epochs": 2, "timestep": 2458, "ep_reward": 256.7019958496094, "reward": 0.5550037622451782, "action": -0.8155860900878906}
{"mode": "train", "epochs": 2, "timestep": 2459, "ep_reward": 257.0930480957031, "reward": 0.3910478949546814, "action": -0.6381798982620239}
{"mode": "train", "epochs": 2, "timestep": 2460, "ep_reward": 257.3517150878906, "reward": 0.25866973400115967, "action": -0.7370990514755249}
{"mode": "train", "epochs": 2, "timestep": 2461, "ep_reward": 257.4833984375, "reward": 0.13169312477111816, "action": -1.6567275524139404}
{"mode": "train", "epochs": 2, "timestep": 2462, "ep_reward": 257.4683837890625, "reward": -0.015012145042419434, "action": -0.7837101221084595}
{"mode": "train", "epochs": 2, "timestep": 2463, "ep_reward": 257.5969543457031, "reward": 0.1285707950592041, "action": -0.5079912543296814}
{"mode": "train", "epochs": 2, "timestep": 2464, "ep_reward": 257.87066650390625, "reward": 0.2737083435058594, "action": -0.8660123348236084}
{"mode": "train", "epochs": 2, "timestep": 2465, "ep_reward": 258.2825927734375, "reward": 0.41193079948425293, "action": -0.9793575406074524}
{"mode": "train", "epochs": 2, "timestep": 2466, "ep_reward": 258.8202209472656, "reward": 0.5376428365707397, "action": -0.8255997896194458}
{"mode": "train", "epochs": 2, "timestep": 2467, "ep_reward": 259.466796875, "reward": 0.6465822458267212, "action": -0.8398885130882263}
{"mode": "train", "epochs": 2, "timestep": 2468, "ep_reward": 260.1999816894531, "reward": 0.733191967010498, "action": -0.49640005826950073}
{"mode": "train", "epochs": 2, "timestep": 2469, "ep_reward": 261.0008239746094, "reward": 0.8008349537849426, "action": -1.0441817045211792}
{"mode": "train", "epochs": 2, "timestep": 2470, "ep_reward": 261.8447265625, "reward": 0.8438887000083923, "action": -1.3353514671325684}
{"mode": "train", "epochs": 2, "timestep": 2471, "ep_reward": 262.71295166015625, "reward": 0.8682233691215515, "action": -0.9578226804733276}
{"mode": "train", "epochs": 2, "timestep": 2472, "ep_reward": 263.5935363769531, "reward": 0.8805786371231079, "action": -1.5743176937103271}
{"mode": "train", "epochs": 2, "timestep": 2473, "ep_reward": 264.4668884277344, "reward": 0.8733517527580261, "action": 0.253920316696167}
{"mode": "train", "epochs": 2, "timestep": 2474, "ep_reward": 265.3323059082031, "reward": 0.8654232025146484, "action": -0.4264761805534363}
{"mode": "train", "epochs": 2, "timestep": 2475, "ep_reward": 266.16650390625, "reward": 0.8342022895812988, "action": -1.4641060829162598}
{"mode": "train", "epochs": 2, "timestep": 2476, "ep_reward": 266.93701171875, "reward": 0.7704970240592957, "action": -0.8352209329605103}
{"mode": "train", "epochs": 2, "timestep": 2477, "ep_reward": 267.6199951171875, "reward": 0.682986855506897, "action": -1.6407686471939087}
{"mode": "train", "epochs": 2, "timestep": 2478, "ep_reward": 268.1681823730469, "reward": 0.5481927394866943, "action": -1.1341564655303955}
{"mode": "train", "epochs": 2, "timestep": 2479, "ep_reward": 268.54547119140625, "reward": 0.3772859573364258, "action": -1.0512378215789795}
{"mode": "train", "epochs": 2, "timestep": 2480, "ep_reward": 268.81573486328125, "reward": 0.2702692151069641, "action": -1.7489781379699707}
{"mode": "train", "epochs": 2, "timestep": 2481, "ep_reward": 268.9613037109375, "reward": 0.14556753635406494, "action": -1.1584218740463257}
{"mode": "train", "epochs": 2, "timestep": 2482, "ep_reward": 268.9621276855469, "reward": 0.0008211731910705566, "action": -0.5918847918510437}
{"mode": "train", "epochs": 2, "timestep": 2483, "ep_reward": 269.0765380859375, "reward": 0.11439681053161621, "action": -1.542719841003418}
{"mode": "train", "epochs": 2, "timestep": 2484, "ep_reward": 269.3228454589844, "reward": 0.24630475044250488, "action": -0.9046897292137146}
{"mode": "train", "epochs": 2, "timestep": 2485, "ep_reward": 269.7102355957031, "reward": 0.38739490509033203, "action": -0.32370996475219727}
{"mode": "train", "epochs": 2, "timestep": 2486, "ep_reward": 270.23480224609375, "reward": 0.5245769023895264, "action": -0.8661057949066162}
{"mode": "train", "epochs": 2, "timestep": 2487, "ep_reward": 270.8702392578125, "reward": 0.6354348063468933, "action": -1.1950833797454834}
{"mode": "train", "epochs": 2, "timestep": 2488, "ep_reward": 271.5909729003906, "reward": 0.7207207679748535, "action": -0.8642060160636902}
{"mode": "train", "epochs": 2, "timestep": 2489, "ep_reward": 272.37811279296875, "reward": 0.7871533632278442, "action": -1.3312065601348877}
{"mode": "train", "epochs": 2, "timestep": 2490, "ep_reward": 273.2071228027344, "reward": 0.8289980888366699, "action": -1.2420448064804077}
{"mode": "train", "epochs": 2, "timestep": 2491, "ep_reward": 274.0608825683594, "reward": 0.8537684679031372, "action": -1.041165828704834}
{"mode": "train", "epochs": 2, "timestep": 2492, "ep_reward": 274.92425537109375, "reward": 0.8633667826652527, "action": -1.2566161155700684}
{"mode": "train", "epochs": 2, "timestep": 2493, "ep_reward": 275.7783203125, "reward": 0.8540588021278381, "action": -0.8919783234596252}
{"mode": "train", "epochs": 2, "timestep": 2494, "ep_reward": 276.60711669921875, "reward": 0.8288015723228455, "action": -0.92762690782547}
{"mode": "train", "epochs": 2, "timestep": 2495, "ep_reward": 277.3873291015625, "reward": 0.7802234292030334, "action": -0.43239790201187134}
{"mode": "train", "epochs": 2, "timestep": 2496, "ep_reward": 278.09600830078125, "reward": 0.7086877822875977, "action": -1.196650743484497}
{"mode": "train", "epochs": 2, "timestep": 2497, "ep_reward": 278.68914794921875, "reward": 0.5931548476219177, "action": -1.0764521360397339}
{"mode": "train", "epochs": 2, "timestep": 2498, "ep_reward": 279.12640380859375, "reward": 0.43726545572280884, "action": -1.1777522563934326}
{"mode": "train", "epochs": 2, "timestep": 2499, "ep_reward": 279.44293212890625, "reward": 0.31654173135757446, "action": -1.3541266918182373}
{"mode": "train", "epochs": 2, "timestep": 2500, "ep_reward": 279.6430358886719, "reward": 0.20010590553283691, "action": -1.215787649154663}
{"mode": "train", "epochs": 2, "timestep": 2501, "ep_reward": 279.7066345214844, "reward": 0.06361347436904907, "action": -1.4269109964370728}
{"mode": "train", "epochs": 2, "timestep": 2502, "ep_reward": 279.7611083984375, "reward": 0.054458677768707275, "action": -1.5904960632324219}
{"mode": "train", "epochs": 2, "timestep": 2503, "ep_reward": 279.9532470703125, "reward": 0.19212943315505981, "action": -1.7229161262512207}
{"mode": "train", "epochs": 2, "timestep": 2504, "ep_reward": 280.276611328125, "reward": 0.3233669400215149, "action": -1.295969009399414}
{"mode": "train", "epochs": 2, "timestep": 2505, "ep_reward": 280.732421875, "reward": 0.455811083316803, "action": -1.2483069896697998}
{"mode": "train", "epochs": 2, "timestep": 2506, "ep_reward": 281.3064270019531, "reward": 0.5740110874176025, "action": -0.8938119411468506}
{"mode": "train", "epochs": 2, "timestep": 2507, "ep_reward": 281.98101806640625, "reward": 0.6745919585227966, "action": -0.960473358631134}
{"mode": "train", "epochs": 2, "timestep": 2508, "ep_reward": 282.7311706542969, "reward": 0.7501506805419922, "action": -1.2310796976089478}
{"mode": "train", "epochs": 2, "timestep": 2509, "ep_reward": 283.53143310546875, "reward": 0.8002726435661316, "action": -0.4622039198875427}
{"mode": "train", "epochs": 2, "timestep": 2510, "ep_reward": 284.36810302734375, "reward": 0.8366551995277405, "action": -0.8456826210021973}
{"mode": "train", "epochs": 2, "timestep": 2511, "ep_reward": 285.2184143066406, "reward": 0.8503053188323975, "action": 0.2219158411026001}
{"mode": "train", "epochs": 2, "timestep": 2512, "ep_reward": 286.07366943359375, "reward": 0.8552453517913818, "action": -0.571031928062439}
{"mode": "train", "epochs": 2, "timestep": 2513, "ep_reward": 286.90789794921875, "reward": 0.8342227935791016, "action": -1.7829630374908447}
{"mode": "train", "epochs": 2, "timestep": 2514, "ep_reward": 287.6865539550781, "reward": 0.7786520719528198, "action": -1.1583064794540405}
{"mode": "train", "epochs": 2, "timestep": 2515, "ep_reward": 288.3856201171875, "reward": 0.6990793943405151, "action": -0.6627624034881592}
{"mode": "train", "epochs": 2, "timestep": 2516, "ep_reward": 288.97491455078125, "reward": 0.5892986059188843, "action": -0.8533146381378174}
{"mode": "train", "epochs": 2, "timestep": 2517, "ep_reward": 289.4111633300781, "reward": 0.43623602390289307, "action": -0.6414148807525635}
{"mode": "train", "epochs": 2, "timestep": 2518, "ep_reward": 289.7291564941406, "reward": 0.31799113750457764, "action": -1.074056625366211}
{"mode": "train", "epochs": 2, "timestep": 2519, "ep_reward": 289.930908203125, "reward": 0.20175385475158691, "action": -1.3616702556610107}
{"mode": "train", "epochs": 2, "timestep": 2520, "ep_reward": 289.99652099609375, "reward": 0.06561845541000366, "action": -0.9662180542945862}
{"mode": "train", "epochs": 2, "timestep": 2521, "ep_reward": 290.04913330078125, "reward": 0.052614450454711914, "action": -0.8614590764045715}
{"mode": "train", "epochs": 2, "timestep": 2522, "ep_reward": 290.240234375, "reward": 0.19110453128814697, "action": -1.1735280752182007}
{"mode": "train", "epochs": 2, "timestep": 2523, "ep_reward": 290.5693054199219, "reward": 0.3290860056877136, "action": -0.8893751502037048}
{"mode": "train", "epochs": 2, "timestep": 2524, "ep_reward": 291.034423828125, "reward": 0.46510428190231323, "action": -0.8562771081924438}
{"mode": "train", "epochs": 2, "timestep": 2525, "ep_reward": 291.62030029296875, "reward": 0.5858703851699829, "action": -0.9257224798202515}
{"mode": "train", "epochs": 2, "timestep": 2526, "ep_reward": 292.3046875, "reward": 0.6843935251235962, "action": -0.7712812423706055}
{"mode": "train", "epochs": 2, "timestep": 2527, "ep_reward": 293.06610107421875, "reward": 0.7614047527313232, "action": -0.7892899513244629}
{"mode": "train", "epochs": 2, "timestep": 2528, "ep_reward": 293.8824462890625, "reward": 0.8163589239120483, "action": -0.49482494592666626}
{"mode": "train", "epochs": 2, "timestep": 2529, "ep_reward": 294.7369384765625, "reward": 0.854495644569397, "action": -0.8447871208190918}
{"mode": "train", "epochs": 2, "timestep": 2530, "ep_reward": 295.60980224609375, "reward": 0.8728591203689575, "action": -1.116940975189209}
{"mode": "train", "epochs": 2, "timestep": 2531, "ep_reward": 296.4833984375, "reward": 0.8735944032669067, "action": -1.2788457870483398}
{"mode": "train", "epochs": 2, "timestep": 2532, "ep_reward": 297.340087890625, "reward": 0.8566823601722717, "action": -0.5709491968154907}
{"mode": "train", "epochs": 2, "timestep": 2533, "ep_reward": 298.1671142578125, "reward": 0.8270174264907837, "action": -0.6348038911819458}
{"mode": "train", "epochs": 2, "timestep": 2534, "ep_reward": 298.9411315917969, "reward": 0.7740117311477661, "action": -0.7094240188598633}
{"mode": "train", "epochs": 2, "timestep": 2535, "ep_reward": 299.6326599121094, "reward": 0.691531777381897, "action": -1.2078089714050293}
{"mode": "train", "epochs": 2, "timestep": 2536, "ep_reward": 300.19964599609375, "reward": 0.5669913291931152, "action": -0.7797976136207581}
{"mode": "train", "epochs": 2, "timestep": 2537, "ep_reward": 300.60699462890625, "reward": 0.4073474407196045, "action": -0.32503026723861694}
{"mode": "train", "epochs": 2, "timestep": 2538, "ep_reward": 300.8942565917969, "reward": 0.2872552275657654, "action": -0.8933296203613281}
{"mode": "train", "epochs": 2, "timestep": 2539, "ep_reward": 301.0597229003906, "reward": 0.16545337438583374, "action": -0.4969649314880371}
{"mode": "train", "epochs": 2, "timestep": 2540, "ep_reward": 301.083251953125, "reward": 0.023533105850219727, "action": -1.2656242847442627}
{"mode": "train", "epochs": 2, "timestep": 2541, "ep_reward": 301.1767883300781, "reward": 0.09352612495422363, "action": -1.1701664924621582}
{"mode": "train", "epochs": 2, "timestep": 2542, "ep_reward": 301.4062805175781, "reward": 0.22948187589645386, "action": -0.9261038303375244}
{"mode": "train", "epochs": 2, "timestep": 2543, "ep_reward": 301.77630615234375, "reward": 0.3700374960899353, "action": -1.389241099357605}
{"mode": "train", "epochs": 2, "timestep": 2544, "ep_reward": 302.2726135253906, "reward": 0.49630796909332275, "action": -1.2487465143203735}
{"mode": "train", "epochs": 2, "timestep": 2545, "ep_reward": 302.880615234375, "reward": 0.6080053448677063, "action": -0.6966914534568787}
{"mode": "train", "epochs": 2, "timestep": 2546, "ep_reward": 303.584228515625, "reward": 0.7036181688308716, "action": -1.0273228883743286}
{"mode": "train", "epochs": 2, "timestep": 2547, "ep_reward": 304.3563232421875, "reward": 0.7721037864685059, "action": -1.509531021118164}
{"mode": "train", "epochs": 2, "timestep": 2548, "ep_reward": 305.1712646484375, "reward": 0.814950168132782, "action": -0.8557157516479492}
{"mode": "train", "epochs": 2, "timestep": 2549, "ep_reward": 306.015625, "reward": 0.8443517684936523, "action": -1.697396993637085}
{"mode": "train", "epochs": 2, "timestep": 2550, "ep_reward": 306.8638610839844, "reward": 0.8482345938682556, "action": -0.08076518774032593}
{"mode": "train", "epochs": 2, "timestep": 2551, "ep_reward": 307.7117919921875, "reward": 0.8479326963424683, "action": -1.8998334407806396}
{"mode": "train", "epochs": 2, "timestep": 2552, "ep_reward": 308.522216796875, "reward": 0.8104190230369568, "action": -0.4430732727050781}
{"mode": "train", "epochs": 2, "timestep": 2553, "ep_reward": 309.2841491699219, "reward": 0.7619179487228394, "action": -0.7029614448547363}
{"mode": "train", "epochs": 2, "timestep": 2554, "ep_reward": 309.96466064453125, "reward": 0.68050616979599, "action": -1.2175394296646118}
{"mode": "train", "epochs": 2, "timestep": 2555, "ep_reward": 310.5196533203125, "reward": 0.554983377456665, "action": -1.0832537412643433}
{"mode": "train", "epochs": 2, "timestep": 2556, "ep_reward": 310.9141845703125, "reward": 0.39454007148742676, "action": -1.2883819341659546}
{"mode": "train", "epochs": 2, "timestep": 2557, "ep_reward": 311.20806884765625, "reward": 0.29389071464538574, "action": -1.3992589712142944}
{"mode": "train", "epochs": 2, "timestep": 2558, "ep_reward": 311.3813781738281, "reward": 0.17332226037979126, "action": -0.9847610592842102}
{"mode": "train", "epochs": 2, "timestep": 2559, "ep_reward": 311.4140930175781, "reward": 0.032708823680877686, "action": -0.8437532186508179}
{"mode": "train", "epochs": 2, "timestep": 2560, "ep_reward": 311.4990539550781, "reward": 0.08496803045272827, "action": -0.6277487874031067}
{"mode": "train", "epochs": 2, "timestep": 2561, "ep_reward": 311.72650146484375, "reward": 0.227461576461792, "action": 0.21892976760864258}
{"mode": "train", "epochs": 2, "timestep": 2562, "ep_reward": 312.107177734375, "reward": 0.38066762685775757, "action": -1.4020638465881348}
{"mode": "train", "epochs": 2, "timestep": 2563, "ep_reward": 312.6108093261719, "reward": 0.503635048866272, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 2564, "ep_reward": 313.2164306640625, "reward": 0.6056263446807861, "action": -1.4550182819366455}
{"mode": "train", "epochs": 2, "timestep": 2565, "ep_reward": 313.9112548828125, "reward": 0.694832980632782, "action": -0.9525800943374634}
{"mode": "train", "epochs": 2, "timestep": 2566, "ep_reward": 314.6784362792969, "reward": 0.7671829462051392, "action": -1.2459650039672852}
{"mode": "train", "epochs": 2, "timestep": 2567, "ep_reward": 315.49395751953125, "reward": 0.8155208826065063, "action": -1.2277451753616333}
{"mode": "train", "epochs": 2, "timestep": 2568, "ep_reward": 316.33917236328125, "reward": 0.845221757888794, "action": -0.5397508144378662}
{"mode": "train", "epochs": 2, "timestep": 2569, "ep_reward": 317.2024841308594, "reward": 0.8632968068122864, "action": -0.9109894633293152}
{"mode": "train", "epochs": 2, "timestep": 2570, "ep_reward": 318.0638122558594, "reward": 0.8613399863243103, "action": 0.13095927238464355}
{"mode": "train", "epochs": 2, "timestep": 2571, "ep_reward": 318.9149169921875, "reward": 0.851119875907898, "action": -0.44858020544052124}
{"mode": "train", "epochs": 2, "timestep": 2572, "ep_reward": 319.7314147949219, "reward": 0.8164832592010498, "action": -0.7516189813613892}
{"mode": "train", "epochs": 2, "timestep": 2573, "ep_reward": 320.48626708984375, "reward": 0.7548608779907227, "action": -0.7815056443214417}
{"mode": "train", "epochs": 2, "timestep": 2574, "ep_reward": 321.1484680175781, "reward": 0.6622138023376465, "action": -1.3350681066513062}
{"mode": "train", "epochs": 2, "timestep": 2575, "ep_reward": 321.67303466796875, "reward": 0.5245634317398071, "action": -1.3019931316375732}
{"mode": "train", "epochs": 2, "timestep": 2576, "ep_reward": 322.0343017578125, "reward": 0.36127132177352905, "action": -1.4293733835220337}
{"mode": "train", "epochs": 2, "timestep": 2577, "ep_reward": 322.2879333496094, "reward": 0.2536301612854004, "action": -1.1098664999008179}
{"mode": "train", "epochs": 2, "timestep": 2578, "ep_reward": 322.4139099121094, "reward": 0.12597042322158813, "action": -0.854412317276001}
{"mode": "train", "epochs": 2, "timestep": 2579, "ep_reward": 322.40179443359375, "reward": -0.01210331916809082, "action": -0.966632068157196}
{"mode": "train", "epochs": 2, "timestep": 2580, "ep_reward": 322.5361633300781, "reward": 0.13436228036880493, "action": -0.9583144187927246}
{"mode": "train", "epochs": 2, "timestep": 2581, "ep_reward": 322.81011962890625, "reward": 0.2739684581756592, "action": -1.578013300895691}
{"mode": "train", "epochs": 2, "timestep": 2582, "ep_reward": 323.21466064453125, "reward": 0.4045408368110657, "action": -0.6486824750900269}
{"mode": "train", "epochs": 2, "timestep": 2583, "ep_reward": 323.75067138671875, "reward": 0.5360214710235596, "action": -1.0730382204055786}
{"mode": "train", "epochs": 2, "timestep": 2584, "ep_reward": 324.3934020996094, "reward": 0.6427291631698608, "action": -0.5600549578666687}
{"mode": "train", "epochs": 2, "timestep": 2585, "ep_reward": 325.12542724609375, "reward": 0.7320218086242676, "action": -0.5035225749015808}
{"mode": "train", "epochs": 2, "timestep": 2586, "ep_reward": 325.9237976074219, "reward": 0.7983839511871338, "action": -0.9428400993347168}
{"mode": "train", "epochs": 2, "timestep": 2587, "ep_reward": 326.7640380859375, "reward": 0.8402321338653564, "action": -1.5588998794555664}
{"mode": "train", "epochs": 2, "timestep": 2588, "ep_reward": 327.6238098144531, "reward": 0.8597707748413086, "action": -0.5569489598274231}
{"mode": "train", "epochs": 2, "timestep": 2589, "ep_reward": 328.4952697753906, "reward": 0.8714733123779297, "action": -1.320030689239502}
{"mode": "train", "epochs": 2, "timestep": 2590, "ep_reward": 329.3558349609375, "reward": 0.8605644106864929, "action": -0.6253065466880798}
{"mode": "train", "epochs": 2, "timestep": 2591, "ep_reward": 330.1932373046875, "reward": 0.8373908996582031, "action": -1.2549350261688232}
{"mode": "train", "epochs": 2, "timestep": 2592, "ep_reward": 330.9793395996094, "reward": 0.7860956788063049, "action": -1.4267317056655884}
{"mode": "train", "epochs": 2, "timestep": 2593, "ep_reward": 331.68292236328125, "reward": 0.7035760879516602, "action": 0.020251035690307617}
{"mode": "train", "epochs": 2, "timestep": 2594, "ep_reward": 332.286376953125, "reward": 0.6034530401229858, "action": -1.6364123821258545}
{"mode": "train", "epochs": 2, "timestep": 2595, "ep_reward": 332.72784423828125, "reward": 0.44147396087646484, "action": -0.3653433322906494}
{"mode": "train", "epochs": 2, "timestep": 2596, "ep_reward": 333.0451965332031, "reward": 0.31735843420028687, "action": -0.5245574712753296}
{"mode": "train", "epochs": 2, "timestep": 2597, "ep_reward": 333.2462158203125, "reward": 0.2010088562965393, "action": -0.8377193808555603}
{"mode": "train", "epochs": 2, "timestep": 2598, "ep_reward": 333.3108825683594, "reward": 0.06465554237365723, "action": -1.094272255897522}
{"mode": "train", "epochs": 2, "timestep": 2599, "ep_reward": 333.3644714355469, "reward": 0.05359417200088501, "action": -0.615026593208313}
{"mode": "train", "epochs": 2, "timestep": 2600, "ep_reward": 333.55950927734375, "reward": 0.19502341747283936, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 2601, "ep_reward": 333.8817138671875, "reward": 0.3222045302391052, "action": 0.12875032424926758}
{"mode": "train", "epochs": 2, "timestep": 2602, "ep_reward": 334.3534240722656, "reward": 0.47172224521636963, "action": -1.1644243001937866}
{"mode": "train", "epochs": 2, "timestep": 2603, "ep_reward": 334.9412841796875, "reward": 0.587853729724884, "action": -1.3483936786651611}
{"mode": "train", "epochs": 2, "timestep": 2604, "ep_reward": 335.62298583984375, "reward": 0.6817125678062439, "action": -0.8619271516799927}
{"mode": "train", "epochs": 2, "timestep": 2605, "ep_reward": 336.38128662109375, "reward": 0.7582954168319702, "action": -0.09002578258514404}
{"mode": "train", "epochs": 2, "timestep": 2606, "ep_reward": 337.20086669921875, "reward": 0.8195770382881165, "action": -0.9440389275550842}
{"mode": "train", "epochs": 2, "timestep": 2607, "ep_reward": 338.0542907714844, "reward": 0.853432297706604, "action": -1.4696840047836304}
{"mode": "train", "epochs": 2, "timestep": 2608, "ep_reward": 338.92083740234375, "reward": 0.866558849811554, "action": -0.8061443567276001}
{"mode": "train", "epochs": 2, "timestep": 2609, "ep_reward": 339.79010009765625, "reward": 0.8692622184753418, "action": -1.0345484018325806}
{"mode": "train", "epochs": 2, "timestep": 2610, "ep_reward": 340.6433410644531, "reward": 0.8532335758209229, "action": -0.715879499912262}
{"mode": "train", "epochs": 2, "timestep": 2611, "ep_reward": 341.4638977050781, "reward": 0.8205561637878418, "action": -0.7719926238059998}
{"mode": "train", "epochs": 2, "timestep": 2612, "ep_reward": 342.2274169921875, "reward": 0.7635118961334229, "action": -0.7867336273193359}
{"mode": "train", "epochs": 2, "timestep": 2613, "ep_reward": 342.9036865234375, "reward": 0.6762556433677673, "action": -1.1007435321807861}
{"mode": "train", "epochs": 2, "timestep": 2614, "ep_reward": 343.45172119140625, "reward": 0.5480499267578125, "action": -0.7478729486465454}
{"mode": "train", "epochs": 2, "timestep": 2615, "ep_reward": 343.83526611328125, "reward": 0.38355982303619385, "action": -1.320054531097412}
{"mode": "train", "epochs": 2, "timestep": 2616, "ep_reward": 344.1095886230469, "reward": 0.2743132710456848, "action": -1.2826035022735596}
{"mode": "train", "epochs": 2, "timestep": 2617, "ep_reward": 344.2597961425781, "reward": 0.15019530057907104, "action": -1.2833138704299927}
{"mode": "train", "epochs": 2, "timestep": 2618, "ep_reward": 344.2659606933594, "reward": 0.0061743855476379395, "action": -0.3231348395347595}
{"mode": "train", "epochs": 2, "timestep": 2619, "ep_reward": 344.3756408691406, "reward": 0.10968303680419922, "action": -0.74861741065979}
{"mode": "train", "epochs": 2, "timestep": 2620, "ep_reward": 344.6268310546875, "reward": 0.25117552280426025, "action": -1.8840293884277344}
{"mode": "train", "epochs": 2, "timestep": 2621, "ep_reward": 345.0052795410156, "reward": 0.378434956073761, "action": -1.4082666635513306}
{"mode": "train", "epochs": 2, "timestep": 2622, "ep_reward": 345.5094909667969, "reward": 0.5042257308959961, "action": -0.48013508319854736}
{"mode": "train", "epochs": 2, "timestep": 2623, "ep_reward": 346.1325378417969, "reward": 0.6230543851852417, "action": -0.6163883209228516}
{"mode": "train", "epochs": 2, "timestep": 2624, "ep_reward": 346.84869384765625, "reward": 0.7161648273468018, "action": -0.8779081106185913}
{"mode": "train", "epochs": 2, "timestep": 2625, "ep_reward": 347.6317443847656, "reward": 0.7830565571784973, "action": -0.8559987545013428}
{"mode": "train", "epochs": 2, "timestep": 2626, "ep_reward": 348.4608459472656, "reward": 0.8291077017784119, "action": -0.5873734354972839}
{"mode": "train", "epochs": 2, "timestep": 2627, "ep_reward": 349.3197021484375, "reward": 0.8588439226150513, "action": -0.39729899168014526}
{"mode": "train", "epochs": 2, "timestep": 2628, "ep_reward": 350.193115234375, "reward": 0.8734076619148254, "action": -0.36080145835876465}
{"mode": "train", "epochs": 2, "timestep": 2629, "ep_reward": 351.06561279296875, "reward": 0.8724883794784546, "action": -0.8252137303352356}
{"mode": "train", "epochs": 2, "timestep": 2630, "ep_reward": 351.9166259765625, "reward": 0.8510165214538574, "action": -1.1401745080947876}
{"mode": "train", "epochs": 2, "timestep": 2631, "ep_reward": 352.72296142578125, "reward": 0.8063405752182007, "action": -0.943187415599823}
{"mode": "train", "epochs": 2, "timestep": 2632, "ep_reward": 353.4602966308594, "reward": 0.7373260259628296, "action": -1.3661030530929565}
{"mode": "train", "epochs": 2, "timestep": 2633, "ep_reward": 354.09027099609375, "reward": 0.629989504814148, "action": -0.5340635776519775}
{"mode": "train", "epochs": 2, "timestep": 2634, "ep_reward": 354.58428955078125, "reward": 0.49401652812957764, "action": -1.0187768936157227}
{"mode": "train", "epochs": 2, "timestep": 2635, "ep_reward": 354.92645263671875, "reward": 0.3421618938446045, "action": -1.71445631980896}
{"mode": "train", "epochs": 2, "timestep": 2636, "ep_reward": 355.1571960449219, "reward": 0.23074865341186523, "action": -1.127938151359558}
{"mode": "train", "epochs": 2, "timestep": 2637, "ep_reward": 355.2565002441406, "reward": 0.09931051731109619, "action": -0.10849744081497192}
{"mode": "train", "epochs": 2, "timestep": 2638, "ep_reward": 355.27398681640625, "reward": 0.01747947931289673, "action": -0.7974483370780945}
{"mode": "train", "epochs": 2, "timestep": 2639, "ep_reward": 355.4339599609375, "reward": 0.15996962785720825, "action": -1.7362380027770996}
{"mode": "train", "epochs": 2, "timestep": 2640, "ep_reward": 355.7244567871094, "reward": 0.2904946208000183, "action": -1.4521273374557495}
{"mode": "train", "epochs": 2, "timestep": 2641, "ep_reward": 356.1476135253906, "reward": 0.423153281211853, "action": -0.6867061257362366}
{"mode": "train", "epochs": 2, "timestep": 2642, "ep_reward": 356.7001037597656, "reward": 0.5524765849113464, "action": -0.4391641616821289}
{"mode": "train", "epochs": 2, "timestep": 2643, "ep_reward": 357.3627014160156, "reward": 0.662607729434967, "action": -0.5345404744148254}
{"mode": "train", "epochs": 2, "timestep": 2644, "ep_reward": 358.1095886230469, "reward": 0.7468865513801575, "action": -1.0993001461029053}
{"mode": "train", "epochs": 2, "timestep": 2645, "ep_reward": 358.9125061035156, "reward": 0.802931010723114, "action": -0.9210408926010132}
{"mode": "train", "epochs": 2, "timestep": 2646, "ep_reward": 359.7533264160156, "reward": 0.8408180475234985, "action": -0.8302659392356873}
{"mode": "train", "epochs": 2, "timestep": 2647, "ep_reward": 360.614990234375, "reward": 0.8616687059402466, "action": -0.7063749432563782}
{"mode": "train", "epochs": 2, "timestep": 2648, "ep_reward": 361.4819641113281, "reward": 0.866962730884552, "action": -0.04451519250869751}
{"mode": "train", "epochs": 2, "timestep": 2649, "ep_reward": 362.3432922363281, "reward": 0.8613239526748657, "action": -0.23270541429519653}
{"mode": "train", "epochs": 2, "timestep": 2650, "ep_reward": 363.17962646484375, "reward": 0.8363239765167236, "action": -0.4981430172920227}
{"mode": "train", "epochs": 2, "timestep": 2651, "ep_reward": 363.9673156738281, "reward": 0.787680447101593, "action": -0.45438647270202637}
{"mode": "train", "epochs": 2, "timestep": 2652, "ep_reward": 364.6800537109375, "reward": 0.7127344608306885, "action": -1.7580294609069824}
{"mode": "train", "epochs": 2, "timestep": 2653, "ep_reward": 365.2677307128906, "reward": 0.5876837968826294, "action": -0.35956478118896484}
{"mode": "train", "epochs": 2, "timestep": 2654, "ep_reward": 365.7083435058594, "reward": 0.4406023621559143, "action": -1.1557753086090088}
{"mode": "train", "epochs": 2, "timestep": 2655, "ep_reward": 366.0109558105469, "reward": 0.3026196360588074, "action": -0.7884365320205688}
{"mode": "train", "epochs": 2, "timestep": 2656, "ep_reward": 366.19439697265625, "reward": 0.18343055248260498, "action": -1.6581685543060303}
{"mode": "train", "epochs": 2, "timestep": 2657, "ep_reward": 366.23883056640625, "reward": 0.04442393779754639, "action": -1.4029924869537354}
{"mode": "train", "epochs": 2, "timestep": 2658, "ep_reward": 366.3123779296875, "reward": 0.07355338335037231, "action": -1.137609839439392}
{"mode": "train", "epochs": 2, "timestep": 2659, "ep_reward": 366.5216979980469, "reward": 0.20930999517440796, "action": -0.8035914301872253}
{"mode": "train", "epochs": 2, "timestep": 2660, "ep_reward": 366.8736877441406, "reward": 0.35199278593063354, "action": -0.9541720747947693}
{"mode": "train", "epochs": 2, "timestep": 2661, "ep_reward": 367.358642578125, "reward": 0.4849514365196228, "action": -1.1992697715759277}
{"mode": "train", "epochs": 2, "timestep": 2662, "ep_reward": 367.95751953125, "reward": 0.5988773107528687, "action": -0.7927933931350708}
{"mode": "train", "epochs": 2, "timestep": 2663, "ep_reward": 368.6534729003906, "reward": 0.6959497332572937, "action": 0.2921485900878906}
{"mode": "train", "epochs": 2, "timestep": 2664, "ep_reward": 369.43304443359375, "reward": 0.7795565724372864, "action": -1.2124327421188354}
{"mode": "train", "epochs": 2, "timestep": 2665, "ep_reward": 370.2601318359375, "reward": 0.8270723819732666, "action": -0.583141565322876}
{"mode": "train", "epochs": 2, "timestep": 2666, "ep_reward": 371.12225341796875, "reward": 0.8621208667755127, "action": -0.20744264125823975}
{"mode": "train", "epochs": 2, "timestep": 2667, "ep_reward": 372.0063171386719, "reward": 0.8840616941452026, "action": -0.8507308959960938}
{"mode": "train", "epochs": 2, "timestep": 2668, "ep_reward": 372.8927917480469, "reward": 0.8864806890487671, "action": -1.7704055309295654}
{"mode": "train", "epochs": 2, "timestep": 2669, "ep_reward": 373.759521484375, "reward": 0.8667399883270264, "action": -1.1624815464019775}
{"mode": "train", "epochs": 2, "timestep": 2670, "ep_reward": 374.5930480957031, "reward": 0.8335282802581787, "action": -1.5039950609207153}
{"mode": "train", "epochs": 2, "timestep": 2671, "ep_reward": 375.36663818359375, "reward": 0.7735891342163086, "action": -0.5075571537017822}
{"mode": "train", "epochs": 2, "timestep": 2672, "ep_reward": 376.06121826171875, "reward": 0.694571852684021, "action": -0.9236977100372314}
{"mode": "train", "epochs": 2, "timestep": 2673, "ep_reward": 376.6366882324219, "reward": 0.5754610896110535, "action": -1.3664124011993408}
{"mode": "train", "epochs": 2, "timestep": 2674, "ep_reward": 377.04547119140625, "reward": 0.4087679386138916, "action": -0.5414649248123169}
{"mode": "train", "epochs": 2, "timestep": 2675, "ep_reward": 377.337890625, "reward": 0.2924056649208069, "action": -0.8798956274986267}
{"mode": "train", "epochs": 2, "timestep": 2676, "ep_reward": 377.50933837890625, "reward": 0.17143875360488892, "action": -1.2877047061920166}
{"mode": "train", "epochs": 2, "timestep": 2677, "ep_reward": 377.5398254394531, "reward": 0.030481278896331787, "action": -1.5499255657196045}
{"mode": "train", "epochs": 2, "timestep": 2678, "ep_reward": 377.6268005371094, "reward": 0.08698582649230957, "action": -0.6310063600540161}
{"mode": "train", "epochs": 2, "timestep": 2679, "ep_reward": 377.8562927246094, "reward": 0.22949641942977905, "action": -0.2738267183303833}
{"mode": "train", "epochs": 2, "timestep": 2680, "ep_reward": 378.2331237792969, "reward": 0.37683117389678955, "action": -0.763757586479187}
{"mode": "train", "epochs": 2, "timestep": 2681, "ep_reward": 378.7411804199219, "reward": 0.5080535411834717, "action": -1.7234160900115967}
{"mode": "train", "epochs": 2, "timestep": 2682, "ep_reward": 379.35357666015625, "reward": 0.6123900413513184, "action": -0.6583261489868164}
{"mode": "train", "epochs": 2, "timestep": 2683, "ep_reward": 380.06182861328125, "reward": 0.7082443237304688, "action": -0.9190461039543152}
{"mode": "train", "epochs": 2, "timestep": 2684, "ep_reward": 380.84075927734375, "reward": 0.7789207100868225, "action": -0.9162865877151489}
{"mode": "train", "epochs": 2, "timestep": 2685, "ep_reward": 381.6700439453125, "reward": 0.8292906284332275, "action": -0.877411961555481}
{"mode": "train", "epochs": 2, "timestep": 2686, "ep_reward": 382.5321044921875, "reward": 0.8620695471763611, "action": -1.6796282529830933}
{"mode": "train", "epochs": 2, "timestep": 2687, "ep_reward": 383.405029296875, "reward": 0.8729350566864014, "action": -1.3490022420883179}
{"mode": "train", "epochs": 2, "timestep": 2688, "ep_reward": 384.2762145996094, "reward": 0.8711770176887512, "action": -1.8305976390838623}
{"mode": "train", "epochs": 2, "timestep": 2689, "ep_reward": 385.12445068359375, "reward": 0.8482244610786438, "action": -1.9683558940887451}
{"mode": "train", "epochs": 2, "timestep": 2690, "ep_reward": 385.92669677734375, "reward": 0.8022576570510864, "action": -0.4006500840187073}
{"mode": "train", "epochs": 2, "timestep": 2691, "ep_reward": 386.67205810546875, "reward": 0.7453761100769043, "action": -0.669891357421875}
{"mode": "train", "epochs": 2, "timestep": 2692, "ep_reward": 387.3262023925781, "reward": 0.6541491150856018, "action": -1.5752971172332764}
{"mode": "train", "epochs": 2, "timestep": 2693, "ep_reward": 387.8379821777344, "reward": 0.5117698907852173, "action": -1.5068097114562988}
{"mode": "train", "epochs": 2, "timestep": 2694, "ep_reward": 388.2039489746094, "reward": 0.3659709692001343, "action": -1.580815076828003}
{"mode": "train", "epochs": 2, "timestep": 2695, "ep_reward": 388.46331787109375, "reward": 0.25936347246170044, "action": -0.8453468084335327}
{"mode": "train", "epochs": 2, "timestep": 2696, "ep_reward": 388.5959777832031, "reward": 0.1326560378074646, "action": -0.7339433431625366}
{"mode": "train", "epochs": 2, "timestep": 2697, "ep_reward": 388.58184814453125, "reward": -0.014130949974060059, "action": -1.2831053733825684}
{"mode": "train", "epochs": 2, "timestep": 2698, "ep_reward": 388.7095642089844, "reward": 0.12771838903427124, "action": -0.7989100217819214}
{"mode": "train", "epochs": 2, "timestep": 2699, "ep_reward": 388.97882080078125, "reward": 0.2692583203315735, "action": -0.6711666584014893}
{"mode": "train", "epochs": 2, "timestep": 2700, "ep_reward": 389.3892517089844, "reward": 0.41042619943618774, "action": -1.9308509826660156}
{"mode": "train", "epochs": 2, "timestep": 2701, "ep_reward": 389.9148864746094, "reward": 0.5256465673446655, "action": -0.9664925336837769}
{"mode": "train", "epochs": 2, "timestep": 2702, "ep_reward": 390.5502014160156, "reward": 0.6353133916854858, "action": -1.0183793306350708}
{"mode": "train", "epochs": 2, "timestep": 2703, "ep_reward": 391.2720031738281, "reward": 0.7217997312545776, "action": -1.0080889463424683}
{"mode": "train", "epochs": 2, "timestep": 2704, "ep_reward": 392.05780029296875, "reward": 0.7858098149299622, "action": -0.3216865658760071}
{"mode": "train", "epochs": 2, "timestep": 2705, "ep_reward": 392.89276123046875, "reward": 0.8349514007568359, "action": -1.0551631450653076}
{"mode": "train", "epochs": 2, "timestep": 2706, "ep_reward": 393.75189208984375, "reward": 0.8591315746307373, "action": -0.6835019588470459}
{"mode": "train", "epochs": 2, "timestep": 2707, "ep_reward": 394.62188720703125, "reward": 0.8699973821640015, "action": -0.14132064580917358}
{"mode": "train", "epochs": 2, "timestep": 2708, "ep_reward": 395.4912414550781, "reward": 0.869344174861908, "action": -0.21829569339752197}
{"mode": "train", "epochs": 2, "timestep": 2709, "ep_reward": 396.3425598144531, "reward": 0.8513213396072388, "action": -1.1579654216766357}
{"mode": "train", "epochs": 2, "timestep": 2710, "ep_reward": 397.1473693847656, "reward": 0.8048194646835327, "action": -0.9850557446479797}
{"mode": "train", "epochs": 2, "timestep": 2711, "ep_reward": 397.8808288574219, "reward": 0.7334519624710083, "action": -1.5050245523452759}
{"mode": "train", "epochs": 2, "timestep": 2712, "ep_reward": 398.50274658203125, "reward": 0.6219213008880615, "action": -1.5453877449035645}
{"mode": "train", "epochs": 2, "timestep": 2713, "ep_reward": 398.9703369140625, "reward": 0.4675925374031067, "action": -0.6485830545425415}
{"mode": "train", "epochs": 2, "timestep": 2714, "ep_reward": 399.30316162109375, "reward": 0.33283936977386475, "action": -1.6821763515472412}
{"mode": "train", "epochs": 2, "timestep": 2715, "ep_reward": 399.5227966308594, "reward": 0.21964561939239502, "action": -0.7105668783187866}
{"mode": "train", "epochs": 2, "timestep": 2716, "ep_reward": 399.6091003417969, "reward": 0.08631861209869385, "action": -0.5659216642379761}
{"mode": "train", "epochs": 2, "timestep": 2717, "ep_reward": 399.640380859375, "reward": 0.03128784894943237, "action": -0.9041702747344971}
{"mode": "train", "epochs": 2, "timestep": 2718, "ep_reward": 399.8125, "reward": 0.17211663722991943, "action": -0.7954466342926025}
{"mode": "train", "epochs": 2, "timestep": 2719, "ep_reward": 400.1271057128906, "reward": 0.314619779586792, "action": -0.8866791129112244}
{"mode": "train", "epochs": 2, "timestep": 2720, "ep_reward": 400.5779724121094, "reward": 0.4508805274963379, "action": -1.7579243183135986}
{"mode": "train", "epochs": 2, "timestep": 2721, "ep_reward": 401.1413879394531, "reward": 0.563408613204956, "action": -0.6976156234741211}
{"mode": "train", "epochs": 2, "timestep": 2722, "ep_reward": 401.81011962890625, "reward": 0.6687380075454712, "action": -0.7886638045310974}
{"mode": "train", "epochs": 2, "timestep": 2723, "ep_reward": 402.5594177246094, "reward": 0.7493014335632324, "action": -1.4699938297271729}
{"mode": "train", "epochs": 2, "timestep": 2724, "ep_reward": 403.36090087890625, "reward": 0.8014923334121704, "action": -0.7253080606460571}
{"mode": "train", "epochs": 2, "timestep": 2725, "ep_reward": 404.20166015625, "reward": 0.8407694101333618, "action": -1.4288113117218018}
{"mode": "train", "epochs": 2, "timestep": 2726, "ep_reward": 405.0577392578125, "reward": 0.8560645580291748, "action": -0.8045387268066406}
{"mode": "train", "epochs": 2, "timestep": 2727, "ep_reward": 405.9173583984375, "reward": 0.8596147298812866, "action": -0.889144241809845}
{"mode": "train", "epochs": 2, "timestep": 2728, "ep_reward": 406.76177978515625, "reward": 0.8444334864616394, "action": -1.2164934873580933}
{"mode": "train", "epochs": 2, "timestep": 2729, "ep_reward": 407.5670166015625, "reward": 0.805239200592041, "action": -0.7870332598686218}
{"mode": "train", "epochs": 2, "timestep": 2730, "ep_reward": 408.3111267089844, "reward": 0.7441097497940063, "action": -1.5187773704528809}
{"mode": "train", "epochs": 2, "timestep": 2731, "ep_reward": 408.9525146484375, "reward": 0.6413866281509399, "action": -0.4441717267036438}
{"mode": "train", "epochs": 2, "timestep": 2732, "ep_reward": 409.4649963378906, "reward": 0.5124803781509399, "action": -1.8788950443267822}
{"mode": "train", "epochs": 2, "timestep": 2733, "ep_reward": 409.8290710449219, "reward": 0.3640599250793457, "action": -0.47003865242004395}
{"mode": "train", "epochs": 2, "timestep": 2734, "ep_reward": 410.0859375, "reward": 0.25686752796173096, "action": -1.0080490112304688}
{"mode": "train", "epochs": 2, "timestep": 2735, "ep_reward": 410.2156982421875, "reward": 0.12976378202438354, "action": -0.6348601579666138}
{"mode": "train", "epochs": 2, "timestep": 2736, "ep_reward": 410.1992492675781, "reward": -0.01644313335418701, "action": -1.2313177585601807}
{"mode": "train", "epochs": 2, "timestep": 2737, "ep_reward": 410.329833984375, "reward": 0.13059037923812866, "action": -1.0943886041641235}
{"mode": "train", "epochs": 2, "timestep": 2738, "ep_reward": 410.5983581542969, "reward": 0.2685123682022095, "action": -0.9427701234817505}
{"mode": "train", "epochs": 2, "timestep": 2739, "ep_reward": 411.00555419921875, "reward": 0.40719830989837646, "action": -1.2144169807434082}
{"mode": "train", "epochs": 2, "timestep": 2740, "ep_reward": 411.53704833984375, "reward": 0.5315024256706238, "action": -0.2582738995552063}
{"mode": "train", "epochs": 2, "timestep": 2741, "ep_reward": 412.1846618652344, "reward": 0.6476154327392578, "action": -0.7278978824615479}
{"mode": "train", "epochs": 2, "timestep": 2742, "ep_reward": 412.9192199707031, "reward": 0.7345725297927856, "action": -1.6081814765930176}
{"mode": "train", "epochs": 2, "timestep": 2743, "ep_reward": 413.7106628417969, "reward": 0.791438102722168, "action": -0.7910293936729431}
{"mode": "train", "epochs": 2, "timestep": 2744, "ep_reward": 414.5469665527344, "reward": 0.8363070487976074, "action": -0.8498508930206299}
{"mode": "train", "epochs": 2, "timestep": 2745, "ep_reward": 415.4097595214844, "reward": 0.8627813458442688, "action": 0.02105271816253662}
{"mode": "train", "epochs": 2, "timestep": 2746, "ep_reward": 416.28997802734375, "reward": 0.8802301287651062, "action": -0.9526122808456421}
{"mode": "train", "epochs": 2, "timestep": 2747, "ep_reward": 417.1644287109375, "reward": 0.8744425773620605, "action": -1.7801165580749512}
{"mode": "train", "epochs": 2, "timestep": 2748, "ep_reward": 418.0091552734375, "reward": 0.8447265625, "action": -0.9844045042991638}
{"mode": "train", "epochs": 2, "timestep": 2749, "ep_reward": 418.8096618652344, "reward": 0.8005087375640869, "action": -0.8764412999153137}
{"mode": "train", "epochs": 2, "timestep": 2750, "ep_reward": 419.5404357910156, "reward": 0.7307864427566528, "action": -0.5563427209854126}
{"mode": "train", "epochs": 2, "timestep": 2751, "ep_reward": 420.17254638671875, "reward": 0.6321201324462891, "action": -1.0735951662063599}
{"mode": "train", "epochs": 2, "timestep": 2752, "ep_reward": 420.66070556640625, "reward": 0.4881715178489685, "action": -1.337938904762268}
{"mode": "train", "epochs": 2, "timestep": 2753, "ep_reward": 421.0004577636719, "reward": 0.3397485613822937, "action": -1.3667670488357544}
{"mode": "train", "epochs": 2, "timestep": 2754, "ep_reward": 421.228271484375, "reward": 0.22780418395996094, "action": -0.9479905366897583}
{"mode": "train", "epochs": 2, "timestep": 2755, "ep_reward": 421.3241271972656, "reward": 0.0958472490310669, "action": -0.37525850534439087}
{"mode": "train", "epochs": 2, "timestep": 2756, "ep_reward": 421.3453063964844, "reward": 0.021180808544158936, "action": -0.9195287227630615}
{"mode": "train", "epochs": 2, "timestep": 2757, "ep_reward": 421.508544921875, "reward": 0.16324633359909058, "action": -1.4896682500839233}
{"mode": "train", "epochs": 2, "timestep": 2758, "ep_reward": 421.8055419921875, "reward": 0.2970101237297058, "action": -0.7294528484344482}
{"mode": "train", "epochs": 2, "timestep": 2759, "ep_reward": 422.24310302734375, "reward": 0.43755990266799927, "action": -1.188523292541504}
{"mode": "train", "epochs": 2, "timestep": 2760, "ep_reward": 422.8016052246094, "reward": 0.5585070848464966, "action": -1.1465157270431519}
{"mode": "train", "epochs": 2, "timestep": 2761, "ep_reward": 423.46173095703125, "reward": 0.660120964050293, "action": -0.7650956511497498}
{"mode": "train", "epochs": 2, "timestep": 2762, "ep_reward": 424.204345703125, "reward": 0.7426227331161499, "action": -1.4214632511138916}
{"mode": "train", "epochs": 2, "timestep": 2763, "ep_reward": 425.0006408691406, "reward": 0.7963100671768188, "action": -0.9646127820014954}
{"mode": "train", "epochs": 2, "timestep": 2764, "ep_reward": 425.83477783203125, "reward": 0.8341485261917114, "action": -1.212785005569458}
{"mode": "train", "epochs": 2, "timestep": 2765, "ep_reward": 426.68597412109375, "reward": 0.8512073755264282, "action": -1.4129365682601929}
{"mode": "train", "epochs": 2, "timestep": 2766, "ep_reward": 427.53448486328125, "reward": 0.8484981060028076, "action": -1.5894677639007568}
{"mode": "train", "epochs": 2, "timestep": 2767, "ep_reward": 428.35882568359375, "reward": 0.8243393898010254, "action": -1.0793507099151611}
{"mode": "train", "epochs": 2, "timestep": 2768, "ep_reward": 429.1399841308594, "reward": 0.7811693549156189, "action": -1.4070086479187012}
{"mode": "train", "epochs": 2, "timestep": 2769, "ep_reward": 429.84466552734375, "reward": 0.704689621925354, "action": -0.7002643346786499}
{"mode": "train", "epochs": 2, "timestep": 2770, "ep_reward": 430.4447021484375, "reward": 0.6000500917434692, "action": -0.40234076976776123}
{"mode": "train", "epochs": 2, "timestep": 2771, "ep_reward": 430.9037780761719, "reward": 0.4590904116630554, "action": -0.8343771696090698}
{"mode": "train", "epochs": 2, "timestep": 2772, "ep_reward": 431.24212646484375, "reward": 0.3383508324623108, "action": -0.465670645236969}
{"mode": "train", "epochs": 2, "timestep": 2773, "ep_reward": 431.46807861328125, "reward": 0.22594141960144043, "action": -1.4098291397094727}
{"mode": "train", "epochs": 2, "timestep": 2774, "ep_reward": 431.5617370605469, "reward": 0.09366756677627563, "action": -1.2639710903167725}
{"mode": "train", "epochs": 2, "timestep": 2775, "ep_reward": 431.58514404296875, "reward": 0.02342069149017334, "action": -0.8614092469215393}
{"mode": "train", "epochs": 2, "timestep": 2776, "ep_reward": 431.7503967285156, "reward": 0.16525262594223022, "action": -1.0728071928024292}
{"mode": "train", "epochs": 2, "timestep": 2777, "ep_reward": 432.05450439453125, "reward": 0.3041018843650818, "action": -1.5905851125717163}
{"mode": "train", "epochs": 2, "timestep": 2778, "ep_reward": 432.4877624511719, "reward": 0.4332466125488281, "action": -0.34946125745773315}
{"mode": "train", "epochs": 2, "timestep": 2779, "ep_reward": 433.0523376464844, "reward": 0.5645714998245239, "action": -0.9518154859542847}
{"mode": "train", "epochs": 2, "timestep": 2780, "ep_reward": 433.7193603515625, "reward": 0.6670288443565369, "action": -1.4781973361968994}
{"mode": "train", "epochs": 2, "timestep": 2781, "ep_reward": 434.4609680175781, "reward": 0.7416098117828369, "action": -1.2435804605484009}
{"mode": "train", "epochs": 2, "timestep": 2782, "ep_reward": 435.2580261230469, "reward": 0.7970457673072815, "action": -1.5391592979431152}
{"mode": "train", "epochs": 2, "timestep": 2783, "ep_reward": 436.08795166015625, "reward": 0.8299381732940674, "action": -0.8102812767028809}
{"mode": "train", "epochs": 2, "timestep": 2784, "ep_reward": 436.9386901855469, "reward": 0.8507435321807861, "action": -1.0682358741760254}
{"mode": "train", "epochs": 2, "timestep": 2785, "ep_reward": 437.7898254394531, "reward": 0.8511387705802917, "action": -1.1061981916427612}
{"mode": "train", "epochs": 2, "timestep": 2786, "ep_reward": 438.6218566894531, "reward": 0.8320393562316895, "action": -0.48861998319625854}
{"mode": "train", "epochs": 2, "timestep": 2787, "ep_reward": 439.4186706542969, "reward": 0.7968065142631531, "action": -0.7872024774551392}
{"mode": "train", "epochs": 2, "timestep": 2788, "ep_reward": 440.15069580078125, "reward": 0.7320241928100586, "action": -0.6376215219497681}
{"mode": "train", "epochs": 2, "timestep": 2789, "ep_reward": 440.7867736816406, "reward": 0.6360777616500854, "action": -0.772935152053833}
{"mode": "train", "epochs": 2, "timestep": 2790, "ep_reward": 441.28643798828125, "reward": 0.4996596574783325, "action": -0.9140954613685608}
{"mode": "train", "epochs": 2, "timestep": 2791, "ep_reward": 441.640869140625, "reward": 0.3544210195541382, "action": -0.8231774568557739}
{"mode": "train", "epochs": 2, "timestep": 2792, "ep_reward": 441.8861999511719, "reward": 0.24533063173294067, "action": -0.7076500654220581}
{"mode": "train", "epochs": 2, "timestep": 2793, "ep_reward": 442.0024719238281, "reward": 0.11625921726226807, "action": -0.17073553800582886}
{"mode": "train", "epochs": 2, "timestep": 2794, "ep_reward": 442.0011901855469, "reward": -0.0012843608856201172, "action": -1.869462490081787}
{"mode": "train", "epochs": 2, "timestep": 2795, "ep_reward": 442.1451416015625, "reward": 0.14396047592163086, "action": -0.6734069585800171}
{"mode": "train", "epochs": 2, "timestep": 2796, "ep_reward": 442.4325866699219, "reward": 0.2874481678009033, "action": -0.5911011695861816}
{"mode": "train", "epochs": 2, "timestep": 2797, "ep_reward": 442.8611755371094, "reward": 0.428589403629303, "action": -1.126738429069519}
{"mode": "train", "epochs": 2, "timestep": 2798, "ep_reward": 443.4117431640625, "reward": 0.5505715608596802, "action": -1.121759057044983}
{"mode": "train", "epochs": 2, "timestep": 2799, "ep_reward": 444.0658874511719, "reward": 0.654140293598175, "action": -0.6933543682098389}
{"mode": "train", "epochs": 2, "timestep": 2800, "ep_reward": 444.8059997558594, "reward": 0.7401089668273926, "action": -0.649608850479126}
{"mode": "train", "epochs": 2, "timestep": 2801, "ep_reward": 445.6100769042969, "reward": 0.8040875196456909, "action": -1.184469223022461}
{"mode": "train", "epochs": 2, "timestep": 2802, "ep_reward": 446.4541015625, "reward": 0.844010055065155, "action": -0.5925489068031311}
{"mode": "train", "epochs": 2, "timestep": 2803, "ep_reward": 447.3260803222656, "reward": 0.8719925880432129, "action": -1.4376178979873657}
{"mode": "train", "epochs": 2, "timestep": 2804, "ep_reward": 448.20428466796875, "reward": 0.8781912922859192, "action": -0.9312260150909424}
{"mode": "train", "epochs": 2, "timestep": 2805, "ep_reward": 449.0777587890625, "reward": 0.8734877705574036, "action": -0.2767285704612732}
{"mode": "train", "epochs": 2, "timestep": 2806, "ep_reward": 449.9358215332031, "reward": 0.8580684065818787, "action": -0.7241331338882446}
{"mode": "train", "epochs": 2, "timestep": 2807, "ep_reward": 450.7556457519531, "reward": 0.8198152780532837, "action": -1.8498952388763428}
{"mode": "train", "epochs": 2, "timestep": 2808, "ep_reward": 451.5009460449219, "reward": 0.7453103065490723, "action": -0.009857475757598877}
{"mode": "train", "epochs": 2, "timestep": 2809, "ep_reward": 452.15997314453125, "reward": 0.6590313911437988, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 2810, "ep_reward": 452.6699523925781, "reward": 0.509979248046875, "action": -0.9742448925971985}
{"mode": "train", "epochs": 2, "timestep": 2811, "ep_reward": 453.0242919921875, "reward": 0.3543447256088257, "action": -0.2730042338371277}
{"mode": "train", "epochs": 2, "timestep": 2812, "ep_reward": 453.2695007324219, "reward": 0.2452232837677002, "action": -0.16317325830459595}
{"mode": "train", "epochs": 2, "timestep": 2813, "ep_reward": 453.3855285644531, "reward": 0.11601364612579346, "action": -1.1823976039886475}
{"mode": "train", "epochs": 2, "timestep": 2814, "ep_reward": 453.3844909667969, "reward": -0.0010499954223632812, "action": -1.6115567684173584}
{"mode": "train", "epochs": 2, "timestep": 2815, "ep_reward": 453.5285949707031, "reward": 0.14411026239395142, "action": -0.7363801002502441}
{"mode": "train", "epochs": 2, "timestep": 2816, "ep_reward": 453.8154296875, "reward": 0.2868384122848511, "action": -0.37875306606292725}
{"mode": "train", "epochs": 2, "timestep": 2817, "ep_reward": 454.24603271484375, "reward": 0.4306161403656006, "action": -1.3626909255981445}
{"mode": "train", "epochs": 2, "timestep": 2818, "ep_reward": 454.795654296875, "reward": 0.549622118473053, "action": -0.9940371513366699}
{"mode": "train", "epochs": 2, "timestep": 2819, "ep_reward": 455.4503479003906, "reward": 0.6546992063522339, "action": -0.45497941970825195}
{"mode": "train", "epochs": 2, "timestep": 2820, "ep_reward": 456.19317626953125, "reward": 0.7428297996520996, "action": 0.33695852756500244}
{"mode": "train", "epochs": 2, "timestep": 2821, "ep_reward": 457.00799560546875, "reward": 0.8148313164710999, "action": -1.0723227262496948}
{"mode": "train", "epochs": 2, "timestep": 2822, "ep_reward": 457.8626708984375, "reward": 0.8546760082244873, "action": -1.6839874982833862}
{"mode": "train", "epochs": 2, "timestep": 2823, "ep_reward": 458.7372741699219, "reward": 0.8745894432067871, "action": -1.1145380735397339}
{"mode": "train", "epochs": 2, "timestep": 2824, "ep_reward": 459.62213134765625, "reward": 0.884858250617981, "action": -1.4180809259414673}
{"mode": "train", "epochs": 2, "timestep": 2825, "ep_reward": 460.500732421875, "reward": 0.8786056041717529, "action": -0.6723634600639343}
{"mode": "train", "epochs": 2, "timestep": 2826, "ep_reward": 461.3632507324219, "reward": 0.862529993057251, "action": -1.7116715908050537}
{"mode": "train", "epochs": 2, "timestep": 2827, "ep_reward": 462.1814880371094, "reward": 0.818250298500061, "action": -0.8196430206298828}
{"mode": "train", "epochs": 2, "timestep": 2828, "ep_reward": 462.9387512207031, "reward": 0.7572618722915649, "action": -1.2180612087249756}
{"mode": "train", "epochs": 2, "timestep": 2829, "ep_reward": 463.5993347167969, "reward": 0.6605908870697021, "action": -0.7660192847251892}
{"mode": "train", "epochs": 2, "timestep": 2830, "ep_reward": 464.13079833984375, "reward": 0.5314759016036987, "action": -0.8864924907684326}
{"mode": "train", "epochs": 2, "timestep": 2831, "ep_reward": 464.4961853027344, "reward": 0.36539483070373535, "action": -0.11412382125854492}
{"mode": "train", "epochs": 2, "timestep": 2832, "ep_reward": 464.75469970703125, "reward": 0.25852400064468384, "action": -0.15723800659179688}
{"mode": "train", "epochs": 2, "timestep": 2833, "ep_reward": 464.8862609863281, "reward": 0.13156914710998535, "action": -1.178910732269287}
{"mode": "train", "epochs": 2, "timestep": 2834, "ep_reward": 464.8709411621094, "reward": -0.015311121940612793, "action": -1.253327488899231}
{"mode": "train", "epochs": 2, "timestep": 2835, "ep_reward": 464.9996337890625, "reward": 0.12868517637252808, "action": -1.3333444595336914}
{"mode": "train", "epochs": 2, "timestep": 2836, "ep_reward": 465.2632751464844, "reward": 0.2636435627937317, "action": 0.09052109718322754}
{"mode": "train", "epochs": 2, "timestep": 2837, "ep_reward": 465.6787414550781, "reward": 0.4154788851737976, "action": -1.1769829988479614}
{"mode": "train", "epochs": 2, "timestep": 2838, "ep_reward": 466.21722412109375, "reward": 0.5384740829467773, "action": -0.8428124785423279}
{"mode": "train", "epochs": 2, "timestep": 2839, "ep_reward": 466.8642578125, "reward": 0.6470323801040649, "action": -1.3415441513061523}
{"mode": "train", "epochs": 2, "timestep": 2840, "ep_reward": 467.5928955078125, "reward": 0.7286428809165955, "action": -0.8942301869392395}
{"mode": "train", "epochs": 2, "timestep": 2841, "ep_reward": 468.3861389160156, "reward": 0.7932292222976685, "action": -0.921107292175293}
{"mode": "train", "epochs": 2, "timestep": 2842, "ep_reward": 469.22357177734375, "reward": 0.8374360203742981, "action": -1.5383355617523193}
{"mode": "train", "epochs": 2, "timestep": 2843, "ep_reward": 470.08270263671875, "reward": 0.8591325879096985, "action": -1.257812738418579}
{"mode": "train", "epochs": 2, "timestep": 2844, "ep_reward": 470.9499206542969, "reward": 0.8672229051589966, "action": -0.08330506086349487}
{"mode": "train", "epochs": 2, "timestep": 2845, "ep_reward": 471.8188781738281, "reward": 0.8689451217651367, "action": -1.1993682384490967}
{"mode": "train", "epochs": 2, "timestep": 2846, "ep_reward": 472.6627502441406, "reward": 0.8438619375228882, "action": -0.8871727585792542}
{"mode": "train", "epochs": 2, "timestep": 2847, "ep_reward": 473.4631042480469, "reward": 0.8003502488136292, "action": -1.0811747312545776}
{"mode": "train", "epochs": 2, "timestep": 2848, "ep_reward": 474.1911926269531, "reward": 0.728073239326477, "action": -0.4726595878601074}
{"mode": "train", "epochs": 2, "timestep": 2849, "ep_reward": 474.82098388671875, "reward": 0.6298009157180786, "action": -0.1767587661743164}
{"mode": "train", "epochs": 2, "timestep": 2850, "ep_reward": 475.3198547363281, "reward": 0.4988728165626526, "action": -0.8648276329040527}
{"mode": "train", "epochs": 2, "timestep": 2851, "ep_reward": 475.6600036621094, "reward": 0.34014803171157837, "action": -0.5311741828918457}
{"mode": "train", "epochs": 2, "timestep": 2852, "ep_reward": 475.8881530761719, "reward": 0.2281518578529358, "action": -1.0413899421691895}
{"mode": "train", "epochs": 2, "timestep": 2853, "ep_reward": 475.9842834472656, "reward": 0.09614521265029907, "action": -1.436962604522705}
{"mode": "train", "epochs": 2, "timestep": 2854, "ep_reward": 476.0049743652344, "reward": 0.020681262016296387, "action": -1.29096257686615}
{"mode": "train", "epochs": 2, "timestep": 2855, "ep_reward": 476.1679382324219, "reward": 0.1629529595375061, "action": -0.8266961574554443}
{"mode": "train", "epochs": 2, "timestep": 2856, "ep_reward": 476.4728698730469, "reward": 0.30493611097335815, "action": -0.6149663925170898}
{"mode": "train", "epochs": 2, "timestep": 2857, "ep_reward": 476.9179992675781, "reward": 0.44512248039245605, "action": -1.3115170001983643}
{"mode": "train", "epochs": 2, "timestep": 2858, "ep_reward": 477.4811706542969, "reward": 0.5631715059280396, "action": -1.0438083410263062}
{"mode": "train", "epochs": 2, "timestep": 2859, "ep_reward": 478.1461181640625, "reward": 0.66493821144104, "action": -1.9090441465377808}
{"mode": "train", "epochs": 2, "timestep": 2860, "ep_reward": 478.88226318359375, "reward": 0.7361418008804321, "action": -1.7134921550750732}
{"mode": "train", "epochs": 2, "timestep": 2861, "ep_reward": 479.6709899902344, "reward": 0.788720965385437, "action": -1.5576221942901611}
{"mode": "train", "epochs": 2, "timestep": 2862, "ep_reward": 480.4938659667969, "reward": 0.8228766322135925, "action": -0.36771059036254883}
{"mode": "train", "epochs": 2, "timestep": 2863, "ep_reward": 481.34228515625, "reward": 0.848416805267334, "action": -1.411415696144104}
{"mode": "train", "epochs": 2, "timestep": 2864, "ep_reward": 482.1881103515625, "reward": 0.8458367586135864, "action": -1.871896505355835}
{"mode": "train", "epochs": 2, "timestep": 2865, "ep_reward": 483.00677490234375, "reward": 0.818655252456665, "action": -1.4254659414291382}
{"mode": "train", "epochs": 2, "timestep": 2866, "ep_reward": 483.7774963378906, "reward": 0.7707159519195557, "action": -0.5352250337600708}
{"mode": "train", "epochs": 2, "timestep": 2867, "ep_reward": 484.4798889160156, "reward": 0.7024037837982178, "action": -0.42236244678497314}
{"mode": "train", "epochs": 2, "timestep": 2868, "ep_reward": 485.0801696777344, "reward": 0.6002858877182007, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 2869, "ep_reward": 485.5135803222656, "reward": 0.4334205389022827, "action": -1.1122750043869019}
{"mode": "train", "epochs": 2, "timestep": 2870, "ep_reward": 485.8466491699219, "reward": 0.33306312561035156, "action": -0.42386728525161743}
{"mode": "train", "epochs": 2, "timestep": 2871, "ep_reward": 486.06634521484375, "reward": 0.21969544887542725, "action": -0.9041064977645874}
{"mode": "train", "epochs": 2, "timestep": 2872, "ep_reward": 486.15264892578125, "reward": 0.08631259202957153, "action": -1.3069547414779663}
{"mode": "train", "epochs": 2, "timestep": 2873, "ep_reward": 486.18389892578125, "reward": 0.031235158443450928, "action": -0.5494447350502014}
{"mode": "train", "epochs": 2, "timestep": 2874, "ep_reward": 486.3569030761719, "reward": 0.17300289869308472, "action": -0.35933589935302734}
{"mode": "train", "epochs": 2, "timestep": 2875, "ep_reward": 486.6775817871094, "reward": 0.3206794857978821, "action": -0.7467963695526123}
{"mode": "train", "epochs": 2, "timestep": 2876, "ep_reward": 487.135009765625, "reward": 0.4574166536331177, "action": -0.9965699315071106}
{"mode": "train", "epochs": 2, "timestep": 2877, "ep_reward": 487.7118835449219, "reward": 0.5768857002258301, "action": -1.7303210496902466}
{"mode": "train", "epochs": 2, "timestep": 2878, "ep_reward": 488.3812561035156, "reward": 0.6693747639656067, "action": -0.7884479761123657}
{"mode": "train", "epochs": 2, "timestep": 2879, "ep_reward": 489.1316833496094, "reward": 0.7504319548606873, "action": -1.1388769149780273}
{"mode": "train", "epochs": 2, "timestep": 2880, "ep_reward": 489.9381103515625, "reward": 0.8064131140708923, "action": -1.2851427793502808}
{"mode": "train", "epochs": 2, "timestep": 2881, "ep_reward": 490.7802734375, "reward": 0.8421717882156372, "action": -0.83729088306427}
{"mode": "train", "epochs": 2, "timestep": 2882, "ep_reward": 491.644775390625, "reward": 0.8644922971725464, "action": -1.3969569206237793}
{"mode": "train", "epochs": 2, "timestep": 2883, "ep_reward": 492.5107421875, "reward": 0.865978479385376, "action": -0.9412527680397034}
{"mode": "train", "epochs": 2, "timestep": 2884, "ep_reward": 493.3651428222656, "reward": 0.8544100522994995, "action": -0.5425442457199097}
{"mode": "train", "epochs": 2, "timestep": 2885, "ep_reward": 494.1925354003906, "reward": 0.8273872137069702, "action": -0.7419918179512024}
{"mode": "train", "epochs": 2, "timestep": 2886, "ep_reward": 494.9682312011719, "reward": 0.7756881713867188, "action": -0.37654274702072144}
{"mode": "train", "epochs": 2, "timestep": 2887, "ep_reward": 495.66778564453125, "reward": 0.6995633840560913, "action": -1.7474262714385986}
{"mode": "train", "epochs": 2, "timestep": 2888, "ep_reward": 496.23870849609375, "reward": 0.5709196329116821, "action": -0.9411020278930664}
{"mode": "train", "epochs": 2, "timestep": 2889, "ep_reward": 496.6488342285156, "reward": 0.4101211428642273, "action": -0.8019409775733948}
{"mode": "train", "epochs": 2, "timestep": 2890, "ep_reward": 496.9447937011719, "reward": 0.295954167842865, "action": -0.49729353189468384}
{"mode": "train", "epochs": 2, "timestep": 2891, "ep_reward": 497.1204528808594, "reward": 0.1756548285484314, "action": -0.7886401414871216}
{"mode": "train", "epochs": 2, "timestep": 2892, "ep_reward": 497.15576171875, "reward": 0.03531461954116821, "action": -1.2884870767593384}
{"mode": "train", "epochs": 2, "timestep": 2893, "ep_reward": 497.2381286621094, "reward": 0.08236300945281982, "action": -1.160478115081787}
{"mode": "train", "epochs": 2, "timestep": 2894, "ep_reward": 497.45611572265625, "reward": 0.21799331903457642, "action": -1.6072393655776978}
{"mode": "train", "epochs": 2, "timestep": 2895, "ep_reward": 497.80670166015625, "reward": 0.35057729482650757, "action": -0.8533012866973877}
{"mode": "train", "epochs": 2, "timestep": 2896, "ep_reward": 498.29266357421875, "reward": 0.4859684109687805, "action": -0.5155220031738281}
{"mode": "train", "epochs": 2, "timestep": 2897, "ep_reward": 498.9000549316406, "reward": 0.6073803901672363, "action": -1.337860345840454}
{"mode": "train", "epochs": 2, "timestep": 2898, "ep_reward": 499.5970764160156, "reward": 0.6970338225364685, "action": -0.15392446517944336}
{"mode": "train", "epochs": 2, "timestep": 2899, "ep_reward": 500.3725280761719, "reward": 0.7754654884338379, "action": -1.0869677066802979}
{"mode": "train", "epochs": 2, "timestep": 2900, "ep_reward": 501.1953125, "reward": 0.8227853178977966, "action": -1.153757929801941}
{"mode": "train", "epochs": 2, "timestep": 2901, "ep_reward": 502.0462951660156, "reward": 0.8509799242019653, "action": -1.1536509990692139}
{"mode": "train", "epochs": 2, "timestep": 2902, "ep_reward": 502.90838623046875, "reward": 0.8620941638946533, "action": -1.5198423862457275}
{"mode": "train", "epochs": 2, "timestep": 2903, "ep_reward": 503.7613525390625, "reward": 0.852965235710144, "action": -1.1929386854171753}
{"mode": "train", "epochs": 2, "timestep": 2904, "ep_reward": 504.5885314941406, "reward": 0.8271900415420532, "action": -1.5444648265838623}
{"mode": "train", "epochs": 2, "timestep": 2905, "ep_reward": 505.36248779296875, "reward": 0.7739498615264893, "action": -1.128390908241272}
{"mode": "train", "epochs": 2, "timestep": 2906, "ep_reward": 506.0567626953125, "reward": 0.6942612528800964, "action": -1.604677677154541}
{"mode": "train", "epochs": 2, "timestep": 2907, "ep_reward": 506.6268310546875, "reward": 0.57008296251297, "action": -1.6191363334655762}
{"mode": "train", "epochs": 2, "timestep": 2908, "ep_reward": 507.0375061035156, "reward": 0.4106886386871338, "action": -0.05421566963195801}
{"mode": "train", "epochs": 2, "timestep": 2909, "ep_reward": 507.35113525390625, "reward": 0.31363445520401, "action": -0.7607216238975525}
{"mode": "train", "epochs": 2, "timestep": 2910, "ep_reward": 507.5476989746094, "reward": 0.19657212495803833, "action": -1.1376652717590332}
{"mode": "train", "epochs": 2, "timestep": 2911, "ep_reward": 507.6073303222656, "reward": 0.05961716175079346, "action": -0.550961434841156}
{"mode": "train", "epochs": 2, "timestep": 2912, "ep_reward": 507.6659851074219, "reward": 0.05865901708602905, "action": -1.1417224407196045}
{"mode": "train", "epochs": 2, "timestep": 2913, "ep_reward": 507.86181640625, "reward": 0.1958228349685669, "action": -0.9498031139373779}
{"mode": "train", "epochs": 2, "timestep": 2914, "ep_reward": 508.1984558105469, "reward": 0.3366439938545227, "action": -1.526421308517456}
{"mode": "train", "epochs": 2, "timestep": 2915, "ep_reward": 508.66278076171875, "reward": 0.46431148052215576, "action": -0.8459999561309814}
{"mode": "train", "epochs": 2, "timestep": 2916, "ep_reward": 509.24822998046875, "reward": 0.5854427814483643, "action": -1.5821844339370728}
{"mode": "train", "epochs": 2, "timestep": 2917, "ep_reward": 509.92523193359375, "reward": 0.6769950985908508, "action": -1.0473425388336182}
{"mode": "train", "epochs": 2, "timestep": 2918, "ep_reward": 510.6768798828125, "reward": 0.7516608238220215, "action": -1.2298643589019775}
{"mode": "train", "epochs": 2, "timestep": 2919, "ep_reward": 511.4789733886719, "reward": 0.8020956516265869, "action": -1.378836989402771}
{"mode": "train", "epochs": 2, "timestep": 2920, "ep_reward": 512.3098754882812, "reward": 0.8308743834495544, "action": -1.0680136680603027}
{"mode": "train", "epochs": 2, "timestep": 2921, "ep_reward": 513.1531982421875, "reward": 0.8433433771133423, "action": -0.5275527238845825}
{"mode": "train", "epochs": 2, "timestep": 2922, "ep_reward": 513.99462890625, "reward": 0.8414251804351807, "action": -1.4789477586746216}
{"mode": "train", "epochs": 2, "timestep": 2923, "ep_reward": 514.80419921875, "reward": 0.8095443248748779, "action": -1.2190821170806885}
{"mode": "train", "epochs": 2, "timestep": 2924, "ep_reward": 515.5582885742188, "reward": 0.7541104555130005, "action": -0.5401818752288818}
{"mode": "train", "epochs": 2, "timestep": 2925, "ep_reward": 516.2327880859375, "reward": 0.6744940280914307, "action": -1.8042728900909424}
{"mode": "train", "epochs": 2, "timestep": 2926, "ep_reward": 516.7723999023438, "reward": 0.5396325588226318, "action": -0.38805699348449707}
{"mode": "train", "epochs": 2, "timestep": 2927, "ep_reward": 517.1681518554688, "reward": 0.3957381844520569, "action": -0.7816393971443176}
{"mode": "train", "epochs": 2, "timestep": 2928, "ep_reward": 517.4635009765625, "reward": 0.2953430414199829, "action": -0.9192168116569519}
{"mode": "train", "epochs": 2, "timestep": 2929, "ep_reward": 517.6384887695312, "reward": 0.17499911785125732, "action": -0.519729495048523}
{"mode": "train", "epochs": 2, "timestep": 2930, "ep_reward": 517.673095703125, "reward": 0.03461259603500366, "action": -0.621584951877594}
{"mode": "train", "epochs": 2, "timestep": 2931, "ep_reward": 517.756103515625, "reward": 0.08300971984863281, "action": -1.7220656871795654}
{"mode": "train", "epochs": 2, "timestep": 2932, "ep_reward": 517.9730224609375, "reward": 0.21690714359283447, "action": -1.0147318840026855}
{"mode": "train", "epochs": 2, "timestep": 2933, "ep_reward": 518.3302001953125, "reward": 0.3571574091911316, "action": -0.9151460528373718}
{"mode": "train", "epochs": 2, "timestep": 2934, "ep_reward": 518.82080078125, "reward": 0.49057328701019287, "action": -1.0750396251678467}
{"mode": "train", "epochs": 2, "timestep": 2935, "ep_reward": 519.4258422851562, "reward": 0.6050161123275757, "action": -1.1562862396240234}
{"mode": "train", "epochs": 2, "timestep": 2936, "ep_reward": 520.1227416992188, "reward": 0.6968724727630615, "action": -1.0716136693954468}
{"mode": "train", "epochs": 2, "timestep": 2937, "ep_reward": 520.8895874023438, "reward": 0.7668224573135376, "action": -0.8137547373771667}
{"mode": "train", "epochs": 2, "timestep": 2938, "ep_reward": 521.7070922851562, "reward": 0.8175098299980164, "action": -0.4450492858886719}
{"mode": "train", "epochs": 2, "timestep": 2939, "ep_reward": 522.5587768554688, "reward": 0.851694643497467, "action": -0.9515543580055237}
{"mode": "train", "epochs": 2, "timestep": 2940, "ep_reward": 523.4227905273438, "reward": 0.8640198707580566, "action": -0.5689901113510132}
{"mode": "train", "epochs": 2, "timestep": 2941, "ep_reward": 524.28564453125, "reward": 0.8628488779067993, "action": -1.1680806875228882}
{"mode": "train", "epochs": 2, "timestep": 2942, "ep_reward": 525.1240234375, "reward": 0.8383728861808777, "action": -1.455357551574707}
{"mode": "train", "epochs": 2, "timestep": 2943, "ep_reward": 525.91259765625, "reward": 0.7885817885398865, "action": -1.6948251724243164}
{"mode": "train", "epochs": 2, "timestep": 2944, "ep_reward": 526.6189575195312, "reward": 0.7063843607902527, "action": -1.1958388090133667}
{"mode": "train", "epochs": 2, "timestep": 2945, "ep_reward": 527.211181640625, "reward": 0.5922236442565918, "action": -1.9626362323760986}
{"mode": "train", "epochs": 2, "timestep": 2946, "ep_reward": 527.6338500976562, "reward": 0.42269474267959595, "action": -1.3849608898162842}
{"mode": "train", "epochs": 2, "timestep": 2947, "ep_reward": 527.9571533203125, "reward": 0.3232787251472473, "action": -0.6260362863540649}
{"mode": "train", "epochs": 2, "timestep": 2948, "ep_reward": 528.165283203125, "reward": 0.20810115337371826, "action": -0.015177249908447266}
{"mode": "train", "epochs": 2, "timestep": 2949, "ep_reward": 528.2379150390625, "reward": 0.07264971733093262, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 2950, "ep_reward": 528.283203125, "reward": 0.04526776075363159, "action": -0.7290898561477661}
{"mode": "train", "epochs": 2, "timestep": 2951, "ep_reward": 528.4683837890625, "reward": 0.1852002739906311, "action": -1.0088653564453125}
{"mode": "train", "epochs": 2, "timestep": 2952, "ep_reward": 528.7933349609375, "reward": 0.3249531388282776, "action": -1.5291707515716553}
{"mode": "train", "epochs": 2, "timestep": 2953, "ep_reward": 529.24658203125, "reward": 0.4532663822174072, "action": -1.3239136934280396}
{"mode": "train", "epochs": 2, "timestep": 2954, "ep_reward": 529.8173828125, "reward": 0.5707751512527466, "action": -0.21234261989593506}
{"mode": "train", "epochs": 2, "timestep": 2955, "ep_reward": 530.4966430664062, "reward": 0.6792768239974976, "action": -1.9756122827529907}
{"mode": "train", "epochs": 2, "timestep": 2956, "ep_reward": 531.2423706054688, "reward": 0.7457494735717773, "action": -1.0832680463790894}
{"mode": "train", "epochs": 2, "timestep": 2957, "ep_reward": 532.0421752929688, "reward": 0.7998046875, "action": -1.4936649799346924}
{"mode": "train", "epochs": 2, "timestep": 2958, "ep_reward": 532.871826171875, "reward": 0.8296459913253784, "action": -1.5306634902954102}
{"mode": "train", "epochs": 2, "timestep": 2959, "ep_reward": 533.7120361328125, "reward": 0.8402214050292969, "action": -0.8462153077125549}
{"mode": "train", "epochs": 2, "timestep": 2960, "ep_reward": 534.5496826171875, "reward": 0.8376253843307495, "action": -1.0523273944854736}
{"mode": "train", "epochs": 2, "timestep": 2961, "ep_reward": 535.3616333007812, "reward": 0.8119450807571411, "action": -0.8046942353248596}
{"mode": "train", "epochs": 2, "timestep": 2962, "ep_reward": 536.1253051757812, "reward": 0.7636937499046326, "action": -1.2103782892227173}
{"mode": "train", "epochs": 2, "timestep": 2963, "ep_reward": 536.804931640625, "reward": 0.6796331405639648, "action": -1.7251087427139282}
{"mode": "train", "epochs": 2, "timestep": 2964, "ep_reward": 537.3538208007812, "reward": 0.5489099025726318, "action": -0.5544074773788452}
{"mode": "train", "epochs": 2, "timestep": 2965, "ep_reward": 537.757080078125, "reward": 0.40328383445739746, "action": -1.313161849975586}
{"mode": "train", "epochs": 2, "timestep": 2966, "ep_reward": 538.061767578125, "reward": 0.304707407951355, "action": -0.27633053064346313}
{"mode": "train", "epochs": 2, "timestep": 2967, "ep_reward": 538.24755859375, "reward": 0.18578338623046875, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 2968, "ep_reward": 538.2948608398438, "reward": 0.04729461669921875, "action": -0.984329342842102}
{"mode": "train", "epochs": 2, "timestep": 2969, "ep_reward": 538.36572265625, "reward": 0.07083863019943237, "action": -0.9370660781860352}
{"mode": "train", "epochs": 2, "timestep": 2970, "ep_reward": 538.5747680664062, "reward": 0.2090204358100891, "action": -0.7607237100601196}
{"mode": "train", "epochs": 2, "timestep": 2971, "ep_reward": 538.926513671875, "reward": 0.3517504334449768, "action": -1.2502679824829102}
{"mode": "train", "epochs": 2, "timestep": 2972, "ep_reward": 539.407470703125, "reward": 0.48094117641448975, "action": -1.3182268142700195}
{"mode": "train", "epochs": 2, "timestep": 2973, "ep_reward": 540.0016479492188, "reward": 0.5941826105117798, "action": -0.9307435154914856}
{"mode": "train", "epochs": 2, "timestep": 2974, "ep_reward": 540.6923828125, "reward": 0.6907221674919128, "action": -1.0040674209594727}
{"mode": "train", "epochs": 2, "timestep": 2975, "ep_reward": 541.45556640625, "reward": 0.7631918787956238, "action": -1.9533748626708984}
{"mode": "train", "epochs": 2, "timestep": 2976, "ep_reward": 542.26123046875, "reward": 0.8056772947311401, "action": -1.0740725994110107}
{"mode": "train", "epochs": 2, "timestep": 2977, "ep_reward": 543.0982666015625, "reward": 0.837043046951294, "action": -0.513525128364563}
{"mode": "train", "epochs": 2, "timestep": 2978, "ep_reward": 543.9530029296875, "reward": 0.8547408580780029, "action": -0.27152198553085327}
{"mode": "train", "epochs": 2, "timestep": 2979, "ep_reward": 544.8095703125, "reward": 0.8565838932991028, "action": -1.1938564777374268}
{"mode": "train", "epochs": 2, "timestep": 2980, "ep_reward": 545.6409912109375, "reward": 0.8314381837844849, "action": -0.41489607095718384}
{"mode": "train", "epochs": 2, "timestep": 2981, "ep_reward": 546.4324340820312, "reward": 0.7914268970489502, "action": -1.1152682304382324}
{"mode": "train", "epochs": 2, "timestep": 2982, "ep_reward": 547.1490478515625, "reward": 0.7166244983673096, "action": -1.487074613571167}
{"mode": "train", "epochs": 2, "timestep": 2983, "ep_reward": 547.750244140625, "reward": 0.6011958718299866, "action": -1.4982554912567139}
{"mode": "train", "epochs": 2, "timestep": 2984, "ep_reward": 548.1920776367188, "reward": 0.44182443618774414, "action": -0.8654475212097168}
{"mode": "train", "epochs": 2, "timestep": 2985, "ep_reward": 548.5195922851562, "reward": 0.3275332450866699, "action": -0.9310434460639954}
{"mode": "train", "epochs": 2, "timestep": 2986, "ep_reward": 548.7326049804688, "reward": 0.21303939819335938, "action": -1.6177400350570679}
{"mode": "train", "epochs": 2, "timestep": 2987, "ep_reward": 548.8113403320312, "reward": 0.07873731851577759, "action": -1.1441080570220947}
{"mode": "train", "epochs": 2, "timestep": 2988, "ep_reward": 548.8504028320312, "reward": 0.03907197713851929, "action": -1.4012243747711182}
{"mode": "train", "epochs": 2, "timestep": 2989, "ep_reward": 549.0293579101562, "reward": 0.17894643545150757, "action": -0.5673823356628418}
{"mode": "train", "epochs": 2, "timestep": 2990, "ep_reward": 549.3536987304688, "reward": 0.324370801448822, "action": -0.7815797328948975}
{"mode": "train", "epochs": 2, "timestep": 2991, "ep_reward": 549.814697265625, "reward": 0.46098655462265015, "action": -1.009019374847412}
{"mode": "train", "epochs": 2, "timestep": 2992, "ep_reward": 550.3948974609375, "reward": 0.5801709294319153, "action": -1.2840096950531006}
{"mode": "train", "epochs": 2, "timestep": 2993, "ep_reward": 551.0713500976562, "reward": 0.6764777898788452, "action": 0.043196797370910645}
{"mode": "train", "epochs": 2, "timestep": 2994, "ep_reward": 551.8348999023438, "reward": 0.7635471820831299, "action": 0.001950383186340332}
{"mode": "train", "epochs": 2, "timestep": 2995, "ep_reward": 552.66162109375, "reward": 0.8266928195953369, "action": -0.5759336948394775}
{"mode": "train", "epochs": 2, "timestep": 2996, "ep_reward": 553.5275268554688, "reward": 0.8658900260925293, "action": 0.07724738121032715}
{"mode": "train", "epochs": 2, "timestep": 2997, "ep_reward": 554.422119140625, "reward": 0.8945685625076294, "action": -0.8562283515930176}
{"mode": "train", "epochs": 2, "timestep": 2998, "ep_reward": 555.3255004882812, "reward": 0.9034075736999512, "action": -0.9057728052139282}
{"mode": "train", "epochs": 2, "timestep": 2999, "ep_reward": 556.2254028320312, "reward": 0.8998927474021912, "action": -1.0442532300949097}
{"mode": "train", "epochs": 2, "timestep": 3000, "ep_reward": 557.1075439453125, "reward": 0.8821408152580261, "action": -0.8262315392494202}
{"mode": "train", "epochs": 2, "timestep": 3001, "ep_reward": 557.9574584960938, "reward": 0.849936306476593, "action": -1.280965805053711}
{"mode": "train", "epochs": 2, "timestep": 3002, "ep_reward": 558.7500610351562, "reward": 0.792617917060852, "action": -1.180584192276001}
{"mode": "train", "epochs": 2, "timestep": 3003, "ep_reward": 559.4581298828125, "reward": 0.7080415487289429, "action": -0.8552621603012085}
{"mode": "train", "epochs": 2, "timestep": 3004, "ep_reward": 560.05078125, "reward": 0.5926272869110107, "action": -0.5416877269744873}
{"mode": "train", "epochs": 2, "timestep": 3005, "ep_reward": 560.4942016601562, "reward": 0.4434240460395813, "action": -1.3377339839935303}
{"mode": "train", "epochs": 2, "timestep": 3006, "ep_reward": 560.7891235351562, "reward": 0.2949438691139221, "action": -0.9250525236129761}
{"mode": "train", "epochs": 2, "timestep": 3007, "ep_reward": 560.9635620117188, "reward": 0.17442506551742554, "action": -1.3865737915039062}
{"mode": "train", "epochs": 2, "timestep": 3008, "ep_reward": 560.99755859375, "reward": 0.034003496170043945, "action": -1.2016825675964355}
{"mode": "train", "epochs": 2, "timestep": 3009, "ep_reward": 561.0812377929688, "reward": 0.08368080854415894, "action": -0.7289701104164124}
{"mode": "train", "epochs": 2, "timestep": 3010, "ep_reward": 561.3060302734375, "reward": 0.2247719168663025, "action": -1.3611537218093872}
{"mode": "train", "epochs": 2, "timestep": 3011, "ep_reward": 561.6653442382812, "reward": 0.35934174060821533, "action": -0.27074676752090454}
{"mode": "train", "epochs": 2, "timestep": 3012, "ep_reward": 562.1649169921875, "reward": 0.49958592653274536, "action": -1.7024743556976318}
{"mode": "train", "epochs": 2, "timestep": 3013, "ep_reward": 562.7705078125, "reward": 0.6055808067321777, "action": -1.1461529731750488}
{"mode": "train", "epochs": 2, "timestep": 3014, "ep_reward": 563.4682006835938, "reward": 0.6976721286773682, "action": -0.8931303024291992}
{"mode": "train", "epochs": 2, "timestep": 3015, "ep_reward": 564.2376708984375, "reward": 0.7694656848907471, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3016, "ep_reward": 565.0477294921875, "reward": 0.8100308179855347, "action": -1.5120915174484253}
{"mode": "train", "epochs": 2, "timestep": 3017, "ep_reward": 565.884033203125, "reward": 0.8362988233566284, "action": -1.2842282056808472}
{"mode": "train", "epochs": 2, "timestep": 3018, "ep_reward": 566.7300415039062, "reward": 0.846028208732605, "action": -1.4723875522613525}
{"mode": "train", "epochs": 2, "timestep": 3019, "ep_reward": 567.56494140625, "reward": 0.8349025249481201, "action": -0.897240161895752}
{"mode": "train", "epochs": 2, "timestep": 3020, "ep_reward": 568.3724975585938, "reward": 0.8075453042984009, "action": -0.9794439077377319}
{"mode": "train", "epochs": 2, "timestep": 3021, "ep_reward": 569.1260986328125, "reward": 0.7536067366600037, "action": -1.0185872316360474}
{"mode": "train", "epochs": 2, "timestep": 3022, "ep_reward": 569.7930297851562, "reward": 0.6669336557388306, "action": -1.7586885690689087}
{"mode": "train", "epochs": 2, "timestep": 3023, "ep_reward": 570.3231201171875, "reward": 0.5300869941711426, "action": -0.8191573619842529}
{"mode": "train", "epochs": 2, "timestep": 3024, "ep_reward": 570.7147827148438, "reward": 0.3916899561882019, "action": -1.044670820236206}
{"mode": "train", "epochs": 2, "timestep": 3025, "ep_reward": 571.0052490234375, "reward": 0.2904829978942871, "action": 0.3949702978134155}
{"mode": "train", "epochs": 2, "timestep": 3026, "ep_reward": 571.1744384765625, "reward": 0.1691901683807373, "action": -0.779092013835907}
{"mode": "train", "epochs": 2, "timestep": 3027, "ep_reward": 571.202392578125, "reward": 0.027963459491729736, "action": 0.07948243618011475}
{"mode": "train", "epochs": 2, "timestep": 3028, "ep_reward": 571.2918701171875, "reward": 0.08948737382888794, "action": -0.8871872425079346}
{"mode": "train", "epochs": 2, "timestep": 3029, "ep_reward": 571.5206909179688, "reward": 0.22882330417633057, "action": -1.0885040760040283}
{"mode": "train", "epochs": 2, "timestep": 3030, "ep_reward": 571.8875732421875, "reward": 0.3669106364250183, "action": -0.5734579563140869}
{"mode": "train", "epochs": 2, "timestep": 3031, "ep_reward": 572.3904418945312, "reward": 0.5028921365737915, "action": -0.5639548301696777}
{"mode": "train", "epochs": 2, "timestep": 3032, "ep_reward": 573.010986328125, "reward": 0.6205431222915649, "action": -1.4306076765060425}
{"mode": "train", "epochs": 2, "timestep": 3033, "ep_reward": 573.718017578125, "reward": 0.7070388793945312, "action": -1.6491811275482178}
{"mode": "train", "epochs": 2, "timestep": 3034, "ep_reward": 574.4885864257812, "reward": 0.7705860733985901, "action": -0.8807926774024963}
{"mode": "train", "epochs": 2, "timestep": 3035, "ep_reward": 575.3096313476562, "reward": 0.8210576176643372, "action": -0.9218444228172302}
{"mode": "train", "epochs": 2, "timestep": 3036, "ep_reward": 576.1616821289062, "reward": 0.8520213961601257, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3037, "ep_reward": 577.0187377929688, "reward": 0.8570631146430969, "action": -0.8669369220733643}
{"mode": "train", "epochs": 2, "timestep": 3038, "ep_reward": 577.873291015625, "reward": 0.8545563220977783, "action": -0.8134788274765015}
{"mode": "train", "epochs": 2, "timestep": 3039, "ep_reward": 578.7069702148438, "reward": 0.8336857557296753, "action": -1.023261547088623}
{"mode": "train", "epochs": 2, "timestep": 3040, "ep_reward": 579.495361328125, "reward": 0.7883678674697876, "action": -1.517890453338623}
{"mode": "train", "epochs": 2, "timestep": 3041, "ep_reward": 580.2042236328125, "reward": 0.7088572978973389, "action": -0.015326499938964844}
{"mode": "train", "epochs": 2, "timestep": 3042, "ep_reward": 580.8165283203125, "reward": 0.6123009324073792, "action": -1.236107587814331}
{"mode": "train", "epochs": 2, "timestep": 3043, "ep_reward": 581.2766723632812, "reward": 0.46014344692230225, "action": -1.4628779888153076}
{"mode": "train", "epochs": 2, "timestep": 3044, "ep_reward": 581.6085815429688, "reward": 0.3319140076637268, "action": -1.3688015937805176}
{"mode": "train", "epochs": 2, "timestep": 3045, "ep_reward": 581.8270874023438, "reward": 0.21849662065505981, "action": -0.2813456654548645}
{"mode": "train", "epochs": 2, "timestep": 3046, "ep_reward": 581.9119873046875, "reward": 0.08492892980575562, "action": -0.8358175754547119}
{"mode": "train", "epochs": 2, "timestep": 3047, "ep_reward": 581.9447021484375, "reward": 0.032740890979766846, "action": -0.7315101027488708}
{"mode": "train", "epochs": 2, "timestep": 3048, "ep_reward": 582.1181030273438, "reward": 0.17338109016418457, "action": -0.5659388303756714}
{"mode": "train", "epochs": 2, "timestep": 3049, "ep_reward": 582.436767578125, "reward": 0.3186919689178467, "action": -1.1832115650177002}
{"mode": "train", "epochs": 2, "timestep": 3050, "ep_reward": 582.8877563476562, "reward": 0.45097434520721436, "action": -0.6246494054794312}
{"mode": "train", "epochs": 2, "timestep": 3051, "ep_reward": 583.4636840820312, "reward": 0.5759141445159912, "action": -1.8503820896148682}
{"mode": "train", "epochs": 2, "timestep": 3052, "ep_reward": 584.1309204101562, "reward": 0.6672513484954834, "action": -0.30044013261795044}
{"mode": "train", "epochs": 2, "timestep": 3053, "ep_reward": 584.8839111328125, "reward": 0.752974271774292, "action": -0.390997052192688}
{"mode": "train", "epochs": 2, "timestep": 3054, "ep_reward": 585.6982421875, "reward": 0.8143044710159302, "action": -1.9774055480957031}
{"mode": "train", "epochs": 2, "timestep": 3055, "ep_reward": 586.5411987304688, "reward": 0.8429616093635559, "action": -0.37184083461761475}
{"mode": "train", "epochs": 2, "timestep": 3056, "ep_reward": 587.4097290039062, "reward": 0.8685082197189331, "action": -0.6078078746795654}
{"mode": "train", "epochs": 2, "timestep": 3057, "ep_reward": 588.2858276367188, "reward": 0.8761001229286194, "action": -0.6115504503250122}
{"mode": "train", "epochs": 2, "timestep": 3058, "ep_reward": 589.1538696289062, "reward": 0.8680182099342346, "action": -0.939758837223053}
{"mode": "train", "epochs": 2, "timestep": 3059, "ep_reward": 589.9935302734375, "reward": 0.8396768569946289, "action": -0.4782664179801941}
{"mode": "train", "epochs": 2, "timestep": 3060, "ep_reward": 590.7877807617188, "reward": 0.7942257523536682, "action": -1.4924471378326416}
{"mode": "train", "epochs": 2, "timestep": 3061, "ep_reward": 591.4985961914062, "reward": 0.7108340263366699, "action": -0.880730926990509}
{"mode": "train", "epochs": 2, "timestep": 3062, "ep_reward": 592.0974731445312, "reward": 0.5988682508468628, "action": -0.8922202587127686}
{"mode": "train", "epochs": 2, "timestep": 3063, "ep_reward": 592.5442504882812, "reward": 0.4467995762825012, "action": -1.6604440212249756}
{"mode": "train", "epochs": 2, "timestep": 3064, "ep_reward": 592.8566284179688, "reward": 0.31240254640579224, "action": -1.279703140258789}
{"mode": "train", "epochs": 2, "timestep": 3065, "ep_reward": 593.0518798828125, "reward": 0.1952396035194397, "action": -0.6937255859375}
{"mode": "train", "epochs": 2, "timestep": 3066, "ep_reward": 593.1096801757812, "reward": 0.05778515338897705, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3067, "ep_reward": 593.169921875, "reward": 0.06026571989059448, "action": -1.093178153038025}
{"mode": "train", "epochs": 2, "timestep": 3068, "ep_reward": 593.3671264648438, "reward": 0.19723248481750488, "action": -0.6816290616989136}
{"mode": "train", "epochs": 2, "timestep": 3069, "ep_reward": 593.7084350585938, "reward": 0.34133195877075195, "action": -1.720452070236206}
{"mode": "train", "epochs": 2, "timestep": 3070, "ep_reward": 594.1744995117188, "reward": 0.46603530645370483, "action": -0.07484209537506104}
{"mode": "train", "epochs": 2, "timestep": 3071, "ep_reward": 594.7698974609375, "reward": 0.5953741073608398, "action": -1.6575908660888672}
{"mode": "train", "epochs": 2, "timestep": 3072, "ep_reward": 595.4544677734375, "reward": 0.6845898628234863, "action": -1.2516107559204102}
{"mode": "train", "epochs": 2, "timestep": 3073, "ep_reward": 596.2110595703125, "reward": 0.75657719373703, "action": -0.22310543060302734}
{"mode": "train", "epochs": 2, "timestep": 3074, "ep_reward": 597.02734375, "reward": 0.8162611722946167, "action": -0.9400407671928406}
{"mode": "train", "epochs": 2, "timestep": 3075, "ep_reward": 597.8767700195312, "reward": 0.8494162559509277, "action": -0.9315323829650879}
{"mode": "train", "epochs": 2, "timestep": 3076, "ep_reward": 598.7420654296875, "reward": 0.8653230667114258, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3077, "ep_reward": 599.5975952148438, "reward": 0.8555209636688232, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3078, "ep_reward": 600.4237670898438, "reward": 0.8261790871620178, "action": -0.9092820286750793}
{"mode": "train", "epochs": 2, "timestep": 3079, "ep_reward": 601.2071533203125, "reward": 0.7833855152130127, "action": -1.3866722583770752}
{"mode": "train", "epochs": 2, "timestep": 3080, "ep_reward": 601.9132690429688, "reward": 0.7061371803283691, "action": -1.2098608016967773}
{"mode": "train", "epochs": 2, "timestep": 3081, "ep_reward": 602.5068359375, "reward": 0.5935767889022827, "action": -1.064117193222046}
{"mode": "train", "epochs": 2, "timestep": 3082, "ep_reward": 602.9467163085938, "reward": 0.43985843658447266, "action": -0.40917372703552246}
{"mode": "train", "epochs": 2, "timestep": 3083, "ep_reward": 603.2783813476562, "reward": 0.3316400647163391, "action": -1.4805636405944824}
{"mode": "train", "epochs": 2, "timestep": 3084, "ep_reward": 603.4964599609375, "reward": 0.21805810928344727, "action": -1.4984400272369385}
{"mode": "train", "epochs": 2, "timestep": 3085, "ep_reward": 603.5810546875, "reward": 0.08457380533218384, "action": -0.8640474081039429}
{"mode": "train", "epochs": 2, "timestep": 3086, "ep_reward": 603.6140747070312, "reward": 0.03303349018096924, "action": -1.329047679901123}
{"mode": "train", "epochs": 2, "timestep": 3087, "ep_reward": 603.7877807617188, "reward": 0.17370373010635376, "action": -0.5335831642150879}
{"mode": "train", "epochs": 2, "timestep": 3088, "ep_reward": 604.1072387695312, "reward": 0.31948673725128174, "action": -0.5370499491691589}
{"mode": "train", "epochs": 2, "timestep": 3089, "ep_reward": 604.5665283203125, "reward": 0.4592617154121399, "action": -0.18345683813095093}
{"mode": "train", "epochs": 2, "timestep": 3090, "ep_reward": 605.1539916992188, "reward": 0.587436318397522, "action": -0.8809967041015625}
{"mode": "train", "epochs": 2, "timestep": 3091, "ep_reward": 605.8404541015625, "reward": 0.6864330172538757, "action": -1.2527467012405396}
{"mode": "train", "epochs": 2, "timestep": 3092, "ep_reward": 606.6009521484375, "reward": 0.7605082988739014, "action": -1.2056728601455688}
{"mode": "train", "epochs": 2, "timestep": 3093, "ep_reward": 607.4161987304688, "reward": 0.8152691125869751, "action": -0.9754297137260437}
{"mode": "train", "epochs": 2, "timestep": 3094, "ep_reward": 608.2701416015625, "reward": 0.8539712429046631, "action": -1.5476588010787964}
{"mode": "train", "epochs": 2, "timestep": 3095, "ep_reward": 609.142578125, "reward": 0.8724134564399719, "action": -1.1400871276855469}
{"mode": "train", "epochs": 2, "timestep": 3096, "ep_reward": 610.0220947265625, "reward": 0.8794884085655212, "action": -0.9282779693603516}
{"mode": "train", "epochs": 2, "timestep": 3097, "ep_reward": 610.8952026367188, "reward": 0.8731006383895874, "action": -1.8642332553863525}
{"mode": "train", "epochs": 2, "timestep": 3098, "ep_reward": 611.73681640625, "reward": 0.8416211009025574, "action": 0.1160203218460083}
{"mode": "train", "epochs": 2, "timestep": 3099, "ep_reward": 612.5440063476562, "reward": 0.8071928024291992, "action": -1.5814682245254517}
{"mode": "train", "epochs": 2, "timestep": 3100, "ep_reward": 613.2741088867188, "reward": 0.7301328778266907, "action": -0.7628998160362244}
{"mode": "train", "epochs": 2, "timestep": 3101, "ep_reward": 613.9022216796875, "reward": 0.6281332969665527, "action": -1.10995352268219}
{"mode": "train", "epochs": 2, "timestep": 3102, "ep_reward": 614.3846435546875, "reward": 0.4824219346046448, "action": -0.6179688572883606}
{"mode": "train", "epochs": 2, "timestep": 3103, "ep_reward": 614.721435546875, "reward": 0.3368041515350342, "action": -1.7436503171920776}
{"mode": "train", "epochs": 2, "timestep": 3104, "ep_reward": 614.94580078125, "reward": 0.22436529397964478, "action": -1.0002518892288208}
{"mode": "train", "epochs": 2, "timestep": 3105, "ep_reward": 615.03759765625, "reward": 0.09179508686065674, "action": -1.036419153213501}
{"mode": "train", "epochs": 2, "timestep": 3106, "ep_reward": 615.0630493164062, "reward": 0.025480329990386963, "action": -0.5097819566726685}
{"mode": "train", "epochs": 2, "timestep": 3107, "ep_reward": 615.2305908203125, "reward": 0.16753900051116943, "action": -0.6519581079483032}
{"mode": "train", "epochs": 2, "timestep": 3108, "ep_reward": 615.542236328125, "reward": 0.31165117025375366, "action": -0.6318851709365845}
{"mode": "train", "epochs": 2, "timestep": 3109, "ep_reward": 615.9931640625, "reward": 0.45091497898101807, "action": -0.7400731444358826}
{"mode": "train", "epochs": 2, "timestep": 3110, "ep_reward": 616.5675659179688, "reward": 0.5744054317474365, "action": 0.08992266654968262}
{"mode": "train", "epochs": 2, "timestep": 3111, "ep_reward": 617.2531127929688, "reward": 0.6855534911155701, "action": -1.0495264530181885}
{"mode": "train", "epochs": 2, "timestep": 3112, "ep_reward": 618.0150146484375, "reward": 0.7618935108184814, "action": -0.3542160987854004}
{"mode": "train", "epochs": 2, "timestep": 3113, "ep_reward": 618.8389282226562, "reward": 0.823905348777771, "action": -0.7475489377975464}
{"mode": "train", "epochs": 2, "timestep": 3114, "ep_reward": 619.7031860351562, "reward": 0.8642752170562744, "action": -0.8819676041603088}
{"mode": "train", "epochs": 2, "timestep": 3115, "ep_reward": 620.5919799804688, "reward": 0.8887958526611328, "action": -0.1483181118965149}
{"mode": "train", "epochs": 2, "timestep": 3116, "ep_reward": 621.49755859375, "reward": 0.9055482149124146, "action": -1.5858681201934814}
{"mode": "train", "epochs": 2, "timestep": 3117, "ep_reward": 622.3977661132812, "reward": 0.9002364873886108, "action": -1.209015130996704}
{"mode": "train", "epochs": 2, "timestep": 3118, "ep_reward": 623.2823486328125, "reward": 0.8845567107200623, "action": -0.3992331624031067}
{"mode": "train", "epochs": 2, "timestep": 3119, "ep_reward": 624.1422729492188, "reward": 0.8599096536636353, "action": -0.7628579139709473}
{"mode": "train", "epochs": 2, "timestep": 3120, "ep_reward": 624.95556640625, "reward": 0.8133098483085632, "action": -1.376426339149475}
{"mode": "train", "epochs": 2, "timestep": 3121, "ep_reward": 625.6907348632812, "reward": 0.7351812124252319, "action": -1.3194319009780884}
{"mode": "train", "epochs": 2, "timestep": 3122, "ep_reward": 626.314453125, "reward": 0.6237058639526367, "action": -1.158212423324585}
{"mode": "train", "epochs": 2, "timestep": 3123, "ep_reward": 626.7890625, "reward": 0.4745887517929077, "action": -0.404962420463562}
{"mode": "train", "epochs": 2, "timestep": 3124, "ep_reward": 627.1094360351562, "reward": 0.3203582763671875, "action": -1.3312971591949463}
{"mode": "train", "epochs": 2, "timestep": 3125, "ep_reward": 627.3140258789062, "reward": 0.2046002745628357, "action": -1.4384956359863281}
{"mode": "train", "epochs": 2, "timestep": 3126, "ep_reward": 627.3828125, "reward": 0.06876754760742188, "action": -1.8901340961456299}
{"mode": "train", "epochs": 2, "timestep": 3127, "ep_reward": 627.4320678710938, "reward": 0.049244821071624756, "action": -0.9082539081573486}
{"mode": "train", "epochs": 2, "timestep": 3128, "ep_reward": 627.6196899414062, "reward": 0.18764352798461914, "action": -1.0559066534042358}
{"mode": "train", "epochs": 2, "timestep": 3129, "ep_reward": 627.94677734375, "reward": 0.3270866870880127, "action": -1.3837507963180542}
{"mode": "train", "epochs": 2, "timestep": 3130, "ep_reward": 628.404052734375, "reward": 0.45725464820861816, "action": -0.8479371070861816}
{"mode": "train", "epochs": 2, "timestep": 3131, "ep_reward": 628.9833984375, "reward": 0.5793216228485107, "action": -1.851794719696045}
{"mode": "train", "epochs": 2, "timestep": 3132, "ep_reward": 629.6527709960938, "reward": 0.6693844795227051, "action": -0.9214184880256653}
{"mode": "train", "epochs": 2, "timestep": 3133, "ep_reward": 630.39990234375, "reward": 0.7471475601196289, "action": -0.668765664100647}
{"mode": "train", "epochs": 2, "timestep": 3134, "ep_reward": 631.2041625976562, "reward": 0.8042497634887695, "action": -0.52312171459198}
{"mode": "train", "epochs": 2, "timestep": 3135, "ep_reward": 632.0457153320312, "reward": 0.8415738344192505, "action": -1.5641546249389648}
{"mode": "train", "epochs": 2, "timestep": 3136, "ep_reward": 632.8971557617188, "reward": 0.8514400124549866, "action": -0.3883361220359802}
{"mode": "train", "epochs": 2, "timestep": 3137, "ep_reward": 633.7508544921875, "reward": 0.8536868095397949, "action": -1.4253296852111816}
{"mode": "train", "epochs": 2, "timestep": 3138, "ep_reward": 634.5782470703125, "reward": 0.827392041683197, "action": -0.48864907026290894}
{"mode": "train", "epochs": 2, "timestep": 3139, "ep_reward": 635.3654174804688, "reward": 0.7871527075767517, "action": -0.9832055568695068}
{"mode": "train", "epochs": 2, "timestep": 3140, "ep_reward": 636.0792846679688, "reward": 0.7138409614562988, "action": -1.2174009084701538}
{"mode": "train", "epochs": 2, "timestep": 3141, "ep_reward": 636.6812744140625, "reward": 0.6019693613052368, "action": -1.028168797492981}
{"mode": "train", "epochs": 2, "timestep": 3142, "ep_reward": 637.1317138671875, "reward": 0.4504568576812744, "action": -1.230604887008667}
{"mode": "train", "epochs": 2, "timestep": 3143, "ep_reward": 637.4620361328125, "reward": 0.3303505778312683, "action": -0.4414018988609314}
{"mode": "train", "epochs": 2, "timestep": 3144, "ep_reward": 637.6785278320312, "reward": 0.21651095151901245, "action": 0.08978497982025146}
{"mode": "train", "epochs": 2, "timestep": 3145, "ep_reward": 637.7611694335938, "reward": 0.08261346817016602, "action": -0.8692218661308289}
{"mode": "train", "epochs": 2, "timestep": 3146, "ep_reward": 637.7963256835938, "reward": 0.03516179323196411, "action": -0.7325774431228638}
{"mode": "train", "epochs": 2, "timestep": 3147, "ep_reward": 637.9716796875, "reward": 0.17538315057754517, "action": -1.3688734769821167}
{"mode": "train", "epochs": 2, "timestep": 3148, "ep_reward": 638.282470703125, "reward": 0.3108189105987549, "action": -1.131221055984497}
{"mode": "train", "epochs": 2, "timestep": 3149, "ep_reward": 638.7279663085938, "reward": 0.4454990029335022, "action": -1.2248737812042236}
{"mode": "train", "epochs": 2, "timestep": 3150, "ep_reward": 639.2931518554688, "reward": 0.5651867389678955, "action": -0.8109376430511475}
{"mode": "train", "epochs": 2, "timestep": 3151, "ep_reward": 639.9619140625, "reward": 0.668791651725769, "action": -1.2768754959106445}
{"mode": "train", "epochs": 2, "timestep": 3152, "ep_reward": 640.7059936523438, "reward": 0.7440782189369202, "action": -0.7088854312896729}
{"mode": "train", "epochs": 2, "timestep": 3153, "ep_reward": 641.508544921875, "reward": 0.8025551438331604, "action": -0.7189292907714844}
{"mode": "train", "epochs": 2, "timestep": 3154, "ep_reward": 642.3486938476562, "reward": 0.8401469588279724, "action": -0.8279993534088135}
{"mode": "train", "epochs": 2, "timestep": 3155, "ep_reward": 643.2070922851562, "reward": 0.8584024310112, "action": -1.2402629852294922}
{"mode": "train", "epochs": 2, "timestep": 3156, "ep_reward": 644.0629272460938, "reward": 0.8558341264724731, "action": -0.7217231392860413}
{"mode": "train", "epochs": 2, "timestep": 3157, "ep_reward": 644.9022216796875, "reward": 0.83931565284729, "action": -1.3324558734893799}
{"mode": "train", "epochs": 2, "timestep": 3158, "ep_reward": 645.6975708007812, "reward": 0.7953301668167114, "action": -0.1558459997177124}
{"mode": "train", "epochs": 2, "timestep": 3159, "ep_reward": 646.4344482421875, "reward": 0.7369056344032288, "action": -0.6820981502532959}
{"mode": "train", "epochs": 2, "timestep": 3160, "ep_reward": 647.0753784179688, "reward": 0.6409470438957214, "action": -1.1202906370162964}
{"mode": "train", "epochs": 2, "timestep": 3161, "ep_reward": 647.57568359375, "reward": 0.5002835392951965, "action": -1.107162594795227}
{"mode": "train", "epochs": 2, "timestep": 3162, "ep_reward": 647.9292602539062, "reward": 0.3535797595977783, "action": -0.872195839881897}
{"mode": "train", "epochs": 2, "timestep": 3163, "ep_reward": 648.1734619140625, "reward": 0.24422043561935425, "action": -1.4794161319732666}
{"mode": "train", "epochs": 2, "timestep": 3164, "ep_reward": 648.2885131835938, "reward": 0.11506211757659912, "action": -0.641480565071106}
{"mode": "train", "epochs": 2, "timestep": 3165, "ep_reward": 648.2887573242188, "reward": 0.00024020671844482422, "action": -0.045171916484832764}
{"mode": "train", "epochs": 2, "timestep": 3166, "ep_reward": 648.43603515625, "reward": 0.1472790241241455, "action": -0.40981173515319824}
{"mode": "train", "epochs": 2, "timestep": 3167, "ep_reward": 648.7296142578125, "reward": 0.29356616735458374, "action": -0.5935019254684448}
{"mode": "train", "epochs": 2, "timestep": 3168, "ep_reward": 649.1630859375, "reward": 0.43348121643066406, "action": -1.165840983390808}
{"mode": "train", "epochs": 2, "timestep": 3169, "ep_reward": 649.7171630859375, "reward": 0.5540744066238403, "action": -0.7811968326568604}
{"mode": "train", "epochs": 2, "timestep": 3170, "ep_reward": 650.3776245117188, "reward": 0.6604505777359009, "action": -0.8086086511611938}
{"mode": "train", "epochs": 2, "timestep": 3171, "ep_reward": 651.1220092773438, "reward": 0.7443631291389465, "action": -1.1101995706558228}
{"mode": "train", "epochs": 2, "timestep": 3172, "ep_reward": 651.9263305664062, "reward": 0.8043137192726135, "action": -0.8869380950927734}
{"mode": "train", "epochs": 2, "timestep": 3173, "ep_reward": 652.7737426757812, "reward": 0.8474174737930298, "action": -1.4136714935302734}
{"mode": "train", "epochs": 2, "timestep": 3174, "ep_reward": 653.643798828125, "reward": 0.8700394034385681, "action": -1.0155771970748901}
{"mode": "train", "epochs": 2, "timestep": 3175, "ep_reward": 654.52490234375, "reward": 0.881109893321991, "action": -1.0596036911010742}
{"mode": "train", "epochs": 2, "timestep": 3176, "ep_reward": 655.4019165039062, "reward": 0.8770127892494202, "action": -1.9401394128799438}
{"mode": "train", "epochs": 2, "timestep": 3177, "ep_reward": 656.2507934570312, "reward": 0.8488577604293823, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3178, "ep_reward": 657.0486450195312, "reward": 0.797825038433075, "action": -1.3821717500686646}
{"mode": "train", "epochs": 2, "timestep": 3179, "ep_reward": 657.7727661132812, "reward": 0.7241003513336182, "action": -0.848659873008728}
{"mode": "train", "epochs": 2, "timestep": 3180, "ep_reward": 658.3944702148438, "reward": 0.6217175722122192, "action": -0.0447002649307251}
{"mode": "train", "epochs": 2, "timestep": 3181, "ep_reward": 658.8861694335938, "reward": 0.4916688799858093, "action": -1.5558679103851318}
{"mode": "train", "epochs": 2, "timestep": 3182, "ep_reward": 659.2313842773438, "reward": 0.345187783241272, "action": -0.20472079515457153}
{"mode": "train", "epochs": 2, "timestep": 3183, "ep_reward": 659.4654541015625, "reward": 0.23404240608215332, "action": -1.7551349401474}
{"mode": "train", "epochs": 2, "timestep": 3184, "ep_reward": 659.5686645507812, "reward": 0.10319751501083374, "action": -1.1494364738464355}
{"mode": "train", "epochs": 2, "timestep": 3185, "ep_reward": 659.5818481445312, "reward": 0.013176441192626953, "action": -0.8549439311027527}
{"mode": "train", "epochs": 2, "timestep": 3186, "ep_reward": 659.7382202148438, "reward": 0.15634536743164062, "action": -1.114305853843689}
{"mode": "train", "epochs": 2, "timestep": 3187, "ep_reward": 660.0327758789062, "reward": 0.29454976320266724, "action": -1.3570683002471924}
{"mode": "train", "epochs": 2, "timestep": 3188, "ep_reward": 660.459716796875, "reward": 0.42694753408432007, "action": -1.578792929649353}
{"mode": "train", "epochs": 2, "timestep": 3189, "ep_reward": 661.004638671875, "reward": 0.5448986887931824, "action": -1.5673999786376953}
{"mode": "train", "epochs": 2, "timestep": 3190, "ep_reward": 661.6490478515625, "reward": 0.6444132328033447, "action": -0.9417532086372375}
{"mode": "train", "epochs": 2, "timestep": 3191, "ep_reward": 662.3770141601562, "reward": 0.7279637455940247, "action": -0.6540200710296631}
{"mode": "train", "epochs": 2, "timestep": 3192, "ep_reward": 663.16748046875, "reward": 0.7904378771781921, "action": -1.1260387897491455}
{"mode": "train", "epochs": 2, "timestep": 3193, "ep_reward": 663.9942626953125, "reward": 0.8268089294433594, "action": 0.12456512451171875}
{"mode": "train", "epochs": 2, "timestep": 3194, "ep_reward": 664.8491821289062, "reward": 0.854904294013977, "action": -1.0993353128433228}
{"mode": "train", "epochs": 2, "timestep": 3195, "ep_reward": 665.703125, "reward": 0.8539330363273621, "action": -1.4939720630645752}
{"mode": "train", "epochs": 2, "timestep": 3196, "ep_reward": 666.5333862304688, "reward": 0.8302718997001648, "action": -1.3101047277450562}
{"mode": "train", "epochs": 2, "timestep": 3197, "ep_reward": 667.3184204101562, "reward": 0.7850491404533386, "action": 0.05075109004974365}
{"mode": "train", "epochs": 2, "timestep": 3198, "ep_reward": 668.045166015625, "reward": 0.726742148399353, "action": -0.9736491441726685}
{"mode": "train", "epochs": 2, "timestep": 3199, "ep_reward": 668.6689453125, "reward": 0.6237909197807312, "action": -0.6032150983810425}
{"mode": "train", "epochs": 2, "timestep": 3200, "ep_reward": 669.1549682617188, "reward": 0.4860435724258423, "action": -0.9063606262207031}
{"mode": "train", "epochs": 2, "timestep": 3201, "ep_reward": 669.5016479492188, "reward": 0.34670817852020264, "action": -0.505211353302002}
{"mode": "train", "epochs": 2, "timestep": 3202, "ep_reward": 669.7376708984375, "reward": 0.23604917526245117, "action": -0.6164308786392212}
{"mode": "train", "epochs": 2, "timestep": 3203, "ep_reward": 669.843017578125, "reward": 0.10536110401153564, "action": -0.9899775385856628}
{"mode": "train", "epochs": 2, "timestep": 3204, "ep_reward": 669.8538208007812, "reward": 0.010828197002410889, "action": -0.9849565625190735}
{"mode": "train", "epochs": 2, "timestep": 3205, "ep_reward": 670.0081787109375, "reward": 0.1543462872505188, "action": -0.8732261061668396}
{"mode": "train", "epochs": 2, "timestep": 3206, "ep_reward": 670.3036499023438, "reward": 0.29544419050216675, "action": -1.6467217206954956}
{"mode": "train", "epochs": 2, "timestep": 3207, "ep_reward": 670.7276000976562, "reward": 0.4239741563796997, "action": -1.0674456357955933}
{"mode": "train", "epochs": 2, "timestep": 3208, "ep_reward": 671.2758178710938, "reward": 0.5482457876205444, "action": -1.1358832120895386}
{"mode": "train", "epochs": 2, "timestep": 3209, "ep_reward": 671.9277954101562, "reward": 0.6519473791122437, "action": -0.3155960440635681}
{"mode": "train", "epochs": 2, "timestep": 3210, "ep_reward": 672.6686401367188, "reward": 0.7408688068389893, "action": -0.19837737083435059}
{"mode": "train", "epochs": 2, "timestep": 3211, "ep_reward": 673.475341796875, "reward": 0.8067117929458618, "action": -0.7741416096687317}
{"mode": "train", "epochs": 2, "timestep": 3212, "ep_reward": 674.3221435546875, "reward": 0.8467985987663269, "action": -0.2889282703399658}
{"mode": "train", "epochs": 2, "timestep": 3213, "ep_reward": 675.19580078125, "reward": 0.8736319541931152, "action": -0.5860048532485962}
{"mode": "train", "epochs": 2, "timestep": 3214, "ep_reward": 676.0784301757812, "reward": 0.8826389312744141, "action": -1.0094778537750244}
{"mode": "train", "epochs": 2, "timestep": 3215, "ep_reward": 676.9518432617188, "reward": 0.873422384262085, "action": -0.6758612394332886}
{"mode": "train", "epochs": 2, "timestep": 3216, "ep_reward": 677.8021240234375, "reward": 0.8502960801124573, "action": -1.2269606590270996}
{"mode": "train", "epochs": 2, "timestep": 3217, "ep_reward": 678.603759765625, "reward": 0.8016106486320496, "action": -1.3358666896820068}
{"mode": "train", "epochs": 2, "timestep": 3218, "ep_reward": 679.328125, "reward": 0.7243461608886719, "action": -0.7652379870414734}
{"mode": "train", "epochs": 2, "timestep": 3219, "ep_reward": 679.9476318359375, "reward": 0.6194889545440674, "action": -0.4457682967185974}
{"mode": "train", "epochs": 2, "timestep": 3220, "ep_reward": 680.428466796875, "reward": 0.4808542728424072, "action": -1.3684955835342407}
{"mode": "train", "epochs": 2, "timestep": 3221, "ep_reward": 680.7578735351562, "reward": 0.3293834328651428, "action": -0.634819746017456}
{"mode": "train", "epochs": 2, "timestep": 3222, "ep_reward": 680.97314453125, "reward": 0.21527165174484253, "action": -1.2783244848251343}
{"mode": "train", "epochs": 2, "timestep": 3223, "ep_reward": 681.054443359375, "reward": 0.08129274845123291, "action": -0.8649110794067383}
{"mode": "train", "epochs": 2, "timestep": 3224, "ep_reward": 681.0908813476562, "reward": 0.03641170263290405, "action": -1.6121177673339844}
{"mode": "train", "epochs": 2, "timestep": 3225, "ep_reward": 681.267578125, "reward": 0.17668670415878296, "action": -0.3772950768470764}
{"mode": "train", "epochs": 2, "timestep": 3226, "ep_reward": 681.592041015625, "reward": 0.32444119453430176, "action": -0.4096890687942505}
{"mode": "train", "epochs": 2, "timestep": 3227, "ep_reward": 682.0569458007812, "reward": 0.4648827910423279, "action": -1.8333144187927246}
{"mode": "train", "epochs": 2, "timestep": 3228, "ep_reward": 682.6311645507812, "reward": 0.5742321014404297, "action": -1.012650966644287}
{"mode": "train", "epochs": 2, "timestep": 3229, "ep_reward": 683.3053588867188, "reward": 0.6742223501205444, "action": -1.7623521089553833}
{"mode": "train", "epochs": 2, "timestep": 3230, "ep_reward": 684.0501708984375, "reward": 0.7447978258132935, "action": -1.749995231628418}
{"mode": "train", "epochs": 2, "timestep": 3231, "ep_reward": 684.845458984375, "reward": 0.7953010201454163, "action": -0.23795533180236816}
{"mode": "train", "epochs": 2, "timestep": 3232, "ep_reward": 685.6849975585938, "reward": 0.8395549058914185, "action": -1.570544719696045}
{"mode": "train", "epochs": 2, "timestep": 3233, "ep_reward": 686.5384521484375, "reward": 0.8534753322601318, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3234, "ep_reward": 687.3845825195312, "reward": 0.8461321592330933, "action": -0.8164352178573608}
{"mode": "train", "epochs": 2, "timestep": 3235, "ep_reward": 688.2142944335938, "reward": 0.829719066619873, "action": -1.3341796398162842}
{"mode": "train", "epochs": 2, "timestep": 3236, "ep_reward": 688.9996337890625, "reward": 0.7853503823280334, "action": -0.28533345460891724}
{"mode": "train", "epochs": 2, "timestep": 3237, "ep_reward": 689.7236938476562, "reward": 0.7240567803382874, "action": -1.3649474382400513}
{"mode": "train", "epochs": 2, "timestep": 3238, "ep_reward": 690.3394775390625, "reward": 0.6157853603363037, "action": -1.1061012744903564}
{"mode": "train", "epochs": 2, "timestep": 3239, "ep_reward": 690.8079223632812, "reward": 0.46843421459198, "action": -1.172754168510437}
{"mode": "train", "epochs": 2, "timestep": 3240, "ep_reward": 691.1539916992188, "reward": 0.3460543155670166, "action": 0.0485762357711792}
{"mode": "train", "epochs": 2, "timestep": 3241, "ep_reward": 691.3890380859375, "reward": 0.23507505655288696, "action": -1.766946792602539}
{"mode": "train", "epochs": 2, "timestep": 3242, "ep_reward": 691.4934692382812, "reward": 0.10440528392791748, "action": -1.1410062313079834}
{"mode": "train", "epochs": 2, "timestep": 3243, "ep_reward": 691.5053100585938, "reward": 0.011840343475341797, "action": -1.0491657257080078}
{"mode": "train", "epochs": 2, "timestep": 3244, "ep_reward": 691.6605834960938, "reward": 0.1552765965461731, "action": -0.27492696046829224}
{"mode": "train", "epochs": 2, "timestep": 3245, "ep_reward": 691.9644775390625, "reward": 0.3038642406463623, "action": -0.998637855052948}
{"mode": "train", "epochs": 2, "timestep": 3246, "ep_reward": 692.4031372070312, "reward": 0.4386354684829712, "action": -0.6017342805862427}
{"mode": "train", "epochs": 2, "timestep": 3247, "ep_reward": 692.9683227539062, "reward": 0.5652072429656982, "action": -0.678617537021637}
{"mode": "train", "epochs": 2, "timestep": 3248, "ep_reward": 693.6388549804688, "reward": 0.670547604560852, "action": -0.6648486852645874}
{"mode": "train", "epochs": 2, "timestep": 3249, "ep_reward": 694.3923950195312, "reward": 0.7535663843154907, "action": -0.12455219030380249}
{"mode": "train", "epochs": 2, "timestep": 3250, "ep_reward": 695.2119750976562, "reward": 0.8195878863334656, "action": -0.7856806516647339}
{"mode": "train", "epochs": 2, "timestep": 3251, "ep_reward": 696.0729370117188, "reward": 0.8609690070152283, "action": -1.567030668258667}
{"mode": "train", "epochs": 2, "timestep": 3252, "ep_reward": 696.9545288085938, "reward": 0.8815950155258179, "action": -1.0345503091812134}
{"mode": "train", "epochs": 2, "timestep": 3253, "ep_reward": 697.8475341796875, "reward": 0.8930137157440186, "action": -1.0795780420303345}
{"mode": "train", "epochs": 2, "timestep": 3254, "ep_reward": 698.7385864257812, "reward": 0.8910739421844482, "action": -0.6004000902175903}
{"mode": "train", "epochs": 2, "timestep": 3255, "ep_reward": 699.617431640625, "reward": 0.8788391947746277, "action": -1.0226033926010132}
{"mode": "train", "epochs": 2, "timestep": 3256, "ep_reward": 700.4642333984375, "reward": 0.8468025326728821, "action": -0.7808665633201599}
{"mode": "train", "epochs": 2, "timestep": 3257, "ep_reward": 701.26025390625, "reward": 0.7960301637649536, "action": -0.06136274337768555}
{"mode": "train", "epochs": 2, "timestep": 3258, "ep_reward": 701.9874267578125, "reward": 0.7271527051925659, "action": -0.2823619842529297}
{"mode": "train", "epochs": 2, "timestep": 3259, "ep_reward": 702.6131591796875, "reward": 0.6257380247116089, "action": -1.2798688411712646}
{"mode": "train", "epochs": 2, "timestep": 3260, "ep_reward": 703.087890625, "reward": 0.474736750125885, "action": -1.2622761726379395}
{"mode": "train", "epochs": 2, "timestep": 3261, "ep_reward": 703.4002685546875, "reward": 0.3123677968978882, "action": -0.6237668991088867}
{"mode": "train", "epochs": 2, "timestep": 3262, "ep_reward": 703.5953979492188, "reward": 0.19513195753097534, "action": -0.2524980306625366}
{"mode": "train", "epochs": 2, "timestep": 3263, "ep_reward": 703.6532592773438, "reward": 0.057878851890563965, "action": 0.15248095989227295}
{"mode": "train", "epochs": 2, "timestep": 3264, "ep_reward": 703.7137451171875, "reward": 0.06049478054046631, "action": 0.04656386375427246}
{"mode": "train", "epochs": 2, "timestep": 3265, "ep_reward": 703.92431640625, "reward": 0.2105695605278015, "action": -0.3594678044319153}
{"mode": "train", "epochs": 2, "timestep": 3266, "ep_reward": 704.2800903320312, "reward": 0.3557509779930115, "action": -1.5461876392364502}
{"mode": "train", "epochs": 2, "timestep": 3267, "ep_reward": 704.7593383789062, "reward": 0.47922569513320923, "action": -1.9197965860366821}
{"mode": "train", "epochs": 2, "timestep": 3268, "ep_reward": 705.3450317382812, "reward": 0.5856809616088867, "action": -1.3844122886657715}
{"mode": "train", "epochs": 2, "timestep": 3269, "ep_reward": 706.0247192382812, "reward": 0.6796581745147705, "action": -0.9295032620429993}
{"mode": "train", "epochs": 2, "timestep": 3270, "ep_reward": 706.7809448242188, "reward": 0.7562302350997925, "action": -0.5609217882156372}
{"mode": "train", "epochs": 2, "timestep": 3271, "ep_reward": 707.5950927734375, "reward": 0.8141177892684937, "action": -0.9803443551063538}
{"mode": "train", "epochs": 2, "timestep": 3272, "ep_reward": 708.4436645507812, "reward": 0.8485816717147827, "action": -1.3573187589645386}
{"mode": "train", "epochs": 2, "timestep": 3273, "ep_reward": 709.3065795898438, "reward": 0.8628944158554077, "action": -1.2897765636444092}
{"mode": "train", "epochs": 2, "timestep": 3274, "ep_reward": 710.1679077148438, "reward": 0.861304759979248, "action": -1.0862427949905396}
{"mode": "train", "epochs": 2, "timestep": 3275, "ep_reward": 711.0113525390625, "reward": 0.8434710502624512, "action": -1.6121455430984497}
{"mode": "train", "epochs": 2, "timestep": 3276, "ep_reward": 711.8104858398438, "reward": 0.7991518974304199, "action": -0.7601956725120544}
{"mode": "train", "epochs": 2, "timestep": 3277, "ep_reward": 712.5467529296875, "reward": 0.7362532615661621, "action": -0.6034380197525024}
{"mode": "train", "epochs": 2, "timestep": 3278, "ep_reward": 713.1895141601562, "reward": 0.6427434682846069, "action": -0.33520060777664185}
{"mode": "train", "epochs": 2, "timestep": 3279, "ep_reward": 713.7047119140625, "reward": 0.5151920914649963, "action": -1.5575939416885376}
{"mode": "train", "epochs": 2, "timestep": 3280, "ep_reward": 714.0653686523438, "reward": 0.36065417528152466, "action": -0.35374754667282104}
{"mode": "train", "epochs": 2, "timestep": 3281, "ep_reward": 714.318115234375, "reward": 0.2527713179588318, "action": -0.8773845434188843}
{"mode": "train", "epochs": 2, "timestep": 3282, "ep_reward": 714.443115234375, "reward": 0.12497711181640625, "action": 0.06735455989837646}
{"mode": "train", "epochs": 2, "timestep": 3283, "ep_reward": 714.43212890625, "reward": -0.01097404956817627, "action": -1.3163479566574097}
{"mode": "train", "epochs": 2, "timestep": 3284, "ep_reward": 714.5673217773438, "reward": 0.13519787788391113, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3285, "ep_reward": 714.8291625976562, "reward": 0.2618287205696106, "action": -1.5857601165771484}
{"mode": "train", "epochs": 2, "timestep": 3286, "ep_reward": 715.223876953125, "reward": 0.39472776651382446, "action": -0.5932199954986572}
{"mode": "train", "epochs": 2, "timestep": 3287, "ep_reward": 715.7529907226562, "reward": 0.5291332006454468, "action": -0.4581325054168701}
{"mode": "train", "epochs": 2, "timestep": 3288, "ep_reward": 716.3964233398438, "reward": 0.6434242725372314, "action": -1.8253874778747559}
{"mode": "train", "epochs": 2, "timestep": 3289, "ep_reward": 717.1157836914062, "reward": 0.7193764448165894, "action": -0.9549270868301392}
{"mode": "train", "epochs": 2, "timestep": 3290, "ep_reward": 717.8977661132812, "reward": 0.7819653153419495, "action": -0.23790347576141357}
{"mode": "train", "epochs": 2, "timestep": 3291, "ep_reward": 718.7269287109375, "reward": 0.8291420936584473, "action": -0.8362858295440674}
{"mode": "train", "epochs": 2, "timestep": 3292, "ep_reward": 719.5779418945312, "reward": 0.8510410189628601, "action": -1.1709725856781006}
{"mode": "train", "epochs": 2, "timestep": 3293, "ep_reward": 720.4299926757812, "reward": 0.8520702123641968, "action": -0.48455846309661865}
{"mode": "train", "epochs": 2, "timestep": 3294, "ep_reward": 721.2705688476562, "reward": 0.8405518531799316, "action": -1.1410552263259888}
{"mode": "train", "epochs": 2, "timestep": 3295, "ep_reward": 722.0722045898438, "reward": 0.801627516746521, "action": -0.9011674523353577}
{"mode": "train", "epochs": 2, "timestep": 3296, "ep_reward": 722.8106689453125, "reward": 0.7384461760520935, "action": -0.9791138768196106}
{"mode": "train", "epochs": 2, "timestep": 3297, "ep_reward": 723.4518432617188, "reward": 0.6411821842193604, "action": -1.0652611255645752}
{"mode": "train", "epochs": 2, "timestep": 3298, "ep_reward": 723.9545288085938, "reward": 0.5026644468307495, "action": -1.3825880289077759}
{"mode": "train", "epochs": 2, "timestep": 3299, "ep_reward": 724.3162231445312, "reward": 0.3616885542869568, "action": -0.6690151691436768}
{"mode": "train", "epochs": 2, "timestep": 3300, "ep_reward": 724.5701293945312, "reward": 0.25393664836883545, "action": -1.5649758577346802}
{"mode": "train", "epochs": 2, "timestep": 3301, "ep_reward": 724.696533203125, "reward": 0.12642109394073486, "action": -0.824100136756897}
{"mode": "train", "epochs": 2, "timestep": 3302, "ep_reward": 724.683837890625, "reward": -0.012712359428405762, "action": -1.593914270401001}
{"mode": "train", "epochs": 2, "timestep": 3303, "ep_reward": 724.817626953125, "reward": 0.13380229473114014, "action": -1.6668338775634766}
{"mode": "train", "epochs": 2, "timestep": 3304, "ep_reward": 725.0822143554688, "reward": 0.264590322971344, "action": -1.4968503713607788}
{"mode": "train", "epochs": 2, "timestep": 3305, "ep_reward": 725.4801025390625, "reward": 0.39788639545440674, "action": 0.04079556465148926}
{"mode": "train", "epochs": 2, "timestep": 3306, "ep_reward": 726.018798828125, "reward": 0.5387035608291626, "action": -1.4681613445281982}
{"mode": "train", "epochs": 2, "timestep": 3307, "ep_reward": 726.659423828125, "reward": 0.6406344175338745, "action": -1.3438223600387573}
{"mode": "train", "epochs": 2, "timestep": 3308, "ep_reward": 727.3817749023438, "reward": 0.7223447561264038, "action": -0.29710853099823}
{"mode": "train", "epochs": 2, "timestep": 3309, "ep_reward": 728.1732788085938, "reward": 0.7915002107620239, "action": -0.4514926075935364}
{"mode": "train", "epochs": 2, "timestep": 3310, "ep_reward": 729.010498046875, "reward": 0.8371976613998413, "action": -0.7959519028663635}
{"mode": "train", "epochs": 2, "timestep": 3311, "ep_reward": 729.8719482421875, "reward": 0.8614228963851929, "action": -0.6033273339271545}
{"mode": "train", "epochs": 2, "timestep": 3312, "ep_reward": 730.7427368164062, "reward": 0.870776355266571, "action": -0.5802919268608093}
{"mode": "train", "epochs": 2, "timestep": 3313, "ep_reward": 731.6068115234375, "reward": 0.8641038537025452, "action": -0.6912778615951538}
{"mode": "train", "epochs": 2, "timestep": 3314, "ep_reward": 732.4454956054688, "reward": 0.8387137651443481, "action": -0.8724967837333679}
{"mode": "train", "epochs": 2, "timestep": 3315, "ep_reward": 733.2354125976562, "reward": 0.7899136543273926, "action": -1.4398713111877441}
{"mode": "train", "epochs": 2, "timestep": 3316, "ep_reward": 733.9420166015625, "reward": 0.7065980434417725, "action": -1.7190760374069214}
{"mode": "train", "epochs": 2, "timestep": 3317, "ep_reward": 734.524169921875, "reward": 0.5821664929389954, "action": -1.031418800354004}
{"mode": "train", "epochs": 2, "timestep": 3318, "ep_reward": 734.9478149414062, "reward": 0.4236183166503906, "action": -1.0877771377563477}
{"mode": "train", "epochs": 2, "timestep": 3319, "ep_reward": 735.2564697265625, "reward": 0.3086257576942444, "action": -1.5412439107894897}
{"mode": "train", "epochs": 2, "timestep": 3320, "ep_reward": 735.447265625, "reward": 0.19076967239379883, "action": -1.101423978805542}
{"mode": "train", "epochs": 2, "timestep": 3321, "ep_reward": 735.4999389648438, "reward": 0.05266737937927246, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3322, "ep_reward": 735.5652465820312, "reward": 0.0653260350227356, "action": -1.2473527193069458}
{"mode": "train", "epochs": 2, "timestep": 3323, "ep_reward": 735.7669067382812, "reward": 0.20164769887924194, "action": -0.2220821976661682}
{"mode": "train", "epochs": 2, "timestep": 3324, "ep_reward": 736.1184692382812, "reward": 0.3515896797180176, "action": -0.36745160818099976}
{"mode": "train", "epochs": 2, "timestep": 3325, "ep_reward": 736.6090087890625, "reward": 0.49051088094711304, "action": -1.0322481393814087}
{"mode": "train", "epochs": 2, "timestep": 3326, "ep_reward": 737.2137451171875, "reward": 0.6047172546386719, "action": -1.7535744905471802}
{"mode": "train", "epochs": 2, "timestep": 3327, "ep_reward": 737.9053344726562, "reward": 0.6915906071662903, "action": -1.1908535957336426}
{"mode": "train", "epochs": 2, "timestep": 3328, "ep_reward": 738.6686401367188, "reward": 0.763333797454834, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3329, "ep_reward": 739.4761352539062, "reward": 0.8074946403503418, "action": -0.9401658773422241}
{"mode": "train", "epochs": 2, "timestep": 3330, "ep_reward": 740.3187255859375, "reward": 0.8425679206848145, "action": -1.0823655128479004}
{"mode": "train", "epochs": 2, "timestep": 3331, "ep_reward": 741.1771850585938, "reward": 0.8584737181663513, "action": -1.784275770187378}
{"mode": "train", "epochs": 2, "timestep": 3332, "ep_reward": 742.0282592773438, "reward": 0.8510703444480896, "action": -1.1294981241226196}
{"mode": "train", "epochs": 2, "timestep": 3333, "ep_reward": 742.8582763671875, "reward": 0.8300279378890991, "action": -1.4082074165344238}
{"mode": "train", "epochs": 2, "timestep": 3334, "ep_reward": 743.64111328125, "reward": 0.78281170129776, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3335, "ep_reward": 744.3394165039062, "reward": 0.6983075141906738, "action": -1.476420283317566}
{"mode": "train", "epochs": 2, "timestep": 3336, "ep_reward": 744.9196166992188, "reward": 0.5801950693130493, "action": -1.2536258697509766}
{"mode": "train", "epochs": 2, "timestep": 3337, "ep_reward": 745.342041015625, "reward": 0.4224129319190979, "action": -1.7010273933410645}
{"mode": "train", "epochs": 2, "timestep": 3338, "ep_reward": 745.6703491210938, "reward": 0.32829564809799194, "action": -0.983702540397644}
{"mode": "train", "epochs": 2, "timestep": 3339, "ep_reward": 745.8843994140625, "reward": 0.21403753757476807, "action": -1.1422991752624512}
{"mode": "train", "epochs": 2, "timestep": 3340, "ep_reward": 745.9642944335938, "reward": 0.07987058162689209, "action": -0.44155699014663696}
{"mode": "train", "epochs": 2, "timestep": 3341, "ep_reward": 746.0023193359375, "reward": 0.03803420066833496, "action": -0.9479188919067383}
{"mode": "train", "epochs": 2, "timestep": 3342, "ep_reward": 746.1802978515625, "reward": 0.17798781394958496, "action": -0.5907690525054932}
{"mode": "train", "epochs": 2, "timestep": 3343, "ep_reward": 746.50341796875, "reward": 0.32310473918914795, "action": -0.8555576205253601}
{"mode": "train", "epochs": 2, "timestep": 3344, "ep_reward": 746.9623413085938, "reward": 0.4589238166809082, "action": -1.3626679182052612}
{"mode": "train", "epochs": 2, "timestep": 3345, "ep_reward": 747.536865234375, "reward": 0.5745129585266113, "action": -1.5908087491989136}
{"mode": "train", "epochs": 2, "timestep": 3346, "ep_reward": 748.2054443359375, "reward": 0.6685878038406372, "action": -0.8061820864677429}
{"mode": "train", "epochs": 2, "timestep": 3347, "ep_reward": 748.954345703125, "reward": 0.7488797903060913, "action": -0.8443088531494141}
{"mode": "train", "epochs": 2, "timestep": 3348, "ep_reward": 749.7606811523438, "reward": 0.806331217288971, "action": -0.6723199486732483}
{"mode": "train", "epochs": 2, "timestep": 3349, "ep_reward": 750.6060180664062, "reward": 0.8453092575073242, "action": -0.48274022340774536}
{"mode": "train", "epochs": 2, "timestep": 3350, "ep_reward": 751.4741821289062, "reward": 0.8681888580322266, "action": -0.5432248115539551}
{"mode": "train", "epochs": 2, "timestep": 3351, "ep_reward": 752.3485717773438, "reward": 0.8743988871574402, "action": -1.4858137369155884}
{"mode": "train", "epochs": 2, "timestep": 3352, "ep_reward": 753.2051391601562, "reward": 0.8565439581871033, "action": -0.45323634147644043}
{"mode": "train", "epochs": 2, "timestep": 3353, "ep_reward": 754.033935546875, "reward": 0.8287808895111084, "action": -0.9514896869659424}
{"mode": "train", "epochs": 2, "timestep": 3354, "ep_reward": 754.8073120117188, "reward": 0.773378312587738, "action": -1.29120671749115}
{"mode": "train", "epochs": 2, "timestep": 3355, "ep_reward": 755.491455078125, "reward": 0.6841245293617249, "action": -1.4189518690109253}
{"mode": "train", "epochs": 2, "timestep": 3356, "ep_reward": 756.0462646484375, "reward": 0.5547938346862793, "action": -1.3347269296646118}
{"mode": "train", "epochs": 2, "timestep": 3357, "ep_reward": 756.4327392578125, "reward": 0.386496901512146, "action": -1.5767123699188232}
{"mode": "train", "epochs": 2, "timestep": 3358, "ep_reward": 756.7169799804688, "reward": 0.28421640396118164, "action": -0.9665603637695312}
{"mode": "train", "epochs": 2, "timestep": 3359, "ep_reward": 756.8787231445312, "reward": 0.16172748804092407, "action": -1.651709794998169}
{"mode": "train", "epochs": 2, "timestep": 3360, "ep_reward": 756.8981323242188, "reward": 0.019389748573303223, "action": -1.4536699056625366}
{"mode": "train", "epochs": 2, "timestep": 3361, "ep_reward": 756.9955444335938, "reward": 0.09738284349441528, "action": -1.0468696355819702}
{"mode": "train", "epochs": 2, "timestep": 3362, "ep_reward": 757.2305297851562, "reward": 0.23498743772506714, "action": -0.9165114164352417}
{"mode": "train", "epochs": 2, "timestep": 3363, "ep_reward": 757.6058349609375, "reward": 0.3752947449684143, "action": -0.7509126663208008}
{"mode": "train", "epochs": 2, "timestep": 3364, "ep_reward": 758.1141967773438, "reward": 0.5083478093147278, "action": 0.44065916538238525}
{"mode": "train", "epochs": 2, "timestep": 3365, "ep_reward": 758.7498779296875, "reward": 0.6357002258300781, "action": -1.3674753904342651}
{"mode": "train", "epochs": 2, "timestep": 3366, "ep_reward": 759.4700317382812, "reward": 0.7201700210571289, "action": -0.5834881067276001}
{"mode": "train", "epochs": 2, "timestep": 3367, "ep_reward": 760.2610473632812, "reward": 0.7910346984863281, "action": -1.0254331827163696}
{"mode": "train", "epochs": 2, "timestep": 3368, "ep_reward": 761.0990600585938, "reward": 0.8380318880081177, "action": -1.0258365869522095}
{"mode": "train", "epochs": 2, "timestep": 3369, "ep_reward": 761.9672241210938, "reward": 0.8681482076644897, "action": -1.7004971504211426}
{"mode": "train", "epochs": 2, "timestep": 3370, "ep_reward": 762.8456420898438, "reward": 0.8784051537513733, "action": -0.4043521285057068}
{"mode": "train", "epochs": 2, "timestep": 3371, "ep_reward": 763.7301635742188, "reward": 0.884495198726654, "action": -1.0159963369369507}
{"mode": "train", "epochs": 2, "timestep": 3372, "ep_reward": 764.6009521484375, "reward": 0.870804488658905, "action": -1.173028588294983}
{"mode": "train", "epochs": 2, "timestep": 3373, "ep_reward": 765.4390869140625, "reward": 0.8381359577178955, "action": -1.335192322731018}
{"mode": "train", "epochs": 2, "timestep": 3374, "ep_reward": 766.2202758789062, "reward": 0.7812185287475586, "action": -0.45119935274124146}
{"mode": "train", "epochs": 2, "timestep": 3375, "ep_reward": 766.9253540039062, "reward": 0.7050589323043823, "action": -0.8669746518135071}
{"mode": "train", "epochs": 2, "timestep": 3376, "ep_reward": 767.5154418945312, "reward": 0.5901038646697998, "action": -0.18903005123138428}
{"mode": "train", "epochs": 2, "timestep": 3377, "ep_reward": 767.9617309570312, "reward": 0.4462944269180298, "action": -0.820782482624054}
{"mode": "train", "epochs": 2, "timestep": 3378, "ep_reward": 768.2640991210938, "reward": 0.3023948073387146, "action": -1.198798656463623}
{"mode": "train", "epochs": 2, "timestep": 3379, "ep_reward": 768.4473876953125, "reward": 0.1832985281944275, "action": -1.253121256828308}
{"mode": "train", "epochs": 2, "timestep": 3380, "ep_reward": 768.49169921875, "reward": 0.044285356998443604, "action": -0.6202245354652405}
{"mode": "train", "epochs": 2, "timestep": 3381, "ep_reward": 768.5655517578125, "reward": 0.07384324073791504, "action": -0.5969903469085693}
{"mode": "train", "epochs": 2, "timestep": 3382, "ep_reward": 768.7818603515625, "reward": 0.21632468700408936, "action": -1.0042790174484253}
{"mode": "train", "epochs": 2, "timestep": 3383, "ep_reward": 769.136962890625, "reward": 0.35509413480758667, "action": -1.3672418594360352}
{"mode": "train", "epochs": 2, "timestep": 3384, "ep_reward": 769.6195068359375, "reward": 0.48254507780075073, "action": -0.7402254343032837}
{"mode": "train", "epochs": 2, "timestep": 3385, "ep_reward": 770.2213745117188, "reward": 0.6018505692481995, "action": -0.9301666021347046}
{"mode": "train", "epochs": 2, "timestep": 3386, "ep_reward": 770.91845703125, "reward": 0.6971002817153931, "action": -0.40775060653686523}
{"mode": "train", "epochs": 2, "timestep": 3387, "ep_reward": 771.69287109375, "reward": 0.7744218111038208, "action": -0.6968969106674194}
{"mode": "train", "epochs": 2, "timestep": 3388, "ep_reward": 772.5200805664062, "reward": 0.8272054195404053, "action": -1.1541898250579834}
{"mode": "train", "epochs": 2, "timestep": 3389, "ep_reward": 773.3779296875, "reward": 0.8578694462776184, "action": -1.3395863771438599}
{"mode": "train", "epochs": 2, "timestep": 3390, "ep_reward": 774.2490844726562, "reward": 0.8711555600166321, "action": -1.3939189910888672}
{"mode": "train", "epochs": 2, "timestep": 3391, "ep_reward": 775.1175537109375, "reward": 0.8684449791908264, "action": -1.3365942239761353}
{"mode": "train", "epochs": 2, "timestep": 3392, "ep_reward": 775.9666748046875, "reward": 0.8491144180297852, "action": -0.4066372513771057}
{"mode": "train", "epochs": 2, "timestep": 3393, "ep_reward": 776.784912109375, "reward": 0.8182539939880371, "action": -1.0155301094055176}
{"mode": "train", "epochs": 2, "timestep": 3394, "ep_reward": 777.542236328125, "reward": 0.757318377494812, "action": 0.020081281661987305}
{"mode": "train", "epochs": 2, "timestep": 3395, "ep_reward": 778.2203979492188, "reward": 0.6781848669052124, "action": -0.2841726541519165}
{"mode": "train", "epochs": 2, "timestep": 3396, "ep_reward": 778.7821655273438, "reward": 0.561778724193573, "action": -0.24362772703170776}
{"mode": "train", "epochs": 2, "timestep": 3397, "ep_reward": 779.1910400390625, "reward": 0.4089028239250183, "action": -1.615923285484314}
{"mode": "train", "epochs": 2, "timestep": 3398, "ep_reward": 779.4677124023438, "reward": 0.2766910195350647, "action": -0.6585839986801147}
{"mode": "train", "epochs": 2, "timestep": 3399, "ep_reward": 779.6206665039062, "reward": 0.15295803546905518, "action": -0.8615430593490601}
{"mode": "train", "epochs": 2, "timestep": 3400, "ep_reward": 779.6298828125, "reward": 0.009215593338012695, "action": -1.1005091667175293}
{"mode": "train", "epochs": 2, "timestep": 3401, "ep_reward": 779.7367553710938, "reward": 0.10685545206069946, "action": -0.6761765480041504}
{"mode": "train", "epochs": 2, "timestep": 3402, "ep_reward": 779.9859619140625, "reward": 0.24919414520263672, "action": -1.7657029628753662}
{"mode": "train", "epochs": 2, "timestep": 3403, "ep_reward": 780.3638305664062, "reward": 0.37788593769073486, "action": -1.0522141456604004}
{"mode": "train", "epochs": 2, "timestep": 3404, "ep_reward": 780.8713989257812, "reward": 0.5075976848602295, "action": -1.3756316900253296}
{"mode": "train", "epochs": 2, "timestep": 3405, "ep_reward": 781.4874267578125, "reward": 0.6159994006156921, "action": -0.9574447870254517}
{"mode": "train", "epochs": 2, "timestep": 3406, "ep_reward": 782.1944580078125, "reward": 0.7070157527923584, "action": -1.3961069583892822}
{"mode": "train", "epochs": 2, "timestep": 3407, "ep_reward": 782.9649658203125, "reward": 0.7705071568489075, "action": -1.0683666467666626}
{"mode": "train", "epochs": 2, "timestep": 3408, "ep_reward": 783.7806396484375, "reward": 0.8156892657279968, "action": -1.6265411376953125}
{"mode": "train", "epochs": 2, "timestep": 3409, "ep_reward": 784.6165771484375, "reward": 0.8359432816505432, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3410, "ep_reward": 785.4503173828125, "reward": 0.8337284326553345, "action": -1.2273826599121094}
{"mode": "train", "epochs": 2, "timestep": 3411, "ep_reward": 786.2680053710938, "reward": 0.8176858425140381, "action": -0.8931581377983093}
{"mode": "train", "epochs": 2, "timestep": 3412, "ep_reward": 787.0488891601562, "reward": 0.7809118032455444, "action": -0.3220020532608032}
{"mode": "train", "epochs": 2, "timestep": 3413, "ep_reward": 787.77099609375, "reward": 0.7220852375030518, "action": -1.3380296230316162}
{"mode": "train", "epochs": 2, "timestep": 3414, "ep_reward": 788.3873291015625, "reward": 0.6163151264190674, "action": -1.4514808654785156}
{"mode": "train", "epochs": 2, "timestep": 3415, "ep_reward": 788.8525390625, "reward": 0.4651947021484375, "action": -0.7795573472976685}
{"mode": "train", "epochs": 2, "timestep": 3416, "ep_reward": 789.2069091796875, "reward": 0.3543516993522644, "action": -1.336875319480896}
{"mode": "train", "epochs": 2, "timestep": 3417, "ep_reward": 789.4522705078125, "reward": 0.24534004926681519, "action": -0.5915540456771851}
{"mode": "train", "epochs": 2, "timestep": 3418, "ep_reward": 789.5684204101562, "reward": 0.11617237329483032, "action": -1.1910938024520874}
{"mode": "train", "epochs": 2, "timestep": 3419, "ep_reward": 789.5671997070312, "reward": -0.0012112855911254883, "action": -1.5245909690856934}
{"mode": "train", "epochs": 2, "timestep": 3420, "ep_reward": 789.7111206054688, "reward": 0.14392834901809692, "action": -0.9840553402900696}
{"mode": "train", "epochs": 2, "timestep": 3421, "ep_reward": 789.99462890625, "reward": 0.2835215926170349, "action": -1.0871384143829346}
{"mode": "train", "epochs": 2, "timestep": 3422, "ep_reward": 790.4142456054688, "reward": 0.4196120500564575, "action": -0.6749980449676514}
{"mode": "train", "epochs": 2, "timestep": 3423, "ep_reward": 790.9627685546875, "reward": 0.5485447645187378, "action": -0.6820540428161621}
{"mode": "train", "epochs": 2, "timestep": 3424, "ep_reward": 791.6197509765625, "reward": 0.6570050716400146, "action": -0.8874744176864624}
{"mode": "train", "epochs": 2, "timestep": 3425, "ep_reward": 792.3599853515625, "reward": 0.7402077913284302, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3426, "ep_reward": 793.1516723632812, "reward": 0.7916886210441589, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3427, "ep_reward": 793.9765014648438, "reward": 0.824825644493103, "action": -0.06722056865692139}
{"mode": "train", "epochs": 2, "timestep": 3428, "ep_reward": 794.8330688476562, "reward": 0.8565489649772644, "action": -1.7633392810821533}
{"mode": "train", "epochs": 2, "timestep": 3429, "ep_reward": 795.6892700195312, "reward": 0.8561862111091614, "action": -0.727623462677002}
{"mode": "train", "epochs": 2, "timestep": 3430, "ep_reward": 796.5360717773438, "reward": 0.8468073606491089, "action": -1.3533875942230225}
{"mode": "train", "epochs": 2, "timestep": 3431, "ep_reward": 797.3472290039062, "reward": 0.8111791610717773, "action": -0.20189803838729858}
{"mode": "train", "epochs": 2, "timestep": 3432, "ep_reward": 798.1095581054688, "reward": 0.762299656867981, "action": -0.8621881604194641}
{"mode": "train", "epochs": 2, "timestep": 3433, "ep_reward": 798.7859497070312, "reward": 0.6763931512832642, "action": -1.0700048208236694}
{"mode": "train", "epochs": 2, "timestep": 3434, "ep_reward": 799.336181640625, "reward": 0.5502067804336548, "action": -1.2454586029052734}
{"mode": "train", "epochs": 2, "timestep": 3435, "ep_reward": 799.72216796875, "reward": 0.3860045075416565, "action": -1.7947776317596436}
{"mode": "train", "epochs": 2, "timestep": 3436, "ep_reward": 800.005859375, "reward": 0.28370386362075806, "action": -0.6690693497657776}
{"mode": "train", "epochs": 2, "timestep": 3437, "ep_reward": 800.1670532226562, "reward": 0.16118890047073364, "action": -1.0542560815811157}
{"mode": "train", "epochs": 2, "timestep": 3438, "ep_reward": 800.1858520507812, "reward": 0.018783211708068848, "action": -0.19412648677825928}
{"mode": "train", "epochs": 2, "timestep": 3439, "ep_reward": 800.2838134765625, "reward": 0.09797704219818115, "action": -1.594490885734558}
{"mode": "train", "epochs": 2, "timestep": 3440, "ep_reward": 800.5136108398438, "reward": 0.2298184633255005, "action": 0.06599080562591553}
{"mode": "train", "epochs": 2, "timestep": 3441, "ep_reward": 800.8969116210938, "reward": 0.3832942843437195, "action": -0.961523175239563}
{"mode": "train", "epochs": 2, "timestep": 3442, "ep_reward": 801.4093627929688, "reward": 0.5124778151512146, "action": -0.8075655698776245}
{"mode": "train", "epochs": 2, "timestep": 3443, "ep_reward": 802.03515625, "reward": 0.6258162260055542, "action": -1.821081280708313}
{"mode": "train", "epochs": 2, "timestep": 3444, "ep_reward": 802.7425537109375, "reward": 0.7074232697486877, "action": -0.9998509883880615}
{"mode": "train", "epochs": 2, "timestep": 3445, "ep_reward": 803.5186767578125, "reward": 0.7761507630348206, "action": -1.4628264904022217}
{"mode": "train", "epochs": 2, "timestep": 3446, "ep_reward": 804.338623046875, "reward": 0.8199405074119568, "action": -1.5285429954528809}
{"mode": "train", "epochs": 2, "timestep": 3447, "ep_reward": 805.1834716796875, "reward": 0.8448346257209778, "action": -1.343583345413208}
{"mode": "train", "epochs": 2, "timestep": 3448, "ep_reward": 806.0372924804688, "reward": 0.8538092970848083, "action": -1.1040964126586914}
{"mode": "train", "epochs": 2, "timestep": 3449, "ep_reward": 806.8841552734375, "reward": 0.8468543291091919, "action": -0.7781437635421753}
{"mode": "train", "epochs": 2, "timestep": 3450, "ep_reward": 807.7071533203125, "reward": 0.8229984045028687, "action": 0.13672006130218506}
{"mode": "train", "epochs": 2, "timestep": 3451, "ep_reward": 808.49267578125, "reward": 0.7855312824249268, "action": -1.5276098251342773}
{"mode": "train", "epochs": 2, "timestep": 3452, "ep_reward": 809.1948852539062, "reward": 0.7022092342376709, "action": -1.9993946552276611}
{"mode": "train", "epochs": 2, "timestep": 3453, "ep_reward": 809.7688598632812, "reward": 0.573958694934845, "action": -1.4131031036376953}
{"mode": "train", "epochs": 2, "timestep": 3454, "ep_reward": 810.177978515625, "reward": 0.4091067910194397, "action": -1.806572675704956}
{"mode": "train", "epochs": 2, "timestep": 3455, "ep_reward": 810.4898071289062, "reward": 0.31183165311813354, "action": -1.5221322774887085}
{"mode": "train", "epochs": 2, "timestep": 3456, "ep_reward": 810.6843872070312, "reward": 0.1945849061012268, "action": -0.9615622758865356}
{"mode": "train", "epochs": 2, "timestep": 3457, "ep_reward": 810.741455078125, "reward": 0.05709642171859741, "action": -1.8469622135162354}
{"mode": "train", "epochs": 2, "timestep": 3458, "ep_reward": 810.8024291992188, "reward": 0.06100022792816162, "action": -1.0090594291687012}
{"mode": "train", "epochs": 2, "timestep": 3459, "ep_reward": 811.0004272460938, "reward": 0.1980075240135193, "action": 0.06586956977844238}
{"mode": "train", "epochs": 2, "timestep": 3460, "ep_reward": 811.3515625, "reward": 0.3511606454849243, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3461, "ep_reward": 811.8223266601562, "reward": 0.4707396626472473, "action": -1.3724801540374756}
{"mode": "train", "epochs": 2, "timestep": 3462, "ep_reward": 812.4072265625, "reward": 0.5848840475082397, "action": -1.1970524787902832}
{"mode": "train", "epochs": 2, "timestep": 3463, "ep_reward": 813.0877075195312, "reward": 0.6805062890052795, "action": -1.6628551483154297}
{"mode": "train", "epochs": 2, "timestep": 3464, "ep_reward": 813.8367919921875, "reward": 0.7490549087524414, "action": -0.6757597923278809}
{"mode": "train", "epochs": 2, "timestep": 3465, "ep_reward": 814.6422119140625, "reward": 0.8053997755050659, "action": -0.905379593372345}
{"mode": "train", "epochs": 2, "timestep": 3466, "ep_reward": 815.4810791015625, "reward": 0.8388642072677612, "action": -0.967087984085083}
{"mode": "train", "epochs": 2, "timestep": 3467, "ep_reward": 816.3341674804688, "reward": 0.8530763983726501, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3468, "ep_reward": 817.1740112304688, "reward": 0.839825451374054, "action": -1.3543848991394043}
{"mode": "train", "epochs": 2, "timestep": 3469, "ep_reward": 817.9851684570312, "reward": 0.8111519813537598, "action": -0.9962279200553894}
{"mode": "train", "epochs": 2, "timestep": 3470, "ep_reward": 818.7456665039062, "reward": 0.7605220079421997, "action": -0.9074850082397461}
{"mode": "train", "epochs": 2, "timestep": 3471, "ep_reward": 819.4252319335938, "reward": 0.6795415878295898, "action": -1.1972013711929321}
{"mode": "train", "epochs": 2, "timestep": 3472, "ep_reward": 819.9815063476562, "reward": 0.5562559366226196, "action": -1.3746161460876465}
{"mode": "train", "epochs": 2, "timestep": 3473, "ep_reward": 820.385009765625, "reward": 0.4035170078277588, "action": -0.21540874242782593}
{"mode": "train", "epochs": 2, "timestep": 3474, "ep_reward": 820.6898803710938, "reward": 0.30485260486602783, "action": -0.5183050632476807}
{"mode": "train", "epochs": 2, "timestep": 3475, "ep_reward": 820.8759765625, "reward": 0.18612247705459595, "action": -1.246579885482788}
{"mode": "train", "epochs": 2, "timestep": 3476, "ep_reward": 820.9234008789062, "reward": 0.04741811752319336, "action": -1.5599405765533447}
{"mode": "train", "epochs": 2, "timestep": 3477, "ep_reward": 820.9940795898438, "reward": 0.070670485496521, "action": -0.4470307230949402}
{"mode": "train", "epochs": 2, "timestep": 3478, "ep_reward": 821.2090454101562, "reward": 0.21496659517288208, "action": -0.24663525819778442}
{"mode": "train", "epochs": 2, "timestep": 3479, "ep_reward": 821.5717163085938, "reward": 0.36264729499816895, "action": -0.9852402806282043}
{"mode": "train", "epochs": 2, "timestep": 3480, "ep_reward": 822.064208984375, "reward": 0.4925042390823364, "action": -1.4901355504989624}
{"mode": "train", "epochs": 2, "timestep": 3481, "ep_reward": 822.665771484375, "reward": 0.6015333533287048, "action": -1.674957275390625}
{"mode": "train", "epochs": 2, "timestep": 3482, "ep_reward": 823.35546875, "reward": 0.6896908283233643, "action": -0.8431848883628845}
{"mode": "train", "epochs": 2, "timestep": 3483, "ep_reward": 824.1204223632812, "reward": 0.76495361328125, "action": -0.8519208431243896}
{"mode": "train", "epochs": 2, "timestep": 3484, "ep_reward": 824.93896484375, "reward": 0.8185571432113647, "action": -1.4624425172805786}
{"mode": "train", "epochs": 2, "timestep": 3485, "ep_reward": 825.7872924804688, "reward": 0.8483012318611145, "action": -0.6972196102142334}
{"mode": "train", "epochs": 2, "timestep": 3486, "ep_reward": 826.655029296875, "reward": 0.8677071928977966, "action": -1.2523539066314697}
{"mode": "train", "epochs": 2, "timestep": 3487, "ep_reward": 827.5213012695312, "reward": 0.8662514686584473, "action": -1.617506980895996}
{"mode": "train", "epochs": 2, "timestep": 3488, "ep_reward": 828.3654174804688, "reward": 0.8441162705421448, "action": -1.099838376045227}
{"mode": "train", "epochs": 2, "timestep": 3489, "ep_reward": 829.1705932617188, "reward": 0.8051972985267639, "action": -1.7377461194992065}
{"mode": "train", "epochs": 2, "timestep": 3490, "ep_reward": 829.9030151367188, "reward": 0.7324270009994507, "action": -0.9973456859588623}
{"mode": "train", "epochs": 2, "timestep": 3491, "ep_reward": 830.5359497070312, "reward": 0.6329560279846191, "action": -1.1696817874908447}
{"mode": "train", "epochs": 2, "timestep": 3492, "ep_reward": 831.026123046875, "reward": 0.49019384384155273, "action": -1.7413990497589111}
{"mode": "train", "epochs": 2, "timestep": 3493, "ep_reward": 831.38330078125, "reward": 0.357147753238678, "action": -1.0225858688354492}
{"mode": "train", "epochs": 2, "timestep": 3494, "ep_reward": 831.6318969726562, "reward": 0.2486041784286499, "action": -1.0108864307403564}
{"mode": "train", "epochs": 2, "timestep": 3495, "ep_reward": 831.751953125, "reward": 0.12002897262573242, "action": -1.2305545806884766}
{"mode": "train", "epochs": 2, "timestep": 3496, "ep_reward": 831.7465209960938, "reward": -0.005450010299682617, "action": -0.9962862730026245}
{"mode": "train", "epochs": 2, "timestep": 3497, "ep_reward": 831.8866577148438, "reward": 0.1401335597038269, "action": -1.1982372999191284}
{"mode": "train", "epochs": 2, "timestep": 3498, "ep_reward": 832.1636962890625, "reward": 0.2770301103591919, "action": -0.6388959288597107}
{"mode": "train", "epochs": 2, "timestep": 3499, "ep_reward": 832.5829467773438, "reward": 0.4192620515823364, "action": 0.1042337417602539}
{"mode": "train", "epochs": 2, "timestep": 3500, "ep_reward": 833.1396484375, "reward": 0.5567187666893005, "action": -0.32958120107650757}
{"mode": "train", "epochs": 2, "timestep": 3501, "ep_reward": 833.8067016601562, "reward": 0.6670741438865662, "action": -1.1985386610031128}
{"mode": "train", "epochs": 2, "timestep": 3502, "ep_reward": 834.5528564453125, "reward": 0.7461519241333008, "action": -1.7432715892791748}
{"mode": "train", "epochs": 2, "timestep": 3503, "ep_reward": 835.3533935546875, "reward": 0.800514280796051, "action": -1.4680328369140625}
{"mode": "train", "epochs": 2, "timestep": 3504, "ep_reward": 836.1929321289062, "reward": 0.8395549058914185, "action": -0.9589642286300659}
{"mode": "train", "epochs": 2, "timestep": 3505, "ep_reward": 837.0589599609375, "reward": 0.8660198450088501, "action": -1.9131927490234375}
{"mode": "train", "epochs": 2, "timestep": 3506, "ep_reward": 837.9284057617188, "reward": 0.8694532513618469, "action": 0.027719616889953613}
{"mode": "train", "epochs": 2, "timestep": 3507, "ep_reward": 838.8015747070312, "reward": 0.8731875419616699, "action": -1.0028791427612305}
{"mode": "train", "epochs": 2, "timestep": 3508, "ep_reward": 839.6532592773438, "reward": 0.851682186126709, "action": -0.7552027702331543}
{"mode": "train", "epochs": 2, "timestep": 3509, "ep_reward": 840.4656982421875, "reward": 0.8124165534973145, "action": -1.0626896619796753}
{"mode": "train", "epochs": 2, "timestep": 3510, "ep_reward": 841.2103881835938, "reward": 0.7446737289428711, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3511, "ep_reward": 841.8424682617188, "reward": 0.6320914030075073, "action": -1.3800578117370605}
{"mode": "train", "epochs": 2, "timestep": 3512, "ep_reward": 842.326904296875, "reward": 0.4844106435775757, "action": -1.4235410690307617}
{"mode": "train", "epochs": 2, "timestep": 3513, "ep_reward": 842.6735229492188, "reward": 0.34664881229400635, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3514, "ep_reward": 842.90966796875, "reward": 0.23617440462112427, "action": -1.3141005039215088}
{"mode": "train", "epochs": 2, "timestep": 3515, "ep_reward": 843.0153198242188, "reward": 0.10564625263214111, "action": -0.5674083828926086}
{"mode": "train", "epochs": 2, "timestep": 3516, "ep_reward": 843.0259399414062, "reward": 0.01061946153640747, "action": -0.21534591913223267}
{"mode": "train", "epochs": 2, "timestep": 3517, "ep_reward": 843.1817016601562, "reward": 0.15577459335327148, "action": -1.339701771736145}
{"mode": "train", "epochs": 2, "timestep": 3518, "ep_reward": 843.4725952148438, "reward": 0.2908768653869629, "action": -0.7333778142929077}
{"mode": "train", "epochs": 2, "timestep": 3519, "ep_reward": 843.9036254882812, "reward": 0.4310299754142761, "action": -1.9553531408309937}
{"mode": "train", "epochs": 2, "timestep": 3520, "ep_reward": 844.447509765625, "reward": 0.5438840985298157, "action": -1.378307580947876}
{"mode": "train", "epochs": 2, "timestep": 3521, "ep_reward": 845.0931396484375, "reward": 0.645660400390625, "action": -1.2469183206558228}
{"mode": "train", "epochs": 2, "timestep": 3522, "ep_reward": 845.8193969726562, "reward": 0.7262699604034424, "action": -1.1857635974884033}
{"mode": "train", "epochs": 2, "timestep": 3523, "ep_reward": 846.6039428710938, "reward": 0.7845593690872192, "action": -1.0586272478103638}
{"mode": "train", "epochs": 2, "timestep": 3524, "ep_reward": 847.4265747070312, "reward": 0.8226350545883179, "action": -0.6619853973388672}
{"mode": "train", "epochs": 2, "timestep": 3525, "ep_reward": 848.27099609375, "reward": 0.8443948030471802, "action": -1.1951336860656738}
{"mode": "train", "epochs": 2, "timestep": 3526, "ep_reward": 849.11328125, "reward": 0.8422952890396118, "action": -0.7560367584228516}
{"mode": "train", "epochs": 2, "timestep": 3527, "ep_reward": 849.9371948242188, "reward": 0.8238986134529114, "action": -1.8257858753204346}
{"mode": "train", "epochs": 2, "timestep": 3528, "ep_reward": 850.7078247070312, "reward": 0.7706429362297058, "action": -1.4220119714736938}
{"mode": "train", "epochs": 2, "timestep": 3529, "ep_reward": 851.3973999023438, "reward": 0.6895895600318909, "action": -1.8365025520324707}
{"mode": "train", "epochs": 2, "timestep": 3530, "ep_reward": 851.9603271484375, "reward": 0.5629239082336426, "action": -1.7298377752304077}
{"mode": "train", "epochs": 2, "timestep": 3531, "ep_reward": 852.3771362304688, "reward": 0.4167787432670593, "action": -1.2815731763839722}
{"mode": "train", "epochs": 2, "timestep": 3532, "ep_reward": 852.6983032226562, "reward": 0.32119542360305786, "action": -1.282626748085022}
{"mode": "train", "epochs": 2, "timestep": 3533, "ep_reward": 852.9039916992188, "reward": 0.20570427179336548, "action": -0.4294885993003845}
{"mode": "train", "epochs": 2, "timestep": 3534, "ep_reward": 852.973876953125, "reward": 0.0699014663696289, "action": -1.9280675649642944}
{"mode": "train", "epochs": 2, "timestep": 3535, "ep_reward": 853.0219116210938, "reward": 0.04802769422531128, "action": -1.2856850624084473}
{"mode": "train", "epochs": 2, "timestep": 3536, "ep_reward": 853.2085571289062, "reward": 0.18662166595458984, "action": -1.1533565521240234}
{"mode": "train", "epochs": 2, "timestep": 3537, "ep_reward": 853.533447265625, "reward": 0.3249187469482422, "action": -0.8625816106796265}
{"mode": "train", "epochs": 2, "timestep": 3538, "ep_reward": 853.9950561523438, "reward": 0.4615951180458069, "action": -0.7160649299621582}
{"mode": "train", "epochs": 2, "timestep": 3539, "ep_reward": 854.5792846679688, "reward": 0.5842571258544922, "action": -1.8313710689544678}
{"mode": "train", "epochs": 2, "timestep": 3540, "ep_reward": 855.253173828125, "reward": 0.6738713979721069, "action": -1.0468367338180542}
{"mode": "train", "epochs": 2, "timestep": 3541, "ep_reward": 856.0032958984375, "reward": 0.7500931024551392, "action": -1.0229697227478027}
{"mode": "train", "epochs": 2, "timestep": 3542, "ep_reward": 856.8076782226562, "reward": 0.8043537735939026, "action": -0.5624256134033203}
{"mode": "train", "epochs": 2, "timestep": 3543, "ep_reward": 857.650146484375, "reward": 0.842491626739502, "action": -0.7449730634689331}
{"mode": "train", "epochs": 2, "timestep": 3544, "ep_reward": 858.5109252929688, "reward": 0.8607931137084961, "action": -0.18685764074325562}
{"mode": "train", "epochs": 2, "timestep": 3545, "ep_reward": 859.3777465820312, "reward": 0.8668373823165894, "action": -1.4654120206832886}
{"mode": "train", "epochs": 2, "timestep": 3546, "ep_reward": 860.2222290039062, "reward": 0.8444806337356567, "action": -0.036729514598846436}
{"mode": "train", "epochs": 2, "timestep": 3547, "ep_reward": 861.037109375, "reward": 0.8148990869522095, "action": -1.0988755226135254}
{"mode": "train", "epochs": 2, "timestep": 3548, "ep_reward": 861.78759765625, "reward": 0.7504659295082092, "action": -0.8985962867736816}
{"mode": "train", "epochs": 2, "timestep": 3549, "ep_reward": 862.4437255859375, "reward": 0.6561052799224854, "action": -1.97682785987854}
{"mode": "train", "epochs": 2, "timestep": 3550, "ep_reward": 862.9514770507812, "reward": 0.507742166519165, "action": -0.34227997064590454}
{"mode": "train", "epochs": 2, "timestep": 3551, "ep_reward": 863.3132934570312, "reward": 0.36184680461883545, "action": -1.034975290298462}
{"mode": "train", "epochs": 2, "timestep": 3552, "ep_reward": 863.5675048828125, "reward": 0.25423139333724976, "action": -1.2391246557235718}
{"mode": "train", "epochs": 2, "timestep": 3553, "ep_reward": 863.6941528320312, "reward": 0.12667220830917358, "action": -1.0533866882324219}
{"mode": "train", "epochs": 2, "timestep": 3554, "ep_reward": 863.6812744140625, "reward": -0.012888669967651367, "action": -0.5472114086151123}
{"mode": "train", "epochs": 2, "timestep": 3555, "ep_reward": 863.81494140625, "reward": 0.13366222381591797, "action": -0.7772864103317261}
{"mode": "train", "epochs": 2, "timestep": 3556, "ep_reward": 864.090576171875, "reward": 0.2756240963935852, "action": -0.591364324092865}
{"mode": "train", "epochs": 2, "timestep": 3557, "ep_reward": 864.5081787109375, "reward": 0.4176197648048401, "action": -0.512349009513855}
{"mode": "train", "epochs": 2, "timestep": 3558, "ep_reward": 865.0559692382812, "reward": 0.547805905342102, "action": -1.3112726211547852}
{"mode": "train", "epochs": 2, "timestep": 3559, "ep_reward": 865.7059326171875, "reward": 0.6499420404434204, "action": -0.2596357464790344}
{"mode": "train", "epochs": 2, "timestep": 3560, "ep_reward": 866.4471435546875, "reward": 0.7412036061286926, "action": -0.8141307830810547}
{"mode": "train", "epochs": 2, "timestep": 3561, "ep_reward": 867.2517700195312, "reward": 0.8046569228172302, "action": -0.6823439598083496}
{"mode": "train", "epochs": 2, "timestep": 3562, "ep_reward": 868.1018676757812, "reward": 0.8500949144363403, "action": -0.7887795567512512}
{"mode": "train", "epochs": 2, "timestep": 3563, "ep_reward": 868.980224609375, "reward": 0.8783480525016785, "action": -0.6075055003166199}
{"mode": "train", "epochs": 2, "timestep": 3564, "ep_reward": 869.8739624023438, "reward": 0.8937609195709229, "action": -1.568670392036438}
{"mode": "train", "epochs": 2, "timestep": 3565, "ep_reward": 870.7627563476562, "reward": 0.8888150453567505, "action": -1.5415630340576172}
{"mode": "train", "epochs": 2, "timestep": 3566, "ep_reward": 871.632080078125, "reward": 0.8693459630012512, "action": -0.6176937818527222}
{"mode": "train", "epochs": 2, "timestep": 3567, "ep_reward": 872.4720458984375, "reward": 0.8399902582168579, "action": -0.05488163232803345}
{"mode": "train", "epochs": 2, "timestep": 3568, "ep_reward": 873.267333984375, "reward": 0.7953053712844849, "action": -0.7798046469688416}
{"mode": "train", "epochs": 2, "timestep": 3569, "ep_reward": 873.98486328125, "reward": 0.7175360918045044, "action": -1.4608523845672607}
{"mode": "train", "epochs": 2, "timestep": 3570, "ep_reward": 874.5823364257812, "reward": 0.5974447131156921, "action": -1.3740830421447754}
{"mode": "train", "epochs": 2, "timestep": 3571, "ep_reward": 875.0192260742188, "reward": 0.43688493967056274, "action": -0.7557992935180664}
{"mode": "train", "epochs": 2, "timestep": 3572, "ep_reward": 875.3207397460938, "reward": 0.30150163173675537, "action": -1.8341445922851562}
{"mode": "train", "epochs": 2, "timestep": 3573, "ep_reward": 875.5031127929688, "reward": 0.18236422538757324, "action": -1.375003457069397}
{"mode": "train", "epochs": 2, "timestep": 3574, "ep_reward": 875.54638671875, "reward": 0.043253183364868164, "action": 0.06363379955291748}
{"mode": "train", "epochs": 2, "timestep": 3575, "ep_reward": 875.6212768554688, "reward": 0.07487809658050537, "action": -0.47065818309783936}
{"mode": "train", "epochs": 2, "timestep": 3576, "ep_reward": 875.8401489257812, "reward": 0.2188814878463745, "action": -1.4617210626602173}
{"mode": "train", "epochs": 2, "timestep": 3577, "ep_reward": 876.1919555664062, "reward": 0.3518298268318176, "action": -0.5693708658218384}
{"mode": "train", "epochs": 2, "timestep": 3578, "ep_reward": 876.6812744140625, "reward": 0.4893200397491455, "action": -0.3830561637878418}
{"mode": "train", "epochs": 2, "timestep": 3579, "ep_reward": 877.2924194335938, "reward": 0.6111752390861511, "action": -0.9489670395851135}
{"mode": "train", "epochs": 2, "timestep": 3580, "ep_reward": 877.9970092773438, "reward": 0.7045866250991821, "action": -0.7823835611343384}
{"mode": "train", "epochs": 2, "timestep": 3581, "ep_reward": 878.7745361328125, "reward": 0.7775388956069946, "action": -0.6499214768409729}
{"mode": "train", "epochs": 2, "timestep": 3582, "ep_reward": 879.6055297851562, "reward": 0.8309734463691711, "action": -0.2906121015548706}
{"mode": "train", "epochs": 2, "timestep": 3583, "ep_reward": 880.4747314453125, "reward": 0.8692086935043335, "action": -0.33475255966186523}
{"mode": "train", "epochs": 2, "timestep": 3584, "ep_reward": 881.3663940429688, "reward": 0.8916426301002502, "action": -0.07267332077026367}
{"mode": "train", "epochs": 2, "timestep": 3585, "ep_reward": 882.2691650390625, "reward": 0.9027588367462158, "action": 0.3413963317871094}
{"mode": "train", "epochs": 2, "timestep": 3586, "ep_reward": 883.173828125, "reward": 0.9046726226806641, "action": -1.1997417211532593}
{"mode": "train", "epochs": 2, "timestep": 3587, "ep_reward": 884.0564575195312, "reward": 0.8826068639755249, "action": 0.4199337959289551}
{"mode": "train", "epochs": 2, "timestep": 3588, "ep_reward": 884.9146728515625, "reward": 0.8582184910774231, "action": -0.6182543039321899}
{"mode": "train", "epochs": 2, "timestep": 3589, "ep_reward": 885.721435546875, "reward": 0.8067887425422668, "action": -1.0356870889663696}
{"mode": "train", "epochs": 2, "timestep": 3590, "ep_reward": 886.4474487304688, "reward": 0.7259966731071472, "action": -0.70139080286026}
{"mode": "train", "epochs": 2, "timestep": 3591, "ep_reward": 887.0642700195312, "reward": 0.6168232560157776, "action": -0.36937880516052246}
{"mode": "train", "epochs": 2, "timestep": 3592, "ep_reward": 887.5409545898438, "reward": 0.4766574501991272, "action": -0.9710755348205566}
{"mode": "train", "epochs": 2, "timestep": 3593, "ep_reward": 887.8402099609375, "reward": 0.29924190044403076, "action": -0.16460943222045898}
{"mode": "train", "epochs": 2, "timestep": 3594, "ep_reward": 888.019775390625, "reward": 0.1795358657836914, "action": -0.6595809459686279}
{"mode": "train", "epochs": 2, "timestep": 3595, "ep_reward": 888.0595703125, "reward": 0.03978639841079712, "action": -1.2441152334213257}
{"mode": "train", "epochs": 2, "timestep": 3596, "ep_reward": 888.1376342773438, "reward": 0.07809370756149292, "action": -0.9904478192329407}
{"mode": "train", "epochs": 2, "timestep": 3597, "ep_reward": 888.3534545898438, "reward": 0.21582990884780884, "action": -0.8152838945388794}
{"mode": "train", "epochs": 2, "timestep": 3598, "ep_reward": 888.7113037109375, "reward": 0.3578563332557678, "action": -0.8382542729377747}
{"mode": "train", "epochs": 2, "timestep": 3599, "ep_reward": 889.2026977539062, "reward": 0.4913715720176697, "action": -1.423901915550232}
{"mode": "train", "epochs": 2, "timestep": 3600, "ep_reward": 889.8045043945312, "reward": 0.6017793416976929, "action": -0.6765148043632507}
{"mode": "train", "epochs": 2, "timestep": 3601, "ep_reward": 890.5038452148438, "reward": 0.6993460655212402, "action": -1.2070837020874023}
{"mode": "train", "epochs": 2, "timestep": 3602, "ep_reward": 891.2722778320312, "reward": 0.7684357166290283, "action": -1.5524566173553467}
{"mode": "train", "epochs": 2, "timestep": 3603, "ep_reward": 892.0859985351562, "reward": 0.8136905431747437, "action": -1.592596411705017}
{"mode": "train", "epochs": 2, "timestep": 3604, "ep_reward": 892.926025390625, "reward": 0.8400245308876038, "action": -0.9811305403709412}
{"mode": "train", "epochs": 2, "timestep": 3605, "ep_reward": 893.7799072265625, "reward": 0.8538792133331299, "action": -0.3004150986671448}
{"mode": "train", "epochs": 2, "timestep": 3606, "ep_reward": 894.6356811523438, "reward": 0.8557518720626831, "action": -1.7153024673461914}
{"mode": "train", "epochs": 2, "timestep": 3607, "ep_reward": 895.4613037109375, "reward": 0.8256250023841858, "action": -1.7874027490615845}
{"mode": "train", "epochs": 2, "timestep": 3608, "ep_reward": 896.23095703125, "reward": 0.7696820497512817, "action": -1.9741754531860352}
{"mode": "train", "epochs": 2, "timestep": 3609, "ep_reward": 896.90966796875, "reward": 0.6787101626396179, "action": -0.642038106918335}
{"mode": "train", "epochs": 2, "timestep": 3610, "ep_reward": 897.4743041992188, "reward": 0.5646259188652039, "action": -0.543767511844635}
{"mode": "train", "epochs": 2, "timestep": 3611, "ep_reward": 897.8845825195312, "reward": 0.41025954484939575, "action": -0.33246129751205444}
{"mode": "train", "epochs": 2, "timestep": 3612, "ep_reward": 898.1958618164062, "reward": 0.31129759550094604, "action": -0.4015641212463379}
{"mode": "train", "epochs": 2, "timestep": 3613, "ep_reward": 898.3895874023438, "reward": 0.19372129440307617, "action": -1.376345157623291}
{"mode": "train", "epochs": 2, "timestep": 3614, "ep_reward": 898.4459838867188, "reward": 0.056369006633758545, "action": 0.05266368389129639}
{"mode": "train", "epochs": 2, "timestep": 3615, "ep_reward": 898.5079345703125, "reward": 0.06193983554840088, "action": -1.069675326347351}
{"mode": "train", "epochs": 2, "timestep": 3616, "ep_reward": 898.7066040039062, "reward": 0.19866317510604858, "action": -0.9069033265113831}
{"mode": "train", "epochs": 2, "timestep": 3617, "ep_reward": 899.0467529296875, "reward": 0.340154767036438, "action": -0.6711714863777161}
{"mode": "train", "epochs": 2, "timestep": 3618, "ep_reward": 899.5244140625, "reward": 0.4776386618614197, "action": -0.06806677579879761}
{"mode": "train", "epochs": 2, "timestep": 3619, "ep_reward": 900.1293334960938, "reward": 0.6048907041549683, "action": -0.2643829584121704}
{"mode": "train", "epochs": 2, "timestep": 3620, "ep_reward": 900.835693359375, "reward": 0.706331193447113, "action": -0.488203227519989}
{"mode": "train", "epochs": 2, "timestep": 3621, "ep_reward": 901.6178588867188, "reward": 0.7821553349494934, "action": -0.9796987771987915}
{"mode": "train", "epochs": 2, "timestep": 3622, "ep_reward": 902.451171875, "reward": 0.8333097696304321, "action": -1.3759286403656006}
{"mode": "train", "epochs": 2, "timestep": 3623, "ep_reward": 903.315673828125, "reward": 0.8645153045654297, "action": -1.764723539352417}
{"mode": "train", "epochs": 2, "timestep": 3624, "ep_reward": 904.194091796875, "reward": 0.8784167766571045, "action": -0.8851602673530579}
{"mode": "train", "epochs": 2, "timestep": 3625, "ep_reward": 905.0792236328125, "reward": 0.8851608037948608, "action": -0.6629722118377686}
{"mode": "train", "epochs": 2, "timestep": 3626, "ep_reward": 905.9585571289062, "reward": 0.8793100714683533, "action": -0.5292775630950928}
{"mode": "train", "epochs": 2, "timestep": 3627, "ep_reward": 906.8173828125, "reward": 0.858830988407135, "action": -1.1104191541671753}
{"mode": "train", "epochs": 2, "timestep": 3628, "ep_reward": 907.6314697265625, "reward": 0.8140621185302734, "action": -0.7277599573135376}
{"mode": "train", "epochs": 2, "timestep": 3629, "ep_reward": 908.3795166015625, "reward": 0.748019814491272, "action": -0.9889592528343201}
{"mode": "train", "epochs": 2, "timestep": 3630, "ep_reward": 909.0272827148438, "reward": 0.6477375626564026, "action": -1.2814226150512695}
{"mode": "train", "epochs": 2, "timestep": 3631, "ep_reward": 909.5323486328125, "reward": 0.5050527453422546, "action": -1.2252230644226074}
{"mode": "train", "epochs": 2, "timestep": 3632, "ep_reward": 909.8763427734375, "reward": 0.3439876437187195, "action": -1.2997381687164307}
{"mode": "train", "epochs": 2, "timestep": 3633, "ep_reward": 910.1091918945312, "reward": 0.23284900188446045, "action": -0.9988635778427124}
{"mode": "train", "epochs": 2, "timestep": 3634, "ep_reward": 910.2108764648438, "reward": 0.10170602798461914, "action": -0.5794970989227295}
{"mode": "train", "epochs": 2, "timestep": 3635, "ep_reward": 910.2257690429688, "reward": 0.014870524406433105, "action": -0.8820747137069702}
{"mode": "train", "epochs": 2, "timestep": 3636, "ep_reward": 910.3836669921875, "reward": 0.15789860486984253, "action": -0.3970147967338562}
{"mode": "train", "epochs": 2, "timestep": 3637, "ep_reward": 910.688720703125, "reward": 0.30507099628448486, "action": -0.7627412676811218}
{"mode": "train", "epochs": 2, "timestep": 3638, "ep_reward": 911.1315307617188, "reward": 0.4427803158760071, "action": -0.5762311220169067}
{"mode": "train", "epochs": 2, "timestep": 3639, "ep_reward": 911.7005004882812, "reward": 0.5689511299133301, "action": -1.077096700668335}
{"mode": "train", "epochs": 2, "timestep": 3640, "ep_reward": 912.3701171875, "reward": 0.6696113348007202, "action": -0.3522034287452698}
{"mode": "train", "epochs": 2, "timestep": 3641, "ep_reward": 913.1256103515625, "reward": 0.7554939985275269, "action": -0.8454158902168274}
{"mode": "train", "epochs": 2, "timestep": 3642, "ep_reward": 913.9405517578125, "reward": 0.8149127960205078, "action": -1.579160213470459}
{"mode": "train", "epochs": 2, "timestep": 3643, "ep_reward": 914.7908325195312, "reward": 0.8502767086029053, "action": -1.4740227460861206}
{"mode": "train", "epochs": 2, "timestep": 3644, "ep_reward": 915.6620483398438, "reward": 0.8712254762649536, "action": -0.741510272026062}
{"mode": "train", "epochs": 2, "timestep": 3645, "ep_reward": 916.54541015625, "reward": 0.8833542466163635, "action": -0.5801792144775391}
{"mode": "train", "epochs": 2, "timestep": 3646, "ep_reward": 917.427734375, "reward": 0.8823465704917908, "action": -0.8140256404876709}
{"mode": "train", "epochs": 2, "timestep": 3647, "ep_reward": 918.2918090820312, "reward": 0.8640642166137695, "action": -1.4997386932373047}
{"mode": "train", "epochs": 2, "timestep": 3648, "ep_reward": 919.112548828125, "reward": 0.8207609057426453, "action": -1.8393537998199463}
{"mode": "train", "epochs": 2, "timestep": 3649, "ep_reward": 919.8605346679688, "reward": 0.7480056285858154, "action": -0.535698652267456}
{"mode": "train", "epochs": 2, "timestep": 3650, "ep_reward": 920.5174560546875, "reward": 0.6569128632545471, "action": -1.080230474472046}
{"mode": "train", "epochs": 2, "timestep": 3651, "ep_reward": 921.0389404296875, "reward": 0.5214869976043701, "action": -1.2292091846466064}
{"mode": "train", "epochs": 2, "timestep": 3652, "ep_reward": 921.3988037109375, "reward": 0.3598451018333435, "action": -1.1124614477157593}
{"mode": "train", "epochs": 2, "timestep": 3653, "ep_reward": 921.6505737304688, "reward": 0.25178062915802, "action": -1.4924399852752686}
{"mode": "train", "epochs": 2, "timestep": 3654, "ep_reward": 921.7744750976562, "reward": 0.12390691041946411, "action": 0.35554230213165283}
{"mode": "train", "epochs": 2, "timestep": 3655, "ep_reward": 921.7647705078125, "reward": -0.009729623794555664, "action": -1.127089023590088}
{"mode": "train", "epochs": 2, "timestep": 3656, "ep_reward": 921.9013061523438, "reward": 0.13650989532470703, "action": -0.3670666813850403}
{"mode": "train", "epochs": 2, "timestep": 3657, "ep_reward": 922.184814453125, "reward": 0.28351515531539917, "action": -1.2979462146759033}
{"mode": "train", "epochs": 2, "timestep": 3658, "ep_reward": 922.6007080078125, "reward": 0.41588127613067627, "action": -0.9991539120674133}
{"mode": "train", "epochs": 2, "timestep": 3659, "ep_reward": 923.141845703125, "reward": 0.5411664247512817, "action": -1.1034436225891113}
{"mode": "train", "epochs": 2, "timestep": 3660, "ep_reward": 923.7884521484375, "reward": 0.6465989351272583, "action": -0.9927117824554443}
{"mode": "train", "epochs": 2, "timestep": 3661, "ep_reward": 924.5197143554688, "reward": 0.7312341928482056, "action": -1.0199116468429565}
{"mode": "train", "epochs": 2, "timestep": 3662, "ep_reward": 925.3133544921875, "reward": 0.7936283946037292, "action": -0.7638947367668152}
{"mode": "train", "epochs": 2, "timestep": 3663, "ep_reward": 926.151611328125, "reward": 0.8382442593574524, "action": -0.6748803853988647}
{"mode": "train", "epochs": 2, "timestep": 3664, "ep_reward": 927.0173950195312, "reward": 0.8657980561256409, "action": -0.28232401609420776}
{"mode": "train", "epochs": 2, "timestep": 3665, "ep_reward": 927.8980712890625, "reward": 0.8806544542312622, "action": -0.1995689868927002}
{"mode": "train", "epochs": 2, "timestep": 3666, "ep_reward": 928.779296875, "reward": 0.8812457919120789, "action": -1.0537817478179932}
{"mode": "train", "epochs": 2, "timestep": 3667, "ep_reward": 929.6386108398438, "reward": 0.8593308925628662, "action": -0.3111610412597656}
{"mode": "train", "epochs": 2, "timestep": 3668, "ep_reward": 930.4638061523438, "reward": 0.8251914381980896, "action": -1.415771245956421}
{"mode": "train", "epochs": 2, "timestep": 3669, "ep_reward": 931.220458984375, "reward": 0.75666743516922, "action": -1.6685078144073486}
{"mode": "train", "epochs": 2, "timestep": 3670, "ep_reward": 931.872802734375, "reward": 0.6523213386535645, "action": -0.8131291270256042}
{"mode": "train", "epochs": 2, "timestep": 3671, "ep_reward": 932.39208984375, "reward": 0.5193003416061401, "action": 0.03970348834991455}
{"mode": "train", "epochs": 2, "timestep": 3672, "ep_reward": 932.7523803710938, "reward": 0.36030882596969604, "action": -1.3546302318572998}
{"mode": "train", "epochs": 2, "timestep": 3673, "ep_reward": 933.0004272460938, "reward": 0.24803268909454346, "action": -1.7025823593139648}
{"mode": "train", "epochs": 2, "timestep": 3674, "ep_reward": 933.1199951171875, "reward": 0.11957699060440063, "action": -0.29102641344070435}
{"mode": "train", "epochs": 2, "timestep": 3675, "ep_reward": 933.1151123046875, "reward": -0.004887580871582031, "action": -1.3812685012817383}
{"mode": "train", "epochs": 2, "timestep": 3676, "ep_reward": 933.2557983398438, "reward": 0.14070725440979004, "action": -1.030843734741211}
{"mode": "train", "epochs": 2, "timestep": 3677, "ep_reward": 933.535400390625, "reward": 0.279629647731781, "action": -1.2586407661437988}
{"mode": "train", "epochs": 2, "timestep": 3678, "ep_reward": 933.9493408203125, "reward": 0.4139648675918579, "action": -0.12716156244277954}
{"mode": "train", "epochs": 2, "timestep": 3679, "ep_reward": 934.4992065429688, "reward": 0.549890398979187, "action": -1.378494143486023}
{"mode": "train", "epochs": 2, "timestep": 3680, "ep_reward": 935.150146484375, "reward": 0.6509385704994202, "action": -0.5029284358024597}
{"mode": "train", "epochs": 2, "timestep": 3681, "ep_reward": 935.8892211914062, "reward": 0.7390860319137573, "action": -1.5346994400024414}
{"mode": "train", "epochs": 2, "timestep": 3682, "ep_reward": 936.6844482421875, "reward": 0.7952173352241516, "action": -1.1974753141403198}
{"mode": "train", "epochs": 2, "timestep": 3683, "ep_reward": 937.519775390625, "reward": 0.835303544998169, "action": -1.106990098953247}
{"mode": "train", "epochs": 2, "timestep": 3684, "ep_reward": 938.3782348632812, "reward": 0.8584789037704468, "action": -1.3788121938705444}
{"mode": "train", "epochs": 2, "timestep": 3685, "ep_reward": 939.240966796875, "reward": 0.8627198934555054, "action": -1.621361255645752}
{"mode": "train", "epochs": 2, "timestep": 3686, "ep_reward": 940.0884399414062, "reward": 0.8474932312965393, "action": -0.4267117977142334}
{"mode": "train", "epochs": 2, "timestep": 3687, "ep_reward": 940.9115600585938, "reward": 0.8231396079063416, "action": -1.1946346759796143}
{"mode": "train", "epochs": 2, "timestep": 3688, "ep_reward": 941.6790161132812, "reward": 0.7674565315246582, "action": -1.4127795696258545}
{"mode": "train", "epochs": 2, "timestep": 3689, "ep_reward": 942.3568115234375, "reward": 0.6777839660644531, "action": -1.7710261344909668}
{"mode": "train", "epochs": 2, "timestep": 3690, "ep_reward": 942.9000854492188, "reward": 0.5432708263397217, "action": -0.47935086488723755}
{"mode": "train", "epochs": 2, "timestep": 3691, "ep_reward": 943.2921752929688, "reward": 0.3920970559120178, "action": -0.5431597232818604}
{"mode": "train", "epochs": 2, "timestep": 3692, "ep_reward": 943.5830688476562, "reward": 0.29091912508010864, "action": -0.12094855308532715}
{"mode": "train", "epochs": 2, "timestep": 3693, "ep_reward": 943.7527465820312, "reward": 0.169655442237854, "action": -1.032734990119934}
{"mode": "train", "epochs": 2, "timestep": 3694, "ep_reward": 943.7811889648438, "reward": 0.028443217277526855, "action": -1.1202473640441895}
{"mode": "train", "epochs": 2, "timestep": 3695, "ep_reward": 943.8701782226562, "reward": 0.08900177478790283, "action": -0.5438969135284424}
{"mode": "train", "epochs": 2, "timestep": 3696, "ep_reward": 944.102783203125, "reward": 0.23262596130371094, "action": -0.6648634076118469}
{"mode": "train", "epochs": 2, "timestep": 3697, "ep_reward": 944.477783203125, "reward": 0.3749934434890747, "action": -0.29359906911849976}
{"mode": "train", "epochs": 2, "timestep": 3698, "ep_reward": 944.9900512695312, "reward": 0.5122889280319214, "action": 0.04549109935760498}
{"mode": "train", "epochs": 2, "timestep": 3699, "ep_reward": 945.6241455078125, "reward": 0.6340981125831604, "action": -1.669958472251892}
{"mode": "train", "epochs": 2, "timestep": 3700, "ep_reward": 946.3405151367188, "reward": 0.716394305229187, "action": -1.3437806367874146}
{"mode": "train", "epochs": 2, "timestep": 3701, "ep_reward": 947.1229248046875, "reward": 0.7824375629425049, "action": -0.8692823052406311}
{"mode": "train", "epochs": 2, "timestep": 3702, "ep_reward": 947.9564208984375, "reward": 0.8335086107254028, "action": -1.2403079271316528}
{"mode": "train", "epochs": 2, "timestep": 3703, "ep_reward": 948.8209838867188, "reward": 0.8645522594451904, "action": -0.5098475217819214}
{"mode": "train", "epochs": 2, "timestep": 3704, "ep_reward": 949.7073364257812, "reward": 0.8863223791122437, "action": -1.118103265762329}
{"mode": "train", "epochs": 2, "timestep": 3705, "ep_reward": 950.596923828125, "reward": 0.8896104097366333, "action": -1.5074883699417114}
{"mode": "train", "epochs": 2, "timestep": 3706, "ep_reward": 951.4725952148438, "reward": 0.875669538974762, "action": -1.4262679815292358}
{"mode": "train", "epochs": 2, "timestep": 3707, "ep_reward": 952.3178100585938, "reward": 0.8452007174491882, "action": -1.03151535987854}
{"mode": "train", "epochs": 2, "timestep": 3708, "ep_reward": 953.114501953125, "reward": 0.7966966032981873, "action": -0.7173660397529602}
{"mode": "train", "epochs": 2, "timestep": 3709, "ep_reward": 953.8390502929688, "reward": 0.7245232462882996, "action": -1.0684499740600586}
{"mode": "train", "epochs": 2, "timestep": 3710, "ep_reward": 954.453857421875, "reward": 0.614812970161438, "action": -0.8973117470741272}
{"mode": "train", "epochs": 2, "timestep": 3711, "ep_reward": 954.9215698242188, "reward": 0.4677276015281677, "action": -0.1510571837425232}
{"mode": "train", "epochs": 2, "timestep": 3712, "ep_reward": 955.245361328125, "reward": 0.3237687945365906, "action": -0.7535133361816406}
{"mode": "train", "epochs": 2, "timestep": 3713, "ep_reward": 955.4539184570312, "reward": 0.2085382342338562, "action": -1.5478250980377197}
{"mode": "train", "epochs": 2, "timestep": 3714, "ep_reward": 955.5274047851562, "reward": 0.07349967956542969, "action": -1.055234432220459}
{"mode": "train", "epochs": 2, "timestep": 3715, "ep_reward": 955.5718994140625, "reward": 0.04448932409286499, "action": -1.4743382930755615}
{"mode": "train", "epochs": 2, "timestep": 3716, "ep_reward": 955.7555541992188, "reward": 0.18362730741500854, "action": -0.9177055358886719}
{"mode": "train", "epochs": 2, "timestep": 3717, "ep_reward": 956.0803833007812, "reward": 0.32480818033218384, "action": -0.8430842161178589}
{"mode": "train", "epochs": 2, "timestep": 3718, "ep_reward": 956.5416870117188, "reward": 0.4613262414932251, "action": -0.57804274559021}
{"mode": "train", "epochs": 2, "timestep": 3719, "ep_reward": 957.127197265625, "reward": 0.585486650466919, "action": -1.2044247388839722}
{"mode": "train", "epochs": 2, "timestep": 3720, "ep_reward": 957.8087158203125, "reward": 0.681525707244873, "action": 0.05683004856109619}
{"mode": "train", "epochs": 2, "timestep": 3721, "ep_reward": 958.5758666992188, "reward": 0.7671610713005066, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3722, "ep_reward": 959.3880615234375, "reward": 0.81217360496521, "action": -1.5774400234222412}
{"mode": "train", "epochs": 2, "timestep": 3723, "ep_reward": 960.2315063476562, "reward": 0.8434655070304871, "action": -0.82403564453125}
{"mode": "train", "epochs": 2, "timestep": 3724, "ep_reward": 961.095703125, "reward": 0.8641963005065918, "action": -1.0026824474334717}
{"mode": "train", "epochs": 2, "timestep": 3725, "ep_reward": 961.9628295898438, "reward": 0.8671108484268188, "action": -0.5718380212783813}
{"mode": "train", "epochs": 2, "timestep": 3726, "ep_reward": 962.8197631835938, "reward": 0.8569356203079224, "action": -0.5419214963912964}
{"mode": "train", "epochs": 2, "timestep": 3727, "ep_reward": 963.6480712890625, "reward": 0.828324019908905, "action": -1.2556699514389038}
{"mode": "train", "epochs": 2, "timestep": 3728, "ep_reward": 964.4176635742188, "reward": 0.7695963978767395, "action": -0.5042010545730591}
{"mode": "train", "epochs": 2, "timestep": 3729, "ep_reward": 965.1068725585938, "reward": 0.6892213821411133, "action": -0.9870655536651611}
{"mode": "train", "epochs": 2, "timestep": 3730, "ep_reward": 965.67431640625, "reward": 0.5674705505371094, "action": -0.7181373834609985}
{"mode": "train", "epochs": 2, "timestep": 3731, "ep_reward": 966.0833740234375, "reward": 0.40903061628341675, "action": 0.11652719974517822}
{"mode": "train", "epochs": 2, "timestep": 3732, "ep_reward": 966.3721313476562, "reward": 0.2887459397315979, "action": -1.2058452367782593}
{"mode": "train", "epochs": 2, "timestep": 3733, "ep_reward": 966.539306640625, "reward": 0.16715991497039795, "action": -1.2954800128936768}
{"mode": "train", "epochs": 2, "timestep": 3734, "ep_reward": 966.56494140625, "reward": 0.02565711736679077, "action": -0.7290830612182617}
{"mode": "train", "epochs": 2, "timestep": 3735, "ep_reward": 966.6566162109375, "reward": 0.09166765213012695, "action": -0.6086869239807129}
{"mode": "train", "epochs": 2, "timestep": 3736, "ep_reward": 966.89111328125, "reward": 0.23448151350021362, "action": -1.4018640518188477}
{"mode": "train", "epochs": 2, "timestep": 3737, "ep_reward": 967.259033203125, "reward": 0.3679087162017822, "action": -1.2957179546356201}
{"mode": "train", "epochs": 2, "timestep": 3738, "ep_reward": 967.7544555664062, "reward": 0.4954201579093933, "action": -0.8553356528282166}
{"mode": "train", "epochs": 2, "timestep": 3739, "ep_reward": 968.3658447265625, "reward": 0.6113965511322021, "action": -1.545074701309204}
{"mode": "train", "epochs": 2, "timestep": 3740, "ep_reward": 969.0639038085938, "reward": 0.6980640888214111, "action": -1.2343279123306274}
{"mode": "train", "epochs": 2, "timestep": 3741, "ep_reward": 969.8298950195312, "reward": 0.7659670114517212, "action": -0.310092568397522}
{"mode": "train", "epochs": 2, "timestep": 3742, "ep_reward": 970.6505126953125, "reward": 0.8206124901771545, "action": -1.3375078439712524}
{"mode": "train", "epochs": 2, "timestep": 3743, "ep_reward": 971.4967651367188, "reward": 0.8462475538253784, "action": -1.2225514650344849}
{"mode": "train", "epochs": 2, "timestep": 3744, "ep_reward": 972.3521118164062, "reward": 0.8553637862205505, "action": -0.47464221715927124}
{"mode": "train", "epochs": 2, "timestep": 3745, "ep_reward": 973.205322265625, "reward": 0.8532241582870483, "action": -1.3023312091827393}
{"mode": "train", "epochs": 2, "timestep": 3746, "ep_reward": 974.029541015625, "reward": 0.8242239952087402, "action": -0.8654443621635437}
{"mode": "train", "epochs": 2, "timestep": 3747, "ep_reward": 974.80517578125, "reward": 0.7756073474884033, "action": -1.2002549171447754}
{"mode": "train", "epochs": 2, "timestep": 3748, "ep_reward": 975.4987182617188, "reward": 0.6935403347015381, "action": -1.0681449174880981}
{"mode": "train", "epochs": 2, "timestep": 3749, "ep_reward": 976.0744018554688, "reward": 0.5756593942642212, "action": -0.39507967233657837}
{"mode": "train", "epochs": 2, "timestep": 3750, "ep_reward": 976.5003051757812, "reward": 0.4258941411972046, "action": -1.5191445350646973}
{"mode": "train", "epochs": 2, "timestep": 3751, "ep_reward": 976.810791015625, "reward": 0.31050002574920654, "action": -1.0500043630599976}
{"mode": "train", "epochs": 2, "timestep": 3752, "ep_reward": 977.0037231445312, "reward": 0.19294637441635132, "action": -0.523520290851593}
{"mode": "train", "epochs": 2, "timestep": 3753, "ep_reward": 977.0590209960938, "reward": 0.055296361446380615, "action": -0.9739769101142883}
{"mode": "train", "epochs": 2, "timestep": 3754, "ep_reward": 977.1219482421875, "reward": 0.06295770406723022, "action": -0.9879010915756226}
{"mode": "train", "epochs": 2, "timestep": 3755, "ep_reward": 977.3222045898438, "reward": 0.20024466514587402, "action": -0.926557719707489}
{"mode": "train", "epochs": 2, "timestep": 3756, "ep_reward": 977.6633911132812, "reward": 0.3412055969238281, "action": -1.6674096584320068}
{"mode": "train", "epochs": 2, "timestep": 3757, "ep_reward": 978.130126953125, "reward": 0.46676206588745117, "action": -0.9203661680221558}
{"mode": "train", "epochs": 2, "timestep": 3758, "ep_reward": 978.7169799804688, "reward": 0.58682781457901, "action": -0.9208220839500427}
{"mode": "train", "epochs": 2, "timestep": 3759, "ep_reward": 979.40185546875, "reward": 0.6848934888839722, "action": -0.6315321922302246}
{"mode": "train", "epochs": 2, "timestep": 3760, "ep_reward": 980.1640625, "reward": 0.762195885181427, "action": -0.19550234079360962}
{"mode": "train", "epochs": 2, "timestep": 3761, "ep_reward": 980.9845581054688, "reward": 0.8205136060714722, "action": -1.7675151824951172}
{"mode": "train", "epochs": 2, "timestep": 3762, "ep_reward": 981.8302612304688, "reward": 0.8456828594207764, "action": -0.283702552318573}
{"mode": "train", "epochs": 2, "timestep": 3763, "ep_reward": 982.69677734375, "reward": 0.8664894104003906, "action": -0.5350232124328613}
{"mode": "train", "epochs": 2, "timestep": 3764, "ep_reward": 983.5653686523438, "reward": 0.8686028718948364, "action": -0.8562041521072388}
{"mode": "train", "epochs": 2, "timestep": 3765, "ep_reward": 984.4163208007812, "reward": 0.8509784936904907, "action": -1.2111351490020752}
{"mode": "train", "epochs": 2, "timestep": 3766, "ep_reward": 985.2260131835938, "reward": 0.8096665143966675, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3767, "ep_reward": 985.9591064453125, "reward": 0.7331186532974243, "action": -0.8499741554260254}
{"mode": "train", "epochs": 2, "timestep": 3768, "ep_reward": 986.5934448242188, "reward": 0.6343112587928772, "action": -1.932815670967102}
{"mode": "train", "epochs": 2, "timestep": 3769, "ep_reward": 987.0730590820312, "reward": 0.47959405183792114, "action": -0.5480169057846069}
{"mode": "train", "epochs": 2, "timestep": 3770, "ep_reward": 987.4246826171875, "reward": 0.3515964150428772, "action": -1.0273714065551758}
{"mode": "train", "epochs": 2, "timestep": 3771, "ep_reward": 987.6666870117188, "reward": 0.24198603630065918, "action": -0.1820746660232544}
{"mode": "train", "epochs": 2, "timestep": 3772, "ep_reward": 987.7789916992188, "reward": 0.11228621006011963, "action": -0.6351275444030762}
{"mode": "train", "epochs": 2, "timestep": 3773, "ep_reward": 987.7821655273438, "reward": 0.003159046173095703, "action": -1.6606998443603516}
{"mode": "train", "epochs": 2, "timestep": 3774, "ep_reward": 987.9299926757812, "reward": 0.14780426025390625, "action": -0.6204217672348022}
{"mode": "train", "epochs": 2, "timestep": 3775, "ep_reward": 988.221923828125, "reward": 0.29192906618118286, "action": -1.4407405853271484}
{"mode": "train", "epochs": 2, "timestep": 3776, "ep_reward": 988.6446533203125, "reward": 0.4227294325828552, "action": -0.2212243676185608}
{"mode": "train", "epochs": 2, "timestep": 3777, "ep_reward": 989.2009887695312, "reward": 0.5563168525695801, "action": -0.8017870187759399}
{"mode": "train", "epochs": 2, "timestep": 3778, "ep_reward": 989.8629150390625, "reward": 0.6619166731834412, "action": -1.8482460975646973}
{"mode": "train", "epochs": 2, "timestep": 3779, "ep_reward": 990.5983276367188, "reward": 0.7354317903518677, "action": 0.09345757961273193}
{"mode": "train", "epochs": 2, "timestep": 3780, "ep_reward": 991.4044189453125, "reward": 0.8061070442199707, "action": -1.7296998500823975}
{"mode": "train", "epochs": 2, "timestep": 3781, "ep_reward": 992.2448120117188, "reward": 0.840371310710907, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3782, "ep_reward": 993.1010131835938, "reward": 0.8561848998069763, "action": -0.26916515827178955}
{"mode": "train", "epochs": 2, "timestep": 3783, "ep_reward": 993.97119140625, "reward": 0.8701549768447876, "action": -1.3127915859222412}
{"mode": "train", "epochs": 2, "timestep": 3784, "ep_reward": 994.8300170898438, "reward": 0.8587994575500488, "action": -0.9884905815124512}
{"mode": "train", "epochs": 2, "timestep": 3785, "ep_reward": 995.6613159179688, "reward": 0.8312989473342896, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3786, "ep_reward": 996.4314575195312, "reward": 0.7701610922813416, "action": 0.18594706058502197}
{"mode": "train", "epochs": 2, "timestep": 3787, "ep_reward": 997.13427734375, "reward": 0.7028419971466064, "action": -0.8465272188186646}
{"mode": "train", "epochs": 2, "timestep": 3788, "ep_reward": 997.723876953125, "reward": 0.5895954370498657, "action": -0.2632337212562561}
{"mode": "train", "epochs": 2, "timestep": 3789, "ep_reward": 998.1691284179688, "reward": 0.4452213644981384, "action": -1.0730565786361694}
{"mode": "train", "epochs": 2, "timestep": 3790, "ep_reward": 998.480712890625, "reward": 0.3115651607513428, "action": -1.2211753129959106}
{"mode": "train", "epochs": 2, "timestep": 3791, "ep_reward": 998.6748657226562, "reward": 0.1941811442375183, "action": -1.0922179222106934}
{"mode": "train", "epochs": 2, "timestep": 3792, "ep_reward": 998.7315063476562, "reward": 0.05663430690765381, "action": -1.8599718809127808}
{"mode": "train", "epochs": 2, "timestep": 3793, "ep_reward": 998.7928466796875, "reward": 0.06136608123779297, "action": -1.6307358741760254}
{"mode": "train", "epochs": 2, "timestep": 3794, "ep_reward": 998.9910888671875, "reward": 0.19823122024536133, "action": -1.054997205734253}
{"mode": "train", "epochs": 2, "timestep": 3795, "ep_reward": 999.3289184570312, "reward": 0.33784812688827515, "action": -1.091291904449463}
{"mode": "train", "epochs": 2, "timestep": 3796, "ep_reward": 999.7996215820312, "reward": 0.4707329273223877, "action": -1.0428657531738281}
{"mode": "train", "epochs": 2, "timestep": 3797, "ep_reward": 1000.3881225585938, "reward": 0.5884766578674316, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3798, "ep_reward": 1001.063232421875, "reward": 0.6751067638397217, "action": -1.2598739862442017}
{"mode": "train", "epochs": 2, "timestep": 3799, "ep_reward": 1001.81103515625, "reward": 0.7478287220001221, "action": -0.844059944152832}
{"mode": "train", "epochs": 2, "timestep": 3800, "ep_reward": 1002.61279296875, "reward": 0.8017790913581848, "action": -1.8075677156448364}
{"mode": "train", "epochs": 2, "timestep": 3801, "ep_reward": 1003.4389038085938, "reward": 0.8260976672172546, "action": 0.16435503959655762}
{"mode": "train", "epochs": 2, "timestep": 3802, "ep_reward": 1004.2879028320312, "reward": 0.8490248918533325, "action": -0.6840286254882812}
{"mode": "train", "epochs": 2, "timestep": 3803, "ep_reward": 1005.133056640625, "reward": 0.8451457023620605, "action": -0.3784602880477905}
{"mode": "train", "epochs": 2, "timestep": 3804, "ep_reward": 1005.957275390625, "reward": 0.8242300748825073, "action": -1.06585693359375}
{"mode": "train", "epochs": 2, "timestep": 3805, "ep_reward": 1006.73046875, "reward": 0.7732155323028564, "action": -0.6565281748771667}
{"mode": "train", "epochs": 2, "timestep": 3806, "ep_reward": 1007.4275512695312, "reward": 0.6970656514167786, "action": -1.3084080219268799}
{"mode": "train", "epochs": 2, "timestep": 3807, "ep_reward": 1008.0039672851562, "reward": 0.5763856172561646, "action": -1.3191790580749512}
{"mode": "train", "epochs": 2, "timestep": 3808, "ep_reward": 1008.415771484375, "reward": 0.4118303060531616, "action": -0.6039810180664062}
{"mode": "train", "epochs": 2, "timestep": 3809, "ep_reward": 1008.72412109375, "reward": 0.3083644509315491, "action": -0.9109381437301636}
{"mode": "train", "epochs": 2, "timestep": 3810, "ep_reward": 1008.91455078125, "reward": 0.1904115080833435, "action": 0.03492701053619385}
{"mode": "train", "epochs": 2, "timestep": 3811, "ep_reward": 1008.9669189453125, "reward": 0.052362024784088135, "action": -0.822211503982544}
{"mode": "train", "epochs": 2, "timestep": 3812, "ep_reward": 1009.03271484375, "reward": 0.06581062078475952, "action": -1.4460586309432983}
{"mode": "train", "epochs": 2, "timestep": 3813, "ep_reward": 1009.2348022460938, "reward": 0.2021004557609558, "action": -0.3398624062538147}
{"mode": "train", "epochs": 2, "timestep": 3814, "ep_reward": 1009.5853881835938, "reward": 0.3505793809890747, "action": -0.7149299383163452}
{"mode": "train", "epochs": 2, "timestep": 3815, "ep_reward": 1010.0711059570312, "reward": 0.48573988676071167, "action": -1.3061259984970093}
{"mode": "train", "epochs": 2, "timestep": 3816, "ep_reward": 1010.6690063476562, "reward": 0.5979028940200806, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3817, "ep_reward": 1011.352294921875, "reward": 0.6832937002182007, "action": 0.8303141593933105}
{"mode": "train", "epochs": 2, "timestep": 3818, "ep_reward": 1012.1272583007812, "reward": 0.7749502658843994, "action": -0.7708936333656311}
{"mode": "train", "epochs": 2, "timestep": 3819, "ep_reward": 1012.9550170898438, "reward": 0.8277555108070374, "action": -0.46927231550216675}
{"mode": "train", "epochs": 2, "timestep": 3820, "ep_reward": 1013.81982421875, "reward": 0.8648000955581665, "action": -1.0256644487380981}
{"mode": "train", "epochs": 2, "timestep": 3821, "ep_reward": 1014.70166015625, "reward": 0.8818079233169556, "action": -1.2074990272521973}
{"mode": "train", "epochs": 2, "timestep": 3822, "ep_reward": 1015.5849609375, "reward": 0.8832878470420837, "action": -0.952320396900177}
{"mode": "train", "epochs": 2, "timestep": 3823, "ep_reward": 1016.4568481445312, "reward": 0.8719084858894348, "action": -1.1562340259552002}
{"mode": "train", "epochs": 2, "timestep": 3824, "ep_reward": 1017.29833984375, "reward": 0.8414814472198486, "action": -1.120154619216919}
{"mode": "train", "epochs": 2, "timestep": 3825, "ep_reward": 1018.0875244140625, "reward": 0.7891913056373596, "action": -1.8710074424743652}
{"mode": "train", "epochs": 2, "timestep": 3826, "ep_reward": 1018.7869873046875, "reward": 0.6994575262069702, "action": -1.4585258960723877}
{"mode": "train", "epochs": 2, "timestep": 3827, "ep_reward": 1019.3629150390625, "reward": 0.5759328603744507, "action": -0.6768689155578613}
{"mode": "train", "epochs": 2, "timestep": 3828, "ep_reward": 1019.7840576171875, "reward": 0.4211302399635315, "action": -0.7461174130439758}
{"mode": "train", "epochs": 2, "timestep": 3829, "ep_reward": 1020.087158203125, "reward": 0.30310511589050293, "action": -0.8251378536224365}
{"mode": "train", "epochs": 2, "timestep": 3830, "ep_reward": 1020.2713012695312, "reward": 0.1841697096824646, "action": -0.167674720287323}
{"mode": "train", "epochs": 2, "timestep": 3831, "ep_reward": 1020.31640625, "reward": 0.045082926750183105, "action": -1.3259748220443726}
{"mode": "train", "epochs": 2, "timestep": 3832, "ep_reward": 1020.389404296875, "reward": 0.07299971580505371, "action": -0.5152658820152283}
{"mode": "train", "epochs": 2, "timestep": 3833, "ep_reward": 1020.6057739257812, "reward": 0.21634191274642944, "action": -1.7118308544158936}
{"mode": "train", "epochs": 2, "timestep": 3834, "ep_reward": 1020.9521484375, "reward": 0.3463619351387024, "action": -0.85206538438797}
{"mode": "train", "epochs": 2, "timestep": 3835, "ep_reward": 1021.4336547851562, "reward": 0.4814947843551636, "action": -0.03424030542373657}
{"mode": "train", "epochs": 2, "timestep": 3836, "ep_reward": 1022.0423583984375, "reward": 0.6087312698364258, "action": -0.44579213857650757}
{"mode": "train", "epochs": 2, "timestep": 3837, "ep_reward": 1022.7498168945312, "reward": 0.7074438333511353, "action": -1.0326379537582397}
{"mode": "train", "epochs": 2, "timestep": 3838, "ep_reward": 1023.5272216796875, "reward": 0.7774268388748169, "action": -1.7396221160888672}
{"mode": "train", "epochs": 2, "timestep": 3839, "ep_reward": 1024.3487548828125, "reward": 0.8215491771697998, "action": -1.017111897468567}
{"mode": "train", "epochs": 2, "timestep": 3840, "ep_reward": 1025.203125, "reward": 0.8543096780776978, "action": -1.6309034824371338}
{"mode": "train", "epochs": 2, "timestep": 3841, "ep_reward": 1026.06884765625, "reward": 0.8657297492027283, "action": -1.3483121395111084}
{"mode": "train", "epochs": 2, "timestep": 3842, "ep_reward": 1026.9322509765625, "reward": 0.8633834719657898, "action": -1.2813016176223755}
{"mode": "train", "epochs": 2, "timestep": 3843, "ep_reward": 1027.7760009765625, "reward": 0.8437381982803345, "action": -1.6353669166564941}
{"mode": "train", "epochs": 2, "timestep": 3844, "ep_reward": 1028.5750732421875, "reward": 0.7990819215774536, "action": -0.8327916860580444}
{"mode": "train", "epochs": 2, "timestep": 3845, "ep_reward": 1029.3101806640625, "reward": 0.7350497245788574, "action": -1.6418453454971313}
{"mode": "train", "epochs": 2, "timestep": 3846, "ep_reward": 1029.9373779296875, "reward": 0.6272001266479492, "action": -0.6389420628547668}
{"mode": "train", "epochs": 2, "timestep": 3847, "ep_reward": 1030.428466796875, "reward": 0.4910849928855896, "action": -0.523665189743042}
{"mode": "train", "epochs": 2, "timestep": 3848, "ep_reward": 1030.78369140625, "reward": 0.3552130460739136, "action": -1.6688082218170166}
{"mode": "train", "epochs": 2, "timestep": 3849, "ep_reward": 1031.0299072265625, "reward": 0.24621319770812988, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3850, "ep_reward": 1031.1473388671875, "reward": 0.11743426322937012, "action": -1.2802073955535889}
{"mode": "train", "epochs": 2, "timestep": 3851, "ep_reward": 1031.144775390625, "reward": -0.00251162052154541, "action": -0.734115481376648}
{"mode": "train", "epochs": 2, "timestep": 3852, "ep_reward": 1031.2874755859375, "reward": 0.14273720979690552, "action": -0.7155733108520508}
{"mode": "train", "epochs": 2, "timestep": 3853, "ep_reward": 1031.572998046875, "reward": 0.28557711839675903, "action": -1.4362925291061401}
{"mode": "train", "epochs": 2, "timestep": 3854, "ep_reward": 1031.98974609375, "reward": 0.41679465770721436, "action": -1.3527519702911377}
{"mode": "train", "epochs": 2, "timestep": 3855, "ep_reward": 1032.5281982421875, "reward": 0.5384231805801392, "action": -0.9967368841171265}
{"mode": "train", "epochs": 2, "timestep": 3856, "ep_reward": 1033.173583984375, "reward": 0.6454143524169922, "action": -1.0889736413955688}
{"mode": "train", "epochs": 2, "timestep": 3857, "ep_reward": 1033.9022216796875, "reward": 0.728670597076416, "action": -0.33426302671432495}
{"mode": "train", "epochs": 2, "timestep": 3858, "ep_reward": 1034.6983642578125, "reward": 0.796108603477478, "action": -1.8435673713684082}
{"mode": "train", "epochs": 2, "timestep": 3859, "ep_reward": 1035.5274658203125, "reward": 0.8290945887565613, "action": -1.4726324081420898}
{"mode": "train", "epochs": 2, "timestep": 3860, "ep_reward": 1036.375, "reward": 0.8474732637405396, "action": -1.0363414287567139}
{"mode": "train", "epochs": 2, "timestep": 3861, "ep_reward": 1037.226806640625, "reward": 0.8517978191375732, "action": -0.6456035375595093}
{"mode": "train", "epochs": 2, "timestep": 3862, "ep_reward": 1038.0677490234375, "reward": 0.8409038186073303, "action": -1.240006446838379}
{"mode": "train", "epochs": 2, "timestep": 3863, "ep_reward": 1038.8709716796875, "reward": 0.803208589553833, "action": -0.4562298655509949}
{"mode": "train", "epochs": 2, "timestep": 3864, "ep_reward": 1039.6185302734375, "reward": 0.7475473880767822, "action": -0.5561050176620483}
{"mode": "train", "epochs": 2, "timestep": 3865, "ep_reward": 1040.2783203125, "reward": 0.6597342491149902, "action": -1.260272741317749}
{"mode": "train", "epochs": 2, "timestep": 3866, "ep_reward": 1040.802734375, "reward": 0.5244557857513428, "action": -1.5235198736190796}
{"mode": "train", "epochs": 2, "timestep": 3867, "ep_reward": 1041.1754150390625, "reward": 0.37274080514907837, "action": -1.058570146560669}
{"mode": "train", "epochs": 2, "timestep": 3868, "ep_reward": 1041.44287109375, "reward": 0.26740753650665283, "action": -1.0398612022399902}
{"mode": "train", "epochs": 2, "timestep": 3869, "ep_reward": 1041.5848388671875, "reward": 0.1420108675956726, "action": -1.4199094772338867}
{"mode": "train", "epochs": 2, "timestep": 3870, "ep_reward": 1041.5814208984375, "reward": -0.0034044981002807617, "action": -1.7924602031707764}
{"mode": "train", "epochs": 2, "timestep": 3871, "ep_reward": 1041.6995849609375, "reward": 0.11817014217376709, "action": 0.501530647277832}
{"mode": "train", "epochs": 2, "timestep": 3872, "ep_reward": 1041.9749755859375, "reward": 0.2754164934158325, "action": -0.9399309754371643}
{"mode": "train", "epochs": 2, "timestep": 3873, "ep_reward": 1042.3856201171875, "reward": 0.41062235832214355, "action": -0.9287437200546265}
{"mode": "train", "epochs": 2, "timestep": 3874, "ep_reward": 1042.921630859375, "reward": 0.5359687805175781, "action": -0.8221265077590942}
{"mode": "train", "epochs": 2, "timestep": 3875, "ep_reward": 1043.566650390625, "reward": 0.6449782848358154, "action": -0.7230416536331177}
{"mode": "train", "epochs": 2, "timestep": 3876, "ep_reward": 1044.30029296875, "reward": 0.7336428165435791, "action": -0.4008752107620239}
{"mode": "train", "epochs": 2, "timestep": 3877, "ep_reward": 1045.1038818359375, "reward": 0.8035398721694946, "action": -0.9088740348815918}
{"mode": "train", "epochs": 2, "timestep": 3878, "ep_reward": 1045.9537353515625, "reward": 0.8499069809913635, "action": -1.1169995069503784}
{"mode": "train", "epochs": 2, "timestep": 3879, "ep_reward": 1046.8328857421875, "reward": 0.8790941834449768, "action": -1.39081609249115}
{"mode": "train", "epochs": 2, "timestep": 3880, "ep_reward": 1047.7259521484375, "reward": 0.8931177258491516, "action": -0.08092474937438965}
{"mode": "train", "epochs": 2, "timestep": 3881, "ep_reward": 1048.630126953125, "reward": 0.9041823744773865, "action": -1.0392329692840576}
{"mode": "train", "epochs": 2, "timestep": 3882, "ep_reward": 1049.526123046875, "reward": 0.8960261940956116, "action": -0.8193531632423401}
{"mode": "train", "epochs": 2, "timestep": 3883, "ep_reward": 1050.40185546875, "reward": 0.8757027983665466, "action": -0.7194381356239319}
{"mode": "train", "epochs": 2, "timestep": 3884, "ep_reward": 1051.2412109375, "reward": 0.8393554091453552, "action": 0.16665339469909668}
{"mode": "train", "epochs": 2, "timestep": 3885, "ep_reward": 1052.031982421875, "reward": 0.7907310128211975, "action": -0.3606780171394348}
{"mode": "train", "epochs": 2, "timestep": 3886, "ep_reward": 1052.7440185546875, "reward": 0.7120609283447266, "action": -0.8130433559417725}
{"mode": "train", "epochs": 2, "timestep": 3887, "ep_reward": 1053.34033203125, "reward": 0.5963531136512756, "action": -0.8472902774810791}
{"mode": "train", "epochs": 2, "timestep": 3888, "ep_reward": 1053.783447265625, "reward": 0.4431643486022949, "action": -0.4275447726249695}
{"mode": "train", "epochs": 2, "timestep": 3889, "ep_reward": 1054.066162109375, "reward": 0.2826552987098694, "action": -0.7459043860435486}
{"mode": "train", "epochs": 2, "timestep": 3890, "ep_reward": 1054.2259521484375, "reward": 0.1598171591758728, "action": -1.8078677654266357}
{"mode": "train", "epochs": 2, "timestep": 3891, "ep_reward": 1054.2431640625, "reward": 0.017258882522583008, "action": -1.2094206809997559}
{"mode": "train", "epochs": 2, "timestep": 3892, "ep_reward": 1054.3426513671875, "reward": 0.0994303822517395, "action": -0.8782885670661926}
{"mode": "train", "epochs": 2, "timestep": 3893, "ep_reward": 1054.5819091796875, "reward": 0.2392008900642395, "action": -0.8422073721885681}
{"mode": "train", "epochs": 2, "timestep": 3894, "ep_reward": 1054.961669921875, "reward": 0.37975049018859863, "action": -1.7327651977539062}
{"mode": "train", "epochs": 2, "timestep": 3895, "ep_reward": 1055.462158203125, "reward": 0.5005007386207581, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3896, "ep_reward": 1056.0654296875, "reward": 0.6032666563987732, "action": -0.00578153133392334}
{"mode": "train", "epochs": 2, "timestep": 3897, "ep_reward": 1056.7718505859375, "reward": 0.7063726186752319, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3898, "ep_reward": 1057.5367431640625, "reward": 0.7649242877960205, "action": -0.5503807067871094}
{"mode": "train", "epochs": 2, "timestep": 3899, "ep_reward": 1058.35302734375, "reward": 0.8163007497787476, "action": -1.047719955444336}
{"mode": "train", "epochs": 2, "timestep": 3900, "ep_reward": 1059.1959228515625, "reward": 0.8428711891174316, "action": -0.7777607440948486}
{"mode": "train", "epochs": 2, "timestep": 3901, "ep_reward": 1060.0491943359375, "reward": 0.8532577753067017, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3902, "ep_reward": 1060.883056640625, "reward": 0.8339030146598816, "action": -1.4351778030395508}
{"mode": "train", "epochs": 2, "timestep": 3903, "ep_reward": 1061.68017578125, "reward": 0.7971373796463013, "action": -1.0417720079421997}
{"mode": "train", "epochs": 2, "timestep": 3904, "ep_reward": 1062.4169921875, "reward": 0.7368510961532593, "action": -0.7366517186164856}
{"mode": "train", "epochs": 2, "timestep": 3905, "ep_reward": 1063.0634765625, "reward": 0.6465270519256592, "action": -1.6264333724975586}
{"mode": "train", "epochs": 2, "timestep": 3906, "ep_reward": 1063.56689453125, "reward": 0.5033870935440063, "action": -1.213941216468811}
{"mode": "train", "epochs": 2, "timestep": 3907, "ep_reward": 1063.94189453125, "reward": 0.37499791383743286, "action": -1.1490833759307861}
{"mode": "train", "epochs": 2, "timestep": 3908, "ep_reward": 1064.2120361328125, "reward": 0.27018600702285767, "action": -0.759493350982666}
{"mode": "train", "epochs": 2, "timestep": 3909, "ep_reward": 1064.3572998046875, "reward": 0.1452333927154541, "action": -1.4304814338684082}
{"mode": "train", "epochs": 2, "timestep": 3910, "ep_reward": 1064.3577880859375, "reward": 0.00043851137161254883, "action": -0.9758347272872925}
{"mode": "train", "epochs": 2, "timestep": 3911, "ep_reward": 1064.4725341796875, "reward": 0.11475658416748047, "action": -1.3267722129821777}
{"mode": "train", "epochs": 2, "timestep": 3912, "ep_reward": 1064.7218017578125, "reward": 0.24922138452529907, "action": -1.8304643630981445}
{"mode": "train", "epochs": 2, "timestep": 3913, "ep_reward": 1065.0999755859375, "reward": 0.37815964221954346, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3914, "ep_reward": 1065.5972900390625, "reward": 0.49731600284576416, "action": -1.4888793230056763}
{"mode": "train", "epochs": 2, "timestep": 3915, "ep_reward": 1066.2032470703125, "reward": 0.6060059070587158, "action": -1.3136346340179443}
{"mode": "train", "epochs": 2, "timestep": 3916, "ep_reward": 1066.89697265625, "reward": 0.6937392950057983, "action": -0.103756844997406}
{"mode": "train", "epochs": 2, "timestep": 3917, "ep_reward": 1067.6658935546875, "reward": 0.7689777612686157, "action": -0.658439576625824}
{"mode": "train", "epochs": 2, "timestep": 3918, "ep_reward": 1068.47998046875, "reward": 0.8140393495559692, "action": -1.3098722696304321}
{"mode": "train", "epochs": 2, "timestep": 3919, "ep_reward": 1069.31201171875, "reward": 0.8319823741912842, "action": -1.0321134328842163}
{"mode": "train", "epochs": 2, "timestep": 3920, "ep_reward": 1070.1444091796875, "reward": 0.8324089050292969, "action": -0.25491863489151}
{"mode": "train", "epochs": 2, "timestep": 3921, "ep_reward": 1070.963623046875, "reward": 0.819177508354187, "action": -0.6116918921470642}
{"mode": "train", "epochs": 2, "timestep": 3922, "ep_reward": 1071.7425537109375, "reward": 0.7789257168769836, "action": -1.0220155715942383}
{"mode": "train", "epochs": 2, "timestep": 3923, "ep_reward": 1072.44775390625, "reward": 0.7051578760147095, "action": -1.421716332435608}
{"mode": "train", "epochs": 2, "timestep": 3924, "ep_reward": 1073.0369873046875, "reward": 0.5892544984817505, "action": -1.1299760341644287}
{"mode": "train", "epochs": 2, "timestep": 3925, "ep_reward": 1073.47021484375, "reward": 0.4332152009010315, "action": -1.0210840702056885}
{"mode": "train", "epochs": 2, "timestep": 3926, "ep_reward": 1073.80029296875, "reward": 0.3300209045410156, "action": -0.5036903619766235}
{"mode": "train", "epochs": 2, "timestep": 3927, "ep_reward": 1074.016357421875, "reward": 0.2160571813583374, "action": -0.9473252892494202}
{"mode": "train", "epochs": 2, "timestep": 3928, "ep_reward": 1074.0985107421875, "reward": 0.08216136693954468, "action": -0.6438174247741699}
{"mode": "train", "epochs": 2, "timestep": 3929, "ep_reward": 1074.134033203125, "reward": 0.03551691770553589, "action": -1.7170219421386719}
{"mode": "train", "epochs": 2, "timestep": 3930, "ep_reward": 1074.3099365234375, "reward": 0.17592722177505493, "action": -0.5873042345046997}
{"mode": "train", "epochs": 2, "timestep": 3931, "ep_reward": 1074.6309814453125, "reward": 0.32099592685699463, "action": -1.36151123046875}
{"mode": "train", "epochs": 2, "timestep": 3932, "ep_reward": 1075.0819091796875, "reward": 0.4508700370788574, "action": -1.9102036952972412}
{"mode": "train", "epochs": 2, "timestep": 3933, "ep_reward": 1075.6435546875, "reward": 0.5616651177406311, "action": -1.7214138507843018}
{"mode": "train", "epochs": 2, "timestep": 3934, "ep_reward": 1076.2999267578125, "reward": 0.6563902497291565, "action": -0.5891991257667542}
{"mode": "train", "epochs": 2, "timestep": 3935, "ep_reward": 1077.0404052734375, "reward": 0.7404236793518066, "action": -0.5192935466766357}
{"mode": "train", "epochs": 2, "timestep": 3936, "ep_reward": 1077.8414306640625, "reward": 0.8010082840919495, "action": -0.7503630518913269}
{"mode": "train", "epochs": 2, "timestep": 3937, "ep_reward": 1078.6796875, "reward": 0.8382203578948975, "action": -0.6621748805046082}
{"mode": "train", "epochs": 2, "timestep": 3938, "ep_reward": 1079.537109375, "reward": 0.8574116826057434, "action": -2.0}
{"mode": "train", "epochs": 2, "timestep": 3939, "ep_reward": 1080.384521484375, "reward": 0.8473784923553467, "action": -1.0168824195861816}
{"mode": "train", "epochs": 2, "timestep": 3940, "ep_reward": 1081.2108154296875, "reward": 0.8263499140739441, "action": 0.0474928617477417}
{"mode": "train", "epochs": 2, "timestep": 3941, "ep_reward": 1082.0042724609375, "reward": 0.793470025062561, "action": 0.027782440185546875}
{"mode": "train", "epochs": 2, "timestep": 3942, "ep_reward": 1082.7393798828125, "reward": 0.73505038022995, "action": -1.5950822830200195}
{"mode": "train", "epochs": 2, "timestep": 3943, "ep_reward": 1083.364501953125, "reward": 0.6251336336135864, "action": -1.2189630270004272}
{"mode": "train", "epochs": 2, "timestep": 3944, "ep_reward": 1083.842529296875, "reward": 0.4779675006866455, "action": -0.6272380352020264}
{"mode": "train", "epochs": 2, "timestep": 3945, "ep_reward": 1084.1865234375, "reward": 0.3440397381782532, "action": -1.2010060548782349}
{"mode": "train", "epochs": 2, "timestep": 3946, "ep_reward": 1084.41943359375, "reward": 0.23295354843139648, "action": -0.1624908447265625}
{"mode": "train", "epochs": 2, "timestep": 3947, "ep_reward": 1084.5211181640625, "reward": 0.10168135166168213, "action": -1.2449231147766113}
{"mode": "train", "epochs": 2, "timestep": 3948, "ep_reward": 1084.535888671875, "reward": 0.014792919158935547, "action": -1.064586877822876}
{"mode": "train", "epochs": 2, "timestep": 3949, "ep_reward": 1084.6937255859375, "reward": 0.1578432321548462, "action": -0.5224496126174927}
{"mode": "train", "epochs": 2, "timestep": 3950, "ep_reward": 1084.9971923828125, "reward": 0.3034853935241699, "action": -0.5047739744186401}
{"mode": "train", "epochs": 2, "timestep": 3951, "ep_reward": 1085.4417724609375, "reward": 0.4445626139640808, "action": 0.051321983337402344}
{"mode": "train", "epochs": 2, "timestep": 3952, "ep_reward": 1086.01904296875, "reward": 0.5772265791893005, "action": -0.43004393577575684}
{"mode": "train", "epochs": 2, "timestep": 3953, "ep_reward": 1086.70166015625, "reward": 0.6825899481773376, "action": -0.9823952913284302}
{"mode": "train", "epochs": 2, "timestep": 3954, "ep_reward": 1087.462158203125, "reward": 0.760469913482666, "action": -1.769257664680481}
{"mode": "train", "epochs": 2, "timestep": 3955, "ep_reward": 1088.2744140625, "reward": 0.8122872710227966, "action": -0.9784041047096252}
{"mode": "train", "epochs": 2, "timestep": 3956, "ep_reward": 1089.128173828125, "reward": 0.853814959526062, "action": -0.5291303396224976}
{"mode": "train", "epochs": 2, "timestep": 3957, "ep_reward": 1090.01123046875, "reward": 0.8830183744430542, "action": -1.3641839027404785}
{"mode": "train", "epochs": 2, "timestep": 3958, "ep_reward": 1090.903564453125, "reward": 0.8923816084861755, "action": -0.6601871252059937}
{"mode": "train", "epochs": 2, "timestep": 3959, "ep_reward": 1091.7974853515625, "reward": 0.8939560651779175, "action": -1.4542787075042725}
{"mode": "train", "epochs": 2, "timestep": 3960, "ep_reward": 1092.6729736328125, "reward": 0.875510573387146, "action": -1.041090488433838}
{"mode": "train", "epochs": 2, "timestep": 3961, "ep_reward": 1093.5162353515625, "reward": 0.8432524800300598, "action": -0.35146743059158325}
{"mode": "train", "epochs": 2, "timestep": 3962, "ep_reward": 1094.3125, "reward": 0.7963201403617859, "action": -1.4017568826675415}
{"mode": "train", "epochs": 2, "timestep": 3963, "ep_reward": 1095.0244140625, "reward": 0.7118594646453857, "action": -1.0121833086013794}
{"mode": "train", "epochs": 2, "timestep": 3964, "ep_reward": 1095.6209716796875, "reward": 0.5965677499771118, "action": -0.6901129484176636}
{"mode": "train", "epochs": 2, "timestep": 3965, "ep_reward": 1096.0675048828125, "reward": 0.4465262293815613, "action": -1.0289669036865234}
{"mode": "train", "epochs": 2, "timestep": 3966, "ep_reward": 1096.37060546875, "reward": 0.30305933952331543, "action": -1.732659935951233}
{"mode": "train", "epochs": 2, "timestep": 3967, "ep_reward": 1096.554931640625, "reward": 0.18427246809005737, "action": -0.5154715776443481}
{"mode": "train", "epochs": 2, "timestep": 3968, "ep_reward": 1096.60009765625, "reward": 0.04511910676956177, "action": -1.8308916091918945}
{"mode": "train", "epochs": 2, "timestep": 3969, "ep_reward": 1096.6729736328125, "reward": 0.07288271188735962, "action": -0.1331891417503357}
{"mode": "train", "epochs": 2, "timestep": 3970, "ep_reward": 1096.8939208984375, "reward": 0.2209823727607727, "action": -1.5050115585327148}
{"mode": "train", "epochs": 2, "timestep": 3971, "ep_reward": 1097.2464599609375, "reward": 0.35255753993988037, "action": -1.3331595659255981}
{"mode": "train", "epochs": 2, "timestep": 3972, "ep_reward": 1097.72705078125, "reward": 0.4805866479873657, "action": -1.3668062686920166}
{"mode": "train", "epochs": 2, "timestep": 3973, "ep_reward": 1098.3203125, "reward": 0.593309223651886, "action": -1.23095703125}
{"mode": "train", "epochs": 2, "timestep": 3974, "ep_reward": 1099.0072021484375, "reward": 0.6869163513183594, "action": -1.2130881547927856}
{"mode": "train", "epochs": 2, "timestep": 3975, "ep_reward": 1099.765380859375, "reward": 0.7581644058227539, "action": -0.3287150263786316}
{"mode": "train", "epochs": 2, "timestep": 3976, "ep_reward": 1100.5810546875, "reward": 0.8156446218490601, "action": -0.8228784203529358}
{"mode": "train", "epochs": 2, "timestep": 3977, "ep_reward": 1101.4293212890625, "reward": 0.8482800722122192, "action": -1.6538195610046387}
{"mode": "train", "epochs": 2, "timestep": 3978, "ep_reward": 1102.28564453125, "reward": 0.8563467264175415, "action": -1.3769683837890625}
{"mode": "train", "epochs": 2, "timestep": 3979, "ep_reward": 1103.134765625, "reward": 0.8491470813751221, "action": -1.4425410032272339}
{"mode": "train", "epochs": 2, "timestep": 3980, "ep_reward": 1103.9560546875, "reward": 0.821336567401886, "action": -0.7946160435676575}
{"mode": "train", "epochs": 2, "timestep": 3981, "ep_reward": 1104.7318115234375, "reward": 0.7758036255836487, "action": -0.5742080211639404}
{"mode": "train", "epochs": 2, "timestep": 3982, "ep_reward": 1105.4356689453125, "reward": 0.7038404941558838, "action": -0.7256370782852173}
{"mode": "train", "epochs": 2, "timestep": 3983, "ep_reward": 1106.03076171875, "reward": 0.5951200723648071, "action": -0.39477968215942383}
{"mode": "train", "epochs": 2, "timestep": 3984, "ep_reward": 1106.4820556640625, "reward": 0.45123493671417236, "action": -0.9412400126457214}
{"mode": "train", "epochs": 2, "timestep": 3985, "ep_reward": 1106.805908203125, "reward": 0.3239109516143799, "action": -0.5774935483932495}
{"mode": "train", "epochs": 2, "timestep": 3986, "ep_reward": 1107.0146484375, "reward": 0.20879775285720825, "action": -0.8202433586120605}
{"mode": "train", "epochs": 2, "timestep": 3987, "ep_reward": 1107.0882568359375, "reward": 0.07364904880523682, "action": -1.2412933111190796}
{"mode": "train", "epochs": 2, "timestep": 3988, "ep_reward": 1107.132568359375, "reward": 0.044362664222717285, "action": -1.1420421600341797}
{"mode": "train", "epochs": 2, "timestep": 3989, "ep_reward": 1107.3160400390625, "reward": 0.18345701694488525, "action": -1.029771327972412}
{"mode": "train", "epochs": 2, "timestep": 3990, "ep_reward": 1107.6392822265625, "reward": 0.32329612970352173, "action": -0.030728161334991455}
{"mode": "train", "epochs": 2, "timestep": 3991, "ep_reward": 1108.10888671875, "reward": 0.46965235471725464, "action": -0.59577476978302}
{"mode": "train", "epochs": 2, "timestep": 3992, "ep_reward": 1108.7008056640625, "reward": 0.5919701457023621, "action": -0.9046619534492493}
{"mode": "train", "epochs": 2, "timestep": 3993, "ep_reward": 1109.390625, "reward": 0.6898765563964844, "action": -0.38891667127609253}
{"mode": "train", "epochs": 2, "timestep": 3994, "ep_reward": 1110.1610107421875, "reward": 0.7703975439071655, "action": -1.1211246252059937}
{"mode": "train", "epochs": 2, "timestep": 3995, "ep_reward": 1110.984375, "reward": 0.8233291506767273, "action": -1.0168118476867676}
{"mode": "train", "epochs": 2, "timestep": 3996, "ep_reward": 1111.843994140625, "reward": 0.8596381545066833, "action": -1.338759183883667}
{"mode": "train", "epochs": 2, "timestep": 3997, "ep_reward": 1112.72216796875, "reward": 0.8781982660293579, "action": -1.1207702159881592}
{"mode": "train", "epochs": 2, "timestep": 3998, "ep_reward": 1113.6065673828125, "reward": 0.8843438029289246, "action": -1.0106465816497803}
{"mode": "train", "epochs": 2, "timestep": 3999, "ep_reward": 1114.4833984375, "reward": 0.8768889904022217, "action": -0.9011819362640381}
{"mode": "train", "epochs": 2, "timestep": 4000, "ep_reward": 1115.33740234375, "reward": 0.8540545105934143, "action": -0.9884673953056335}
{"mode": "train", "epochs": 3, "timestep": 4001, "ep_reward": 0.5103455781936646, "reward": 0.5103455781936646, "action": 0.25806206464767456}
{"mode": "train", "epochs": 3, "timestep": 4002, "ep_reward": 1.0114749670028687, "reward": 0.5011293888092041, "action": 0.7808371186256409}
{"mode": "train", "epochs": 3, "timestep": 4003, "ep_reward": 1.495379090309143, "reward": 0.4839041233062744, "action": 0.9187978506088257}
{"mode": "train", "epochs": 3, "timestep": 4004, "ep_reward": 1.954158067703247, "reward": 0.4587790369987488, "action": 0.8907924294471741}
{"mode": "train", "epochs": 3, "timestep": 4005, "ep_reward": 2.3809866905212402, "reward": 0.42682868242263794, "action": 2.0}
{"mode": "train", "epochs": 3, "timestep": 4006, "ep_reward": 2.7640748023986816, "reward": 0.3830881118774414, "action": 0.29790985584259033}
{"mode": "train", "epochs": 3, "timestep": 4007, "ep_reward": 3.139631748199463, "reward": 0.3755570650100708, "action": 1.2007502317428589}
{"mode": "train", "epochs": 3, "timestep": 4008, "ep_reward": 3.5515191555023193, "reward": 0.41188740730285645, "action": 0.4260014295578003}
{"mode": "train", "epochs": 3, "timestep": 4009, "ep_reward": 4.0023579597473145, "reward": 0.45083892345428467, "action": 1.0051677227020264}
{"mode": "train", "epochs": 3, "timestep": 4010, "ep_reward": 4.489979267120361, "reward": 0.4876213073730469, "action": 0.8885725736618042}
{"mode": "train", "epochs": 3, "timestep": 4011, "ep_reward": 5.013180732727051, "reward": 0.523201584815979, "action": 0.726127028465271}
{"mode": "train", "epochs": 3, "timestep": 4012, "ep_reward": 5.569079875946045, "reward": 0.5558992624282837, "action": 0.7084636688232422}
{"mode": "train", "epochs": 3, "timestep": 4013, "ep_reward": 6.152923583984375, "reward": 0.583843469619751, "action": 0.9392924904823303}
{"mode": "train", "epochs": 3, "timestep": 4014, "ep_reward": 6.758901119232178, "reward": 0.6059776544570923, "action": 1.2790833711624146}
{"mode": "train", "epochs": 3, "timestep": 4015, "ep_reward": 7.3814616203308105, "reward": 0.6225605010986328, "action": 1.1243526935577393}
{"mode": "train", "epochs": 3, "timestep": 4016, "ep_reward": 8.015152931213379, "reward": 0.6336915493011475, "action": 0.4018983840942383}
{"mode": "train", "epochs": 3, "timestep": 4017, "ep_reward": 8.6522855758667, "reward": 0.6371327042579651, "action": -0.02386307716369629}
{"mode": "train", "epochs": 3, "timestep": 4018, "ep_reward": 9.282380104064941, "reward": 0.6300949454307556, "action": 1.4705142974853516}
{"mode": "train", "epochs": 3, "timestep": 4019, "ep_reward": 9.900579452514648, "reward": 0.6181998252868652, "action": 0.9505507349967957}
{"mode": "train", "epochs": 3, "timestep": 4020, "ep_reward": 10.499953269958496, "reward": 0.5993741750717163, "action": 0.3877686858177185}
{"mode": "train", "epochs": 3, "timestep": 4021, "ep_reward": 11.071653366088867, "reward": 0.5717004537582397, "action": -1.0219331979751587}
{"mode": "train", "epochs": 3, "timestep": 4022, "ep_reward": 11.600279808044434, "reward": 0.5286262035369873, "action": -0.39140015840530396}
{"mode": "train", "epochs": 3, "timestep": 4023, "ep_reward": 12.078617095947266, "reward": 0.47833728790283203, "action": -1.0508649349212646}
{"mode": "train", "epochs": 3, "timestep": 4024, "ep_reward": 12.494974136352539, "reward": 0.41635727882385254, "action": -0.04391813278198242}
{"mode": "train", "epochs": 3, "timestep": 4025, "ep_reward": 12.850894927978516, "reward": 0.3559209704399109, "action": -1.8457717895507812}
{"mode": "train", "epochs": 3, "timestep": 4026, "ep_reward": 13.205810546875, "reward": 0.3549155592918396, "action": -1.025935173034668}
{"mode": "train", "epochs": 3, "timestep": 4027, "ep_reward": 13.6187105178833, "reward": 0.41290026903152466, "action": -0.5314545631408691}
{"mode": "train", "epochs": 3, "timestep": 4028, "ep_reward": 14.092169761657715, "reward": 0.4734591245651245, "action": -0.7143152356147766}
{"mode": "train", "epochs": 3, "timestep": 4029, "ep_reward": 14.62291431427002, "reward": 0.5307446718215942, "action": -0.492037832736969}
{"mode": "train", "epochs": 3, "timestep": 4030, "ep_reward": 15.207029342651367, "reward": 0.5841153860092163, "action": -1.2036782503128052}
{"mode": "train", "epochs": 3, "timestep": 4031, "ep_reward": 15.835882186889648, "reward": 0.6288526058197021, "action": -0.6299124956130981}
{"mode": "train", "epochs": 3, "timestep": 4032, "ep_reward": 16.50391960144043, "reward": 0.668036699295044, "action": -0.7122477889060974}
{"mode": "train", "epochs": 3, "timestep": 4033, "ep_reward": 17.20134925842285, "reward": 0.6974296569824219, "action": -1.6691820621490479}
{"mode": "train", "epochs": 3, "timestep": 4034, "ep_reward": 17.91851234436035, "reward": 0.7171631455421448, "action": -0.9939013123512268}
{"mode": "train", "epochs": 3, "timestep": 4035, "ep_reward": 18.647655487060547, "reward": 0.7291421890258789, "action": -1.3003883361816406}
{"mode": "train", "epochs": 3, "timestep": 4036, "ep_reward": 19.3797550201416, "reward": 0.7320997714996338, "action": 0.39950698614120483}
{"mode": "train", "epochs": 3, "timestep": 4037, "ep_reward": 20.10096549987793, "reward": 0.7212111949920654, "action": 1.2971948385238647}
{"mode": "train", "epochs": 3, "timestep": 4038, "ep_reward": 20.79134750366211, "reward": 0.6903825998306274, "action": 0.9620745182037354}
{"mode": "train", "epochs": 3, "timestep": 4039, "ep_reward": 21.43286895751953, "reward": 0.6415219306945801, "action": 0.21154946088790894}
{"mode": "train", "epochs": 3, "timestep": 4040, "ep_reward": 22.013622283935547, "reward": 0.5807524919509888, "action": 0.611318051815033}
{"mode": "train", "epochs": 3, "timestep": 4041, "ep_reward": 22.517847061157227, "reward": 0.5042241811752319, "action": 1.2005815505981445}
{"mode": "train", "epochs": 3, "timestep": 4042, "ep_reward": 22.928695678710938, "reward": 0.41084885597229004, "action": 0.6681485772132874}
{"mode": "train", "epochs": 3, "timestep": 4043, "ep_reward": 23.242366790771484, "reward": 0.313670814037323, "action": 1.348604679107666}
{"mode": "train", "epochs": 3, "timestep": 4044, "ep_reward": 23.532386779785156, "reward": 0.2900196313858032, "action": 1.7008912563323975}
{"mode": "train", "epochs": 3, "timestep": 4045, "ep_reward": 23.89972496032715, "reward": 0.3673388361930847, "action": 1.198099136352539}
{"mode": "train", "epochs": 3, "timestep": 4046, "ep_reward": 24.350765228271484, "reward": 0.45104098320007324, "action": 0.6374673843383789}
{"mode": "train", "epochs": 3, "timestep": 4047, "ep_reward": 24.88735580444336, "reward": 0.5365898609161377, "action": 1.6004588603973389}
{"mode": "train", "epochs": 3, "timestep": 4048, "ep_reward": 25.497535705566406, "reward": 0.6101789474487305, "action": 0.6353964805603027}
{"mode": "train", "epochs": 3, "timestep": 4049, "ep_reward": 26.17925262451172, "reward": 0.681717038154602, "action": 0.8832306861877441}
{"mode": "train", "epochs": 3, "timestep": 4050, "ep_reward": 26.919450759887695, "reward": 0.7401981353759766, "action": 1.2050069570541382}
{"mode": "train", "epochs": 3, "timestep": 4051, "ep_reward": 27.705123901367188, "reward": 0.7856730818748474, "action": 1.7233595848083496}
{"mode": "train", "epochs": 3, "timestep": 4052, "ep_reward": 28.524539947509766, "reward": 0.8194156885147095, "action": 1.0138912200927734}
{"mode": "train", "epochs": 3, "timestep": 4053, "ep_reward": 29.369768142700195, "reward": 0.8452287912368774, "action": 1.1214966773986816}
{"mode": "train", "epochs": 3, "timestep": 4054, "ep_reward": 30.2303524017334, "reward": 0.8605844974517822, "action": 0.700669527053833}
{"mode": "train", "epochs": 3, "timestep": 4055, "ep_reward": 31.096046447753906, "reward": 0.8656935095787048, "action": 1.5808459520339966}
{"mode": "train", "epochs": 3, "timestep": 4056, "ep_reward": 31.95794677734375, "reward": 0.8618996143341064, "action": 1.0037389993667603}
{"mode": "train", "epochs": 3, "timestep": 4057, "ep_reward": 32.80607604980469, "reward": 0.8481305837631226, "action": 0.7035428285598755}
{"mode": "train", "epochs": 3, "timestep": 4058, "ep_reward": 33.62831497192383, "reward": 0.8222407102584839, "action": -0.900198221206665}
{"mode": "train", "epochs": 3, "timestep": 4059, "ep_reward": 34.40217971801758, "reward": 0.7738646864891052, "action": -0.6893314719200134}
{"mode": "train", "epochs": 3, "timestep": 4060, "ep_reward": 35.10774612426758, "reward": 0.7055665850639343, "action": -0.8107637166976929}
{"mode": "train", "epochs": 3, "timestep": 4061, "ep_reward": 35.722415924072266, "reward": 0.6146702766418457, "action": -1.2007917165756226}
{"mode": "train", "epochs": 3, "timestep": 4062, "ep_reward": 36.22062301635742, "reward": 0.49820786714553833, "action": -0.8334183692932129}
{"mode": "train", "epochs": 3, "timestep": 4063, "ep_reward": 36.587459564208984, "reward": 0.3668366074562073, "action": -0.5604413747787476}
{"mode": "train", "epochs": 3, "timestep": 4064, "ep_reward": 36.815494537353516, "reward": 0.22803634405136108, "action": -1.4618667364120483}
{"mode": "train", "epochs": 3, "timestep": 4065, "ep_reward": 36.985572814941406, "reward": 0.17007720470428467, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4066, "ep_reward": 37.25752258300781, "reward": 0.271947979927063, "action": -0.17254096269607544}
{"mode": "train", "epochs": 3, "timestep": 4067, "ep_reward": 37.654441833496094, "reward": 0.39691799879074097, "action": -1.3039779663085938}
{"mode": "train", "epochs": 3, "timestep": 4068, "ep_reward": 38.160343170166016, "reward": 0.5059003829956055, "action": -0.7428634166717529}
{"mode": "train", "epochs": 3, "timestep": 4069, "ep_reward": 38.77171325683594, "reward": 0.6113685965538025, "action": -0.8965727090835571}
{"mode": "train", "epochs": 3, "timestep": 4070, "ep_reward": 39.47266387939453, "reward": 0.7009496688842773, "action": -1.2927162647247314}
{"mode": "train", "epochs": 3, "timestep": 4071, "ep_reward": 40.244606018066406, "reward": 0.7719430923461914, "action": -0.9384013414382935}
{"mode": "train", "epochs": 3, "timestep": 4072, "ep_reward": 41.07505416870117, "reward": 0.8304474353790283, "action": -1.4983106851577759}
{"mode": "train", "epochs": 3, "timestep": 4073, "ep_reward": 41.94731140136719, "reward": 0.8722569346427917, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4074, "ep_reward": 42.84919357299805, "reward": 0.9018822312355042, "action": -0.5537596940994263}
{"mode": "train", "epochs": 3, "timestep": 4075, "ep_reward": 43.77907943725586, "reward": 0.9298843145370483, "action": -1.0062836408615112}
{"mode": "train", "epochs": 3, "timestep": 4076, "ep_reward": 44.72754669189453, "reward": 0.9484663605690002, "action": -1.0010336637496948}
{"mode": "train", "epochs": 3, "timestep": 4077, "ep_reward": 45.68940734863281, "reward": 0.9618611931800842, "action": -1.0973683595657349}
{"mode": "train", "epochs": 3, "timestep": 4078, "ep_reward": 46.660648345947266, "reward": 0.9712411761283875, "action": -0.6783607602119446}
{"mode": "train", "epochs": 3, "timestep": 4079, "ep_reward": 47.63936996459961, "reward": 0.9787209033966064, "action": -1.7058391571044922}
{"mode": "train", "epochs": 3, "timestep": 4080, "ep_reward": 48.62119674682617, "reward": 0.9818263053894043, "action": -0.8339084982872009}
{"mode": "train", "epochs": 3, "timestep": 4081, "ep_reward": 49.60653305053711, "reward": 0.9853376150131226, "action": -1.3966602087020874}
{"mode": "train", "epochs": 3, "timestep": 4082, "ep_reward": 50.59260940551758, "reward": 0.9860760569572449, "action": -1.1429250240325928}
{"mode": "train", "epochs": 3, "timestep": 4083, "ep_reward": 51.578487396240234, "reward": 0.9858788251876831, "action": -1.1432819366455078}
{"mode": "train", "epochs": 3, "timestep": 4084, "ep_reward": 52.562355041503906, "reward": 0.9838691353797913, "action": -0.9614856243133545}
{"mode": "train", "epochs": 3, "timestep": 4085, "ep_reward": 53.54238510131836, "reward": 0.9800311923027039, "action": -1.0830460786819458}
{"mode": "train", "epochs": 3, "timestep": 4086, "ep_reward": 54.514892578125, "reward": 0.972508430480957, "action": -1.7115957736968994}
{"mode": "train", "epochs": 3, "timestep": 4087, "ep_reward": 55.472503662109375, "reward": 0.9576126337051392, "action": -1.1011403799057007}
{"mode": "train", "epochs": 3, "timestep": 4088, "ep_reward": 56.4102897644043, "reward": 0.9377868175506592, "action": -1.1991475820541382}
{"mode": "train", "epochs": 3, "timestep": 4089, "ep_reward": 57.31739807128906, "reward": 0.907107949256897, "action": -0.10074937343597412}
{"mode": "train", "epochs": 3, "timestep": 4090, "ep_reward": 58.187374114990234, "reward": 0.8699743747711182, "action": -1.6170634031295776}
{"mode": "train", "epochs": 3, "timestep": 4091, "ep_reward": 58.99014663696289, "reward": 0.802770733833313, "action": -1.2048817873001099}
{"mode": "train", "epochs": 3, "timestep": 4092, "ep_reward": 59.70206832885742, "reward": 0.7119229435920715, "action": -1.016271710395813}
{"mode": "train", "epochs": 3, "timestep": 4093, "ep_reward": 60.29291534423828, "reward": 0.5908480882644653, "action": -0.8926549553871155}
{"mode": "train", "epochs": 3, "timestep": 4094, "ep_reward": 60.729488372802734, "reward": 0.436573326587677, "action": -0.9720780253410339}
{"mode": "train", "epochs": 3, "timestep": 4095, "ep_reward": 60.97857666015625, "reward": 0.24908971786499023, "action": -1.7511591911315918}
{"mode": "train", "epochs": 3, "timestep": 4096, "ep_reward": 61.09621810913086, "reward": 0.11764317750930786, "action": -1.250133991241455}
{"mode": "train", "epochs": 3, "timestep": 4097, "ep_reward": 61.09330749511719, "reward": -0.002908945083618164, "action": -1.758928894996643}
{"mode": "train", "epochs": 3, "timestep": 4098, "ep_reward": 61.235713958740234, "reward": 0.14240485429763794, "action": -1.5445740222930908}
{"mode": "train", "epochs": 3, "timestep": 4099, "ep_reward": 61.510780334472656, "reward": 0.27506524324417114, "action": -0.22765374183654785}
{"mode": "train", "epochs": 3, "timestep": 4100, "ep_reward": 61.93373489379883, "reward": 0.4229557514190674, "action": -1.2246854305267334}
{"mode": "train", "epochs": 3, "timestep": 4101, "ep_reward": 62.478660583496094, "reward": 0.5449255704879761, "action": -1.5174541473388672}
{"mode": "train", "epochs": 3, "timestep": 4102, "ep_reward": 63.123992919921875, "reward": 0.6453334093093872, "action": -0.5840597152709961}
{"mode": "train", "epochs": 3, "timestep": 4103, "ep_reward": 63.857513427734375, "reward": 0.7335206866264343, "action": -1.0386090278625488}
{"mode": "train", "epochs": 3, "timestep": 4104, "ep_reward": 64.651611328125, "reward": 0.794094443321228, "action": -1.5057952404022217}
{"mode": "train", "epochs": 3, "timestep": 4105, "ep_reward": 65.48213958740234, "reward": 0.8305255174636841, "action": -0.8494003415107727}
{"mode": "train", "epochs": 3, "timestep": 4106, "ep_reward": 66.3367691040039, "reward": 0.8546296954154968, "action": -0.579414427280426}
{"mode": "train", "epochs": 3, "timestep": 4107, "ep_reward": 67.20050811767578, "reward": 0.8637390732765198, "action": -0.8242950439453125}
{"mode": "train", "epochs": 3, "timestep": 4108, "ep_reward": 68.05399322509766, "reward": 0.8534821271896362, "action": -0.9529263973236084}
{"mode": "train", "epochs": 3, "timestep": 4109, "ep_reward": 68.87667846679688, "reward": 0.8226882219314575, "action": -0.418130099773407}
{"mode": "train", "epochs": 3, "timestep": 4110, "ep_reward": 69.65045928955078, "reward": 0.7737777233123779, "action": -0.9785252213478088}
{"mode": "train", "epochs": 3, "timestep": 4111, "ep_reward": 70.34036254882812, "reward": 0.6899020671844482, "action": -0.9815718531608582}
{"mode": "train", "epochs": 3, "timestep": 4112, "ep_reward": 70.9096908569336, "reward": 0.5693292617797852, "action": -1.24410879611969}
{"mode": "train", "epochs": 3, "timestep": 4113, "ep_reward": 71.3127670288086, "reward": 0.403073251247406, "action": -0.7531397342681885}
{"mode": "train", "epochs": 3, "timestep": 4114, "ep_reward": 71.60614776611328, "reward": 0.2933804392814636, "action": -0.939349353313446}
{"mode": "train", "epochs": 3, "timestep": 4115, "ep_reward": 71.7787857055664, "reward": 0.17263692617416382, "action": -0.9980459809303284}
{"mode": "train", "epochs": 3, "timestep": 4116, "ep_reward": 71.81051635742188, "reward": 0.0317305326461792, "action": -1.927593469619751}
{"mode": "train", "epochs": 3, "timestep": 4117, "ep_reward": 71.89624786376953, "reward": 0.08573192358016968, "action": -0.49846816062927246}
{"mode": "train", "epochs": 3, "timestep": 4118, "ep_reward": 72.12605285644531, "reward": 0.22980594635009766, "action": -0.864627480506897}
{"mode": "train", "epochs": 3, "timestep": 4119, "ep_reward": 72.49576568603516, "reward": 0.36971068382263184, "action": -0.864868700504303}
{"mode": "train", "epochs": 3, "timestep": 4120, "ep_reward": 72.99697875976562, "reward": 0.5012162923812866, "action": -0.9783830642700195}
{"mode": "train", "epochs": 3, "timestep": 4121, "ep_reward": 73.61163330078125, "reward": 0.6146581172943115, "action": -1.0885250568389893}
{"mode": "train", "epochs": 3, "timestep": 4122, "ep_reward": 74.3173828125, "reward": 0.7057514190673828, "action": -1.626739263534546}
{"mode": "train", "epochs": 3, "timestep": 4123, "ep_reward": 75.0876235961914, "reward": 0.7702415585517883, "action": -1.1107561588287354}
{"mode": "train", "epochs": 3, "timestep": 4124, "ep_reward": 75.90727233886719, "reward": 0.8196509480476379, "action": -0.29489630460739136}
{"mode": "train", "epochs": 3, "timestep": 4125, "ep_reward": 76.76445770263672, "reward": 0.8571878671646118, "action": -1.1799079179763794}
{"mode": "train", "epochs": 3, "timestep": 4126, "ep_reward": 77.6349868774414, "reward": 0.8705263137817383, "action": -1.3707042932510376}
{"mode": "train", "epochs": 3, "timestep": 4127, "ep_reward": 78.50154113769531, "reward": 0.8665552735328674, "action": -0.9744722843170166}
{"mode": "train", "epochs": 3, "timestep": 4128, "ep_reward": 79.35020446777344, "reward": 0.8486612439155579, "action": -0.8753194212913513}
{"mode": "train", "epochs": 3, "timestep": 4129, "ep_reward": 80.16162109375, "reward": 0.8114128112792969, "action": -0.3993517756462097}
{"mode": "train", "epochs": 3, "timestep": 4130, "ep_reward": 80.91592407226562, "reward": 0.7543025612831116, "action": -0.9871382713317871}
{"mode": "train", "epochs": 3, "timestep": 4131, "ep_reward": 81.5759048461914, "reward": 0.6599795818328857, "action": -1.3871232271194458}
{"mode": "train", "epochs": 3, "timestep": 4132, "ep_reward": 82.09735870361328, "reward": 0.5214537382125854, "action": -1.7442066669464111}
{"mode": "train", "epochs": 3, "timestep": 4133, "ep_reward": 82.46195220947266, "reward": 0.36459165811538696, "action": -1.1772006750106812}
{"mode": "train", "epochs": 3, "timestep": 4134, "ep_reward": 82.7193603515625, "reward": 0.2574084401130676, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4135, "ep_reward": 82.84993743896484, "reward": 0.13057488203048706, "action": -1.0098803043365479}
{"mode": "train", "epochs": 3, "timestep": 4136, "ep_reward": 82.83351135253906, "reward": -0.016422629356384277, "action": -0.8150985240936279}
{"mode": "train", "epochs": 3, "timestep": 4137, "ep_reward": 82.96327209472656, "reward": 0.1297593116760254, "action": -0.9849987626075745}
{"mode": "train", "epochs": 3, "timestep": 4138, "ep_reward": 83.23229217529297, "reward": 0.269018292427063, "action": -0.9562774896621704}
{"mode": "train", "epochs": 3, "timestep": 4139, "ep_reward": 83.63967895507812, "reward": 0.4073903560638428, "action": 0.158014178276062}
{"mode": "train", "epochs": 3, "timestep": 4140, "ep_reward": 84.18668365478516, "reward": 0.5470019578933716, "action": -0.8428109884262085}
{"mode": "train", "epochs": 3, "timestep": 4141, "ep_reward": 84.84061431884766, "reward": 0.6539270877838135, "action": -1.460610270500183}
{"mode": "train", "epochs": 3, "timestep": 4142, "ep_reward": 85.57379913330078, "reward": 0.7331880331039429, "action": -1.757716178894043}
{"mode": "train", "epochs": 3, "timestep": 4143, "ep_reward": 86.36354064941406, "reward": 0.789742112159729, "action": -0.7758957147598267}
{"mode": "train", "epochs": 3, "timestep": 4144, "ep_reward": 87.19953155517578, "reward": 0.8359877467155457, "action": -1.1932672262191772}
{"mode": "train", "epochs": 3, "timestep": 4145, "ep_reward": 88.06033325195312, "reward": 0.8608025312423706, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4146, "ep_reward": 88.92345428466797, "reward": 0.8631225228309631, "action": -0.6732307076454163}
{"mode": "train", "epochs": 3, "timestep": 4147, "ep_reward": 89.78334045410156, "reward": 0.8598875999450684, "action": -1.2149662971496582}
{"mode": "train", "epochs": 3, "timestep": 4148, "ep_reward": 90.61654663085938, "reward": 0.8332046270370483, "action": -1.9921060800552368}
{"mode": "train", "epochs": 3, "timestep": 4149, "ep_reward": 91.39189910888672, "reward": 0.7753521203994751, "action": -0.04069429636001587}
{"mode": "train", "epochs": 3, "timestep": 4150, "ep_reward": 92.10060119628906, "reward": 0.7087058424949646, "action": -1.6618225574493408}
{"mode": "train", "epochs": 3, "timestep": 4151, "ep_reward": 92.68798828125, "reward": 0.5873901844024658, "action": -1.0915480852127075}
{"mode": "train", "epochs": 3, "timestep": 4152, "ep_reward": 93.11791229248047, "reward": 0.42992103099823, "action": -1.8034372329711914}
{"mode": "train", "epochs": 3, "timestep": 4153, "ep_reward": 93.43597412109375, "reward": 0.3180655241012573, "action": -0.7266412973403931}
{"mode": "train", "epochs": 3, "timestep": 4154, "ep_reward": 93.63772583007812, "reward": 0.20175278186798096, "action": -1.5854995250701904}
{"mode": "train", "epochs": 3, "timestep": 4155, "ep_reward": 93.70343780517578, "reward": 0.06570941209793091, "action": -0.4359883666038513}
{"mode": "train", "epochs": 3, "timestep": 4156, "ep_reward": 93.75603485107422, "reward": 0.052596867084503174, "action": -0.5804438591003418}
{"mode": "train", "epochs": 3, "timestep": 4157, "ep_reward": 93.95059204101562, "reward": 0.1945585012435913, "action": -1.3602839708328247}
{"mode": "train", "epochs": 3, "timestep": 4158, "ep_reward": 94.28008270263672, "reward": 0.3294938802719116, "action": -1.2423503398895264}
{"mode": "train", "epochs": 3, "timestep": 4159, "ep_reward": 94.74102783203125, "reward": 0.4609459638595581, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4160, "ep_reward": 95.31068420410156, "reward": 0.5696579217910767, "action": -0.5924339890480042}
{"mode": "train", "epochs": 3, "timestep": 4161, "ep_reward": 95.98501586914062, "reward": 0.6743297576904297, "action": -1.4792941808700562}
{"mode": "train", "epochs": 3, "timestep": 4162, "ep_reward": 96.73052978515625, "reward": 0.745514988899231, "action": -1.0003949403762817}
{"mode": "train", "epochs": 3, "timestep": 4163, "ep_reward": 97.5296859741211, "reward": 0.7991578578948975, "action": -1.0163997411727905}
{"mode": "train", "epochs": 3, "timestep": 4164, "ep_reward": 98.36116027832031, "reward": 0.8314763903617859, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4165, "ep_reward": 99.19676208496094, "reward": 0.8355996608734131, "action": -1.0385792255401611}
{"mode": "train", "epochs": 3, "timestep": 4166, "ep_reward": 100.0251693725586, "reward": 0.8284056782722473, "action": -1.3345551490783691}
{"mode": "train", "epochs": 3, "timestep": 4167, "ep_reward": 100.82085418701172, "reward": 0.7956816554069519, "action": -0.3223620057106018}
{"mode": "train", "epochs": 3, "timestep": 4168, "ep_reward": 101.56758880615234, "reward": 0.7467312812805176, "action": -1.4946329593658447}
{"mode": "train", "epochs": 3, "timestep": 4169, "ep_reward": 102.2191162109375, "reward": 0.6515305042266846, "action": -0.664881706237793}
{"mode": "train", "epochs": 3, "timestep": 4170, "ep_reward": 102.74551391601562, "reward": 0.526397705078125, "action": -0.33886849880218506}
{"mode": "train", "epochs": 3, "timestep": 4171, "ep_reward": 103.13201141357422, "reward": 0.3865002393722534, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4172, "ep_reward": 103.41635131835938, "reward": 0.28433895111083984, "action": -0.9244952201843262}
{"mode": "train", "epochs": 3, "timestep": 4173, "ep_reward": 103.57837677001953, "reward": 0.16202312707901, "action": -0.4270888566970825}
{"mode": "train", "epochs": 3, "timestep": 4174, "ep_reward": 103.59796905517578, "reward": 0.01958853006362915, "action": -1.1883134841918945}
{"mode": "train", "epochs": 3, "timestep": 4175, "ep_reward": 103.6951904296875, "reward": 0.09721851348876953, "action": -1.203941822052002}
{"mode": "train", "epochs": 3, "timestep": 4176, "ep_reward": 103.92809295654297, "reward": 0.23290079832077026, "action": -0.4818386435508728}
{"mode": "train", "epochs": 3, "timestep": 4177, "ep_reward": 104.3069839477539, "reward": 0.3788914084434509, "action": -0.9311589002609253}
{"mode": "train", "epochs": 3, "timestep": 4178, "ep_reward": 104.81598663330078, "reward": 0.5089998245239258, "action": -1.728365182876587}
{"mode": "train", "epochs": 3, "timestep": 4179, "ep_reward": 105.4292984008789, "reward": 0.613309383392334, "action": -0.7390456199645996}
{"mode": "train", "epochs": 3, "timestep": 4180, "ep_reward": 106.13695526123047, "reward": 0.7076573371887207, "action": -0.7072204351425171}
{"mode": "train", "epochs": 3, "timestep": 4181, "ep_reward": 106.91575622558594, "reward": 0.7788045406341553, "action": -1.181803584098816}
{"mode": "train", "epochs": 3, "timestep": 4182, "ep_reward": 107.74024963378906, "reward": 0.8244918584823608, "action": -0.6988105773925781}
{"mode": "train", "epochs": 3, "timestep": 4183, "ep_reward": 108.59615325927734, "reward": 0.85590660572052, "action": -0.9070141315460205}
{"mode": "train", "epochs": 3, "timestep": 4184, "ep_reward": 109.46482849121094, "reward": 0.868678867816925, "action": -1.3529088497161865}
{"mode": "train", "epochs": 3, "timestep": 4185, "ep_reward": 110.32632446289062, "reward": 0.8614981174468994, "action": -0.01058506965637207}
{"mode": "train", "epochs": 3, "timestep": 4186, "ep_reward": 111.17475891113281, "reward": 0.8484334945678711, "action": -0.8316318988800049}
{"mode": "train", "epochs": 3, "timestep": 4187, "ep_reward": 111.98263549804688, "reward": 0.8078781962394714, "action": -1.4369698762893677}
{"mode": "train", "epochs": 3, "timestep": 4188, "ep_reward": 112.71741485595703, "reward": 0.7347791194915771, "action": -1.5595723390579224}
{"mode": "train", "epochs": 3, "timestep": 4189, "ep_reward": 113.34246826171875, "reward": 0.6250525712966919, "action": -1.2262742519378662}
{"mode": "train", "epochs": 3, "timestep": 4190, "ep_reward": 113.81995391845703, "reward": 0.47748661041259766, "action": -1.6608296632766724}
{"mode": "train", "epochs": 3, "timestep": 4191, "ep_reward": 114.16302490234375, "reward": 0.3430742621421814, "action": -1.7018710374832153}
{"mode": "train", "epochs": 3, "timestep": 4192, "ep_reward": 114.3948974609375, "reward": 0.23187416791915894, "action": -0.8067502975463867}
{"mode": "train", "epochs": 3, "timestep": 4193, "ep_reward": 114.495361328125, "reward": 0.10046190023422241, "action": -1.3407379388809204}
{"mode": "train", "epochs": 3, "timestep": 4194, "ep_reward": 114.51142120361328, "reward": 0.016057848930358887, "action": -1.2672148942947388}
{"mode": "train", "epochs": 3, "timestep": 4195, "ep_reward": 114.67025756835938, "reward": 0.1588369607925415, "action": -1.5013372898101807}
{"mode": "train", "epochs": 3, "timestep": 4196, "ep_reward": 114.96255493164062, "reward": 0.29230010509490967, "action": -1.2575620412826538}
{"mode": "train", "epochs": 3, "timestep": 4197, "ep_reward": 115.38932800292969, "reward": 0.4267699718475342, "action": -1.1494941711425781}
{"mode": "train", "epochs": 3, "timestep": 4198, "ep_reward": 115.93931579589844, "reward": 0.5499895811080933, "action": -0.605973482131958}
{"mode": "train", "epochs": 3, "timestep": 4199, "ep_reward": 116.59803009033203, "reward": 0.6587157249450684, "action": -1.6219768524169922}
{"mode": "train", "epochs": 3, "timestep": 4200, "ep_reward": 117.33125305175781, "reward": 0.7332220077514648, "action": -0.7981522083282471}
{"mode": "train", "epochs": 3, "timestep": 4201, "ep_reward": 118.12503051757812, "reward": 0.7937779426574707, "action": -0.5384259223937988}
{"mode": "train", "epochs": 3, "timestep": 4202, "ep_reward": 118.96038055419922, "reward": 0.8353521823883057, "action": -0.600601315498352}
{"mode": "train", "epochs": 3, "timestep": 4203, "ep_reward": 119.81768035888672, "reward": 0.8573011755943298, "action": -1.3500151634216309}
{"mode": "train", "epochs": 3, "timestep": 4204, "ep_reward": 120.6729507446289, "reward": 0.8552696108818054, "action": -1.3976386785507202}
{"mode": "train", "epochs": 3, "timestep": 4205, "ep_reward": 121.5069808959961, "reward": 0.8340314030647278, "action": -0.11092966794967651}
{"mode": "train", "epochs": 3, "timestep": 4206, "ep_reward": 122.31034851074219, "reward": 0.8033711314201355, "action": -1.2462084293365479}
{"mode": "train", "epochs": 3, "timestep": 4207, "ep_reward": 123.0454330444336, "reward": 0.7350811958312988, "action": -1.1787513494491577}
{"mode": "train", "epochs": 3, "timestep": 4208, "ep_reward": 123.67864990234375, "reward": 0.633216381072998, "action": -0.9051746129989624}
{"mode": "train", "epochs": 3, "timestep": 4209, "ep_reward": 124.17305755615234, "reward": 0.4944111108779907, "action": -0.7640872001647949}
{"mode": "train", "epochs": 3, "timestep": 4210, "ep_reward": 124.52877807617188, "reward": 0.3557208180427551, "action": -0.7968083620071411}
{"mode": "train", "epochs": 3, "timestep": 4211, "ep_reward": 124.77569580078125, "reward": 0.24691617488861084, "action": -0.2084052562713623}
{"mode": "train", "epochs": 3, "timestep": 4212, "ep_reward": 124.89363098144531, "reward": 0.11793899536132812, "action": -1.4864816665649414}
{"mode": "train", "epochs": 3, "timestep": 4213, "ep_reward": 124.89028930664062, "reward": -0.0033409595489501953, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4214, "ep_reward": 125.03250122070312, "reward": 0.14221525192260742, "action": -0.4410354495048523}
{"mode": "train", "epochs": 3, "timestep": 4215, "ep_reward": 125.32102966308594, "reward": 0.28852516412734985, "action": -0.5847747921943665}
{"mode": "train", "epochs": 3, "timestep": 4216, "ep_reward": 125.75031280517578, "reward": 0.42928051948547363, "action": -0.49385470151901245}
{"mode": "train", "epochs": 3, "timestep": 4217, "ep_reward": 126.3082046508789, "reward": 0.5578896403312683, "action": -1.205911636352539}
{"mode": "train", "epochs": 3, "timestep": 4218, "ep_reward": 126.96744537353516, "reward": 0.6592371463775635, "action": -0.8917770981788635}
{"mode": "train", "epochs": 3, "timestep": 4219, "ep_reward": 127.71014404296875, "reward": 0.742698073387146, "action": -1.1978524923324585}
{"mode": "train", "epochs": 3, "timestep": 4220, "ep_reward": 128.51229858398438, "reward": 0.8021610379219055, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4221, "ep_reward": 129.34902954101562, "reward": 0.8367253541946411, "action": -1.0318232774734497}
{"mode": "train", "epochs": 3, "timestep": 4222, "ep_reward": 130.21206665039062, "reward": 0.8630303144454956, "action": -0.5881226062774658}
{"mode": "train", "epochs": 3, "timestep": 4223, "ep_reward": 131.08921813964844, "reward": 0.8771442174911499, "action": -0.32904261350631714}
{"mode": "train", "epochs": 3, "timestep": 4224, "ep_reward": 131.96742248535156, "reward": 0.8782034516334534, "action": -0.44661468267440796}
{"mode": "train", "epochs": 3, "timestep": 4225, "ep_reward": 132.83004760742188, "reward": 0.8626302480697632, "action": -1.221048355102539}
{"mode": "train", "epochs": 3, "timestep": 4226, "ep_reward": 133.65162658691406, "reward": 0.8215863704681396, "action": -1.460754632949829}
{"mode": "train", "epochs": 3, "timestep": 4227, "ep_reward": 134.4046173095703, "reward": 0.7529959678649902, "action": -0.9497390389442444}
{"mode": "train", "epochs": 3, "timestep": 4228, "ep_reward": 135.06236267089844, "reward": 0.6577491760253906, "action": -0.4086785912513733}
{"mode": "train", "epochs": 3, "timestep": 4229, "ep_reward": 135.59487915039062, "reward": 0.5325120687484741, "action": -1.0748413801193237}
{"mode": "train", "epochs": 3, "timestep": 4230, "ep_reward": 135.95620727539062, "reward": 0.36132872104644775, "action": -1.1662381887435913}
{"mode": "train", "epochs": 3, "timestep": 4231, "ep_reward": 136.2097625732422, "reward": 0.2535586953163147, "action": -1.6197013854980469}
{"mode": "train", "epochs": 3, "timestep": 4232, "ep_reward": 136.3356170654297, "reward": 0.12584930658340454, "action": -1.7071096897125244}
{"mode": "train", "epochs": 3, "timestep": 4233, "ep_reward": 136.32354736328125, "reward": -0.012062788009643555, "action": -0.22982937097549438}
{"mode": "train", "epochs": 3, "timestep": 4234, "ep_reward": 136.45794677734375, "reward": 0.1344013810157776, "action": -0.36197686195373535}
{"mode": "train", "epochs": 3, "timestep": 4235, "ep_reward": 136.7394561767578, "reward": 0.28150296211242676, "action": -0.593542218208313}
{"mode": "train", "epochs": 3, "timestep": 4236, "ep_reward": 137.1617889404297, "reward": 0.42232561111450195, "action": -0.6278266906738281}
{"mode": "train", "epochs": 3, "timestep": 4237, "ep_reward": 137.71209716796875, "reward": 0.5503135919570923, "action": -0.1624089479446411}
{"mode": "train", "epochs": 3, "timestep": 4238, "ep_reward": 138.37559509277344, "reward": 0.6634960174560547, "action": -0.8576826453208923}
{"mode": "train", "epochs": 3, "timestep": 4239, "ep_reward": 139.12249755859375, "reward": 0.7468991279602051, "action": -0.6322253942489624}
{"mode": "train", "epochs": 3, "timestep": 4240, "ep_reward": 139.93385314941406, "reward": 0.8113628029823303, "action": -1.8221924304962158}
{"mode": "train", "epochs": 3, "timestep": 4241, "ep_reward": 140.7821807861328, "reward": 0.8483293056488037, "action": -0.7821422815322876}
{"mode": "train", "epochs": 3, "timestep": 4242, "ep_reward": 141.6605682373047, "reward": 0.8783929347991943, "action": -1.2086586952209473}
{"mode": "train", "epochs": 3, "timestep": 4243, "ep_reward": 142.55203247070312, "reward": 0.8914691209793091, "action": -0.4412164092063904}
{"mode": "train", "epochs": 3, "timestep": 4244, "ep_reward": 143.44931030273438, "reward": 0.8972827792167664, "action": -1.1936668157577515}
{"mode": "train", "epochs": 3, "timestep": 4245, "ep_reward": 144.3335418701172, "reward": 0.88423091173172, "action": -0.1562896966934204}
{"mode": "train", "epochs": 3, "timestep": 4246, "ep_reward": 145.19766235351562, "reward": 0.8641222715377808, "action": -1.958165168762207}
{"mode": "train", "epochs": 3, "timestep": 4247, "ep_reward": 146.0070037841797, "reward": 0.8093408942222595, "action": -0.759529173374176}
{"mode": "train", "epochs": 3, "timestep": 4248, "ep_reward": 146.74642944335938, "reward": 0.7394304871559143, "action": -0.8355563879013062}
{"mode": "train", "epochs": 3, "timestep": 4249, "ep_reward": 147.38348388671875, "reward": 0.6370474100112915, "action": -0.2924928665161133}
{"mode": "train", "epochs": 3, "timestep": 4250, "ep_reward": 147.88873291015625, "reward": 0.505245566368103, "action": -1.2139956951141357}
{"mode": "train", "epochs": 3, "timestep": 4251, "ep_reward": 148.22230529785156, "reward": 0.33357393741607666, "action": -1.2055413722991943}
{"mode": "train", "epochs": 3, "timestep": 4252, "ep_reward": 148.44268798828125, "reward": 0.22038334608078003, "action": -1.0245928764343262}
{"mode": "train", "epochs": 3, "timestep": 4253, "ep_reward": 148.5299072265625, "reward": 0.08721435070037842, "action": -0.5451436042785645}
{"mode": "train", "epochs": 3, "timestep": 4254, "ep_reward": 148.5601348876953, "reward": 0.030234992504119873, "action": -1.6250931024551392}
{"mode": "train", "epochs": 3, "timestep": 4255, "ep_reward": 148.7313690185547, "reward": 0.1712343692779541, "action": -1.325474739074707}
{"mode": "train", "epochs": 3, "timestep": 4256, "ep_reward": 149.03848266601562, "reward": 0.307115375995636, "action": -1.269305944442749}
{"mode": "train", "epochs": 3, "timestep": 4257, "ep_reward": 149.4788055419922, "reward": 0.44032514095306396, "action": -0.9516555070877075}
{"mode": "train", "epochs": 3, "timestep": 4258, "ep_reward": 150.04261779785156, "reward": 0.5638112425804138, "action": -1.2366557121276855}
{"mode": "train", "epochs": 3, "timestep": 4259, "ep_reward": 150.7060089111328, "reward": 0.6633938550949097, "action": -0.27908122539520264}
{"mode": "train", "epochs": 3, "timestep": 4260, "ep_reward": 151.4554443359375, "reward": 0.7494388222694397, "action": -1.3209284543991089}
{"mode": "train", "epochs": 3, "timestep": 4261, "ep_reward": 152.25772094726562, "reward": 0.8022791147232056, "action": -0.5767033100128174}
{"mode": "train", "epochs": 3, "timestep": 4262, "ep_reward": 153.09970092773438, "reward": 0.8419828414916992, "action": -0.7198822498321533}
{"mode": "train", "epochs": 3, "timestep": 4263, "ep_reward": 153.9619598388672, "reward": 0.8622660636901855, "action": -0.5361210107803345}
{"mode": "train", "epochs": 3, "timestep": 4264, "ep_reward": 154.82923889160156, "reward": 0.8672757744789124, "action": -1.6069589853286743}
{"mode": "train", "epochs": 3, "timestep": 4265, "ep_reward": 155.6750946044922, "reward": 0.8458482623100281, "action": -0.09418249130249023}
{"mode": "train", "epochs": 3, "timestep": 4266, "ep_reward": 156.4931640625, "reward": 0.818073570728302, "action": -0.6312786340713501}
{"mode": "train", "epochs": 3, "timestep": 4267, "ep_reward": 157.25465393066406, "reward": 0.7614967226982117, "action": -1.438146710395813}
{"mode": "train", "epochs": 3, "timestep": 4268, "ep_reward": 157.9195556640625, "reward": 0.6649000644683838, "action": -1.537158727645874}
{"mode": "train", "epochs": 3, "timestep": 4269, "ep_reward": 158.44638061523438, "reward": 0.5268226861953735, "action": 0.00878763198852539}
{"mode": "train", "epochs": 3, "timestep": 4270, "ep_reward": 158.81857299804688, "reward": 0.3721850514411926, "action": -1.021571397781372}
{"mode": "train", "epochs": 3, "timestep": 4271, "ep_reward": 159.08534240722656, "reward": 0.26677441596984863, "action": -0.6825599670410156}
{"mode": "train", "epochs": 3, "timestep": 4272, "ep_reward": 159.22662353515625, "reward": 0.14127975702285767, "action": -1.1097017526626587}
{"mode": "train", "epochs": 3, "timestep": 4273, "ep_reward": 159.2224578857422, "reward": -0.004158496856689453, "action": -1.0441761016845703}
{"mode": "train", "epochs": 3, "timestep": 4274, "ep_reward": 159.34133911132812, "reward": 0.11888158321380615, "action": -1.1872400045394897}
{"mode": "train", "epochs": 3, "timestep": 4275, "ep_reward": 159.5966796875, "reward": 0.25534719228744507, "action": -0.9265499711036682}
{"mode": "train", "epochs": 3, "timestep": 4276, "ep_reward": 159.9917449951172, "reward": 0.39506399631500244, "action": -0.4861077666282654}
{"mode": "train", "epochs": 3, "timestep": 4277, "ep_reward": 160.52078247070312, "reward": 0.5290398001670837, "action": -1.3389734029769897}
{"mode": "train", "epochs": 3, "timestep": 4278, "ep_reward": 161.15489196777344, "reward": 0.6341034770011902, "action": -1.2376108169555664}
{"mode": "train", "epochs": 3, "timestep": 4279, "ep_reward": 161.8739776611328, "reward": 0.7190786600112915, "action": -0.9304590225219727}
{"mode": "train", "epochs": 3, "timestep": 4280, "ep_reward": 162.65895080566406, "reward": 0.7849745154380798, "action": -0.7355746030807495}
{"mode": "train", "epochs": 3, "timestep": 4281, "ep_reward": 163.49073791503906, "reward": 0.8317927122116089, "action": -0.5600123405456543}
{"mode": "train", "epochs": 3, "timestep": 4282, "ep_reward": 164.3523406982422, "reward": 0.8615956902503967, "action": -0.575178861618042}
{"mode": "train", "epochs": 3, "timestep": 4283, "ep_reward": 165.22711181640625, "reward": 0.8747661709785461, "action": -1.193527102470398}
{"mode": "train", "epochs": 3, "timestep": 4284, "ep_reward": 166.0941925048828, "reward": 0.8670874238014221, "action": -1.343640685081482}
{"mode": "train", "epochs": 3, "timestep": 4285, "ep_reward": 166.93453979492188, "reward": 0.8403416872024536, "action": -1.0007816553115845}
{"mode": "train", "epochs": 3, "timestep": 4286, "ep_reward": 167.72935485839844, "reward": 0.794815182685852, "action": -0.9506499171257019}
{"mode": "train", "epochs": 3, "timestep": 4287, "ep_reward": 168.45176696777344, "reward": 0.7224166393280029, "action": -0.5246379375457764}
{"mode": "train", "epochs": 3, "timestep": 4288, "ep_reward": 169.0733642578125, "reward": 0.6215946674346924, "action": -0.12400853633880615}
{"mode": "train", "epochs": 3, "timestep": 4289, "ep_reward": 169.5624237060547, "reward": 0.489063560962677, "action": -1.157597541809082}
{"mode": "train", "epochs": 3, "timestep": 4290, "ep_reward": 169.89791870117188, "reward": 0.3354928493499756, "action": -1.5211271047592163}
{"mode": "train", "epochs": 3, "timestep": 4291, "ep_reward": 170.1207275390625, "reward": 0.22280454635620117, "action": 0.009035587310791016}
{"mode": "train", "epochs": 3, "timestep": 4292, "ep_reward": 170.21060180664062, "reward": 0.08987808227539062, "action": -1.2229735851287842}
{"mode": "train", "epochs": 3, "timestep": 4293, "ep_reward": 170.23802185058594, "reward": 0.02741307020187378, "action": -1.2200558185577393}
{"mode": "train", "epochs": 3, "timestep": 4294, "ep_reward": 170.4068603515625, "reward": 0.16883164644241333, "action": -0.16378337144851685}
{"mode": "train", "epochs": 3, "timestep": 4295, "ep_reward": 170.725830078125, "reward": 0.3189660310745239, "action": -1.3917112350463867}
{"mode": "train", "epochs": 3, "timestep": 4296, "ep_reward": 171.17385864257812, "reward": 0.4480304718017578, "action": -1.190353512763977}
{"mode": "train", "epochs": 3, "timestep": 4297, "ep_reward": 171.7410430908203, "reward": 0.5671806335449219, "action": 0.07745361328125}
{"mode": "train", "epochs": 3, "timestep": 4298, "ep_reward": 172.42083740234375, "reward": 0.6797898411750793, "action": -0.1722257137298584}
{"mode": "train", "epochs": 3, "timestep": 4299, "ep_reward": 173.18563842773438, "reward": 0.7648009657859802, "action": -0.4324347972869873}
{"mode": "train", "epochs": 3, "timestep": 4300, "ep_reward": 174.01083374023438, "reward": 0.825201153755188, "action": -1.0155562162399292}
{"mode": "train", "epochs": 3, "timestep": 4301, "ep_reward": 174.87362670898438, "reward": 0.8627945184707642, "action": -0.47849249839782715}
{"mode": "train", "epochs": 3, "timestep": 4302, "ep_reward": 175.76307678222656, "reward": 0.8894447684288025, "action": -1.3779762983322144}
{"mode": "train", "epochs": 3, "timestep": 4303, "ep_reward": 176.6595458984375, "reward": 0.8964658975601196, "action": -0.9355635643005371}
{"mode": "train", "epochs": 3, "timestep": 4304, "ep_reward": 177.55368041992188, "reward": 0.894133985042572, "action": -0.5453028082847595}
{"mode": "train", "epochs": 3, "timestep": 4305, "ep_reward": 178.43487548828125, "reward": 0.8811973333358765, "action": -0.2773500680923462}
{"mode": "train", "epochs": 3, "timestep": 4306, "ep_reward": 179.28981018066406, "reward": 0.8549320697784424, "action": -0.9738256335258484}
{"mode": "train", "epochs": 3, "timestep": 4307, "ep_reward": 180.09280395507812, "reward": 0.8029924035072327, "action": -1.2989165782928467}
{"mode": "train", "epochs": 3, "timestep": 4308, "ep_reward": 180.81381225585938, "reward": 0.7210017442703247, "action": -0.7547764778137207}
{"mode": "train", "epochs": 3, "timestep": 4309, "ep_reward": 181.42515563964844, "reward": 0.6113503575325012, "action": -1.684234619140625}
{"mode": "train", "epochs": 3, "timestep": 4310, "ep_reward": 181.87513732910156, "reward": 0.4499824047088623, "action": -0.21397483348846436}
{"mode": "train", "epochs": 3, "timestep": 4311, "ep_reward": 182.18035888671875, "reward": 0.30521726608276367, "action": -1.8211604356765747}
{"mode": "train", "epochs": 3, "timestep": 4312, "ep_reward": 182.36720275878906, "reward": 0.1868404746055603, "action": -0.7377597093582153}
{"mode": "train", "epochs": 3, "timestep": 4313, "ep_reward": 182.41551208496094, "reward": 0.04831570386886597, "action": -0.3686581254005432}
{"mode": "train", "epochs": 3, "timestep": 4314, "ep_reward": 182.48529052734375, "reward": 0.06978332996368408, "action": -1.6193490028381348}
{"mode": "train", "epochs": 3, "timestep": 4315, "ep_reward": 182.6907196044922, "reward": 0.20543360710144043, "action": -1.406404972076416}
{"mode": "train", "epochs": 3, "timestep": 4316, "ep_reward": 183.03146362304688, "reward": 0.34074145555496216, "action": -1.2349058389663696}
{"mode": "train", "epochs": 3, "timestep": 4317, "ep_reward": 183.50375366210938, "reward": 0.4722967743873596, "action": 0.16067731380462646}
{"mode": "train", "epochs": 3, "timestep": 4318, "ep_reward": 184.10723876953125, "reward": 0.6034849882125854, "action": -1.2770999670028687}
{"mode": "train", "epochs": 3, "timestep": 4319, "ep_reward": 184.80201721191406, "reward": 0.6947800517082214, "action": -1.244718313217163}
{"mode": "train", "epochs": 3, "timestep": 4320, "ep_reward": 185.56642150878906, "reward": 0.7644072771072388, "action": -0.7643974423408508}
{"mode": "train", "epochs": 3, "timestep": 4321, "ep_reward": 186.3836669921875, "reward": 0.8172484040260315, "action": -0.5552850961685181}
{"mode": "train", "epochs": 3, "timestep": 4322, "ep_reward": 187.23597717285156, "reward": 0.8523168563842773, "action": -0.9006940126419067}
{"mode": "train", "epochs": 3, "timestep": 4323, "ep_reward": 188.10305786132812, "reward": 0.8670879006385803, "action": -1.6980613470077515}
{"mode": "train", "epochs": 3, "timestep": 4324, "ep_reward": 188.9617462158203, "reward": 0.8586857914924622, "action": -1.5696544647216797}
{"mode": "train", "epochs": 3, "timestep": 4325, "ep_reward": 189.79429626464844, "reward": 0.8325510621070862, "action": -0.7665480375289917}
{"mode": "train", "epochs": 3, "timestep": 4326, "ep_reward": 190.58563232421875, "reward": 0.7913352847099304, "action": -1.0828970670700073}
{"mode": "train", "epochs": 3, "timestep": 4327, "ep_reward": 191.30453491210938, "reward": 0.7189077138900757, "action": -1.6790010929107666}
{"mode": "train", "epochs": 3, "timestep": 4328, "ep_reward": 191.9075469970703, "reward": 0.6030151844024658, "action": -1.1528770923614502}
{"mode": "train", "epochs": 3, "timestep": 4329, "ep_reward": 192.3579864501953, "reward": 0.4504459500312805, "action": -0.7780596613883972}
{"mode": "train", "epochs": 3, "timestep": 4330, "ep_reward": 192.69277954101562, "reward": 0.33478844165802, "action": -1.3490922451019287}
{"mode": "train", "epochs": 3, "timestep": 4331, "ep_reward": 192.91465759277344, "reward": 0.22187787294387817, "action": -0.8803635835647583}
{"mode": "train", "epochs": 3, "timestep": 4332, "ep_reward": 193.00350952148438, "reward": 0.08885228633880615, "action": -1.2528315782546997}
{"mode": "train", "epochs": 3, "timestep": 4333, "ep_reward": 193.03195190429688, "reward": 0.028447210788726807, "action": -1.4954240322113037}
{"mode": "train", "epochs": 3, "timestep": 4334, "ep_reward": 193.2014923095703, "reward": 0.16954660415649414, "action": -1.8955738544464111}
{"mode": "train", "epochs": 3, "timestep": 4335, "ep_reward": 193.49974060058594, "reward": 0.2982531785964966, "action": -1.5070921182632446}
{"mode": "train", "epochs": 3, "timestep": 4336, "ep_reward": 193.92977905273438, "reward": 0.43003135919570923, "action": -1.0081892013549805}
{"mode": "train", "epochs": 3, "timestep": 4337, "ep_reward": 194.484619140625, "reward": 0.5548328161239624, "action": -0.8090433478355408}
{"mode": "train", "epochs": 3, "timestep": 4338, "ep_reward": 195.14498901367188, "reward": 0.6603747606277466, "action": -0.27198028564453125}
{"mode": "train", "epochs": 3, "timestep": 4339, "ep_reward": 195.89158630371094, "reward": 0.7466040849685669, "action": -1.2227391004562378}
{"mode": "train", "epochs": 3, "timestep": 4340, "ep_reward": 196.69129943847656, "reward": 0.7997162938117981, "action": -1.262953519821167}
{"mode": "train", "epochs": 3, "timestep": 4341, "ep_reward": 197.52345275878906, "reward": 0.8321460485458374, "action": -1.7646987438201904}
{"mode": "train", "epochs": 3, "timestep": 4342, "ep_reward": 198.36488342285156, "reward": 0.8414312601089478, "action": -0.14224010705947876}
{"mode": "train", "epochs": 3, "timestep": 4343, "ep_reward": 199.21142578125, "reward": 0.8465349078178406, "action": -0.4637288451194763}
{"mode": "train", "epochs": 3, "timestep": 4344, "ep_reward": 200.0404815673828, "reward": 0.8290590047836304, "action": -0.7348811626434326}
{"mode": "train", "epochs": 3, "timestep": 4345, "ep_reward": 200.82704162597656, "reward": 0.786564826965332, "action": -0.2075445055961609}
{"mode": "train", "epochs": 3, "timestep": 4346, "ep_reward": 201.5496063232422, "reward": 0.7225571870803833, "action": -1.3422032594680786}
{"mode": "train", "epochs": 3, "timestep": 4347, "ep_reward": 202.16102600097656, "reward": 0.6114180088043213, "action": -0.9210188984870911}
{"mode": "train", "epochs": 3, "timestep": 4348, "ep_reward": 202.6253662109375, "reward": 0.46434086561203003, "action": -0.7734310626983643}
{"mode": "train", "epochs": 3, "timestep": 4349, "ep_reward": 202.9599151611328, "reward": 0.3345434069633484, "action": -0.5100083351135254}
{"mode": "train", "epochs": 3, "timestep": 4350, "ep_reward": 203.18142700195312, "reward": 0.22151190042495728, "action": -0.2968437075614929}
{"mode": "train", "epochs": 3, "timestep": 4351, "ep_reward": 203.2698211669922, "reward": 0.08839768171310425, "action": -1.1123414039611816}
{"mode": "train", "epochs": 3, "timestep": 4352, "ep_reward": 203.29881286621094, "reward": 0.02899569272994995, "action": -1.224683165550232}
{"mode": "train", "epochs": 3, "timestep": 4353, "ep_reward": 203.4689178466797, "reward": 0.17010486125946045, "action": -1.2798271179199219}
{"mode": "train", "epochs": 3, "timestep": 4354, "ep_reward": 203.77554321289062, "reward": 0.30662745237350464, "action": -0.31701260805130005}
{"mode": "train", "epochs": 3, "timestep": 4355, "ep_reward": 204.22666931152344, "reward": 0.45112520456314087, "action": -1.1615509986877441}
{"mode": "train", "epochs": 3, "timestep": 4356, "ep_reward": 204.79685974121094, "reward": 0.5701836347579956, "action": -0.9843800067901611}
{"mode": "train", "epochs": 3, "timestep": 4357, "ep_reward": 205.4681396484375, "reward": 0.6712797284126282, "action": -1.4251965284347534}
{"mode": "train", "epochs": 3, "timestep": 4358, "ep_reward": 206.21389770507812, "reward": 0.7457547187805176, "action": -0.25218743085861206}
{"mode": "train", "epochs": 3, "timestep": 4359, "ep_reward": 207.02342224121094, "reward": 0.8095241785049438, "action": -1.6125068664550781}
{"mode": "train", "epochs": 3, "timestep": 4360, "ep_reward": 207.86480712890625, "reward": 0.8413844704627991, "action": -0.5146986246109009}
{"mode": "train", "epochs": 3, "timestep": 4361, "ep_reward": 208.7302703857422, "reward": 0.8654632568359375, "action": -0.7181529402732849}
{"mode": "train", "epochs": 3, "timestep": 4362, "ep_reward": 209.60177612304688, "reward": 0.8715097308158875, "action": -0.914794385433197}
{"mode": "train", "epochs": 3, "timestep": 4363, "ep_reward": 210.46139526367188, "reward": 0.8596115112304688, "action": -0.1922607421875}
{"mode": "train", "epochs": 3, "timestep": 4364, "ep_reward": 211.29714965820312, "reward": 0.8357553482055664, "action": -1.9201536178588867}
{"mode": "train", "epochs": 3, "timestep": 4365, "ep_reward": 212.06996154785156, "reward": 0.7728055715560913, "action": -0.66148841381073}
{"mode": "train", "epochs": 3, "timestep": 4366, "ep_reward": 212.76231384277344, "reward": 0.6923567056655884, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4367, "ep_reward": 213.3201904296875, "reward": 0.5578803420066833, "action": -1.0241162776947021}
{"mode": "train", "epochs": 3, "timestep": 4368, "ep_reward": 213.7123565673828, "reward": 0.3921658396720886, "action": -0.9139163494110107}
{"mode": "train", "epochs": 3, "timestep": 4369, "ep_reward": 214.00291442871094, "reward": 0.29056352376937866, "action": -0.39146214723587036}
{"mode": "train", "epochs": 3, "timestep": 4370, "ep_reward": 214.1721954345703, "reward": 0.16927754878997803, "action": -0.8272839784622192}
{"mode": "train", "epochs": 3, "timestep": 4371, "ep_reward": 214.20016479492188, "reward": 0.027970075607299805, "action": -1.248206615447998}
{"mode": "train", "epochs": 3, "timestep": 4372, "ep_reward": 214.2895965576172, "reward": 0.08943760395050049, "action": -0.2505568861961365}
{"mode": "train", "epochs": 3, "timestep": 4373, "ep_reward": 214.5262908935547, "reward": 0.23669958114624023, "action": -0.6963669061660767}
{"mode": "train", "epochs": 3, "timestep": 4374, "ep_reward": 214.90415954589844, "reward": 0.3778630495071411, "action": -0.7159765958786011}
{"mode": "train", "epochs": 3, "timestep": 4375, "ep_reward": 215.41380310058594, "reward": 0.5096492767333984, "action": -1.212242841720581}
{"mode": "train", "epochs": 3, "timestep": 4376, "ep_reward": 216.03282165527344, "reward": 0.6190111041069031, "action": -1.4120122194290161}
{"mode": "train", "epochs": 3, "timestep": 4377, "ep_reward": 216.7391815185547, "reward": 0.7063639163970947, "action": -0.6986535787582397}
{"mode": "train", "epochs": 3, "timestep": 4378, "ep_reward": 217.5185546875, "reward": 0.7793723344802856, "action": -0.4424605965614319}
{"mode": "train", "epochs": 3, "timestep": 4379, "ep_reward": 218.3522186279297, "reward": 0.8336641788482666, "action": 0.053095459938049316}
{"mode": "train", "epochs": 3, "timestep": 4380, "ep_reward": 219.2256622314453, "reward": 0.8734409809112549, "action": -1.371718406677246}
{"mode": "train", "epochs": 3, "timestep": 4381, "ep_reward": 220.11288452148438, "reward": 0.887218713760376, "action": -0.9915180206298828}
{"mode": "train", "epochs": 3, "timestep": 4382, "ep_reward": 221.00340270996094, "reward": 0.8905201554298401, "action": -1.237853765487671}
{"mode": "train", "epochs": 3, "timestep": 4383, "ep_reward": 221.8813018798828, "reward": 0.8778939843177795, "action": -1.0201207399368286}
{"mode": "train", "epochs": 3, "timestep": 4384, "ep_reward": 222.73184204101562, "reward": 0.8505457043647766, "action": -0.6768984794616699}
{"mode": "train", "epochs": 3, "timestep": 4385, "ep_reward": 223.537841796875, "reward": 0.8059933185577393, "action": -1.1570029258728027}
{"mode": "train", "epochs": 3, "timestep": 4386, "ep_reward": 224.26849365234375, "reward": 0.7306479811668396, "action": -1.242519736289978}
{"mode": "train", "epochs": 3, "timestep": 4387, "ep_reward": 224.8888397216797, "reward": 0.6203451156616211, "action": -0.35809534788131714}
{"mode": "train", "epochs": 3, "timestep": 4388, "ep_reward": 225.37196350097656, "reward": 0.48311758041381836, "action": 0.26839518547058105}
{"mode": "train", "epochs": 3, "timestep": 4389, "ep_reward": 225.69915771484375, "reward": 0.32719939947128296, "action": -0.3888200521469116}
{"mode": "train", "epochs": 3, "timestep": 4390, "ep_reward": 225.91184997558594, "reward": 0.21268582344055176, "action": -1.0099412202835083}
{"mode": "train", "epochs": 3, "timestep": 4391, "ep_reward": 225.99002075195312, "reward": 0.07816380262374878, "action": -1.4214706420898438}
{"mode": "train", "epochs": 3, "timestep": 4392, "ep_reward": 226.0296630859375, "reward": 0.039642512798309326, "action": -1.2869609594345093}
{"mode": "train", "epochs": 3, "timestep": 4393, "ep_reward": 226.2088623046875, "reward": 0.17919683456420898, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4394, "ep_reward": 226.5157470703125, "reward": 0.30687761306762695, "action": -0.6205896139144897}
{"mode": "train", "epochs": 3, "timestep": 4395, "ep_reward": 226.9647674560547, "reward": 0.4490148425102234, "action": -1.4084811210632324}
{"mode": "train", "epochs": 3, "timestep": 4396, "ep_reward": 227.531005859375, "reward": 0.5662342309951782, "action": -0.5453844666481018}
{"mode": "train", "epochs": 3, "timestep": 4397, "ep_reward": 228.20335388183594, "reward": 0.6723531484603882, "action": -0.49726539850234985}
{"mode": "train", "epochs": 3, "timestep": 4398, "ep_reward": 228.9573974609375, "reward": 0.7540438771247864, "action": -1.0945996046066284}
{"mode": "train", "epochs": 3, "timestep": 4399, "ep_reward": 229.76441955566406, "reward": 0.8070182800292969, "action": -1.6194751262664795}
{"mode": "train", "epochs": 3, "timestep": 4400, "ep_reward": 230.6002197265625, "reward": 0.8357951641082764, "action": -1.1589192152023315}
{"mode": "train", "epochs": 3, "timestep": 4401, "ep_reward": 231.4508056640625, "reward": 0.8505788445472717, "action": -0.6610085964202881}
{"mode": "train", "epochs": 3, "timestep": 4402, "ep_reward": 232.30238342285156, "reward": 0.8515824675559998, "action": -1.407578945159912}
{"mode": "train", "epochs": 3, "timestep": 4403, "ep_reward": 233.12881469726562, "reward": 0.8264312744140625, "action": -0.22381293773651123}
{"mode": "train", "epochs": 3, "timestep": 4404, "ep_reward": 233.9186553955078, "reward": 0.7898344993591309, "action": -1.7926859855651855}
{"mode": "train", "epochs": 3, "timestep": 4405, "ep_reward": 234.62693786621094, "reward": 0.7082819938659668, "action": -1.285109519958496}
{"mode": "train", "epochs": 3, "timestep": 4406, "ep_reward": 235.2216339111328, "reward": 0.5946977138519287, "action": -1.2717829942703247}
{"mode": "train", "epochs": 3, "timestep": 4407, "ep_reward": 235.6592254638672, "reward": 0.4375903606414795, "action": -1.4428584575653076}
{"mode": "train", "epochs": 3, "timestep": 4408, "ep_reward": 235.9893035888672, "reward": 0.33007705211639404, "action": 0.2050187587738037}
{"mode": "train", "epochs": 3, "timestep": 4409, "ep_reward": 236.20547485351562, "reward": 0.21616840362548828, "action": -0.22246038913726807}
{"mode": "train", "epochs": 3, "timestep": 4410, "ep_reward": 236.28750610351562, "reward": 0.08203786611557007, "action": -1.8984742164611816}
{"mode": "train", "epochs": 3, "timestep": 4411, "ep_reward": 236.3230743408203, "reward": 0.035564303398132324, "action": -0.8866161704063416}
{"mode": "train", "epochs": 3, "timestep": 4412, "ep_reward": 236.49891662597656, "reward": 0.17584633827209473, "action": -0.5506033301353455}
{"mode": "train", "epochs": 3, "timestep": 4413, "ep_reward": 236.8203887939453, "reward": 0.32146573066711426, "action": 0.28515326976776123}
{"mode": "train", "epochs": 3, "timestep": 4414, "ep_reward": 237.29100036621094, "reward": 0.47060543298721313, "action": -1.0939537286758423}
{"mode": "train", "epochs": 3, "timestep": 4415, "ep_reward": 237.87777709960938, "reward": 0.5867727994918823, "action": -1.3566102981567383}
{"mode": "train", "epochs": 3, "timestep": 4416, "ep_reward": 238.55905151367188, "reward": 0.6812804341316223, "action": -0.80704265832901}
{"mode": "train", "epochs": 3, "timestep": 4417, "ep_reward": 239.3193359375, "reward": 0.7602773904800415, "action": -0.407900869846344}
{"mode": "train", "epochs": 3, "timestep": 4418, "ep_reward": 240.14085388183594, "reward": 0.8215107321739197, "action": -1.280564308166504}
{"mode": "train", "epochs": 3, "timestep": 4419, "ep_reward": 240.99798583984375, "reward": 0.8571311831474304, "action": -1.0327045917510986}
{"mode": "train", "epochs": 3, "timestep": 4420, "ep_reward": 241.87753295898438, "reward": 0.8795500993728638, "action": -0.7418599128723145}
{"mode": "train", "epochs": 3, "timestep": 4421, "ep_reward": 242.7676544189453, "reward": 0.890116810798645, "action": -1.3942852020263672}
{"mode": "train", "epochs": 3, "timestep": 4422, "ep_reward": 243.64956665039062, "reward": 0.8819093704223633, "action": -0.9127914309501648}
{"mode": "train", "epochs": 3, "timestep": 4423, "ep_reward": 244.511474609375, "reward": 0.8619087934494019, "action": -1.1941442489624023}
{"mode": "train", "epochs": 3, "timestep": 4424, "ep_reward": 245.33180236816406, "reward": 0.8203306794166565, "action": -1.5267868041992188}
{"mode": "train", "epochs": 3, "timestep": 4425, "ep_reward": 246.08193969726562, "reward": 0.7501343488693237, "action": -0.11257940530776978}
{"mode": "train", "epochs": 3, "timestep": 4426, "ep_reward": 246.74635314941406, "reward": 0.6644158363342285, "action": -0.3087370991706848}
{"mode": "train", "epochs": 3, "timestep": 4427, "ep_reward": 247.2884063720703, "reward": 0.5420556664466858, "action": -0.9948267340660095}
{"mode": "train", "epochs": 3, "timestep": 4428, "ep_reward": 247.66009521484375, "reward": 0.37168121337890625, "action": -0.9365322589874268}
{"mode": "train", "epochs": 3, "timestep": 4429, "ep_reward": 247.91494750976562, "reward": 0.2548462152481079, "action": -0.8238884806632996}
{"mode": "train", "epochs": 3, "timestep": 4430, "ep_reward": 248.04234313964844, "reward": 0.12738823890686035, "action": -0.34612518548965454}
{"mode": "train", "epochs": 3, "timestep": 4431, "ep_reward": 248.02853393554688, "reward": -0.01381385326385498, "action": -1.7975504398345947}
{"mode": "train", "epochs": 3, "timestep": 4432, "ep_reward": 248.16148376464844, "reward": 0.13294243812561035, "action": -1.3441786766052246}
{"mode": "train", "epochs": 3, "timestep": 4433, "ep_reward": 248.42922973632812, "reward": 0.2677420377731323, "action": -1.4582993984222412}
{"mode": "train", "epochs": 3, "timestep": 4434, "ep_reward": 248.82998657226562, "reward": 0.4007510542869568, "action": -0.6705033779144287}
{"mode": "train", "epochs": 3, "timestep": 4435, "ep_reward": 249.36257934570312, "reward": 0.5325976610183716, "action": -1.7238423824310303}
{"mode": "train", "epochs": 3, "timestep": 4436, "ep_reward": 249.9954833984375, "reward": 0.6329035758972168, "action": -0.6910449266433716}
{"mode": "train", "epochs": 3, "timestep": 4437, "ep_reward": 250.7178497314453, "reward": 0.7223594188690186, "action": -0.8979294896125793}
{"mode": "train", "epochs": 3, "timestep": 4438, "ep_reward": 251.50363159179688, "reward": 0.7857770919799805, "action": -1.6036558151245117}
{"mode": "train", "epochs": 3, "timestep": 4439, "ep_reward": 252.32516479492188, "reward": 0.8215340375900269, "action": -1.6513035297393799}
{"mode": "train", "epochs": 3, "timestep": 4440, "ep_reward": 253.16311645507812, "reward": 0.8379580974578857, "action": -0.5420176982879639}
{"mode": "train", "epochs": 3, "timestep": 4441, "ep_reward": 254.00857543945312, "reward": 0.845458447933197, "action": -0.6269938945770264}
{"mode": "train", "epochs": 3, "timestep": 4442, "ep_reward": 254.8411407470703, "reward": 0.8325716257095337, "action": -0.8785032033920288}
{"mode": "train", "epochs": 3, "timestep": 4443, "ep_reward": 255.63636779785156, "reward": 0.7952196002006531, "action": -0.5988175272941589}
{"mode": "train", "epochs": 3, "timestep": 4444, "ep_reward": 256.370361328125, "reward": 0.734001874923706, "action": -0.7118963003158569}
{"mode": "train", "epochs": 3, "timestep": 4445, "ep_reward": 257.0091552734375, "reward": 0.6387876272201538, "action": -0.9272938370704651}
{"mode": "train", "epochs": 3, "timestep": 4446, "ep_reward": 257.5106506347656, "reward": 0.501491904258728, "action": -0.7275595664978027}
{"mode": "train", "epochs": 3, "timestep": 4447, "ep_reward": 257.86993408203125, "reward": 0.35929346084594727, "action": -1.350803256034851}
{"mode": "train", "epochs": 3, "timestep": 4448, "ep_reward": 258.12115478515625, "reward": 0.25122976303100586, "action": -1.1088839769363403}
{"mode": "train", "epochs": 3, "timestep": 4449, "ep_reward": 258.2442626953125, "reward": 0.12310868501663208, "action": -1.2447963953018188}
{"mode": "train", "epochs": 3, "timestep": 4450, "ep_reward": 258.23529052734375, "reward": -0.008972644805908203, "action": -1.3598544597625732}
{"mode": "train", "epochs": 3, "timestep": 4451, "ep_reward": 258.37237548828125, "reward": 0.1370735764503479, "action": -1.4334529638290405}
{"mode": "train", "epochs": 3, "timestep": 4452, "ep_reward": 258.6433410644531, "reward": 0.27098047733306885, "action": -0.49487781524658203}
{"mode": "train", "epochs": 3, "timestep": 4453, "ep_reward": 259.0590515136719, "reward": 0.41570448875427246, "action": -0.5788155794143677}
{"mode": "train", "epochs": 3, "timestep": 4454, "ep_reward": 259.6051025390625, "reward": 0.5460438132286072, "action": -0.967752993106842}
{"mode": "train", "epochs": 3, "timestep": 4455, "ep_reward": 260.257080078125, "reward": 0.6519697904586792, "action": -1.2057197093963623}
{"mode": "train", "epochs": 3, "timestep": 4456, "ep_reward": 260.99053955078125, "reward": 0.7334492206573486, "action": -1.3442028760910034}
{"mode": "train", "epochs": 3, "timestep": 4457, "ep_reward": 261.7828369140625, "reward": 0.7922916412353516, "action": -1.3862401247024536}
{"mode": "train", "epochs": 3, "timestep": 4458, "ep_reward": 262.6139831542969, "reward": 0.8311329483985901, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4459, "ep_reward": 263.46099853515625, "reward": 0.8470267057418823, "action": -1.2201464176177979}
{"mode": "train", "epochs": 3, "timestep": 4460, "ep_reward": 264.313232421875, "reward": 0.8522260189056396, "action": -0.4052060842514038}
{"mode": "train", "epochs": 3, "timestep": 4461, "ep_reward": 265.1594543457031, "reward": 0.8462173342704773, "action": -1.60295832157135}
{"mode": "train", "epochs": 3, "timestep": 4462, "ep_reward": 265.96783447265625, "reward": 0.808376669883728, "action": -1.4405148029327393}
{"mode": "train", "epochs": 3, "timestep": 4463, "ep_reward": 266.7129821777344, "reward": 0.7451336979866028, "action": -1.4523059129714966}
{"mode": "train", "epochs": 3, "timestep": 4464, "ep_reward": 267.3603515625, "reward": 0.6473785638809204, "action": -1.0225000381469727}
{"mode": "train", "epochs": 3, "timestep": 4465, "ep_reward": 267.8741149902344, "reward": 0.5137702226638794, "action": -1.6464563608169556}
{"mode": "train", "epochs": 3, "timestep": 4466, "ep_reward": 268.251220703125, "reward": 0.37709879875183105, "action": -0.30599457025527954}
{"mode": "train", "epochs": 3, "timestep": 4467, "ep_reward": 268.5238952636719, "reward": 0.2726675271987915, "action": 0.45754003524780273}
{"mode": "train", "epochs": 3, "timestep": 4468, "ep_reward": 268.672119140625, "reward": 0.14823520183563232, "action": -0.5824078321456909}
{"mode": "train", "epochs": 3, "timestep": 4469, "ep_reward": 268.6758728027344, "reward": 0.0037404894828796387, "action": -1.2106939554214478}
{"mode": "train", "epochs": 3, "timestep": 4470, "ep_reward": 268.7876892089844, "reward": 0.11182445287704468, "action": -0.6469548940658569}
{"mode": "train", "epochs": 3, "timestep": 4471, "ep_reward": 269.04254150390625, "reward": 0.25485557317733765, "action": -0.133858323097229}
{"mode": "train", "epochs": 3, "timestep": 4472, "ep_reward": 269.4454650878906, "reward": 0.4029325842857361, "action": -0.5893412828445435}
{"mode": "train", "epochs": 3, "timestep": 4473, "ep_reward": 269.978759765625, "reward": 0.5332927703857422, "action": -1.104221224784851}
{"mode": "train", "epochs": 3, "timestep": 4474, "ep_reward": 270.6185607910156, "reward": 0.6398042440414429, "action": -1.5131350755691528}
{"mode": "train", "epochs": 3, "timestep": 4475, "ep_reward": 271.340576171875, "reward": 0.7220149040222168, "action": -0.7799767255783081}
{"mode": "train", "epochs": 3, "timestep": 4476, "ep_reward": 272.131103515625, "reward": 0.7905353307723999, "action": -1.187476634979248}
{"mode": "train", "epochs": 3, "timestep": 4477, "ep_reward": 272.96673583984375, "reward": 0.8356322646141052, "action": -1.8811827898025513}
{"mode": "train", "epochs": 3, "timestep": 4478, "ep_reward": 273.8252258300781, "reward": 0.8584932684898376, "action": -1.1034306287765503}
{"mode": "train", "epochs": 3, "timestep": 4479, "ep_reward": 274.69732666015625, "reward": 0.8720943331718445, "action": -1.9062455892562866}
{"mode": "train", "epochs": 3, "timestep": 4480, "ep_reward": 275.5606994628906, "reward": 0.8633716106414795, "action": -1.6329009532928467}
{"mode": "train", "epochs": 3, "timestep": 4481, "ep_reward": 276.39935302734375, "reward": 0.8386500477790833, "action": -1.490724802017212}
{"mode": "train", "epochs": 3, "timestep": 4482, "ep_reward": 277.19195556640625, "reward": 0.7926006317138672, "action": -1.0891069173812866}
{"mode": "train", "epochs": 3, "timestep": 4483, "ep_reward": 277.9142150878906, "reward": 0.7222620844841003, "action": -0.7518786787986755}
{"mode": "train", "epochs": 3, "timestep": 4484, "ep_reward": 278.53558349609375, "reward": 0.6213561296463013, "action": -1.029482126235962}
{"mode": "train", "epochs": 3, "timestep": 4485, "ep_reward": 279.0119323730469, "reward": 0.4763554334640503, "action": -1.1430952548980713}
{"mode": "train", "epochs": 3, "timestep": 4486, "ep_reward": 279.357421875, "reward": 0.34549808502197266, "action": 0.33605778217315674}
{"mode": "train", "epochs": 3, "timestep": 4487, "ep_reward": 279.59197998046875, "reward": 0.23455137014389038, "action": -0.9849751591682434}
{"mode": "train", "epochs": 3, "timestep": 4488, "ep_reward": 279.69561767578125, "reward": 0.10363829135894775, "action": -1.1401606798171997}
{"mode": "train", "epochs": 3, "timestep": 4489, "ep_reward": 279.7083435058594, "reward": 0.01273423433303833, "action": -0.4013252854347229}
{"mode": "train", "epochs": 3, "timestep": 4490, "ep_reward": 279.8643493652344, "reward": 0.15600556135177612, "action": 0.1712801456451416}
{"mode": "train", "epochs": 3, "timestep": 4491, "ep_reward": 280.1744384765625, "reward": 0.310081422328949, "action": -0.7788848876953125}
{"mode": "train", "epochs": 3, "timestep": 4492, "ep_reward": 280.6205749511719, "reward": 0.44614529609680176, "action": -1.2693806886672974}
{"mode": "train", "epochs": 3, "timestep": 4493, "ep_reward": 281.1844787597656, "reward": 0.5638924837112427, "action": -0.49495410919189453}
{"mode": "train", "epochs": 3, "timestep": 4494, "ep_reward": 281.8556823730469, "reward": 0.6712042093276978, "action": -1.4763600826263428}
{"mode": "train", "epochs": 3, "timestep": 4495, "ep_reward": 282.6024475097656, "reward": 0.746772050857544, "action": -0.9008495807647705}
{"mode": "train", "epochs": 3, "timestep": 4496, "ep_reward": 283.4099426269531, "reward": 0.8074970245361328, "action": -1.2561862468719482}
{"mode": "train", "epochs": 3, "timestep": 4497, "ep_reward": 284.2565002441406, "reward": 0.8465541005134583, "action": -0.8591461777687073}
{"mode": "train", "epochs": 3, "timestep": 4498, "ep_reward": 285.1290283203125, "reward": 0.8725400567054749, "action": -1.3273543119430542}
{"mode": "train", "epochs": 3, "timestep": 4499, "ep_reward": 286.0089111328125, "reward": 0.8798838257789612, "action": -1.804905891418457}
{"mode": "train", "epochs": 3, "timestep": 4500, "ep_reward": 286.8773193359375, "reward": 0.868395209312439, "action": -1.2387769222259521}
{"mode": "train", "epochs": 3, "timestep": 4501, "ep_reward": 287.72125244140625, "reward": 0.8439321517944336, "action": -1.4190080165863037}
{"mode": "train", "epochs": 3, "timestep": 4502, "ep_reward": 288.5172119140625, "reward": 0.795962393283844, "action": -1.247782826423645}
{"mode": "train", "epochs": 3, "timestep": 4503, "ep_reward": 289.2387390136719, "reward": 0.7215325236320496, "action": -0.18676984310150146}
{"mode": "train", "epochs": 3, "timestep": 4504, "ep_reward": 289.8646545410156, "reward": 0.625920295715332, "action": -1.1297473907470703}
{"mode": "train", "epochs": 3, "timestep": 4505, "ep_reward": 290.34423828125, "reward": 0.47957438230514526, "action": -0.08717936277389526}
{"mode": "train", "epochs": 3, "timestep": 4506, "ep_reward": 290.6826477050781, "reward": 0.3384213447570801, "action": -0.7163823843002319}
{"mode": "train", "epochs": 3, "timestep": 4507, "ep_reward": 290.9087219238281, "reward": 0.22607958316802979, "action": -1.2162678241729736}
{"mode": "train", "epochs": 3, "timestep": 4508, "ep_reward": 291.0025329589844, "reward": 0.09382021427154541, "action": -1.066150188446045}
{"mode": "train", "epochs": 3, "timestep": 4509, "ep_reward": 291.0258483886719, "reward": 0.02330172061920166, "action": -0.72850501537323}
{"mode": "train", "epochs": 3, "timestep": 4510, "ep_reward": 291.19097900390625, "reward": 0.16513937711715698, "action": -1.0610826015472412}
{"mode": "train", "epochs": 3, "timestep": 4511, "ep_reward": 291.4952392578125, "reward": 0.3042502999305725, "action": -0.7947748899459839}
{"mode": "train", "epochs": 3, "timestep": 4512, "ep_reward": 291.9381103515625, "reward": 0.4428812265396118, "action": -0.4191415309906006}
{"mode": "train", "epochs": 3, "timestep": 4513, "ep_reward": 292.50958251953125, "reward": 0.5714578628540039, "action": -0.7858855724334717}
{"mode": "train", "epochs": 3, "timestep": 4514, "ep_reward": 293.18408203125, "reward": 0.6745113134384155, "action": -0.6035972833633423}
{"mode": "train", "epochs": 3, "timestep": 4515, "ep_reward": 293.940673828125, "reward": 0.7565821409225464, "action": -0.8456575274467468}
{"mode": "train", "epochs": 3, "timestep": 4516, "ep_reward": 294.7554016113281, "reward": 0.8147278428077698, "action": -0.9785082936286926}
{"mode": "train", "epochs": 3, "timestep": 4517, "ep_reward": 295.6084899902344, "reward": 0.8530831336975098, "action": -1.5069198608398438}
{"mode": "train", "epochs": 3, "timestep": 4518, "ep_reward": 296.4798583984375, "reward": 0.8713791370391846, "action": -0.6679943799972534}
{"mode": "train", "epochs": 3, "timestep": 4519, "ep_reward": 297.3614196777344, "reward": 0.8815498352050781, "action": -0.8849624991416931}
{"mode": "train", "epochs": 3, "timestep": 4520, "ep_reward": 298.2364501953125, "reward": 0.8750214576721191, "action": -1.5812268257141113}
{"mode": "train", "epochs": 3, "timestep": 4521, "ep_reward": 299.08209228515625, "reward": 0.8456557989120483, "action": -1.773569107055664}
{"mode": "train", "epochs": 3, "timestep": 4522, "ep_reward": 299.874267578125, "reward": 0.7921642065048218, "action": -0.4516271948814392}
{"mode": "train", "epochs": 3, "timestep": 4523, "ep_reward": 300.5985107421875, "reward": 0.7242584228515625, "action": -1.1205389499664307}
{"mode": "train", "epochs": 3, "timestep": 4524, "ep_reward": 301.2137451171875, "reward": 0.6152279376983643, "action": -0.20028841495513916}
{"mode": "train", "epochs": 3, "timestep": 4525, "ep_reward": 301.6934509277344, "reward": 0.479692280292511, "action": -0.6212841272354126}
{"mode": "train", "epochs": 3, "timestep": 4526, "ep_reward": 302.0248107910156, "reward": 0.3313528299331665, "action": -1.0216294527053833}
{"mode": "train", "epochs": 3, "timestep": 4527, "ep_reward": 302.2425537109375, "reward": 0.21774601936340332, "action": -0.6208603382110596}
{"mode": "train", "epochs": 3, "timestep": 4528, "ep_reward": 302.3265686035156, "reward": 0.08402591943740845, "action": -1.2449649572372437}
{"mode": "train", "epochs": 3, "timestep": 4529, "ep_reward": 302.3602294921875, "reward": 0.033660829067230225, "action": -0.27418315410614014}
{"mode": "train", "epochs": 3, "timestep": 4530, "ep_reward": 302.5390319824219, "reward": 0.1788150668144226, "action": -1.3829681873321533}
{"mode": "train", "epochs": 3, "timestep": 4531, "ep_reward": 302.8522033691406, "reward": 0.3131588101387024, "action": -0.8115895986557007}
{"mode": "train", "epochs": 3, "timestep": 4532, "ep_reward": 303.3030090332031, "reward": 0.45080506801605225, "action": -1.5856378078460693}
{"mode": "train", "epochs": 3, "timestep": 4533, "ep_reward": 303.8683166503906, "reward": 0.5652962923049927, "action": -1.135204792022705}
{"mode": "train", "epochs": 3, "timestep": 4534, "ep_reward": 304.5340270996094, "reward": 0.6656967997550964, "action": -0.7601410150527954}
{"mode": "train", "epochs": 3, "timestep": 4535, "ep_reward": 305.2809753417969, "reward": 0.746962308883667, "action": -0.5040146112442017}
{"mode": "train", "epochs": 3, "timestep": 4536, "ep_reward": 306.0885925292969, "reward": 0.8076265454292297, "action": -1.2788505554199219}
{"mode": "train", "epochs": 3, "timestep": 4537, "ep_reward": 306.9299011230469, "reward": 0.8413181900978088, "action": 0.1136084794998169}
{"mode": "train", "epochs": 3, "timestep": 4538, "ep_reward": 307.7989501953125, "reward": 0.8690627217292786, "action": -1.8590447902679443}
{"mode": "train", "epochs": 3, "timestep": 4539, "ep_reward": 308.66302490234375, "reward": 0.864082932472229, "action": -0.9154767990112305}
{"mode": "train", "epochs": 3, "timestep": 4540, "ep_reward": 309.5126953125, "reward": 0.8496586680412292, "action": -1.332829236984253}
{"mode": "train", "epochs": 3, "timestep": 4541, "ep_reward": 310.3236999511719, "reward": 0.8110067844390869, "action": -1.1002140045166016}
{"mode": "train", "epochs": 3, "timestep": 4542, "ep_reward": 311.0723571777344, "reward": 0.7486612796783447, "action": -0.8221638798713684}
{"mode": "train", "epochs": 3, "timestep": 4543, "ep_reward": 311.7296447753906, "reward": 0.6572781801223755, "action": -0.4801671504974365}
{"mode": "train", "epochs": 3, "timestep": 4544, "ep_reward": 312.2622375488281, "reward": 0.5325906276702881, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4545, "ep_reward": 312.6343994140625, "reward": 0.37216246128082275, "action": -0.15693247318267822}
{"mode": "train", "epochs": 3, "timestep": 4546, "ep_reward": 312.9010925292969, "reward": 0.26668447256088257, "action": -0.5209189057350159}
{"mode": "train", "epochs": 3, "timestep": 4547, "ep_reward": 313.0422668457031, "reward": 0.14118629693984985, "action": -0.9225090742111206}
{"mode": "train", "epochs": 3, "timestep": 4548, "ep_reward": 313.037841796875, "reward": -0.004414916038513184, "action": -1.7570908069610596}
{"mode": "train", "epochs": 3, "timestep": 4549, "ep_reward": 313.15679931640625, "reward": 0.11897224187850952, "action": -1.339200496673584}
{"mode": "train", "epochs": 3, "timestep": 4550, "ep_reward": 313.410400390625, "reward": 0.25359266996383667, "action": -0.33494019508361816}
{"mode": "train", "epochs": 3, "timestep": 4551, "ep_reward": 313.8112487792969, "reward": 0.40085190534591675, "action": -0.6469419598579407}
{"mode": "train", "epochs": 3, "timestep": 4552, "ep_reward": 314.34307861328125, "reward": 0.5318256616592407, "action": -1.4903982877731323}
{"mode": "train", "epochs": 3, "timestep": 4553, "ep_reward": 314.9779052734375, "reward": 0.6348191499710083, "action": -1.1394150257110596}
{"mode": "train", "epochs": 3, "timestep": 4554, "ep_reward": 315.6986389160156, "reward": 0.7207375168800354, "action": -0.870622992515564}
{"mode": "train", "epochs": 3, "timestep": 4555, "ep_reward": 316.48565673828125, "reward": 0.7870047688484192, "action": -1.7308032512664795}
{"mode": "train", "epochs": 3, "timestep": 4556, "ep_reward": 317.31103515625, "reward": 0.8253719210624695, "action": -1.1807825565338135}
{"mode": "train", "epochs": 3, "timestep": 4557, "ep_reward": 318.1617126464844, "reward": 0.8506793975830078, "action": -0.9395291209220886}
{"mode": "train", "epochs": 3, "timestep": 4558, "ep_reward": 319.02252197265625, "reward": 0.8608193397521973, "action": -0.4914586544036865}
{"mode": "train", "epochs": 3, "timestep": 4559, "ep_reward": 319.88006591796875, "reward": 0.8575460910797119, "action": -1.308188796043396}
{"mode": "train", "epochs": 3, "timestep": 4560, "ep_reward": 320.708251953125, "reward": 0.8281716108322144, "action": -0.20828557014465332}
{"mode": "train", "epochs": 3, "timestep": 4561, "ep_reward": 321.4949645996094, "reward": 0.7867140769958496, "action": -1.1301770210266113}
{"mode": "train", "epochs": 3, "timestep": 4562, "ep_reward": 322.2028503417969, "reward": 0.7078748345375061, "action": -1.2529575824737549}
{"mode": "train", "epochs": 3, "timestep": 4563, "ep_reward": 322.7941589355469, "reward": 0.5913150310516357, "action": -0.4985295534133911}
{"mode": "train", "epochs": 3, "timestep": 4564, "ep_reward": 323.2383117675781, "reward": 0.44416379928588867, "action": -0.9111871719360352}
{"mode": "train", "epochs": 3, "timestep": 4565, "ep_reward": 323.5551452636719, "reward": 0.31683027744293213, "action": -0.4655548930168152}
{"mode": "train", "epochs": 3, "timestep": 4566, "ep_reward": 323.7554931640625, "reward": 0.20034557580947876, "action": -1.0976674556732178}
{"mode": "train", "epochs": 3, "timestep": 4567, "ep_reward": 323.8194580078125, "reward": 0.06396353244781494, "action": -0.7488055229187012}
{"mode": "train", "epochs": 3, "timestep": 4568, "ep_reward": 323.873779296875, "reward": 0.054313719272613525, "action": -0.8290361166000366}
{"mode": "train", "epochs": 3, "timestep": 4569, "ep_reward": 324.06707763671875, "reward": 0.19330477714538574, "action": -0.8421781063079834}
{"mode": "train", "epochs": 3, "timestep": 4570, "ep_reward": 324.40234375, "reward": 0.3352564573287964, "action": -0.8164504766464233}
{"mode": "train", "epochs": 3, "timestep": 4571, "ep_reward": 324.8733825683594, "reward": 0.4710359573364258, "action": -1.0996029376983643}
{"mode": "train", "epochs": 3, "timestep": 4572, "ep_reward": 325.4613952636719, "reward": 0.588019609451294, "action": -0.8730777502059937}
{"mode": "train", "epochs": 3, "timestep": 4573, "ep_reward": 326.14813232421875, "reward": 0.6867219805717468, "action": -0.8463804125785828}
{"mode": "train", "epochs": 3, "timestep": 4574, "ep_reward": 326.91094970703125, "reward": 0.7628124952316284, "action": -0.7963557839393616}
{"mode": "train", "epochs": 3, "timestep": 4575, "ep_reward": 327.728759765625, "reward": 0.8177962899208069, "action": -0.9613832235336304}
{"mode": "train", "epochs": 3, "timestep": 4576, "ep_reward": 328.5812072753906, "reward": 0.8524608612060547, "action": -0.6906512975692749}
{"mode": "train", "epochs": 3, "timestep": 4577, "ep_reward": 329.4539489746094, "reward": 0.8727478384971619, "action": -0.9444513916969299}
{"mode": "train", "epochs": 3, "timestep": 4578, "ep_reward": 330.32940673828125, "reward": 0.8754462003707886, "action": -1.6074755191802979}
{"mode": "train", "epochs": 3, "timestep": 4579, "ep_reward": 331.1859436035156, "reward": 0.856544554233551, "action": -0.11083942651748657}
{"mode": "train", "epochs": 3, "timestep": 4580, "ep_reward": 332.0177917480469, "reward": 0.8318530321121216, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4581, "ep_reward": 332.7835998535156, "reward": 0.7657989263534546, "action": -0.8908484578132629}
{"mode": "train", "epochs": 3, "timestep": 4582, "ep_reward": 333.46331787109375, "reward": 0.6797260046005249, "action": -0.8698099255561829}
{"mode": "train", "epochs": 3, "timestep": 4583, "ep_reward": 334.0202941894531, "reward": 0.5569796562194824, "action": -1.2449519634246826}
{"mode": "train", "epochs": 3, "timestep": 4584, "ep_reward": 334.4073486328125, "reward": 0.3870481252670288, "action": -0.061375558376312256}
{"mode": "train", "epochs": 3, "timestep": 4585, "ep_reward": 334.6903381347656, "reward": 0.28299033641815186, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4586, "ep_reward": 334.85089111328125, "reward": 0.16055738925933838, "action": -1.3980656862258911}
{"mode": "train", "epochs": 3, "timestep": 4587, "ep_reward": 334.86895751953125, "reward": 0.018052339553833008, "action": -1.0352802276611328}
{"mode": "train", "epochs": 3, "timestep": 4588, "ep_reward": 334.96746826171875, "reward": 0.09850919246673584, "action": -1.981208086013794}
{"mode": "train", "epochs": 3, "timestep": 4589, "ep_reward": 335.19775390625, "reward": 0.2302989363670349, "action": -0.9044473767280579}
{"mode": "train", "epochs": 3, "timestep": 4590, "ep_reward": 335.56964111328125, "reward": 0.37187427282333374, "action": -1.2236649990081787}
{"mode": "train", "epochs": 3, "timestep": 4591, "ep_reward": 336.0699768066406, "reward": 0.5003393888473511, "action": -0.5758170485496521}
{"mode": "train", "epochs": 3, "timestep": 4592, "ep_reward": 336.688720703125, "reward": 0.6187368631362915, "action": -0.6912354230880737}
{"mode": "train", "epochs": 3, "timestep": 4593, "ep_reward": 337.40106201171875, "reward": 0.7123435735702515, "action": -0.2344346046447754}
{"mode": "train", "epochs": 3, "timestep": 4594, "ep_reward": 338.1876525878906, "reward": 0.7865976095199585, "action": -0.3007373809814453}
{"mode": "train", "epochs": 3, "timestep": 4595, "ep_reward": 339.0256652832031, "reward": 0.8380199670791626, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4596, "ep_reward": 339.8833923339844, "reward": 0.8577216863632202, "action": -0.41371655464172363}
{"mode": "train", "epochs": 3, "timestep": 4597, "ep_reward": 340.7579040527344, "reward": 0.8745207786560059, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4598, "ep_reward": 341.6204833984375, "reward": 0.8625803589820862, "action": -0.566788911819458}
{"mode": "train", "epochs": 3, "timestep": 4599, "ep_reward": 342.46551513671875, "reward": 0.8450179100036621, "action": -1.0906083583831787}
{"mode": "train", "epochs": 3, "timestep": 4600, "ep_reward": 343.2673034667969, "reward": 0.8018020391464233, "action": -0.8033506870269775}
{"mode": "train", "epochs": 3, "timestep": 4601, "ep_reward": 344.0022888183594, "reward": 0.7349869012832642, "action": -0.9278889298439026}
{"mode": "train", "epochs": 3, "timestep": 4602, "ep_reward": 344.6360168457031, "reward": 0.6337401866912842, "action": -1.5942472219467163}
{"mode": "train", "epochs": 3, "timestep": 4603, "ep_reward": 345.1190490722656, "reward": 0.48302918672561646, "action": -1.2135066986083984}
{"mode": "train", "epochs": 3, "timestep": 4604, "ep_reward": 345.464111328125, "reward": 0.34507012367248535, "action": -1.4160268306732178}
{"mode": "train", "epochs": 3, "timestep": 4605, "ep_reward": 345.6983337402344, "reward": 0.23421555757522583, "action": -0.6382683515548706}
{"mode": "train", "epochs": 3, "timestep": 4606, "ep_reward": 345.8016052246094, "reward": 0.10326951742172241, "action": -0.5302693843841553}
{"mode": "train", "epochs": 3, "timestep": 4607, "ep_reward": 345.81475830078125, "reward": 0.013156414031982422, "action": -0.9639105796813965}
{"mode": "train", "epochs": 3, "timestep": 4608, "ep_reward": 345.9710693359375, "reward": 0.15630453824996948, "action": -1.3371237516403198}
{"mode": "train", "epochs": 3, "timestep": 4609, "ep_reward": 346.2629089355469, "reward": 0.29184263944625854, "action": -0.4968661665916443}
{"mode": "train", "epochs": 3, "timestep": 4610, "ep_reward": 346.6980895996094, "reward": 0.4351885914802551, "action": -1.155447006225586}
{"mode": "train", "epochs": 3, "timestep": 4611, "ep_reward": 347.2546691894531, "reward": 0.556584358215332, "action": -0.6865912675857544}
{"mode": "train", "epochs": 3, "timestep": 4612, "ep_reward": 347.9180908203125, "reward": 0.6634261608123779, "action": -1.0947030782699585}
{"mode": "train", "epochs": 3, "timestep": 4613, "ep_reward": 348.6611633300781, "reward": 0.743082582950592, "action": 0.01829349994659424}
{"mode": "train", "epochs": 3, "timestep": 4614, "ep_reward": 349.4720458984375, "reward": 0.8108969926834106, "action": -0.6886124610900879}
{"mode": "train", "epochs": 3, "timestep": 4615, "ep_reward": 350.3240051269531, "reward": 0.8519566655158997, "action": -0.8276259899139404}
{"mode": "train", "epochs": 3, "timestep": 4616, "ep_reward": 351.1993408203125, "reward": 0.8753465414047241, "action": -0.7343024015426636}
{"mode": "train", "epochs": 3, "timestep": 4617, "ep_reward": 352.08404541015625, "reward": 0.8846943378448486, "action": -1.176353931427002}
{"mode": "train", "epochs": 3, "timestep": 4618, "ep_reward": 352.96014404296875, "reward": 0.8760881423950195, "action": -0.060630857944488525}
{"mode": "train", "epochs": 3, "timestep": 4619, "ep_reward": 353.8208312988281, "reward": 0.860687792301178, "action": -1.6778488159179688}
{"mode": "train", "epochs": 3, "timestep": 4620, "ep_reward": 354.6327209472656, "reward": 0.8118836879730225, "action": -1.2968330383300781}
{"mode": "train", "epochs": 3, "timestep": 4621, "ep_reward": 355.3726806640625, "reward": 0.7399716377258301, "action": -0.8820309638977051}
{"mode": "train", "epochs": 3, "timestep": 4622, "ep_reward": 356.0124206542969, "reward": 0.6397355794906616, "action": -0.24227678775787354}
{"mode": "train", "epochs": 3, "timestep": 4623, "ep_reward": 356.5232238769531, "reward": 0.5107965469360352, "action": 0.11353087425231934}
{"mode": "train", "epochs": 3, "timestep": 4624, "ep_reward": 356.8742370605469, "reward": 0.35102003812789917, "action": -1.2958014011383057}
{"mode": "train", "epochs": 3, "timestep": 4625, "ep_reward": 357.10980224609375, "reward": 0.23557955026626587, "action": -1.2870750427246094}
{"mode": "train", "epochs": 3, "timestep": 4626, "ep_reward": 357.2145690917969, "reward": 0.10477668046951294, "action": -1.7488901615142822}
{"mode": "train", "epochs": 3, "timestep": 4627, "ep_reward": 357.22589111328125, "reward": 0.011319935321807861, "action": -1.018225908279419}
{"mode": "train", "epochs": 3, "timestep": 4628, "ep_reward": 357.380615234375, "reward": 0.15473878383636475, "action": -1.1758911609649658}
{"mode": "train", "epochs": 3, "timestep": 4629, "ep_reward": 357.6728210449219, "reward": 0.2921944856643677, "action": -1.0341628789901733}
{"mode": "train", "epochs": 3, "timestep": 4630, "ep_reward": 358.1016540527344, "reward": 0.42883652448654175, "action": -0.6293890476226807}
{"mode": "train", "epochs": 3, "timestep": 4631, "ep_reward": 358.65887451171875, "reward": 0.5572056174278259, "action": -1.0585519075393677}
{"mode": "train", "epochs": 3, "timestep": 4632, "ep_reward": 359.31903076171875, "reward": 0.660163402557373, "action": -0.28361302614212036}
{"mode": "train", "epochs": 3, "timestep": 4633, "ep_reward": 360.06707763671875, "reward": 0.7480547428131104, "action": -1.0659438371658325}
{"mode": "train", "epochs": 3, "timestep": 4634, "ep_reward": 360.8729248046875, "reward": 0.8058362007141113, "action": -0.29099512100219727}
{"mode": "train", "epochs": 3, "timestep": 4635, "ep_reward": 361.7237854003906, "reward": 0.8508651256561279, "action": -1.0344816446304321}
{"mode": "train", "epochs": 3, "timestep": 4636, "ep_reward": 362.5965270996094, "reward": 0.872734785079956, "action": -0.9073241353034973}
{"mode": "train", "epochs": 3, "timestep": 4637, "ep_reward": 363.4772644042969, "reward": 0.8807258009910583, "action": -0.6592575311660767}
{"mode": "train", "epochs": 3, "timestep": 4638, "ep_reward": 364.35308837890625, "reward": 0.875811755657196, "action": -1.1144052743911743}
{"mode": "train", "epochs": 3, "timestep": 4639, "ep_reward": 365.2035827636719, "reward": 0.850500226020813, "action": -1.8200583457946777}
{"mode": "train", "epochs": 3, "timestep": 4640, "ep_reward": 366.00103759765625, "reward": 0.7974429130554199, "action": -0.6664562225341797}
{"mode": "train", "epochs": 3, "timestep": 4641, "ep_reward": 366.7293701171875, "reward": 0.7283459901809692, "action": -0.46829652786254883}
{"mode": "train", "epochs": 3, "timestep": 4642, "ep_reward": 367.3586120605469, "reward": 0.629255473613739, "action": -1.4771151542663574}
{"mode": "train", "epochs": 3, "timestep": 4643, "ep_reward": 367.8365783691406, "reward": 0.4779796004295349, "action": -0.4641305208206177}
{"mode": "train", "epochs": 3, "timestep": 4644, "ep_reward": 368.1708984375, "reward": 0.33431655168533325, "action": -0.24974340200424194}
{"mode": "train", "epochs": 3, "timestep": 4645, "ep_reward": 368.3919982910156, "reward": 0.22109133005142212, "action": -1.511306643486023}
{"mode": "train", "epochs": 3, "timestep": 4646, "ep_reward": 368.4800720214844, "reward": 0.08806884288787842, "action": -1.1277167797088623}
{"mode": "train", "epochs": 3, "timestep": 4647, "ep_reward": 368.5092468261719, "reward": 0.029181599617004395, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4648, "ep_reward": 368.67974853515625, "reward": 0.1705009937286377, "action": -0.08808028697967529}
{"mode": "train", "epochs": 3, "timestep": 4649, "ep_reward": 369.00140380859375, "reward": 0.32166194915771484, "action": -0.848217785358429}
{"mode": "train", "epochs": 3, "timestep": 4650, "ep_reward": 369.4581298828125, "reward": 0.4567232131958008, "action": -1.4882326126098633}
{"mode": "train", "epochs": 3, "timestep": 4651, "ep_reward": 370.0291442871094, "reward": 0.571019172668457, "action": -0.5954650044441223}
{"mode": "train", "epochs": 3, "timestep": 4652, "ep_reward": 370.7052001953125, "reward": 0.6760501861572266, "action": -0.853940486907959}
{"mode": "train", "epochs": 3, "timestep": 4653, "ep_reward": 371.4607238769531, "reward": 0.7555254697799683, "action": -0.9551798701286316}
{"mode": "train", "epochs": 3, "timestep": 4654, "ep_reward": 372.27349853515625, "reward": 0.8127638101577759, "action": -1.6410777568817139}
{"mode": "train", "epochs": 3, "timestep": 4655, "ep_reward": 373.1194152832031, "reward": 0.8459043502807617, "action": -1.072594165802002}
{"mode": "train", "epochs": 3, "timestep": 4656, "ep_reward": 373.9869689941406, "reward": 0.8675649166107178, "action": -0.8390251994132996}
{"mode": "train", "epochs": 3, "timestep": 4657, "ep_reward": 374.8625183105469, "reward": 0.8755441904067993, "action": -1.1284161806106567}
{"mode": "train", "epochs": 3, "timestep": 4658, "ep_reward": 375.72796630859375, "reward": 0.8654481172561646, "action": -0.8309192061424255}
{"mode": "train", "epochs": 3, "timestep": 4659, "ep_reward": 376.568115234375, "reward": 0.8401361703872681, "action": -0.6600099802017212}
{"mode": "train", "epochs": 3, "timestep": 4660, "ep_reward": 377.3632507324219, "reward": 0.7951244711875916, "action": -0.653164803981781}
{"mode": "train", "epochs": 3, "timestep": 4661, "ep_reward": 378.08697509765625, "reward": 0.7237263321876526, "action": -0.7832600474357605}
{"mode": "train", "epochs": 3, "timestep": 4662, "ep_reward": 378.7048645019531, "reward": 0.6178938150405884, "action": -0.5566710233688354}
{"mode": "train", "epochs": 3, "timestep": 4663, "ep_reward": 379.1817932128906, "reward": 0.4769399166107178, "action": -0.854536771774292}
{"mode": "train", "epochs": 3, "timestep": 4664, "ep_reward": 379.5079650878906, "reward": 0.32617777585983276, "action": -0.7506099343299866}
{"mode": "train", "epochs": 3, "timestep": 4665, "ep_reward": 379.7193908691406, "reward": 0.2114177942276001, "action": -1.5380154848098755}
{"mode": "train", "epochs": 3, "timestep": 4666, "ep_reward": 379.7962646484375, "reward": 0.07686221599578857, "action": -0.9519075155258179}
{"mode": "train", "epochs": 3, "timestep": 4667, "ep_reward": 379.83734130859375, "reward": 0.04108983278274536, "action": -1.0783525705337524}
{"mode": "train", "epochs": 3, "timestep": 4668, "ep_reward": 380.01788330078125, "reward": 0.1805548071861267, "action": -1.365604043006897}
{"mode": "train", "epochs": 3, "timestep": 4669, "ep_reward": 380.33404541015625, "reward": 0.31615734100341797, "action": -0.6767703294754028}
{"mode": "train", "epochs": 3, "timestep": 4670, "ep_reward": 380.78985595703125, "reward": 0.45580893754959106, "action": -1.8223485946655273}
{"mode": "train", "epochs": 3, "timestep": 4671, "ep_reward": 381.35687255859375, "reward": 0.5670122504234314, "action": -1.6046371459960938}
{"mode": "train", "epochs": 3, "timestep": 4672, "ep_reward": 382.0186462402344, "reward": 0.661780834197998, "action": -1.3822824954986572}
{"mode": "train", "epochs": 3, "timestep": 4673, "ep_reward": 382.7550964355469, "reward": 0.7364440560340881, "action": -1.2236499786376953}
{"mode": "train", "epochs": 3, "timestep": 4674, "ep_reward": 383.5450439453125, "reward": 0.789944589138031, "action": 0.24541938304901123}
{"mode": "train", "epochs": 3, "timestep": 4675, "ep_reward": 384.38043212890625, "reward": 0.8353946805000305, "action": -1.0296694040298462}
{"mode": "train", "epochs": 3, "timestep": 4676, "ep_reward": 385.2296447753906, "reward": 0.8492239117622375, "action": -1.1390292644500732}
{"mode": "train", "epochs": 3, "timestep": 4677, "ep_reward": 386.07318115234375, "reward": 0.8435342907905579, "action": -0.47987914085388184}
{"mode": "train", "epochs": 3, "timestep": 4678, "ep_reward": 386.8970642089844, "reward": 0.823879063129425, "action": -0.7057053446769714}
{"mode": "train", "epochs": 3, "timestep": 4679, "ep_reward": 387.676025390625, "reward": 0.7789686918258667, "action": -0.1706368327140808}
{"mode": "train", "epochs": 3, "timestep": 4680, "ep_reward": 388.3880920410156, "reward": 0.7120761275291443, "action": -0.6693782210350037}
{"mode": "train", "epochs": 3, "timestep": 4681, "ep_reward": 388.9939880371094, "reward": 0.6059093475341797, "action": -0.8276668787002563}
{"mode": "train", "epochs": 3, "timestep": 4682, "ep_reward": 389.45196533203125, "reward": 0.45796263217926025, "action": -0.7452500462532043}
{"mode": "train", "epochs": 3, "timestep": 4683, "ep_reward": 389.7776794433594, "reward": 0.3257094621658325, "action": -1.7132060527801514}
{"mode": "train", "epochs": 3, "timestep": 4684, "ep_reward": 389.9888000488281, "reward": 0.2111327052116394, "action": -0.9090589284896851}
{"mode": "train", "epochs": 3, "timestep": 4685, "ep_reward": 390.0652770996094, "reward": 0.07646256685256958, "action": 0.4715350866317749}
{"mode": "train", "epochs": 3, "timestep": 4686, "ep_reward": 390.1068420410156, "reward": 0.0415613055229187, "action": -0.9654956459999084}
{"mode": "train", "epochs": 3, "timestep": 4687, "ep_reward": 390.28778076171875, "reward": 0.18092679977416992, "action": -1.4991610050201416}
{"mode": "train", "epochs": 3, "timestep": 4688, "ep_reward": 390.60247802734375, "reward": 0.31471139192581177, "action": -1.7549251317977905}
{"mode": "train", "epochs": 3, "timestep": 4689, "ep_reward": 391.0443420410156, "reward": 0.4418746829032898, "action": -0.9351786375045776}
{"mode": "train", "epochs": 3, "timestep": 4690, "ep_reward": 391.6101379394531, "reward": 0.5657979249954224, "action": -0.5052303075790405}
{"mode": "train", "epochs": 3, "timestep": 4691, "ep_reward": 392.2823486328125, "reward": 0.672222375869751, "action": -1.5230884552001953}
{"mode": "train", "epochs": 3, "timestep": 4692, "ep_reward": 393.0260925292969, "reward": 0.7437530755996704, "action": -0.9198580384254456}
{"mode": "train", "epochs": 3, "timestep": 4693, "ep_reward": 393.82513427734375, "reward": 0.7990565896034241, "action": -0.6388805508613586}
{"mode": "train", "epochs": 3, "timestep": 4694, "ep_reward": 394.66094970703125, "reward": 0.8358184099197388, "action": -1.0249298810958862}
{"mode": "train", "epochs": 3, "timestep": 4695, "ep_reward": 395.51092529296875, "reward": 0.8499659895896912, "action": -1.4958010911941528}
{"mode": "train", "epochs": 3, "timestep": 4696, "ep_reward": 396.35235595703125, "reward": 0.8414288759231567, "action": 0.1308838129043579}
{"mode": "train", "epochs": 3, "timestep": 4697, "ep_reward": 397.1803283691406, "reward": 0.8279794454574585, "action": -1.1601473093032837}
{"mode": "train", "epochs": 3, "timestep": 4698, "ep_reward": 397.9595642089844, "reward": 0.7792258858680725, "action": -0.7222346067428589}
{"mode": "train", "epochs": 3, "timestep": 4699, "ep_reward": 398.6656494140625, "reward": 0.7060960531234741, "action": -0.5874574184417725}
{"mode": "train", "epochs": 3, "timestep": 4700, "ep_reward": 399.26544189453125, "reward": 0.5998063087463379, "action": -1.225378394126892}
{"mode": "train", "epochs": 3, "timestep": 4701, "ep_reward": 399.7093505859375, "reward": 0.4439096450805664, "action": -1.3415583372116089}
{"mode": "train", "epochs": 3, "timestep": 4702, "ep_reward": 400.03326416015625, "reward": 0.3239099979400635, "action": -0.8156619668006897}
{"mode": "train", "epochs": 3, "timestep": 4703, "ep_reward": 400.2420349121094, "reward": 0.20876044034957886, "action": -1.3413163423538208}
{"mode": "train", "epochs": 3, "timestep": 4704, "ep_reward": 400.3158264160156, "reward": 0.07379394769668579, "action": -0.11955136060714722}
{"mode": "train", "epochs": 3, "timestep": 4705, "ep_reward": 400.36016845703125, "reward": 0.04433351755142212, "action": -0.8802779316902161}
{"mode": "train", "epochs": 3, "timestep": 4706, "ep_reward": 400.5436096191406, "reward": 0.18343985080718994, "action": -0.5625365972518921}
{"mode": "train", "epochs": 3, "timestep": 4707, "ep_reward": 400.8725891113281, "reward": 0.32896506786346436, "action": -0.9791983366012573}
{"mode": "train", "epochs": 3, "timestep": 4708, "ep_reward": 401.33544921875, "reward": 0.46285897493362427, "action": -1.6444131135940552}
{"mode": "train", "epochs": 3, "timestep": 4709, "ep_reward": 401.9104309082031, "reward": 0.5749895572662354, "action": -0.6903682947158813}
{"mode": "train", "epochs": 3, "timestep": 4710, "ep_reward": 402.5884704589844, "reward": 0.6780316829681396, "action": -1.2994879484176636}
{"mode": "train", "epochs": 3, "timestep": 4711, "ep_reward": 403.3402099609375, "reward": 0.7517285943031311, "action": -0.7415810823440552}
{"mode": "train", "epochs": 3, "timestep": 4712, "ep_reward": 404.1493835449219, "reward": 0.8091604709625244, "action": -0.9284108281135559}
{"mode": "train", "epochs": 3, "timestep": 4713, "ep_reward": 404.99444580078125, "reward": 0.8450475335121155, "action": -1.0315443277359009}
{"mode": "train", "epochs": 3, "timestep": 4714, "ep_reward": 405.8570861816406, "reward": 0.8626354932785034, "action": -0.9059526920318604}
{"mode": "train", "epochs": 3, "timestep": 4715, "ep_reward": 406.7218322753906, "reward": 0.8647361993789673, "action": -0.986591100692749}
{"mode": "train", "epochs": 3, "timestep": 4716, "ep_reward": 407.5706481933594, "reward": 0.8488072156906128, "action": -0.6146727800369263}
{"mode": "train", "epochs": 3, "timestep": 4717, "ep_reward": 408.386962890625, "reward": 0.8163053393363953, "action": -0.8154950737953186}
{"mode": "train", "epochs": 3, "timestep": 4718, "ep_reward": 409.1444396972656, "reward": 0.7574751973152161, "action": -1.1936150789260864}
{"mode": "train", "epochs": 3, "timestep": 4719, "ep_reward": 409.80755615234375, "reward": 0.6631048917770386, "action": -0.5260641574859619}
{"mode": "train", "epochs": 3, "timestep": 4720, "ep_reward": 410.3469543457031, "reward": 0.5394010543823242, "action": -0.41479796171188354}
{"mode": "train", "epochs": 3, "timestep": 4721, "ep_reward": 410.72515869140625, "reward": 0.3781982660293579, "action": 0.07806789875030518}
{"mode": "train", "epochs": 3, "timestep": 4722, "ep_reward": 410.9937438964844, "reward": 0.26858365535736084, "action": -0.6309168338775635}
{"mode": "train", "epochs": 3, "timestep": 4723, "ep_reward": 411.13720703125, "reward": 0.14345306158065796, "action": -0.6227730512619019}
{"mode": "train", "epochs": 3, "timestep": 4724, "ep_reward": 411.1355285644531, "reward": -0.0016762018203735352, "action": -0.6063703298568726}
{"mode": "train", "epochs": 3, "timestep": 4725, "ep_reward": 411.2522277832031, "reward": 0.11670094728469849, "action": -1.177240252494812}
{"mode": "train", "epochs": 3, "timestep": 4726, "ep_reward": 411.5054931640625, "reward": 0.25327837467193604, "action": -0.35778194665908813}
{"mode": "train", "epochs": 3, "timestep": 4727, "ep_reward": 411.9053955078125, "reward": 0.3998919725418091, "action": -0.9724189639091492}
{"mode": "train", "epochs": 3, "timestep": 4728, "ep_reward": 412.4325256347656, "reward": 0.5271179676055908, "action": -1.615100622177124}
{"mode": "train", "epochs": 3, "timestep": 4729, "ep_reward": 413.06219482421875, "reward": 0.6296745538711548, "action": 0.29419243335723877}
{"mode": "train", "epochs": 3, "timestep": 4730, "ep_reward": 413.7926025390625, "reward": 0.7304179668426514, "action": -1.3903567790985107}
{"mode": "train", "epochs": 3, "timestep": 4731, "ep_reward": 414.58367919921875, "reward": 0.7910868525505066, "action": -0.6602364778518677}
{"mode": "train", "epochs": 3, "timestep": 4732, "ep_reward": 415.42254638671875, "reward": 0.838868260383606, "action": -0.5029885768890381}
{"mode": "train", "epochs": 3, "timestep": 4733, "ep_reward": 416.2927551269531, "reward": 0.8702012896537781, "action": -0.951300859451294}
{"mode": "train", "epochs": 3, "timestep": 4734, "ep_reward": 417.1754455566406, "reward": 0.8826963305473328, "action": -0.90914386510849}
{"mode": "train", "epochs": 3, "timestep": 4735, "ep_reward": 418.0565185546875, "reward": 0.8810696005821228, "action": -1.4861478805541992}
{"mode": "train", "epochs": 3, "timestep": 4736, "ep_reward": 418.9154968261719, "reward": 0.8589730262756348, "action": -1.413332462310791}
{"mode": "train", "epochs": 3, "timestep": 4737, "ep_reward": 419.73309326171875, "reward": 0.8175979256629944, "action": -1.2169582843780518}
{"mode": "train", "epochs": 3, "timestep": 4738, "ep_reward": 420.4856262207031, "reward": 0.7525279521942139, "action": -1.2632040977478027}
{"mode": "train", "epochs": 3, "timestep": 4739, "ep_reward": 421.1398620605469, "reward": 0.6542215347290039, "action": -1.6978280544281006}
{"mode": "train", "epochs": 3, "timestep": 4740, "ep_reward": 421.64947509765625, "reward": 0.5096068382263184, "action": -0.691680371761322}
{"mode": "train", "epochs": 3, "timestep": 4741, "ep_reward": 422.0121154785156, "reward": 0.36265528202056885, "action": -1.139125108718872}
{"mode": "train", "epochs": 3, "timestep": 4742, "ep_reward": 422.2671813964844, "reward": 0.2550687789916992, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4743, "ep_reward": 422.39495849609375, "reward": 0.1277661919593811, "action": -1.472961187362671}
{"mode": "train", "epochs": 3, "timestep": 4744, "ep_reward": 422.38067626953125, "reward": -0.014272451400756836, "action": -1.136672854423523}
{"mode": "train", "epochs": 3, "timestep": 4745, "ep_reward": 422.51318359375, "reward": 0.13250350952148438, "action": -0.8332411050796509}
{"mode": "train", "epochs": 3, "timestep": 4746, "ep_reward": 422.78680419921875, "reward": 0.27362918853759766, "action": -1.4972178936004639}
{"mode": "train", "epochs": 3, "timestep": 4747, "ep_reward": 423.1915588378906, "reward": 0.40474003553390503, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4748, "ep_reward": 423.7120361328125, "reward": 0.5204747319221497, "action": -0.7546299695968628}
{"mode": "train", "epochs": 3, "timestep": 4749, "ep_reward": 424.3453369140625, "reward": 0.6333051919937134, "action": -1.2105834484100342}
{"mode": "train", "epochs": 3, "timestep": 4750, "ep_reward": 425.0628356933594, "reward": 0.7174999713897705, "action": -1.0984798669815063}
{"mode": "train", "epochs": 3, "timestep": 4751, "ep_reward": 425.8426513671875, "reward": 0.779809832572937, "action": -0.6536743640899658}
{"mode": "train", "epochs": 3, "timestep": 4752, "ep_reward": 426.6670837402344, "reward": 0.8244416117668152, "action": -1.5459474325180054}
{"mode": "train", "epochs": 3, "timestep": 4753, "ep_reward": 427.5085144042969, "reward": 0.8414389491081238, "action": -0.5384945869445801}
{"mode": "train", "epochs": 3, "timestep": 4754, "ep_reward": 428.3573913574219, "reward": 0.8488746881484985, "action": -0.32261908054351807}
{"mode": "train", "epochs": 3, "timestep": 4755, "ep_reward": 429.1966247558594, "reward": 0.8392259478569031, "action": -0.9635369777679443}
{"mode": "train", "epochs": 3, "timestep": 4756, "ep_reward": 429.9989318847656, "reward": 0.8023157119750977, "action": -1.0450332164764404}
{"mode": "train", "epochs": 3, "timestep": 4757, "ep_reward": 430.7368469238281, "reward": 0.7379132509231567, "action": -1.1370797157287598}
{"mode": "train", "epochs": 3, "timestep": 4758, "ep_reward": 431.37548828125, "reward": 0.6386514902114868, "action": -1.2649617195129395}
{"mode": "train", "epochs": 3, "timestep": 4759, "ep_reward": 431.87213134765625, "reward": 0.4966304302215576, "action": -0.7089158296585083}
{"mode": "train", "epochs": 3, "timestep": 4760, "ep_reward": 432.233642578125, "reward": 0.3615044355392456, "action": -0.4839703440666199}
{"mode": "train", "epochs": 3, "timestep": 4761, "ep_reward": 432.48748779296875, "reward": 0.2538410425186157, "action": -0.41652435064315796}
{"mode": "train", "epochs": 3, "timestep": 4762, "ep_reward": 432.6135559082031, "reward": 0.12607932090759277, "action": -1.3019447326660156}
{"mode": "train", "epochs": 3, "timestep": 4763, "ep_reward": 432.6012878417969, "reward": -0.01227414608001709, "action": -0.7684216499328613}
{"mode": "train", "epochs": 3, "timestep": 4764, "ep_reward": 432.73553466796875, "reward": 0.13423281908035278, "action": -0.553307056427002}
{"mode": "train", "epochs": 3, "timestep": 4765, "ep_reward": 433.0145263671875, "reward": 0.27899354696273804, "action": -0.2429119348526001}
{"mode": "train", "epochs": 3, "timestep": 4766, "ep_reward": 433.4389343261719, "reward": 0.42441123723983765, "action": -1.1609398126602173}
{"mode": "train", "epochs": 3, "timestep": 4767, "ep_reward": 433.9849853515625, "reward": 0.546042799949646, "action": -1.2081068754196167}
{"mode": "train", "epochs": 3, "timestep": 4768, "ep_reward": 434.6344909667969, "reward": 0.6495070457458496, "action": -0.8542810678482056}
{"mode": "train", "epochs": 3, "timestep": 4769, "ep_reward": 435.3697204589844, "reward": 0.7352166175842285, "action": -1.5931371450424194}
{"mode": "train", "epochs": 3, "timestep": 4770, "ep_reward": 436.16253662109375, "reward": 0.7928265333175659, "action": -0.8818544149398804}
{"mode": "train", "epochs": 3, "timestep": 4771, "ep_reward": 437.000244140625, "reward": 0.83772212266922, "action": -1.4079303741455078}
{"mode": "train", "epochs": 3, "timestep": 4772, "ep_reward": 437.8611755371094, "reward": 0.8609397411346436, "action": -0.6304129958152771}
{"mode": "train", "epochs": 3, "timestep": 4773, "ep_reward": 438.7357177734375, "reward": 0.874543309211731, "action": -1.8258285522460938}
{"mode": "train", "epochs": 3, "timestep": 4774, "ep_reward": 439.5982360839844, "reward": 0.8625235557556152, "action": -1.22831392288208}
{"mode": "train", "epochs": 3, "timestep": 4775, "ep_reward": 440.4354553222656, "reward": 0.8372319936752319, "action": -0.7445728778839111}
{"mode": "train", "epochs": 3, "timestep": 4776, "ep_reward": 441.2300109863281, "reward": 0.7945604920387268, "action": -0.6125419735908508}
{"mode": "train", "epochs": 3, "timestep": 4777, "ep_reward": 441.9565734863281, "reward": 0.7265701293945312, "action": -1.0657811164855957}
{"mode": "train", "epochs": 3, "timestep": 4778, "ep_reward": 442.5764465332031, "reward": 0.6198854446411133, "action": -0.0801924467086792}
{"mode": "train", "epochs": 3, "timestep": 4779, "ep_reward": 443.0643005371094, "reward": 0.48784583806991577, "action": -1.236328363418579}
{"mode": "train", "epochs": 3, "timestep": 4780, "ep_reward": 443.40155029296875, "reward": 0.3372405171394348, "action": -0.3796260952949524}
{"mode": "train", "epochs": 3, "timestep": 4781, "ep_reward": 443.6262512207031, "reward": 0.2246863842010498, "action": -0.8637503385543823}
{"mode": "train", "epochs": 3, "timestep": 4782, "ep_reward": 443.71844482421875, "reward": 0.09219217300415039, "action": -0.631149172782898}
{"mode": "train", "epochs": 3, "timestep": 4783, "ep_reward": 443.7434387207031, "reward": 0.024991273880004883, "action": -1.4299323558807373}
{"mode": "train", "epochs": 3, "timestep": 4784, "ep_reward": 443.9101257324219, "reward": 0.16668987274169922, "action": -1.0504109859466553}
{"mode": "train", "epochs": 3, "timestep": 4785, "ep_reward": 444.216064453125, "reward": 0.3059329390525818, "action": -1.051641583442688}
{"mode": "train", "epochs": 3, "timestep": 4786, "ep_reward": 444.6573181152344, "reward": 0.44124865531921387, "action": -1.5528595447540283}
{"mode": "train", "epochs": 3, "timestep": 4787, "ep_reward": 445.21484375, "reward": 0.557512104511261, "action": -1.1913034915924072}
{"mode": "train", "epochs": 3, "timestep": 4788, "ep_reward": 445.87359619140625, "reward": 0.6587437391281128, "action": -1.0165963172912598}
{"mode": "train", "epochs": 3, "timestep": 4789, "ep_reward": 446.6124267578125, "reward": 0.7388413548469543, "action": -1.1135342121124268}
{"mode": "train", "epochs": 3, "timestep": 4790, "ep_reward": 447.40771484375, "reward": 0.7952900528907776, "action": -1.1385700702667236}
{"mode": "train", "epochs": 3, "timestep": 4791, "ep_reward": 448.238525390625, "reward": 0.8308116793632507, "action": -1.6985187530517578}
{"mode": "train", "epochs": 3, "timestep": 4792, "ep_reward": 449.0810546875, "reward": 0.8425174355506897, "action": -1.277483344078064}
{"mode": "train", "epochs": 3, "timestep": 4793, "ep_reward": 449.91998291015625, "reward": 0.8389285802841187, "action": -1.7854955196380615}
{"mode": "train", "epochs": 3, "timestep": 4794, "ep_reward": 450.7291259765625, "reward": 0.8091479539871216, "action": -1.6341420412063599}
{"mode": "train", "epochs": 3, "timestep": 4795, "ep_reward": 451.4832458496094, "reward": 0.7541343569755554, "action": -1.102293848991394}
{"mode": "train", "epochs": 3, "timestep": 4796, "ep_reward": 452.1551818847656, "reward": 0.6719279289245605, "action": -0.713808536529541}
{"mode": "train", "epochs": 3, "timestep": 4797, "ep_reward": 452.71075439453125, "reward": 0.5555721521377563, "action": -1.0894381999969482}
{"mode": "train", "epochs": 3, "timestep": 4798, "ep_reward": 453.1193542480469, "reward": 0.4085853099822998, "action": -0.938148021697998}
{"mode": "train", "epochs": 3, "timestep": 4799, "ep_reward": 453.430419921875, "reward": 0.3110765814781189, "action": -1.1027123928070068}
{"mode": "train", "epochs": 3, "timestep": 4800, "ep_reward": 453.62396240234375, "reward": 0.19354307651519775, "action": -1.3995575904846191}
{"mode": "train", "epochs": 3, "timestep": 4801, "ep_reward": 453.68011474609375, "reward": 0.056150615215301514, "action": -0.6746288537979126}
{"mode": "train", "epochs": 3, "timestep": 4802, "ep_reward": 453.7422790527344, "reward": 0.06215280294418335, "action": -0.7660872340202332}
{"mode": "train", "epochs": 3, "timestep": 4803, "ep_reward": 453.9444580078125, "reward": 0.2021821141242981, "action": -0.8210588693618774}
{"mode": "train", "epochs": 3, "timestep": 4804, "ep_reward": 454.2882995605469, "reward": 0.3438444137573242, "action": -1.8732138872146606}
{"mode": "train", "epochs": 3, "timestep": 4805, "ep_reward": 454.75457763671875, "reward": 0.4662802219390869, "action": -1.338266372680664}
{"mode": "train", "epochs": 3, "timestep": 4806, "ep_reward": 455.3362731933594, "reward": 0.5816922187805176, "action": -0.9501330852508545}
{"mode": "train", "epochs": 3, "timestep": 4807, "ep_reward": 456.0166320800781, "reward": 0.6803637742996216, "action": -0.9859910607337952}
{"mode": "train", "epochs": 3, "timestep": 4808, "ep_reward": 456.7715759277344, "reward": 0.75493323802948, "action": -1.2909678220748901}
{"mode": "train", "epochs": 3, "timestep": 4809, "ep_reward": 457.575927734375, "reward": 0.8043656349182129, "action": -0.7414146661758423}
{"mode": "train", "epochs": 3, "timestep": 4810, "ep_reward": 458.4145812988281, "reward": 0.8386436104774475, "action": -0.8224838376045227}
{"mode": "train", "epochs": 3, "timestep": 4811, "ep_reward": 459.26800537109375, "reward": 0.8534224033355713, "action": -0.960030198097229}
{"mode": "train", "epochs": 3, "timestep": 4812, "ep_reward": 460.1168212890625, "reward": 0.848831057548523, "action": -1.1094039678573608}
{"mode": "train", "epochs": 3, "timestep": 4813, "ep_reward": 460.93988037109375, "reward": 0.8230621814727783, "action": -0.8643704652786255}
{"mode": "train", "epochs": 3, "timestep": 4814, "ep_reward": 461.7156066894531, "reward": 0.7757265567779541, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4815, "ep_reward": 462.40069580078125, "reward": 0.6850903034210205, "action": -0.7421345710754395}
{"mode": "train", "epochs": 3, "timestep": 4816, "ep_reward": 462.9712829589844, "reward": 0.5705918073654175, "action": -1.1584594249725342}
{"mode": "train", "epochs": 3, "timestep": 4817, "ep_reward": 463.3795166015625, "reward": 0.40823256969451904, "action": -0.5145651698112488}
{"mode": "train", "epochs": 3, "timestep": 4818, "ep_reward": 463.690185546875, "reward": 0.31065505743026733, "action": -0.5211241245269775}
{"mode": "train", "epochs": 3, "timestep": 4819, "ep_reward": 463.8832092285156, "reward": 0.1930147409439087, "action": -1.1372184753417969}
{"mode": "train", "epochs": 3, "timestep": 4820, "ep_reward": 463.9385681152344, "reward": 0.05535757541656494, "action": -1.6106308698654175}
{"mode": "train", "epochs": 3, "timestep": 4821, "ep_reward": 464.0013122558594, "reward": 0.06273120641708374, "action": -1.3479628562927246}
{"mode": "train", "epochs": 3, "timestep": 4822, "ep_reward": 464.2006530761719, "reward": 0.19932985305786133, "action": -1.2305806875228882}
{"mode": "train", "epochs": 3, "timestep": 4823, "ep_reward": 464.5374755859375, "reward": 0.3368276357650757, "action": -0.7068179845809937}
{"mode": "train", "epochs": 3, "timestep": 4824, "ep_reward": 465.0121154785156, "reward": 0.4746297597885132, "action": -0.8017944097518921}
{"mode": "train", "epochs": 3, "timestep": 4825, "ep_reward": 465.606689453125, "reward": 0.5945875644683838, "action": -0.5319591164588928}
{"mode": "train", "epochs": 3, "timestep": 4826, "ep_reward": 466.3019104003906, "reward": 0.6952358484268188, "action": -1.0862165689468384}
{"mode": "train", "epochs": 3, "timestep": 4827, "ep_reward": 467.06890869140625, "reward": 0.766995906829834, "action": -0.9707662463188171}
{"mode": "train", "epochs": 3, "timestep": 4828, "ep_reward": 467.8878479003906, "reward": 0.8189540505409241, "action": -0.32449305057525635}
{"mode": "train", "epochs": 3, "timestep": 4829, "ep_reward": 468.745361328125, "reward": 0.8574986457824707, "action": -0.6007037162780762}
{"mode": "train", "epochs": 3, "timestep": 4830, "ep_reward": 469.62225341796875, "reward": 0.8768799901008606, "action": -1.4569554328918457}
{"mode": "train", "epochs": 3, "timestep": 4831, "ep_reward": 470.49664306640625, "reward": 0.8743789792060852, "action": -0.7103694677352905}
{"mode": "train", "epochs": 3, "timestep": 4832, "ep_reward": 471.3586730957031, "reward": 0.8620216846466064, "action": -0.6277375221252441}
{"mode": "train", "epochs": 3, "timestep": 4833, "ep_reward": 472.19085693359375, "reward": 0.8321926593780518, "action": -1.0897774696350098}
{"mode": "train", "epochs": 3, "timestep": 4834, "ep_reward": 472.9661865234375, "reward": 0.7753201127052307, "action": -0.282248318195343}
{"mode": "train", "epochs": 3, "timestep": 4835, "ep_reward": 473.66473388671875, "reward": 0.6985372304916382, "action": -1.0890581607818604}
{"mode": "train", "epochs": 3, "timestep": 4836, "ep_reward": 474.24237060546875, "reward": 0.5776479244232178, "action": -1.3896827697753906}
{"mode": "train", "epochs": 3, "timestep": 4837, "ep_reward": 474.6534118652344, "reward": 0.41105538606643677, "action": -0.681700587272644}
{"mode": "train", "epochs": 3, "timestep": 4838, "ep_reward": 474.94390869140625, "reward": 0.2904828190803528, "action": -1.4633326530456543}
{"mode": "train", "epochs": 3, "timestep": 4839, "ep_reward": 475.11309814453125, "reward": 0.16918736696243286, "action": -1.72906494140625}
{"mode": "train", "epochs": 3, "timestep": 4840, "ep_reward": 475.1410217285156, "reward": 0.027937471866607666, "action": -1.7657790184020996}
{"mode": "train", "epochs": 3, "timestep": 4841, "ep_reward": 475.2303466796875, "reward": 0.08933305740356445, "action": -0.842591404914856}
{"mode": "train", "epochs": 3, "timestep": 4842, "ep_reward": 475.4595642089844, "reward": 0.22921526432037354, "action": -1.1335160732269287}
{"mode": "train", "epochs": 3, "timestep": 4843, "ep_reward": 475.8262023925781, "reward": 0.366635799407959, "action": -0.7123357057571411}
{"mode": "train", "epochs": 3, "timestep": 4844, "ep_reward": 476.3271484375, "reward": 0.5009503364562988, "action": -1.3142755031585693}
{"mode": "train", "epochs": 3, "timestep": 4845, "ep_reward": 476.93817138671875, "reward": 0.611016035079956, "action": -0.883327066898346}
{"mode": "train", "epochs": 3, "timestep": 4846, "ep_reward": 477.6427001953125, "reward": 0.7045258283615112, "action": -1.3684507608413696}
{"mode": "train", "epochs": 3, "timestep": 4847, "ep_reward": 478.41339111328125, "reward": 0.7706938982009888, "action": -0.9853350520133972}
{"mode": "train", "epochs": 3, "timestep": 4848, "ep_reward": 479.23309326171875, "reward": 0.8197004795074463, "action": -1.2114734649658203}
{"mode": "train", "epochs": 3, "timestep": 4849, "ep_reward": 480.08087158203125, "reward": 0.8477771282196045, "action": -1.01803719997406}
{"mode": "train", "epochs": 3, "timestep": 4850, "ep_reward": 480.9410400390625, "reward": 0.8601671457290649, "action": -0.9954133629798889}
{"mode": "train", "epochs": 3, "timestep": 4851, "ep_reward": 481.79638671875, "reward": 0.855359673500061, "action": -1.794763207435608}
{"mode": "train", "epochs": 3, "timestep": 4852, "ep_reward": 482.6203918457031, "reward": 0.8239915370941162, "action": -1.01442551612854}
{"mode": "train", "epochs": 3, "timestep": 4853, "ep_reward": 483.3962097167969, "reward": 0.7758257389068604, "action": -1.0720462799072266}
{"mode": "train", "epochs": 3, "timestep": 4854, "ep_reward": 484.09332275390625, "reward": 0.6971114873886108, "action": -1.544858455657959}
{"mode": "train", "epochs": 3, "timestep": 4855, "ep_reward": 484.6679382324219, "reward": 0.574628472328186, "action": -0.7527070045471191}
{"mode": "train", "epochs": 3, "timestep": 4856, "ep_reward": 485.08734130859375, "reward": 0.41940897703170776, "action": -1.5106101036071777}
{"mode": "train", "epochs": 3, "timestep": 4857, "ep_reward": 485.4025573730469, "reward": 0.31521737575531006, "action": -1.3434290885925293}
{"mode": "train", "epochs": 3, "timestep": 4858, "ep_reward": 485.6010437011719, "reward": 0.1984773874282837, "action": -1.5273213386535645}
{"mode": "train", "epochs": 3, "timestep": 4859, "ep_reward": 485.6627197265625, "reward": 0.06166684627532959, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4860, "ep_reward": 485.71905517578125, "reward": 0.05634331703186035, "action": -1.3252698183059692}
{"mode": "train", "epochs": 3, "timestep": 4861, "ep_reward": 485.9129333496094, "reward": 0.19388693571090698, "action": -0.49679476022720337}
{"mode": "train", "epochs": 3, "timestep": 4862, "ep_reward": 486.25323486328125, "reward": 0.34030234813690186, "action": -1.2735629081726074}
{"mode": "train", "epochs": 3, "timestep": 4863, "ep_reward": 486.7231750488281, "reward": 0.4699384570121765, "action": -1.381548285484314}
{"mode": "train", "epochs": 3, "timestep": 4864, "ep_reward": 487.3072204589844, "reward": 0.5840417146682739, "action": -1.1805517673492432}
{"mode": "train", "epochs": 3, "timestep": 4865, "ep_reward": 487.98748779296875, "reward": 0.6802533268928528, "action": -0.3846363425254822}
{"mode": "train", "epochs": 3, "timestep": 4866, "ep_reward": 488.7489013671875, "reward": 0.761401891708374, "action": -0.5478795766830444}
{"mode": "train", "epochs": 3, "timestep": 4867, "ep_reward": 489.5669860839844, "reward": 0.8180742859840393, "action": -0.47686445713043213}
{"mode": "train", "epochs": 3, "timestep": 4868, "ep_reward": 490.4225769042969, "reward": 0.8555773496627808, "action": -1.7353672981262207}
{"mode": "train", "epochs": 3, "timestep": 4869, "ep_reward": 491.2886657714844, "reward": 0.8660826683044434, "action": -1.4301353693008423}
{"mode": "train", "epochs": 3, "timestep": 4870, "ep_reward": 492.15167236328125, "reward": 0.8630147576332092, "action": -1.5355212688446045}
{"mode": "train", "epochs": 3, "timestep": 4871, "ep_reward": 492.9927062988281, "reward": 0.8410415649414062, "action": -1.2207497358322144}
{"mode": "train", "epochs": 3, "timestep": 4872, "ep_reward": 493.79278564453125, "reward": 0.8000693321228027, "action": -1.2713310718536377}
{"mode": "train", "epochs": 3, "timestep": 4873, "ep_reward": 494.52386474609375, "reward": 0.7310906648635864, "action": -0.7985724806785583}
{"mode": "train", "epochs": 3, "timestep": 4874, "ep_reward": 495.1573486328125, "reward": 0.6334788799285889, "action": -0.49252593517303467}
{"mode": "train", "epochs": 3, "timestep": 4875, "ep_reward": 495.6584167480469, "reward": 0.5010643601417542, "action": -0.8441764116287231}
{"mode": "train", "epochs": 3, "timestep": 4876, "ep_reward": 496.0149841308594, "reward": 0.3565695881843567, "action": -0.47126954793930054}
{"mode": "train", "epochs": 3, "timestep": 4877, "ep_reward": 496.2628479003906, "reward": 0.24786537885665894, "action": -0.8517571687698364}
{"mode": "train", "epochs": 3, "timestep": 4878, "ep_reward": 496.382080078125, "reward": 0.11923772096633911, "action": -0.11906838417053223}
{"mode": "train", "epochs": 3, "timestep": 4879, "ep_reward": 496.37744140625, "reward": -0.004631519317626953, "action": -1.9462707042694092}
{"mode": "train", "epochs": 3, "timestep": 4880, "ep_reward": 496.5185241699219, "reward": 0.14108115434646606, "action": -0.349678099155426}
{"mode": "train", "epochs": 3, "timestep": 4881, "ep_reward": 496.8070373535156, "reward": 0.28850477933883667, "action": -0.33549201488494873}
{"mode": "train", "epochs": 3, "timestep": 4882, "ep_reward": 497.23895263671875, "reward": 0.4319053888320923, "action": -1.3101834058761597}
{"mode": "train", "epochs": 3, "timestep": 4883, "ep_reward": 497.7899475097656, "reward": 0.550990104675293, "action": -0.48363226652145386}
{"mode": "train", "epochs": 3, "timestep": 4884, "ep_reward": 498.4508972167969, "reward": 0.6609484553337097, "action": -0.7257511615753174}
{"mode": "train", "epochs": 3, "timestep": 4885, "ep_reward": 499.1965637207031, "reward": 0.745660662651062, "action": -1.3324165344238281}
{"mode": "train", "epochs": 3, "timestep": 4886, "ep_reward": 500.00048828125, "reward": 0.8039180040359497, "action": -1.0297291278839111}
{"mode": "train", "epochs": 3, "timestep": 4887, "ep_reward": 500.8471374511719, "reward": 0.8466418981552124, "action": -0.49173521995544434}
{"mode": "train", "epochs": 3, "timestep": 4888, "ep_reward": 501.72418212890625, "reward": 0.8770351409912109, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4889, "ep_reward": 502.60565185546875, "reward": 0.8814778923988342, "action": -1.7612831592559814}
{"mode": "train", "epochs": 3, "timestep": 4890, "ep_reward": 503.47894287109375, "reward": 0.8733028173446655, "action": -0.9954418540000916}
{"mode": "train", "epochs": 3, "timestep": 4891, "ep_reward": 504.333740234375, "reward": 0.8548072576522827, "action": -1.0512069463729858}
{"mode": "train", "epochs": 3, "timestep": 4892, "ep_reward": 505.149658203125, "reward": 0.8159223794937134, "action": -1.8433078527450562}
{"mode": "train", "epochs": 3, "timestep": 4893, "ep_reward": 505.8926696777344, "reward": 0.7430025339126587, "action": -1.331955909729004}
{"mode": "train", "epochs": 3, "timestep": 4894, "ep_reward": 506.5337219238281, "reward": 0.6410393714904785, "action": -0.45780354738235474}
{"mode": "train", "epochs": 3, "timestep": 4895, "ep_reward": 507.0447692871094, "reward": 0.5110353231430054, "action": -1.5178871154785156}
{"mode": "train", "epochs": 3, "timestep": 4896, "ep_reward": 507.4035949707031, "reward": 0.3588212728500366, "action": -1.4267079830169678}
{"mode": "train", "epochs": 3, "timestep": 4897, "ep_reward": 507.65423583984375, "reward": 0.25064295530319214, "action": -1.3468403816223145}
{"mode": "train", "epochs": 3, "timestep": 4898, "ep_reward": 507.77655029296875, "reward": 0.12231475114822388, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4899, "ep_reward": 507.768310546875, "reward": -0.00825202465057373, "action": -1.3604117631912231}
{"mode": "train", "epochs": 3, "timestep": 4900, "ep_reward": 507.9060974121094, "reward": 0.13779163360595703, "action": -0.7599081993103027}
{"mode": "train", "epochs": 3, "timestep": 4901, "ep_reward": 508.1861267089844, "reward": 0.2800392508506775, "action": -0.8796945810317993}
{"mode": "train", "epochs": 3, "timestep": 4902, "ep_reward": 508.6044921875, "reward": 0.4183543920516968, "action": -0.5152493715286255}
{"mode": "train", "epochs": 3, "timestep": 4903, "ep_reward": 509.1532897949219, "reward": 0.548798143863678, "action": -0.5826549530029297}
{"mode": "train", "epochs": 3, "timestep": 4904, "ep_reward": 509.8114929199219, "reward": 0.6581970453262329, "action": -0.7460919618606567}
{"mode": "train", "epochs": 3, "timestep": 4905, "ep_reward": 510.5547180175781, "reward": 0.7432148456573486, "action": -0.8685036897659302}
{"mode": "train", "epochs": 3, "timestep": 4906, "ep_reward": 511.3602600097656, "reward": 0.8055492043495178, "action": -1.0339394807815552}
{"mode": "train", "epochs": 3, "timestep": 4907, "ep_reward": 512.2078857421875, "reward": 0.8476532101631165, "action": -0.966223955154419}
{"mode": "train", "epochs": 3, "timestep": 4908, "ep_reward": 513.0819702148438, "reward": 0.8740900754928589, "action": -1.2075272798538208}
{"mode": "train", "epochs": 3, "timestep": 4909, "ep_reward": 513.9662475585938, "reward": 0.8842672109603882, "action": -0.5317747592926025}
{"mode": "train", "epochs": 3, "timestep": 4910, "ep_reward": 514.8519287109375, "reward": 0.8856824636459351, "action": -0.6604263782501221}
{"mode": "train", "epochs": 3, "timestep": 4911, "ep_reward": 515.7232055664062, "reward": 0.8712724447250366, "action": -1.5290606021881104}
{"mode": "train", "epochs": 3, "timestep": 4912, "ep_reward": 516.5548706054688, "reward": 0.8316638469696045, "action": -1.281742811203003}
{"mode": "train", "epochs": 3, "timestep": 4913, "ep_reward": 517.3251953125, "reward": 0.7703237533569336, "action": -0.7965874671936035}
{"mode": "train", "epochs": 3, "timestep": 4914, "ep_reward": 518.0092163085938, "reward": 0.6840153932571411, "action": -1.4954081773757935}
{"mode": "train", "epochs": 3, "timestep": 4915, "ep_reward": 518.561279296875, "reward": 0.5520758032798767, "action": -0.807728111743927}
{"mode": "train", "epochs": 3, "timestep": 4916, "ep_reward": 518.9490356445312, "reward": 0.38773810863494873, "action": -0.18452543020248413}
{"mode": "train", "epochs": 3, "timestep": 4917, "ep_reward": 519.2241821289062, "reward": 0.2751502990722656, "action": 0.18975162506103516}
{"mode": "train", "epochs": 3, "timestep": 4918, "ep_reward": 519.3753051757812, "reward": 0.15112662315368652, "action": -0.7718833088874817}
{"mode": "train", "epochs": 3, "timestep": 4919, "ep_reward": 519.3824462890625, "reward": 0.007155776023864746, "action": -0.5660194158554077}
{"mode": "train", "epochs": 3, "timestep": 4920, "ep_reward": 519.4910888671875, "reward": 0.10863816738128662, "action": -1.6740922927856445}
{"mode": "train", "epochs": 3, "timestep": 4921, "ep_reward": 519.72998046875, "reward": 0.2389059066772461, "action": -1.0959006547927856}
{"mode": "train", "epochs": 3, "timestep": 4922, "ep_reward": 520.1080322265625, "reward": 0.37807536125183105, "action": -1.3209965229034424}
{"mode": "train", "epochs": 3, "timestep": 4923, "ep_reward": 520.6130981445312, "reward": 0.5050593614578247, "action": -0.7999652624130249}
{"mode": "train", "epochs": 3, "timestep": 4924, "ep_reward": 521.2333374023438, "reward": 0.6202695965766907, "action": -0.3361470699310303}
{"mode": "train", "epochs": 3, "timestep": 4925, "ep_reward": 521.9497680664062, "reward": 0.7164542078971863, "action": -1.4574133157730103}
{"mode": "train", "epochs": 3, "timestep": 4926, "ep_reward": 522.7273559570312, "reward": 0.7775862812995911, "action": -1.0287742614746094}
{"mode": "train", "epochs": 3, "timestep": 4927, "ep_reward": 523.5493774414062, "reward": 0.8220461010932922, "action": -0.8943412899971008}
{"mode": "train", "epochs": 3, "timestep": 4928, "ep_reward": 524.3978881835938, "reward": 0.8484869599342346, "action": -0.38200992345809937}
{"mode": "train", "epochs": 3, "timestep": 4929, "ep_reward": 525.25927734375, "reward": 0.8613767623901367, "action": -1.658119559288025}
{"mode": "train", "epochs": 3, "timestep": 4930, "ep_reward": 526.1046142578125, "reward": 0.8453121185302734, "action": -1.5875701904296875}
{"mode": "train", "epochs": 3, "timestep": 4931, "ep_reward": 526.9132080078125, "reward": 0.8085997104644775, "action": -1.3119349479675293}
{"mode": "train", "epochs": 3, "timestep": 4932, "ep_reward": 527.6611938476562, "reward": 0.7479777336120605, "action": -0.7383198738098145}
{"mode": "train", "epochs": 3, "timestep": 4933, "ep_reward": 528.3222045898438, "reward": 0.6609880924224854, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4934, "ep_reward": 528.8392944335938, "reward": 0.5170955657958984, "action": 0.30141472816467285}
{"mode": "train", "epochs": 3, "timestep": 4935, "ep_reward": 529.220947265625, "reward": 0.38164108991622925, "action": -1.8162633180618286}
{"mode": "train", "epochs": 3, "timestep": 4936, "ep_reward": 529.4993286132812, "reward": 0.27838289737701416, "action": -0.916029691696167}
{"mode": "train", "epochs": 3, "timestep": 4937, "ep_reward": 529.6542358398438, "reward": 0.15493649244308472, "action": -1.1835023164749146}
{"mode": "train", "epochs": 3, "timestep": 4938, "ep_reward": 529.6655883789062, "reward": 0.01136326789855957, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 4939, "ep_reward": 529.7703247070312, "reward": 0.10474687814712524, "action": -0.4248899221420288}
{"mode": "train", "epochs": 3, "timestep": 4940, "ep_reward": 530.0206298828125, "reward": 0.25031179189682007, "action": -0.45233744382858276}
{"mode": "train", "epochs": 3, "timestep": 4941, "ep_reward": 530.4148559570312, "reward": 0.39419782161712646, "action": -1.3362101316452026}
{"mode": "train", "epochs": 3, "timestep": 4942, "ep_reward": 530.93212890625, "reward": 0.5172921419143677, "action": -0.8916720151901245}
{"mode": "train", "epochs": 3, "timestep": 4943, "ep_reward": 531.5610961914062, "reward": 0.6289806365966797, "action": -1.1542718410491943}
{"mode": "train", "epochs": 3, "timestep": 4944, "ep_reward": 532.2776489257812, "reward": 0.7165470123291016, "action": -1.0152987241744995}
{"mode": "train", "epochs": 3, "timestep": 4945, "ep_reward": 533.0615844726562, "reward": 0.7839390635490417, "action": -1.147492527961731}
{"mode": "train", "epochs": 3, "timestep": 4946, "ep_reward": 533.891845703125, "reward": 0.830265998840332, "action": -0.2531612515449524}
{"mode": "train", "epochs": 3, "timestep": 4947, "ep_reward": 534.758056640625, "reward": 0.866202712059021, "action": -0.9910386204719543}
{"mode": "train", "epochs": 3, "timestep": 4948, "ep_reward": 535.638427734375, "reward": 0.8803660273551941, "action": -0.8579444885253906}
{"mode": "train", "epochs": 3, "timestep": 4949, "ep_reward": 536.5194702148438, "reward": 0.8810628056526184, "action": -0.9046053886413574}
{"mode": "train", "epochs": 3, "timestep": 4950, "ep_reward": 537.3855590820312, "reward": 0.8660721182823181, "action": -0.7074775099754333}
{"mode": "train", "epochs": 3, "timestep": 4951, "ep_reward": 538.2205200195312, "reward": 0.8349442481994629, "action": -0.5558505654335022}
{"mode": "train", "epochs": 3, "timestep": 4952, "ep_reward": 539.00390625, "reward": 0.7833939790725708, "action": -1.0796467065811157}
{"mode": "train", "epochs": 3, "timestep": 4953, "ep_reward": 539.7022705078125, "reward": 0.6983784437179565, "action": -0.2573304772377014}
{"mode": "train", "epochs": 3, "timestep": 4954, "ep_reward": 540.2911376953125, "reward": 0.5888930559158325, "action": -1.0925606489181519}
{"mode": "train", "epochs": 3, "timestep": 4955, "ep_reward": 540.72119140625, "reward": 0.43003255128860474, "action": -1.2764991521835327}
{"mode": "train", "epochs": 3, "timestep": 4956, "ep_reward": 541.0144653320312, "reward": 0.2932707667350769, "action": -1.0164910554885864}
{"mode": "train", "epochs": 3, "timestep": 4957, "ep_reward": 541.1869506835938, "reward": 0.17247360944747925, "action": -1.3212616443634033}
{"mode": "train", "epochs": 3, "timestep": 4958, "ep_reward": 541.21875, "reward": 0.03177398443222046, "action": -0.9522698521614075}
{"mode": "train", "epochs": 3, "timestep": 4959, "ep_reward": 541.3045654296875, "reward": 0.08580827713012695, "action": -1.0023666620254517}
{"mode": "train", "epochs": 3, "timestep": 4960, "ep_reward": 541.528076171875, "reward": 0.22353053092956543, "action": -1.5416450500488281}
{"mode": "train", "epochs": 3, "timestep": 4961, "ep_reward": 541.8844604492188, "reward": 0.3563695549964905, "action": -1.3938685655593872}
{"mode": "train", "epochs": 3, "timestep": 4962, "ep_reward": 542.3688354492188, "reward": 0.48439711332321167, "action": -1.428257942199707}
{"mode": "train", "epochs": 3, "timestep": 4963, "ep_reward": 542.9647827148438, "reward": 0.5959599614143372, "action": -1.6503427028656006}
{"mode": "train", "epochs": 3, "timestep": 4964, "ep_reward": 543.6486206054688, "reward": 0.6838226318359375, "action": -0.9071856737136841}
{"mode": "train", "epochs": 3, "timestep": 4965, "ep_reward": 544.4046630859375, "reward": 0.7560458183288574, "action": -1.8526993989944458}
{"mode": "train", "epochs": 3, "timestep": 4966, "ep_reward": 545.2007446289062, "reward": 0.7960611581802368, "action": -1.1675645112991333}
{"mode": "train", "epochs": 3, "timestep": 4967, "ep_reward": 546.0223388671875, "reward": 0.8215858936309814, "action": -0.48555928468704224}
{"mode": "train", "epochs": 3, "timestep": 4968, "ep_reward": 546.8549194335938, "reward": 0.8326101899147034, "action": -0.900940477848053}
{"mode": "train", "epochs": 3, "timestep": 4969, "ep_reward": 547.67333984375, "reward": 0.818408191204071, "action": -0.7589280605316162}
{"mode": "train", "epochs": 3, "timestep": 4970, "ep_reward": 548.455078125, "reward": 0.781742513179779, "action": -1.3738638162612915}
{"mode": "train", "epochs": 3, "timestep": 4971, "ep_reward": 549.1641845703125, "reward": 0.7090767621994019, "action": -0.9563324451446533}
{"mode": "train", "epochs": 3, "timestep": 4972, "ep_reward": 549.7685546875, "reward": 0.6043979525566101, "action": -1.3688745498657227}
{"mode": "train", "epochs": 3, "timestep": 4973, "ep_reward": 550.218994140625, "reward": 0.45045560598373413, "action": -1.688116431236267}
{"mode": "train", "epochs": 3, "timestep": 4974, "ep_reward": 550.5657348632812, "reward": 0.34672367572784424, "action": -1.6180020570755005}
{"mode": "train", "epochs": 3, "timestep": 4975, "ep_reward": 550.8019409179688, "reward": 0.2362343668937683, "action": -0.7393444776535034}
{"mode": "train", "epochs": 3, "timestep": 4976, "ep_reward": 550.9073486328125, "reward": 0.10541415214538574, "action": -1.9438036680221558}
{"mode": "train", "epochs": 3, "timestep": 4977, "ep_reward": 550.9178466796875, "reward": 0.010478973388671875, "action": -1.6051979064941406}
{"mode": "train", "epochs": 3, "timestep": 4978, "ep_reward": 551.0719604492188, "reward": 0.15409445762634277, "action": -1.1531286239624023}
{"mode": "train", "epochs": 3, "timestep": 4979, "ep_reward": 551.36376953125, "reward": 0.2918263077735901, "action": -0.9836335182189941}
{"mode": "train", "epochs": 3, "timestep": 4980, "ep_reward": 551.7927856445312, "reward": 0.42903077602386475, "action": -0.8832263350486755}
{"mode": "train", "epochs": 3, "timestep": 4981, "ep_reward": 552.34716796875, "reward": 0.5543919801712036, "action": -1.4660481214523315}
{"mode": "train", "epochs": 3, "timestep": 4982, "ep_reward": 553.000732421875, "reward": 0.6535558700561523, "action": -0.8411906957626343}
{"mode": "train", "epochs": 3, "timestep": 4983, "ep_reward": 553.7379150390625, "reward": 0.737183690071106, "action": -1.146694540977478}
{"mode": "train", "epochs": 3, "timestep": 4984, "ep_reward": 554.5330200195312, "reward": 0.795096755027771, "action": -1.8652126789093018}
{"mode": "train", "epochs": 3, "timestep": 4985, "ep_reward": 555.3596801757812, "reward": 0.8266581296920776, "action": -1.2593333721160889}
{"mode": "train", "epochs": 3, "timestep": 4986, "ep_reward": 556.2049560546875, "reward": 0.8452744483947754, "action": -0.5886458158493042}
{"mode": "train", "epochs": 3, "timestep": 4987, "ep_reward": 557.0562744140625, "reward": 0.8513432145118713, "action": -1.6897659301757812}
{"mode": "train", "epochs": 3, "timestep": 4988, "ep_reward": 557.8842163085938, "reward": 0.8279672265052795, "action": -1.7147763967514038}
{"mode": "train", "epochs": 3, "timestep": 4989, "ep_reward": 558.6644897460938, "reward": 0.7802560329437256, "action": -1.08858323097229}
{"mode": "train", "epochs": 3, "timestep": 4990, "ep_reward": 559.3734741210938, "reward": 0.7089877128601074, "action": -1.4491697549819946}
{"mode": "train", "epochs": 3, "timestep": 4991, "ep_reward": 559.969482421875, "reward": 0.596015214920044, "action": -1.237891674041748}
{"mode": "train", "epochs": 3, "timestep": 4992, "ep_reward": 560.4108276367188, "reward": 0.44132930040359497, "action": -0.8941541910171509}
{"mode": "train", "epochs": 3, "timestep": 4993, "ep_reward": 560.7509765625, "reward": 0.3401692509651184, "action": -1.6845016479492188}
{"mode": "train", "epochs": 3, "timestep": 4994, "ep_reward": 560.9793090820312, "reward": 0.2283039689064026, "action": -1.45395827293396}
{"mode": "train", "epochs": 3, "timestep": 4995, "ep_reward": 561.0758056640625, "reward": 0.096474289894104, "action": -0.9109236001968384}
{"mode": "train", "epochs": 3, "timestep": 4996, "ep_reward": 561.0961303710938, "reward": 0.020315349102020264, "action": -1.7881217002868652}
{"mode": "train", "epochs": 3, "timestep": 4997, "ep_reward": 561.2588500976562, "reward": 0.1627022624015808, "action": -0.9694442749023438}
{"mode": "train", "epochs": 3, "timestep": 4998, "ep_reward": 561.5617065429688, "reward": 0.30283409357070923, "action": -1.3161041736602783}
{"mode": "train", "epochs": 3, "timestep": 4999, "ep_reward": 561.996826171875, "reward": 0.43511903285980225, "action": -0.9763298034667969}
{"mode": "train", "epochs": 3, "timestep": 5000, "ep_reward": 562.5556640625, "reward": 0.558861494064331, "action": -0.7252862453460693}
{"mode": "train", "epochs": 3, "timestep": 5001, "ep_reward": 563.2203979492188, "reward": 0.6647578477859497, "action": -1.4319462776184082}
{"mode": "train", "epochs": 3, "timestep": 5002, "ep_reward": 563.9608154296875, "reward": 0.7404351830482483, "action": -0.38719987869262695}
{"mode": "train", "epochs": 3, "timestep": 5003, "ep_reward": 564.7650146484375, "reward": 0.8041799068450928, "action": -1.0111602544784546}
{"mode": "train", "epochs": 3, "timestep": 5004, "ep_reward": 565.6067504882812, "reward": 0.8417251706123352, "action": -0.9736313223838806}
{"mode": "train", "epochs": 3, "timestep": 5005, "ep_reward": 566.4688720703125, "reward": 0.8621018528938293, "action": 0.30576062202453613}
{"mode": "train", "epochs": 3, "timestep": 5006, "ep_reward": 567.3455810546875, "reward": 0.8767094612121582, "action": -1.388670563697815}
{"mode": "train", "epochs": 3, "timestep": 5007, "ep_reward": 568.2067260742188, "reward": 0.8611268997192383, "action": -1.493973970413208}
{"mode": "train", "epochs": 3, "timestep": 5008, "ep_reward": 569.0321655273438, "reward": 0.8254561424255371, "action": -0.7793449759483337}
{"mode": "train", "epochs": 3, "timestep": 5009, "ep_reward": 569.804931640625, "reward": 0.7727600932121277, "action": -0.3213224411010742}
{"mode": "train", "epochs": 3, "timestep": 5010, "ep_reward": 570.5013427734375, "reward": 0.6964266300201416, "action": -1.5415104627609253}
{"mode": "train", "epochs": 3, "timestep": 5011, "ep_reward": 571.07080078125, "reward": 0.5694652795791626, "action": -1.5689640045166016}
{"mode": "train", "epochs": 3, "timestep": 5012, "ep_reward": 571.4686889648438, "reward": 0.39790189266204834, "action": -0.9886183142662048}
{"mode": "train", "epochs": 3, "timestep": 5013, "ep_reward": 571.7611694335938, "reward": 0.29247575998306274, "action": -1.9090251922607422}
{"mode": "train", "epochs": 3, "timestep": 5014, "ep_reward": 571.9329833984375, "reward": 0.171827495098114, "action": -0.38747066259384155}
{"mode": "train", "epochs": 3, "timestep": 5015, "ep_reward": 571.9638061523438, "reward": 0.03082197904586792, "action": -1.5430541038513184}
{"mode": "train", "epochs": 3, "timestep": 5016, "ep_reward": 572.0504150390625, "reward": 0.08661043643951416, "action": -1.1169962882995605}
{"mode": "train", "epochs": 3, "timestep": 5017, "ep_reward": 572.2733764648438, "reward": 0.22298139333724976, "action": -1.2063055038452148}
{"mode": "train", "epochs": 3, "timestep": 5018, "ep_reward": 572.6336669921875, "reward": 0.3602820038795471, "action": -0.793954610824585}
{"mode": "train", "epochs": 3, "timestep": 5019, "ep_reward": 573.1284790039062, "reward": 0.4948042035102844, "action": -0.8922590613365173}
{"mode": "train", "epochs": 3, "timestep": 5020, "ep_reward": 573.7390747070312, "reward": 0.6105652451515198, "action": -0.7441644668579102}
{"mode": "train", "epochs": 3, "timestep": 5021, "ep_reward": 574.4447021484375, "reward": 0.7056306600570679, "action": -0.15837866067886353}
{"mode": "train", "epochs": 3, "timestep": 5022, "ep_reward": 575.2273559570312, "reward": 0.7826809883117676, "action": -0.9543425440788269}
{"mode": "train", "epochs": 3, "timestep": 5023, "ep_reward": 576.0580444335938, "reward": 0.8307019472122192, "action": -1.4675195217132568}
{"mode": "train", "epochs": 3, "timestep": 5024, "ep_reward": 576.9148559570312, "reward": 0.8568248152732849, "action": -1.024246096611023}
{"mode": "train", "epochs": 3, "timestep": 5025, "ep_reward": 577.7855224609375, "reward": 0.8706828951835632, "action": -0.5523080825805664}
{"mode": "train", "epochs": 3, "timestep": 5026, "ep_reward": 578.6581420898438, "reward": 0.8726374506950378, "action": -1.4326763153076172}
{"mode": "train", "epochs": 3, "timestep": 5027, "ep_reward": 579.5086669921875, "reward": 0.8505043983459473, "action": -0.6911389827728271}
{"mode": "train", "epochs": 3, "timestep": 5028, "ep_reward": 580.323486328125, "reward": 0.8148459792137146, "action": -0.9155757427215576}
{"mode": "train", "epochs": 3, "timestep": 5029, "ep_reward": 581.0758056640625, "reward": 0.752338171005249, "action": -0.12087291479110718}
{"mode": "train", "epochs": 3, "timestep": 5030, "ep_reward": 581.7443237304688, "reward": 0.6685237288475037, "action": -0.9625167846679688}
{"mode": "train", "epochs": 3, "timestep": 5031, "ep_reward": 582.282958984375, "reward": 0.5386499166488647, "action": -0.713843822479248}
{"mode": "train", "epochs": 3, "timestep": 5032, "ep_reward": 582.655029296875, "reward": 0.3720870018005371, "action": -0.7466588616371155}
{"mode": "train", "epochs": 3, "timestep": 5033, "ep_reward": 582.9159545898438, "reward": 0.2609429955482483, "action": -1.3555697202682495}
{"mode": "train", "epochs": 3, "timestep": 5034, "ep_reward": 583.0504760742188, "reward": 0.1345387101173401, "action": -1.1574459075927734}
{"mode": "train", "epochs": 3, "timestep": 5035, "ep_reward": 583.0386352539062, "reward": -0.011856317520141602, "action": -0.8387874960899353}
{"mode": "train", "epochs": 3, "timestep": 5036, "ep_reward": 583.1644287109375, "reward": 0.1257954239845276, "action": -0.5049135684967041}
{"mode": "train", "epochs": 3, "timestep": 5037, "ep_reward": 583.4353637695312, "reward": 0.27092212438583374, "action": -0.6160905361175537}
{"mode": "train", "epochs": 3, "timestep": 5038, "ep_reward": 583.84765625, "reward": 0.412286639213562, "action": -0.08850079774856567}
{"mode": "train", "epochs": 3, "timestep": 5039, "ep_reward": 584.3951416015625, "reward": 0.5474642515182495, "action": -1.3828052282333374}
{"mode": "train", "epochs": 3, "timestep": 5040, "ep_reward": 585.0438842773438, "reward": 0.6487170457839966, "action": -1.5171606540679932}
{"mode": "train", "epochs": 3, "timestep": 5041, "ep_reward": 585.7725219726562, "reward": 0.728665828704834, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5042, "ep_reward": 586.5569458007812, "reward": 0.7844452857971191, "action": -0.9883288741111755}
{"mode": "train", "epochs": 3, "timestep": 5043, "ep_reward": 587.3873901367188, "reward": 0.8304484486579895, "action": -1.2939320802688599}
{"mode": "train", "epochs": 3, "timestep": 5044, "ep_reward": 588.2433471679688, "reward": 0.855945348739624, "action": -0.9649211168289185}
{"mode": "train", "epochs": 3, "timestep": 5045, "ep_reward": 589.1112060546875, "reward": 0.8678323030471802, "action": 0.233306884765625}
{"mode": "train", "epochs": 3, "timestep": 5046, "ep_reward": 589.9849243164062, "reward": 0.8737251162528992, "action": -0.3494827151298523}
{"mode": "train", "epochs": 3, "timestep": 5047, "ep_reward": 590.8434448242188, "reward": 0.8585235476493835, "action": -0.8450535535812378}
{"mode": "train", "epochs": 3, "timestep": 5048, "ep_reward": 591.66357421875, "reward": 0.8201168179512024, "action": -1.2044671773910522}
{"mode": "train", "epochs": 3, "timestep": 5049, "ep_reward": 592.4171752929688, "reward": 0.7535896301269531, "action": -1.101536750793457}
{"mode": "train", "epochs": 3, "timestep": 5050, "ep_reward": 593.0731201171875, "reward": 0.6559635400772095, "action": -1.928404688835144}
{"mode": "train", "epochs": 3, "timestep": 5051, "ep_reward": 593.5806274414062, "reward": 0.5075124502182007, "action": -0.7970569133758545}
{"mode": "train", "epochs": 3, "timestep": 5052, "ep_reward": 593.9373779296875, "reward": 0.3567799925804138, "action": -1.3957871198654175}
{"mode": "train", "epochs": 3, "timestep": 5053, "ep_reward": 594.1856689453125, "reward": 0.24828416109085083, "action": -0.38942456245422363}
{"mode": "train", "epochs": 3, "timestep": 5054, "ep_reward": 594.3053588867188, "reward": 0.11968183517456055, "action": -0.25865209102630615}
{"mode": "train", "epochs": 3, "timestep": 5055, "ep_reward": 594.3004150390625, "reward": -0.004922389984130859, "action": -0.6413119435310364}
{"mode": "train", "epochs": 3, "timestep": 5056, "ep_reward": 594.4410400390625, "reward": 0.14063477516174316, "action": -0.5171375274658203}
{"mode": "train", "epochs": 3, "timestep": 5057, "ep_reward": 594.7269897460938, "reward": 0.2859238386154175, "action": -1.0379223823547363}
{"mode": "train", "epochs": 3, "timestep": 5058, "ep_reward": 595.1484375, "reward": 0.4214264154434204, "action": -1.7566349506378174}
{"mode": "train", "epochs": 3, "timestep": 5059, "ep_reward": 595.6858520507812, "reward": 0.5374433994293213, "action": -1.028957724571228}
{"mode": "train", "epochs": 3, "timestep": 5060, "ep_reward": 596.3301391601562, "reward": 0.6443009376525879, "action": -1.0800760984420776}
{"mode": "train", "epochs": 3, "timestep": 5061, "ep_reward": 597.0582885742188, "reward": 0.7281442284584045, "action": -0.2500358819961548}
{"mode": "train", "epochs": 3, "timestep": 5062, "ep_reward": 597.8553466796875, "reward": 0.7970842123031616, "action": -1.0797066688537598}
{"mode": "train", "epochs": 3, "timestep": 5063, "ep_reward": 598.6928100585938, "reward": 0.8374462127685547, "action": -1.235527753829956}
{"mode": "train", "epochs": 3, "timestep": 5064, "ep_reward": 599.5516357421875, "reward": 0.8588154315948486, "action": -1.7359697818756104}
{"mode": "train", "epochs": 3, "timestep": 5065, "ep_reward": 600.4111328125, "reward": 0.8594757914543152, "action": -1.1542103290557861}
{"mode": "train", "epochs": 3, "timestep": 5066, "ep_reward": 601.2584838867188, "reward": 0.8473591804504395, "action": -1.4928879737854004}
{"mode": "train", "epochs": 3, "timestep": 5067, "ep_reward": 602.0699462890625, "reward": 0.8114362955093384, "action": -1.0601948499679565}
{"mode": "train", "epochs": 3, "timestep": 5068, "ep_reward": 602.8237915039062, "reward": 0.7538219094276428, "action": -1.3720368146896362}
{"mode": "train", "epochs": 3, "timestep": 5069, "ep_reward": 603.4837036132812, "reward": 0.6599071025848389, "action": -1.5921993255615234}
{"mode": "train", "epochs": 3, "timestep": 5070, "ep_reward": 604.0055541992188, "reward": 0.5218462944030762, "action": -0.522807240486145}
{"mode": "train", "epochs": 3, "timestep": 5071, "ep_reward": 604.3876953125, "reward": 0.3821171522140503, "action": -1.8508565425872803}
{"mode": "train", "epochs": 3, "timestep": 5072, "ep_reward": 604.6666259765625, "reward": 0.27894920110702515, "action": -1.0869951248168945}
{"mode": "train", "epochs": 3, "timestep": 5073, "ep_reward": 604.8223266601562, "reward": 0.15571486949920654, "action": -0.09332406520843506}
{"mode": "train", "epochs": 3, "timestep": 5074, "ep_reward": 604.834716796875, "reward": 0.012373387813568115, "action": -0.7480529546737671}
{"mode": "train", "epochs": 3, "timestep": 5075, "ep_reward": 604.938720703125, "reward": 0.10397899150848389, "action": -0.8874461650848389}
{"mode": "train", "epochs": 3, "timestep": 5076, "ep_reward": 605.1824951171875, "reward": 0.24377018213272095, "action": -0.7832486033439636}
{"mode": "train", "epochs": 3, "timestep": 5077, "ep_reward": 605.5673217773438, "reward": 0.38484710454940796, "action": -1.859532117843628}
{"mode": "train", "epochs": 3, "timestep": 5078, "ep_reward": 606.0711059570312, "reward": 0.5038087964057922, "action": -0.22791266441345215}
{"mode": "train", "epochs": 3, "timestep": 5079, "ep_reward": 606.6962280273438, "reward": 0.6251087784767151, "action": -1.9149894714355469}
{"mode": "train", "epochs": 3, "timestep": 5080, "ep_reward": 607.4017333984375, "reward": 0.7054922580718994, "action": -0.665891170501709}
{"mode": "train", "epochs": 3, "timestep": 5081, "ep_reward": 608.1785888671875, "reward": 0.776865541934967, "action": -0.3751784563064575}
{"mode": "train", "epochs": 3, "timestep": 5082, "ep_reward": 609.0074462890625, "reward": 0.8288606405258179, "action": -0.29083412885665894}
{"mode": "train", "epochs": 3, "timestep": 5083, "ep_reward": 609.8696899414062, "reward": 0.8622279167175293, "action": -0.7375667095184326}
{"mode": "train", "epochs": 3, "timestep": 5084, "ep_reward": 610.7450561523438, "reward": 0.8753412961959839, "action": -1.1613762378692627}
{"mode": "train", "epochs": 3, "timestep": 5085, "ep_reward": 611.614501953125, "reward": 0.8694697618484497, "action": -1.1196813583374023}
{"mode": "train", "epochs": 3, "timestep": 5086, "ep_reward": 612.4611206054688, "reward": 0.8465980291366577, "action": -1.730245590209961}
{"mode": "train", "epochs": 3, "timestep": 5087, "ep_reward": 613.257568359375, "reward": 0.7964707016944885, "action": -1.0498465299606323}
{"mode": "train", "epochs": 3, "timestep": 5088, "ep_reward": 613.9826049804688, "reward": 0.7250267267227173, "action": -0.402152419090271}
{"mode": "train", "epochs": 3, "timestep": 5089, "ep_reward": 614.6104125976562, "reward": 0.6277793645858765, "action": -1.1256775856018066}
{"mode": "train", "epochs": 3, "timestep": 5090, "ep_reward": 615.092529296875, "reward": 0.48209285736083984, "action": -1.6136550903320312}
{"mode": "train", "epochs": 3, "timestep": 5091, "ep_reward": 615.4334716796875, "reward": 0.3409486413002014, "action": -0.7587210536003113}
{"mode": "train", "epochs": 3, "timestep": 5092, "ep_reward": 615.6625366210938, "reward": 0.22908222675323486, "action": -1.3693463802337646}
{"mode": "train", "epochs": 3, "timestep": 5093, "ep_reward": 615.7598876953125, "reward": 0.09734761714935303, "action": -1.0362812280654907}
{"mode": "train", "epochs": 3, "timestep": 5094, "ep_reward": 615.7794189453125, "reward": 0.01956099271774292, "action": -0.023241519927978516}
{"mode": "train", "epochs": 3, "timestep": 5095, "ep_reward": 615.9468383789062, "reward": 0.16744625568389893, "action": -0.8788244128227234}
{"mode": "train", "epochs": 3, "timestep": 5096, "ep_reward": 616.25439453125, "reward": 0.30755138397216797, "action": -1.1465682983398438}
{"mode": "train", "epochs": 3, "timestep": 5097, "ep_reward": 616.69482421875, "reward": 0.4404454827308655, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5098, "ep_reward": 617.246337890625, "reward": 0.5515331029891968, "action": -0.24507808685302734}
{"mode": "train", "epochs": 3, "timestep": 5099, "ep_reward": 617.9102783203125, "reward": 0.6639330387115479, "action": -0.7786026000976562}
{"mode": "train", "epochs": 3, "timestep": 5100, "ep_reward": 618.6566162109375, "reward": 0.7463236451148987, "action": -0.17352408170700073}
{"mode": "train", "epochs": 3, "timestep": 5101, "ep_reward": 619.46826171875, "reward": 0.8116750717163086, "action": -0.9459027051925659}
{"mode": "train", "epochs": 3, "timestep": 5102, "ep_reward": 620.3185424804688, "reward": 0.8502689599990845, "action": -0.8027241230010986}
{"mode": "train", "epochs": 3, "timestep": 5103, "ep_reward": 621.19189453125, "reward": 0.8733313083648682, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5104, "ep_reward": 622.0636596679688, "reward": 0.8717667460441589, "action": -1.6971704959869385}
{"mode": "train", "epochs": 3, "timestep": 5105, "ep_reward": 622.9199829101562, "reward": 0.8563033938407898, "action": -0.8048585057258606}
{"mode": "train", "epochs": 3, "timestep": 5106, "ep_reward": 623.7493896484375, "reward": 0.829390287399292, "action": -1.7306537628173828}
{"mode": "train", "epochs": 3, "timestep": 5107, "ep_reward": 624.5191040039062, "reward": 0.7697116136550903, "action": -1.1416032314300537}
{"mode": "train", "epochs": 3, "timestep": 5108, "ep_reward": 625.203857421875, "reward": 0.6847724914550781, "action": -1.1743927001953125}
{"mode": "train", "epochs": 3, "timestep": 5109, "ep_reward": 625.7651977539062, "reward": 0.561335563659668, "action": -0.8801319599151611}
{"mode": "train", "epochs": 3, "timestep": 5110, "ep_reward": 626.1644897460938, "reward": 0.3993144631385803, "action": -0.7806745171546936}
{"mode": "train", "epochs": 3, "timestep": 5111, "ep_reward": 626.4615478515625, "reward": 0.2970712184906006, "action": -1.5934308767318726}
{"mode": "train", "epochs": 3, "timestep": 5112, "ep_reward": 626.638671875, "reward": 0.17711853981018066, "action": -1.0140868425369263}
{"mode": "train", "epochs": 3, "timestep": 5113, "ep_reward": 626.67578125, "reward": 0.03710436820983887, "action": -0.7150495052337646}
{"mode": "train", "epochs": 3, "timestep": 5114, "ep_reward": 626.7564697265625, "reward": 0.08070921897888184, "action": -1.2040815353393555}
{"mode": "train", "epochs": 3, "timestep": 5115, "ep_reward": 626.9723510742188, "reward": 0.2158898115158081, "action": -0.47103381156921387}
{"mode": "train", "epochs": 3, "timestep": 5116, "ep_reward": 627.3350219726562, "reward": 0.3626520037651062, "action": -0.07493525743484497}
{"mode": "train", "epochs": 3, "timestep": 5117, "ep_reward": 627.8394165039062, "reward": 0.5043767690658569, "action": -0.8318157196044922}
{"mode": "train", "epochs": 3, "timestep": 5118, "ep_reward": 628.4580688476562, "reward": 0.6186767816543579, "action": -1.144848346710205}
{"mode": "train", "epochs": 3, "timestep": 5119, "ep_reward": 629.166748046875, "reward": 0.7086726427078247, "action": -1.405748724937439}
{"mode": "train", "epochs": 3, "timestep": 5120, "ep_reward": 629.9420166015625, "reward": 0.7752589583396912, "action": -0.12604588270187378}
{"mode": "train", "epochs": 3, "timestep": 5121, "ep_reward": 630.7750854492188, "reward": 0.8330501914024353, "action": -1.1968085765838623}
{"mode": "train", "epochs": 3, "timestep": 5122, "ep_reward": 631.6387329101562, "reward": 0.863642692565918, "action": -1.0241458415985107}
{"mode": "train", "epochs": 3, "timestep": 5123, "ep_reward": 632.519287109375, "reward": 0.8805375099182129, "action": -0.9727033972740173}
{"mode": "train", "epochs": 3, "timestep": 5124, "ep_reward": 633.4028930664062, "reward": 0.8835867047309875, "action": -0.4863045811653137}
{"mode": "train", "epochs": 3, "timestep": 5125, "ep_reward": 634.2786254882812, "reward": 0.8757620453834534, "action": -1.4605252742767334}
{"mode": "train", "epochs": 3, "timestep": 5126, "ep_reward": 635.1214599609375, "reward": 0.8428520560264587, "action": -1.683576226234436}
{"mode": "train", "epochs": 3, "timestep": 5127, "ep_reward": 635.9065551757812, "reward": 0.7850950360298157, "action": -0.609142541885376}
{"mode": "train", "epochs": 3, "timestep": 5128, "ep_reward": 636.6160888671875, "reward": 0.7095310091972351, "action": -1.4023665189743042}
{"mode": "train", "epochs": 3, "timestep": 5129, "ep_reward": 637.2056274414062, "reward": 0.5895336270332336, "action": -0.6528963446617126}
{"mode": "train", "epochs": 3, "timestep": 5130, "ep_reward": 637.6441650390625, "reward": 0.4385547637939453, "action": -1.79688560962677}
{"mode": "train", "epochs": 3, "timestep": 5131, "ep_reward": 637.951904296875, "reward": 0.3077528476715088, "action": -1.2596256732940674}
{"mode": "train", "epochs": 3, "timestep": 5132, "ep_reward": 638.1414794921875, "reward": 0.1895872950553894, "action": -1.6261658668518066}
{"mode": "train", "epochs": 3, "timestep": 5133, "ep_reward": 638.1930541992188, "reward": 0.05158567428588867, "action": -1.0435632467269897}
{"mode": "train", "epochs": 3, "timestep": 5134, "ep_reward": 638.2596435546875, "reward": 0.06661641597747803, "action": -0.9334540963172913}
{"mode": "train", "epochs": 3, "timestep": 5135, "ep_reward": 638.4642944335938, "reward": 0.20466017723083496, "action": -1.1737151145935059}
{"mode": "train", "epochs": 3, "timestep": 5136, "ep_reward": 638.8067016601562, "reward": 0.34239381551742554, "action": -1.4309688806533813}
{"mode": "train", "epochs": 3, "timestep": 5137, "ep_reward": 639.277587890625, "reward": 0.47089725732803345, "action": -0.6852151155471802}
{"mode": "train", "epochs": 3, "timestep": 5138, "ep_reward": 639.8705444335938, "reward": 0.5929563045501709, "action": -0.44462108612060547}
{"mode": "train", "epochs": 3, "timestep": 5139, "ep_reward": 640.5652465820312, "reward": 0.6946738958358765, "action": -0.9722371697425842}
{"mode": "train", "epochs": 3, "timestep": 5140, "ep_reward": 641.3323974609375, "reward": 0.76716548204422, "action": -0.6313261985778809}
{"mode": "train", "epochs": 3, "timestep": 5141, "ep_reward": 642.1536865234375, "reward": 0.8212760090827942, "action": -1.0284397602081299}
{"mode": "train", "epochs": 3, "timestep": 5142, "ep_reward": 643.0065307617188, "reward": 0.8528731465339661, "action": -1.0314455032348633}
{"mode": "train", "epochs": 3, "timestep": 5143, "ep_reward": 643.8743286132812, "reward": 0.8678228855133057, "action": -0.6634455919265747}
{"mode": "train", "epochs": 3, "timestep": 5144, "ep_reward": 644.744140625, "reward": 0.8698087930679321, "action": -0.8989453911781311}
{"mode": "train", "epochs": 3, "timestep": 5145, "ep_reward": 645.5972290039062, "reward": 0.8530601859092712, "action": -0.3604176640510559}
{"mode": "train", "epochs": 3, "timestep": 5146, "ep_reward": 646.4190673828125, "reward": 0.8218566179275513, "action": -1.3174161911010742}
{"mode": "train", "epochs": 3, "timestep": 5147, "ep_reward": 647.1763305664062, "reward": 0.7572510838508606, "action": -1.3363921642303467}
{"mode": "train", "epochs": 3, "timestep": 5148, "ep_reward": 647.8363037109375, "reward": 0.659972608089447, "action": -1.2287112474441528}
{"mode": "train", "epochs": 3, "timestep": 5149, "ep_reward": 648.3607177734375, "reward": 0.5243983268737793, "action": -1.042019009590149}
{"mode": "train", "epochs": 3, "timestep": 5150, "ep_reward": 648.728515625, "reward": 0.36780935525894165, "action": -0.9480463862419128}
{"mode": "train", "epochs": 3, "timestep": 5151, "ep_reward": 648.9899291992188, "reward": 0.2614127993583679, "action": -1.2251321077346802}
{"mode": "train", "epochs": 3, "timestep": 5152, "ep_reward": 649.1250610351562, "reward": 0.1351127028465271, "action": -0.7552267909049988}
{"mode": "train", "epochs": 3, "timestep": 5153, "ep_reward": 649.1136474609375, "reward": -0.01140594482421875, "action": -1.773254632949829}
{"mode": "train", "epochs": 3, "timestep": 5154, "ep_reward": 649.2388305664062, "reward": 0.12515783309936523, "action": -1.3993618488311768}
{"mode": "train", "epochs": 3, "timestep": 5155, "ep_reward": 649.4979248046875, "reward": 0.2590743899345398, "action": -1.4377069473266602}
{"mode": "train", "epochs": 3, "timestep": 5156, "ep_reward": 649.8906860351562, "reward": 0.39278799295425415, "action": -0.8702454566955566}
{"mode": "train", "epochs": 3, "timestep": 5157, "ep_reward": 650.4141845703125, "reward": 0.5234881639480591, "action": -0.21308135986328125}
{"mode": "train", "epochs": 3, "timestep": 5158, "ep_reward": 651.0558471679688, "reward": 0.6416585445404053, "action": -0.4608510136604309}
{"mode": "train", "epochs": 3, "timestep": 5159, "ep_reward": 651.7881469726562, "reward": 0.7322739958763123, "action": -1.3163330554962158}
{"mode": "train", "epochs": 3, "timestep": 5160, "ep_reward": 652.580078125, "reward": 0.7919345498085022, "action": -0.3767920136451721}
{"mode": "train", "epochs": 3, "timestep": 5161, "ep_reward": 653.420166015625, "reward": 0.8400625586509705, "action": -0.3702318072319031}
{"mode": "train", "epochs": 3, "timestep": 5162, "ep_reward": 654.2901000976562, "reward": 0.869907557964325, "action": -1.316344976425171}
{"mode": "train", "epochs": 3, "timestep": 5163, "ep_reward": 655.1666870117188, "reward": 0.8766001462936401, "action": -0.8935993909835815}
{"mode": "train", "epochs": 3, "timestep": 5164, "ep_reward": 656.0381469726562, "reward": 0.871471643447876, "action": -0.760278582572937}
{"mode": "train", "epochs": 3, "timestep": 5165, "ep_reward": 656.8888549804688, "reward": 0.8506993055343628, "action": -0.8974224925041199}
{"mode": "train", "epochs": 3, "timestep": 5166, "ep_reward": 657.6973266601562, "reward": 0.8084536790847778, "action": -1.6889594793319702}
{"mode": "train", "epochs": 3, "timestep": 5167, "ep_reward": 658.4288330078125, "reward": 0.7315267324447632, "action": -1.1682939529418945}
{"mode": "train", "epochs": 3, "timestep": 5168, "ep_reward": 659.0541381835938, "reward": 0.625333309173584, "action": -1.051586627960205}
{"mode": "train", "epochs": 3, "timestep": 5169, "ep_reward": 659.5342407226562, "reward": 0.48012274503707886, "action": -1.2584137916564941}
{"mode": "train", "epochs": 3, "timestep": 5170, "ep_reward": 659.8741455078125, "reward": 0.33990854024887085, "action": -0.7975436449050903}
{"mode": "train", "epochs": 3, "timestep": 5171, "ep_reward": 660.10205078125, "reward": 0.22792595624923706, "action": -0.733812153339386}
{"mode": "train", "epochs": 3, "timestep": 5172, "ep_reward": 660.1979370117188, "reward": 0.09590291976928711, "action": -1.048163652420044}
{"mode": "train", "epochs": 3, "timestep": 5173, "ep_reward": 660.218994140625, "reward": 0.02105492353439331, "action": -0.9369526505470276}
{"mode": "train", "epochs": 3, "timestep": 5174, "ep_reward": 660.3822631835938, "reward": 0.1632722020149231, "action": -0.28948014974594116}
{"mode": "train", "epochs": 3, "timestep": 5175, "ep_reward": 660.6941528320312, "reward": 0.3118847608566284, "action": -0.32169079780578613}
{"mode": "train", "epochs": 3, "timestep": 5176, "ep_reward": 661.1480712890625, "reward": 0.4539007544517517, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5177, "ep_reward": 661.710693359375, "reward": 0.5626498460769653, "action": -1.3012584447860718}
{"mode": "train", "epochs": 3, "timestep": 5178, "ep_reward": 662.3726806640625, "reward": 0.6619973182678223, "action": -1.4942834377288818}
{"mode": "train", "epochs": 3, "timestep": 5179, "ep_reward": 663.1107177734375, "reward": 0.7380626201629639, "action": -0.633676290512085}
{"mode": "train", "epochs": 3, "timestep": 5180, "ep_reward": 663.9114990234375, "reward": 0.8008111119270325, "action": -0.9644433259963989}
{"mode": "train", "epochs": 3, "timestep": 5181, "ep_reward": 664.751708984375, "reward": 0.8402268886566162, "action": -0.6604372262954712}
{"mode": "train", "epochs": 3, "timestep": 5182, "ep_reward": 665.6162719726562, "reward": 0.8645502328872681, "action": -0.45590806007385254}
{"mode": "train", "epochs": 3, "timestep": 5183, "ep_reward": 666.490478515625, "reward": 0.874212920665741, "action": -1.4482437372207642}
{"mode": "train", "epochs": 3, "timestep": 5184, "ep_reward": 667.3500366210938, "reward": 0.8595549464225769, "action": -0.22739428281784058}
{"mode": "train", "epochs": 3, "timestep": 5185, "ep_reward": 668.1873779296875, "reward": 0.8373278379440308, "action": -0.23787426948547363}
{"mode": "train", "epochs": 3, "timestep": 5186, "ep_reward": 668.9815063476562, "reward": 0.7941434979438782, "action": -1.3623335361480713}
{"mode": "train", "epochs": 3, "timestep": 5187, "ep_reward": 669.69384765625, "reward": 0.7123278975486755, "action": -1.0689961910247803}
{"mode": "train", "epochs": 3, "timestep": 5188, "ep_reward": 670.2920532226562, "reward": 0.5982178449630737, "action": -0.896472156047821}
{"mode": "train", "epochs": 3, "timestep": 5189, "ep_reward": 670.738037109375, "reward": 0.4460011124610901, "action": -1.3400624990463257}
{"mode": "train", "epochs": 3, "timestep": 5190, "ep_reward": 671.05078125, "reward": 0.31271636486053467, "action": 0.36051392555236816}
{"mode": "train", "epochs": 3, "timestep": 5191, "ep_reward": 671.2462158203125, "reward": 0.19543904066085815, "action": -1.2082483768463135}
{"mode": "train", "epochs": 3, "timestep": 5192, "ep_reward": 671.3045043945312, "reward": 0.05828726291656494, "action": -0.8888113498687744}
{"mode": "train", "epochs": 3, "timestep": 5193, "ep_reward": 671.364501953125, "reward": 0.06001549959182739, "action": -0.6197866201400757}
{"mode": "train", "epochs": 3, "timestep": 5194, "ep_reward": 671.5663452148438, "reward": 0.20184290409088135, "action": -0.15388363599777222}
{"mode": "train", "epochs": 3, "timestep": 5195, "ep_reward": 671.9176635742188, "reward": 0.35132884979248047, "action": -1.6843516826629639}
{"mode": "train", "epochs": 3, "timestep": 5196, "ep_reward": 672.3920288085938, "reward": 0.4743543267250061, "action": -1.2473480701446533}
{"mode": "train", "epochs": 3, "timestep": 5197, "ep_reward": 672.9810791015625, "reward": 0.5890542268753052, "action": -1.665924072265625}
{"mode": "train", "epochs": 3, "timestep": 5198, "ep_reward": 673.6605834960938, "reward": 0.6794989705085754, "action": -0.5798060894012451}
{"mode": "train", "epochs": 3, "timestep": 5199, "ep_reward": 674.4196166992188, "reward": 0.7590153813362122, "action": -1.094875454902649}
{"mode": "train", "epochs": 3, "timestep": 5200, "ep_reward": 675.2310180664062, "reward": 0.8113813400268555, "action": 0.14540159702301025}
{"mode": "train", "epochs": 3, "timestep": 5201, "ep_reward": 676.0859375, "reward": 0.8549087047576904, "action": -0.9334017038345337}
{"mode": "train", "epochs": 3, "timestep": 5202, "ep_reward": 676.9578857421875, "reward": 0.8719317317008972, "action": -0.7291508913040161}
{"mode": "train", "epochs": 3, "timestep": 5203, "ep_reward": 677.8330078125, "reward": 0.8751196265220642, "action": -1.1663609743118286}
{"mode": "train", "epochs": 3, "timestep": 5204, "ep_reward": 678.69140625, "reward": 0.8583889007568359, "action": -1.8769588470458984}
{"mode": "train", "epochs": 3, "timestep": 5205, "ep_reward": 679.5068359375, "reward": 0.8154439330101013, "action": -1.099990725517273}
{"mode": "train", "epochs": 3, "timestep": 5206, "ep_reward": 680.2606201171875, "reward": 0.753807544708252, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5207, "ep_reward": 680.9091186523438, "reward": 0.6484938263893127, "action": -0.9228730797767639}
{"mode": "train", "epochs": 3, "timestep": 5208, "ep_reward": 681.42431640625, "reward": 0.5152170658111572, "action": -1.2102614641189575}
{"mode": "train", "epochs": 3, "timestep": 5209, "ep_reward": 681.794189453125, "reward": 0.36987805366516113, "action": -1.077646017074585}
{"mode": "train", "epochs": 3, "timestep": 5210, "ep_reward": 682.05810546875, "reward": 0.26393187046051025, "action": -1.2240959405899048}
{"mode": "train", "epochs": 3, "timestep": 5211, "ep_reward": 682.1961059570312, "reward": 0.13801342248916626, "action": -1.1835718154907227}
{"mode": "train", "epochs": 3, "timestep": 5212, "ep_reward": 682.1881713867188, "reward": -0.007923483848571777, "action": -1.2681176662445068}
{"mode": "train", "epochs": 3, "timestep": 5213, "ep_reward": 682.3104248046875, "reward": 0.12223142385482788, "action": -0.9423653483390808}
{"mode": "train", "epochs": 3, "timestep": 5214, "ep_reward": 682.5722045898438, "reward": 0.2617526054382324, "action": -1.473201036453247}
{"mode": "train", "epochs": 3, "timestep": 5215, "ep_reward": 682.966064453125, "reward": 0.39385682344436646, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5216, "ep_reward": 683.4769287109375, "reward": 0.5108915567398071, "action": -0.04916614294052124}
{"mode": "train", "epochs": 3, "timestep": 5217, "ep_reward": 684.110107421875, "reward": 0.6331844329833984, "action": -1.0847156047821045}
{"mode": "train", "epochs": 3, "timestep": 5218, "ep_reward": 684.8294067382812, "reward": 0.7192790508270264, "action": -1.0177857875823975}
{"mode": "train", "epochs": 3, "timestep": 5219, "ep_reward": 685.6126708984375, "reward": 0.7832621932029724, "action": -0.9988451600074768}
{"mode": "train", "epochs": 3, "timestep": 5220, "ep_reward": 686.4390258789062, "reward": 0.8263449668884277, "action": -1.034461259841919}
{"mode": "train", "epochs": 3, "timestep": 5221, "ep_reward": 687.2892456054688, "reward": 0.8502392172813416, "action": -0.626587986946106}
{"mode": "train", "epochs": 3, "timestep": 5222, "ep_reward": 688.149169921875, "reward": 0.8599543571472168, "action": -1.3505624532699585}
{"mode": "train", "epochs": 3, "timestep": 5223, "ep_reward": 688.9946899414062, "reward": 0.8455413579940796, "action": -0.26493239402770996}
{"mode": "train", "epochs": 3, "timestep": 5224, "ep_reward": 689.8157958984375, "reward": 0.8211054801940918, "action": -0.0974777340888977}
{"mode": "train", "epochs": 3, "timestep": 5225, "ep_reward": 690.591552734375, "reward": 0.7757400274276733, "action": -0.28903114795684814}
{"mode": "train", "epochs": 3, "timestep": 5226, "ep_reward": 691.2925415039062, "reward": 0.7009778618812561, "action": -1.414583683013916}
{"mode": "train", "epochs": 3, "timestep": 5227, "ep_reward": 691.8701782226562, "reward": 0.577613115310669, "action": -0.34044164419174194}
{"mode": "train", "epochs": 3, "timestep": 5228, "ep_reward": 692.2985229492188, "reward": 0.42836689949035645, "action": -0.07622051239013672}
{"mode": "train", "epochs": 3, "timestep": 5229, "ep_reward": 692.5984497070312, "reward": 0.29992061853408813, "action": -1.0569628477096558}
{"mode": "train", "epochs": 3, "timestep": 5230, "ep_reward": 692.77880859375, "reward": 0.1803768277168274, "action": -1.0527173280715942}
{"mode": "train", "epochs": 3, "timestep": 5231, "ep_reward": 692.8195190429688, "reward": 0.04073774814605713, "action": -1.6228959560394287}
{"mode": "train", "epochs": 3, "timestep": 5232, "ep_reward": 692.8966674804688, "reward": 0.07712221145629883, "action": -0.8779404759407043}
{"mode": "train", "epochs": 3, "timestep": 5233, "ep_reward": 693.1129150390625, "reward": 0.21626347303390503, "action": -0.4245795011520386}
{"mode": "train", "epochs": 3, "timestep": 5234, "ep_reward": 693.4757080078125, "reward": 0.36279165744781494, "action": -0.8052868843078613}
{"mode": "train", "epochs": 3, "timestep": 5235, "ep_reward": 693.9713134765625, "reward": 0.4956187605857849, "action": -0.89048832654953}
{"mode": "train", "epochs": 3, "timestep": 5236, "ep_reward": 694.5820922851562, "reward": 0.6108052730560303, "action": -1.3662009239196777}
{"mode": "train", "epochs": 3, "timestep": 5237, "ep_reward": 695.2822875976562, "reward": 0.7002155184745789, "action": 0.46037113666534424}
{"mode": "train", "epochs": 3, "timestep": 5238, "ep_reward": 696.0670166015625, "reward": 0.7847366333007812, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5239, "ep_reward": 696.892822265625, "reward": 0.825835645198822, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5240, "ep_reward": 697.74365234375, "reward": 0.8508062362670898, "action": -0.6479430198669434}
{"mode": "train", "epochs": 3, "timestep": 5241, "ep_reward": 698.6144409179688, "reward": 0.8707603812217712, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5242, "ep_reward": 699.4783325195312, "reward": 0.863864541053772, "action": -0.8128229975700378}
{"mode": "train", "epochs": 3, "timestep": 5243, "ep_reward": 700.327880859375, "reward": 0.8495708703994751, "action": -1.1050127744674683}
{"mode": "train", "epochs": 3, "timestep": 5244, "ep_reward": 701.1401977539062, "reward": 0.8123118877410889, "action": -1.525216817855835}
{"mode": "train", "epochs": 3, "timestep": 5245, "ep_reward": 701.8848876953125, "reward": 0.7447164058685303, "action": 0.09312164783477783}
{"mode": "train", "epochs": 3, "timestep": 5246, "ep_reward": 702.548583984375, "reward": 0.6637267470359802, "action": -0.8592904806137085}
{"mode": "train", "epochs": 3, "timestep": 5247, "ep_reward": 703.0835571289062, "reward": 0.5349452495574951, "action": -0.6239491701126099}
{"mode": "train", "epochs": 3, "timestep": 5248, "ep_reward": 703.4545288085938, "reward": 0.37098824977874756, "action": -0.6757309436798096}
{"mode": "train", "epochs": 3, "timestep": 5249, "ep_reward": 703.7197875976562, "reward": 0.26526349782943726, "action": -0.9007143974304199}
{"mode": "train", "epochs": 3, "timestep": 5250, "ep_reward": 703.8592529296875, "reward": 0.1394820213317871, "action": -1.4433597326278687}
{"mode": "train", "epochs": 3, "timestep": 5251, "ep_reward": 703.8531494140625, "reward": -0.006108283996582031, "action": -0.5524290204048157}
{"mode": "train", "epochs": 3, "timestep": 5252, "ep_reward": 703.9736938476562, "reward": 0.12057375907897949, "action": -1.667586088180542}
{"mode": "train", "epochs": 3, "timestep": 5253, "ep_reward": 704.224853515625, "reward": 0.25112974643707275, "action": -0.5034240484237671}
{"mode": "train", "epochs": 3, "timestep": 5254, "ep_reward": 704.6220092773438, "reward": 0.3971557021141052, "action": -0.7263191938400269}
{"mode": "train", "epochs": 3, "timestep": 5255, "ep_reward": 705.1502685546875, "reward": 0.5282663106918335, "action": -1.142505168914795}
{"mode": "train", "epochs": 3, "timestep": 5256, "ep_reward": 705.7858276367188, "reward": 0.6355569362640381, "action": -1.216470718383789}
{"mode": "train", "epochs": 3, "timestep": 5257, "ep_reward": 706.5061645507812, "reward": 0.7203361392021179, "action": 0.19500195980072021}
{"mode": "train", "epochs": 3, "timestep": 5258, "ep_reward": 707.3019409179688, "reward": 0.7957897782325745, "action": -1.2618823051452637}
{"mode": "train", "epochs": 3, "timestep": 5259, "ep_reward": 708.1386108398438, "reward": 0.836681604385376, "action": -0.5351608991622925}
{"mode": "train", "epochs": 3, "timestep": 5260, "ep_reward": 709.0049438476562, "reward": 0.8663176894187927, "action": -0.7110599279403687}
{"mode": "train", "epochs": 3, "timestep": 5261, "ep_reward": 709.8833618164062, "reward": 0.8784385919570923, "action": -1.9806172847747803}
{"mode": "train", "epochs": 3, "timestep": 5262, "ep_reward": 710.7483520507812, "reward": 0.8649775981903076, "action": -0.9722489714622498}
{"mode": "train", "epochs": 3, "timestep": 5263, "ep_reward": 711.5903930664062, "reward": 0.8420635461807251, "action": -1.020785927772522}
{"mode": "train", "epochs": 3, "timestep": 5264, "ep_reward": 712.3876342773438, "reward": 0.7972715497016907, "action": -0.632042646408081}
{"mode": "train", "epochs": 3, "timestep": 5265, "ep_reward": 713.1173095703125, "reward": 0.7297046184539795, "action": -1.3141815662384033}
{"mode": "train", "epochs": 3, "timestep": 5266, "ep_reward": 713.7379760742188, "reward": 0.6206390261650085, "action": -0.5039857625961304}
{"mode": "train", "epochs": 3, "timestep": 5267, "ep_reward": 714.220458984375, "reward": 0.48246920108795166, "action": -0.046331048011779785}
{"mode": "train", "epochs": 3, "timestep": 5268, "ep_reward": 714.5579833984375, "reward": 0.33752304315567017, "action": -0.9400891065597534}
{"mode": "train", "epochs": 3, "timestep": 5269, "ep_reward": 714.7830810546875, "reward": 0.22507601976394653, "action": -0.8938853740692139}
{"mode": "train", "epochs": 3, "timestep": 5270, "ep_reward": 714.875732421875, "reward": 0.09266859292984009, "action": -0.3004988431930542}
{"mode": "train", "epochs": 3, "timestep": 5271, "ep_reward": 714.900146484375, "reward": 0.024427831172943115, "action": -1.809280276298523}
{"mode": "train", "epochs": 3, "timestep": 5272, "ep_reward": 715.06640625, "reward": 0.16624504327774048, "action": -1.2091009616851807}
{"mode": "train", "epochs": 3, "timestep": 5273, "ep_reward": 715.3699340820312, "reward": 0.3035256862640381, "action": -0.9457447528839111}
{"mode": "train", "epochs": 3, "timestep": 5274, "ep_reward": 715.8106079101562, "reward": 0.44064921140670776, "action": -0.6714301109313965}
{"mode": "train", "epochs": 3, "timestep": 5275, "ep_reward": 716.3775634765625, "reward": 0.5669255256652832, "action": -1.2175488471984863}
{"mode": "train", "epochs": 3, "timestep": 5276, "ep_reward": 717.0438232421875, "reward": 0.6662396192550659, "action": -1.4202139377593994}
{"mode": "train", "epochs": 3, "timestep": 5277, "ep_reward": 717.7854614257812, "reward": 0.7416315674781799, "action": -0.20152151584625244}
{"mode": "train", "epochs": 3, "timestep": 5278, "ep_reward": 718.5921020507812, "reward": 0.8066674470901489, "action": -0.3875882029533386}
{"mode": "train", "epochs": 3, "timestep": 5279, "ep_reward": 719.4410400390625, "reward": 0.8489371538162231, "action": -1.1185880899429321}
{"mode": "train", "epochs": 3, "timestep": 5280, "ep_reward": 720.308837890625, "reward": 0.867806613445282, "action": -0.3104349970817566}
{"mode": "train", "epochs": 3, "timestep": 5281, "ep_reward": 721.1864624023438, "reward": 0.8776280879974365, "action": -0.9233719706535339}
{"mode": "train", "epochs": 3, "timestep": 5282, "ep_reward": 722.0533447265625, "reward": 0.8668555021286011, "action": -0.21262139081954956}
{"mode": "train", "epochs": 3, "timestep": 5283, "ep_reward": 722.8983154296875, "reward": 0.8449952006340027, "action": -0.5052260756492615}
{"mode": "train", "epochs": 3, "timestep": 5284, "ep_reward": 723.6986694335938, "reward": 0.8003484010696411, "action": -0.6088837385177612}
{"mode": "train", "epochs": 3, "timestep": 5285, "ep_reward": 724.4277954101562, "reward": 0.7291178107261658, "action": -0.7040896415710449}
{"mode": "train", "epochs": 3, "timestep": 5286, "ep_reward": 725.052490234375, "reward": 0.6246762871742249, "action": -1.5899724960327148}
{"mode": "train", "epochs": 3, "timestep": 5287, "ep_reward": 725.5218505859375, "reward": 0.4693610668182373, "action": -0.9897407293319702}
{"mode": "train", "epochs": 3, "timestep": 5288, "ep_reward": 725.8441772460938, "reward": 0.3222966194152832, "action": -1.0625430345535278}
{"mode": "train", "epochs": 3, "timestep": 5289, "ep_reward": 726.051025390625, "reward": 0.20682549476623535, "action": -1.6094026565551758}
{"mode": "train", "epochs": 3, "timestep": 5290, "ep_reward": 726.1223754882812, "reward": 0.07135820388793945, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5291, "ep_reward": 726.1689453125, "reward": 0.046559691429138184, "action": -1.016530990600586}
{"mode": "train", "epochs": 3, "timestep": 5292, "ep_reward": 726.3541870117188, "reward": 0.1852518916130066, "action": -1.5435281991958618}
{"mode": "train", "epochs": 3, "timestep": 5293, "ep_reward": 726.6729125976562, "reward": 0.31873130798339844, "action": -0.4644981026649475}
{"mode": "train", "epochs": 3, "timestep": 5294, "ep_reward": 727.134033203125, "reward": 0.46113431453704834, "action": -1.437273383140564}
{"mode": "train", "epochs": 3, "timestep": 5295, "ep_reward": 727.7098999023438, "reward": 0.575869083404541, "action": -1.798313021659851}
{"mode": "train", "epochs": 3, "timestep": 5296, "ep_reward": 728.376953125, "reward": 0.667028546333313, "action": -1.4199674129486084}
{"mode": "train", "epochs": 3, "timestep": 5297, "ep_reward": 729.1172485351562, "reward": 0.7403132915496826, "action": -0.9885630011558533}
{"mode": "train", "epochs": 3, "timestep": 5298, "ep_reward": 729.9125366210938, "reward": 0.7952694296836853, "action": -0.5606215000152588}
{"mode": "train", "epochs": 3, "timestep": 5299, "ep_reward": 730.7453002929688, "reward": 0.832793116569519, "action": -0.10255634784698486}
{"mode": "train", "epochs": 3, "timestep": 5300, "ep_reward": 731.5999145507812, "reward": 0.8546059131622314, "action": -1.8256027698516846}
{"mode": "train", "epochs": 3, "timestep": 5301, "ep_reward": 732.4426879882812, "reward": 0.842795193195343, "action": -0.6457266807556152}
{"mode": "train", "epochs": 3, "timestep": 5302, "ep_reward": 733.2640380859375, "reward": 0.8213630318641663, "action": -1.1788904666900635}
{"mode": "train", "epochs": 3, "timestep": 5303, "ep_reward": 734.0347290039062, "reward": 0.7706856727600098, "action": -0.7360221147537231}
{"mode": "train", "epochs": 3, "timestep": 5304, "ep_reward": 734.7294921875, "reward": 0.6947706937789917, "action": -0.3019682765007019}
{"mode": "train", "epochs": 3, "timestep": 5305, "ep_reward": 735.3182983398438, "reward": 0.5888082981109619, "action": -1.830519676208496}
{"mode": "train", "epochs": 3, "timestep": 5306, "ep_reward": 735.7380981445312, "reward": 0.419796347618103, "action": -0.4594324231147766}
{"mode": "train", "epochs": 3, "timestep": 5307, "ep_reward": 736.0531616210938, "reward": 0.31507372856140137, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5308, "ep_reward": 736.251708984375, "reward": 0.19851988554000854, "action": -1.236388087272644}
{"mode": "train", "epochs": 3, "timestep": 5309, "ep_reward": 736.3134765625, "reward": 0.061795175075531006, "action": -1.3427623510360718}
{"mode": "train", "epochs": 3, "timestep": 5310, "ep_reward": 736.369873046875, "reward": 0.05638390779495239, "action": -1.1180850267410278}
{"mode": "train", "epochs": 3, "timestep": 5311, "ep_reward": 736.5636596679688, "reward": 0.19380998611450195, "action": -1.2658030986785889}
{"mode": "train", "epochs": 3, "timestep": 5312, "ep_reward": 736.8944702148438, "reward": 0.3308253884315491, "action": -0.6394797563552856}
{"mode": "train", "epochs": 3, "timestep": 5313, "ep_reward": 737.3643798828125, "reward": 0.469936728477478, "action": -0.5722638368606567}
{"mode": "train", "epochs": 3, "timestep": 5314, "ep_reward": 737.9574584960938, "reward": 0.5930636525154114, "action": -0.8036447167396545}
{"mode": "train", "epochs": 3, "timestep": 5315, "ep_reward": 738.6488647460938, "reward": 0.691402792930603, "action": -1.2070215940475464}
{"mode": "train", "epochs": 3, "timestep": 5316, "ep_reward": 739.4120483398438, "reward": 0.7631563544273376, "action": -0.7028398513793945}
{"mode": "train", "epochs": 3, "timestep": 5317, "ep_reward": 740.2305908203125, "reward": 0.8185261487960815, "action": -1.084546685218811}
{"mode": "train", "epochs": 3, "timestep": 5318, "ep_reward": 741.0822143554688, "reward": 0.8516314625740051, "action": -0.7079454064369202}
{"mode": "train", "epochs": 3, "timestep": 5319, "ep_reward": 741.953369140625, "reward": 0.871140718460083, "action": -1.507787823677063}
{"mode": "train", "epochs": 3, "timestep": 5320, "ep_reward": 742.82177734375, "reward": 0.8684098720550537, "action": -1.0686451196670532}
{"mode": "train", "epochs": 3, "timestep": 5321, "ep_reward": 743.6742553710938, "reward": 0.8524499535560608, "action": -0.5806097984313965}
{"mode": "train", "epochs": 3, "timestep": 5322, "ep_reward": 744.49560546875, "reward": 0.8213741779327393, "action": -0.9255386590957642}
{"mode": "train", "epochs": 3, "timestep": 5323, "ep_reward": 745.2587890625, "reward": 0.763169527053833, "action": -0.5013929605484009}
{"mode": "train", "epochs": 3, "timestep": 5324, "ep_reward": 745.9385375976562, "reward": 0.6797438859939575, "action": -0.9876392483711243}
{"mode": "train", "epochs": 3, "timestep": 5325, "ep_reward": 746.4927368164062, "reward": 0.5541979074478149, "action": -1.5311088562011719}
{"mode": "train", "epochs": 3, "timestep": 5326, "ep_reward": 746.8726806640625, "reward": 0.3799216151237488, "action": -1.354938268661499}
{"mode": "train", "epochs": 3, "timestep": 5327, "ep_reward": 747.1487426757812, "reward": 0.27608686685562134, "action": -1.5530188083648682}
{"mode": "train", "epochs": 3, "timestep": 5328, "ep_reward": 747.3011474609375, "reward": 0.15240585803985596, "action": -0.7320582866668701}
{"mode": "train", "epochs": 3, "timestep": 5329, "ep_reward": 747.3096923828125, "reward": 0.008561015129089355, "action": -1.1363310813903809}
{"mode": "train", "epochs": 3, "timestep": 5330, "ep_reward": 747.4171752929688, "reward": 0.10746371746063232, "action": -0.46431469917297363}
{"mode": "train", "epochs": 3, "timestep": 5331, "ep_reward": 747.6697387695312, "reward": 0.25256896018981934, "action": -1.0150033235549927}
{"mode": "train", "epochs": 3, "timestep": 5332, "ep_reward": 748.0595092773438, "reward": 0.3897613286972046, "action": -1.1926673650741577}
{"mode": "train", "epochs": 3, "timestep": 5333, "ep_reward": 748.5751342773438, "reward": 0.515654444694519, "action": -0.2866470217704773}
{"mode": "train", "epochs": 3, "timestep": 5334, "ep_reward": 749.2091674804688, "reward": 0.634046733379364, "action": -1.5656810998916626}
{"mode": "train", "epochs": 3, "timestep": 5335, "ep_reward": 749.9256591796875, "reward": 0.7164992094039917, "action": -1.5056226253509521}
{"mode": "train", "epochs": 3, "timestep": 5336, "ep_reward": 750.7046508789062, "reward": 0.778982400894165, "action": -1.3757137060165405}
{"mode": "train", "epochs": 3, "timestep": 5337, "ep_reward": 751.5277099609375, "reward": 0.8230451345443726, "action": -0.599987268447876}
{"mode": "train", "epochs": 3, "timestep": 5338, "ep_reward": 752.3831787109375, "reward": 0.8554590940475464, "action": -0.8095754384994507}
{"mode": "train", "epochs": 3, "timestep": 5339, "ep_reward": 753.2523803710938, "reward": 0.8691723346710205, "action": -0.1917983889579773}
{"mode": "train", "epochs": 3, "timestep": 5340, "ep_reward": 754.1243896484375, "reward": 0.8720085024833679, "action": -0.8714765310287476}
{"mode": "train", "epochs": 3, "timestep": 5341, "ep_reward": 754.9769287109375, "reward": 0.8525307178497314, "action": -0.3215528726577759}
{"mode": "train", "epochs": 3, "timestep": 5342, "ep_reward": 755.7955932617188, "reward": 0.8186631202697754, "action": -0.8645268678665161}
{"mode": "train", "epochs": 3, "timestep": 5343, "ep_reward": 756.5512084960938, "reward": 0.755616307258606, "action": -1.5611653327941895}
{"mode": "train", "epochs": 3, "timestep": 5344, "ep_reward": 757.2041015625, "reward": 0.6528952121734619, "action": -0.5445278882980347}
{"mode": "train", "epochs": 3, "timestep": 5345, "ep_reward": 757.7283935546875, "reward": 0.5242971777915955, "action": -0.5448644161224365}
{"mode": "train", "epochs": 3, "timestep": 5346, "ep_reward": 758.0873413085938, "reward": 0.3589656949043274, "action": -0.22057580947875977}
{"mode": "train", "epochs": 3, "timestep": 5347, "ep_reward": 758.338134765625, "reward": 0.2507804036140442, "action": 0.06787025928497314}
{"mode": "train", "epochs": 3, "timestep": 5348, "ep_reward": 758.4606323242188, "reward": 0.12251430749893188, "action": -1.1237359046936035}
{"mode": "train", "epochs": 3, "timestep": 5349, "ep_reward": 758.452392578125, "reward": -0.008257389068603516, "action": -1.1924413442611694}
{"mode": "train", "epochs": 3, "timestep": 5350, "ep_reward": 758.590087890625, "reward": 0.13769173622131348, "action": -1.31440269947052}
{"mode": "train", "epochs": 3, "timestep": 5351, "ep_reward": 758.8630981445312, "reward": 0.2730017304420471, "action": -1.3450183868408203}
{"mode": "train", "epochs": 3, "timestep": 5352, "ep_reward": 759.2702026367188, "reward": 0.40711379051208496, "action": -0.49647849798202515}
{"mode": "train", "epochs": 3, "timestep": 5353, "ep_reward": 759.8104248046875, "reward": 0.5402107238769531, "action": -0.4745502471923828}
{"mode": "train", "epochs": 3, "timestep": 5354, "ep_reward": 760.462890625, "reward": 0.6524550318717957, "action": -0.02868819236755371}
{"mode": "train", "epochs": 3, "timestep": 5355, "ep_reward": 761.2077026367188, "reward": 0.7447870969772339, "action": -1.4218716621398926}
{"mode": "train", "epochs": 3, "timestep": 5356, "ep_reward": 762.0089721679688, "reward": 0.8012411594390869, "action": -0.6809785962104797}
{"mode": "train", "epochs": 3, "timestep": 5357, "ep_reward": 762.8543090820312, "reward": 0.8453310132026672, "action": -0.6204167604446411}
{"mode": "train", "epochs": 3, "timestep": 5358, "ep_reward": 763.726806640625, "reward": 0.8725085258483887, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5359, "ep_reward": 764.6005859375, "reward": 0.8737583756446838, "action": -1.257075548171997}
{"mode": "train", "epochs": 3, "timestep": 5360, "ep_reward": 765.4659423828125, "reward": 0.8653266429901123, "action": -1.1750717163085938}
{"mode": "train", "epochs": 3, "timestep": 5361, "ep_reward": 766.3054809570312, "reward": 0.8395249843597412, "action": -1.7957842350006104}
{"mode": "train", "epochs": 3, "timestep": 5362, "ep_reward": 767.0905151367188, "reward": 0.7850300073623657, "action": -1.6545839309692383}
{"mode": "train", "epochs": 3, "timestep": 5363, "ep_reward": 767.7918090820312, "reward": 0.7013213634490967, "action": -0.4064146876335144}
{"mode": "train", "epochs": 3, "timestep": 5364, "ep_reward": 768.3880004882812, "reward": 0.596183180809021, "action": -0.5830966234207153}
{"mode": "train", "epochs": 3, "timestep": 5365, "ep_reward": 768.8373413085938, "reward": 0.44932812452316284, "action": -1.5791828632354736}
{"mode": "train", "epochs": 3, "timestep": 5366, "ep_reward": 769.1598510742188, "reward": 0.3225318193435669, "action": -0.8940688371658325}
{"mode": "train", "epochs": 3, "timestep": 5367, "ep_reward": 769.3670043945312, "reward": 0.20712900161743164, "action": -1.3480663299560547}
{"mode": "train", "epochs": 3, "timestep": 5368, "ep_reward": 769.4389038085938, "reward": 0.07187914848327637, "action": -0.6328377723693848}
{"mode": "train", "epochs": 3, "timestep": 5369, "ep_reward": 769.4851684570312, "reward": 0.04626339673995972, "action": -0.9633049964904785}
{"mode": "train", "epochs": 3, "timestep": 5370, "ep_reward": 769.6702880859375, "reward": 0.18512439727783203, "action": -0.4764794707298279}
{"mode": "train", "epochs": 3, "timestep": 5371, "ep_reward": 770.0020141601562, "reward": 0.33170366287231445, "action": -1.17109215259552}
{"mode": "train", "epochs": 3, "timestep": 5372, "ep_reward": 770.4651489257812, "reward": 0.4631494879722595, "action": -0.8564907908439636}
{"mode": "train", "epochs": 3, "timestep": 5373, "ep_reward": 771.0490112304688, "reward": 0.5838825702667236, "action": -1.378679871559143}
{"mode": "train", "epochs": 3, "timestep": 5374, "ep_reward": 771.7274169921875, "reward": 0.6783859729766846, "action": -0.7857280373573303}
{"mode": "train", "epochs": 3, "timestep": 5375, "ep_reward": 772.4843139648438, "reward": 0.7568823099136353, "action": -0.9541492462158203}
{"mode": "train", "epochs": 3, "timestep": 5376, "ep_reward": 773.2962036132812, "reward": 0.8119008541107178, "action": -0.9565137624740601}
{"mode": "train", "epochs": 3, "timestep": 5377, "ep_reward": 774.1439208984375, "reward": 0.8477279543876648, "action": -0.5635563731193542}
{"mode": "train", "epochs": 3, "timestep": 5378, "ep_reward": 775.0136108398438, "reward": 0.8696699142456055, "action": -1.1701033115386963}
{"mode": "train", "epochs": 3, "timestep": 5379, "ep_reward": 775.8843994140625, "reward": 0.8708075881004333, "action": -0.4514067769050598}
{"mode": "train", "epochs": 3, "timestep": 5380, "ep_reward": 776.74609375, "reward": 0.8616946935653687, "action": -0.8270769119262695}
{"mode": "train", "epochs": 3, "timestep": 5381, "ep_reward": 777.5771484375, "reward": 0.8310630917549133, "action": -0.8029693365097046}
{"mode": "train", "epochs": 3, "timestep": 5382, "ep_reward": 778.3550415039062, "reward": 0.7779046297073364, "action": -1.4481983184814453}
{"mode": "train", "epochs": 3, "timestep": 5383, "ep_reward": 779.043212890625, "reward": 0.6881815195083618, "action": -1.2407604455947876}
{"mode": "train", "epochs": 3, "timestep": 5384, "ep_reward": 779.6060180664062, "reward": 0.5628031492233276, "action": -1.341953992843628}
{"mode": "train", "epochs": 3, "timestep": 5385, "ep_reward": 779.9989624023438, "reward": 0.39294862747192383, "action": -1.0356076955795288}
{"mode": "train", "epochs": 3, "timestep": 5386, "ep_reward": 780.2869873046875, "reward": 0.28799504041671753, "action": -0.27373629808425903}
{"mode": "train", "epochs": 3, "timestep": 5387, "ep_reward": 780.4532470703125, "reward": 0.16625845432281494, "action": -0.6849341988563538}
{"mode": "train", "epochs": 3, "timestep": 5388, "ep_reward": 780.477783203125, "reward": 0.0245245099067688, "action": -0.9112094640731812}
{"mode": "train", "epochs": 3, "timestep": 5389, "ep_reward": 780.5704345703125, "reward": 0.09264934062957764, "action": -1.1135698556900024}
{"mode": "train", "epochs": 3, "timestep": 5390, "ep_reward": 780.7997436523438, "reward": 0.22929519414901733, "action": -0.7974623441696167}
{"mode": "train", "epochs": 3, "timestep": 5391, "ep_reward": 781.1710205078125, "reward": 0.3713018298149109, "action": -1.4156666994094849}
{"mode": "train", "epochs": 3, "timestep": 5392, "ep_reward": 781.6680297851562, "reward": 0.4970228672027588, "action": -0.3939921259880066}
{"mode": "train", "epochs": 3, "timestep": 5393, "ep_reward": 782.285888671875, "reward": 0.6178814768791199, "action": -0.286099374294281}
{"mode": "train", "epochs": 3, "timestep": 5394, "ep_reward": 783.001708984375, "reward": 0.715826690196991, "action": -1.6003506183624268}
{"mode": "train", "epochs": 3, "timestep": 5395, "ep_reward": 783.7796630859375, "reward": 0.7779668569564819, "action": -1.6617209911346436}
{"mode": "train", "epochs": 3, "timestep": 5396, "ep_reward": 784.5999755859375, "reward": 0.8203070163726807, "action": -1.0636851787567139}
{"mode": "train", "epochs": 3, "timestep": 5397, "ep_reward": 785.4497680664062, "reward": 0.8498042821884155, "action": -0.6490930318832397}
{"mode": "train", "epochs": 3, "timestep": 5398, "ep_reward": 786.3153076171875, "reward": 0.8655642867088318, "action": -1.1893733739852905}
{"mode": "train", "epochs": 3, "timestep": 5399, "ep_reward": 787.17529296875, "reward": 0.8600108027458191, "action": -1.25262451171875}
{"mode": "train", "epochs": 3, "timestep": 5400, "ep_reward": 788.0106811523438, "reward": 0.8353884220123291, "action": -1.224736213684082}
{"mode": "train", "epochs": 3, "timestep": 5401, "ep_reward": 788.7990112304688, "reward": 0.7883027791976929, "action": -1.3908085823059082}
{"mode": "train", "epochs": 3, "timestep": 5402, "ep_reward": 789.5093994140625, "reward": 0.7103993892669678, "action": -0.16026657819747925}
{"mode": "train", "epochs": 3, "timestep": 5403, "ep_reward": 790.1216430664062, "reward": 0.6122491359710693, "action": -1.3800033330917358}
{"mode": "train", "epochs": 3, "timestep": 5404, "ep_reward": 790.57958984375, "reward": 0.45795685052871704, "action": -0.8958059549331665}
{"mode": "train", "epochs": 3, "timestep": 5405, "ep_reward": 790.9116821289062, "reward": 0.3321058750152588, "action": -1.0924323797225952}
{"mode": "train", "epochs": 3, "timestep": 5406, "ep_reward": 791.1303100585938, "reward": 0.21862488985061646, "action": -0.9374086260795593}
{"mode": "train", "epochs": 3, "timestep": 5407, "ep_reward": 791.2155151367188, "reward": 0.08517509698867798, "action": -0.27175629138946533}
{"mode": "train", "epochs": 3, "timestep": 5408, "ep_reward": 791.248046875, "reward": 0.03251403570175171, "action": -0.8291022777557373}
{"mode": "train", "epochs": 3, "timestep": 5409, "ep_reward": 791.4210205078125, "reward": 0.17296266555786133, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5410, "ep_reward": 791.721435546875, "reward": 0.30038630962371826, "action": -1.6866968870162964}
{"mode": "train", "epochs": 3, "timestep": 5411, "ep_reward": 792.1514282226562, "reward": 0.4299820065498352, "action": -1.174660563468933}
{"mode": "train", "epochs": 3, "timestep": 5412, "ep_reward": 792.704345703125, "reward": 0.5529388189315796, "action": -1.317529559135437}
{"mode": "train", "epochs": 3, "timestep": 5413, "ep_reward": 793.3573608398438, "reward": 0.6530410051345825, "action": -1.0492968559265137}
{"mode": "train", "epochs": 3, "timestep": 5414, "ep_reward": 794.0894165039062, "reward": 0.7320293188095093, "action": -0.66860032081604}
{"mode": "train", "epochs": 3, "timestep": 5415, "ep_reward": 794.8799438476562, "reward": 0.7905313372612, "action": -1.1364697217941284}
{"mode": "train", "epochs": 3, "timestep": 5416, "ep_reward": 795.7021484375, "reward": 0.8221993446350098, "action": -0.9462870359420776}
{"mode": "train", "epochs": 3, "timestep": 5417, "ep_reward": 796.537353515625, "reward": 0.8351994752883911, "action": -1.1011111736297607}
{"mode": "train", "epochs": 3, "timestep": 5418, "ep_reward": 797.3635864257812, "reward": 0.8262253999710083, "action": -0.8738760948181152}
{"mode": "train", "epochs": 3, "timestep": 5419, "ep_reward": 798.160400390625, "reward": 0.7968043684959412, "action": 0.27384161949157715}
{"mode": "train", "epochs": 3, "timestep": 5420, "ep_reward": 798.9142456054688, "reward": 0.7538520097732544, "action": -0.8686307072639465}
{"mode": "train", "epochs": 3, "timestep": 5421, "ep_reward": 799.5819091796875, "reward": 0.6676346063613892, "action": -1.1613569259643555}
{"mode": "train", "epochs": 3, "timestep": 5422, "ep_reward": 800.1204833984375, "reward": 0.5385804772377014, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5423, "ep_reward": 800.5086669921875, "reward": 0.38818591833114624, "action": -1.1893550157546997}
{"mode": "train", "epochs": 3, "timestep": 5424, "ep_reward": 800.7948608398438, "reward": 0.2861761450767517, "action": -1.0771112442016602}
{"mode": "train", "epochs": 3, "timestep": 5425, "ep_reward": 800.9590454101562, "reward": 0.16421175003051758, "action": -0.4372694492340088}
{"mode": "train", "epochs": 3, "timestep": 5426, "ep_reward": 800.9811401367188, "reward": 0.022106826305389404, "action": -1.2161904573440552}
{"mode": "train", "epochs": 3, "timestep": 5427, "ep_reward": 801.075927734375, "reward": 0.0948064923286438, "action": -1.5364439487457275}
{"mode": "train", "epochs": 3, "timestep": 5428, "ep_reward": 801.302978515625, "reward": 0.22707444429397583, "action": -0.41828858852386475}
{"mode": "train", "epochs": 3, "timestep": 5429, "ep_reward": 801.677490234375, "reward": 0.374511182308197, "action": -1.7769242525100708}
{"mode": "train", "epochs": 3, "timestep": 5430, "ep_reward": 802.1731567382812, "reward": 0.49564099311828613, "action": -1.034399151802063}
{"mode": "train", "epochs": 3, "timestep": 5431, "ep_reward": 802.7830200195312, "reward": 0.6098463535308838, "action": -0.4278573989868164}
{"mode": "train", "epochs": 3, "timestep": 5432, "ep_reward": 803.4906616210938, "reward": 0.7076407074928284, "action": -1.7696571350097656}
{"mode": "train", "epochs": 3, "timestep": 5433, "ep_reward": 804.2592163085938, "reward": 0.7685296535491943, "action": -1.3119585514068604}
{"mode": "train", "epochs": 3, "timestep": 5434, "ep_reward": 805.0725708007812, "reward": 0.8133355975151062, "action": -0.3707278370857239}
{"mode": "train", "epochs": 3, "timestep": 5435, "ep_reward": 805.9193725585938, "reward": 0.8468314409255981, "action": -1.2066597938537598}
{"mode": "train", "epochs": 3, "timestep": 5436, "ep_reward": 806.7740478515625, "reward": 0.8546454906463623, "action": -1.1602630615234375}
{"mode": "train", "epochs": 3, "timestep": 5437, "ep_reward": 807.6187744140625, "reward": 0.844735324382782, "action": -0.5691308975219727}
{"mode": "train", "epochs": 3, "timestep": 5438, "ep_reward": 808.4388427734375, "reward": 0.8200927972793579, "action": -0.8832980394363403}
{"mode": "train", "epochs": 3, "timestep": 5439, "ep_reward": 809.2073364257812, "reward": 0.7685099840164185, "action": -0.7855707406997681}
{"mode": "train", "epochs": 3, "timestep": 5440, "ep_reward": 809.8954467773438, "reward": 0.6880936622619629, "action": -0.39023882150650024}
{"mode": "train", "epochs": 3, "timestep": 5441, "ep_reward": 810.472412109375, "reward": 0.5769508481025696, "action": -0.855226993560791}
{"mode": "train", "epochs": 3, "timestep": 5442, "ep_reward": 810.8919067382812, "reward": 0.4194900393486023, "action": -0.9098759889602661}
{"mode": "train", "epochs": 3, "timestep": 5443, "ep_reward": 811.1947021484375, "reward": 0.30282169580459595, "action": -0.09809315204620361}
{"mode": "train", "epochs": 3, "timestep": 5444, "ep_reward": 811.3783569335938, "reward": 0.18368053436279297, "action": -1.3607103824615479}
{"mode": "train", "epochs": 3, "timestep": 5445, "ep_reward": 811.423095703125, "reward": 0.04475057125091553, "action": -0.5696276426315308}
{"mode": "train", "epochs": 3, "timestep": 5446, "ep_reward": 811.4964599609375, "reward": 0.07339328527450562, "action": -0.607896625995636}
{"mode": "train", "epochs": 3, "timestep": 5447, "ep_reward": 811.7122192382812, "reward": 0.21575182676315308, "action": -0.7492266297340393}
{"mode": "train", "epochs": 3, "timestep": 5448, "ep_reward": 812.0699462890625, "reward": 0.3577364683151245, "action": -0.7601409554481506}
{"mode": "train", "epochs": 3, "timestep": 5449, "ep_reward": 812.5616455078125, "reward": 0.49167460203170776, "action": -0.3022959232330322}
{"mode": "train", "epochs": 3, "timestep": 5450, "ep_reward": 813.1754150390625, "reward": 0.6137850284576416, "action": -0.8999485373497009}
{"mode": "train", "epochs": 3, "timestep": 5451, "ep_reward": 813.8827514648438, "reward": 0.7073208093643188, "action": -0.48001283407211304}
{"mode": "train", "epochs": 3, "timestep": 5452, "ep_reward": 814.6655883789062, "reward": 0.7828395366668701, "action": -0.6582415103912354}
{"mode": "train", "epochs": 3, "timestep": 5453, "ep_reward": 815.501708984375, "reward": 0.836137592792511, "action": -0.9056739807128906}
{"mode": "train", "epochs": 3, "timestep": 5454, "ep_reward": 816.3720092773438, "reward": 0.8703294992446899, "action": -0.6166791915893555}
{"mode": "train", "epochs": 3, "timestep": 5455, "ep_reward": 817.2642822265625, "reward": 0.8922566771507263, "action": -0.4649360775947571}
{"mode": "train", "epochs": 3, "timestep": 5456, "ep_reward": 818.1666870117188, "reward": 0.9024111032485962, "action": -0.05238741636276245}
{"mode": "train", "epochs": 3, "timestep": 5457, "ep_reward": 819.0701293945312, "reward": 0.9034282565116882, "action": -0.8371714949607849}
{"mode": "train", "epochs": 3, "timestep": 5458, "ep_reward": 819.9561767578125, "reward": 0.8860710859298706, "action": -0.29318946599960327}
{"mode": "train", "epochs": 3, "timestep": 5459, "ep_reward": 820.8140869140625, "reward": 0.8579167723655701, "action": -0.211858868598938}
{"mode": "train", "epochs": 3, "timestep": 5460, "ep_reward": 821.6262817382812, "reward": 0.8121950030326843, "action": -0.7844738364219666}
{"mode": "train", "epochs": 3, "timestep": 5461, "ep_reward": 822.3634033203125, "reward": 0.7371310591697693, "action": -0.8270608186721802}
{"mode": "train", "epochs": 3, "timestep": 5462, "ep_reward": 822.9938354492188, "reward": 0.6304055452346802, "action": -1.2631556987762451}
{"mode": "train", "epochs": 3, "timestep": 5463, "ep_reward": 823.4747314453125, "reward": 0.48090118169784546, "action": -0.7004638314247131}
{"mode": "train", "epochs": 3, "timestep": 5464, "ep_reward": 823.7843017578125, "reward": 0.3095923066139221, "action": -0.49297088384628296}
{"mode": "train", "epochs": 3, "timestep": 5465, "ep_reward": 823.97607421875, "reward": 0.1917930245399475, "action": -0.802780270576477}
{"mode": "train", "epochs": 3, "timestep": 5466, "ep_reward": 824.0300903320312, "reward": 0.05404478311538696, "action": -0.4890173077583313}
{"mode": "train", "epochs": 3, "timestep": 5467, "ep_reward": 824.0943603515625, "reward": 0.06428182125091553, "action": -0.4194068908691406}
{"mode": "train", "epochs": 3, "timestep": 5468, "ep_reward": 824.3030395507812, "reward": 0.20869022607803345, "action": -0.7324529886245728}
{"mode": "train", "epochs": 3, "timestep": 5469, "ep_reward": 824.6537475585938, "reward": 0.35068124532699585, "action": 0.15311765670776367}
{"mode": "train", "epochs": 3, "timestep": 5470, "ep_reward": 825.1491088867188, "reward": 0.49534523487091064, "action": -1.1405298709869385}
{"mode": "train", "epochs": 3, "timestep": 5471, "ep_reward": 825.756591796875, "reward": 0.6074768304824829, "action": -0.7776963710784912}
{"mode": "train", "epochs": 3, "timestep": 5472, "ep_reward": 826.4601440429688, "reward": 0.7035773992538452, "action": -0.07154417037963867}
{"mode": "train", "epochs": 3, "timestep": 5473, "ep_reward": 827.2440185546875, "reward": 0.783854067325592, "action": -1.5799179077148438}
{"mode": "train", "epochs": 3, "timestep": 5474, "ep_reward": 828.0748291015625, "reward": 0.8308063745498657, "action": -1.654557704925537}
{"mode": "train", "epochs": 3, "timestep": 5475, "ep_reward": 828.9361572265625, "reward": 0.8613487482070923, "action": -1.7198734283447266}
{"mode": "train", "epochs": 3, "timestep": 5476, "ep_reward": 829.813232421875, "reward": 0.8770489692687988, "action": -1.4301849603652954}
{"mode": "train", "epochs": 3, "timestep": 5477, "ep_reward": 830.6942138671875, "reward": 0.8809897899627686, "action": -0.6557894945144653}
{"mode": "train", "epochs": 3, "timestep": 5478, "ep_reward": 831.570556640625, "reward": 0.8763169050216675, "action": -1.1263107061386108}
{"mode": "train", "epochs": 3, "timestep": 5479, "ep_reward": 832.421875, "reward": 0.8513452410697937, "action": -0.9429636001586914}
{"mode": "train", "epochs": 3, "timestep": 5480, "ep_reward": 833.2294921875, "reward": 0.807633638381958, "action": -0.7880969643592834}
{"mode": "train", "epochs": 3, "timestep": 5481, "ep_reward": 833.96923828125, "reward": 0.7397682666778564, "action": -1.4406155347824097}
{"mode": "train", "epochs": 3, "timestep": 5482, "ep_reward": 834.6007080078125, "reward": 0.6314429044723511, "action": -1.056620717048645}
{"mode": "train", "epochs": 3, "timestep": 5483, "ep_reward": 835.0883178710938, "reward": 0.4876277446746826, "action": -0.6084043979644775}
{"mode": "train", "epochs": 3, "timestep": 5484, "ep_reward": 835.427734375, "reward": 0.3393937945365906, "action": -0.9974379539489746}
{"mode": "train", "epochs": 3, "timestep": 5485, "ep_reward": 835.6549072265625, "reward": 0.22717326879501343, "action": -1.777445912361145}
{"mode": "train", "epochs": 3, "timestep": 5486, "ep_reward": 835.7501220703125, "reward": 0.09522485733032227, "action": -0.991150438785553}
{"mode": "train", "epochs": 3, "timestep": 5487, "ep_reward": 835.7719116210938, "reward": 0.021800994873046875, "action": -0.8289170265197754}
{"mode": "train", "epochs": 3, "timestep": 5488, "ep_reward": 835.935791015625, "reward": 0.1638936996459961, "action": -0.5840065479278564}
{"mode": "train", "epochs": 3, "timestep": 5489, "ep_reward": 836.2446899414062, "reward": 0.30888181924819946, "action": -0.6136907339096069}
{"mode": "train", "epochs": 3, "timestep": 5490, "ep_reward": 836.6931762695312, "reward": 0.4484947919845581, "action": -0.10410565137863159}
{"mode": "train", "epochs": 3, "timestep": 5491, "ep_reward": 837.2722778320312, "reward": 0.5790885090827942, "action": -1.0264499187469482}
{"mode": "train", "epochs": 3, "timestep": 5492, "ep_reward": 837.9505004882812, "reward": 0.6781986355781555, "action": -1.6274102926254272}
{"mode": "train", "epochs": 3, "timestep": 5493, "ep_reward": 838.701171875, "reward": 0.7506875991821289, "action": -1.2122783660888672}
{"mode": "train", "epochs": 3, "timestep": 5494, "ep_reward": 839.5084838867188, "reward": 0.8073399066925049, "action": -1.3196460008621216}
{"mode": "train", "epochs": 3, "timestep": 5495, "ep_reward": 840.3531494140625, "reward": 0.8446536064147949, "action": -1.2961969375610352}
{"mode": "train", "epochs": 3, "timestep": 5496, "ep_reward": 841.2189331054688, "reward": 0.8657783269882202, "action": -0.6833036541938782}
{"mode": "train", "epochs": 3, "timestep": 5497, "ep_reward": 842.09521484375, "reward": 0.8762847781181335, "action": -1.3403313159942627}
{"mode": "train", "epochs": 3, "timestep": 5498, "ep_reward": 842.9609985351562, "reward": 0.8657609224319458, "action": -1.1919512748718262}
{"mode": "train", "epochs": 3, "timestep": 5499, "ep_reward": 843.7993774414062, "reward": 0.8383818864822388, "action": -1.6489620208740234}
{"mode": "train", "epochs": 3, "timestep": 5500, "ep_reward": 844.5831909179688, "reward": 0.7838438153266907, "action": -1.106070876121521}
{"mode": "train", "epochs": 3, "timestep": 5501, "ep_reward": 845.2882690429688, "reward": 0.7051014304161072, "action": -1.585524082183838}
{"mode": "train", "epochs": 3, "timestep": 5502, "ep_reward": 845.8717041015625, "reward": 0.5834139585494995, "action": -0.7108907699584961}
{"mode": "train", "epochs": 3, "timestep": 5503, "ep_reward": 846.3026123046875, "reward": 0.43091511726379395, "action": -1.0666254758834839}
{"mode": "train", "epochs": 3, "timestep": 5504, "ep_reward": 846.6178588867188, "reward": 0.31523507833480835, "action": -0.6350295543670654}
{"mode": "train", "epochs": 3, "timestep": 5505, "ep_reward": 846.8162841796875, "reward": 0.19839942455291748, "action": -1.5007591247558594}
{"mode": "train", "epochs": 3, "timestep": 5506, "ep_reward": 846.8780517578125, "reward": 0.061767637729644775, "action": -0.9217348098754883}
{"mode": "train", "epochs": 3, "timestep": 5507, "ep_reward": 846.9345703125, "reward": 0.05653798580169678, "action": -0.43004345893859863}
{"mode": "train", "epochs": 3, "timestep": 5508, "ep_reward": 847.1351318359375, "reward": 0.2005710005760193, "action": -0.7407605648040771}
{"mode": "train", "epochs": 3, "timestep": 5509, "ep_reward": 847.4777221679688, "reward": 0.34261661767959595, "action": -1.180601716041565}
{"mode": "train", "epochs": 3, "timestep": 5510, "ep_reward": 847.9505615234375, "reward": 0.4728280305862427, "action": -0.5991790294647217}
{"mode": "train", "epochs": 3, "timestep": 5511, "ep_reward": 848.5454711914062, "reward": 0.5948930978775024, "action": -0.7387552261352539}
{"mode": "train", "epochs": 3, "timestep": 5512, "ep_reward": 849.2391357421875, "reward": 0.6936793923377991, "action": -1.1652710437774658}
{"mode": "train", "epochs": 3, "timestep": 5513, "ep_reward": 850.0051879882812, "reward": 0.7660506963729858, "action": -0.6043378710746765}
{"mode": "train", "epochs": 3, "timestep": 5514, "ep_reward": 850.828125, "reward": 0.8229115009307861, "action": -0.6603387594223022}
{"mode": "train", "epochs": 3, "timestep": 5515, "ep_reward": 851.6887817382812, "reward": 0.8606495261192322, "action": -0.24235594272613525}
{"mode": "train", "epochs": 3, "timestep": 5516, "ep_reward": 852.574462890625, "reward": 0.8856632113456726, "action": -1.2064008712768555}
{"mode": "train", "epochs": 3, "timestep": 5517, "ep_reward": 853.4638671875, "reward": 0.889406144618988, "action": -0.40639352798461914}
{"mode": "train", "epochs": 3, "timestep": 5518, "ep_reward": 854.3494873046875, "reward": 0.8856077194213867, "action": -0.4562506079673767}
{"mode": "train", "epochs": 3, "timestep": 5519, "ep_reward": 855.2161254882812, "reward": 0.8666368722915649, "action": -0.5728553533554077}
{"mode": "train", "epochs": 3, "timestep": 5520, "ep_reward": 856.045166015625, "reward": 0.82902991771698, "action": -0.7730437517166138}
{"mode": "train", "epochs": 3, "timestep": 5521, "ep_reward": 856.8120727539062, "reward": 0.7669047713279724, "action": -0.6418311595916748}
{"mode": "train", "epochs": 3, "timestep": 5522, "ep_reward": 857.4893188476562, "reward": 0.6772346496582031, "action": -0.8071339726448059}
{"mode": "train", "epochs": 3, "timestep": 5523, "ep_reward": 858.0400390625, "reward": 0.5506924390792847, "action": -0.22553706169128418}
{"mode": "train", "epochs": 3, "timestep": 5524, "ep_reward": 858.4349975585938, "reward": 0.39496463537216187, "action": -1.9608162641525269}
{"mode": "train", "epochs": 3, "timestep": 5525, "ep_reward": 858.6917724609375, "reward": 0.2567891478538513, "action": -0.7140363454818726}
{"mode": "train", "epochs": 3, "timestep": 5526, "ep_reward": 858.8213500976562, "reward": 0.1295715570449829, "action": -1.1906795501708984}
{"mode": "train", "epochs": 3, "timestep": 5527, "ep_reward": 858.8051147460938, "reward": -0.01621401309967041, "action": -0.457883358001709}
{"mode": "train", "epochs": 3, "timestep": 5528, "ep_reward": 858.9358520507812, "reward": 0.13073670864105225, "action": -0.9567635655403137}
{"mode": "train", "epochs": 3, "timestep": 5529, "ep_reward": 859.206298828125, "reward": 0.27042412757873535, "action": -0.2836607098579407}
{"mode": "train", "epochs": 3, "timestep": 5530, "ep_reward": 859.6229858398438, "reward": 0.41671502590179443, "action": -0.39025384187698364}
{"mode": "train", "epochs": 3, "timestep": 5531, "ep_reward": 860.1713256835938, "reward": 0.5483241677284241, "action": -0.19240111112594604}
{"mode": "train", "epochs": 3, "timestep": 5532, "ep_reward": 860.8328247070312, "reward": 0.6615040898323059, "action": -1.5080747604370117}
{"mode": "train", "epochs": 3, "timestep": 5533, "ep_reward": 861.5722045898438, "reward": 0.7393723726272583, "action": -0.6717983484268188}
{"mode": "train", "epochs": 3, "timestep": 5534, "ep_reward": 862.3771362304688, "reward": 0.8049012422561646, "action": -0.6544841527938843}
{"mode": "train", "epochs": 3, "timestep": 5535, "ep_reward": 863.2284545898438, "reward": 0.8513091206550598, "action": -1.2102242708206177}
{"mode": "train", "epochs": 3, "timestep": 5536, "ep_reward": 864.10595703125, "reward": 0.8774852752685547, "action": 0.0011938810348510742}
{"mode": "train", "epochs": 3, "timestep": 5537, "ep_reward": 865.0046997070312, "reward": 0.8987491130828857, "action": -1.6756012439727783}
{"mode": "train", "epochs": 3, "timestep": 5538, "ep_reward": 865.8998413085938, "reward": 0.8951360583305359, "action": -1.0204533338546753}
{"mode": "train", "epochs": 3, "timestep": 5539, "ep_reward": 866.7827758789062, "reward": 0.8829324245452881, "action": 0.4582251310348511}
{"mode": "train", "epochs": 3, "timestep": 5540, "ep_reward": 867.6505737304688, "reward": 0.8677971363067627, "action": -0.904490053653717}
{"mode": "train", "epochs": 3, "timestep": 5541, "ep_reward": 868.4741821289062, "reward": 0.8235979676246643, "action": -1.8671107292175293}
{"mode": "train", "epochs": 3, "timestep": 5542, "ep_reward": 869.21923828125, "reward": 0.7450352907180786, "action": -0.8979724049568176}
{"mode": "train", "epochs": 3, "timestep": 5543, "ep_reward": 869.8629150390625, "reward": 0.6436502933502197, "action": -1.1998602151870728}
{"mode": "train", "epochs": 3, "timestep": 5544, "ep_reward": 870.3631591796875, "reward": 0.5002713203430176, "action": -1.4634392261505127}
{"mode": "train", "epochs": 3, "timestep": 5545, "ep_reward": 870.6992797851562, "reward": 0.3360992670059204, "action": -1.2195196151733398}
{"mode": "train", "epochs": 3, "timestep": 5546, "ep_reward": 870.9227294921875, "reward": 0.22344601154327393, "action": -0.6142115592956543}
{"mode": "train", "epochs": 3, "timestep": 5547, "ep_reward": 871.0133666992188, "reward": 0.09065920114517212, "action": -1.1899745464324951}
{"mode": "train", "epochs": 3, "timestep": 5548, "ep_reward": 871.0399780273438, "reward": 0.026636123657226562, "action": -0.8412885069847107}
{"mode": "train", "epochs": 3, "timestep": 5549, "ep_reward": 871.2080078125, "reward": 0.16805291175842285, "action": -0.9896435141563416}
{"mode": "train", "epochs": 3, "timestep": 5550, "ep_reward": 871.5160522460938, "reward": 0.30807143449783325, "action": -1.022510051727295}
{"mode": "train", "epochs": 3, "timestep": 5551, "ep_reward": 871.9596557617188, "reward": 0.4436035752296448, "action": -0.9032869935035706}
{"mode": "train", "epochs": 3, "timestep": 5552, "ep_reward": 872.5264282226562, "reward": 0.566752552986145, "action": -1.3991514444351196}
{"mode": "train", "epochs": 3, "timestep": 5553, "ep_reward": 873.1907348632812, "reward": 0.664284348487854, "action": -0.7622247934341431}
{"mode": "train", "epochs": 3, "timestep": 5554, "ep_reward": 873.9367065429688, "reward": 0.7459626197814941, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5555, "ep_reward": 874.7307739257812, "reward": 0.7940528392791748, "action": -0.8933995962142944}
{"mode": "train", "epochs": 3, "timestep": 5556, "ep_reward": 875.5635986328125, "reward": 0.8328069448471069, "action": -0.8418402671813965}
{"mode": "train", "epochs": 3, "timestep": 5557, "ep_reward": 876.416748046875, "reward": 0.8531606197357178, "action": -1.0846713781356812}
{"mode": "train", "epochs": 3, "timestep": 5558, "ep_reward": 877.2702026367188, "reward": 0.8534530401229858, "action": -1.7710906267166138}
{"mode": "train", "epochs": 3, "timestep": 5559, "ep_reward": 878.0985717773438, "reward": 0.8283727765083313, "action": -0.9588798880577087}
{"mode": "train", "epochs": 3, "timestep": 5560, "ep_reward": 878.88623046875, "reward": 0.7876669764518738, "action": -1.3243653774261475}
{"mode": "train", "epochs": 3, "timestep": 5561, "ep_reward": 879.600341796875, "reward": 0.7141132354736328, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5562, "ep_reward": 880.1946411132812, "reward": 0.5942904949188232, "action": -1.3333414793014526}
{"mode": "train", "epochs": 3, "timestep": 5563, "ep_reward": 880.632080078125, "reward": 0.4374377131462097, "action": -0.811396062374115}
{"mode": "train", "epochs": 3, "timestep": 5564, "ep_reward": 880.9706420898438, "reward": 0.3385375142097473, "action": -1.1979647874832153}
{"mode": "train", "epochs": 3, "timestep": 5565, "ep_reward": 881.1969604492188, "reward": 0.2263365387916565, "action": -0.8325223922729492}
{"mode": "train", "epochs": 3, "timestep": 5566, "ep_reward": 881.291015625, "reward": 0.09406596422195435, "action": -1.0366084575653076}
{"mode": "train", "epochs": 3, "timestep": 5567, "ep_reward": 881.3140258789062, "reward": 0.023020386695861816, "action": -0.9490506052970886}
{"mode": "train", "epochs": 3, "timestep": 5568, "ep_reward": 881.4788818359375, "reward": 0.1648271679878235, "action": -1.5922489166259766}
{"mode": "train", "epochs": 3, "timestep": 5569, "ep_reward": 881.7761840820312, "reward": 0.2973024249076843, "action": -1.100845456123352}
{"mode": "train", "epochs": 3, "timestep": 5570, "ep_reward": 882.2097778320312, "reward": 0.4336109161376953, "action": -0.593815803527832}
{"mode": "train", "epochs": 3, "timestep": 5571, "ep_reward": 882.7719116210938, "reward": 0.5621500015258789, "action": -1.0938465595245361}
{"mode": "train", "epochs": 3, "timestep": 5572, "ep_reward": 883.435302734375, "reward": 0.6634142398834229, "action": -1.9847115278244019}
{"mode": "train", "epochs": 3, "timestep": 5573, "ep_reward": 884.1686401367188, "reward": 0.7333482503890991, "action": -1.1679717302322388}
{"mode": "train", "epochs": 3, "timestep": 5574, "ep_reward": 884.9586181640625, "reward": 0.7899860143661499, "action": -0.7209765315055847}
{"mode": "train", "epochs": 3, "timestep": 5575, "ep_reward": 885.7882080078125, "reward": 0.8295905590057373, "action": -0.522409200668335}
{"mode": "train", "epochs": 3, "timestep": 5576, "ep_reward": 886.6395263671875, "reward": 0.8513469696044922, "action": -1.3339519500732422}
{"mode": "train", "epochs": 3, "timestep": 5577, "ep_reward": 887.4871826171875, "reward": 0.8476462960243225, "action": -0.17976754903793335}
{"mode": "train", "epochs": 3, "timestep": 5578, "ep_reward": 888.3223876953125, "reward": 0.8352259397506714, "action": -0.8510457277297974}
{"mode": "train", "epochs": 3, "timestep": 5579, "ep_reward": 889.1170043945312, "reward": 0.7946335077285767, "action": -1.7506258487701416}
{"mode": "train", "epochs": 3, "timestep": 5580, "ep_reward": 889.8331298828125, "reward": 0.7161378860473633, "action": -1.6971275806427002}
{"mode": "train", "epochs": 3, "timestep": 5581, "ep_reward": 890.4332885742188, "reward": 0.6001666784286499, "action": -1.2170870304107666}
{"mode": "train", "epochs": 3, "timestep": 5582, "ep_reward": 890.8795166015625, "reward": 0.44620364904403687, "action": -1.2832454442977905}
{"mode": "train", "epochs": 3, "timestep": 5583, "ep_reward": 891.2166137695312, "reward": 0.33711349964141846, "action": -1.2848734855651855}
{"mode": "train", "epochs": 3, "timestep": 5584, "ep_reward": 891.4412231445312, "reward": 0.22460150718688965, "action": -1.2149766683578491}
{"mode": "train", "epochs": 3, "timestep": 5585, "ep_reward": 891.5332641601562, "reward": 0.09206181764602661, "action": -1.324188232421875}
{"mode": "train", "epochs": 3, "timestep": 5586, "ep_reward": 891.558349609375, "reward": 0.02508401870727539, "action": -1.157331943511963}
{"mode": "train", "epochs": 3, "timestep": 5587, "ep_reward": 891.72509765625, "reward": 0.1667705774307251, "action": -0.6979973316192627}
{"mode": "train", "epochs": 3, "timestep": 5588, "ep_reward": 892.0354614257812, "reward": 0.310366690158844, "action": -1.0383963584899902}
{"mode": "train", "epochs": 3, "timestep": 5589, "ep_reward": 892.4805297851562, "reward": 0.4450806975364685, "action": -0.6540062427520752}
{"mode": "train", "epochs": 3, "timestep": 5590, "ep_reward": 893.0512084960938, "reward": 0.5706664323806763, "action": -0.7064390778541565}
{"mode": "train", "epochs": 3, "timestep": 5591, "ep_reward": 893.725830078125, "reward": 0.6745994687080383, "action": -1.1948856115341187}
{"mode": "train", "epochs": 3, "timestep": 5592, "ep_reward": 894.47705078125, "reward": 0.7511902451515198, "action": -0.0923619270324707}
{"mode": "train", "epochs": 3, "timestep": 5593, "ep_reward": 895.2935180664062, "reward": 0.816485583782196, "action": -0.2693467140197754}
{"mode": "train", "epochs": 3, "timestep": 5594, "ep_reward": 896.1536865234375, "reward": 0.8601452708244324, "action": -0.24391871690750122}
{"mode": "train", "epochs": 3, "timestep": 5595, "ep_reward": 897.0413208007812, "reward": 0.8876387476921082, "action": -0.6688108444213867}
{"mode": "train", "epochs": 3, "timestep": 5596, "ep_reward": 897.9395751953125, "reward": 0.8982829451560974, "action": -1.0102351903915405}
{"mode": "train", "epochs": 3, "timestep": 5597, "ep_reward": 898.8333129882812, "reward": 0.8937400579452515, "action": -0.7273627519607544}
{"mode": "train", "epochs": 3, "timestep": 5598, "ep_reward": 899.7108154296875, "reward": 0.8774892091751099, "action": -0.8913969993591309}
{"mode": "train", "epochs": 3, "timestep": 5599, "ep_reward": 900.5541381835938, "reward": 0.8433228135108948, "action": 0.1583099365234375}
{"mode": "train", "epochs": 3, "timestep": 5600, "ep_reward": 901.3527221679688, "reward": 0.7985597252845764, "action": -0.3746817111968994}
{"mode": "train", "epochs": 3, "timestep": 5601, "ep_reward": 902.0770263671875, "reward": 0.7243080139160156, "action": -0.2519156336784363}
{"mode": "train", "epochs": 3, "timestep": 5602, "ep_reward": 902.6981201171875, "reward": 0.6211186647415161, "action": -1.0142837762832642}
{"mode": "train", "epochs": 3, "timestep": 5603, "ep_reward": 903.170654296875, "reward": 0.4725577235221863, "action": -0.5116931796073914}
{"mode": "train", "epochs": 3, "timestep": 5604, "ep_reward": 903.4733276367188, "reward": 0.30268996953964233, "action": -1.1697297096252441}
{"mode": "train", "epochs": 3, "timestep": 5605, "ep_reward": 903.6569213867188, "reward": 0.18362140655517578, "action": -1.3825085163116455}
{"mode": "train", "epochs": 3, "timestep": 5606, "ep_reward": 903.7015380859375, "reward": 0.04464513063430786, "action": -0.9933984875679016}
{"mode": "train", "epochs": 3, "timestep": 5607, "ep_reward": 903.7750244140625, "reward": 0.073458731174469, "action": -0.563444972038269}
{"mode": "train", "epochs": 3, "timestep": 5608, "ep_reward": 903.991455078125, "reward": 0.21640163660049438, "action": -0.30056124925613403}
{"mode": "train", "epochs": 3, "timestep": 5609, "ep_reward": 904.3550415039062, "reward": 0.3635833263397217, "action": -1.4995867013931274}
{"mode": "train", "epochs": 3, "timestep": 5610, "ep_reward": 904.8428955078125, "reward": 0.48783499002456665, "action": -0.46772193908691406}
{"mode": "train", "epochs": 3, "timestep": 5611, "ep_reward": 905.4518432617188, "reward": 0.6089463233947754, "action": -0.6766163110733032}
{"mode": "train", "epochs": 3, "timestep": 5612, "ep_reward": 906.1574096679688, "reward": 0.7055362462997437, "action": -0.5678905844688416}
{"mode": "train", "epochs": 3, "timestep": 5613, "ep_reward": 906.93798828125, "reward": 0.7805762887001038, "action": -0.09122473001480103}
{"mode": "train", "epochs": 3, "timestep": 5614, "ep_reward": 907.776611328125, "reward": 0.8386062979698181, "action": -1.0712336301803589}
{"mode": "train", "epochs": 3, "timestep": 5615, "ep_reward": 908.647705078125, "reward": 0.8711017966270447, "action": -0.7922458648681641}
{"mode": "train", "epochs": 3, "timestep": 5616, "ep_reward": 909.5392456054688, "reward": 0.8915610313415527, "action": 0.11198067665100098}
{"mode": "train", "epochs": 3, "timestep": 5617, "ep_reward": 910.4449462890625, "reward": 0.9056891202926636, "action": -0.9700833559036255}
{"mode": "train", "epochs": 3, "timestep": 5618, "ep_reward": 911.3449096679688, "reward": 0.8999679088592529, "action": -0.7700566649436951}
{"mode": "train", "epochs": 3, "timestep": 5619, "ep_reward": 912.2274169921875, "reward": 0.8825093507766724, "action": -1.2002724409103394}
{"mode": "train", "epochs": 3, "timestep": 5620, "ep_reward": 913.0724487304688, "reward": 0.8450617790222168, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5621, "ep_reward": 913.849853515625, "reward": 0.7773897647857666, "action": -0.8516588807106018}
{"mode": "train", "epochs": 3, "timestep": 5622, "ep_reward": 914.5408325195312, "reward": 0.6909866333007812, "action": -1.3568787574768066}
{"mode": "train", "epochs": 3, "timestep": 5623, "ep_reward": 915.10302734375, "reward": 0.562213659286499, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5624, "ep_reward": 915.4840087890625, "reward": 0.38099634647369385, "action": -0.6405624151229858}
{"mode": "train", "epochs": 3, "timestep": 5625, "ep_reward": 915.7564697265625, "reward": 0.272452712059021, "action": -1.398375391960144}
{"mode": "train", "epochs": 3, "timestep": 5626, "ep_reward": 915.9044799804688, "reward": 0.1479933261871338, "action": -1.5044991970062256}
{"mode": "train", "epochs": 3, "timestep": 5627, "ep_reward": 915.9078979492188, "reward": 0.003445267677307129, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5628, "ep_reward": 916.019775390625, "reward": 0.11187773942947388, "action": -1.2262685298919678}
{"mode": "train", "epochs": 3, "timestep": 5629, "ep_reward": 916.2673950195312, "reward": 0.24760395288467407, "action": -1.3414499759674072}
{"mode": "train", "epochs": 3, "timestep": 5630, "ep_reward": 916.6499633789062, "reward": 0.3825598955154419, "action": -1.293932557106018}
{"mode": "train", "epochs": 3, "timestep": 5631, "ep_reward": 917.1589965820312, "reward": 0.509058952331543, "action": -1.599241018295288}
{"mode": "train", "epochs": 3, "timestep": 5632, "ep_reward": 917.7738037109375, "reward": 0.6147819757461548, "action": -0.6101336479187012}
{"mode": "train", "epochs": 3, "timestep": 5633, "ep_reward": 918.48291015625, "reward": 0.709103524684906, "action": -1.252530574798584}
{"mode": "train", "epochs": 3, "timestep": 5634, "ep_reward": 919.255615234375, "reward": 0.7726776599884033, "action": -1.3535206317901611}
{"mode": "train", "epochs": 3, "timestep": 5635, "ep_reward": 920.0695190429688, "reward": 0.8138871192932129, "action": -0.019769906997680664}
{"mode": "train", "epochs": 3, "timestep": 5636, "ep_reward": 920.9165649414062, "reward": 0.8470527529716492, "action": -1.6395232677459717}
{"mode": "train", "epochs": 3, "timestep": 5637, "ep_reward": 921.7635498046875, "reward": 0.8470079898834229, "action": -1.082092523574829}
{"mode": "train", "epochs": 3, "timestep": 5638, "ep_reward": 922.5960693359375, "reward": 0.8325181007385254, "action": -1.506504774093628}
{"mode": "train", "epochs": 3, "timestep": 5639, "ep_reward": 923.3871459960938, "reward": 0.7911052703857422, "action": -1.7288929224014282}
{"mode": "train", "epochs": 3, "timestep": 5640, "ep_reward": 924.1049194335938, "reward": 0.7177538275718689, "action": -1.7382982969284058}
{"mode": "train", "epochs": 3, "timestep": 5641, "ep_reward": 924.7109985351562, "reward": 0.606074333190918, "action": -0.6443140506744385}
{"mode": "train", "epochs": 3, "timestep": 5642, "ep_reward": 925.1763916015625, "reward": 0.4654006361961365, "action": -1.067116141319275}
{"mode": "train", "epochs": 3, "timestep": 5643, "ep_reward": 925.53125, "reward": 0.35483402013778687, "action": -0.7710388898849487}
{"mode": "train", "epochs": 3, "timestep": 5644, "ep_reward": 925.7770385742188, "reward": 0.24579113721847534, "action": -0.986656665802002}
{"mode": "train", "epochs": 3, "timestep": 5645, "ep_reward": 925.8936767578125, "reward": 0.11660826206207275, "action": -1.898191213607788}
{"mode": "train", "epochs": 3, "timestep": 5646, "ep_reward": 925.8919677734375, "reward": -0.0017212629318237305, "action": -0.5191632509231567}
{"mode": "train", "epochs": 3, "timestep": 5647, "ep_reward": 926.0352172851562, "reward": 0.14322644472122192, "action": -1.8167067766189575}
{"mode": "train", "epochs": 3, "timestep": 5648, "ep_reward": 926.3076171875, "reward": 0.27242887020111084, "action": -1.1611465215682983}
{"mode": "train", "epochs": 3, "timestep": 5649, "ep_reward": 926.71728515625, "reward": 0.4096664786338806, "action": -1.2041627168655396}
{"mode": "train", "epochs": 3, "timestep": 5650, "ep_reward": 927.2518310546875, "reward": 0.5345486402511597, "action": -0.9510643482208252}
{"mode": "train", "epochs": 3, "timestep": 5651, "ep_reward": 927.8944702148438, "reward": 0.6426540017127991, "action": -0.8716915249824524}
{"mode": "train", "epochs": 3, "timestep": 5652, "ep_reward": 928.6223754882812, "reward": 0.7278943061828613, "action": -0.031313955783843994}
{"mode": "train", "epochs": 3, "timestep": 5653, "ep_reward": 929.4196166992188, "reward": 0.7972506284713745, "action": -1.3603816032409668}
{"mode": "train", "epochs": 3, "timestep": 5654, "ep_reward": 930.2523803710938, "reward": 0.8327829837799072, "action": -1.0732897520065308}
{"mode": "train", "epochs": 3, "timestep": 5655, "ep_reward": 931.1050415039062, "reward": 0.8526387214660645, "action": -1.0740171670913696}
{"mode": "train", "epochs": 3, "timestep": 5656, "ep_reward": 931.9599609375, "reward": 0.8549158573150635, "action": -0.006517171859741211}
{"mode": "train", "epochs": 3, "timestep": 5657, "ep_reward": 932.80859375, "reward": 0.8486526012420654, "action": 0.036519527435302734}
{"mode": "train", "epochs": 3, "timestep": 5658, "ep_reward": 933.6322631835938, "reward": 0.8236960768699646, "action": -0.5348354578018188}
{"mode": "train", "epochs": 3, "timestep": 5659, "ep_reward": 934.40283203125, "reward": 0.7705808281898499, "action": -1.1911084651947021}
{"mode": "train", "epochs": 3, "timestep": 5660, "ep_reward": 935.0836791992188, "reward": 0.6808339357376099, "action": -0.14703094959259033}
{"mode": "train", "epochs": 3, "timestep": 5661, "ep_reward": 935.65185546875, "reward": 0.5681653618812561, "action": -0.8188078999519348}
{"mode": "train", "epochs": 3, "timestep": 5662, "ep_reward": 936.059814453125, "reward": 0.4079824686050415, "action": -0.9702602028846741}
{"mode": "train", "epochs": 3, "timestep": 5663, "ep_reward": 936.3438110351562, "reward": 0.28399384021759033, "action": -0.8611360192298889}
{"mode": "train", "epochs": 3, "timestep": 5664, "ep_reward": 936.5053100585938, "reward": 0.16151881217956543, "action": -1.2829504013061523}
{"mode": "train", "epochs": 3, "timestep": 5665, "ep_reward": 936.5244750976562, "reward": 0.019142568111419678, "action": -0.9889104962348938}
{"mode": "train", "epochs": 3, "timestep": 5666, "ep_reward": 936.6221313476562, "reward": 0.09765487909317017, "action": -1.2153663635253906}
{"mode": "train", "epochs": 3, "timestep": 5667, "ep_reward": 936.8553466796875, "reward": 0.23319792747497559, "action": -0.66518235206604}
{"mode": "train", "epochs": 3, "timestep": 5668, "ep_reward": 937.2323608398438, "reward": 0.3770217299461365, "action": -0.22746706008911133}
{"mode": "train", "epochs": 3, "timestep": 5669, "ep_reward": 937.7479858398438, "reward": 0.5156029462814331, "action": -1.774512529373169}
{"mode": "train", "epochs": 3, "timestep": 5670, "ep_reward": 938.3662109375, "reward": 0.618248462677002, "action": -1.2048908472061157}
{"mode": "train", "epochs": 3, "timestep": 5671, "ep_reward": 939.0734252929688, "reward": 0.7071959972381592, "action": -0.34935230016708374}
{"mode": "train", "epochs": 3, "timestep": 5672, "ep_reward": 939.8553466796875, "reward": 0.7819068431854248, "action": -0.7612693309783936}
{"mode": "train", "epochs": 3, "timestep": 5673, "ep_reward": 940.6865234375, "reward": 0.8311728835105896, "action": -0.6116899251937866}
{"mode": "train", "epochs": 3, "timestep": 5674, "ep_reward": 941.5499877929688, "reward": 0.863456666469574, "action": -0.7855858206748962}
{"mode": "train", "epochs": 3, "timestep": 5675, "ep_reward": 942.4282836914062, "reward": 0.8782858848571777, "action": -1.4849481582641602}
{"mode": "train", "epochs": 3, "timestep": 5676, "ep_reward": 943.3008422851562, "reward": 0.8725611567497253, "action": -0.25745970010757446}
{"mode": "train", "epochs": 3, "timestep": 5677, "ep_reward": 944.1616821289062, "reward": 0.8608250617980957, "action": -0.8879448175430298}
{"mode": "train", "epochs": 3, "timestep": 5678, "ep_reward": 944.9866943359375, "reward": 0.8249920010566711, "action": -1.6663364171981812}
{"mode": "train", "epochs": 3, "timestep": 5679, "ep_reward": 945.74365234375, "reward": 0.7569833993911743, "action": -1.3324161767959595}
{"mode": "train", "epochs": 3, "timestep": 5680, "ep_reward": 946.4031982421875, "reward": 0.6595432758331299, "action": -1.2089158296585083}
{"mode": "train", "epochs": 3, "timestep": 5681, "ep_reward": 946.9273071289062, "reward": 0.524102509021759, "action": -0.5779538154602051}
{"mode": "train", "epochs": 3, "timestep": 5682, "ep_reward": 947.2945556640625, "reward": 0.3672226071357727, "action": -0.6674149632453918}
{"mode": "train", "epochs": 3, "timestep": 5683, "ep_reward": 947.5552368164062, "reward": 0.26070451736450195, "action": -0.9756766557693481}
{"mode": "train", "epochs": 3, "timestep": 5684, "ep_reward": 947.6893920898438, "reward": 0.1341748833656311, "action": -1.2850449085235596}
{"mode": "train", "epochs": 3, "timestep": 5685, "ep_reward": 947.677001953125, "reward": -0.012384533882141113, "action": -1.6273760795593262}
{"mode": "train", "epochs": 3, "timestep": 5686, "ep_reward": 947.8031005859375, "reward": 0.12609624862670898, "action": -1.1563862562179565}
{"mode": "train", "epochs": 3, "timestep": 5687, "ep_reward": 948.0662231445312, "reward": 0.26309674978256226, "action": -1.219993233680725}
{"mode": "train", "epochs": 3, "timestep": 5688, "ep_reward": 948.4649047851562, "reward": 0.3986746668815613, "action": -1.8300710916519165}
{"mode": "train", "epochs": 3, "timestep": 5689, "ep_reward": 948.9819946289062, "reward": 0.5170995593070984, "action": -0.7608509063720703}
{"mode": "train", "epochs": 3, "timestep": 5690, "ep_reward": 949.612548828125, "reward": 0.6305583119392395, "action": -0.5924888849258423}
{"mode": "train", "epochs": 3, "timestep": 5691, "ep_reward": 950.3343505859375, "reward": 0.7217973470687866, "action": -0.5029432773590088}
{"mode": "train", "epochs": 3, "timestep": 5692, "ep_reward": 951.1241455078125, "reward": 0.7897712588310242, "action": -0.5012863874435425}
{"mode": "train", "epochs": 3, "timestep": 5693, "ep_reward": 951.960205078125, "reward": 0.8360635042190552, "action": -1.057883858680725}
{"mode": "train", "epochs": 3, "timestep": 5694, "ep_reward": 952.8193359375, "reward": 0.8591307997703552, "action": -1.1186963319778442}
{"mode": "train", "epochs": 3, "timestep": 5695, "ep_reward": 953.6843872070312, "reward": 0.8650587201118469, "action": -1.4998371601104736}
{"mode": "train", "epochs": 3, "timestep": 5696, "ep_reward": 954.5347900390625, "reward": 0.8503996729850769, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5697, "ep_reward": 955.3450317382812, "reward": 0.81021648645401, "action": -1.8561326265335083}
{"mode": "train", "epochs": 3, "timestep": 5698, "ep_reward": 956.0888061523438, "reward": 0.7437937259674072, "action": -1.0560665130615234}
{"mode": "train", "epochs": 3, "timestep": 5699, "ep_reward": 956.7407836914062, "reward": 0.6519482135772705, "action": -1.012333631515503}
{"mode": "train", "epochs": 3, "timestep": 5700, "ep_reward": 957.26123046875, "reward": 0.5204713344573975, "action": -0.39691925048828125}
{"mode": "train", "epochs": 3, "timestep": 5701, "ep_reward": 957.642333984375, "reward": 0.3811153769493103, "action": -0.3475502133369446}
{"mode": "train", "epochs": 3, "timestep": 5702, "ep_reward": 957.9197998046875, "reward": 0.277454674243927, "action": -1.2175902128219604}
{"mode": "train", "epochs": 3, "timestep": 5703, "ep_reward": 958.07373046875, "reward": 0.15391266345977783, "action": -0.9527696967124939}
{"mode": "train", "epochs": 3, "timestep": 5704, "ep_reward": 958.0840454101562, "reward": 0.01029127836227417, "action": -1.2500492334365845}
{"mode": "train", "epochs": 3, "timestep": 5705, "ep_reward": 958.18994140625, "reward": 0.10588645935058594, "action": -0.26543349027633667}
{"mode": "train", "epochs": 3, "timestep": 5706, "ep_reward": 958.4432983398438, "reward": 0.2533525824546814, "action": -1.3199896812438965}
{"mode": "train", "epochs": 3, "timestep": 5707, "ep_reward": 958.829833984375, "reward": 0.3865354061126709, "action": -0.010188519954681396}
{"mode": "train", "epochs": 3, "timestep": 5708, "ep_reward": 959.3560791015625, "reward": 0.5262628793716431, "action": -0.4647552967071533}
{"mode": "train", "epochs": 3, "timestep": 5709, "ep_reward": 959.996826171875, "reward": 0.6407233476638794, "action": 0.15792953968048096}
{"mode": "train", "epochs": 3, "timestep": 5710, "ep_reward": 960.735107421875, "reward": 0.7383084297180176, "action": -1.2073065042495728}
{"mode": "train", "epochs": 3, "timestep": 5711, "ep_reward": 961.5362548828125, "reward": 0.8011290431022644, "action": -0.36058855056762695}
{"mode": "train", "epochs": 3, "timestep": 5712, "ep_reward": 962.3887939453125, "reward": 0.8525509834289551, "action": -1.6461241245269775}
{"mode": "train", "epochs": 3, "timestep": 5713, "ep_reward": 963.2674560546875, "reward": 0.8786498308181763, "action": -1.0711902379989624}
{"mode": "train", "epochs": 3, "timestep": 5714, "ep_reward": 964.16357421875, "reward": 0.8961260914802551, "action": -0.9737289547920227}
{"mode": "train", "epochs": 3, "timestep": 5715, "ep_reward": 965.0657348632812, "reward": 0.9021628499031067, "action": -0.5472003221511841}
{"mode": "train", "epochs": 3, "timestep": 5716, "ep_reward": 965.9649047851562, "reward": 0.8991649746894836, "action": -0.5560571551322937}
{"mode": "train", "epochs": 3, "timestep": 5717, "ep_reward": 966.847900390625, "reward": 0.8829667568206787, "action": -1.1639865636825562}
{"mode": "train", "epochs": 3, "timestep": 5718, "ep_reward": 967.6936645507812, "reward": 0.8457542657852173, "action": -1.0483360290527344}
{"mode": "train", "epochs": 3, "timestep": 5719, "ep_reward": 968.4815063476562, "reward": 0.7878676652908325, "action": -0.8501605987548828}
{"mode": "train", "epochs": 3, "timestep": 5720, "ep_reward": 969.1857299804688, "reward": 0.7042422294616699, "action": -0.5279596447944641}
{"mode": "train", "epochs": 3, "timestep": 5721, "ep_reward": 969.7767944335938, "reward": 0.5910807847976685, "action": -0.7667945027351379}
{"mode": "train", "epochs": 3, "timestep": 5722, "ep_reward": 970.2144775390625, "reward": 0.43766385316848755, "action": -1.3764697313308716}
{"mode": "train", "epochs": 3, "timestep": 5723, "ep_reward": 970.5007934570312, "reward": 0.28629130125045776, "action": -0.42924392223358154}
{"mode": "train", "epochs": 3, "timestep": 5724, "ep_reward": 970.6650390625, "reward": 0.16423261165618896, "action": -0.8465172052383423}
{"mode": "train", "epochs": 3, "timestep": 5725, "ep_reward": 970.6870727539062, "reward": 0.0220564603805542, "action": -1.7573350667953491}
{"mode": "train", "epochs": 3, "timestep": 5726, "ep_reward": 970.781982421875, "reward": 0.0949169397354126, "action": -0.12201577425003052}
{"mode": "train", "epochs": 3, "timestep": 5727, "ep_reward": 971.02587890625, "reward": 0.24389219284057617, "action": -1.0315476655960083}
{"mode": "train", "epochs": 3, "timestep": 5728, "ep_reward": 971.4063720703125, "reward": 0.380521297454834, "action": -0.8114487528800964}
{"mode": "train", "epochs": 3, "timestep": 5729, "ep_reward": 971.9176635742188, "reward": 0.5112830400466919, "action": -0.680496096611023}
{"mode": "train", "epochs": 3, "timestep": 5730, "ep_reward": 972.5438232421875, "reward": 0.6261705756187439, "action": -0.2780229449272156}
{"mode": "train", "epochs": 3, "timestep": 5731, "ep_reward": 973.2667236328125, "reward": 0.722915530204773, "action": -0.7344841957092285}
{"mode": "train", "epochs": 3, "timestep": 5732, "ep_reward": 974.0592651367188, "reward": 0.7925233840942383, "action": -1.508446216583252}
{"mode": "train", "epochs": 3, "timestep": 5733, "ep_reward": 974.8958129882812, "reward": 0.8365679979324341, "action": -0.9621871709823608}
{"mode": "train", "epochs": 3, "timestep": 5734, "ep_reward": 975.7647094726562, "reward": 0.8689134120941162, "action": -0.8415296673774719}
{"mode": "train", "epochs": 3, "timestep": 5735, "ep_reward": 976.6521606445312, "reward": 0.8874726295471191, "action": -1.2851536273956299}
{"mode": "train", "epochs": 3, "timestep": 5736, "ep_reward": 977.5413818359375, "reward": 0.8892456889152527, "action": -0.7287918329238892}
{"mode": "train", "epochs": 3, "timestep": 5737, "ep_reward": 978.4227294921875, "reward": 0.8813312649726868, "action": -1.1481928825378418}
{"mode": "train", "epochs": 3, "timestep": 5738, "ep_reward": 979.2767333984375, "reward": 0.8540151715278625, "action": -1.4000242948532104}
{"mode": "train", "epochs": 3, "timestep": 5739, "ep_reward": 980.0803833007812, "reward": 0.8036752939224243, "action": -1.583366870880127}
{"mode": "train", "epochs": 3, "timestep": 5740, "ep_reward": 980.8038940429688, "reward": 0.7234847545623779, "action": -1.7181990146636963}
{"mode": "train", "epochs": 3, "timestep": 5741, "ep_reward": 981.4090576171875, "reward": 0.6051582098007202, "action": -0.9140399694442749}
{"mode": "train", "epochs": 3, "timestep": 5742, "ep_reward": 981.8643798828125, "reward": 0.45534276962280273, "action": -1.1905773878097534}
{"mode": "train", "epochs": 3, "timestep": 5743, "ep_reward": 982.1875610351562, "reward": 0.32315701246261597, "action": -0.22630709409713745}
{"mode": "train", "epochs": 3, "timestep": 5744, "ep_reward": 982.3954467773438, "reward": 0.20787733793258667, "action": -0.8397910594940186}
{"mode": "train", "epochs": 3, "timestep": 5745, "ep_reward": 982.4680786132812, "reward": 0.07262647151947021, "action": -0.9277185201644897}
{"mode": "train", "epochs": 3, "timestep": 5746, "ep_reward": 982.5136108398438, "reward": 0.04553347826004028, "action": -0.2531523108482361}
{"mode": "train", "epochs": 3, "timestep": 5747, "ep_reward": 982.7050170898438, "reward": 0.1914328932762146, "action": -0.5301840305328369}
{"mode": "train", "epochs": 3, "timestep": 5748, "ep_reward": 983.0409545898438, "reward": 0.3359193801879883, "action": -0.23950624465942383}
{"mode": "train", "epochs": 3, "timestep": 5749, "ep_reward": 983.517822265625, "reward": 0.47686898708343506, "action": -1.4967297315597534}
{"mode": "train", "epochs": 3, "timestep": 5750, "ep_reward": 984.105712890625, "reward": 0.5879185199737549, "action": -0.9779402017593384}
{"mode": "train", "epochs": 3, "timestep": 5751, "ep_reward": 984.7915649414062, "reward": 0.6858511567115784, "action": -1.1025652885437012}
{"mode": "train", "epochs": 3, "timestep": 5752, "ep_reward": 985.5526123046875, "reward": 0.7610276937484741, "action": -0.36302632093429565}
{"mode": "train", "epochs": 3, "timestep": 5753, "ep_reward": 986.3746337890625, "reward": 0.8220176100730896, "action": -0.7934585809707642}
{"mode": "train", "epochs": 3, "timestep": 5754, "ep_reward": 987.2351684570312, "reward": 0.8605185151100159, "action": -1.3621251583099365}
{"mode": "train", "epochs": 3, "timestep": 5755, "ep_reward": 988.1144409179688, "reward": 0.8792970180511475, "action": -0.879385232925415}
{"mode": "train", "epochs": 3, "timestep": 5756, "ep_reward": 989.0023193359375, "reward": 0.8878688812255859, "action": -0.9626418352127075}
{"mode": "train", "epochs": 3, "timestep": 5757, "ep_reward": 989.8840942382812, "reward": 0.8817957639694214, "action": -0.8326230049133301}
{"mode": "train", "epochs": 3, "timestep": 5758, "ep_reward": 990.745361328125, "reward": 0.8612412214279175, "action": -0.8341227769851685}
{"mode": "train", "epochs": 3, "timestep": 5759, "ep_reward": 991.5672607421875, "reward": 0.8219127655029297, "action": -0.7853905558586121}
{"mode": "train", "epochs": 3, "timestep": 5760, "ep_reward": 992.3263549804688, "reward": 0.7591107487678528, "action": -1.6497057676315308}
{"mode": "train", "epochs": 3, "timestep": 5761, "ep_reward": 992.981689453125, "reward": 0.6553163528442383, "action": -0.7506246566772461}
{"mode": "train", "epochs": 3, "timestep": 5762, "ep_reward": 993.5054931640625, "reward": 0.5237933397293091, "action": -0.8905960917472839}
{"mode": "train", "epochs": 3, "timestep": 5763, "ep_reward": 993.8614501953125, "reward": 0.3559446334838867, "action": -1.166410207748413}
{"mode": "train", "epochs": 3, "timestep": 5764, "ep_reward": 994.108642578125, "reward": 0.24716997146606445, "action": -1.0259538888931274}
{"mode": "train", "epochs": 3, "timestep": 5765, "ep_reward": 994.22705078125, "reward": 0.1184077262878418, "action": -0.7106195092201233}
{"mode": "train", "epochs": 3, "timestep": 5766, "ep_reward": 994.2235107421875, "reward": -0.00353395938873291, "action": -0.862054705619812}
{"mode": "train", "epochs": 3, "timestep": 5767, "ep_reward": 994.3654174804688, "reward": 0.14188939332962036, "action": 0.06883871555328369}
{"mode": "train", "epochs": 3, "timestep": 5768, "ep_reward": 994.6598510742188, "reward": 0.2944498062133789, "action": -0.5981172919273376}
{"mode": "train", "epochs": 3, "timestep": 5769, "ep_reward": 995.093505859375, "reward": 0.4336574673652649, "action": -1.074941635131836}
{"mode": "train", "epochs": 3, "timestep": 5770, "ep_reward": 995.6483154296875, "reward": 0.5548150539398193, "action": -1.5285863876342773}
{"mode": "train", "epochs": 3, "timestep": 5771, "ep_reward": 996.3018188476562, "reward": 0.6534967422485352, "action": 0.12742090225219727}
{"mode": "train", "epochs": 3, "timestep": 5772, "ep_reward": 997.0492553710938, "reward": 0.7474110126495361, "action": -1.8399252891540527}
{"mode": "train", "epochs": 3, "timestep": 5773, "ep_reward": 997.8504028320312, "reward": 0.8011724352836609, "action": -0.7956411838531494}
{"mode": "train", "epochs": 3, "timestep": 5774, "ep_reward": 998.6964721679688, "reward": 0.8460870981216431, "action": -0.8719210624694824}
{"mode": "train", "epochs": 3, "timestep": 5775, "ep_reward": 999.5701904296875, "reward": 0.8737109899520874, "action": -1.1784405708312988}
{"mode": "train", "epochs": 3, "timestep": 5776, "ep_reward": 1000.45458984375, "reward": 0.8844096064567566, "action": -1.1523634195327759}
{"mode": "train", "epochs": 3, "timestep": 5777, "ep_reward": 1001.3358154296875, "reward": 0.8812016248703003, "action": -0.8853331208229065}
{"mode": "train", "epochs": 3, "timestep": 5778, "ep_reward": 1002.2005615234375, "reward": 0.8647381067276001, "action": -0.7566776871681213}
{"mode": "train", "epochs": 3, "timestep": 5779, "ep_reward": 1003.0317993164062, "reward": 0.8312144875526428, "action": -1.2380858659744263}
{"mode": "train", "epochs": 3, "timestep": 5780, "ep_reward": 1003.8016357421875, "reward": 0.7698097229003906, "action": -1.8155531883239746}
{"mode": "train", "epochs": 3, "timestep": 5781, "ep_reward": 1004.471923828125, "reward": 0.670287013053894, "action": -1.9446288347244263}
{"mode": "train", "epochs": 3, "timestep": 5782, "ep_reward": 1004.9993896484375, "reward": 0.5274616479873657, "action": -1.8951895236968994}
{"mode": "train", "epochs": 3, "timestep": 5783, "ep_reward": 1005.371826171875, "reward": 0.37243974208831787, "action": -1.875531554222107}
{"mode": "train", "epochs": 3, "timestep": 5784, "ep_reward": 1005.6390380859375, "reward": 0.2671966552734375, "action": -1.235502004623413}
{"mode": "train", "epochs": 3, "timestep": 5785, "ep_reward": 1005.7808837890625, "reward": 0.14186644554138184, "action": -0.9439209699630737}
{"mode": "train", "epochs": 3, "timestep": 5786, "ep_reward": 1005.7774047851562, "reward": -0.0034513473510742188, "action": -0.13279199600219727}
{"mode": "train", "epochs": 3, "timestep": 5787, "ep_reward": 1005.8956909179688, "reward": 0.11826038360595703, "action": -1.5267335176467896}
{"mode": "train", "epochs": 3, "timestep": 5788, "ep_reward": 1006.1460571289062, "reward": 0.2503957152366638, "action": -1.416504144668579}
{"mode": "train", "epochs": 3, "timestep": 5789, "ep_reward": 1006.5309448242188, "reward": 0.3849148154258728, "action": -1.298426866531372}
{"mode": "train", "epochs": 3, "timestep": 5790, "ep_reward": 1007.0423583984375, "reward": 0.5114348530769348, "action": -1.7107880115509033}
{"mode": "train", "epochs": 3, "timestep": 5791, "ep_reward": 1007.6576538085938, "reward": 0.6152897477149963, "action": -1.6847383975982666}
{"mode": "train", "epochs": 3, "timestep": 5792, "ep_reward": 1008.3555297851562, "reward": 0.6978528499603271, "action": -0.2078925371170044}
{"mode": "train", "epochs": 3, "timestep": 5793, "ep_reward": 1009.127197265625, "reward": 0.7716816067695618, "action": -1.4274104833602905}
{"mode": "train", "epochs": 3, "timestep": 5794, "ep_reward": 1009.9371337890625, "reward": 0.8099457621574402, "action": -0.8589765429496765}
{"mode": "train", "epochs": 3, "timestep": 5795, "ep_reward": 1010.7699584960938, "reward": 0.8328226804733276, "action": -1.3195137977600098}
{"mode": "train", "epochs": 3, "timestep": 5796, "ep_reward": 1011.6010131835938, "reward": 0.831039309501648, "action": -1.6157209873199463}
{"mode": "train", "epochs": 3, "timestep": 5797, "ep_reward": 1012.4053344726562, "reward": 0.8043288588523865, "action": -1.0870212316513062}
{"mode": "train", "epochs": 3, "timestep": 5798, "ep_reward": 1013.1619262695312, "reward": 0.7565920352935791, "action": 0.38908934593200684}
{"mode": "train", "epochs": 3, "timestep": 5799, "ep_reward": 1013.857421875, "reward": 0.6955018043518066, "action": -1.073442816734314}
{"mode": "train", "epochs": 3, "timestep": 5800, "ep_reward": 1014.4384155273438, "reward": 0.5809879302978516, "action": -1.2982521057128906}
{"mode": "train", "epochs": 3, "timestep": 5801, "ep_reward": 1014.8577880859375, "reward": 0.41936320066452026, "action": -1.0859664678573608}
{"mode": "train", "epochs": 3, "timestep": 5802, "ep_reward": 1015.18017578125, "reward": 0.3224111795425415, "action": -1.5836331844329834}
{"mode": "train", "epochs": 3, "timestep": 5803, "ep_reward": 1015.3871459960938, "reward": 0.20696663856506348, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5804, "ep_reward": 1015.4588623046875, "reward": 0.07172417640686035, "action": -1.4901363849639893}
{"mode": "train", "epochs": 3, "timestep": 5805, "ep_reward": 1015.5051879882812, "reward": 0.04635041952133179, "action": -0.6263493299484253}
{"mode": "train", "epochs": 3, "timestep": 5806, "ep_reward": 1015.6926879882812, "reward": 0.18749243021011353, "action": -1.5849950313568115}
{"mode": "train", "epochs": 3, "timestep": 5807, "ep_reward": 1016.0126342773438, "reward": 0.31993401050567627, "action": -0.9942162036895752}
{"mode": "train", "epochs": 3, "timestep": 5808, "ep_reward": 1016.4683837890625, "reward": 0.4557643532752991, "action": -0.8036968111991882}
{"mode": "train", "epochs": 3, "timestep": 5809, "ep_reward": 1017.0470581054688, "reward": 0.5786747932434082, "action": -0.8965178728103638}
{"mode": "train", "epochs": 3, "timestep": 5810, "ep_reward": 1017.7258911132812, "reward": 0.678810715675354, "action": -1.2107385396957397}
{"mode": "train", "epochs": 3, "timestep": 5811, "ep_reward": 1018.4785766601562, "reward": 0.7526805400848389, "action": -1.2139215469360352}
{"mode": "train", "epochs": 3, "timestep": 5812, "ep_reward": 1019.2835693359375, "reward": 0.8049752712249756, "action": -0.898446798324585}
{"mode": "train", "epochs": 3, "timestep": 5813, "ep_reward": 1020.1238403320312, "reward": 0.8402623534202576, "action": -1.2705307006835938}
{"mode": "train", "epochs": 3, "timestep": 5814, "ep_reward": 1020.97802734375, "reward": 0.8542001843452454, "action": -0.8344953656196594}
{"mode": "train", "epochs": 3, "timestep": 5815, "ep_reward": 1021.8323974609375, "reward": 0.8543608784675598, "action": -0.19950640201568604}
{"mode": "train", "epochs": 3, "timestep": 5816, "ep_reward": 1022.6742553710938, "reward": 0.8418339490890503, "action": -0.45055222511291504}
{"mode": "train", "epochs": 3, "timestep": 5817, "ep_reward": 1023.4808349609375, "reward": 0.8065657615661621, "action": -0.29446059465408325}
{"mode": "train", "epochs": 3, "timestep": 5818, "ep_reward": 1024.2291259765625, "reward": 0.7483150959014893, "action": -0.4859089255332947}
{"mode": "train", "epochs": 3, "timestep": 5819, "ep_reward": 1024.8868408203125, "reward": 0.6577510833740234, "action": -1.2926734685897827}
{"mode": "train", "epochs": 3, "timestep": 5820, "ep_reward": 1025.40625, "reward": 0.5193849802017212, "action": -0.8100516200065613}
{"mode": "train", "epochs": 3, "timestep": 5821, "ep_reward": 1025.765380859375, "reward": 0.35913997888565063, "action": -1.2122551202774048}
{"mode": "train", "epochs": 3, "timestep": 5822, "ep_reward": 1026.0164794921875, "reward": 0.2510764002799988, "action": -0.4365040063858032}
{"mode": "train", "epochs": 3, "timestep": 5823, "ep_reward": 1026.139404296875, "reward": 0.12288093566894531, "action": -0.9920660257339478}
{"mode": "train", "epochs": 3, "timestep": 5824, "ep_reward": 1026.130859375, "reward": -0.008562207221984863, "action": -0.4247151017189026}
{"mode": "train", "epochs": 3, "timestep": 5825, "ep_reward": 1026.268310546875, "reward": 0.1374465823173523, "action": -0.695683479309082}
{"mode": "train", "epochs": 3, "timestep": 5826, "ep_reward": 1026.548828125, "reward": 0.28047454357147217, "action": -0.9726858139038086}
{"mode": "train", "epochs": 3, "timestep": 5827, "ep_reward": 1026.9664306640625, "reward": 0.4175529479980469, "action": -0.18786925077438354}
{"mode": "train", "epochs": 3, "timestep": 5828, "ep_reward": 1027.5181884765625, "reward": 0.5517263412475586, "action": -0.9654583930969238}
{"mode": "train", "epochs": 3, "timestep": 5829, "ep_reward": 1028.1746826171875, "reward": 0.656497597694397, "action": -1.7945983409881592}
{"mode": "train", "epochs": 3, "timestep": 5830, "ep_reward": 1028.9066162109375, "reward": 0.7318727374076843, "action": -1.7839438915252686}
{"mode": "train", "epochs": 3, "timestep": 5831, "ep_reward": 1029.6942138671875, "reward": 0.7875864505767822, "action": -1.540869116783142}
{"mode": "train", "epochs": 3, "timestep": 5832, "ep_reward": 1030.5205078125, "reward": 0.8263406753540039, "action": -1.892620325088501}
{"mode": "train", "epochs": 3, "timestep": 5833, "ep_reward": 1031.364501953125, "reward": 0.8440496325492859, "action": -1.3565824031829834}
{"mode": "train", "epochs": 3, "timestep": 5834, "ep_reward": 1032.213134765625, "reward": 0.8486611247062683, "action": -0.20610761642456055}
{"mode": "train", "epochs": 3, "timestep": 5835, "ep_reward": 1033.05810546875, "reward": 0.8449256420135498, "action": -1.1283289194107056}
{"mode": "train", "epochs": 3, "timestep": 5836, "ep_reward": 1033.8701171875, "reward": 0.8120051026344299, "action": -1.8694205284118652}
{"mode": "train", "epochs": 3, "timestep": 5837, "ep_reward": 1034.615234375, "reward": 0.7450894117355347, "action": -0.9993568658828735}
{"mode": "train", "epochs": 3, "timestep": 5838, "ep_reward": 1035.2689208984375, "reward": 0.6537243127822876, "action": -1.175298810005188}
{"mode": "train", "epochs": 3, "timestep": 5839, "ep_reward": 1035.788818359375, "reward": 0.5199052095413208, "action": -0.6101826429367065}
{"mode": "train", "epochs": 3, "timestep": 5840, "ep_reward": 1036.16845703125, "reward": 0.37961339950561523, "action": -1.6943020820617676}
{"mode": "train", "epochs": 3, "timestep": 5841, "ep_reward": 1036.4443359375, "reward": 0.27584773302078247, "action": -1.1707592010498047}
{"mode": "train", "epochs": 3, "timestep": 5842, "ep_reward": 1036.5963134765625, "reward": 0.15196269750595093, "action": -1.3191641569137573}
{"mode": "train", "epochs": 3, "timestep": 5843, "ep_reward": 1036.6044921875, "reward": 0.008162140846252441, "action": -0.8493055701255798}
{"mode": "train", "epochs": 3, "timestep": 5844, "ep_reward": 1036.7122802734375, "reward": 0.1078333854675293, "action": -0.9033480882644653}
{"mode": "train", "epochs": 3, "timestep": 5845, "ep_reward": 1036.959716796875, "reward": 0.24747604131698608, "action": -1.249624490737915}
{"mode": "train", "epochs": 3, "timestep": 5846, "ep_reward": 1037.3426513671875, "reward": 0.382956862449646, "action": -0.9682303667068481}
{"mode": "train", "epochs": 3, "timestep": 5847, "ep_reward": 1037.85546875, "reward": 0.5127567648887634, "action": -1.5667271614074707}
{"mode": "train", "epochs": 3, "timestep": 5848, "ep_reward": 1038.4735107421875, "reward": 0.6180959939956665, "action": -1.6339242458343506}
{"mode": "train", "epochs": 3, "timestep": 5849, "ep_reward": 1039.1754150390625, "reward": 0.7019407153129578, "action": -1.483203649520874}
{"mode": "train", "epochs": 3, "timestep": 5850, "ep_reward": 1039.940673828125, "reward": 0.7652943730354309, "action": -0.7485876083374023}
{"mode": "train", "epochs": 3, "timestep": 5851, "ep_reward": 1040.7545166015625, "reward": 0.8138902187347412, "action": -0.44837433099746704}
{"mode": "train", "epochs": 3, "timestep": 5852, "ep_reward": 1041.59912109375, "reward": 0.8445473909378052, "action": -1.212875247001648}
{"mode": "train", "epochs": 3, "timestep": 5853, "ep_reward": 1042.4488525390625, "reward": 0.849747896194458, "action": -0.2580345869064331}
{"mode": "train", "epochs": 3, "timestep": 5854, "ep_reward": 1043.293701171875, "reward": 0.8448463678359985, "action": -1.3667240142822266}
{"mode": "train", "epochs": 3, "timestep": 5855, "ep_reward": 1044.1025390625, "reward": 0.8087906837463379, "action": -1.9696353673934937}
{"mode": "train", "epochs": 3, "timestep": 5856, "ep_reward": 1044.841796875, "reward": 0.7392747402191162, "action": -1.0974622964859009}
{"mode": "train", "epochs": 3, "timestep": 5857, "ep_reward": 1045.486328125, "reward": 0.6445528268814087, "action": -0.1114039421081543}
{"mode": "train", "epochs": 3, "timestep": 5858, "ep_reward": 1046.01025390625, "reward": 0.5239050388336182, "action": -0.3747425079345703}
{"mode": "train", "epochs": 3, "timestep": 5859, "ep_reward": 1046.38671875, "reward": 0.3764328956604004, "action": -1.0120842456817627}
{"mode": "train", "epochs": 3, "timestep": 5860, "ep_reward": 1046.6585693359375, "reward": 0.2719106078147888, "action": -0.6587189435958862}
{"mode": "train", "epochs": 3, "timestep": 5861, "ep_reward": 1046.8057861328125, "reward": 0.14727163314819336, "action": -1.2927777767181396}
{"mode": "train", "epochs": 3, "timestep": 5862, "ep_reward": 1046.8084716796875, "reward": 0.002739548683166504, "action": -1.076777696609497}
{"mode": "train", "epochs": 3, "timestep": 5863, "ep_reward": 1046.921142578125, "reward": 0.11269545555114746, "action": -1.1684459447860718}
{"mode": "train", "epochs": 3, "timestep": 5864, "ep_reward": 1047.1702880859375, "reward": 0.2491358518600464, "action": -1.547871470451355}
{"mode": "train", "epochs": 3, "timestep": 5865, "ep_reward": 1047.5517578125, "reward": 0.3814540505409241, "action": -0.8314110636711121}
{"mode": "train", "epochs": 3, "timestep": 5866, "ep_reward": 1048.0655517578125, "reward": 0.513739824295044, "action": -0.722657322883606}
{"mode": "train", "epochs": 3, "timestep": 5867, "ep_reward": 1048.6937255859375, "reward": 0.6281406879425049, "action": -1.1199651956558228}
{"mode": "train", "epochs": 3, "timestep": 5868, "ep_reward": 1049.408935546875, "reward": 0.7152311205863953, "action": -1.2082338333129883}
{"mode": "train", "epochs": 3, "timestep": 5869, "ep_reward": 1050.1878662109375, "reward": 0.7789665460586548, "action": -1.1305450201034546}
{"mode": "train", "epochs": 3, "timestep": 5870, "ep_reward": 1051.010498046875, "reward": 0.8226058483123779, "action": -0.7432599067687988}
{"mode": "train", "epochs": 3, "timestep": 5871, "ep_reward": 1051.8609619140625, "reward": 0.8505085110664368, "action": -1.4795578718185425}
{"mode": "train", "epochs": 3, "timestep": 5872, "ep_reward": 1052.7152099609375, "reward": 0.854214072227478, "action": -1.7161962985992432}
{"mode": "train", "epochs": 3, "timestep": 5873, "ep_reward": 1053.552490234375, "reward": 0.8372982740402222, "action": -0.8634048700332642}
{"mode": "train", "epochs": 3, "timestep": 5874, "ep_reward": 1054.359130859375, "reward": 0.806672215461731, "action": -1.2383288145065308}
{"mode": "train", "epochs": 3, "timestep": 5875, "ep_reward": 1055.105224609375, "reward": 0.7460678815841675, "action": -0.6125019192695618}
{"mode": "train", "epochs": 3, "timestep": 5876, "ep_reward": 1055.7652587890625, "reward": 0.6600472927093506, "action": -0.8105238676071167}
{"mode": "train", "epochs": 3, "timestep": 5877, "ep_reward": 1056.298583984375, "reward": 0.5333300828933716, "action": -1.1286609172821045}
{"mode": "train", "epochs": 3, "timestep": 5878, "ep_reward": 1056.6805419921875, "reward": 0.38201022148132324, "action": -1.447045087814331}
{"mode": "train", "epochs": 3, "timestep": 5879, "ep_reward": 1056.9593505859375, "reward": 0.2787661552429199, "action": -0.5263686776161194}
{"mode": "train", "epochs": 3, "timestep": 5880, "ep_reward": 1057.11474609375, "reward": 0.15540766716003418, "action": -0.5019475221633911}
{"mode": "train", "epochs": 3, "timestep": 5881, "ep_reward": 1057.126708984375, "reward": 0.012011945247650146, "action": -0.8850423693656921}
{"mode": "train", "epochs": 3, "timestep": 5882, "ep_reward": 1057.23095703125, "reward": 0.10428094863891602, "action": -1.1107370853424072}
{"mode": "train", "epochs": 3, "timestep": 5883, "ep_reward": 1057.4722900390625, "reward": 0.24131309986114502, "action": -0.8141807317733765}
{"mode": "train", "epochs": 3, "timestep": 5884, "ep_reward": 1057.85498046875, "reward": 0.38272935152053833, "action": -1.136781930923462}
{"mode": "train", "epochs": 3, "timestep": 5885, "ep_reward": 1058.3653564453125, "reward": 0.5103710889816284, "action": -1.5819118022918701}
{"mode": "train", "epochs": 3, "timestep": 5886, "ep_reward": 1058.9813232421875, "reward": 0.616011381149292, "action": -1.2209162712097168}
{"mode": "train", "epochs": 3, "timestep": 5887, "ep_reward": 1059.68603515625, "reward": 0.7046568393707275, "action": -0.823293924331665}
{"mode": "train", "epochs": 3, "timestep": 5888, "ep_reward": 1060.4603271484375, "reward": 0.7743425965309143, "action": -0.8899955749511719}
{"mode": "train", "epochs": 3, "timestep": 5889, "ep_reward": 1061.281982421875, "reward": 0.8215951919555664, "action": 0.02424323558807373}
{"mode": "train", "epochs": 3, "timestep": 5890, "ep_reward": 1062.1392822265625, "reward": 0.8573204278945923, "action": -0.8407679200172424}
{"mode": "train", "epochs": 3, "timestep": 5891, "ep_reward": 1063.00732421875, "reward": 0.8680450320243835, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5892, "ep_reward": 1063.859619140625, "reward": 0.8523221611976624, "action": -0.5436775088310242}
{"mode": "train", "epochs": 3, "timestep": 5893, "ep_reward": 1064.689697265625, "reward": 0.8301122784614563, "action": -1.1301593780517578}
{"mode": "train", "epochs": 3, "timestep": 5894, "ep_reward": 1065.468994140625, "reward": 0.7792471647262573, "action": -1.9393566846847534}
{"mode": "train", "epochs": 3, "timestep": 5895, "ep_reward": 1066.1578369140625, "reward": 0.6888742446899414, "action": -0.7644792795181274}
{"mode": "train", "epochs": 3, "timestep": 5896, "ep_reward": 1066.73193359375, "reward": 0.5741158723831177, "action": -0.8114900588989258}
{"mode": "train", "epochs": 3, "timestep": 5897, "ep_reward": 1067.149169921875, "reward": 0.41723668575286865, "action": -0.8234216570854187}
{"mode": "train", "epochs": 3, "timestep": 5898, "ep_reward": 1067.4578857421875, "reward": 0.30876487493515015, "action": -1.1294662952423096}
{"mode": "train", "epochs": 3, "timestep": 5899, "ep_reward": 1067.648681640625, "reward": 0.1908097267150879, "action": -1.3231151103973389}
{"mode": "train", "epochs": 3, "timestep": 5900, "ep_reward": 1067.70166015625, "reward": 0.05297750234603882, "action": -0.4689406752586365}
{"mode": "train", "epochs": 3, "timestep": 5901, "ep_reward": 1067.7669677734375, "reward": 0.06533598899841309, "action": -0.6361843943595886}
{"mode": "train", "epochs": 3, "timestep": 5902, "ep_reward": 1067.97412109375, "reward": 0.2071332335472107, "action": 0.0541614294052124}
{"mode": "train", "epochs": 3, "timestep": 5903, "ep_reward": 1068.333251953125, "reward": 0.35917627811431885, "action": -0.4474219083786011}
{"mode": "train", "epochs": 3, "timestep": 5904, "ep_reward": 1068.8284912109375, "reward": 0.4952743649482727, "action": -1.6014070510864258}
{"mode": "train", "epochs": 3, "timestep": 5905, "ep_reward": 1069.4310302734375, "reward": 0.6025940179824829, "action": -0.6102871894836426}
{"mode": "train", "epochs": 3, "timestep": 5906, "ep_reward": 1070.132080078125, "reward": 0.7011080384254456, "action": -1.4143238067626953}
{"mode": "train", "epochs": 3, "timestep": 5907, "ep_reward": 1070.9022216796875, "reward": 0.7700847387313843, "action": -0.7148187160491943}
{"mode": "train", "epochs": 3, "timestep": 5908, "ep_reward": 1071.7279052734375, "reward": 0.8256310224533081, "action": -0.7858206033706665}
{"mode": "train", "epochs": 3, "timestep": 5909, "ep_reward": 1072.59033203125, "reward": 0.862393856048584, "action": -1.4557881355285645}
{"mode": "train", "epochs": 3, "timestep": 5910, "ep_reward": 1073.468994140625, "reward": 0.8786331415176392, "action": -1.3905953168869019}
{"mode": "train", "epochs": 3, "timestep": 5911, "ep_reward": 1074.3502197265625, "reward": 0.8812751173973083, "action": -0.9224538803100586}
{"mode": "train", "epochs": 3, "timestep": 5912, "ep_reward": 1075.2227783203125, "reward": 0.8725988864898682, "action": -1.7248823642730713}
{"mode": "train", "epochs": 3, "timestep": 5913, "ep_reward": 1076.0625, "reward": 0.8397794961929321, "action": -0.49537402391433716}
{"mode": "train", "epochs": 3, "timestep": 5914, "ep_reward": 1076.85888671875, "reward": 0.7963842749595642, "action": -0.751895010471344}
{"mode": "train", "epochs": 3, "timestep": 5915, "ep_reward": 1077.5828857421875, "reward": 0.7240515351295471, "action": -1.1743710041046143}
{"mode": "train", "epochs": 3, "timestep": 5916, "ep_reward": 1078.1956787109375, "reward": 0.6128116250038147, "action": -1.9678335189819336}
{"mode": "train", "epochs": 3, "timestep": 5917, "ep_reward": 1078.6441650390625, "reward": 0.44852256774902344, "action": -0.6709238886833191}
{"mode": "train", "epochs": 3, "timestep": 5918, "ep_reward": 1078.9661865234375, "reward": 0.32206428050994873, "action": -1.086357831954956}
{"mode": "train", "epochs": 3, "timestep": 5919, "ep_reward": 1079.1728515625, "reward": 0.20669782161712646, "action": -0.34239786863327026}
{"mode": "train", "epochs": 3, "timestep": 5920, "ep_reward": 1079.2440185546875, "reward": 0.07121777534484863, "action": -0.913171112537384}
{"mode": "train", "epochs": 3, "timestep": 5921, "ep_reward": 1079.290771484375, "reward": 0.04673182964324951, "action": -2.0}
{"mode": "train", "epochs": 3, "timestep": 5922, "ep_reward": 1079.4764404296875, "reward": 0.18571597337722778, "action": -0.25718235969543457}
{"mode": "train", "epochs": 3, "timestep": 5923, "ep_reward": 1079.8115234375, "reward": 0.3350377678871155, "action": -0.7446218729019165}
{"mode": "train", "epochs": 3, "timestep": 5924, "ep_reward": 1080.2822265625, "reward": 0.4707408547401428, "action": -1.59833824634552}
{"mode": "train", "epochs": 3, "timestep": 5925, "ep_reward": 1080.8642578125, "reward": 0.5820279121398926, "action": -0.7032772898674011}
{"mode": "train", "epochs": 3, "timestep": 5926, "ep_reward": 1081.5479736328125, "reward": 0.6837664246559143, "action": -0.054581403732299805}
{"mode": "train", "epochs": 3, "timestep": 5927, "ep_reward": 1082.3160400390625, "reward": 0.7681061029434204, "action": -1.791154146194458}
{"mode": "train", "epochs": 3, "timestep": 5928, "ep_reward": 1083.131103515625, "reward": 0.8150146007537842, "action": -1.7718350887298584}
{"mode": "train", "epochs": 3, "timestep": 5929, "ep_reward": 1083.9759521484375, "reward": 0.8449082970619202, "action": -1.0745371580123901}
{"mode": "train", "epochs": 3, "timestep": 5930, "ep_reward": 1084.8402099609375, "reward": 0.8642005324363708, "action": -0.5566746592521667}
{"mode": "train", "epochs": 3, "timestep": 5931, "ep_reward": 1085.7119140625, "reward": 0.871688723564148, "action": -0.4821922779083252}
{"mode": "train", "epochs": 3, "timestep": 5932, "ep_reward": 1086.5755615234375, "reward": 0.8636000752449036, "action": -0.9811088442802429}
{"mode": "train", "epochs": 3, "timestep": 5933, "ep_reward": 1087.40869140625, "reward": 0.8331365585327148, "action": -0.21644562482833862}
{"mode": "train", "epochs": 3, "timestep": 5934, "ep_reward": 1088.1966552734375, "reward": 0.7879851460456848, "action": -1.3388233184814453}
{"mode": "train", "epochs": 3, "timestep": 5935, "ep_reward": 1088.900146484375, "reward": 0.7035030722618103, "action": -1.0576542615890503}
{"mode": "train", "epochs": 3, "timestep": 5936, "ep_reward": 1089.4862060546875, "reward": 0.5860963463783264, "action": -0.3198903203010559}
{"mode": "train", "epochs": 3, "timestep": 5937, "ep_reward": 1089.925537109375, "reward": 0.4393605589866638, "action": -1.2264938354492188}
{"mode": "train", "epochs": 3, "timestep": 5938, "ep_reward": 1090.2294921875, "reward": 0.3039820194244385, "action": -1.2078540325164795}
{"mode": "train", "epochs": 3, "timestep": 5939, "ep_reward": 1090.414794921875, "reward": 0.18524664640426636, "action": -0.5716183185577393}
{"mode": "train", "epochs": 3, "timestep": 5940, "ep_reward": 1090.461181640625, "reward": 0.04644465446472168, "action": 0.47038424015045166}
{"mode": "train", "epochs": 3, "timestep": 5941, "ep_reward": 1090.532958984375, "reward": 0.07173442840576172, "action": -0.8660245537757874}
{"mode": "train", "epochs": 3, "timestep": 5942, "ep_reward": 1090.74365234375, "reward": 0.2107146978378296, "action": -1.526102066040039}
{"mode": "train", "epochs": 3, "timestep": 5943, "ep_reward": 1091.087646484375, "reward": 0.34393346309661865, "action": -0.2541239857673645}
{"mode": "train", "epochs": 3, "timestep": 5944, "ep_reward": 1091.57421875, "reward": 0.48656171560287476, "action": -0.19373935461044312}
{"mode": "train", "epochs": 3, "timestep": 5945, "ep_reward": 1092.1851806640625, "reward": 0.6109832525253296, "action": -1.0314102172851562}
{"mode": "train", "epochs": 3, "timestep": 5946, "ep_reward": 1092.8887939453125, "reward": 0.7035965919494629, "action": -1.0100338459014893}
{"mode": "train", "epochs": 3, "timestep": 5947, "ep_reward": 1093.6634521484375, "reward": 0.7746533155441284, "action": -0.42440664768218994}
{"mode": "train", "epochs": 3, "timestep": 5948, "ep_reward": 1094.49365234375, "reward": 0.8302464485168457, "action": -0.6158326864242554}
{"mode": "train", "epochs": 3, "timestep": 5949, "ep_reward": 1095.3594970703125, "reward": 0.8658183217048645, "action": -0.09129142761230469}
{"mode": "train", "epochs": 3, "timestep": 5950, "ep_reward": 1096.2493896484375, "reward": 0.8899146318435669, "action": -0.5136986970901489}
{"mode": "train", "epochs": 3, "timestep": 5951, "ep_reward": 1097.1466064453125, "reward": 0.8971992135047913, "action": -0.30731910467147827}
{"mode": "train", "epochs": 3, "timestep": 5952, "ep_reward": 1098.0396728515625, "reward": 0.893049955368042, "action": -1.3942605257034302}
{"mode": "train", "epochs": 3, "timestep": 5953, "ep_reward": 1098.90576171875, "reward": 0.8660721778869629, "action": -0.8106709718704224}
{"mode": "train", "epochs": 3, "timestep": 5954, "ep_reward": 1099.73095703125, "reward": 0.825193464756012, "action": -1.61697518825531}
{"mode": "train", "epochs": 3, "timestep": 5955, "ep_reward": 1100.4830322265625, "reward": 0.7521128058433533, "action": -0.8756574988365173}
{"mode": "train", "epochs": 3, "timestep": 5956, "ep_reward": 1101.1378173828125, "reward": 0.6547942161560059, "action": -0.745450496673584}
{"mode": "train", "epochs": 3, "timestep": 5957, "ep_reward": 1101.66015625, "reward": 0.5222880840301514, "action": -0.9210139513015747}
{"mode": "train", "epochs": 3, "timestep": 5958, "ep_reward": 1102.009033203125, "reward": 0.3489082455635071, "action": -0.8783965110778809}
{"mode": "train", "epochs": 3, "timestep": 5959, "ep_reward": 1102.247802734375, "reward": 0.23873478174209595, "action": -0.3077482581138611}
{"mode": "train", "epochs": 3, "timestep": 5960, "ep_reward": 1102.356201171875, "reward": 0.1083526611328125, "action": -1.648038387298584}
{"mode": "train", "epochs": 3, "timestep": 5961, "ep_reward": 1102.3636474609375, "reward": 0.007404446601867676, "action": -1.2813456058502197}
{"mode": "train", "epochs": 3, "timestep": 5962, "ep_reward": 1102.51513671875, "reward": 0.15144312381744385, "action": -0.5539434552192688}
{"mode": "train", "epochs": 3, "timestep": 5963, "ep_reward": 1102.8115234375, "reward": 0.2964167594909668, "action": -1.608964443206787}
{"mode": "train", "epochs": 3, "timestep": 5964, "ep_reward": 1103.2362060546875, "reward": 0.42472773790359497, "action": -1.5636756420135498}
{"mode": "train", "epochs": 3, "timestep": 5965, "ep_reward": 1103.7791748046875, "reward": 0.5430268049240112, "action": -0.6898770332336426}
{"mode": "train", "epochs": 3, "timestep": 5966, "ep_reward": 1104.431640625, "reward": 0.6524178385734558, "action": -0.6970045566558838}
{"mode": "train", "epochs": 3, "timestep": 5967, "ep_reward": 1105.16943359375, "reward": 0.7377957105636597, "action": -0.9535408616065979}
{"mode": "train", "epochs": 3, "timestep": 5968, "ep_reward": 1105.9671630859375, "reward": 0.7977628707885742, "action": -1.2060073614120483}
{"mode": "train", "epochs": 3, "timestep": 5969, "ep_reward": 1106.802490234375, "reward": 0.8353716731071472, "action": -1.1406309604644775}
{"mode": "train", "epochs": 3, "timestep": 5970, "ep_reward": 1107.658203125, "reward": 0.8556709885597229, "action": -0.7446852326393127}
{"mode": "train", "epochs": 3, "timestep": 5971, "ep_reward": 1108.5203857421875, "reward": 0.8622221946716309, "action": -1.2143733501434326}
{"mode": "train", "epochs": 3, "timestep": 5972, "ep_reward": 1109.3675537109375, "reward": 0.8471277952194214, "action": -0.32046961784362793}
{"mode": "train", "epochs": 3, "timestep": 5973, "ep_reward": 1110.1878662109375, "reward": 0.8203108310699463, "action": -0.6951888799667358}
{"mode": "train", "epochs": 3, "timestep": 5974, "ep_reward": 1110.9542236328125, "reward": 0.7663040161132812, "action": -1.3778666257858276}
{"mode": "train", "epochs": 3, "timestep": 5975, "ep_reward": 1111.6282958984375, "reward": 0.6740918755531311, "action": -1.3904368877410889}
{"mode": "train", "epochs": 3, "timestep": 5976, "ep_reward": 1112.1705322265625, "reward": 0.5422887206077576, "action": -0.5739182233810425}
{"mode": "train", "epochs": 3, "timestep": 5977, "ep_reward": 1112.5537109375, "reward": 0.38316792249679565, "action": -0.29473114013671875}
{"mode": "train", "epochs": 3, "timestep": 5978, "ep_reward": 1112.833740234375, "reward": 0.2799939513206482, "action": -0.831446647644043}
{"mode": "train", "epochs": 3, "timestep": 5979, "ep_reward": 1112.990478515625, "reward": 0.15670228004455566, "action": -1.7721381187438965}
{"mode": "train", "epochs": 3, "timestep": 5980, "ep_reward": 1113.0042724609375, "reward": 0.013738036155700684, "action": -0.5571877956390381}
{"mode": "train", "epochs": 3, "timestep": 5981, "ep_reward": 1113.1070556640625, "reward": 0.10275542736053467, "action": -0.8251712322235107}
{"mode": "train", "epochs": 3, "timestep": 5982, "ep_reward": 1113.350341796875, "reward": 0.24326997995376587, "action": -0.9442778825759888}
{"mode": "train", "epochs": 3, "timestep": 5983, "ep_reward": 1113.7327880859375, "reward": 0.3824042081832886, "action": -1.2611678838729858}
{"mode": "train", "epochs": 3, "timestep": 5984, "ep_reward": 1114.2413330078125, "reward": 0.508552074432373, "action": -1.0964856147766113}
{"mode": "train", "epochs": 3, "timestep": 5985, "ep_reward": 1114.8609619140625, "reward": 0.6196384429931641, "action": -1.73173189163208}
{"mode": "train", "epochs": 3, "timestep": 5986, "ep_reward": 1115.563720703125, "reward": 0.7027349472045898, "action": -0.998803436756134}
{"mode": "train", "epochs": 3, "timestep": 5987, "ep_reward": 1116.3349609375, "reward": 0.7712839245796204, "action": -1.7418190240859985}
{"mode": "train", "epochs": 3, "timestep": 5988, "ep_reward": 1117.146484375, "reward": 0.8115745186805725, "action": -1.2286112308502197}
{"mode": "train", "epochs": 3, "timestep": 5989, "ep_reward": 1117.9837646484375, "reward": 0.8372342586517334, "action": -0.9272206425666809}
{"mode": "train", "epochs": 3, "timestep": 5990, "ep_reward": 1118.8304443359375, "reward": 0.8467245101928711, "action": -0.7246342897415161}
{"mode": "train", "epochs": 3, "timestep": 5991, "ep_reward": 1119.6693115234375, "reward": 0.8388546705245972, "action": -1.3149774074554443}
{"mode": "train", "epochs": 3, "timestep": 5992, "ep_reward": 1120.47314453125, "reward": 0.8038468360900879, "action": -1.637498140335083}
{"mode": "train", "epochs": 3, "timestep": 5993, "ep_reward": 1121.211181640625, "reward": 0.738028347492218, "action": -1.342748761177063}
{"mode": "train", "epochs": 3, "timestep": 5994, "ep_reward": 1121.8514404296875, "reward": 0.6403029561042786, "action": -0.9940043091773987}
{"mode": "train", "epochs": 3, "timestep": 5995, "ep_reward": 1122.35693359375, "reward": 0.5054922699928284, "action": -0.639189600944519}
{"mode": "train", "epochs": 3, "timestep": 5996, "ep_reward": 1122.732421875, "reward": 0.3754485845565796, "action": -1.7043430805206299}
{"mode": "train", "epochs": 3, "timestep": 5997, "ep_reward": 1123.003173828125, "reward": 0.270765483379364, "action": -1.3984225988388062}
{"mode": "train", "epochs": 3, "timestep": 5998, "ep_reward": 1123.149169921875, "reward": 0.14596599340438843, "action": -1.6820999383926392}
{"mode": "train", "epochs": 3, "timestep": 5999, "ep_reward": 1123.1505126953125, "reward": 0.0013773441314697266, "action": -0.5402807593345642}
{"mode": "train", "epochs": 3, "timestep": 6000, "ep_reward": 1123.264404296875, "reward": 0.11393868923187256, "action": -1.3852550983428955}
{"mode": "train", "epochs": 4, "timestep": 6001, "ep_reward": 0.527579665184021, "reward": 0.527579665184021, "action": 0.7340022921562195}
{"mode": "train", "epochs": 4, "timestep": 6002, "ep_reward": 1.0394551753997803, "reward": 0.5118755102157593, "action": 1.0512568950653076}
{"mode": "train", "epochs": 4, "timestep": 6003, "ep_reward": 1.5257982015609741, "reward": 0.48634302616119385, "action": 0.6817470192909241}
{"mode": "train", "epochs": 4, "timestep": 6004, "ep_reward": 1.9799444675445557, "reward": 0.45414620637893677, "action": 0.4700242280960083}
{"mode": "train", "epochs": 4, "timestep": 6005, "ep_reward": 2.3973255157470703, "reward": 0.41738104820251465, "action": 0.5796278715133667}
{"mode": "train", "epochs": 4, "timestep": 6006, "ep_reward": 2.77372145652771, "reward": 0.3763958811759949, "action": 1.1639448404312134}
{"mode": "train", "epochs": 4, "timestep": 6007, "ep_reward": 3.153576374053955, "reward": 0.3798549175262451, "action": 1.253067970275879}
{"mode": "train", "epochs": 4, "timestep": 6008, "ep_reward": 3.5724077224731445, "reward": 0.418831467628479, "action": 0.7384334802627563}
{"mode": "train", "epochs": 4, "timestep": 6009, "ep_reward": 4.03262186050415, "reward": 0.4602143168449402, "action": 0.5527893900871277}
{"mode": "train", "epochs": 4, "timestep": 6010, "ep_reward": 4.533313274383545, "reward": 0.5006912350654602, "action": 0.8850875496864319}
{"mode": "train", "epochs": 4, "timestep": 6011, "ep_reward": 5.070972442626953, "reward": 0.5376589894294739, "action": 0.3615618944168091}
{"mode": "train", "epochs": 4, "timestep": 6012, "ep_reward": 5.642311096191406, "reward": 0.5713386535644531, "action": 1.072080373764038}
{"mode": "train", "epochs": 4, "timestep": 6013, "ep_reward": 6.240571022033691, "reward": 0.5982598066329956, "action": 1.4930906295776367}
{"mode": "train", "epochs": 4, "timestep": 6014, "ep_reward": 6.8607330322265625, "reward": 0.6201620101928711, "action": 1.217385172843933}
{"mode": "train", "epochs": 4, "timestep": 6015, "ep_reward": 7.498082160949707, "reward": 0.6373488903045654, "action": 0.5938889980316162}
{"mode": "train", "epochs": 4, "timestep": 6016, "ep_reward": 8.14547061920166, "reward": 0.6473888158798218, "action": 2.0}
{"mode": "train", "epochs": 4, "timestep": 6017, "ep_reward": 8.797468185424805, "reward": 0.651997983455658, "action": 0.5198378562927246}
{"mode": "train", "epochs": 4, "timestep": 6018, "ep_reward": 9.446186065673828, "reward": 0.6487182378768921, "action": 1.1607105731964111}
{"mode": "train", "epochs": 4, "timestep": 6019, "ep_reward": 10.084762573242188, "reward": 0.6385763883590698, "action": 0.7058566808700562}
{"mode": "train", "epochs": 4, "timestep": 6020, "ep_reward": 10.704791069030762, "reward": 0.6200283765792847, "action": -0.5298044085502625}
{"mode": "train", "epochs": 4, "timestep": 6021, "ep_reward": 11.292306900024414, "reward": 0.5875157117843628, "action": -0.39441657066345215}
{"mode": "train", "epochs": 4, "timestep": 6022, "ep_reward": 11.836284637451172, "reward": 0.5439778566360474, "action": 0.19368791580200195}
{"mode": "train", "epochs": 4, "timestep": 6023, "ep_reward": 12.331010818481445, "reward": 0.4947260022163391, "action": -1.7009360790252686}
{"mode": "train", "epochs": 4, "timestep": 6024, "ep_reward": 12.756569862365723, "reward": 0.42555922269821167, "action": -0.9222398400306702}
{"mode": "train", "epochs": 4, "timestep": 6025, "ep_reward": 13.109506607055664, "reward": 0.3529365658760071, "action": -0.3876863121986389}
{"mode": "train", "epochs": 4, "timestep": 6026, "ep_reward": 13.45148754119873, "reward": 0.34198129177093506, "action": -1.634204626083374}
{"mode": "train", "epochs": 4, "timestep": 6027, "ep_reward": 13.8515625, "reward": 0.4000750184059143, "action": -0.9653069376945496}
{"mode": "train", "epochs": 4, "timestep": 6028, "ep_reward": 14.314967155456543, "reward": 0.46340471506118774, "action": -1.1046544313430786}
{"mode": "train", "epochs": 4, "timestep": 6029, "ep_reward": 14.839943885803223, "reward": 0.5249763131141663, "action": -0.7825217247009277}
{"mode": "train", "epochs": 4, "timestep": 6030, "ep_reward": 15.424325942993164, "reward": 0.5843819975852966, "action": -0.49177563190460205}
{"mode": "train", "epochs": 4, "timestep": 6031, "ep_reward": 16.062158584594727, "reward": 0.6378324031829834, "action": -1.6731553077697754}
{"mode": "train", "epochs": 4, "timestep": 6032, "ep_reward": 16.74177360534668, "reward": 0.6796143054962158, "action": -0.2609858512878418}
{"mode": "train", "epochs": 4, "timestep": 6033, "ep_reward": 17.45839500427246, "reward": 0.7166215181350708, "action": -1.1727646589279175}
{"mode": "train", "epochs": 4, "timestep": 6034, "ep_reward": 18.199350357055664, "reward": 0.7409548163414001, "action": -0.5990034341812134}
{"mode": "train", "epochs": 4, "timestep": 6035, "ep_reward": 18.954824447631836, "reward": 0.7554737329483032, "action": -0.6130899786949158}
{"mode": "train", "epochs": 4, "timestep": 6036, "ep_reward": 19.71302032470703, "reward": 0.7581965327262878, "action": -0.0751449465751648}
{"mode": "train", "epochs": 4, "timestep": 6037, "ep_reward": 20.460338592529297, "reward": 0.7473185062408447, "action": 0.6132750511169434}
{"mode": "train", "epochs": 4, "timestep": 6038, "ep_reward": 21.179147720336914, "reward": 0.7188093662261963, "action": 1.8230702877044678}
{"mode": "train", "epochs": 4, "timestep": 6039, "ep_reward": 21.844602584838867, "reward": 0.6654550433158875, "action": 0.16980290412902832}
{"mode": "train", "epochs": 4, "timestep": 6040, "ep_reward": 22.446229934692383, "reward": 0.6016279458999634, "action": 0.8203274011611938}
{"mode": "train", "epochs": 4, "timestep": 6041, "ep_reward": 22.9646053314209, "reward": 0.5183756351470947, "action": 1.191806674003601}
{"mode": "train", "epochs": 4, "timestep": 6042, "ep_reward": 23.38210678100586, "reward": 0.41750234365463257, "action": 1.9495099782943726}
{"mode": "train", "epochs": 4, "timestep": 6043, "ep_reward": 23.679370880126953, "reward": 0.2972649931907654, "action": 0.28165149688720703}
{"mode": "train", "epochs": 4, "timestep": 6044, "ep_reward": 23.939144134521484, "reward": 0.25977253913879395, "action": 0.7211302518844604}
{"mode": "train", "epochs": 4, "timestep": 6045, "ep_reward": 24.289005279541016, "reward": 0.34986066818237305, "action": 0.4387121796607971}
{"mode": "train", "epochs": 4, "timestep": 6046, "ep_reward": 24.73188591003418, "reward": 0.4428800344467163, "action": 2.0}
{"mode": "train", "epochs": 4, "timestep": 6047, "ep_reward": 25.25433921813965, "reward": 0.5224533677101135, "action": 1.7389347553253174}
{"mode": "train", "epochs": 4, "timestep": 6048, "ep_reward": 25.855323791503906, "reward": 0.6009837985038757, "action": 1.25044846534729}
{"mode": "train", "epochs": 4, "timestep": 6049, "ep_reward": 26.530841827392578, "reward": 0.6755187511444092, "action": 1.1968052387237549}
{"mode": "train", "epochs": 4, "timestep": 6050, "ep_reward": 27.270639419555664, "reward": 0.7397968769073486, "action": 0.4810527563095093}
{"mode": "train", "epochs": 4, "timestep": 6051, "ep_reward": 28.0656681060791, "reward": 0.7950291633605957, "action": 1.1339166164398193}
{"mode": "train", "epochs": 4, "timestep": 6052, "ep_reward": 28.900196075439453, "reward": 0.8345286250114441, "action": 1.1682521104812622}
{"mode": "train", "epochs": 4, "timestep": 6053, "ep_reward": 29.763355255126953, "reward": 0.8631587028503418, "action": 1.4275155067443848}
{"mode": "train", "epochs": 4, "timestep": 6054, "ep_reward": 30.645423889160156, "reward": 0.8820691108703613, "action": 0.07478362321853638}
{"mode": "train", "epochs": 4, "timestep": 6055, "ep_reward": 31.537921905517578, "reward": 0.892497718334198, "action": 0.7269293069839478}
{"mode": "train", "epochs": 4, "timestep": 6056, "ep_reward": 32.42973327636719, "reward": 0.8918113708496094, "action": 0.7138508558273315}
{"mode": "train", "epochs": 4, "timestep": 6057, "ep_reward": 33.31089782714844, "reward": 0.8811644315719604, "action": -0.8495687246322632}
{"mode": "train", "epochs": 4, "timestep": 6058, "ep_reward": 34.16413879394531, "reward": 0.8532420992851257, "action": -0.934833288192749}
{"mode": "train", "epochs": 4, "timestep": 6059, "ep_reward": 34.970115661621094, "reward": 0.8059753179550171, "action": -0.48314356803894043}
{"mode": "train", "epochs": 4, "timestep": 6060, "ep_reward": 35.71073532104492, "reward": 0.7406207323074341, "action": -0.9625411629676819}
{"mode": "train", "epochs": 4, "timestep": 6061, "ep_reward": 36.360008239746094, "reward": 0.6492746472358704, "action": -1.600208044052124}
{"mode": "train", "epochs": 4, "timestep": 6062, "ep_reward": 36.886383056640625, "reward": 0.5263744592666626, "action": -1.5031068325042725}
{"mode": "train", "epochs": 4, "timestep": 6063, "ep_reward": 37.265804290771484, "reward": 0.37942057847976685, "action": -1.5183725357055664}
{"mode": "train", "epochs": 4, "timestep": 6064, "ep_reward": 37.479923248291016, "reward": 0.21412009000778198, "action": -0.6206918954849243}
{"mode": "train", "epochs": 4, "timestep": 6065, "ep_reward": 37.57638931274414, "reward": 0.09646642208099365, "action": -0.6720570921897888}
{"mode": "train", "epochs": 4, "timestep": 6066, "ep_reward": 37.796165466308594, "reward": 0.21977663040161133, "action": -0.836846649646759}
{"mode": "train", "epochs": 4, "timestep": 6067, "ep_reward": 38.141334533691406, "reward": 0.34517043828964233, "action": -1.3638747930526733}
{"mode": "train", "epochs": 4, "timestep": 6068, "ep_reward": 38.60424041748047, "reward": 0.46290576457977295, "action": -0.5669702291488647}
{"mode": "train", "epochs": 4, "timestep": 6069, "ep_reward": 39.18441390991211, "reward": 0.58017498254776, "action": -0.8373322486877441}
{"mode": "train", "epochs": 4, "timestep": 6070, "ep_reward": 39.863059997558594, "reward": 0.678645133972168, "action": -1.1635897159576416}
{"mode": "train", "epochs": 4, "timestep": 6071, "ep_reward": 40.61978530883789, "reward": 0.7567250728607178, "action": -0.3108062744140625}
{"mode": "train", "epochs": 4, "timestep": 6072, "ep_reward": 41.44349670410156, "reward": 0.8237112760543823, "action": -1.767592191696167}
{"mode": "train", "epochs": 4, "timestep": 6073, "ep_reward": 42.30863952636719, "reward": 0.8651427030563354, "action": -1.1427708864212036}
{"mode": "train", "epochs": 4, "timestep": 6074, "ep_reward": 43.20753479003906, "reward": 0.8988943099975586, "action": -1.5842154026031494}
{"mode": "train", "epochs": 4, "timestep": 6075, "ep_reward": 44.12788772583008, "reward": 0.9203528761863708, "action": -1.6116732358932495}
{"mode": "train", "epochs": 4, "timestep": 6076, "ep_reward": 45.061927795410156, "reward": 0.9340401291847229, "action": -0.7971985340118408}
{"mode": "train", "epochs": 4, "timestep": 6077, "ep_reward": 46.006988525390625, "reward": 0.945061981678009, "action": -0.05091965198516846}
{"mode": "train", "epochs": 4, "timestep": 6078, "ep_reward": 46.960208892822266, "reward": 0.953221321105957, "action": -1.6203184127807617}
{"mode": "train", "epochs": 4, "timestep": 6079, "ep_reward": 47.90774917602539, "reward": 0.9475399255752563, "action": -0.9305246472358704}
{"mode": "train", "epochs": 4, "timestep": 6080, "ep_reward": 48.84610366821289, "reward": 0.9383552670478821, "action": -0.8125793933868408}
{"mode": "train", "epochs": 4, "timestep": 6081, "ep_reward": 49.76718521118164, "reward": 0.9210813045501709, "action": -1.6027673482894897}
{"mode": "train", "epochs": 4, "timestep": 6082, "ep_reward": 50.65378952026367, "reward": 0.8866036534309387, "action": -1.1698811054229736}
{"mode": "train", "epochs": 4, "timestep": 6083, "ep_reward": 51.49148178100586, "reward": 0.8376935124397278, "action": -1.5421521663665771}
{"mode": "train", "epochs": 4, "timestep": 6084, "ep_reward": 52.25318908691406, "reward": 0.7617080211639404, "action": -1.7445565462112427}
{"mode": "train", "epochs": 4, "timestep": 6085, "ep_reward": 52.90451431274414, "reward": 0.6513241529464722, "action": -1.1158586740493774}
{"mode": "train", "epochs": 4, "timestep": 6086, "ep_reward": 53.41476821899414, "reward": 0.5102547407150269, "action": -1.551400899887085}
{"mode": "train", "epochs": 4, "timestep": 6087, "ep_reward": 53.738319396972656, "reward": 0.3235500454902649, "action": -1.3897334337234497}
{"mode": "train", "epochs": 4, "timestep": 6088, "ep_reward": 53.94580841064453, "reward": 0.2074878215789795, "action": -1.0041664838790894}
{"mode": "train", "epochs": 4, "timestep": 6089, "ep_reward": 54.017974853515625, "reward": 0.07216811180114746, "action": -1.208132028579712}
{"mode": "train", "epochs": 4, "timestep": 6090, "ep_reward": 54.063926696777344, "reward": 0.04595136642456055, "action": -0.3704415559768677}
{"mode": "train", "epochs": 4, "timestep": 6091, "ep_reward": 54.25430679321289, "reward": 0.19037920236587524, "action": -0.8519788980484009}
{"mode": "train", "epochs": 4, "timestep": 6092, "ep_reward": 54.58534622192383, "reward": 0.33103978633880615, "action": -1.88139009475708}
{"mode": "train", "epochs": 4, "timestep": 6093, "ep_reward": 55.03934860229492, "reward": 0.4540017247200012, "action": -1.2852667570114136}
{"mode": "train", "epochs": 4, "timestep": 6094, "ep_reward": 55.61101150512695, "reward": 0.5716633796691895, "action": -1.1813139915466309}
{"mode": "train", "epochs": 4, "timestep": 6095, "ep_reward": 56.281211853027344, "reward": 0.6702021360397339, "action": -0.758934497833252}
{"mode": "train", "epochs": 4, "timestep": 6096, "ep_reward": 57.030914306640625, "reward": 0.749700665473938, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6097, "ep_reward": 57.82609176635742, "reward": 0.7951776385307312, "action": -0.6070526838302612}
{"mode": "train", "epochs": 4, "timestep": 6098, "ep_reward": 58.659698486328125, "reward": 0.8336060643196106, "action": -0.7434433698654175}
{"mode": "train", "epochs": 4, "timestep": 6099, "ep_reward": 59.51112365722656, "reward": 0.8514265418052673, "action": -1.2899304628372192}
{"mode": "train", "epochs": 4, "timestep": 6100, "ep_reward": 60.35723876953125, "reward": 0.8461141586303711, "action": 0.3690371513366699}
{"mode": "train", "epochs": 4, "timestep": 6101, "ep_reward": 61.19409942626953, "reward": 0.8368602991104126, "action": -0.5256966352462769}
{"mode": "train", "epochs": 4, "timestep": 6102, "ep_reward": 61.99224853515625, "reward": 0.7981505393981934, "action": -0.7801048755645752}
{"mode": "train", "epochs": 4, "timestep": 6103, "ep_reward": 62.72272491455078, "reward": 0.7304774522781372, "action": -1.3696608543395996}
{"mode": "train", "epochs": 4, "timestep": 6104, "ep_reward": 63.344688415527344, "reward": 0.6219625473022461, "action": -0.18184220790863037}
{"mode": "train", "epochs": 4, "timestep": 6105, "ep_reward": 63.83433532714844, "reward": 0.4896450638771057, "action": -0.9271437525749207}
{"mode": "train", "epochs": 4, "timestep": 6106, "ep_reward": 64.17720031738281, "reward": 0.34286367893218994, "action": -0.6696808934211731}
{"mode": "train", "epochs": 4, "timestep": 6107, "ep_reward": 64.40863800048828, "reward": 0.2314414381980896, "action": -0.7864866852760315}
{"mode": "train", "epochs": 4, "timestep": 6108, "ep_reward": 64.508544921875, "reward": 0.09990978240966797, "action": -1.5943217277526855}
{"mode": "train", "epochs": 4, "timestep": 6109, "ep_reward": 64.52505493164062, "reward": 0.01651144027709961, "action": -1.755033016204834}
{"mode": "train", "epochs": 4, "timestep": 6110, "ep_reward": 64.68444061279297, "reward": 0.159382164478302, "action": -1.0530709028244019}
{"mode": "train", "epochs": 4, "timestep": 6111, "ep_reward": 64.98290252685547, "reward": 0.29845935106277466, "action": -1.0039316415786743}
{"mode": "train", "epochs": 4, "timestep": 6112, "ep_reward": 65.41781616210938, "reward": 0.43491655588150024, "action": -0.3110746741294861}
{"mode": "train", "epochs": 4, "timestep": 6113, "ep_reward": 65.9837875366211, "reward": 0.5659701228141785, "action": -0.051784515380859375}
{"mode": "train", "epochs": 4, "timestep": 6114, "ep_reward": 66.66128540039062, "reward": 0.6774944067001343, "action": -0.47959446907043457}
{"mode": "train", "epochs": 4, "timestep": 6115, "ep_reward": 67.42176818847656, "reward": 0.7604830265045166, "action": -0.20551955699920654}
{"mode": "train", "epochs": 4, "timestep": 6116, "ep_reward": 68.24579620361328, "reward": 0.8240247964859009, "action": -0.2582026720046997}
{"mode": "train", "epochs": 4, "timestep": 6117, "ep_reward": 69.11381530761719, "reward": 0.8680156469345093, "action": -1.442755937576294}
{"mode": "train", "epochs": 4, "timestep": 6118, "ep_reward": 70.002197265625, "reward": 0.8883799314498901, "action": -0.8606806397438049}
{"mode": "train", "epochs": 4, "timestep": 6119, "ep_reward": 70.90266418457031, "reward": 0.9004660844802856, "action": -0.8163537383079529}
{"mode": "train", "epochs": 4, "timestep": 6120, "ep_reward": 71.80342864990234, "reward": 0.9007635712623596, "action": -0.19369149208068848}
{"mode": "train", "epochs": 4, "timestep": 6121, "ep_reward": 72.69649505615234, "reward": 0.8930643796920776, "action": -1.2515296936035156}
{"mode": "train", "epochs": 4, "timestep": 6122, "ep_reward": 73.5591812133789, "reward": 0.8626874685287476, "action": -0.9650539755821228}
{"mode": "train", "epochs": 4, "timestep": 6123, "ep_reward": 74.37449645996094, "reward": 0.8153180480003357, "action": -1.0749378204345703}
{"mode": "train", "epochs": 4, "timestep": 6124, "ep_reward": 75.1162109375, "reward": 0.741710901260376, "action": -1.167319893836975}
{"mode": "train", "epochs": 4, "timestep": 6125, "ep_reward": 75.75086212158203, "reward": 0.6346492767333984, "action": 0.026989340782165527}
{"mode": "train", "epochs": 4, "timestep": 6126, "ep_reward": 76.25740814208984, "reward": 0.5065487027168274, "action": -1.2922086715698242}
{"mode": "train", "epochs": 4, "timestep": 6127, "ep_reward": 76.58648681640625, "reward": 0.329082190990448, "action": -0.2784866690635681}
{"mode": "train", "epochs": 4, "timestep": 6128, "ep_reward": 76.80133819580078, "reward": 0.2148529291152954, "action": -1.473297119140625}
{"mode": "train", "epochs": 4, "timestep": 6129, "ep_reward": 76.88220977783203, "reward": 0.08086806535720825, "action": -0.5945515036582947}
{"mode": "train", "epochs": 4, "timestep": 6130, "ep_reward": 76.91900634765625, "reward": 0.036794424057006836, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6131, "ep_reward": 77.09609985351562, "reward": 0.17709028720855713, "action": -0.4902231693267822}
{"mode": "train", "epochs": 4, "timestep": 6132, "ep_reward": 77.41956329345703, "reward": 0.32346630096435547, "action": -0.38802361488342285}
{"mode": "train", "epochs": 4, "timestep": 6133, "ep_reward": 77.88411712646484, "reward": 0.4645501971244812, "action": -1.2362300157546997}
{"mode": "train", "epochs": 4, "timestep": 6134, "ep_reward": 78.46460723876953, "reward": 0.5804923176765442, "action": -1.0210545063018799}
{"mode": "train", "epochs": 4, "timestep": 6135, "ep_reward": 79.14388275146484, "reward": 0.6792736053466797, "action": -1.7245219945907593}
{"mode": "train", "epochs": 4, "timestep": 6136, "ep_reward": 79.89354705810547, "reward": 0.7496630549430847, "action": -1.3502132892608643}
{"mode": "train", "epochs": 4, "timestep": 6137, "ep_reward": 80.69709777832031, "reward": 0.803551435470581, "action": -0.48285675048828125}
{"mode": "train", "epochs": 4, "timestep": 6138, "ep_reward": 81.54267883300781, "reward": 0.8455778360366821, "action": -1.5969926118850708}
{"mode": "train", "epochs": 4, "timestep": 6139, "ep_reward": 82.40342712402344, "reward": 0.860747218132019, "action": -0.983514130115509}
{"mode": "train", "epochs": 4, "timestep": 6140, "ep_reward": 83.26803588867188, "reward": 0.8646077513694763, "action": -1.6222658157348633}
{"mode": "train", "epochs": 4, "timestep": 6141, "ep_reward": 84.11357116699219, "reward": 0.8455333709716797, "action": -0.4073503613471985}
{"mode": "train", "epochs": 4, "timestep": 6142, "ep_reward": 84.93064880371094, "reward": 0.817081093788147, "action": -1.539811134338379}
{"mode": "train", "epochs": 4, "timestep": 6143, "ep_reward": 85.68314361572266, "reward": 0.752494752407074, "action": -0.8060404062271118}
{"mode": "train", "epochs": 4, "timestep": 6144, "ep_reward": 86.34673309326172, "reward": 0.6635880470275879, "action": -0.6265432834625244}
{"mode": "train", "epochs": 4, "timestep": 6145, "ep_reward": 86.88606262207031, "reward": 0.5393298864364624, "action": -1.7702679634094238}
{"mode": "train", "epochs": 4, "timestep": 6146, "ep_reward": 87.26432037353516, "reward": 0.3782603144645691, "action": -0.144142746925354}
{"mode": "train", "epochs": 4, "timestep": 6147, "ep_reward": 87.53815460205078, "reward": 0.2738335132598877, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6148, "ep_reward": 87.68800354003906, "reward": 0.14984667301177979, "action": -0.9695776700973511}
{"mode": "train", "epochs": 4, "timestep": 6149, "ep_reward": 87.6934814453125, "reward": 0.005477428436279297, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6150, "ep_reward": 87.80360412597656, "reward": 0.11012482643127441, "action": 0.3382152318954468}
{"mode": "train", "epochs": 4, "timestep": 6151, "ep_reward": 88.06880187988281, "reward": 0.26519447565078735, "action": -0.626446008682251}
{"mode": "train", "epochs": 4, "timestep": 6152, "ep_reward": 88.47364807128906, "reward": 0.40484726428985596, "action": -0.624131441116333}
{"mode": "train", "epochs": 4, "timestep": 6153, "ep_reward": 89.0074234008789, "reward": 0.5337762832641602, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6154, "ep_reward": 89.63837432861328, "reward": 0.6309528350830078, "action": -1.376574158668518}
{"mode": "train", "epochs": 4, "timestep": 6155, "ep_reward": 90.35452270507812, "reward": 0.7161499261856079, "action": -1.1030958890914917}
{"mode": "train", "epochs": 4, "timestep": 6156, "ep_reward": 91.13761901855469, "reward": 0.7830942869186401, "action": -1.2954366207122803}
{"mode": "train", "epochs": 4, "timestep": 6157, "ep_reward": 91.96629333496094, "reward": 0.8286769390106201, "action": -0.9554999470710754}
{"mode": "train", "epochs": 4, "timestep": 6158, "ep_reward": 92.8259506225586, "reward": 0.8596569299697876, "action": -0.4832839369773865}
{"mode": "train", "epochs": 4, "timestep": 6159, "ep_reward": 93.70442199707031, "reward": 0.8784703016281128, "action": -0.12619692087173462}
{"mode": "train", "epochs": 4, "timestep": 6160, "ep_reward": 94.58968353271484, "reward": 0.8852628469467163, "action": -0.0046128034591674805}
{"mode": "train", "epochs": 4, "timestep": 6161, "ep_reward": 95.46820068359375, "reward": 0.8785162568092346, "action": -1.1272332668304443}
{"mode": "train", "epochs": 4, "timestep": 6162, "ep_reward": 96.3144760131836, "reward": 0.8462746739387512, "action": -1.0669556856155396}
{"mode": "train", "epochs": 4, "timestep": 6163, "ep_reward": 97.10765075683594, "reward": 0.7931761741638184, "action": -0.04803586006164551}
{"mode": "train", "epochs": 4, "timestep": 6164, "ep_reward": 97.83185577392578, "reward": 0.7242058515548706, "action": -1.5441615581512451}
{"mode": "train", "epochs": 4, "timestep": 6165, "ep_reward": 98.4373550415039, "reward": 0.6054979562759399, "action": -0.3138408064842224}
{"mode": "train", "epochs": 4, "timestep": 6166, "ep_reward": 98.9012222290039, "reward": 0.46386492252349854, "action": -1.0213032960891724}
{"mode": "train", "epochs": 4, "timestep": 6167, "ep_reward": 99.21063995361328, "reward": 0.3094204068183899, "action": -1.101743221282959}
{"mode": "train", "epochs": 4, "timestep": 6168, "ep_reward": 99.40233612060547, "reward": 0.19169771671295166, "action": -0.17176228761672974}
{"mode": "train", "epochs": 4, "timestep": 6169, "ep_reward": 99.45614624023438, "reward": 0.053809285163879395, "action": -1.2235785722732544}
{"mode": "train", "epochs": 4, "timestep": 6170, "ep_reward": 99.52044677734375, "reward": 0.06430333852767944, "action": -1.5332984924316406}
{"mode": "train", "epochs": 4, "timestep": 6171, "ep_reward": 99.7212142944336, "reward": 0.20076948404312134, "action": -0.8310328722000122}
{"mode": "train", "epochs": 4, "timestep": 6172, "ep_reward": 100.0643539428711, "reward": 0.3431413173675537, "action": -1.2840042114257812}
{"mode": "train", "epochs": 4, "timestep": 6173, "ep_reward": 100.53744506835938, "reward": 0.47308915853500366, "action": -0.15925413370132446}
{"mode": "train", "epochs": 4, "timestep": 6174, "ep_reward": 101.1378402709961, "reward": 0.6003957986831665, "action": -0.555086612701416}
{"mode": "train", "epochs": 4, "timestep": 6175, "ep_reward": 101.83757781982422, "reward": 0.6997406482696533, "action": -0.9890973567962646}
{"mode": "train", "epochs": 4, "timestep": 6176, "ep_reward": 102.60921478271484, "reward": 0.7716368436813354, "action": -1.8185272216796875}
{"mode": "train", "epochs": 4, "timestep": 6177, "ep_reward": 103.42526245117188, "reward": 0.816051185131073, "action": -0.6194484233856201}
{"mode": "train", "epochs": 4, "timestep": 6178, "ep_reward": 104.27814483642578, "reward": 0.8528836369514465, "action": -0.4324202537536621}
{"mode": "train", "epochs": 4, "timestep": 6179, "ep_reward": 105.15235900878906, "reward": 0.8742141723632812, "action": -0.9232178926467896}
{"mode": "train", "epochs": 4, "timestep": 6180, "ep_reward": 106.02843475341797, "reward": 0.8760769963264465, "action": -1.258359670639038}
{"mode": "train", "epochs": 4, "timestep": 6181, "ep_reward": 106.88760375976562, "reward": 0.8591656684875488, "action": -0.7859811782836914}
{"mode": "train", "epochs": 4, "timestep": 6182, "ep_reward": 107.715087890625, "reward": 0.8274849057197571, "action": -0.8547655344009399}
{"mode": "train", "epochs": 4, "timestep": 6183, "ep_reward": 108.48702239990234, "reward": 0.771935224533081, "action": -1.3182718753814697}
{"mode": "train", "epochs": 4, "timestep": 6184, "ep_reward": 109.16829681396484, "reward": 0.6812777519226074, "action": -0.6357146501541138}
{"mode": "train", "epochs": 4, "timestep": 6185, "ep_reward": 109.73030090332031, "reward": 0.5620042085647583, "action": -0.3923851251602173}
{"mode": "train", "epochs": 4, "timestep": 6186, "ep_reward": 110.13746643066406, "reward": 0.4071637988090515, "action": -1.3358800411224365}
{"mode": "train", "epochs": 4, "timestep": 6187, "ep_reward": 110.42188262939453, "reward": 0.2844166159629822, "action": -1.4473764896392822}
{"mode": "train", "epochs": 4, "timestep": 6188, "ep_reward": 110.58402252197266, "reward": 0.16213923692703247, "action": -1.1137782335281372}
{"mode": "train", "epochs": 4, "timestep": 6189, "ep_reward": 110.60384368896484, "reward": 0.019821584224700928, "action": -1.0133609771728516}
{"mode": "train", "epochs": 4, "timestep": 6190, "ep_reward": 110.70074462890625, "reward": 0.09690326452255249, "action": -1.8413822650909424}
{"mode": "train", "epochs": 4, "timestep": 6191, "ep_reward": 110.92967987060547, "reward": 0.2289333939552307, "action": -0.4086896777153015}
{"mode": "train", "epochs": 4, "timestep": 6192, "ep_reward": 111.30628204345703, "reward": 0.37660467624664307, "action": -1.129656195640564}
{"mode": "train", "epochs": 4, "timestep": 6193, "ep_reward": 111.81134796142578, "reward": 0.5050663352012634, "action": -0.972270131111145}
{"mode": "train", "epochs": 4, "timestep": 6194, "ep_reward": 112.42959594726562, "reward": 0.6182491779327393, "action": -0.5473356246948242}
{"mode": "train", "epochs": 4, "timestep": 6195, "ep_reward": 113.1430892944336, "reward": 0.7134962677955627, "action": -1.1288598775863647}
{"mode": "train", "epochs": 4, "timestep": 6196, "ep_reward": 113.92285919189453, "reward": 0.7797673940658569, "action": -1.691469669342041}
{"mode": "train", "epochs": 4, "timestep": 6197, "ep_reward": 114.74369812011719, "reward": 0.8208385705947876, "action": -1.567575216293335}
{"mode": "train", "epochs": 4, "timestep": 6198, "ep_reward": 115.588623046875, "reward": 0.8449232578277588, "action": -1.6250237226486206}
{"mode": "train", "epochs": 4, "timestep": 6199, "ep_reward": 116.4396743774414, "reward": 0.8510527610778809, "action": -0.4844397306442261}
{"mode": "train", "epochs": 4, "timestep": 6200, "ep_reward": 117.28868865966797, "reward": 0.8490157723426819, "action": -1.4781250953674316}
{"mode": "train", "epochs": 4, "timestep": 6201, "ep_reward": 118.10652923583984, "reward": 0.8178423047065735, "action": -0.9166280031204224}
{"mode": "train", "epochs": 4, "timestep": 6202, "ep_reward": 118.87395477294922, "reward": 0.7674242854118347, "action": -0.576595664024353}
{"mode": "train", "epochs": 4, "timestep": 6203, "ep_reward": 119.56489562988281, "reward": 0.6909395456314087, "action": 0.06879079341888428}
{"mode": "train", "epochs": 4, "timestep": 6204, "ep_reward": 120.15296173095703, "reward": 0.5880657434463501, "action": -0.9808067679405212}
{"mode": "train", "epochs": 4, "timestep": 6205, "ep_reward": 120.58490753173828, "reward": 0.43194854259490967, "action": -0.7786054015159607}
{"mode": "train", "epochs": 4, "timestep": 6206, "ep_reward": 120.89552307128906, "reward": 0.3106156587600708, "action": -0.26578307151794434}
{"mode": "train", "epochs": 4, "timestep": 6207, "ep_reward": 121.0883560180664, "reward": 0.19283318519592285, "action": -1.7812316417694092}
{"mode": "train", "epochs": 4, "timestep": 6208, "ep_reward": 121.14354705810547, "reward": 0.05519282817840576, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6209, "ep_reward": 121.20629119873047, "reward": 0.06274515390396118, "action": -1.6911273002624512}
{"mode": "train", "epochs": 4, "timestep": 6210, "ep_reward": 121.40553283691406, "reward": 0.19924533367156982, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6211, "ep_reward": 121.73274230957031, "reward": 0.3272057771682739, "action": 0.04499006271362305}
{"mode": "train", "epochs": 4, "timestep": 6212, "ep_reward": 122.2086181640625, "reward": 0.4758768677711487, "action": -1.3894188404083252}
{"mode": "train", "epochs": 4, "timestep": 6213, "ep_reward": 122.7977523803711, "reward": 0.5891328454017639, "action": -1.1203254461288452}
{"mode": "train", "epochs": 4, "timestep": 6214, "ep_reward": 123.48247528076172, "reward": 0.6847223043441772, "action": -0.2017536759376526}
{"mode": "train", "epochs": 4, "timestep": 6215, "ep_reward": 124.24828338623047, "reward": 0.7658063173294067, "action": -1.8567936420440674}
{"mode": "train", "epochs": 4, "timestep": 6216, "ep_reward": 125.05731964111328, "reward": 0.8090357780456543, "action": -0.8328906297683716}
{"mode": "train", "epochs": 4, "timestep": 6217, "ep_reward": 125.89979553222656, "reward": 0.8424726724624634, "action": -1.2491471767425537}
{"mode": "train", "epochs": 4, "timestep": 6218, "ep_reward": 126.7539291381836, "reward": 0.8541302680969238, "action": -1.0373727083206177}
{"mode": "train", "epochs": 4, "timestep": 6219, "ep_reward": 127.60374450683594, "reward": 0.8498126268386841, "action": -0.44797706604003906}
{"mode": "train", "epochs": 4, "timestep": 6220, "ep_reward": 128.4353485107422, "reward": 0.8316025733947754, "action": -0.9222809076309204}
{"mode": "train", "epochs": 4, "timestep": 6221, "ep_reward": 129.2218475341797, "reward": 0.7865031957626343, "action": -1.0383005142211914}
{"mode": "train", "epochs": 4, "timestep": 6222, "ep_reward": 129.93362426757812, "reward": 0.711774468421936, "action": -0.5915070176124573}
{"mode": "train", "epochs": 4, "timestep": 6223, "ep_reward": 130.54100036621094, "reward": 0.6073781251907349, "action": -1.8447871208190918}
{"mode": "train", "epochs": 4, "timestep": 6224, "ep_reward": 130.9851531982422, "reward": 0.4441577196121216, "action": -0.8894490003585815}
{"mode": "train", "epochs": 4, "timestep": 6225, "ep_reward": 131.31312561035156, "reward": 0.3279726505279541, "action": -1.2211235761642456}
{"mode": "train", "epochs": 4, "timestep": 6226, "ep_reward": 131.5267333984375, "reward": 0.21360641717910767, "action": -1.6220269203186035}
{"mode": "train", "epochs": 4, "timestep": 6227, "ep_reward": 131.60614013671875, "reward": 0.0794135332107544, "action": -0.9968603253364563}
{"mode": "train", "epochs": 4, "timestep": 6228, "ep_reward": 131.64456176757812, "reward": 0.03841429948806763, "action": -1.2766730785369873}
{"mode": "train", "epochs": 4, "timestep": 6229, "ep_reward": 131.8228759765625, "reward": 0.17831861972808838, "action": -0.9994932413101196}
{"mode": "train", "epochs": 4, "timestep": 6230, "ep_reward": 132.1412811279297, "reward": 0.3184112310409546, "action": -0.797842800617218}
{"mode": "train", "epochs": 4, "timestep": 6231, "ep_reward": 132.59730529785156, "reward": 0.4560256600379944, "action": -0.5377489328384399}
{"mode": "train", "epochs": 4, "timestep": 6232, "ep_reward": 133.17861938476562, "reward": 0.5813076496124268, "action": -1.696394920349121}
{"mode": "train", "epochs": 4, "timestep": 6233, "ep_reward": 133.85166931152344, "reward": 0.6730508804321289, "action": -1.4591796398162842}
{"mode": "train", "epochs": 4, "timestep": 6234, "ep_reward": 134.59800720214844, "reward": 0.7463423013687134, "action": -1.0141469240188599}
{"mode": "train", "epochs": 4, "timestep": 6235, "ep_reward": 135.4004364013672, "reward": 0.8024298548698425, "action": -1.485059142112732}
{"mode": "train", "epochs": 4, "timestep": 6236, "ep_reward": 136.23486328125, "reward": 0.8344243168830872, "action": -1.0466920137405396}
{"mode": "train", "epochs": 4, "timestep": 6237, "ep_reward": 137.08697509765625, "reward": 0.8521137833595276, "action": -1.0595347881317139}
{"mode": "train", "epochs": 4, "timestep": 6238, "ep_reward": 137.9387664794922, "reward": 0.8517880439758301, "action": -1.0281877517700195}
{"mode": "train", "epochs": 4, "timestep": 6239, "ep_reward": 138.77133178710938, "reward": 0.8325657844543457, "action": -1.3679826259613037}
{"mode": "train", "epochs": 4, "timestep": 6240, "ep_reward": 139.55857849121094, "reward": 0.7872523665428162, "action": -1.0006119012832642}
{"mode": "train", "epochs": 4, "timestep": 6241, "ep_reward": 140.27549743652344, "reward": 0.7169114947319031, "action": -1.375650405883789}
{"mode": "train", "epochs": 4, "timestep": 6242, "ep_reward": 140.88157653808594, "reward": 0.6060833930969238, "action": -0.48904675245285034}
{"mode": "train", "epochs": 4, "timestep": 6243, "ep_reward": 141.34715270996094, "reward": 0.465579092502594, "action": -0.4485057592391968}
{"mode": "train", "epochs": 4, "timestep": 6244, "ep_reward": 141.6888427734375, "reward": 0.3416840434074402, "action": -0.4640451669692993}
{"mode": "train", "epochs": 4, "timestep": 6245, "ep_reward": 141.91888427734375, "reward": 0.23003661632537842, "action": -0.4640663266181946}
{"mode": "train", "epochs": 4, "timestep": 6246, "ep_reward": 142.01707458496094, "reward": 0.09819042682647705, "action": -1.8421516418457031}
{"mode": "train", "epochs": 4, "timestep": 6247, "ep_reward": 142.03549194335938, "reward": 0.01841670274734497, "action": -1.1639817953109741}
{"mode": "train", "epochs": 4, "timestep": 6248, "ep_reward": 142.19650268554688, "reward": 0.16100579500198364, "action": -0.3621988892555237}
{"mode": "train", "epochs": 4, "timestep": 6249, "ep_reward": 142.50509643554688, "reward": 0.308596670627594, "action": -1.2395092248916626}
{"mode": "train", "epochs": 4, "timestep": 6250, "ep_reward": 142.94541931152344, "reward": 0.4403223991394043, "action": -1.4933216571807861}
{"mode": "train", "epochs": 4, "timestep": 6251, "ep_reward": 143.50244140625, "reward": 0.5570173859596252, "action": -1.318751335144043}
{"mode": "train", "epochs": 4, "timestep": 6252, "ep_reward": 144.1596221923828, "reward": 0.6571784019470215, "action": -1.190168857574463}
{"mode": "train", "epochs": 4, "timestep": 6253, "ep_reward": 144.89627075195312, "reward": 0.7366447448730469, "action": -1.1012874841690063}
{"mode": "train", "epochs": 4, "timestep": 6254, "ep_reward": 145.6912078857422, "reward": 0.7949323654174805, "action": 0.2226353883743286}
{"mode": "train", "epochs": 4, "timestep": 6255, "ep_reward": 146.535400390625, "reward": 0.8441943526268005, "action": -1.5593301057815552}
{"mode": "train", "epochs": 4, "timestep": 6256, "ep_reward": 147.3951873779297, "reward": 0.8597862720489502, "action": -1.0274317264556885}
{"mode": "train", "epochs": 4, "timestep": 6257, "ep_reward": 148.25857543945312, "reward": 0.8633937239646912, "action": 0.8079836368560791}
{"mode": "train", "epochs": 4, "timestep": 6258, "ep_reward": 149.12477111816406, "reward": 0.8661960959434509, "action": -0.3442445397377014}
{"mode": "train", "epochs": 4, "timestep": 6259, "ep_reward": 149.96658325195312, "reward": 0.8418059349060059, "action": -0.8204928636550903}
{"mode": "train", "epochs": 4, "timestep": 6260, "ep_reward": 150.75857543945312, "reward": 0.7919948101043701, "action": -1.3122398853302002}
{"mode": "train", "epochs": 4, "timestep": 6261, "ep_reward": 151.46775817871094, "reward": 0.709187924861908, "action": -0.863696813583374}
{"mode": "train", "epochs": 4, "timestep": 6262, "ep_reward": 152.06407165527344, "reward": 0.5963100790977478, "action": -0.4624152183532715}
{"mode": "train", "epochs": 4, "timestep": 6263, "ep_reward": 152.51426696777344, "reward": 0.4501904249191284, "action": -0.5514812469482422}
{"mode": "train", "epochs": 4, "timestep": 6264, "ep_reward": 152.822998046875, "reward": 0.30873793363571167, "action": -1.4938406944274902}
{"mode": "train", "epochs": 4, "timestep": 6265, "ep_reward": 153.0137176513672, "reward": 0.19071543216705322, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6266, "ep_reward": 153.0666961669922, "reward": 0.052978694438934326, "action": -1.0913097858428955}
{"mode": "train", "epochs": 4, "timestep": 6267, "ep_reward": 153.1319580078125, "reward": 0.06526851654052734, "action": -0.6102181673049927}
{"mode": "train", "epochs": 4, "timestep": 6268, "ep_reward": 153.3392791748047, "reward": 0.20732462406158447, "action": -0.9112715125083923}
{"mode": "train", "epochs": 4, "timestep": 6269, "ep_reward": 153.68687438964844, "reward": 0.3475998640060425, "action": -0.5277777314186096}
{"mode": "train", "epochs": 4, "timestep": 6270, "ep_reward": 154.17227172851562, "reward": 0.4853992462158203, "action": -0.6912962198257446}
{"mode": "train", "epochs": 4, "timestep": 6271, "ep_reward": 154.77667236328125, "reward": 0.604407012462616, "action": -0.13120585680007935}
{"mode": "train", "epochs": 4, "timestep": 6272, "ep_reward": 155.4838409423828, "reward": 0.7071653604507446, "action": -1.1988219022750854}
{"mode": "train", "epochs": 4, "timestep": 6273, "ep_reward": 156.2605438232422, "reward": 0.7767058610916138, "action": -1.0398027896881104}
{"mode": "train", "epochs": 4, "timestep": 6274, "ep_reward": 157.08880615234375, "reward": 0.8282668590545654, "action": -0.8543448448181152}
{"mode": "train", "epochs": 4, "timestep": 6275, "ep_reward": 157.9528350830078, "reward": 0.8640261888504028, "action": -0.3988337516784668}
{"mode": "train", "epochs": 4, "timestep": 6276, "ep_reward": 158.84083557128906, "reward": 0.8880071640014648, "action": -0.8903483152389526}
{"mode": "train", "epochs": 4, "timestep": 6277, "ep_reward": 159.73556518554688, "reward": 0.8947286605834961, "action": -0.91086745262146}
{"mode": "train", "epochs": 4, "timestep": 6278, "ep_reward": 160.6236572265625, "reward": 0.8880929946899414, "action": -0.8400571346282959}
{"mode": "train", "epochs": 4, "timestep": 6279, "ep_reward": 161.49093627929688, "reward": 0.8672776222229004, "action": 0.06834375858306885}
{"mode": "train", "epochs": 4, "timestep": 6280, "ep_reward": 162.32794189453125, "reward": 0.8369982838630676, "action": -0.8060862421989441}
{"mode": "train", "epochs": 4, "timestep": 6281, "ep_reward": 163.1053466796875, "reward": 0.7774072885513306, "action": -1.6884993314743042}
{"mode": "train", "epochs": 4, "timestep": 6282, "ep_reward": 163.78411865234375, "reward": 0.678768515586853, "action": -1.3711943626403809}
{"mode": "train", "epochs": 4, "timestep": 6283, "ep_reward": 164.32943725585938, "reward": 0.5453137159347534, "action": -0.6789718866348267}
{"mode": "train", "epochs": 4, "timestep": 6284, "ep_reward": 164.71038818359375, "reward": 0.3809526562690735, "action": -1.3004028797149658}
{"mode": "train", "epochs": 4, "timestep": 6285, "ep_reward": 164.97076416015625, "reward": 0.26037079095840454, "action": -0.6281242370605469}
{"mode": "train", "epochs": 4, "timestep": 6286, "ep_reward": 165.10455322265625, "reward": 0.13378554582595825, "action": -0.965035080909729}
{"mode": "train", "epochs": 4, "timestep": 6287, "ep_reward": 165.0918426513672, "reward": -0.012712717056274414, "action": -0.2676781415939331}
{"mode": "train", "epochs": 4, "timestep": 6288, "ep_reward": 165.21832275390625, "reward": 0.12648677825927734, "action": -1.3576629161834717}
{"mode": "train", "epochs": 4, "timestep": 6289, "ep_reward": 165.47940063476562, "reward": 0.2610737681388855, "action": -0.42470645904541016}
{"mode": "train", "epochs": 4, "timestep": 6290, "ep_reward": 165.8863067626953, "reward": 0.40690094232559204, "action": -1.1207016706466675}
{"mode": "train", "epochs": 4, "timestep": 6291, "ep_reward": 166.4183349609375, "reward": 0.5320225954055786, "action": -0.9542526006698608}
{"mode": "train", "epochs": 4, "timestep": 6292, "ep_reward": 167.0590362548828, "reward": 0.6406959295272827, "action": -0.717359721660614}
{"mode": "train", "epochs": 4, "timestep": 6293, "ep_reward": 167.78836059570312, "reward": 0.7293250560760498, "action": -0.07195031642913818}
{"mode": "train", "epochs": 4, "timestep": 6294, "ep_reward": 168.58921813964844, "reward": 0.8008561134338379, "action": -0.5276584625244141}
{"mode": "train", "epochs": 4, "timestep": 6295, "ep_reward": 169.43646240234375, "reward": 0.8472394347190857, "action": -1.291426658630371}
{"mode": "train", "epochs": 4, "timestep": 6296, "ep_reward": 170.30715942382812, "reward": 0.8706981539726257, "action": -0.6244361400604248}
{"mode": "train", "epochs": 4, "timestep": 6297, "ep_reward": 171.19174194335938, "reward": 0.8845809698104858, "action": -1.5244390964508057}
{"mode": "train", "epochs": 4, "timestep": 6298, "ep_reward": 172.06866455078125, "reward": 0.876915693283081, "action": -1.5754928588867188}
{"mode": "train", "epochs": 4, "timestep": 6299, "ep_reward": 172.92091369628906, "reward": 0.8522434234619141, "action": -1.0997636318206787}
{"mode": "train", "epochs": 4, "timestep": 6300, "ep_reward": 173.73219299316406, "reward": 0.8112800717353821, "action": -0.3764401078224182}
{"mode": "train", "epochs": 4, "timestep": 6301, "ep_reward": 174.4849090576172, "reward": 0.7527151703834534, "action": -0.4874919056892395}
{"mode": "train", "epochs": 4, "timestep": 6302, "ep_reward": 175.14793395996094, "reward": 0.6630263328552246, "action": -1.706840991973877}
{"mode": "train", "epochs": 4, "timestep": 6303, "ep_reward": 175.6678009033203, "reward": 0.5198687314987183, "action": -1.8899168968200684}
{"mode": "train", "epochs": 4, "timestep": 6304, "ep_reward": 176.0277557373047, "reward": 0.3599485158920288, "action": -1.0061631202697754}
{"mode": "train", "epochs": 4, "timestep": 6305, "ep_reward": 176.27957153320312, "reward": 0.2518084645271301, "action": -1.900287389755249}
{"mode": "train", "epochs": 4, "timestep": 6306, "ep_reward": 176.40357971191406, "reward": 0.12401223182678223, "action": -0.841284990310669}
{"mode": "train", "epochs": 4, "timestep": 6307, "ep_reward": 176.3937225341797, "reward": -0.00985407829284668, "action": -0.7444174289703369}
{"mode": "train", "epochs": 4, "timestep": 6308, "ep_reward": 176.5300750732422, "reward": 0.13634806871414185, "action": -0.48824191093444824}
{"mode": "train", "epochs": 4, "timestep": 6309, "ep_reward": 176.81204223632812, "reward": 0.2819629907608032, "action": -0.13752508163452148}
{"mode": "train", "epochs": 4, "timestep": 6310, "ep_reward": 177.2403564453125, "reward": 0.4283215403556824, "action": -1.2149473428726196}
{"mode": "train", "epochs": 4, "timestep": 6311, "ep_reward": 177.7891082763672, "reward": 0.5487510561943054, "action": -1.1290417909622192}
{"mode": "train", "epochs": 4, "timestep": 6312, "ep_reward": 178.44161987304688, "reward": 0.6525155305862427, "action": -1.0083719491958618}
{"mode": "train", "epochs": 4, "timestep": 6313, "ep_reward": 179.177978515625, "reward": 0.7363604307174683, "action": -0.5900930166244507}
{"mode": "train", "epochs": 4, "timestep": 6314, "ep_reward": 179.9804229736328, "reward": 0.8024437427520752, "action": -1.4792399406433105}
{"mode": "train", "epochs": 4, "timestep": 6315, "ep_reward": 180.8220977783203, "reward": 0.8416779041290283, "action": -0.8478872776031494}
{"mode": "train", "epochs": 4, "timestep": 6316, "ep_reward": 181.69187927246094, "reward": 0.8697848320007324, "action": -0.4601163864135742}
{"mode": "train", "epochs": 4, "timestep": 6317, "ep_reward": 182.57766723632812, "reward": 0.8857886791229248, "action": -1.0515596866607666}
{"mode": "train", "epochs": 4, "timestep": 6318, "ep_reward": 183.46063232421875, "reward": 0.8829652070999146, "action": -1.1059212684631348}
{"mode": "train", "epochs": 4, "timestep": 6319, "ep_reward": 184.3249969482422, "reward": 0.8643712997436523, "action": -1.0055559873580933}
{"mode": "train", "epochs": 4, "timestep": 6320, "ep_reward": 185.15310668945312, "reward": 0.8281096816062927, "action": -0.8192626237869263}
{"mode": "train", "epochs": 4, "timestep": 6321, "ep_reward": 185.92344665527344, "reward": 0.7703461647033691, "action": -0.6755542755126953}
{"mode": "train", "epochs": 4, "timestep": 6322, "ep_reward": 186.6085205078125, "reward": 0.6850693821907043, "action": -0.557042121887207}
{"mode": "train", "epochs": 4, "timestep": 6323, "ep_reward": 187.17503356933594, "reward": 0.5665068626403809, "action": 0.162392258644104}
{"mode": "train", "epochs": 4, "timestep": 6324, "ep_reward": 187.59645080566406, "reward": 0.4214162826538086, "action": -1.3062664270401}
{"mode": "train", "epochs": 4, "timestep": 6325, "ep_reward": 187.8756866455078, "reward": 0.27924132347106934, "action": -1.5649811029434204}
{"mode": "train", "epochs": 4, "timestep": 6326, "ep_reward": 188.03176879882812, "reward": 0.15608245134353638, "action": -1.0378360748291016}
{"mode": "train", "epochs": 4, "timestep": 6327, "ep_reward": 188.04466247558594, "reward": 0.012888967990875244, "action": -0.5060444474220276}
{"mode": "train", "epochs": 4, "timestep": 6328, "ep_reward": 188.1481475830078, "reward": 0.10348182916641235, "action": -1.2171692848205566}
{"mode": "train", "epochs": 4, "timestep": 6329, "ep_reward": 188.38723754882812, "reward": 0.23909056186676025, "action": -1.309288501739502}
{"mode": "train", "epochs": 4, "timestep": 6330, "ep_reward": 188.76182556152344, "reward": 0.3745880722999573, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6331, "ep_reward": 189.25550842285156, "reward": 0.49368834495544434, "action": -0.8452932834625244}
{"mode": "train", "epochs": 4, "timestep": 6332, "ep_reward": 189.86585998535156, "reward": 0.610356330871582, "action": -1.0099376440048218}
{"mode": "train", "epochs": 4, "timestep": 6333, "ep_reward": 190.5675811767578, "reward": 0.701718807220459, "action": 0.04129338264465332}
{"mode": "train", "epochs": 4, "timestep": 6334, "ep_reward": 191.3467559814453, "reward": 0.7791711091995239, "action": -0.9587855935096741}
{"mode": "train", "epochs": 4, "timestep": 6335, "ep_reward": 192.1708221435547, "reward": 0.824061930179596, "action": -0.8129169940948486}
{"mode": "train", "epochs": 4, "timestep": 6336, "ep_reward": 193.0219268798828, "reward": 0.8511056900024414, "action": -0.8688226938247681}
{"mode": "train", "epochs": 4, "timestep": 6337, "ep_reward": 193.88198852539062, "reward": 0.8600625991821289, "action": -0.8109716773033142}
{"mode": "train", "epochs": 4, "timestep": 6338, "ep_reward": 194.73394775390625, "reward": 0.8519579768180847, "action": -1.135056734085083}
{"mode": "train", "epochs": 4, "timestep": 6339, "ep_reward": 195.55526733398438, "reward": 0.8213208317756653, "action": -0.18197596073150635}
{"mode": "train", "epochs": 4, "timestep": 6340, "ep_reward": 196.33175659179688, "reward": 0.7764851450920105, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6341, "ep_reward": 197.013916015625, "reward": 0.682163417339325, "action": -0.5562126636505127}
{"mode": "train", "epochs": 4, "timestep": 6342, "ep_reward": 197.58053588867188, "reward": 0.5666149854660034, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6343, "ep_reward": 197.97720336914062, "reward": 0.3966696858406067, "action": -0.980156660079956}
{"mode": "train", "epochs": 4, "timestep": 6344, "ep_reward": 198.27371215820312, "reward": 0.29651618003845215, "action": -0.8207674026489258}
{"mode": "train", "epochs": 4, "timestep": 6345, "ep_reward": 198.45008850097656, "reward": 0.17638236284255981, "action": -0.26459795236587524}
{"mode": "train", "epochs": 4, "timestep": 6346, "ep_reward": 198.48622131347656, "reward": 0.03612798452377319, "action": -1.1795753240585327}
{"mode": "train", "epochs": 4, "timestep": 6347, "ep_reward": 198.56788635253906, "reward": 0.08166897296905518, "action": -0.5333186388015747}
{"mode": "train", "epochs": 4, "timestep": 6348, "ep_reward": 198.7930145263672, "reward": 0.22512394189834595, "action": -1.3458752632141113}
{"mode": "train", "epochs": 4, "timestep": 6349, "ep_reward": 199.15243530273438, "reward": 0.3594227433204651, "action": -0.7840644121170044}
{"mode": "train", "epochs": 4, "timestep": 6350, "ep_reward": 199.64581298828125, "reward": 0.4933822751045227, "action": -1.9153276681900024}
{"mode": "train", "epochs": 4, "timestep": 6351, "ep_reward": 200.2438507080078, "reward": 0.5980401635169983, "action": -1.327949047088623}
{"mode": "train", "epochs": 4, "timestep": 6352, "ep_reward": 200.93345642089844, "reward": 0.6896097660064697, "action": 0.19412612915039062}
{"mode": "train", "epochs": 4, "timestep": 6353, "ep_reward": 201.70643615722656, "reward": 0.7729766964912415, "action": -1.1659654378890991}
{"mode": "train", "epochs": 4, "timestep": 6354, "ep_reward": 202.52691650390625, "reward": 0.820481538772583, "action": -0.9162992238998413}
{"mode": "train", "epochs": 4, "timestep": 6355, "ep_reward": 203.37838745117188, "reward": 0.8514652848243713, "action": -1.1400636434555054}
{"mode": "train", "epochs": 4, "timestep": 6356, "ep_reward": 204.241943359375, "reward": 0.8635484576225281, "action": -0.09371984004974365}
{"mode": "train", "epochs": 4, "timestep": 6357, "ep_reward": 205.10995483398438, "reward": 0.8680144548416138, "action": -0.129838228225708}
{"mode": "train", "epochs": 4, "timestep": 6358, "ep_reward": 205.96542358398438, "reward": 0.8554649353027344, "action": -0.3432145118713379}
{"mode": "train", "epochs": 4, "timestep": 6359, "ep_reward": 206.78781127929688, "reward": 0.8223941922187805, "action": -0.8723621368408203}
{"mode": "train", "epochs": 4, "timestep": 6360, "ep_reward": 207.548583984375, "reward": 0.7607734799385071, "action": -1.3395768404006958}
{"mode": "train", "epochs": 4, "timestep": 6361, "ep_reward": 208.21148681640625, "reward": 0.6629059314727783, "action": -0.7189254760742188}
{"mode": "train", "epochs": 4, "timestep": 6362, "ep_reward": 208.74609375, "reward": 0.5346094965934753, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6363, "ep_reward": 209.11033630371094, "reward": 0.3642430901527405, "action": -0.7655697464942932}
{"mode": "train", "epochs": 4, "timestep": 6364, "ep_reward": 209.36727905273438, "reward": 0.2569466233253479, "action": -1.9209067821502686}
{"mode": "train", "epochs": 4, "timestep": 6365, "ep_reward": 209.49732971191406, "reward": 0.1300499439239502, "action": -0.6282171010971069}
{"mode": "train", "epochs": 4, "timestep": 6366, "ep_reward": 209.48065185546875, "reward": -0.016684412956237793, "action": -0.4369034767150879}
{"mode": "train", "epochs": 4, "timestep": 6367, "ep_reward": 209.61093139648438, "reward": 0.13028371334075928, "action": -1.2731953859329224}
{"mode": "train", "epochs": 4, "timestep": 6368, "ep_reward": 209.8767852783203, "reward": 0.2658558487892151, "action": -1.6783045530319214}
{"mode": "train", "epochs": 4, "timestep": 6369, "ep_reward": 210.27279663085938, "reward": 0.3960111141204834, "action": -1.518507957458496}
{"mode": "train", "epochs": 4, "timestep": 6370, "ep_reward": 210.79151916503906, "reward": 0.5187240242958069, "action": -1.5335545539855957}
{"mode": "train", "epochs": 4, "timestep": 6371, "ep_reward": 211.41490173339844, "reward": 0.6233789920806885, "action": -0.024856269359588623}
{"mode": "train", "epochs": 4, "timestep": 6372, "ep_reward": 212.13584899902344, "reward": 0.7209460735321045, "action": -1.593989372253418}
{"mode": "train", "epochs": 4, "timestep": 6373, "ep_reward": 212.9135284423828, "reward": 0.7776728868484497, "action": -0.7744743227958679}
{"mode": "train", "epochs": 4, "timestep": 6374, "ep_reward": 213.7343292236328, "reward": 0.8208000063896179, "action": -1.5365519523620605}
{"mode": "train", "epochs": 4, "timestep": 6375, "ep_reward": 214.57127380371094, "reward": 0.8369466066360474, "action": -0.9183781147003174}
{"mode": "train", "epochs": 4, "timestep": 6376, "ep_reward": 215.4106903076172, "reward": 0.8394208550453186, "action": -0.3592054843902588}
{"mode": "train", "epochs": 4, "timestep": 6377, "ep_reward": 216.2373809814453, "reward": 0.8266871571540833, "action": -1.9510126113891602}
{"mode": "train", "epochs": 4, "timestep": 6378, "ep_reward": 217.01199340820312, "reward": 0.774605929851532, "action": -1.043274164199829}
{"mode": "train", "epochs": 4, "timestep": 6379, "ep_reward": 217.71315002441406, "reward": 0.7011617422103882, "action": -1.3793184757232666}
{"mode": "train", "epochs": 4, "timestep": 6380, "ep_reward": 218.2990264892578, "reward": 0.5858770608901978, "action": -0.5079504251480103}
{"mode": "train", "epochs": 4, "timestep": 6381, "ep_reward": 218.73863220214844, "reward": 0.43960005044937134, "action": -0.11495774984359741}
{"mode": "train", "epochs": 4, "timestep": 6382, "ep_reward": 219.0720977783203, "reward": 0.3334657549858093, "action": -0.5997787714004517}
{"mode": "train", "epochs": 4, "timestep": 6383, "ep_reward": 219.29226684570312, "reward": 0.220170795917511, "action": -1.0383150577545166}
{"mode": "train", "epochs": 4, "timestep": 6384, "ep_reward": 219.37921142578125, "reward": 0.08694523572921753, "action": -0.8269565105438232}
{"mode": "train", "epochs": 4, "timestep": 6385, "ep_reward": 219.4098663330078, "reward": 0.030649304389953613, "action": -0.37844640016555786}
{"mode": "train", "epochs": 4, "timestep": 6386, "ep_reward": 219.58433532714844, "reward": 0.17446935176849365, "action": -1.0144919157028198}
{"mode": "train", "epochs": 4, "timestep": 6387, "ep_reward": 219.89779663085938, "reward": 0.3134579062461853, "action": -1.9848682880401611}
{"mode": "train", "epochs": 4, "timestep": 6388, "ep_reward": 220.3345489501953, "reward": 0.4367518424987793, "action": -1.4640626907348633}
{"mode": "train", "epochs": 4, "timestep": 6389, "ep_reward": 220.88955688476562, "reward": 0.5550118684768677, "action": -0.958656370639801}
{"mode": "train", "epochs": 4, "timestep": 6390, "ep_reward": 221.54859924316406, "reward": 0.6590375304222107, "action": -0.17518818378448486}
{"mode": "train", "epochs": 4, "timestep": 6391, "ep_reward": 222.29542541503906, "reward": 0.7468326091766357, "action": -0.5135136246681213}
{"mode": "train", "epochs": 4, "timestep": 6392, "ep_reward": 223.1023406982422, "reward": 0.806920051574707, "action": -1.2542517185211182}
{"mode": "train", "epochs": 4, "timestep": 6393, "ep_reward": 223.9424285888672, "reward": 0.8400846123695374, "action": -0.6405321955680847}
{"mode": "train", "epochs": 4, "timestep": 6394, "ep_reward": 224.80322265625, "reward": 0.8607922792434692, "action": 0.4144463539123535}
{"mode": "train", "epochs": 4, "timestep": 6395, "ep_reward": 225.67681884765625, "reward": 0.8735930919647217, "action": -0.8892931938171387}
{"mode": "train", "epochs": 4, "timestep": 6396, "ep_reward": 226.5357208251953, "reward": 0.8589072227478027, "action": -1.5086159706115723}
{"mode": "train", "epochs": 4, "timestep": 6397, "ep_reward": 227.35501098632812, "reward": 0.8192951679229736, "action": -1.347462773323059}
{"mode": "train", "epochs": 4, "timestep": 6398, "ep_reward": 228.1106719970703, "reward": 0.7556633353233337, "action": -1.1374754905700684}
{"mode": "train", "epochs": 4, "timestep": 6399, "ep_reward": 228.77255249023438, "reward": 0.6618841290473938, "action": -1.5023947954177856}
{"mode": "train", "epochs": 4, "timestep": 6400, "ep_reward": 229.29620361328125, "reward": 0.5236512422561646, "action": -0.2561466693878174}
{"mode": "train", "epochs": 4, "timestep": 6401, "ep_reward": 229.66856384277344, "reward": 0.3723660707473755, "action": -1.584111213684082}
{"mode": "train", "epochs": 4, "timestep": 6402, "ep_reward": 229.93568420410156, "reward": 0.26711857318878174, "action": -0.48640984296798706}
{"mode": "train", "epochs": 4, "timestep": 6403, "ep_reward": 230.07740783691406, "reward": 0.14172029495239258, "action": -0.6112141013145447}
{"mode": "train", "epochs": 4, "timestep": 6404, "ep_reward": 230.07376098632812, "reward": -0.0036520957946777344, "action": -0.3061385154724121}
{"mode": "train", "epochs": 4, "timestep": 6405, "ep_reward": 230.19215393066406, "reward": 0.11838603019714355, "action": -1.7304401397705078}
{"mode": "train", "epochs": 4, "timestep": 6406, "ep_reward": 230.44021606445312, "reward": 0.2480640411376953, "action": -0.8381180763244629}
{"mode": "train", "epochs": 4, "timestep": 6407, "ep_reward": 230.8304901123047, "reward": 0.3902783989906311, "action": -0.4499037265777588}
{"mode": "train", "epochs": 4, "timestep": 6408, "ep_reward": 231.35630798339844, "reward": 0.5258234739303589, "action": -0.8402828574180603}
{"mode": "train", "epochs": 4, "timestep": 6409, "ep_reward": 231.99305725097656, "reward": 0.6367546319961548, "action": -1.2480130195617676}
{"mode": "train", "epochs": 4, "timestep": 6410, "ep_reward": 232.71409606933594, "reward": 0.7210367918014526, "action": -0.6749563813209534}
{"mode": "train", "epochs": 4, "timestep": 6411, "ep_reward": 233.50279235839844, "reward": 0.7886930704116821, "action": -0.4037773609161377}
{"mode": "train", "epochs": 4, "timestep": 6412, "ep_reward": 234.34036254882812, "reward": 0.8375771045684814, "action": -0.615776777267456}
{"mode": "train", "epochs": 4, "timestep": 6413, "ep_reward": 235.20660400390625, "reward": 0.8662383556365967, "action": -1.4011542797088623}
{"mode": "train", "epochs": 4, "timestep": 6414, "ep_reward": 236.07936096191406, "reward": 0.8727622628211975, "action": -0.9699389338493347}
{"mode": "train", "epochs": 4, "timestep": 6415, "ep_reward": 236.94650268554688, "reward": 0.8671443462371826, "action": -0.4629075527191162}
{"mode": "train", "epochs": 4, "timestep": 6416, "ep_reward": 237.79519653320312, "reward": 0.8486940860748291, "action": -1.1356544494628906}
{"mode": "train", "epochs": 4, "timestep": 6417, "ep_reward": 238.59893798828125, "reward": 0.8037369847297668, "action": -0.6467058062553406}
{"mode": "train", "epochs": 4, "timestep": 6418, "ep_reward": 239.33657836914062, "reward": 0.7376384735107422, "action": -0.25344735383987427}
{"mode": "train", "epochs": 4, "timestep": 6419, "ep_reward": 239.98143005371094, "reward": 0.6448484659194946, "action": -1.746938943862915}
{"mode": "train", "epochs": 4, "timestep": 6420, "ep_reward": 240.47593688964844, "reward": 0.4945034384727478, "action": -1.387671947479248}
{"mode": "train", "epochs": 4, "timestep": 6421, "ep_reward": 240.81985473632812, "reward": 0.3439130187034607, "action": -1.501133680343628}
{"mode": "train", "epochs": 4, "timestep": 6422, "ep_reward": 241.05264282226562, "reward": 0.23278546333312988, "action": -1.1711338758468628}
{"mode": "train", "epochs": 4, "timestep": 6423, "ep_reward": 241.15432739257812, "reward": 0.10168826580047607, "action": 0.028992176055908203}
{"mode": "train", "epochs": 4, "timestep": 6424, "ep_reward": 241.16925048828125, "reward": 0.014930129051208496, "action": -0.597077488899231}
{"mode": "train", "epochs": 4, "timestep": 6425, "ep_reward": 241.32713317871094, "reward": 0.1578882932662964, "action": -0.8137645125389099}
{"mode": "train", "epochs": 4, "timestep": 6426, "ep_reward": 241.6270751953125, "reward": 0.2999446988105774, "action": -0.457283079624176}
{"mode": "train", "epochs": 4, "timestep": 6427, "ep_reward": 242.0694122314453, "reward": 0.4423409104347229, "action": -0.4873018264770508}
{"mode": "train", "epochs": 4, "timestep": 6428, "ep_reward": 242.6390838623047, "reward": 0.5696728229522705, "action": -0.9887617230415344}
{"mode": "train", "epochs": 4, "timestep": 6429, "ep_reward": 243.31011962890625, "reward": 0.6710402965545654, "action": -0.9100189208984375}
{"mode": "train", "epochs": 4, "timestep": 6430, "ep_reward": 244.06163024902344, "reward": 0.7515037059783936, "action": -0.7889163494110107}
{"mode": "train", "epochs": 4, "timestep": 6431, "ep_reward": 244.87359619140625, "reward": 0.8119689226150513, "action": -0.38600683212280273}
{"mode": "train", "epochs": 4, "timestep": 6432, "ep_reward": 245.7303924560547, "reward": 0.8567942976951599, "action": -0.5659482479095459}
{"mode": "train", "epochs": 4, "timestep": 6433, "ep_reward": 246.6143035888672, "reward": 0.8839097619056702, "action": -0.22987449169158936}
{"mode": "train", "epochs": 4, "timestep": 6434, "ep_reward": 247.51393127441406, "reward": 0.8996307849884033, "action": -1.369844675064087}
{"mode": "train", "epochs": 4, "timestep": 6435, "ep_reward": 248.40829467773438, "reward": 0.8943634033203125, "action": -1.140552043914795}
{"mode": "train", "epochs": 4, "timestep": 6436, "ep_reward": 249.28515625, "reward": 0.8768637776374817, "action": -1.0040050745010376}
{"mode": "train", "epochs": 4, "timestep": 6437, "ep_reward": 250.1287384033203, "reward": 0.8435813188552856, "action": -0.21636074781417847}
{"mode": "train", "epochs": 4, "timestep": 6438, "ep_reward": 250.92532348632812, "reward": 0.7965824604034424, "action": -1.9765489101409912}
{"mode": "train", "epochs": 4, "timestep": 6439, "ep_reward": 251.62965393066406, "reward": 0.7043288946151733, "action": -0.825292706489563}
{"mode": "train", "epochs": 4, "timestep": 6440, "ep_reward": 252.21824645996094, "reward": 0.588590145111084, "action": -1.8898788690567017}
{"mode": "train", "epochs": 4, "timestep": 6441, "ep_reward": 252.63534545898438, "reward": 0.41710102558135986, "action": -0.8040401935577393}
{"mode": "train", "epochs": 4, "timestep": 6442, "ep_reward": 252.92877197265625, "reward": 0.29342180490493774, "action": -0.20295101404190063}
{"mode": "train", "epochs": 4, "timestep": 6443, "ep_reward": 253.10137939453125, "reward": 0.17260068655014038, "action": -1.1633416414260864}
{"mode": "train", "epochs": 4, "timestep": 6444, "ep_reward": 253.1332244873047, "reward": 0.03184843063354492, "action": -1.2500121593475342}
{"mode": "train", "epochs": 4, "timestep": 6445, "ep_reward": 253.2188720703125, "reward": 0.08564990758895874, "action": -1.3513007164001465}
{"mode": "train", "epochs": 4, "timestep": 6446, "ep_reward": 253.43780517578125, "reward": 0.2189350128173828, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6447, "ep_reward": 253.78477478027344, "reward": 0.3469736576080322, "action": -0.8523532152175903}
{"mode": "train", "epochs": 4, "timestep": 6448, "ep_reward": 254.2682342529297, "reward": 0.4834519028663635, "action": -0.3162110447883606}
{"mode": "train", "epochs": 4, "timestep": 6449, "ep_reward": 254.8759765625, "reward": 0.6077389121055603, "action": -0.8244702816009521}
{"mode": "train", "epochs": 4, "timestep": 6450, "ep_reward": 255.5780029296875, "reward": 0.7020193338394165, "action": -1.735776662826538}
{"mode": "train", "epochs": 4, "timestep": 6451, "ep_reward": 256.3421325683594, "reward": 0.7641405463218689, "action": -1.1082030534744263}
{"mode": "train", "epochs": 4, "timestep": 6452, "ep_reward": 257.15338134765625, "reward": 0.8112583160400391, "action": -0.8937618136405945}
{"mode": "train", "epochs": 4, "timestep": 6453, "ep_reward": 257.993408203125, "reward": 0.8400307893753052, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6454, "ep_reward": 258.8336181640625, "reward": 0.8402040600776672, "action": -0.7775506973266602}
{"mode": "train", "epochs": 4, "timestep": 6455, "ep_reward": 259.665283203125, "reward": 0.8316780924797058, "action": -1.4854099750518799}
{"mode": "train", "epochs": 4, "timestep": 6456, "ep_reward": 260.45904541015625, "reward": 0.7937732934951782, "action": -1.165837049484253}
{"mode": "train", "epochs": 4, "timestep": 6457, "ep_reward": 261.18994140625, "reward": 0.7309074401855469, "action": -1.2659294605255127}
{"mode": "train", "epochs": 4, "timestep": 6458, "ep_reward": 261.8216552734375, "reward": 0.6317174434661865, "action": -0.5990117788314819}
{"mode": "train", "epochs": 4, "timestep": 6459, "ep_reward": 262.32183837890625, "reward": 0.5001827478408813, "action": -0.019964635372161865}
{"mode": "train", "epochs": 4, "timestep": 6460, "ep_reward": 262.69287109375, "reward": 0.37104105949401855, "action": -0.7870718240737915}
{"mode": "train", "epochs": 4, "timestep": 6461, "ep_reward": 262.958251953125, "reward": 0.26536697149276733, "action": -0.5820602774620056}
{"mode": "train", "epochs": 4, "timestep": 6462, "ep_reward": 263.09783935546875, "reward": 0.13958323001861572, "action": -1.3450703620910645}
{"mode": "train", "epochs": 4, "timestep": 6463, "ep_reward": 263.0917053222656, "reward": -0.006123065948486328, "action": -1.4278371334075928}
{"mode": "train", "epochs": 4, "timestep": 6464, "ep_reward": 263.2122802734375, "reward": 0.12057793140411377, "action": -1.1940046548843384}
{"mode": "train", "epochs": 4, "timestep": 6465, "ep_reward": 263.46929931640625, "reward": 0.2570079565048218, "action": -0.9075202941894531}
{"mode": "train", "epochs": 4, "timestep": 6466, "ep_reward": 263.8662109375, "reward": 0.3969067931175232, "action": -0.353900671005249}
{"mode": "train", "epochs": 4, "timestep": 6467, "ep_reward": 264.3984069824219, "reward": 0.5322062373161316, "action": -0.9886094927787781}
{"mode": "train", "epochs": 4, "timestep": 6468, "ep_reward": 265.038818359375, "reward": 0.6404198408126831, "action": -1.0028232336044312}
{"mode": "train", "epochs": 4, "timestep": 6469, "ep_reward": 265.76544189453125, "reward": 0.7266279458999634, "action": -0.8161939382553101}
{"mode": "train", "epochs": 4, "timestep": 6470, "ep_reward": 266.5580139160156, "reward": 0.792565643787384, "action": -1.0812938213348389}
{"mode": "train", "epochs": 4, "timestep": 6471, "ep_reward": 267.39404296875, "reward": 0.836031436920166, "action": -1.4880043268203735}
{"mode": "train", "epochs": 4, "timestep": 6472, "ep_reward": 268.2529602050781, "reward": 0.858920156955719, "action": -0.6376714110374451}
{"mode": "train", "epochs": 4, "timestep": 6473, "ep_reward": 269.125732421875, "reward": 0.8727864027023315, "action": -1.1975044012069702}
{"mode": "train", "epochs": 4, "timestep": 6474, "ep_reward": 269.9918518066406, "reward": 0.8661290407180786, "action": -1.105359673500061}
{"mode": "train", "epochs": 4, "timestep": 6475, "ep_reward": 270.8344421386719, "reward": 0.8425939679145813, "action": -0.8475760221481323}
{"mode": "train", "epochs": 4, "timestep": 6476, "ep_reward": 271.634521484375, "reward": 0.80007004737854, "action": -1.4775406122207642}
{"mode": "train", "epochs": 4, "timestep": 6477, "ep_reward": 272.3583068847656, "reward": 0.7237802743911743, "action": 0.16544735431671143}
{"mode": "train", "epochs": 4, "timestep": 6478, "ep_reward": 272.9917907714844, "reward": 0.6334747076034546, "action": -1.0771981477737427}
{"mode": "train", "epochs": 4, "timestep": 6479, "ep_reward": 273.4818115234375, "reward": 0.49000585079193115, "action": -0.8097911477088928}
{"mode": "train", "epochs": 4, "timestep": 6480, "ep_reward": 273.82269287109375, "reward": 0.3408823609352112, "action": -1.275663137435913}
{"mode": "train", "epochs": 4, "timestep": 6481, "ep_reward": 274.0518798828125, "reward": 0.2291892170906067, "action": -0.33740895986557007}
{"mode": "train", "epochs": 4, "timestep": 6482, "ep_reward": 274.1492919921875, "reward": 0.09741079807281494, "action": 0.07583248615264893}
{"mode": "train", "epochs": 4, "timestep": 6483, "ep_reward": 274.1686706542969, "reward": 0.019391000270843506, "action": -1.667993426322937}
{"mode": "train", "epochs": 4, "timestep": 6484, "ep_reward": 274.3304443359375, "reward": 0.16177809238433838, "action": -1.5868284702301025}
{"mode": "train", "epochs": 4, "timestep": 6485, "ep_reward": 274.6247253417969, "reward": 0.2942890524864197, "action": -0.8644075393676758}
{"mode": "train", "epochs": 4, "timestep": 6486, "ep_reward": 275.0583190917969, "reward": 0.4335835576057434, "action": -0.9383440613746643}
{"mode": "train", "epochs": 4, "timestep": 6487, "ep_reward": 275.6163635253906, "reward": 0.5580425262451172, "action": -1.1493244171142578}
{"mode": "train", "epochs": 4, "timestep": 6488, "ep_reward": 276.27593994140625, "reward": 0.6595851182937622, "action": -1.654703140258789}
{"mode": "train", "epochs": 4, "timestep": 6489, "ep_reward": 277.0095520019531, "reward": 0.7336007952690125, "action": -0.7062219381332397}
{"mode": "train", "epochs": 4, "timestep": 6490, "ep_reward": 277.8043518066406, "reward": 0.7948092818260193, "action": -1.2804217338562012}
{"mode": "train", "epochs": 4, "timestep": 6491, "ep_reward": 278.6339416503906, "reward": 0.8295791149139404, "action": -1.1971243619918823}
{"mode": "train", "epochs": 4, "timestep": 6492, "ep_reward": 279.4801940917969, "reward": 0.8462543487548828, "action": -1.0431214570999146}
{"mode": "train", "epochs": 4, "timestep": 6493, "ep_reward": 280.32598876953125, "reward": 0.845787763595581, "action": -0.5428711175918579}
{"mode": "train", "epochs": 4, "timestep": 6494, "ep_reward": 281.15618896484375, "reward": 0.8301926851272583, "action": -1.5207513570785522}
{"mode": "train", "epochs": 4, "timestep": 6495, "ep_reward": 281.9382629394531, "reward": 0.7820608019828796, "action": -1.2608411312103271}
{"mode": "train", "epochs": 4, "timestep": 6496, "ep_reward": 282.644775390625, "reward": 0.7065157294273376, "action": -1.810222864151001}
{"mode": "train", "epochs": 4, "timestep": 6497, "ep_reward": 283.2307434082031, "reward": 0.585978090763092, "action": -1.0507434606552124}
{"mode": "train", "epochs": 4, "timestep": 6498, "ep_reward": 283.6614074707031, "reward": 0.43067920207977295, "action": -0.7462469339370728}
{"mode": "train", "epochs": 4, "timestep": 6499, "ep_reward": 283.9924011230469, "reward": 0.3309985399246216, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6500, "ep_reward": 284.20989990234375, "reward": 0.2174903154373169, "action": -1.1149406433105469}
{"mode": "train", "epochs": 4, "timestep": 6501, "ep_reward": 284.2935485839844, "reward": 0.08363795280456543, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6502, "ep_reward": 284.3273620605469, "reward": 0.03381145000457764, "action": -1.2650902271270752}
{"mode": "train", "epochs": 4, "timestep": 6503, "ep_reward": 284.5017395019531, "reward": 0.17437124252319336, "action": -0.5056443214416504}
{"mode": "train", "epochs": 4, "timestep": 6504, "ep_reward": 284.8221130371094, "reward": 0.32037442922592163, "action": -1.550581932067871}
{"mode": "train", "epochs": 4, "timestep": 6505, "ep_reward": 285.2701721191406, "reward": 0.4480661153793335, "action": -1.1421012878417969}
{"mode": "train", "epochs": 4, "timestep": 6506, "ep_reward": 285.83819580078125, "reward": 0.5680325627326965, "action": -1.0010377168655396}
{"mode": "train", "epochs": 4, "timestep": 6507, "ep_reward": 286.507568359375, "reward": 0.6693769693374634, "action": -0.39402949810028076}
{"mode": "train", "epochs": 4, "timestep": 6508, "ep_reward": 287.2610778808594, "reward": 0.7535210251808167, "action": -1.1000075340270996}
{"mode": "train", "epochs": 4, "timestep": 6509, "ep_reward": 288.06927490234375, "reward": 0.8082035183906555, "action": -1.7192087173461914}
{"mode": "train", "epochs": 4, "timestep": 6510, "ep_reward": 288.9078063964844, "reward": 0.8385206460952759, "action": -1.2047333717346191}
{"mode": "train", "epochs": 4, "timestep": 6511, "ep_reward": 289.763671875, "reward": 0.8558680415153503, "action": -1.4447053670883179}
{"mode": "train", "epochs": 4, "timestep": 6512, "ep_reward": 290.6175842285156, "reward": 0.8539155721664429, "action": -0.10608696937561035}
{"mode": "train", "epochs": 4, "timestep": 6513, "ep_reward": 291.4631652832031, "reward": 0.8455815315246582, "action": -0.9196316003799438}
{"mode": "train", "epochs": 4, "timestep": 6514, "ep_reward": 292.27239990234375, "reward": 0.8092319369316101, "action": -1.9003981351852417}
{"mode": "train", "epochs": 4, "timestep": 6515, "ep_reward": 293.0084228515625, "reward": 0.7360165119171143, "action": -1.6735118627548218}
{"mode": "train", "epochs": 4, "timestep": 6516, "ep_reward": 293.6374206542969, "reward": 0.6289864778518677, "action": -1.1029311418533325}
{"mode": "train", "epochs": 4, "timestep": 6517, "ep_reward": 294.1241760253906, "reward": 0.48676884174346924, "action": -0.7046891450881958}
{"mode": "train", "epochs": 4, "timestep": 6518, "ep_reward": 294.4828186035156, "reward": 0.35863441228866577, "action": -0.5888259410858154}
{"mode": "train", "epochs": 4, "timestep": 6519, "ep_reward": 294.73321533203125, "reward": 0.2504008412361145, "action": -0.23658740520477295}
{"mode": "train", "epochs": 4, "timestep": 6520, "ep_reward": 294.85528564453125, "reward": 0.12208133935928345, "action": -1.0727319717407227}
{"mode": "train", "epochs": 4, "timestep": 6521, "ep_reward": 294.84759521484375, "reward": -0.0076885223388671875, "action": -0.5119147300720215}
{"mode": "train", "epochs": 4, "timestep": 6522, "ep_reward": 294.98565673828125, "reward": 0.13805735111236572, "action": -1.6732735633850098}
{"mode": "train", "epochs": 4, "timestep": 6523, "ep_reward": 295.254638671875, "reward": 0.268968403339386, "action": -0.804682731628418}
{"mode": "train", "epochs": 4, "timestep": 6524, "ep_reward": 295.6651611328125, "reward": 0.41051608324050903, "action": -0.6661025881767273}
{"mode": "train", "epochs": 4, "timestep": 6525, "ep_reward": 296.2062072753906, "reward": 0.5410439372062683, "action": -1.0294288396835327}
{"mode": "train", "epochs": 4, "timestep": 6526, "ep_reward": 296.8534240722656, "reward": 0.6472029685974121, "action": -1.3073186874389648}
{"mode": "train", "epochs": 4, "timestep": 6527, "ep_reward": 297.5814208984375, "reward": 0.7279875874519348, "action": -1.802417516708374}
{"mode": "train", "epochs": 4, "timestep": 6528, "ep_reward": 298.3638916015625, "reward": 0.7824798822402954, "action": -0.49911272525787354}
{"mode": "train", "epochs": 4, "timestep": 6529, "ep_reward": 299.1923828125, "reward": 0.828487753868103, "action": -1.7515486478805542}
{"mode": "train", "epochs": 4, "timestep": 6530, "ep_reward": 300.03656005859375, "reward": 0.8441725969314575, "action": -0.6809052228927612}
{"mode": "train", "epochs": 4, "timestep": 6531, "ep_reward": 300.8876953125, "reward": 0.8511377573013306, "action": -1.1159347295761108}
{"mode": "train", "epochs": 4, "timestep": 6532, "ep_reward": 301.72283935546875, "reward": 0.8351430892944336, "action": -0.9398715496063232}
{"mode": "train", "epochs": 4, "timestep": 6533, "ep_reward": 302.52166748046875, "reward": 0.7988406419754028, "action": -0.9789424538612366}
{"mode": "train", "epochs": 4, "timestep": 6534, "ep_reward": 303.25689697265625, "reward": 0.7352406978607178, "action": -0.4521949887275696}
{"mode": "train", "epochs": 4, "timestep": 6535, "ep_reward": 303.90185546875, "reward": 0.6449609994888306, "action": -0.7723393440246582}
{"mode": "train", "epochs": 4, "timestep": 6536, "ep_reward": 304.4142150878906, "reward": 0.5123451948165894, "action": -0.6472859382629395}
{"mode": "train", "epochs": 4, "timestep": 6537, "ep_reward": 304.77923583984375, "reward": 0.36502957344055176, "action": -1.899611234664917}
{"mode": "train", "epochs": 4, "timestep": 6538, "ep_reward": 305.03753662109375, "reward": 0.25831449031829834, "action": -0.8144932389259338}
{"mode": "train", "epochs": 4, "timestep": 6539, "ep_reward": 305.1689147949219, "reward": 0.1313742995262146, "action": -1.1534714698791504}
{"mode": "train", "epochs": 4, "timestep": 6540, "ep_reward": 305.1534118652344, "reward": -0.01549375057220459, "action": -0.9226444959640503}
{"mode": "train", "epochs": 4, "timestep": 6541, "ep_reward": 305.2823181152344, "reward": 0.12891322374343872, "action": -1.1468294858932495}
{"mode": "train", "epochs": 4, "timestep": 6542, "ep_reward": 305.54840087890625, "reward": 0.2660874128341675, "action": -1.3275725841522217}
{"mode": "train", "epochs": 4, "timestep": 6543, "ep_reward": 305.94879150390625, "reward": 0.4004003405570984, "action": -0.5125299692153931}
{"mode": "train", "epochs": 4, "timestep": 6544, "ep_reward": 306.4826354980469, "reward": 0.5338380336761475, "action": -1.3424575328826904}
{"mode": "train", "epochs": 4, "timestep": 6545, "ep_reward": 307.1206970214844, "reward": 0.6380765438079834, "action": -0.7789444923400879}
{"mode": "train", "epochs": 4, "timestep": 6546, "ep_reward": 307.8467712402344, "reward": 0.7260695695877075, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6547, "ep_reward": 308.6268005371094, "reward": 0.7800246477127075, "action": -0.8927172422409058}
{"mode": "train", "epochs": 4, "timestep": 6548, "ep_reward": 309.45111083984375, "reward": 0.8243196606636047, "action": -0.6834149360656738}
{"mode": "train", "epochs": 4, "timestep": 6549, "ep_reward": 310.30224609375, "reward": 0.8511499166488647, "action": -0.17161434888839722}
{"mode": "train", "epochs": 4, "timestep": 6550, "ep_reward": 311.16680908203125, "reward": 0.8645756244659424, "action": -1.1569839715957642}
{"mode": "train", "epochs": 4, "timestep": 6551, "ep_reward": 312.01898193359375, "reward": 0.8521672487258911, "action": -1.0486390590667725}
{"mode": "train", "epochs": 4, "timestep": 6552, "ep_reward": 312.8397521972656, "reward": 0.8207836151123047, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6553, "ep_reward": 313.5943298339844, "reward": 0.7545673847198486, "action": -0.659712016582489}
{"mode": "train", "epochs": 4, "timestep": 6554, "ep_reward": 314.2647399902344, "reward": 0.6704142689704895, "action": -0.49432581663131714}
{"mode": "train", "epochs": 4, "timestep": 6555, "ep_reward": 314.8162841796875, "reward": 0.5515319108963013, "action": -1.1495946645736694}
{"mode": "train", "epochs": 4, "timestep": 6556, "ep_reward": 315.2039489746094, "reward": 0.3876549005508423, "action": -0.42387545108795166}
{"mode": "train", "epochs": 4, "timestep": 6557, "ep_reward": 315.4893798828125, "reward": 0.2854164242744446, "action": -1.213035225868225}
{"mode": "train", "epochs": 4, "timestep": 6558, "ep_reward": 315.6527404785156, "reward": 0.1633511185646057, "action": 0.05590224266052246}
{"mode": "train", "epochs": 4, "timestep": 6559, "ep_reward": 315.6739196777344, "reward": 0.021190106868743896, "action": -0.2745630145072937}
{"mode": "train", "epochs": 4, "timestep": 6560, "ep_reward": 315.7697448730469, "reward": 0.0958329439163208, "action": -0.9736693501472473}
{"mode": "train", "epochs": 4, "timestep": 6561, "ep_reward": 316.00408935546875, "reward": 0.23434215784072876, "action": -0.4876316785812378}
{"mode": "train", "epochs": 4, "timestep": 6562, "ep_reward": 316.3838195800781, "reward": 0.37974119186401367, "action": -0.35003185272216797}
{"mode": "train", "epochs": 4, "timestep": 6563, "ep_reward": 316.9000549316406, "reward": 0.516234278678894, "action": -0.715331494808197}
{"mode": "train", "epochs": 4, "timestep": 6564, "ep_reward": 317.5299377441406, "reward": 0.6298872232437134, "action": -0.5232561826705933}
{"mode": "train", "epochs": 4, "timestep": 6565, "ep_reward": 318.2532653808594, "reward": 0.7233142256736755, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6566, "ep_reward": 319.0350646972656, "reward": 0.781790018081665, "action": -0.5830998420715332}
{"mode": "train", "epochs": 4, "timestep": 6567, "ep_reward": 319.8692932128906, "reward": 0.8342230319976807, "action": -0.3662075996398926}
{"mode": "train", "epochs": 4, "timestep": 6568, "ep_reward": 320.7397155761719, "reward": 0.8704243898391724, "action": 0.2786226272583008}
{"mode": "train", "epochs": 4, "timestep": 6569, "ep_reward": 321.6358337402344, "reward": 0.8961303234100342, "action": -0.02209550142288208}
{"mode": "train", "epochs": 4, "timestep": 6570, "ep_reward": 322.5421447753906, "reward": 0.906300961971283, "action": -1.3325555324554443}
{"mode": "train", "epochs": 4, "timestep": 6571, "ep_reward": 323.43707275390625, "reward": 0.8949231505393982, "action": -0.833884060382843}
{"mode": "train", "epochs": 4, "timestep": 6572, "ep_reward": 324.31024169921875, "reward": 0.8731684684753418, "action": -0.5714811682701111}
{"mode": "train", "epochs": 4, "timestep": 6573, "ep_reward": 325.1466064453125, "reward": 0.8363695740699768, "action": -1.544769048690796}
{"mode": "train", "epochs": 4, "timestep": 6574, "ep_reward": 325.9144287109375, "reward": 0.7678270936012268, "action": -0.6879439353942871}
{"mode": "train", "epochs": 4, "timestep": 6575, "ep_reward": 326.59228515625, "reward": 0.6778637766838074, "action": -1.7571183443069458}
{"mode": "train", "epochs": 4, "timestep": 6576, "ep_reward": 327.1302795410156, "reward": 0.5379890203475952, "action": -0.5849501490592957}
{"mode": "train", "epochs": 4, "timestep": 6577, "ep_reward": 327.5035400390625, "reward": 0.37326931953430176, "action": -1.2711095809936523}
{"mode": "train", "epochs": 4, "timestep": 6578, "ep_reward": 327.7566223144531, "reward": 0.2530743479728699, "action": -1.4066606760025024}
{"mode": "train", "epochs": 4, "timestep": 6579, "ep_reward": 327.8819274902344, "reward": 0.12531274557113647, "action": -1.311870813369751}
{"mode": "train", "epochs": 4, "timestep": 6580, "ep_reward": 327.8704528808594, "reward": -0.011483907699584961, "action": -1.3593404293060303}
{"mode": "train", "epochs": 4, "timestep": 6581, "ep_reward": 328.00543212890625, "reward": 0.1349758505821228, "action": -0.7352203726768494}
{"mode": "train", "epochs": 4, "timestep": 6582, "ep_reward": 328.2828674316406, "reward": 0.2774479389190674, "action": -1.0054765939712524}
{"mode": "train", "epochs": 4, "timestep": 6583, "ep_reward": 328.6971435546875, "reward": 0.4142657518386841, "action": -1.1876846551895142}
{"mode": "train", "epochs": 4, "timestep": 6584, "ep_reward": 329.23486328125, "reward": 0.5377339124679565, "action": -0.8113851547241211}
{"mode": "train", "epochs": 4, "timestep": 6585, "ep_reward": 329.88165283203125, "reward": 0.6467950344085693, "action": -1.3363745212554932}
{"mode": "train", "epochs": 4, "timestep": 6586, "ep_reward": 330.60968017578125, "reward": 0.7280413508415222, "action": -1.0876291990280151}
{"mode": "train", "epochs": 4, "timestep": 6587, "ep_reward": 331.3998107910156, "reward": 0.7901381850242615, "action": -0.9225578904151917}
{"mode": "train", "epochs": 4, "timestep": 6588, "ep_reward": 332.23321533203125, "reward": 0.8334070444107056, "action": -1.2132548093795776}
{"mode": "train", "epochs": 4, "timestep": 6589, "ep_reward": 333.0893249511719, "reward": 0.8561081886291504, "action": -0.8669832348823547}
{"mode": "train", "epochs": 4, "timestep": 6590, "ep_reward": 333.954345703125, "reward": 0.8650320768356323, "action": -0.1370300054550171}
{"mode": "train", "epochs": 4, "timestep": 6591, "ep_reward": 334.81781005859375, "reward": 0.8634591698646545, "action": -1.1346518993377686}
{"mode": "train", "epochs": 4, "timestep": 6592, "ep_reward": 335.6529846191406, "reward": 0.8351710438728333, "action": -0.7664563059806824}
{"mode": "train", "epochs": 4, "timestep": 6593, "ep_reward": 336.4409484863281, "reward": 0.7879523038864136, "action": -1.6158905029296875}
{"mode": "train", "epochs": 4, "timestep": 6594, "ep_reward": 337.143798828125, "reward": 0.7028582692146301, "action": -1.7083619832992554}
{"mode": "train", "epochs": 4, "timestep": 6595, "ep_reward": 337.7216796875, "reward": 0.5778683423995972, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6596, "ep_reward": 338.12762451171875, "reward": 0.4059346914291382, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6597, "ep_reward": 338.4356994628906, "reward": 0.3080641031265259, "action": -1.0829955339431763}
{"mode": "train", "epochs": 4, "timestep": 6598, "ep_reward": 338.625732421875, "reward": 0.1900259256362915, "action": -1.0185446739196777}
{"mode": "train", "epochs": 4, "timestep": 6599, "ep_reward": 338.6775817871094, "reward": 0.051838457584381104, "action": -1.8162363767623901}
{"mode": "train", "epochs": 4, "timestep": 6600, "ep_reward": 338.74371337890625, "reward": 0.06614148616790771, "action": -1.5165220499038696}
{"mode": "train", "epochs": 4, "timestep": 6601, "ep_reward": 338.9458923339844, "reward": 0.20219141244888306, "action": -1.804076910018921}
{"mode": "train", "epochs": 4, "timestep": 6602, "ep_reward": 339.2782897949219, "reward": 0.3324089050292969, "action": -1.8480896949768066}
{"mode": "train", "epochs": 4, "timestep": 6603, "ep_reward": 339.7359924316406, "reward": 0.45769834518432617, "action": -0.8130354881286621}
{"mode": "train", "epochs": 4, "timestep": 6604, "ep_reward": 340.3168029785156, "reward": 0.5808130502700806, "action": -0.7144018411636353}
{"mode": "train", "epochs": 4, "timestep": 6605, "ep_reward": 340.9984436035156, "reward": 0.6816397905349731, "action": -0.18150806427001953}
{"mode": "train", "epochs": 4, "timestep": 6606, "ep_reward": 341.76104736328125, "reward": 0.7626125812530518, "action": -0.7192976474761963}
{"mode": "train", "epochs": 4, "timestep": 6607, "ep_reward": 342.5755615234375, "reward": 0.8145100474357605, "action": -1.221812129020691}
{"mode": "train", "epochs": 4, "timestep": 6608, "ep_reward": 343.41754150390625, "reward": 0.841975212097168, "action": -0.45594191551208496}
{"mode": "train", "epochs": 4, "timestep": 6609, "ep_reward": 344.2755126953125, "reward": 0.857981264591217, "action": -1.1198797225952148}
{"mode": "train", "epochs": 4, "timestep": 6610, "ep_reward": 345.1258850097656, "reward": 0.8503845930099487, "action": -0.505358874797821}
{"mode": "train", "epochs": 4, "timestep": 6611, "ep_reward": 345.9549560546875, "reward": 0.8290711641311646, "action": 0.005304932594299316}
{"mode": "train", "epochs": 4, "timestep": 6612, "ep_reward": 346.74591064453125, "reward": 0.7909492254257202, "action": -0.9986891150474548}
{"mode": "train", "epochs": 4, "timestep": 6613, "ep_reward": 347.4614562988281, "reward": 0.7155485153198242, "action": -1.1461825370788574}
{"mode": "train", "epochs": 4, "timestep": 6614, "ep_reward": 348.064697265625, "reward": 0.6032499074935913, "action": -0.5650553107261658}
{"mode": "train", "epochs": 4, "timestep": 6615, "ep_reward": 348.52325439453125, "reward": 0.4585442543029785, "action": -0.873226523399353}
{"mode": "train", "epochs": 4, "timestep": 6616, "ep_reward": 348.84710693359375, "reward": 0.3238637447357178, "action": -1.5098233222961426}
{"mode": "train", "epochs": 4, "timestep": 6617, "ep_reward": 349.0559997558594, "reward": 0.2089030146598816, "action": -0.7469353675842285}
{"mode": "train", "epochs": 4, "timestep": 6618, "ep_reward": 349.1297302246094, "reward": 0.07374310493469238, "action": -1.4259159564971924}
{"mode": "train", "epochs": 4, "timestep": 6619, "ep_reward": 349.1739501953125, "reward": 0.044228315353393555, "action": -1.10382080078125}
{"mode": "train", "epochs": 4, "timestep": 6620, "ep_reward": 349.3571472167969, "reward": 0.18320858478546143, "action": -1.7155272960662842}
{"mode": "train", "epochs": 4, "timestep": 6621, "ep_reward": 349.67156982421875, "reward": 0.314413845539093, "action": -1.3512011766433716}
{"mode": "train", "epochs": 4, "timestep": 6622, "ep_reward": 350.1182556152344, "reward": 0.4466986060142517, "action": -1.6789172887802124}
{"mode": "train", "epochs": 4, "timestep": 6623, "ep_reward": 350.6795349121094, "reward": 0.5612860918045044, "action": -0.9021691083908081}
{"mode": "train", "epochs": 4, "timestep": 6624, "ep_reward": 351.3437805175781, "reward": 0.6642508506774902, "action": -0.8351191878318787}
{"mode": "train", "epochs": 4, "timestep": 6625, "ep_reward": 352.08697509765625, "reward": 0.7432081699371338, "action": -0.8625888228416443}
{"mode": "train", "epochs": 4, "timestep": 6626, "ep_reward": 352.8851013183594, "reward": 0.7981335520744324, "action": -0.9628377556800842}
{"mode": "train", "epochs": 4, "timestep": 6627, "ep_reward": 353.71588134765625, "reward": 0.8307840824127197, "action": -0.6838673949241638}
{"mode": "train", "epochs": 4, "timestep": 6628, "ep_reward": 354.5622253417969, "reward": 0.8463476896286011, "action": -1.4050946235656738}
{"mode": "train", "epochs": 4, "timestep": 6629, "ep_reward": 355.39825439453125, "reward": 0.8360280990600586, "action": -1.5891696214675903}
{"mode": "train", "epochs": 4, "timestep": 6630, "ep_reward": 356.2001647949219, "reward": 0.8018980622291565, "action": -1.2746543884277344}
{"mode": "train", "epochs": 4, "timestep": 6631, "ep_reward": 356.9438171386719, "reward": 0.7436611652374268, "action": -0.8424455523490906}
{"mode": "train", "epochs": 4, "timestep": 6632, "ep_reward": 357.600830078125, "reward": 0.657018780708313, "action": -0.750763475894928}
{"mode": "train", "epochs": 4, "timestep": 6633, "ep_reward": 358.1331481933594, "reward": 0.5323295593261719, "action": -0.7871519923210144}
{"mode": "train", "epochs": 4, "timestep": 6634, "ep_reward": 358.5226745605469, "reward": 0.38953697681427, "action": -0.8548537492752075}
{"mode": "train", "epochs": 4, "timestep": 6635, "ep_reward": 358.81048583984375, "reward": 0.2878141403198242, "action": -0.665236234664917}
{"mode": "train", "epochs": 4, "timestep": 6636, "ep_reward": 358.9764404296875, "reward": 0.1659536361694336, "action": -1.5380501747131348}
{"mode": "train", "epochs": 4, "timestep": 6637, "ep_reward": 359.0007629394531, "reward": 0.024314403533935547, "action": -0.8711569309234619}
{"mode": "train", "epochs": 4, "timestep": 6638, "ep_reward": 359.0936279296875, "reward": 0.09285575151443481, "action": -1.0763778686523438}
{"mode": "train", "epochs": 4, "timestep": 6639, "ep_reward": 359.323486328125, "reward": 0.22986572980880737, "action": -1.531738042831421}
{"mode": "train", "epochs": 4, "timestep": 6640, "ep_reward": 359.6861267089844, "reward": 0.3626534938812256, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6641, "ep_reward": 360.1691589355469, "reward": 0.48303788900375366, "action": -0.4756113886833191}
{"mode": "train", "epochs": 4, "timestep": 6642, "ep_reward": 360.77490234375, "reward": 0.6057302951812744, "action": -0.47948843240737915}
{"mode": "train", "epochs": 4, "timestep": 6643, "ep_reward": 361.47869873046875, "reward": 0.7037860155105591, "action": -0.6145187020301819}
{"mode": "train", "epochs": 4, "timestep": 6644, "ep_reward": 362.25445556640625, "reward": 0.7757543325424194, "action": -0.48566752672195435}
{"mode": "train", "epochs": 4, "timestep": 6645, "ep_reward": 363.0810852050781, "reward": 0.8266338109970093, "action": -0.8278868198394775}
{"mode": "train", "epochs": 4, "timestep": 6646, "ep_reward": 363.9363708496094, "reward": 0.8552934527397156, "action": -0.44729888439178467}
{"mode": "train", "epochs": 4, "timestep": 6647, "ep_reward": 364.8066101074219, "reward": 0.8702359199523926, "action": -0.17716670036315918}
{"mode": "train", "epochs": 4, "timestep": 6648, "ep_reward": 365.67779541015625, "reward": 0.871198296546936, "action": -1.6791361570358276}
{"mode": "train", "epochs": 4, "timestep": 6649, "ep_reward": 366.52001953125, "reward": 0.8422322869300842, "action": -0.4579940438270569}
{"mode": "train", "epochs": 4, "timestep": 6650, "ep_reward": 367.3231506347656, "reward": 0.8031407594680786, "action": -0.48989367485046387}
{"mode": "train", "epochs": 4, "timestep": 6651, "ep_reward": 368.0616760253906, "reward": 0.7385305166244507, "action": -1.042257308959961}
{"mode": "train", "epochs": 4, "timestep": 6652, "ep_reward": 368.6971435546875, "reward": 0.6354796290397644, "action": -1.6833465099334717}
{"mode": "train", "epochs": 4, "timestep": 6653, "ep_reward": 369.18060302734375, "reward": 0.48344987630844116, "action": -0.15809941291809082}
{"mode": "train", "epochs": 4, "timestep": 6654, "ep_reward": 369.5216369628906, "reward": 0.34103941917419434, "action": -1.4171802997589111}
{"mode": "train", "epochs": 4, "timestep": 6655, "ep_reward": 369.75091552734375, "reward": 0.22927451133728027, "action": -1.4996082782745361}
{"mode": "train", "epochs": 4, "timestep": 6656, "ep_reward": 369.8485412597656, "reward": 0.09762901067733765, "action": -0.7684732675552368}
{"mode": "train", "epochs": 4, "timestep": 6657, "ep_reward": 369.8675842285156, "reward": 0.019041061401367188, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6658, "ep_reward": 370.0290832519531, "reward": 0.16149014234542847, "action": -1.8220255374908447}
{"mode": "train", "epochs": 4, "timestep": 6659, "ep_reward": 370.32000732421875, "reward": 0.29091912508010864, "action": -1.7239197492599487}
{"mode": "train", "epochs": 4, "timestep": 6660, "ep_reward": 370.74029541015625, "reward": 0.4202956557273865, "action": -1.2806395292282104}
{"mode": "train", "epochs": 4, "timestep": 6661, "ep_reward": 371.28350830078125, "reward": 0.5432140827178955, "action": -1.5367505550384521}
{"mode": "train", "epochs": 4, "timestep": 6662, "ep_reward": 371.9264221191406, "reward": 0.6429029107093811, "action": -1.2421014308929443}
{"mode": "train", "epochs": 4, "timestep": 6663, "ep_reward": 372.6487731933594, "reward": 0.7223384976387024, "action": -1.3496662378311157}
{"mode": "train", "epochs": 4, "timestep": 6664, "ep_reward": 373.42547607421875, "reward": 0.7766881585121155, "action": -0.6200339794158936}
{"mode": "train", "epochs": 4, "timestep": 6665, "ep_reward": 374.2408752441406, "reward": 0.8153885006904602, "action": -0.8013089299201965}
{"mode": "train", "epochs": 4, "timestep": 6666, "ep_reward": 375.0716552734375, "reward": 0.8307920694351196, "action": -0.24387747049331665}
{"mode": "train", "epochs": 4, "timestep": 6667, "ep_reward": 375.90234375, "reward": 0.8306846618652344, "action": -0.8052918910980225}
{"mode": "train", "epochs": 4, "timestep": 6668, "ep_reward": 376.7055358886719, "reward": 0.8031817674636841, "action": -0.942025363445282}
{"mode": "train", "epochs": 4, "timestep": 6669, "ep_reward": 377.45367431640625, "reward": 0.7481483817100525, "action": -0.10800963640213013}
{"mode": "train", "epochs": 4, "timestep": 6670, "ep_reward": 378.1251525878906, "reward": 0.6714646816253662, "action": 0.0009617805480957031}
{"mode": "train", "epochs": 4, "timestep": 6671, "ep_reward": 378.6862487792969, "reward": 0.5611042380332947, "action": -1.0220087766647339}
{"mode": "train", "epochs": 4, "timestep": 6672, "ep_reward": 379.0826110839844, "reward": 0.396356999874115, "action": -0.8061211109161377}
{"mode": "train", "epochs": 4, "timestep": 6673, "ep_reward": 379.37506103515625, "reward": 0.29246217012405396, "action": -1.1548652648925781}
{"mode": "train", "epochs": 4, "timestep": 6674, "ep_reward": 379.5466613769531, "reward": 0.17160850763320923, "action": -0.8185194730758667}
{"mode": "train", "epochs": 4, "timestep": 6675, "ep_reward": 379.57720947265625, "reward": 0.030540943145751953, "action": -1.8543610572814941}
{"mode": "train", "epochs": 4, "timestep": 6676, "ep_reward": 379.66387939453125, "reward": 0.08665680885314941, "action": -1.9419686794281006}
{"mode": "train", "epochs": 4, "timestep": 6677, "ep_reward": 379.884033203125, "reward": 0.22014039754867554, "action": -0.4612455368041992}
{"mode": "train", "epochs": 4, "timestep": 6678, "ep_reward": 380.2511291503906, "reward": 0.3671020269393921, "action": -1.543750286102295}
{"mode": "train", "epochs": 4, "timestep": 6679, "ep_reward": 380.7427978515625, "reward": 0.4916686415672302, "action": -0.23283177614212036}
{"mode": "train", "epochs": 4, "timestep": 6680, "ep_reward": 381.3579406738281, "reward": 0.6151323318481445, "action": -1.0259652137756348}
{"mode": "train", "epochs": 4, "timestep": 6681, "ep_reward": 382.06451416015625, "reward": 0.7065646648406982, "action": -0.972708523273468}
{"mode": "train", "epochs": 4, "timestep": 6682, "ep_reward": 382.8406677246094, "reward": 0.7761667370796204, "action": -0.7978262901306152}
{"mode": "train", "epochs": 4, "timestep": 6683, "ep_reward": 383.66705322265625, "reward": 0.8263906836509705, "action": -1.245949387550354}
{"mode": "train", "epochs": 4, "timestep": 6684, "ep_reward": 384.5214538574219, "reward": 0.8544109463691711, "action": -0.9204587340354919}
{"mode": "train", "epochs": 4, "timestep": 6685, "ep_reward": 385.39019775390625, "reward": 0.8687466979026794, "action": -0.3020150065422058}
{"mode": "train", "epochs": 4, "timestep": 6686, "ep_reward": 386.2623596191406, "reward": 0.8721568584442139, "action": -1.4626500606536865}
{"mode": "train", "epochs": 4, "timestep": 6687, "ep_reward": 387.1112365722656, "reward": 0.848883867263794, "action": -1.3973238468170166}
{"mode": "train", "epochs": 4, "timestep": 6688, "ep_reward": 387.9162292480469, "reward": 0.8049896955490112, "action": -1.269910454750061}
{"mode": "train", "epochs": 4, "timestep": 6689, "ep_reward": 388.6514892578125, "reward": 0.7352452278137207, "action": -0.6970962285995483}
{"mode": "train", "epochs": 4, "timestep": 6690, "ep_reward": 389.29010009765625, "reward": 0.6386005878448486, "action": -1.3378044366836548}
{"mode": "train", "epochs": 4, "timestep": 6691, "ep_reward": 389.7839660644531, "reward": 0.4938508868217468, "action": -1.5774013996124268}
{"mode": "train", "epochs": 4, "timestep": 6692, "ep_reward": 390.1361999511719, "reward": 0.352239727973938, "action": -0.5659000873565674}
{"mode": "train", "epochs": 4, "timestep": 6693, "ep_reward": 390.3786926269531, "reward": 0.24249780178070068, "action": -1.862336277961731}
{"mode": "train", "epochs": 4, "timestep": 6694, "ep_reward": 390.49176025390625, "reward": 0.11307311058044434, "action": -1.2451807260513306}
{"mode": "train", "epochs": 4, "timestep": 6695, "ep_reward": 390.4941101074219, "reward": 0.0023640990257263184, "action": -0.28459030389785767}
{"mode": "train", "epochs": 4, "timestep": 6696, "ep_reward": 390.6410217285156, "reward": 0.14690148830413818, "action": -1.1226259469985962}
{"mode": "train", "epochs": 4, "timestep": 6697, "ep_reward": 390.9258728027344, "reward": 0.284851610660553, "action": -1.037902593612671}
{"mode": "train", "epochs": 4, "timestep": 6698, "ep_reward": 391.3474426269531, "reward": 0.4215834140777588, "action": -1.6562557220458984}
{"mode": "train", "epochs": 4, "timestep": 6699, "ep_reward": 391.88665771484375, "reward": 0.5392109155654907, "action": -0.8005056381225586}
{"mode": "train", "epochs": 4, "timestep": 6700, "ep_reward": 392.5347900390625, "reward": 0.6481308937072754, "action": -0.8092696666717529}
{"mode": "train", "epochs": 4, "timestep": 6701, "ep_reward": 393.26800537109375, "reward": 0.7332215905189514, "action": -1.1784992218017578}
{"mode": "train", "epochs": 4, "timestep": 6702, "ep_reward": 394.0599365234375, "reward": 0.7919196486473083, "action": -0.42169517278671265}
{"mode": "train", "epochs": 4, "timestep": 6703, "ep_reward": 394.89678955078125, "reward": 0.8368678689002991, "action": -0.5603774189949036}
{"mode": "train", "epochs": 4, "timestep": 6704, "ep_reward": 395.75860595703125, "reward": 0.8618066906929016, "action": -1.0465301275253296}
{"mode": "train", "epochs": 4, "timestep": 6705, "ep_reward": 396.62457275390625, "reward": 0.8659793138504028, "action": -0.6451509594917297}
{"mode": "train", "epochs": 4, "timestep": 6706, "ep_reward": 397.4811706542969, "reward": 0.8565843105316162, "action": -1.6492257118225098}
{"mode": "train", "epochs": 4, "timestep": 6707, "ep_reward": 398.2999267578125, "reward": 0.8187534809112549, "action": -0.49775052070617676}
{"mode": "train", "epochs": 4, "timestep": 6708, "ep_reward": 399.0675354003906, "reward": 0.767601490020752, "action": -1.1555812358856201}
{"mode": "train", "epochs": 4, "timestep": 6709, "ep_reward": 399.7468566894531, "reward": 0.6793204545974731, "action": -0.8828927278518677}
{"mode": "train", "epochs": 4, "timestep": 6710, "ep_reward": 400.3035888671875, "reward": 0.5567251443862915, "action": -1.418199062347412}
{"mode": "train", "epochs": 4, "timestep": 6711, "ep_reward": 400.6913757324219, "reward": 0.3877788782119751, "action": -0.96821528673172}
{"mode": "train", "epochs": 4, "timestep": 6712, "ep_reward": 400.9770812988281, "reward": 0.2857164740562439, "action": 0.08998024463653564}
{"mode": "train", "epochs": 4, "timestep": 6713, "ep_reward": 401.1405944824219, "reward": 0.16350090503692627, "action": -1.240744948387146}
{"mode": "train", "epochs": 4, "timestep": 6714, "ep_reward": 401.1619567871094, "reward": 0.02136099338531494, "action": -1.3670381307601929}
{"mode": "train", "epochs": 4, "timestep": 6715, "ep_reward": 401.257568359375, "reward": 0.09560346603393555, "action": -0.6285996437072754}
{"mode": "train", "epochs": 4, "timestep": 6716, "ep_reward": 401.49591064453125, "reward": 0.23833483457565308, "action": -1.0466161966323853}
{"mode": "train", "epochs": 4, "timestep": 6717, "ep_reward": 401.8719482421875, "reward": 0.3760238289833069, "action": -1.0228279829025269}
{"mode": "train", "epochs": 4, "timestep": 6718, "ep_reward": 402.3774108886719, "reward": 0.5054727792739868, "action": -0.9510261416435242}
{"mode": "train", "epochs": 4, "timestep": 6719, "ep_reward": 402.9961242675781, "reward": 0.6187070608139038, "action": -0.746484637260437}
{"mode": "train", "epochs": 4, "timestep": 6720, "ep_reward": 403.70831298828125, "reward": 0.7121866941452026, "action": -0.562770664691925}
{"mode": "train", "epochs": 4, "timestep": 6721, "ep_reward": 404.49267578125, "reward": 0.7843513488769531, "action": -1.444121241569519}
{"mode": "train", "epochs": 4, "timestep": 6722, "ep_reward": 405.3208312988281, "reward": 0.8281672596931458, "action": -0.8614155650138855}
{"mode": "train", "epochs": 4, "timestep": 6723, "ep_reward": 406.18023681640625, "reward": 0.8594158887863159, "action": -1.0179840326309204}
{"mode": "train", "epochs": 4, "timestep": 6724, "ep_reward": 407.053466796875, "reward": 0.8732327818870544, "action": -1.1840252876281738}
{"mode": "train", "epochs": 4, "timestep": 6725, "ep_reward": 407.9237060546875, "reward": 0.8702340126037598, "action": -0.7491582632064819}
{"mode": "train", "epochs": 4, "timestep": 6726, "ep_reward": 408.7778625488281, "reward": 0.8541482090950012, "action": -1.1143856048583984}
{"mode": "train", "epochs": 4, "timestep": 6727, "ep_reward": 409.5929870605469, "reward": 0.8151297569274902, "action": -0.17424720525741577}
{"mode": "train", "epochs": 4, "timestep": 6728, "ep_reward": 410.354248046875, "reward": 0.761256754398346, "action": -0.9506399035453796}
{"mode": "train", "epochs": 4, "timestep": 6729, "ep_reward": 411.0236511230469, "reward": 0.669387936592102, "action": -0.930651843547821}
{"mode": "train", "epochs": 4, "timestep": 6730, "ep_reward": 411.564208984375, "reward": 0.5405556559562683, "action": -0.5104164481163025}
{"mode": "train", "epochs": 4, "timestep": 6731, "ep_reward": 411.94195556640625, "reward": 0.3777438998222351, "action": -1.7359898090362549}
{"mode": "train", "epochs": 4, "timestep": 6732, "ep_reward": 412.20623779296875, "reward": 0.26427537202835083, "action": -0.6092779636383057}
{"mode": "train", "epochs": 4, "timestep": 6733, "ep_reward": 412.34466552734375, "reward": 0.1384141445159912, "action": 0.3336060047149658}
{"mode": "train", "epochs": 4, "timestep": 6734, "ep_reward": 412.337158203125, "reward": -0.00750279426574707, "action": -0.8683057427406311}
{"mode": "train", "epochs": 4, "timestep": 6735, "ep_reward": 412.458984375, "reward": 0.12181276082992554, "action": -1.541276454925537}
{"mode": "train", "epochs": 4, "timestep": 6736, "ep_reward": 412.7129211425781, "reward": 0.25393450260162354, "action": -1.0037481784820557}
{"mode": "train", "epochs": 4, "timestep": 6737, "ep_reward": 413.10638427734375, "reward": 0.3934672474861145, "action": -0.7180460691452026}
{"mode": "train", "epochs": 4, "timestep": 6738, "ep_reward": 413.6318054199219, "reward": 0.5254279971122742, "action": -1.4845105409622192}
{"mode": "train", "epochs": 4, "timestep": 6739, "ep_reward": 414.26141357421875, "reward": 0.6295985579490662, "action": -0.8887102007865906}
{"mode": "train", "epochs": 4, "timestep": 6740, "ep_reward": 414.9797668457031, "reward": 0.7183511257171631, "action": -0.4782385230064392}
{"mode": "train", "epochs": 4, "timestep": 6741, "ep_reward": 415.7671203613281, "reward": 0.7873676419258118, "action": -1.9409921169281006}
{"mode": "train", "epochs": 4, "timestep": 6742, "ep_reward": 416.5890808105469, "reward": 0.8219696283340454, "action": -1.1355806589126587}
{"mode": "train", "epochs": 4, "timestep": 6743, "ep_reward": 417.4344177246094, "reward": 0.8453473448753357, "action": -1.0404431819915771}
{"mode": "train", "epochs": 4, "timestep": 6744, "ep_reward": 418.2857360839844, "reward": 0.8513070940971375, "action": -1.3666716814041138}
{"mode": "train", "epochs": 4, "timestep": 6745, "ep_reward": 419.12109375, "reward": 0.8353565335273743, "action": -1.2862399816513062}
{"mode": "train", "epochs": 4, "timestep": 6746, "ep_reward": 419.9190368652344, "reward": 0.7979521155357361, "action": -0.5597700476646423}
{"mode": "train", "epochs": 4, "timestep": 6747, "ep_reward": 420.66033935546875, "reward": 0.7413020133972168, "action": -0.6624976396560669}
{"mode": "train", "epochs": 4, "timestep": 6748, "ep_reward": 421.31170654296875, "reward": 0.6513631939888, "action": -1.3620223999023438}
{"mode": "train", "epochs": 4, "timestep": 6749, "ep_reward": 421.8244323730469, "reward": 0.5127339363098145, "action": 0.07066679000854492}
{"mode": "train", "epochs": 4, "timestep": 6750, "ep_reward": 422.1965026855469, "reward": 0.3720782995223999, "action": -1.1273428201675415}
{"mode": "train", "epochs": 4, "timestep": 6751, "ep_reward": 422.463134765625, "reward": 0.26662272214889526, "action": -1.0666731595993042}
{"mode": "train", "epochs": 4, "timestep": 6752, "ep_reward": 422.6042785644531, "reward": 0.14113843441009521, "action": -1.2143745422363281}
{"mode": "train", "epochs": 4, "timestep": 6753, "ep_reward": 422.5999450683594, "reward": -0.004329204559326172, "action": -1.2466986179351807}
{"mode": "train", "epochs": 4, "timestep": 6754, "ep_reward": 422.71893310546875, "reward": 0.11898118257522583, "action": -1.3404693603515625}
{"mode": "train", "epochs": 4, "timestep": 6755, "ep_reward": 422.97247314453125, "reward": 0.2535476088523865, "action": -0.8718447089195251}
{"mode": "train", "epochs": 4, "timestep": 6756, "ep_reward": 423.3667907714844, "reward": 0.39432549476623535, "action": -0.3600153923034668}
{"mode": "train", "epochs": 4, "timestep": 6757, "ep_reward": 423.8968505859375, "reward": 0.5300480723381042, "action": -0.25273776054382324}
{"mode": "train", "epochs": 4, "timestep": 6758, "ep_reward": 424.543212890625, "reward": 0.6463639736175537, "action": -0.5589237213134766}
{"mode": "train", "epochs": 4, "timestep": 6759, "ep_reward": 425.2789001464844, "reward": 0.7356852293014526, "action": -1.4910624027252197}
{"mode": "train", "epochs": 4, "timestep": 6760, "ep_reward": 426.07366943359375, "reward": 0.7947639226913452, "action": -0.5425640344619751}
{"mode": "train", "epochs": 4, "timestep": 6761, "ep_reward": 426.9168395996094, "reward": 0.8431739807128906, "action": -1.0786107778549194}
{"mode": "train", "epochs": 4, "timestep": 6762, "ep_reward": 427.786865234375, "reward": 0.8700333833694458, "action": -1.3292572498321533}
{"mode": "train", "epochs": 4, "timestep": 6763, "ep_reward": 428.6670227050781, "reward": 0.8801642656326294, "action": -1.2139806747436523}
{"mode": "train", "epochs": 4, "timestep": 6764, "ep_reward": 429.5436706542969, "reward": 0.8766375184059143, "action": -0.7770791053771973}
{"mode": "train", "epochs": 4, "timestep": 6765, "ep_reward": 430.4043273925781, "reward": 0.860651433467865, "action": -1.5477149486541748}
{"mode": "train", "epochs": 4, "timestep": 6766, "ep_reward": 431.2229919433594, "reward": 0.8186565637588501, "action": -0.7364599108695984}
{"mode": "train", "epochs": 4, "timestep": 6767, "ep_reward": 431.982666015625, "reward": 0.7596693634986877, "action": -0.02349609136581421}
{"mode": "train", "epochs": 4, "timestep": 6768, "ep_reward": 432.6622314453125, "reward": 0.6795612573623657, "action": 0.21679258346557617}
{"mode": "train", "epochs": 4, "timestep": 6769, "ep_reward": 433.23236083984375, "reward": 0.5701195597648621, "action": -0.3437590003013611}
{"mode": "train", "epochs": 4, "timestep": 6770, "ep_reward": 433.650146484375, "reward": 0.4177996516227722, "action": -0.8226224184036255}
{"mode": "train", "epochs": 4, "timestep": 6771, "ep_reward": 433.9261474609375, "reward": 0.27599549293518066, "action": -0.6522842645645142}
{"mode": "train", "epochs": 4, "timestep": 6772, "ep_reward": 434.0782165527344, "reward": 0.15205657482147217, "action": -1.4390671253204346}
{"mode": "train", "epochs": 4, "timestep": 6773, "ep_reward": 434.0865173339844, "reward": 0.008295834064483643, "action": -0.9359797835350037}
{"mode": "train", "epochs": 4, "timestep": 6774, "ep_reward": 434.1942443847656, "reward": 0.10773265361785889, "action": -0.4035627245903015}
{"mode": "train", "epochs": 4, "timestep": 6775, "ep_reward": 434.44781494140625, "reward": 0.25357478857040405, "action": -1.1414827108383179}
{"mode": "train", "epochs": 4, "timestep": 6776, "ep_reward": 434.83697509765625, "reward": 0.3891518712043762, "action": -0.613514244556427}
{"mode": "train", "epochs": 4, "timestep": 6777, "ep_reward": 435.358642578125, "reward": 0.5216705799102783, "action": -1.1837692260742188}
{"mode": "train", "epochs": 4, "timestep": 6778, "ep_reward": 435.9882507324219, "reward": 0.629613995552063, "action": -0.765437126159668}
{"mode": "train", "epochs": 4, "timestep": 6779, "ep_reward": 436.7088317871094, "reward": 0.7205848097801208, "action": -1.4110990762710571}
{"mode": "train", "epochs": 4, "timestep": 6780, "ep_reward": 437.49237060546875, "reward": 0.7835442423820496, "action": -0.19192564487457275}
{"mode": "train", "epochs": 4, "timestep": 6781, "ep_reward": 438.3296813964844, "reward": 0.8373051881790161, "action": -1.3495796918869019}
{"mode": "train", "epochs": 4, "timestep": 6782, "ep_reward": 439.193115234375, "reward": 0.8634443283081055, "action": -0.78887540102005}
{"mode": "train", "epochs": 4, "timestep": 6783, "ep_reward": 440.0718688964844, "reward": 0.878743588924408, "action": -1.1086978912353516}
{"mode": "train", "epochs": 4, "timestep": 6784, "ep_reward": 440.94842529296875, "reward": 0.8765698075294495, "action": -1.297383189201355}
{"mode": "train", "epochs": 4, "timestep": 6785, "ep_reward": 441.8051452636719, "reward": 0.8567074537277222, "action": -0.5105074644088745}
{"mode": "train", "epochs": 4, "timestep": 6786, "ep_reward": 442.6297912597656, "reward": 0.8246490955352783, "action": -1.0105445384979248}
{"mode": "train", "epochs": 4, "timestep": 6787, "ep_reward": 443.39404296875, "reward": 0.7642425298690796, "action": -1.4435348510742188}
{"mode": "train", "epochs": 4, "timestep": 6788, "ep_reward": 444.0616760253906, "reward": 0.6676478385925293, "action": -1.7893502712249756}
{"mode": "train", "epochs": 4, "timestep": 6789, "ep_reward": 444.58795166015625, "reward": 0.5262828469276428, "action": -0.6753116250038147}
{"mode": "train", "epochs": 4, "timestep": 6790, "ep_reward": 444.95855712890625, "reward": 0.3705955743789673, "action": -1.2778401374816895}
{"mode": "train", "epochs": 4, "timestep": 6791, "ep_reward": 445.22344970703125, "reward": 0.2648804187774658, "action": -0.8748903870582581}
{"mode": "train", "epochs": 4, "timestep": 6792, "ep_reward": 445.3625793457031, "reward": 0.13912814855575562, "action": -0.708964467048645}
{"mode": "train", "epochs": 4, "timestep": 6793, "ep_reward": 445.3558654785156, "reward": -0.006726384162902832, "action": -1.3731496334075928}
{"mode": "train", "epochs": 4, "timestep": 6794, "ep_reward": 445.47705078125, "reward": 0.12118005752563477, "action": -0.6823129653930664}
{"mode": "train", "epochs": 4, "timestep": 6795, "ep_reward": 445.74102783203125, "reward": 0.2639697194099426, "action": -0.9186033606529236}
{"mode": "train", "epochs": 4, "timestep": 6796, "ep_reward": 446.14337158203125, "reward": 0.4023509621620178, "action": -0.8974325656890869}
{"mode": "train", "epochs": 4, "timestep": 6797, "ep_reward": 446.6737060546875, "reward": 0.5303353667259216, "action": -0.6501609086990356}
{"mode": "train", "epochs": 4, "timestep": 6798, "ep_reward": 447.3161315917969, "reward": 0.6424187421798706, "action": -0.8721497058868408}
{"mode": "train", "epochs": 4, "timestep": 6799, "ep_reward": 448.045654296875, "reward": 0.7295336723327637, "action": -1.5775549411773682}
{"mode": "train", "epochs": 4, "timestep": 6800, "ep_reward": 448.8343200683594, "reward": 0.7886710166931152, "action": -0.7130576968193054}
{"mode": "train", "epochs": 4, "timestep": 6801, "ep_reward": 449.6705627441406, "reward": 0.8362433910369873, "action": -0.6789581775665283}
{"mode": "train", "epochs": 4, "timestep": 6802, "ep_reward": 450.5367736816406, "reward": 0.8662040829658508, "action": -0.879535436630249}
{"mode": "train", "epochs": 4, "timestep": 6803, "ep_reward": 451.4156494140625, "reward": 0.878883957862854, "action": -1.0252182483673096}
{"mode": "train", "epochs": 4, "timestep": 6804, "ep_reward": 452.2911376953125, "reward": 0.875487208366394, "action": -0.76079922914505}
{"mode": "train", "epochs": 4, "timestep": 6805, "ep_reward": 453.1492919921875, "reward": 0.85813969373703, "action": -0.914961040019989}
{"mode": "train", "epochs": 4, "timestep": 6806, "ep_reward": 453.9696350097656, "reward": 0.820351779460907, "action": -0.838782548904419}
{"mode": "train", "epochs": 4, "timestep": 6807, "ep_reward": 454.7287902832031, "reward": 0.7591660618782043, "action": -0.6185807585716248}
{"mode": "train", "epochs": 4, "timestep": 6808, "ep_reward": 455.3990478515625, "reward": 0.6702712178230286, "action": -1.0874229669570923}
{"mode": "train", "epochs": 4, "timestep": 6809, "ep_reward": 455.9379577636719, "reward": 0.5389212369918823, "action": -1.0591967105865479}
{"mode": "train", "epochs": 4, "timestep": 6810, "ep_reward": 456.3046569824219, "reward": 0.36669784784317017, "action": -0.5465918183326721}
{"mode": "train", "epochs": 4, "timestep": 6811, "ep_reward": 456.5645751953125, "reward": 0.2599191665649414, "action": -0.3651532530784607}
{"mode": "train", "epochs": 4, "timestep": 6812, "ep_reward": 456.69775390625, "reward": 0.13318264484405518, "action": -1.3592019081115723}
{"mode": "train", "epochs": 4, "timestep": 6813, "ep_reward": 456.6844177246094, "reward": -0.013331174850463867, "action": -0.08269643783569336}
{"mode": "train", "epochs": 4, "timestep": 6814, "ep_reward": 456.8114318847656, "reward": 0.127008855342865, "action": -1.4829497337341309}
{"mode": "train", "epochs": 4, "timestep": 6815, "ep_reward": 457.0713806152344, "reward": 0.25994521379470825, "action": -1.354840874671936}
{"mode": "train", "epochs": 4, "timestep": 6816, "ep_reward": 457.4662170410156, "reward": 0.3948328495025635, "action": -0.4665940999984741}
{"mode": "train", "epochs": 4, "timestep": 6817, "ep_reward": 457.9961853027344, "reward": 0.5299702882766724, "action": -0.0034525394439697266}
{"mode": "train", "epochs": 4, "timestep": 6818, "ep_reward": 458.6451721191406, "reward": 0.6489942669868469, "action": -1.2436574697494507}
{"mode": "train", "epochs": 4, "timestep": 6819, "ep_reward": 459.3760681152344, "reward": 0.7308859825134277, "action": -0.9806224703788757}
{"mode": "train", "epochs": 4, "timestep": 6820, "ep_reward": 460.1698303222656, "reward": 0.7937511801719666, "action": -1.2521944046020508}
{"mode": "train", "epochs": 4, "timestep": 6821, "ep_reward": 461.0042419433594, "reward": 0.8344161510467529, "action": -0.49895524978637695}
{"mode": "train", "epochs": 4, "timestep": 6822, "ep_reward": 461.8680419921875, "reward": 0.8637880086898804, "action": -0.5311808586120605}
{"mode": "train", "epochs": 4, "timestep": 6823, "ep_reward": 462.7446594238281, "reward": 0.8766270875930786, "action": -0.48525726795196533}
{"mode": "train", "epochs": 4, "timestep": 6824, "ep_reward": 463.6191711425781, "reward": 0.8745149970054626, "action": -0.1352885365486145}
{"mode": "train", "epochs": 4, "timestep": 6825, "ep_reward": 464.47857666015625, "reward": 0.8593930602073669, "action": -0.4648182988166809}
{"mode": "train", "epochs": 4, "timestep": 6826, "ep_reward": 465.3017272949219, "reward": 0.8231465816497803, "action": -0.6335629820823669}
{"mode": "train", "epochs": 4, "timestep": 6827, "ep_reward": 466.06390380859375, "reward": 0.7621679902076721, "action": -1.2943243980407715}
{"mode": "train", "epochs": 4, "timestep": 6828, "ep_reward": 466.7275695800781, "reward": 0.6636545062065125, "action": -0.8401707410812378}
{"mode": "train", "epochs": 4, "timestep": 6829, "ep_reward": 467.2605285644531, "reward": 0.5329693555831909, "action": -1.6372125148773193}
{"mode": "train", "epochs": 4, "timestep": 6830, "ep_reward": 467.6185302734375, "reward": 0.3580024242401123, "action": -1.7288079261779785}
{"mode": "train", "epochs": 4, "timestep": 6831, "ep_reward": 467.86834716796875, "reward": 0.24982941150665283, "action": -0.4583510756492615}
{"mode": "train", "epochs": 4, "timestep": 6832, "ep_reward": 467.9898376464844, "reward": 0.1214754581451416, "action": -0.5790455937385559}
{"mode": "train", "epochs": 4, "timestep": 6833, "ep_reward": 467.98284912109375, "reward": -0.0070002079010009766, "action": -1.044057846069336}
{"mode": "train", "epochs": 4, "timestep": 6834, "ep_reward": 468.1215515136719, "reward": 0.13870275020599365, "action": -1.6727936267852783}
{"mode": "train", "epochs": 4, "timestep": 6835, "ep_reward": 468.3910827636719, "reward": 0.26954543590545654, "action": -1.4583748579025269}
{"mode": "train", "epochs": 4, "timestep": 6836, "ep_reward": 468.794189453125, "reward": 0.40309226512908936, "action": -0.32107752561569214}
{"mode": "train", "epochs": 4, "timestep": 6837, "ep_reward": 469.3333435058594, "reward": 0.5391548275947571, "action": -0.7522508502006531}
{"mode": "train", "epochs": 4, "timestep": 6838, "ep_reward": 469.9819641113281, "reward": 0.6486303806304932, "action": -0.8263204097747803}
{"mode": "train", "epochs": 4, "timestep": 6839, "ep_reward": 470.71563720703125, "reward": 0.7336879968643188, "action": -1.7103631496429443}
{"mode": "train", "epochs": 4, "timestep": 6840, "ep_reward": 471.503662109375, "reward": 0.7880173325538635, "action": -1.1480358839035034}
{"mode": "train", "epochs": 4, "timestep": 6841, "ep_reward": 472.33135986328125, "reward": 0.8276833295822144, "action": -1.085307002067566}
{"mode": "train", "epochs": 4, "timestep": 6842, "ep_reward": 473.1804504394531, "reward": 0.8490933179855347, "action": -1.1028878688812256}
{"mode": "train", "epochs": 4, "timestep": 6843, "ep_reward": 474.0327453613281, "reward": 0.8523015975952148, "action": -1.5765376091003418}
{"mode": "train", "epochs": 4, "timestep": 6844, "ep_reward": 474.8649597167969, "reward": 0.8322254419326782, "action": -0.8475683927536011}
{"mode": "train", "epochs": 4, "timestep": 6845, "ep_reward": 475.6615905761719, "reward": 0.7966444492340088, "action": -0.6541409492492676}
{"mode": "train", "epochs": 4, "timestep": 6846, "ep_reward": 476.39788818359375, "reward": 0.736309289932251, "action": -1.4893677234649658}
{"mode": "train", "epochs": 4, "timestep": 6847, "ep_reward": 477.0302734375, "reward": 0.6323713064193726, "action": -0.7341463565826416}
{"mode": "train", "epochs": 4, "timestep": 6848, "ep_reward": 477.52716064453125, "reward": 0.4968997836112976, "action": -1.7163341045379639}
{"mode": "train", "epochs": 4, "timestep": 6849, "ep_reward": 477.8890686035156, "reward": 0.36190587282180786, "action": -0.14798718690872192}
{"mode": "train", "epochs": 4, "timestep": 6850, "ep_reward": 478.143310546875, "reward": 0.25423282384872437, "action": -1.1776143312454224}
{"mode": "train", "epochs": 4, "timestep": 6851, "ep_reward": 478.26995849609375, "reward": 0.12663322687149048, "action": -1.259606122970581}
{"mode": "train", "epochs": 4, "timestep": 6852, "ep_reward": 478.257080078125, "reward": -0.01286613941192627, "action": -0.3280593156814575}
{"mode": "train", "epochs": 4, "timestep": 6853, "ep_reward": 478.3907165527344, "reward": 0.13363611698150635, "action": -1.0804314613342285}
{"mode": "train", "epochs": 4, "timestep": 6854, "ep_reward": 478.6625671386719, "reward": 0.27184027433395386, "action": -0.5981873869895935}
{"mode": "train", "epochs": 4, "timestep": 6855, "ep_reward": 479.07708740234375, "reward": 0.4145315885543823, "action": -0.8547147512435913}
{"mode": "train", "epochs": 4, "timestep": 6856, "ep_reward": 479.61865234375, "reward": 0.5415590405464172, "action": -1.552562952041626}
{"mode": "train", "epochs": 4, "timestep": 6857, "ep_reward": 480.26068115234375, "reward": 0.6420367956161499, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6858, "ep_reward": 480.9781799316406, "reward": 0.7175085544586182, "action": -1.3674508333206177}
{"mode": "train", "epochs": 4, "timestep": 6859, "ep_reward": 481.75640869140625, "reward": 0.778226912021637, "action": -1.1455215215682983}
{"mode": "train", "epochs": 4, "timestep": 6860, "ep_reward": 482.576416015625, "reward": 0.8200188875198364, "action": -0.9386643171310425}
{"mode": "train", "epochs": 4, "timestep": 6861, "ep_reward": 483.4205627441406, "reward": 0.844149649143219, "action": -0.5560957193374634}
{"mode": "train", "epochs": 4, "timestep": 6862, "ep_reward": 484.27374267578125, "reward": 0.8531912565231323, "action": -0.32553422451019287}
{"mode": "train", "epochs": 4, "timestep": 6863, "ep_reward": 485.11962890625, "reward": 0.8458980917930603, "action": -0.5060828924179077}
{"mode": "train", "epochs": 4, "timestep": 6864, "ep_reward": 485.9366455078125, "reward": 0.8170079588890076, "action": -0.8222075700759888}
{"mode": "train", "epochs": 4, "timestep": 6865, "ep_reward": 486.6975402832031, "reward": 0.7608984112739563, "action": -0.1791059970855713}
{"mode": "train", "epochs": 4, "timestep": 6866, "ep_reward": 487.3797912597656, "reward": 0.6822580099105835, "action": -1.5905075073242188}
{"mode": "train", "epochs": 4, "timestep": 6867, "ep_reward": 487.9292297363281, "reward": 0.5494499206542969, "action": -1.6313599348068237}
{"mode": "train", "epochs": 4, "timestep": 6868, "ep_reward": 488.3128662109375, "reward": 0.38362354040145874, "action": -1.4092001914978027}
{"mode": "train", "epochs": 4, "timestep": 6869, "ep_reward": 488.5935363769531, "reward": 0.2806709408760071, "action": -1.0774537324905396}
{"mode": "train", "epochs": 4, "timestep": 6870, "ep_reward": 488.7511291503906, "reward": 0.15760767459869385, "action": -1.454783320426941}
{"mode": "train", "epochs": 4, "timestep": 6871, "ep_reward": 488.7657775878906, "reward": 0.01464158296585083, "action": -1.2355566024780273}
{"mode": "train", "epochs": 4, "timestep": 6872, "ep_reward": 488.8676452636719, "reward": 0.10187697410583496, "action": -0.34378623962402344}
{"mode": "train", "epochs": 4, "timestep": 6873, "ep_reward": 489.1159973144531, "reward": 0.24836695194244385, "action": -0.41822415590286255}
{"mode": "train", "epochs": 4, "timestep": 6874, "ep_reward": 489.5086364746094, "reward": 0.3926471471786499, "action": -0.5513447523117065}
{"mode": "train", "epochs": 4, "timestep": 6875, "ep_reward": 490.033203125, "reward": 0.5245598554611206, "action": -0.612209677696228}
{"mode": "train", "epochs": 4, "timestep": 6876, "ep_reward": 490.6707763671875, "reward": 0.6375865936279297, "action": -1.078230381011963}
{"mode": "train", "epochs": 4, "timestep": 6877, "ep_reward": 491.3954162597656, "reward": 0.7246407270431519, "action": 0.3386741876602173}
{"mode": "train", "epochs": 4, "timestep": 6878, "ep_reward": 492.1983947753906, "reward": 0.8029683828353882, "action": -1.1349575519561768}
{"mode": "train", "epochs": 4, "timestep": 6879, "ep_reward": 493.0470886230469, "reward": 0.848702073097229, "action": -0.7859005928039551}
{"mode": "train", "epochs": 4, "timestep": 6880, "ep_reward": 493.9287109375, "reward": 0.8816277980804443, "action": -1.716245412826538}
{"mode": "train", "epochs": 4, "timestep": 6881, "ep_reward": 494.8236083984375, "reward": 0.8948966860771179, "action": -1.1668508052825928}
{"mode": "train", "epochs": 4, "timestep": 6882, "ep_reward": 495.7237548828125, "reward": 0.9001470804214478, "action": -0.544297456741333}
{"mode": "train", "epochs": 4, "timestep": 6883, "ep_reward": 496.62139892578125, "reward": 0.8976313471794128, "action": -0.3720054626464844}
{"mode": "train", "epochs": 4, "timestep": 6884, "ep_reward": 497.5045471191406, "reward": 0.8831386566162109, "action": -1.5245509147644043}
{"mode": "train", "epochs": 4, "timestep": 6885, "ep_reward": 498.34765625, "reward": 0.8431159257888794, "action": -0.9047434329986572}
{"mode": "train", "epochs": 4, "timestep": 6886, "ep_reward": 499.134033203125, "reward": 0.7863870859146118, "action": -0.9000220894813538}
{"mode": "train", "epochs": 4, "timestep": 6887, "ep_reward": 499.8359069824219, "reward": 0.7018717527389526, "action": -1.1001436710357666}
{"mode": "train", "epochs": 4, "timestep": 6888, "ep_reward": 500.4161071777344, "reward": 0.5801957845687866, "action": -1.0534522533416748}
{"mode": "train", "epochs": 4, "timestep": 6889, "ep_reward": 500.8354187011719, "reward": 0.4193209409713745, "action": -1.179451823234558}
{"mode": "train", "epochs": 4, "timestep": 6890, "ep_reward": 501.1180114746094, "reward": 0.282581627368927, "action": -0.23653584718704224}
{"mode": "train", "epochs": 4, "timestep": 6891, "ep_reward": 501.2778625488281, "reward": 0.15985244512557983, "action": -0.9433048367500305}
{"mode": "train", "epochs": 4, "timestep": 6892, "ep_reward": 501.29498291015625, "reward": 0.017106235027313232, "action": -1.4156227111816406}
{"mode": "train", "epochs": 4, "timestep": 6893, "ep_reward": 501.3945007324219, "reward": 0.09952884912490845, "action": -0.8861003518104553}
{"mode": "train", "epochs": 4, "timestep": 6894, "ep_reward": 501.6336975097656, "reward": 0.23918431997299194, "action": -1.0460151433944702}
{"mode": "train", "epochs": 4, "timestep": 6895, "ep_reward": 502.01116943359375, "reward": 0.3774603605270386, "action": -0.2387915849685669}
{"mode": "train", "epochs": 4, "timestep": 6896, "ep_reward": 502.5272216796875, "reward": 0.5160492658615112, "action": -0.982363760471344}
{"mode": "train", "epochs": 4, "timestep": 6897, "ep_reward": 503.15411376953125, "reward": 0.6268993020057678, "action": -1.7524423599243164}
{"mode": "train", "epochs": 4, "timestep": 6898, "ep_reward": 503.8631591796875, "reward": 0.7090451717376709, "action": -0.5820136666297913}
{"mode": "train", "epochs": 4, "timestep": 6899, "ep_reward": 504.64459228515625, "reward": 0.7814199924468994, "action": -1.117164134979248}
{"mode": "train", "epochs": 4, "timestep": 6900, "ep_reward": 505.4723205566406, "reward": 0.8277341723442078, "action": -1.9220314025878906}
{"mode": "train", "epochs": 4, "timestep": 6901, "ep_reward": 506.32196044921875, "reward": 0.8496469259262085, "action": -0.33958274126052856}
{"mode": "train", "epochs": 4, "timestep": 6902, "ep_reward": 507.19024658203125, "reward": 0.8682863712310791, "action": -0.9458299279212952}
{"mode": "train", "epochs": 4, "timestep": 6903, "ep_reward": 508.0555725097656, "reward": 0.8653168678283691, "action": -1.5042102336883545}
{"mode": "train", "epochs": 4, "timestep": 6904, "ep_reward": 508.895263671875, "reward": 0.8396763205528259, "action": -1.0150679349899292}
{"mode": "train", "epochs": 4, "timestep": 6905, "ep_reward": 509.6918029785156, "reward": 0.7965447902679443, "action": -0.857690691947937}
{"mode": "train", "epochs": 4, "timestep": 6906, "ep_reward": 510.4197692871094, "reward": 0.7279567718505859, "action": -0.36152803897857666}
{"mode": "train", "epochs": 4, "timestep": 6907, "ep_reward": 511.0520935058594, "reward": 0.6323257684707642, "action": -1.66192626953125}
{"mode": "train", "epochs": 4, "timestep": 6908, "ep_reward": 511.5320739746094, "reward": 0.4799874424934387, "action": -1.2265251874923706}
{"mode": "train", "epochs": 4, "timestep": 6909, "ep_reward": 511.87530517578125, "reward": 0.3432367444038391, "action": -0.5632094144821167}
{"mode": "train", "epochs": 4, "timestep": 6910, "ep_reward": 512.107177734375, "reward": 0.23184269666671753, "action": -1.1027873754501343}
{"mode": "train", "epochs": 4, "timestep": 6911, "ep_reward": 512.2077026367188, "reward": 0.1005544662475586, "action": -0.6575387716293335}
{"mode": "train", "epochs": 4, "timestep": 6912, "ep_reward": 512.2237548828125, "reward": 0.016067087650299072, "action": -1.1341434717178345}
{"mode": "train", "epochs": 4, "timestep": 6913, "ep_reward": 512.3826904296875, "reward": 0.1589571237564087, "action": -0.3753901720046997}
{"mode": "train", "epochs": 4, "timestep": 6914, "ep_reward": 512.6890869140625, "reward": 0.3064118027687073, "action": -0.6794086694717407}
{"mode": "train", "epochs": 4, "timestep": 6915, "ep_reward": 513.134033203125, "reward": 0.4449392557144165, "action": -0.9655600786209106}
{"mode": "train", "epochs": 4, "timestep": 6916, "ep_reward": 513.700439453125, "reward": 0.5663949251174927, "action": -1.6574108600616455}
{"mode": "train", "epochs": 4, "timestep": 6917, "ep_reward": 514.362060546875, "reward": 0.6616376638412476, "action": 0.10909855365753174}
{"mode": "train", "epochs": 4, "timestep": 6918, "ep_reward": 515.115234375, "reward": 0.7531455755233765, "action": -1.0139881372451782}
{"mode": "train", "epochs": 4, "timestep": 6919, "ep_reward": 515.9263916015625, "reward": 0.8111599087715149, "action": -1.122692584991455}
{"mode": "train", "epochs": 4, "timestep": 6920, "ep_reward": 516.7762451171875, "reward": 0.8498243093490601, "action": -1.1991015672683716}
{"mode": "train", "epochs": 4, "timestep": 6921, "ep_reward": 517.6481323242188, "reward": 0.8718979954719543, "action": -0.1710321307182312}
{"mode": "train", "epochs": 4, "timestep": 6922, "ep_reward": 518.5353393554688, "reward": 0.8872195482254028, "action": -1.1537020206451416}
{"mode": "train", "epochs": 4, "timestep": 6923, "ep_reward": 519.4157104492188, "reward": 0.8803781867027283, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6924, "ep_reward": 520.2659912109375, "reward": 0.8502663969993591, "action": -0.7747676372528076}
{"mode": "train", "epochs": 4, "timestep": 6925, "ep_reward": 521.0760498046875, "reward": 0.8100447654724121, "action": -1.4135011434555054}
{"mode": "train", "epochs": 4, "timestep": 6926, "ep_reward": 521.8134155273438, "reward": 0.7373743057250977, "action": -1.3855977058410645}
{"mode": "train", "epochs": 4, "timestep": 6927, "ep_reward": 522.4439086914062, "reward": 0.6305097341537476, "action": -0.7516047954559326}
{"mode": "train", "epochs": 4, "timestep": 6928, "ep_reward": 522.935546875, "reward": 0.4916110634803772, "action": -1.7803751230239868}
{"mode": "train", "epochs": 4, "timestep": 6929, "ep_reward": 523.2805786132812, "reward": 0.3450181484222412, "action": -0.15150916576385498}
{"mode": "train", "epochs": 4, "timestep": 6930, "ep_reward": 523.5144653320312, "reward": 0.2338622808456421, "action": -1.6392168998718262}
{"mode": "train", "epochs": 4, "timestep": 6931, "ep_reward": 523.6174926757812, "reward": 0.10302764177322388, "action": -0.4722985029220581}
{"mode": "train", "epochs": 4, "timestep": 6932, "ep_reward": 523.6309204101562, "reward": 0.013438582420349121, "action": -0.8265569806098938}
{"mode": "train", "epochs": 4, "timestep": 6933, "ep_reward": 523.7874755859375, "reward": 0.15657901763916016, "action": -1.0526483058929443}
{"mode": "train", "epochs": 4, "timestep": 6934, "ep_reward": 524.0830078125, "reward": 0.2955145239830017, "action": -1.5559889078140259}
{"mode": "train", "epochs": 4, "timestep": 6935, "ep_reward": 524.5084838867188, "reward": 0.4254875183105469, "action": -0.6813342571258545}
{"mode": "train", "epochs": 4, "timestep": 6936, "ep_reward": 525.0625, "reward": 0.5540010929107666, "action": -1.3187251091003418}
{"mode": "train", "epochs": 4, "timestep": 6937, "ep_reward": 525.7172241210938, "reward": 0.6547393798828125, "action": -0.3926814794540405}
{"mode": "train", "epochs": 4, "timestep": 6938, "ep_reward": 526.4595336914062, "reward": 0.7423046231269836, "action": -0.47912168502807617}
{"mode": "train", "epochs": 4, "timestep": 6939, "ep_reward": 527.2648315429688, "reward": 0.8052730560302734, "action": -1.004206657409668}
{"mode": "train", "epochs": 4, "timestep": 6940, "ep_reward": 528.1080932617188, "reward": 0.8432905673980713, "action": -1.0369315147399902}
{"mode": "train", "epochs": 4, "timestep": 6941, "ep_reward": 528.9716796875, "reward": 0.8636085391044617, "action": -1.800034523010254}
{"mode": "train", "epochs": 4, "timestep": 6942, "ep_reward": 529.8329467773438, "reward": 0.8612418174743652, "action": -1.6460881233215332}
{"mode": "train", "epochs": 4, "timestep": 6943, "ep_reward": 530.6751708984375, "reward": 0.8422204256057739, "action": -1.1311036348342896}
{"mode": "train", "epochs": 4, "timestep": 6944, "ep_reward": 531.4817504882812, "reward": 0.8065510988235474, "action": -0.45528680086135864}
{"mode": "train", "epochs": 4, "timestep": 6945, "ep_reward": 532.2340087890625, "reward": 0.752246618270874, "action": -0.9203367829322815}
{"mode": "train", "epochs": 4, "timestep": 6946, "ep_reward": 532.8955688476562, "reward": 0.6615552306175232, "action": -1.201418399810791}
{"mode": "train", "epochs": 4, "timestep": 6947, "ep_reward": 533.423828125, "reward": 0.5282492637634277, "action": -1.0234953165054321}
{"mode": "train", "epochs": 4, "timestep": 6948, "ep_reward": 533.7999267578125, "reward": 0.3760955333709717, "action": -0.8475228548049927}
{"mode": "train", "epochs": 4, "timestep": 6949, "ep_reward": 534.0713500976562, "reward": 0.2714417576789856, "action": -1.0792937278747559}
{"mode": "train", "epochs": 4, "timestep": 6950, "ep_reward": 534.2182006835938, "reward": 0.1468491554260254, "action": -0.8015366792678833}
{"mode": "train", "epochs": 4, "timestep": 6951, "ep_reward": 534.2203369140625, "reward": 0.0021294355392456055, "action": -1.4707932472229004}
{"mode": "train", "epochs": 4, "timestep": 6952, "ep_reward": 534.3335571289062, "reward": 0.11323279142379761, "action": -0.7100439667701721}
{"mode": "train", "epochs": 4, "timestep": 6953, "ep_reward": 534.5890502929688, "reward": 0.2554677128791809, "action": -0.9205358028411865}
{"mode": "train", "epochs": 4, "timestep": 6954, "ep_reward": 534.9833374023438, "reward": 0.39428412914276123, "action": 0.0472182035446167}
{"mode": "train", "epochs": 4, "timestep": 6955, "ep_reward": 535.5170288085938, "reward": 0.5337196588516235, "action": -1.513728380203247}
{"mode": "train", "epochs": 4, "timestep": 6956, "ep_reward": 536.1531982421875, "reward": 0.6361500024795532, "action": -0.3812061548233032}
{"mode": "train", "epochs": 4, "timestep": 6957, "ep_reward": 536.8826293945312, "reward": 0.7294516563415527, "action": -1.3671438694000244}
{"mode": "train", "epochs": 4, "timestep": 6958, "ep_reward": 537.6739501953125, "reward": 0.791316568851471, "action": -0.8826737403869629}
{"mode": "train", "epochs": 4, "timestep": 6959, "ep_reward": 538.5123291015625, "reward": 0.8383696675300598, "action": -1.4906572103500366}
{"mode": "train", "epochs": 4, "timestep": 6960, "ep_reward": 539.3759765625, "reward": 0.8636197447776794, "action": -0.4806687831878662}
{"mode": "train", "epochs": 4, "timestep": 6961, "ep_reward": 540.2577514648438, "reward": 0.8817679286003113, "action": -0.5541260242462158}
{"mode": "train", "epochs": 4, "timestep": 6962, "ep_reward": 541.1425170898438, "reward": 0.8847565650939941, "action": -1.0821188688278198}
{"mode": "train", "epochs": 4, "timestep": 6963, "ep_reward": 542.0109252929688, "reward": 0.8684096336364746, "action": -1.9645687341690063}
{"mode": "train", "epochs": 4, "timestep": 6964, "ep_reward": 542.8367919921875, "reward": 0.8258726000785828, "action": -0.6325582265853882}
{"mode": "train", "epochs": 4, "timestep": 6965, "ep_reward": 543.6084594726562, "reward": 0.7716512680053711, "action": -0.9471368789672852}
{"mode": "train", "epochs": 4, "timestep": 6966, "ep_reward": 544.2932739257812, "reward": 0.6848362684249878, "action": -0.8967178463935852}
{"mode": "train", "epochs": 4, "timestep": 6967, "ep_reward": 544.8554077148438, "reward": 0.5621578693389893, "action": -1.726294755935669}
{"mode": "train", "epochs": 4, "timestep": 6968, "ep_reward": 545.2409057617188, "reward": 0.38548368215560913, "action": -1.214264988899231}
{"mode": "train", "epochs": 4, "timestep": 6969, "ep_reward": 545.520751953125, "reward": 0.27985137701034546, "action": -0.03581357002258301}
{"mode": "train", "epochs": 4, "timestep": 6970, "ep_reward": 545.6773681640625, "reward": 0.15658968687057495, "action": -1.2674775123596191}
{"mode": "train", "epochs": 4, "timestep": 6971, "ep_reward": 545.6908569335938, "reward": 0.01351255178451538, "action": -0.5191249847412109}
{"mode": "train", "epochs": 4, "timestep": 6972, "ep_reward": 545.7938232421875, "reward": 0.10297757387161255, "action": -0.5603793859481812}
{"mode": "train", "epochs": 4, "timestep": 6973, "ep_reward": 546.0406494140625, "reward": 0.2468211054801941, "action": -0.39668339490890503}
{"mode": "train", "epochs": 4, "timestep": 6974, "ep_reward": 546.4324340820312, "reward": 0.39180874824523926, "action": -1.3382790088653564}
{"mode": "train", "epochs": 4, "timestep": 6975, "ep_reward": 546.9474487304688, "reward": 0.5150431990623474, "action": -1.9273295402526855}
{"mode": "train", "epochs": 4, "timestep": 6976, "ep_reward": 547.563720703125, "reward": 0.616247296333313, "action": 0.15069401264190674}
{"mode": "train", "epochs": 4, "timestep": 6977, "ep_reward": 548.2825317382812, "reward": 0.7188217639923096, "action": -0.7912534475326538}
{"mode": "train", "epochs": 4, "timestep": 6978, "ep_reward": 549.0701904296875, "reward": 0.7876573801040649, "action": -1.1426992416381836}
{"mode": "train", "epochs": 4, "timestep": 6979, "ep_reward": 549.9033203125, "reward": 0.8331467509269714, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 6980, "ep_reward": 550.7578735351562, "reward": 0.8545622825622559, "action": -1.4083056449890137}
{"mode": "train", "epochs": 4, "timestep": 6981, "ep_reward": 551.6227416992188, "reward": 0.8648977279663086, "action": -1.6299779415130615}
{"mode": "train", "epochs": 4, "timestep": 6982, "ep_reward": 552.4794311523438, "reward": 0.8567144274711609, "action": -1.571739912033081}
{"mode": "train", "epochs": 4, "timestep": 6983, "ep_reward": 553.309326171875, "reward": 0.8299137949943542, "action": -0.9163151979446411}
{"mode": "train", "epochs": 4, "timestep": 6984, "ep_reward": 554.0953979492188, "reward": 0.7860929369926453, "action": -1.5121296644210815}
{"mode": "train", "epochs": 4, "timestep": 6985, "ep_reward": 554.8021850585938, "reward": 0.7067865133285522, "action": -0.8877900242805481}
{"mode": "train", "epochs": 4, "timestep": 6986, "ep_reward": 555.4002685546875, "reward": 0.5980817079544067, "action": -1.114986777305603}
{"mode": "train", "epochs": 4, "timestep": 6987, "ep_reward": 555.8445434570312, "reward": 0.4442905783653259, "action": -0.9050059914588928}
{"mode": "train", "epochs": 4, "timestep": 6988, "ep_reward": 556.1742553710938, "reward": 0.32971107959747314, "action": -1.7501976490020752}
{"mode": "train", "epochs": 4, "timestep": 6989, "ep_reward": 556.39013671875, "reward": 0.21586507558822632, "action": -1.2491881847381592}
{"mode": "train", "epochs": 4, "timestep": 6990, "ep_reward": 556.4721069335938, "reward": 0.08195793628692627, "action": -1.0222389698028564}
{"mode": "train", "epochs": 4, "timestep": 6991, "ep_reward": 556.5078735351562, "reward": 0.03574955463409424, "action": -1.3348134756088257}
{"mode": "train", "epochs": 4, "timestep": 6992, "ep_reward": 556.683837890625, "reward": 0.1759592890739441, "action": -1.374617099761963}
{"mode": "train", "epochs": 4, "timestep": 6993, "ep_reward": 556.9951782226562, "reward": 0.31135910749435425, "action": -0.8856939673423767}
{"mode": "train", "epochs": 4, "timestep": 6994, "ep_reward": 557.4441528320312, "reward": 0.4489949941635132, "action": -0.9425175786018372}
{"mode": "train", "epochs": 4, "timestep": 6995, "ep_reward": 558.015380859375, "reward": 0.5712500810623169, "action": -0.6915189623832703}
{"mode": "train", "epochs": 4, "timestep": 6996, "ep_reward": 558.6904907226562, "reward": 0.6751275658607483, "action": -0.307239294052124}
{"mode": "train", "epochs": 4, "timestep": 6997, "ep_reward": 559.4494018554688, "reward": 0.7589016556739807, "action": -0.06401455402374268}
{"mode": "train", "epochs": 4, "timestep": 6998, "ep_reward": 560.2710571289062, "reward": 0.8216587901115417, "action": -0.6023667454719543}
{"mode": "train", "epochs": 4, "timestep": 6999, "ep_reward": 561.131103515625, "reward": 0.8600636124610901, "action": -1.257570743560791}
{"mode": "train", "epochs": 4, "timestep": 7000, "ep_reward": 562.0086059570312, "reward": 0.8775067329406738, "action": -0.6207095980644226}
{"mode": "train", "epochs": 4, "timestep": 7001, "ep_reward": 562.8941650390625, "reward": 0.8855485916137695, "action": -1.0163217782974243}
{"mode": "train", "epochs": 4, "timestep": 7002, "ep_reward": 563.7701416015625, "reward": 0.8759807348251343, "action": -0.5999302268028259}
{"mode": "train", "epochs": 4, "timestep": 7003, "ep_reward": 564.6236572265625, "reward": 0.8535100221633911, "action": -1.2488292455673218}
{"mode": "train", "epochs": 4, "timestep": 7004, "ep_reward": 565.4287109375, "reward": 0.8050779104232788, "action": -1.411352515220642}
{"mode": "train", "epochs": 4, "timestep": 7005, "ep_reward": 566.1564331054688, "reward": 0.7277141809463501, "action": -1.40273118019104}
{"mode": "train", "epochs": 4, "timestep": 7006, "ep_reward": 566.7716674804688, "reward": 0.6152378916740417, "action": -0.5910196900367737}
{"mode": "train", "epochs": 4, "timestep": 7007, "ep_reward": 567.2449340820312, "reward": 0.473272442817688, "action": -1.651542067527771}
{"mode": "train", "epochs": 4, "timestep": 7008, "ep_reward": 567.5735473632812, "reward": 0.3286116123199463, "action": -0.7144079208374023}
{"mode": "train", "epochs": 4, "timestep": 7009, "ep_reward": 567.7879638671875, "reward": 0.21442973613739014, "action": -0.7134748697280884}
{"mode": "train", "epochs": 4, "timestep": 7010, "ep_reward": 567.8681640625, "reward": 0.08021736145019531, "action": -1.0037221908569336}
{"mode": "train", "epochs": 4, "timestep": 7011, "ep_reward": 567.9058227539062, "reward": 0.03766441345214844, "action": -0.44730693101882935}
{"mode": "train", "epochs": 4, "timestep": 7012, "ep_reward": 568.086669921875, "reward": 0.1808415651321411, "action": -1.102780818939209}
{"mode": "train", "epochs": 4, "timestep": 7013, "ep_reward": 568.4056396484375, "reward": 0.3189852237701416, "action": -0.8074288368225098}
{"mode": "train", "epochs": 4, "timestep": 7014, "ep_reward": 568.86181640625, "reward": 0.4561474323272705, "action": -0.8356244564056396}
{"mode": "train", "epochs": 4, "timestep": 7015, "ep_reward": 569.4398193359375, "reward": 0.5780020952224731, "action": -1.8140876293182373}
{"mode": "train", "epochs": 4, "timestep": 7016, "ep_reward": 570.1090698242188, "reward": 0.6692372560501099, "action": -0.6303989291191101}
{"mode": "train", "epochs": 4, "timestep": 7017, "ep_reward": 570.8601684570312, "reward": 0.7511126399040222, "action": -1.2334009408950806}
{"mode": "train", "epochs": 4, "timestep": 7018, "ep_reward": 571.6651611328125, "reward": 0.8049851655960083, "action": -0.3943527340888977}
{"mode": "train", "epochs": 4, "timestep": 7019, "ep_reward": 572.5117797851562, "reward": 0.8466101884841919, "action": -1.0797474384307861}
{"mode": "train", "epochs": 4, "timestep": 7020, "ep_reward": 573.37646484375, "reward": 0.8646584749221802, "action": -1.4135267734527588}
{"mode": "train", "epochs": 4, "timestep": 7021, "ep_reward": 574.240234375, "reward": 0.8637440800666809, "action": -0.48105841875076294}
{"mode": "train", "epochs": 4, "timestep": 7022, "ep_reward": 575.0938720703125, "reward": 0.8536384105682373, "action": -0.9456540942192078}
{"mode": "train", "epochs": 4, "timestep": 7023, "ep_reward": 575.9136962890625, "reward": 0.8198497295379639, "action": -1.6480575799942017}
{"mode": "train", "epochs": 4, "timestep": 7024, "ep_reward": 576.6676025390625, "reward": 0.7539248466491699, "action": -1.154493808746338}
{"mode": "train", "epochs": 4, "timestep": 7025, "ep_reward": 577.3279418945312, "reward": 0.6603683829307556, "action": -0.6287921667098999}
{"mode": "train", "epochs": 4, "timestep": 7026, "ep_reward": 577.863037109375, "reward": 0.5350662469863892, "action": -1.1922467947006226}
{"mode": "train", "epochs": 4, "timestep": 7027, "ep_reward": 578.239013671875, "reward": 0.3759554624557495, "action": -0.6179022789001465}
{"mode": "train", "epochs": 4, "timestep": 7028, "ep_reward": 578.5103149414062, "reward": 0.2712831497192383, "action": -0.7617162466049194}
{"mode": "train", "epochs": 4, "timestep": 7029, "ep_reward": 578.6567993164062, "reward": 0.14651179313659668, "action": -1.5403261184692383}
{"mode": "train", "epochs": 4, "timestep": 7030, "ep_reward": 578.6588134765625, "reward": 0.0019998550415039062, "action": -0.15662217140197754}
{"mode": "train", "epochs": 4, "timestep": 7031, "ep_reward": 578.772216796875, "reward": 0.11337435245513916, "action": -1.4280661344528198}
{"mode": "train", "epochs": 4, "timestep": 7032, "ep_reward": 579.0189208984375, "reward": 0.24672770500183105, "action": -0.4664989113807678}
{"mode": "train", "epochs": 4, "timestep": 7033, "ep_reward": 579.4118041992188, "reward": 0.3928794264793396, "action": -0.6544491052627563}
{"mode": "train", "epochs": 4, "timestep": 7034, "ep_reward": 579.936767578125, "reward": 0.5249645113945007, "action": 1.2818500995635986}
{"mode": "train", "epochs": 4, "timestep": 7035, "ep_reward": 580.5946044921875, "reward": 0.6578580141067505, "action": -0.9233905673027039}
{"mode": "train", "epochs": 4, "timestep": 7036, "ep_reward": 581.336669921875, "reward": 0.7420493960380554, "action": -0.7300768494606018}
{"mode": "train", "epochs": 4, "timestep": 7037, "ep_reward": 582.1439208984375, "reward": 0.807269811630249, "action": -1.8115010261535645}
{"mode": "train", "epochs": 4, "timestep": 7038, "ep_reward": 582.9898071289062, "reward": 0.8458588123321533, "action": -1.2203342914581299}
{"mode": "train", "epochs": 4, "timestep": 7039, "ep_reward": 583.864013671875, "reward": 0.8742355108261108, "action": -0.6792380809783936}
{"mode": "train", "epochs": 4, "timestep": 7040, "ep_reward": 584.7567749023438, "reward": 0.8927505016326904, "action": -0.8589833974838257}
{"mode": "train", "epochs": 4, "timestep": 7041, "ep_reward": 585.65380859375, "reward": 0.8970281481742859, "action": -0.32021909952163696}
{"mode": "train", "epochs": 4, "timestep": 7042, "ep_reward": 586.5462646484375, "reward": 0.8924549221992493, "action": 0.804385781288147}
{"mode": "train", "epochs": 4, "timestep": 7043, "ep_reward": 587.4295654296875, "reward": 0.8833168745040894, "action": -1.3737930059432983}
{"mode": "train", "epochs": 4, "timestep": 7044, "ep_reward": 588.2704467773438, "reward": 0.8408588767051697, "action": -1.8719863891601562}
{"mode": "train", "epochs": 4, "timestep": 7045, "ep_reward": 589.0404663085938, "reward": 0.7700467109680176, "action": -1.34743070602417}
{"mode": "train", "epochs": 4, "timestep": 7046, "ep_reward": 589.7132568359375, "reward": 0.672796368598938, "action": -1.0233898162841797}
{"mode": "train", "epochs": 4, "timestep": 7047, "ep_reward": 590.25537109375, "reward": 0.542100191116333, "action": -0.7435994148254395}
{"mode": "train", "epochs": 4, "timestep": 7048, "ep_reward": 590.6312866210938, "reward": 0.3759094476699829, "action": -0.6038957834243774}
{"mode": "train", "epochs": 4, "timestep": 7049, "ep_reward": 590.8856201171875, "reward": 0.2543249726295471, "action": -0.48068249225616455}
{"mode": "train", "epochs": 4, "timestep": 7050, "ep_reward": 591.01220703125, "reward": 0.12661653757095337, "action": -1.4923429489135742}
{"mode": "train", "epochs": 4, "timestep": 7051, "ep_reward": 590.999267578125, "reward": -0.012943506240844727, "action": -0.9588757753372192}
{"mode": "train", "epochs": 4, "timestep": 7052, "ep_reward": 591.1329345703125, "reward": 0.13365519046783447, "action": -0.7024880647659302}
{"mode": "train", "epochs": 4, "timestep": 7053, "ep_reward": 591.409423828125, "reward": 0.2765175700187683, "action": -0.8784542083740234}
{"mode": "train", "epochs": 4, "timestep": 7054, "ep_reward": 591.8241577148438, "reward": 0.41475045680999756, "action": -1.6405521631240845}
{"mode": "train", "epochs": 4, "timestep": 7055, "ep_reward": 592.3568725585938, "reward": 0.5326844453811646, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7056, "ep_reward": 592.9869384765625, "reward": 0.6300632953643799, "action": -0.85783851146698}
{"mode": "train", "epochs": 4, "timestep": 7057, "ep_reward": 593.7055053710938, "reward": 0.7185463905334473, "action": -1.5213615894317627}
{"mode": "train", "epochs": 4, "timestep": 7058, "ep_reward": 594.4827270507812, "reward": 0.7771978974342346, "action": -1.2635118961334229}
{"mode": "train", "epochs": 4, "timestep": 7059, "ep_reward": 595.2999877929688, "reward": 0.8172646760940552, "action": -1.346282720565796}
{"mode": "train", "epochs": 4, "timestep": 7060, "ep_reward": 596.13671875, "reward": 0.8367398977279663, "action": -1.391797661781311}
{"mode": "train", "epochs": 4, "timestep": 7061, "ep_reward": 596.97314453125, "reward": 0.8363958597183228, "action": -0.961387574672699}
{"mode": "train", "epochs": 4, "timestep": 7062, "ep_reward": 597.7924194335938, "reward": 0.819282054901123, "action": 0.14577651023864746}
{"mode": "train", "epochs": 4, "timestep": 7063, "ep_reward": 598.5825805664062, "reward": 0.7901329398155212, "action": -1.5487513542175293}
{"mode": "train", "epochs": 4, "timestep": 7064, "ep_reward": 599.2978515625, "reward": 0.715292751789093, "action": -0.2845724821090698}
{"mode": "train", "epochs": 4, "timestep": 7065, "ep_reward": 599.9181518554688, "reward": 0.6202787160873413, "action": -0.20970690250396729}
{"mode": "train", "epochs": 4, "timestep": 7066, "ep_reward": 600.4063720703125, "reward": 0.48823487758636475, "action": -1.11101496219635}
{"mode": "train", "epochs": 4, "timestep": 7067, "ep_reward": 600.7559204101562, "reward": 0.3495425581932068, "action": -1.8923532962799072}
{"mode": "train", "epochs": 4, "timestep": 7068, "ep_reward": 600.99560546875, "reward": 0.23969191312789917, "action": -0.6880052089691162}
{"mode": "train", "epochs": 4, "timestep": 7069, "ep_reward": 601.1051635742188, "reward": 0.10958456993103027, "action": -1.217207670211792}
{"mode": "train", "epochs": 4, "timestep": 7070, "ep_reward": 601.1112060546875, "reward": 0.006025791168212891, "action": -1.789466381072998}
{"mode": "train", "epochs": 4, "timestep": 7071, "ep_reward": 601.261474609375, "reward": 0.15029805898666382, "action": -0.7930561900138855}
{"mode": "train", "epochs": 4, "timestep": 7072, "ep_reward": 601.5538940429688, "reward": 0.29239219427108765, "action": -1.08345365524292}
{"mode": "train", "epochs": 4, "timestep": 7073, "ep_reward": 601.9816284179688, "reward": 0.4277145266532898, "action": -0.7906997203826904}
{"mode": "train", "epochs": 4, "timestep": 7074, "ep_reward": 602.5357666015625, "reward": 0.5541317462921143, "action": -0.9120696783065796}
{"mode": "train", "epochs": 4, "timestep": 7075, "ep_reward": 603.1948852539062, "reward": 0.659121036529541, "action": -1.2428725957870483}
{"mode": "train", "epochs": 4, "timestep": 7076, "ep_reward": 603.9332885742188, "reward": 0.738381564617157, "action": -1.7039265632629395}
{"mode": "train", "epochs": 4, "timestep": 7077, "ep_reward": 604.7255249023438, "reward": 0.7922328114509583, "action": -1.5540046691894531}
{"mode": "train", "epochs": 4, "timestep": 7078, "ep_reward": 605.5538330078125, "reward": 0.8282841444015503, "action": -1.042423129081726}
{"mode": "train", "epochs": 4, "timestep": 7079, "ep_reward": 606.404296875, "reward": 0.8504805564880371, "action": -1.4996496438980103}
{"mode": "train", "epochs": 4, "timestep": 7080, "ep_reward": 607.2552490234375, "reward": 0.8509644269943237, "action": -0.42607367038726807}
{"mode": "train", "epochs": 4, "timestep": 7081, "ep_reward": 608.09765625, "reward": 0.8424167633056641, "action": -0.915494441986084}
{"mode": "train", "epochs": 4, "timestep": 7082, "ep_reward": 608.9061889648438, "reward": 0.8085229396820068, "action": -1.2251839637756348}
{"mode": "train", "epochs": 4, "timestep": 7083, "ep_reward": 609.6516723632812, "reward": 0.7454614639282227, "action": -0.8977442383766174}
{"mode": "train", "epochs": 4, "timestep": 7084, "ep_reward": 610.3048706054688, "reward": 0.6532002687454224, "action": -0.6876521110534668}
{"mode": "train", "epochs": 4, "timestep": 7085, "ep_reward": 610.8298950195312, "reward": 0.5250336527824402, "action": -1.1482491493225098}
{"mode": "train", "epochs": 4, "timestep": 7086, "ep_reward": 611.203125, "reward": 0.3732086420059204, "action": -1.1673600673675537}
{"mode": "train", "epochs": 4, "timestep": 7087, "ep_reward": 611.4711303710938, "reward": 0.2680037021636963, "action": -1.0156961679458618}
{"mode": "train", "epochs": 4, "timestep": 7088, "ep_reward": 611.6139526367188, "reward": 0.14282876253128052, "action": -0.48146408796310425}
{"mode": "train", "epochs": 4, "timestep": 7089, "ep_reward": 611.611572265625, "reward": -0.0024014711380004883, "action": -0.5718140006065369}
{"mode": "train", "epochs": 4, "timestep": 7090, "ep_reward": 611.7288208007812, "reward": 0.1172717809677124, "action": -1.6380478143692017}
{"mode": "train", "epochs": 4, "timestep": 7091, "ep_reward": 611.9768676757812, "reward": 0.24807226657867432, "action": -0.921326220035553}
{"mode": "train", "epochs": 4, "timestep": 7092, "ep_reward": 612.3659057617188, "reward": 0.3890452980995178, "action": -0.8694272637367249}
{"mode": "train", "epochs": 4, "timestep": 7093, "ep_reward": 612.8857421875, "reward": 0.5198113918304443, "action": -1.3512743711471558}
{"mode": "train", "epochs": 4, "timestep": 7094, "ep_reward": 613.5120849609375, "reward": 0.6263401508331299, "action": -1.264587163925171}
{"mode": "train", "epochs": 4, "timestep": 7095, "ep_reward": 614.2240600585938, "reward": 0.7119898796081543, "action": -0.9000008702278137}
{"mode": "train", "epochs": 4, "timestep": 7096, "ep_reward": 615.00244140625, "reward": 0.7783880233764648, "action": -0.770942747592926}
{"mode": "train", "epochs": 4, "timestep": 7097, "ep_reward": 615.8265991210938, "reward": 0.8241748213768005, "action": -0.9475317597389221}
{"mode": "train", "epochs": 4, "timestep": 7098, "ep_reward": 616.675537109375, "reward": 0.8489315509796143, "action": -1.1151463985443115}
{"mode": "train", "epochs": 4, "timestep": 7099, "ep_reward": 617.5299072265625, "reward": 0.8543828725814819, "action": -0.4921819567680359}
{"mode": "train", "epochs": 4, "timestep": 7100, "ep_reward": 618.3768920898438, "reward": 0.8469805717468262, "action": -1.998173713684082}
{"mode": "train", "epochs": 4, "timestep": 7101, "ep_reward": 619.1817016601562, "reward": 0.804783284664154, "action": -0.7566876411437988}
{"mode": "train", "epochs": 4, "timestep": 7102, "ep_reward": 619.9298095703125, "reward": 0.7480974197387695, "action": -1.7015374898910522}
{"mode": "train", "epochs": 4, "timestep": 7103, "ep_reward": 620.5771484375, "reward": 0.6473309993743896, "action": -0.6667236089706421}
{"mode": "train", "epochs": 4, "timestep": 7104, "ep_reward": 621.0960083007812, "reward": 0.5188629031181335, "action": -1.532569408416748}
{"mode": "train", "epochs": 4, "timestep": 7105, "ep_reward": 621.472412109375, "reward": 0.3764122724533081, "action": -0.5595608949661255}
{"mode": "train", "epochs": 4, "timestep": 7106, "ep_reward": 621.7440795898438, "reward": 0.27165132761001587, "action": -1.8598341941833496}
{"mode": "train", "epochs": 4, "timestep": 7107, "ep_reward": 621.8912353515625, "reward": 0.14717936515808105, "action": -1.411699891090393}
{"mode": "train", "epochs": 4, "timestep": 7108, "ep_reward": 621.8938598632812, "reward": 0.002611875534057617, "action": -1.4367258548736572}
{"mode": "train", "epochs": 4, "timestep": 7109, "ep_reward": 622.006591796875, "reward": 0.11274516582489014, "action": -1.1950782537460327}
{"mode": "train", "epochs": 4, "timestep": 7110, "ep_reward": 622.2555541992188, "reward": 0.24895185232162476, "action": -0.8879391551017761}
{"mode": "train", "epochs": 4, "timestep": 7111, "ep_reward": 622.6449584960938, "reward": 0.38939499855041504, "action": -0.7149803638458252}
{"mode": "train", "epochs": 4, "timestep": 7112, "ep_reward": 623.1663208007812, "reward": 0.5213344693183899, "action": -1.5387279987335205}
{"mode": "train", "epochs": 4, "timestep": 7113, "ep_reward": 623.7918090820312, "reward": 0.6254595518112183, "action": -1.9436728954315186}
{"mode": "train", "epochs": 4, "timestep": 7114, "ep_reward": 624.4967041015625, "reward": 0.7048909664154053, "action": -1.4050946235656738}
{"mode": "train", "epochs": 4, "timestep": 7115, "ep_reward": 625.2650756835938, "reward": 0.7683959007263184, "action": -0.39523768424987793}
{"mode": "train", "epochs": 4, "timestep": 7116, "ep_reward": 626.084716796875, "reward": 0.8196541666984558, "action": -0.5101039409637451}
{"mode": "train", "epochs": 4, "timestep": 7117, "ep_reward": 626.9341430664062, "reward": 0.8494186401367188, "action": -0.6519259810447693}
{"mode": "train", "epochs": 4, "timestep": 7118, "ep_reward": 627.7940063476562, "reward": 0.8598446249961853, "action": -1.0652128458023071}
{"mode": "train", "epochs": 4, "timestep": 7119, "ep_reward": 628.6428833007812, "reward": 0.8489060997962952, "action": -1.2257449626922607}
{"mode": "train", "epochs": 4, "timestep": 7120, "ep_reward": 629.459228515625, "reward": 0.8163187503814697, "action": -0.43921589851379395}
{"mode": "train", "epochs": 4, "timestep": 7121, "ep_reward": 630.2261962890625, "reward": 0.7669961452484131, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7122, "ep_reward": 630.8953857421875, "reward": 0.6691763401031494, "action": -1.196455478668213}
{"mode": "train", "epochs": 4, "timestep": 7123, "ep_reward": 631.435546875, "reward": 0.5401832461357117, "action": -1.3510634899139404}
{"mode": "train", "epochs": 4, "timestep": 7124, "ep_reward": 631.8242797851562, "reward": 0.38870322704315186, "action": -0.8573524355888367}
{"mode": "train", "epochs": 4, "timestep": 7125, "ep_reward": 632.1110229492188, "reward": 0.28674519062042236, "action": -1.1431776285171509}
{"mode": "train", "epochs": 4, "timestep": 7126, "ep_reward": 632.27587890625, "reward": 0.164880633354187, "action": -0.6252485513687134}
{"mode": "train", "epochs": 4, "timestep": 7127, "ep_reward": 632.2987670898438, "reward": 0.022899210453033447, "action": -1.164313554763794}
{"mode": "train", "epochs": 4, "timestep": 7128, "ep_reward": 632.3929443359375, "reward": 0.0941656231880188, "action": -0.9318775534629822}
{"mode": "train", "epochs": 4, "timestep": 7129, "ep_reward": 632.6259155273438, "reward": 0.23299968242645264, "action": -1.620589017868042}
{"mode": "train", "epochs": 4, "timestep": 7130, "ep_reward": 632.9904174804688, "reward": 0.36452752351760864, "action": -0.697338342666626}
{"mode": "train", "epochs": 4, "timestep": 7131, "ep_reward": 633.4904174804688, "reward": 0.5000110864639282, "action": -0.8469984531402588}
{"mode": "train", "epochs": 4, "timestep": 7132, "ep_reward": 634.1057739257812, "reward": 0.6153595447540283, "action": -1.2807302474975586}
{"mode": "train", "epochs": 4, "timestep": 7133, "ep_reward": 634.8096313476562, "reward": 0.703860878944397, "action": -1.1622713804244995}
{"mode": "train", "epochs": 4, "timestep": 7134, "ep_reward": 635.5808715820312, "reward": 0.77122962474823, "action": -1.2937425374984741}
{"mode": "train", "epochs": 4, "timestep": 7135, "ep_reward": 636.397216796875, "reward": 0.8163471817970276, "action": -0.1704624891281128}
{"mode": "train", "epochs": 4, "timestep": 7136, "ep_reward": 637.2492065429688, "reward": 0.8520051836967468, "action": -1.0562676191329956}
{"mode": "train", "epochs": 4, "timestep": 7137, "ep_reward": 638.111328125, "reward": 0.8620917797088623, "action": -1.6894973516464233}
{"mode": "train", "epochs": 4, "timestep": 7138, "ep_reward": 638.9607543945312, "reward": 0.8494141697883606, "action": -1.1914842128753662}
{"mode": "train", "epochs": 4, "timestep": 7139, "ep_reward": 639.7817993164062, "reward": 0.8210558891296387, "action": -1.2415225505828857}
{"mode": "train", "epochs": 4, "timestep": 7140, "ep_reward": 640.5494995117188, "reward": 0.7676820755004883, "action": -0.45004087686538696}
{"mode": "train", "epochs": 4, "timestep": 7141, "ep_reward": 641.242431640625, "reward": 0.6929559111595154, "action": -0.5643317699432373}
{"mode": "train", "epochs": 4, "timestep": 7142, "ep_reward": 641.8241577148438, "reward": 0.5817102789878845, "action": -0.7671281695365906}
{"mode": "train", "epochs": 4, "timestep": 7143, "ep_reward": 642.2515869140625, "reward": 0.4274212718009949, "action": -0.7486417889595032}
{"mode": "train", "epochs": 4, "timestep": 7144, "ep_reward": 642.5614624023438, "reward": 0.3098999261856079, "action": -0.47083157300949097}
{"mode": "train", "epochs": 4, "timestep": 7145, "ep_reward": 642.7534790039062, "reward": 0.19204169511795044, "action": -1.5730493068695068}
{"mode": "train", "epochs": 4, "timestep": 7146, "ep_reward": 642.8079833984375, "reward": 0.054479241371154785, "action": 0.07787156105041504}
{"mode": "train", "epochs": 4, "timestep": 7147, "ep_reward": 642.8717651367188, "reward": 0.06376945972442627, "action": -1.3103382587432861}
{"mode": "train", "epochs": 4, "timestep": 7148, "ep_reward": 643.072021484375, "reward": 0.20027416944503784, "action": -0.8155293464660645}
{"mode": "train", "epochs": 4, "timestep": 7149, "ep_reward": 643.4147338867188, "reward": 0.3427349328994751, "action": -1.8005967140197754}
{"mode": "train", "epochs": 4, "timestep": 7150, "ep_reward": 643.8812866210938, "reward": 0.46654802560806274, "action": -0.7212626338005066}
{"mode": "train", "epochs": 4, "timestep": 7151, "ep_reward": 644.4701538085938, "reward": 0.5888963937759399, "action": -0.9858802556991577}
{"mode": "train", "epochs": 4, "timestep": 7152, "ep_reward": 645.1559448242188, "reward": 0.685805082321167, "action": -1.4179027080535889}
{"mode": "train", "epochs": 4, "timestep": 7153, "ep_reward": 645.911376953125, "reward": 0.7554065585136414, "action": -0.10367107391357422}
{"mode": "train", "epochs": 4, "timestep": 7154, "ep_reward": 646.7268676757812, "reward": 0.8154604434967041, "action": -0.4967302083969116}
{"mode": "train", "epochs": 4, "timestep": 7155, "ep_reward": 647.5780029296875, "reward": 0.8511224389076233, "action": -1.2261167764663696}
{"mode": "train", "epochs": 4, "timestep": 7156, "ep_reward": 648.4412841796875, "reward": 0.8632520437240601, "action": -0.2675750255584717}
{"mode": "train", "epochs": 4, "timestep": 7157, "ep_reward": 649.30810546875, "reward": 0.8667968511581421, "action": -1.8620989322662354}
{"mode": "train", "epochs": 4, "timestep": 7158, "ep_reward": 650.14697265625, "reward": 0.8388945460319519, "action": -0.8112024068832397}
{"mode": "train", "epochs": 4, "timestep": 7159, "ep_reward": 650.9456176757812, "reward": 0.7986249923706055, "action": -0.6483640670776367}
{"mode": "train", "epochs": 4, "timestep": 7160, "ep_reward": 651.6792602539062, "reward": 0.7336193919181824, "action": -1.2838032245635986}
{"mode": "train", "epochs": 4, "timestep": 7161, "ep_reward": 652.3070678710938, "reward": 0.6277942657470703, "action": -1.147089958190918}
{"mode": "train", "epochs": 4, "timestep": 7162, "ep_reward": 652.78955078125, "reward": 0.4824879765510559, "action": -1.495482087135315}
{"mode": "train", "epochs": 4, "timestep": 7163, "ep_reward": 653.1353759765625, "reward": 0.3458316922187805, "action": -1.5122652053833008}
{"mode": "train", "epochs": 4, "timestep": 7164, "ep_reward": 653.370361328125, "reward": 0.2349933385848999, "action": -1.7029364109039307}
{"mode": "train", "epochs": 4, "timestep": 7165, "ep_reward": 653.474609375, "reward": 0.10427659749984741, "action": -1.2559311389923096}
{"mode": "train", "epochs": 4, "timestep": 7166, "ep_reward": 653.4866333007812, "reward": 0.012025177478790283, "action": -0.2939620614051819}
{"mode": "train", "epochs": 4, "timestep": 7167, "ep_reward": 653.6427612304688, "reward": 0.1561529040336609, "action": -1.8266509771347046}
{"mode": "train", "epochs": 4, "timestep": 7168, "ep_reward": 653.9281616210938, "reward": 0.2853901982307434, "action": -0.3647143244743347}
{"mode": "train", "epochs": 4, "timestep": 7169, "ep_reward": 654.3596801757812, "reward": 0.4314936399459839, "action": -1.1782128810882568}
{"mode": "train", "epochs": 4, "timestep": 7170, "ep_reward": 654.9129638671875, "reward": 0.5532791018486023, "action": -1.0698835849761963}
{"mode": "train", "epochs": 4, "timestep": 7171, "ep_reward": 655.5697021484375, "reward": 0.656732439994812, "action": -0.9088324904441833}
{"mode": "train", "epochs": 4, "timestep": 7172, "ep_reward": 656.3087158203125, "reward": 0.7389843463897705, "action": -1.1494431495666504}
{"mode": "train", "epochs": 4, "timestep": 7173, "ep_reward": 657.105224609375, "reward": 0.7964916229248047, "action": -1.0464695692062378}
{"mode": "train", "epochs": 4, "timestep": 7174, "ep_reward": 657.9401245117188, "reward": 0.8348764181137085, "action": 0.0886530876159668}
{"mode": "train", "epochs": 4, "timestep": 7175, "ep_reward": 658.8048095703125, "reward": 0.8646554946899414, "action": -0.5063462853431702}
{"mode": "train", "epochs": 4, "timestep": 7176, "ep_reward": 659.6773071289062, "reward": 0.8725012540817261, "action": -1.256115436553955}
{"mode": "train", "epochs": 4, "timestep": 7177, "ep_reward": 660.5350341796875, "reward": 0.857718825340271, "action": -0.8258600234985352}
{"mode": "train", "epochs": 4, "timestep": 7178, "ep_reward": 661.3626708984375, "reward": 0.8276324272155762, "action": -1.4982786178588867}
{"mode": "train", "epochs": 4, "timestep": 7179, "ep_reward": 662.1298217773438, "reward": 0.767132043838501, "action": -1.2356308698654175}
{"mode": "train", "epochs": 4, "timestep": 7180, "ep_reward": 662.8075561523438, "reward": 0.6777375936508179, "action": -1.603450059890747}
{"mode": "train", "epochs": 4, "timestep": 7181, "ep_reward": 663.3519287109375, "reward": 0.5443647503852844, "action": -0.9643985033035278}
{"mode": "train", "epochs": 4, "timestep": 7182, "ep_reward": 663.7382202148438, "reward": 0.3863002061843872, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7183, "ep_reward": 664.0223388671875, "reward": 0.2841465473175049, "action": -0.25567400455474854}
{"mode": "train", "epochs": 4, "timestep": 7184, "ep_reward": 664.1840209960938, "reward": 0.16168850660324097, "action": -1.0058226585388184}
{"mode": "train", "epochs": 4, "timestep": 7185, "ep_reward": 664.2032470703125, "reward": 0.019199609756469727, "action": -1.5685124397277832}
{"mode": "train", "epochs": 4, "timestep": 7186, "ep_reward": 664.30078125, "reward": 0.09750968217849731, "action": -1.2542266845703125}
{"mode": "train", "epochs": 4, "timestep": 7187, "ep_reward": 664.5333862304688, "reward": 0.23258310556411743, "action": -0.34790676832199097}
{"mode": "train", "epochs": 4, "timestep": 7188, "ep_reward": 664.9137573242188, "reward": 0.380374550819397, "action": 0.20468103885650635}
{"mode": "train", "epochs": 4, "timestep": 7189, "ep_reward": 665.4369506835938, "reward": 0.5232223272323608, "action": -1.018576979637146}
{"mode": "train", "epochs": 4, "timestep": 7190, "ep_reward": 666.0693969726562, "reward": 0.632461428642273, "action": -0.06746375560760498}
{"mode": "train", "epochs": 4, "timestep": 7191, "ep_reward": 666.7991943359375, "reward": 0.729825496673584, "action": -0.7573169469833374}
{"mode": "train", "epochs": 4, "timestep": 7192, "ep_reward": 667.5971069335938, "reward": 0.7979308366775513, "action": -0.9804876446723938}
{"mode": "train", "epochs": 4, "timestep": 7193, "ep_reward": 668.4423828125, "reward": 0.8452978134155273, "action": -0.8539443016052246}
{"mode": "train", "epochs": 4, "timestep": 7194, "ep_reward": 669.320068359375, "reward": 0.8776659965515137, "action": -1.2866017818450928}
{"mode": "train", "epochs": 4, "timestep": 7195, "ep_reward": 670.2133178710938, "reward": 0.8932783007621765, "action": -0.9392096996307373}
{"mode": "train", "epochs": 4, "timestep": 7196, "ep_reward": 671.1123046875, "reward": 0.8989947438240051, "action": -0.5714702606201172}
{"mode": "train", "epochs": 4, "timestep": 7197, "ep_reward": 672.0071411132812, "reward": 0.8948096632957458, "action": -0.9799936413764954}
{"mode": "train", "epochs": 4, "timestep": 7198, "ep_reward": 672.8807373046875, "reward": 0.8736138939857483, "action": 0.14428722858428955}
{"mode": "train", "epochs": 4, "timestep": 7199, "ep_reward": 673.7258911132812, "reward": 0.8451822996139526, "action": -1.6064505577087402}
{"mode": "train", "epochs": 4, "timestep": 7200, "ep_reward": 674.5057373046875, "reward": 0.7798597812652588, "action": -1.3510284423828125}
{"mode": "train", "epochs": 4, "timestep": 7201, "ep_reward": 675.1925048828125, "reward": 0.6867571473121643, "action": -0.7006292939186096}
{"mode": "train", "epochs": 4, "timestep": 7202, "ep_reward": 675.7579345703125, "reward": 0.5654318332672119, "action": -1.3295538425445557}
{"mode": "train", "epochs": 4, "timestep": 7203, "ep_reward": 676.1538696289062, "reward": 0.3959645628929138, "action": -0.8693508505821228}
{"mode": "train", "epochs": 4, "timestep": 7204, "ep_reward": 676.4227294921875, "reward": 0.26883065700531006, "action": -1.9745352268218994}
{"mode": "train", "epochs": 4, "timestep": 7205, "ep_reward": 676.5667114257812, "reward": 0.14399594068527222, "action": -0.6709198355674744}
{"mode": "train", "epochs": 4, "timestep": 7206, "ep_reward": 676.5654296875, "reward": -0.001253366470336914, "action": -1.9090666770935059}
{"mode": "train", "epochs": 4, "timestep": 7207, "ep_reward": 676.6815185546875, "reward": 0.11607581377029419, "action": -1.5437512397766113}
{"mode": "train", "epochs": 4, "timestep": 7208, "ep_reward": 676.9295043945312, "reward": 0.24799180030822754, "action": -1.1072778701782227}
{"mode": "train", "epochs": 4, "timestep": 7209, "ep_reward": 677.3159790039062, "reward": 0.386501669883728, "action": -0.7983489632606506}
{"mode": "train", "epochs": 4, "timestep": 7210, "ep_reward": 677.8345336914062, "reward": 0.5185789465904236, "action": -0.2612054944038391}
{"mode": "train", "epochs": 4, "timestep": 7211, "ep_reward": 678.4715576171875, "reward": 0.6370068788528442, "action": -1.2970988750457764}
{"mode": "train", "epochs": 4, "timestep": 7212, "ep_reward": 679.1924438476562, "reward": 0.7208679914474487, "action": 0.018023133277893066}
{"mode": "train", "epochs": 4, "timestep": 7213, "ep_reward": 679.9873657226562, "reward": 0.7949002981185913, "action": -0.8331016898155212}
{"mode": "train", "epochs": 4, "timestep": 7214, "ep_reward": 680.8270263671875, "reward": 0.839674711227417, "action": -1.422675609588623}
{"mode": "train", "epochs": 4, "timestep": 7215, "ep_reward": 681.6892700195312, "reward": 0.8622170686721802, "action": -1.806955099105835}
{"mode": "train", "epochs": 4, "timestep": 7216, "ep_reward": 682.5552978515625, "reward": 0.8660452961921692, "action": 0.5272151231765747}
{"mode": "train", "epochs": 4, "timestep": 7217, "ep_reward": 683.4287719726562, "reward": 0.8734574317932129, "action": -0.039365530014038086}
{"mode": "train", "epochs": 4, "timestep": 7218, "ep_reward": 684.2886962890625, "reward": 0.8599467873573303, "action": -0.8962447643280029}
{"mode": "train", "epochs": 4, "timestep": 7219, "ep_reward": 685.109130859375, "reward": 0.820424497127533, "action": -0.19535517692565918}
{"mode": "train", "epochs": 4, "timestep": 7220, "ep_reward": 685.8734741210938, "reward": 0.7643702030181885, "action": -1.1723865270614624}
{"mode": "train", "epochs": 4, "timestep": 7221, "ep_reward": 686.5419311523438, "reward": 0.6684685945510864, "action": -0.7763062715530396}
{"mode": "train", "epochs": 4, "timestep": 7222, "ep_reward": 687.0823974609375, "reward": 0.540486216545105, "action": -0.36450058221817017}
{"mode": "train", "epochs": 4, "timestep": 7223, "ep_reward": 687.4624633789062, "reward": 0.38008207082748413, "action": -0.9905886054039001}
{"mode": "train", "epochs": 4, "timestep": 7224, "ep_reward": 687.7188720703125, "reward": 0.256416916847229, "action": -1.5069292783737183}
{"mode": "train", "epochs": 4, "timestep": 7225, "ep_reward": 687.84814453125, "reward": 0.1292700171470642, "action": -1.1540054082870483}
{"mode": "train", "epochs": 4, "timestep": 7226, "ep_reward": 687.8322143554688, "reward": -0.015910983085632324, "action": -0.9899215698242188}
{"mode": "train", "epochs": 4, "timestep": 7227, "ep_reward": 687.963134765625, "reward": 0.1309056282043457, "action": -1.7654401063919067}
{"mode": "train", "epochs": 4, "timestep": 7228, "ep_reward": 688.2236328125, "reward": 0.2604876160621643, "action": -0.803227961063385}
{"mode": "train", "epochs": 4, "timestep": 7229, "ep_reward": 688.6260375976562, "reward": 0.402418851852417, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7230, "ep_reward": 689.1446533203125, "reward": 0.5186417102813721, "action": -0.1623247265815735}
{"mode": "train", "epochs": 4, "timestep": 7231, "ep_reward": 689.7828979492188, "reward": 0.6382302045822144, "action": -1.2621817588806152}
{"mode": "train", "epochs": 4, "timestep": 7232, "ep_reward": 690.5038452148438, "reward": 0.7209733724594116, "action": -1.3987284898757935}
{"mode": "train", "epochs": 4, "timestep": 7233, "ep_reward": 691.2837524414062, "reward": 0.7799003720283508, "action": -0.5772234797477722}
{"mode": "train", "epochs": 4, "timestep": 7234, "ep_reward": 692.1090087890625, "reward": 0.8252350091934204, "action": -0.7070275545120239}
{"mode": "train", "epochs": 4, "timestep": 7235, "ep_reward": 692.9583740234375, "reward": 0.8493655920028687, "action": -1.8969433307647705}
{"mode": "train", "epochs": 4, "timestep": 7236, "ep_reward": 693.80322265625, "reward": 0.8448362946510315, "action": -0.5202488899230957}
{"mode": "train", "epochs": 4, "timestep": 7237, "ep_reward": 694.6365356445312, "reward": 0.8333232402801514, "action": 0.18870484828948975}
{"mode": "train", "epochs": 4, "timestep": 7238, "ep_reward": 695.4441528320312, "reward": 0.8076151013374329, "action": -0.7010948061943054}
{"mode": "train", "epochs": 4, "timestep": 7239, "ep_reward": 696.1924438476562, "reward": 0.7483073472976685, "action": -0.6338033676147461}
{"mode": "train", "epochs": 4, "timestep": 7240, "ep_reward": 696.8508911132812, "reward": 0.6584666967391968, "action": -1.1967504024505615}
{"mode": "train", "epochs": 4, "timestep": 7241, "ep_reward": 697.3739624023438, "reward": 0.5231002569198608, "action": -1.4610570669174194}
{"mode": "train", "epochs": 4, "timestep": 7242, "ep_reward": 697.7426147460938, "reward": 0.3686234951019287, "action": -1.323903203010559}
{"mode": "train", "epochs": 4, "timestep": 7243, "ep_reward": 698.0049438476562, "reward": 0.2623043656349182, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7244, "ep_reward": 698.1412963867188, "reward": 0.1363431215286255, "action": -0.7278851270675659}
{"mode": "train", "epochs": 4, "timestep": 7245, "ep_reward": 698.1314697265625, "reward": -0.00981438159942627, "action": -0.46097689867019653}
{"mode": "train", "epochs": 4, "timestep": 7246, "ep_reward": 698.2554321289062, "reward": 0.12397617101669312, "action": -0.9922882914543152}
{"mode": "train", "epochs": 4, "timestep": 7247, "ep_reward": 698.5184326171875, "reward": 0.2630150318145752, "action": -0.798237681388855}
{"mode": "train", "epochs": 4, "timestep": 7248, "ep_reward": 698.9219360351562, "reward": 0.40348827838897705, "action": -1.1546730995178223}
{"mode": "train", "epochs": 4, "timestep": 7249, "ep_reward": 699.4505615234375, "reward": 0.5285952687263489, "action": -1.061249017715454}
{"mode": "train", "epochs": 4, "timestep": 7250, "ep_reward": 700.0872192382812, "reward": 0.6366811990737915, "action": -1.2678487300872803}
{"mode": "train", "epochs": 4, "timestep": 7251, "ep_reward": 700.8079833984375, "reward": 0.7207639217376709, "action": -0.2650350332260132}
{"mode": "train", "epochs": 4, "timestep": 7252, "ep_reward": 701.5999755859375, "reward": 0.792014479637146, "action": -1.2387452125549316}
{"mode": "train", "epochs": 4, "timestep": 7253, "ep_reward": 702.4332885742188, "reward": 0.8333014845848083, "action": -1.3769855499267578}
{"mode": "train", "epochs": 4, "timestep": 7254, "ep_reward": 703.2890625, "reward": 0.8557509779930115, "action": -1.7475823163986206}
{"mode": "train", "epochs": 4, "timestep": 7255, "ep_reward": 704.1475830078125, "reward": 0.8585282564163208, "action": -0.877813458442688}
{"mode": "train", "epochs": 4, "timestep": 7256, "ep_reward": 704.9989013671875, "reward": 0.8513020277023315, "action": -0.7506936192512512}
{"mode": "train", "epochs": 4, "timestep": 7257, "ep_reward": 705.8245849609375, "reward": 0.8256816864013672, "action": -1.72264564037323}
{"mode": "train", "epochs": 4, "timestep": 7258, "ep_reward": 706.5909423828125, "reward": 0.7663408517837524, "action": -1.2935973405838013}
{"mode": "train", "epochs": 4, "timestep": 7259, "ep_reward": 707.2704467773438, "reward": 0.6794986724853516, "action": -0.44218385219573975}
{"mode": "train", "epochs": 4, "timestep": 7260, "ep_reward": 707.8360595703125, "reward": 0.5656169652938843, "action": -1.658442735671997}
{"mode": "train", "epochs": 4, "timestep": 7261, "ep_reward": 708.2347412109375, "reward": 0.39866864681243896, "action": -1.21841299533844}
{"mode": "train", "epochs": 4, "timestep": 7262, "ep_reward": 708.53369140625, "reward": 0.2989283800125122, "action": -1.359379768371582}
{"mode": "train", "epochs": 4, "timestep": 7263, "ep_reward": 708.7129516601562, "reward": 0.17927414178848267, "action": -0.9193297028541565}
{"mode": "train", "epochs": 4, "timestep": 7264, "ep_reward": 708.7525024414062, "reward": 0.03955286741256714, "action": -0.9613697528839111}
{"mode": "train", "epochs": 4, "timestep": 7265, "ep_reward": 708.8308715820312, "reward": 0.07839542627334595, "action": -0.6013244390487671}
{"mode": "train", "epochs": 4, "timestep": 7266, "ep_reward": 709.0518188476562, "reward": 0.22094804048538208, "action": -1.1094015836715698}
{"mode": "train", "epochs": 4, "timestep": 7267, "ep_reward": 709.4100952148438, "reward": 0.35826510190963745, "action": -1.637151837348938}
{"mode": "train", "epochs": 4, "timestep": 7268, "ep_reward": 709.8925170898438, "reward": 0.482394814491272, "action": -0.7051228284835815}
{"mode": "train", "epochs": 4, "timestep": 7269, "ep_reward": 710.4947509765625, "reward": 0.6022542715072632, "action": -0.9364868998527527}
{"mode": "train", "epochs": 4, "timestep": 7270, "ep_reward": 711.19189453125, "reward": 0.6971263289451599, "action": -0.9738664031028748}
{"mode": "train", "epochs": 4, "timestep": 7271, "ep_reward": 711.9605712890625, "reward": 0.7686662673950195, "action": -1.08760666847229}
{"mode": "train", "epochs": 4, "timestep": 7272, "ep_reward": 712.7783813476562, "reward": 0.8178110718727112, "action": -1.3793362379074097}
{"mode": "train", "epochs": 4, "timestep": 7273, "ep_reward": 713.6239624023438, "reward": 0.8455591797828674, "action": -1.2294197082519531}
{"mode": "train", "epochs": 4, "timestep": 7274, "ep_reward": 714.481201171875, "reward": 0.8572095036506653, "action": -1.1902540922164917}
{"mode": "train", "epochs": 4, "timestep": 7275, "ep_reward": 715.3328247070312, "reward": 0.851651668548584, "action": -1.0837035179138184}
{"mode": "train", "epochs": 4, "timestep": 7276, "ep_reward": 716.1604614257812, "reward": 0.8276203870773315, "action": -0.9307630658149719}
{"mode": "train", "epochs": 4, "timestep": 7277, "ep_reward": 716.9423217773438, "reward": 0.7818390130996704, "action": -1.0539796352386475}
{"mode": "train", "epochs": 4, "timestep": 7278, "ep_reward": 717.6481323242188, "reward": 0.7057800889015198, "action": -0.17832845449447632}
{"mode": "train", "epochs": 4, "timestep": 7279, "ep_reward": 718.2537841796875, "reward": 0.6056298017501831, "action": -0.6797826886177063}
{"mode": "train", "epochs": 4, "timestep": 7280, "ep_reward": 718.7139892578125, "reward": 0.46018844842910767, "action": -0.8568410277366638}
{"mode": "train", "epochs": 4, "timestep": 7281, "ep_reward": 719.0421142578125, "reward": 0.3281332850456238, "action": -1.8897771835327148}
{"mode": "train", "epochs": 4, "timestep": 7282, "ep_reward": 719.256103515625, "reward": 0.21400809288024902, "action": -1.3355398178100586}
{"mode": "train", "epochs": 4, "timestep": 7283, "ep_reward": 719.3359375, "reward": 0.07984870672225952, "action": -0.743013858795166}
{"mode": "train", "epochs": 4, "timestep": 7284, "ep_reward": 719.3739013671875, "reward": 0.0379641056060791, "action": -1.4185571670532227}
{"mode": "train", "epochs": 4, "timestep": 7285, "ep_reward": 719.5518798828125, "reward": 0.17799729108810425, "action": -0.435136616230011}
{"mode": "train", "epochs": 4, "timestep": 7286, "ep_reward": 719.8768920898438, "reward": 0.32504093647003174, "action": -0.71510910987854}
{"mode": "train", "epochs": 4, "timestep": 7287, "ep_reward": 720.3389892578125, "reward": 0.46212512254714966, "action": -1.2013622522354126}
{"mode": "train", "epochs": 4, "timestep": 7288, "ep_reward": 720.91796875, "reward": 0.578972578048706, "action": -0.879405677318573}
{"mode": "train", "epochs": 4, "timestep": 7289, "ep_reward": 721.597412109375, "reward": 0.6794723272323608, "action": -1.4973468780517578}
{"mode": "train", "epochs": 4, "timestep": 7290, "ep_reward": 722.3491821289062, "reward": 0.7517719864845276, "action": -1.4415475130081177}
{"mode": "train", "epochs": 4, "timestep": 7291, "ep_reward": 723.1534423828125, "reward": 0.8042761087417603, "action": -1.1486655473709106}
{"mode": "train", "epochs": 4, "timestep": 7292, "ep_reward": 723.993896484375, "reward": 0.8404558897018433, "action": 0.014510631561279297}
{"mode": "train", "epochs": 4, "timestep": 7293, "ep_reward": 724.8626708984375, "reward": 0.8687791228294373, "action": -0.8095583915710449}
{"mode": "train", "epochs": 4, "timestep": 7294, "ep_reward": 725.7365112304688, "reward": 0.8738489151000977, "action": -1.7135756015777588}
{"mode": "train", "epochs": 4, "timestep": 7295, "ep_reward": 726.591552734375, "reward": 0.855042576789856, "action": -1.1893996000289917}
{"mode": "train", "epochs": 4, "timestep": 7296, "ep_reward": 727.4125366210938, "reward": 0.8209601044654846, "action": -0.978276789188385}
{"mode": "train", "epochs": 4, "timestep": 7297, "ep_reward": 728.1770629882812, "reward": 0.7645293474197388, "action": -0.3654167056083679}
{"mode": "train", "epochs": 4, "timestep": 7298, "ep_reward": 728.8622436523438, "reward": 0.6851595044136047, "action": -0.43312251567840576}
{"mode": "train", "epochs": 4, "timestep": 7299, "ep_reward": 729.4326171875, "reward": 0.5704008340835571, "action": -0.5407247543334961}
{"mode": "train", "epochs": 4, "timestep": 7300, "ep_reward": 729.8480834960938, "reward": 0.41548508405685425, "action": -1.4347206354141235}
{"mode": "train", "epochs": 4, "timestep": 7301, "ep_reward": 730.138427734375, "reward": 0.2903265953063965, "action": -0.616102933883667}
{"mode": "train", "epochs": 4, "timestep": 7302, "ep_reward": 730.307373046875, "reward": 0.16892588138580322, "action": -1.4648966789245605}
{"mode": "train", "epochs": 4, "timestep": 7303, "ep_reward": 730.3350830078125, "reward": 0.02768915891647339, "action": -1.1391839981079102}
{"mode": "train", "epochs": 4, "timestep": 7304, "ep_reward": 730.4247436523438, "reward": 0.08967220783233643, "action": -0.869961678981781}
{"mode": "train", "epochs": 4, "timestep": 7305, "ep_reward": 730.6539306640625, "reward": 0.22917532920837402, "action": -1.4149229526519775}
{"mode": "train", "epochs": 4, "timestep": 7306, "ep_reward": 731.0170288085938, "reward": 0.36309415102005005, "action": -1.564873456954956}
{"mode": "train", "epochs": 4, "timestep": 7307, "ep_reward": 731.5052490234375, "reward": 0.4882006049156189, "action": -1.1548476219177246}
{"mode": "train", "epochs": 4, "timestep": 7308, "ep_reward": 732.1074829101562, "reward": 0.602259635925293, "action": -1.2001217603683472}
{"mode": "train", "epochs": 4, "timestep": 7309, "ep_reward": 732.8012084960938, "reward": 0.6937002539634705, "action": -1.5049221515655518}
{"mode": "train", "epochs": 4, "timestep": 7310, "ep_reward": 733.5601806640625, "reward": 0.7589731216430664, "action": -1.2889565229415894}
{"mode": "train", "epochs": 4, "timestep": 7311, "ep_reward": 734.36474609375, "reward": 0.8045432567596436, "action": -0.6503185033798218}
{"mode": "train", "epochs": 4, "timestep": 7312, "ep_reward": 735.2000732421875, "reward": 0.8353436589241028, "action": 0.07439577579498291}
{"mode": "train", "epochs": 4, "timestep": 7313, "ep_reward": 736.0531616210938, "reward": 0.8531116843223572, "action": -0.8975183367729187}
{"mode": "train", "epochs": 4, "timestep": 7314, "ep_reward": 736.896484375, "reward": 0.8433529138565063, "action": -1.1961272954940796}
{"mode": "train", "epochs": 4, "timestep": 7315, "ep_reward": 737.7064819335938, "reward": 0.8100107908248901, "action": 0.057012319564819336}
{"mode": "train", "epochs": 4, "timestep": 7316, "ep_reward": 738.4712524414062, "reward": 0.7647829055786133, "action": -1.2521750926971436}
{"mode": "train", "epochs": 4, "timestep": 7317, "ep_reward": 739.146484375, "reward": 0.675217866897583, "action": -1.6175031661987305}
{"mode": "train", "epochs": 4, "timestep": 7318, "ep_reward": 739.6878051757812, "reward": 0.5413012504577637, "action": -0.8303098082542419}
{"mode": "train", "epochs": 4, "timestep": 7319, "ep_reward": 740.0753173828125, "reward": 0.3875313997268677, "action": -0.8624624609947205}
{"mode": "train", "epochs": 4, "timestep": 7320, "ep_reward": 740.360595703125, "reward": 0.28525346517562866, "action": -1.5367010831832886}
{"mode": "train", "epochs": 4, "timestep": 7321, "ep_reward": 740.5237426757812, "reward": 0.16313350200653076, "action": -1.2086105346679688}
{"mode": "train", "epochs": 4, "timestep": 7322, "ep_reward": 740.544677734375, "reward": 0.02095329761505127, "action": -1.2392858266830444}
{"mode": "train", "epochs": 4, "timestep": 7323, "ep_reward": 740.6405639648438, "reward": 0.0958777666091919, "action": -1.5514698028564453}
{"mode": "train", "epochs": 4, "timestep": 7324, "ep_reward": 740.8684692382812, "reward": 0.2279108166694641, "action": -1.2485297918319702}
{"mode": "train", "epochs": 4, "timestep": 7325, "ep_reward": 741.2337646484375, "reward": 0.36526942253112793, "action": -1.0893827676773071}
{"mode": "train", "epochs": 4, "timestep": 7326, "ep_reward": 741.7300415039062, "reward": 0.4962838888168335, "action": -1.028968334197998}
{"mode": "train", "epochs": 4, "timestep": 7327, "ep_reward": 742.3403930664062, "reward": 0.6103383898735046, "action": -1.5096709728240967}
{"mode": "train", "epochs": 4, "timestep": 7328, "ep_reward": 743.0374145507812, "reward": 0.6970285177230835, "action": -0.21230143308639526}
{"mode": "train", "epochs": 4, "timestep": 7329, "ep_reward": 743.81103515625, "reward": 0.773635745048523, "action": -0.40011441707611084}
{"mode": "train", "epochs": 4, "timestep": 7330, "ep_reward": 744.6361083984375, "reward": 0.8250667452812195, "action": -0.862472653388977}
{"mode": "train", "epochs": 4, "timestep": 7331, "ep_reward": 745.4889526367188, "reward": 0.852850079536438, "action": -0.3465302586555481}
{"mode": "train", "epochs": 4, "timestep": 7332, "ep_reward": 746.356689453125, "reward": 0.8677091002464294, "action": -1.1048095226287842}
{"mode": "train", "epochs": 4, "timestep": 7333, "ep_reward": 747.2161254882812, "reward": 0.859410285949707, "action": -1.1336324214935303}
{"mode": "train", "epochs": 4, "timestep": 7334, "ep_reward": 748.04833984375, "reward": 0.8322314620018005, "action": -0.34929579496383667}
{"mode": "train", "epochs": 4, "timestep": 7335, "ep_reward": 748.8387451171875, "reward": 0.7904066443443298, "action": -0.5004724860191345}
{"mode": "train", "epochs": 4, "timestep": 7336, "ep_reward": 749.5592651367188, "reward": 0.7204969525337219, "action": -1.262252688407898}
{"mode": "train", "epochs": 4, "timestep": 7337, "ep_reward": 750.166748046875, "reward": 0.6075057983398438, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7338, "ep_reward": 750.6079711914062, "reward": 0.44119793176651, "action": -1.4438217878341675}
{"mode": "train", "epochs": 4, "timestep": 7339, "ep_reward": 750.929931640625, "reward": 0.3219410181045532, "action": -1.4904265403747559}
{"mode": "train", "epochs": 4, "timestep": 7340, "ep_reward": 751.1365356445312, "reward": 0.20659154653549194, "action": -0.9287964701652527}
{"mode": "train", "epochs": 4, "timestep": 7341, "ep_reward": 751.2077026367188, "reward": 0.07117360830307007, "action": -0.78077232837677}
{"mode": "train", "epochs": 4, "timestep": 7342, "ep_reward": 751.2546997070312, "reward": 0.04699939489364624, "action": -0.698123037815094}
{"mode": "train", "epochs": 4, "timestep": 7343, "ep_reward": 751.4420166015625, "reward": 0.18730956315994263, "action": -1.3889784812927246}
{"mode": "train", "epochs": 4, "timestep": 7344, "ep_reward": 751.764404296875, "reward": 0.3223699927330017, "action": -0.6945452094078064}
{"mode": "train", "epochs": 4, "timestep": 7345, "ep_reward": 752.2257080078125, "reward": 0.461298406124115, "action": -1.3714934587478638}
{"mode": "train", "epochs": 4, "timestep": 7346, "ep_reward": 752.8026123046875, "reward": 0.5768897533416748, "action": -0.6348084211349487}
{"mode": "train", "epochs": 4, "timestep": 7347, "ep_reward": 753.482666015625, "reward": 0.680070161819458, "action": -1.1027674674987793}
{"mode": "train", "epochs": 4, "timestep": 7348, "ep_reward": 754.2373657226562, "reward": 0.7546765804290771, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7349, "ep_reward": 755.0370483398438, "reward": 0.7996591925621033, "action": -1.767614722251892}
{"mode": "train", "epochs": 4, "timestep": 7350, "ep_reward": 755.86474609375, "reward": 0.8277100324630737, "action": -1.1382625102996826}
{"mode": "train", "epochs": 4, "timestep": 7351, "ep_reward": 756.707275390625, "reward": 0.8425551652908325, "action": -0.5737546682357788}
{"mode": "train", "epochs": 4, "timestep": 7352, "ep_reward": 757.5506591796875, "reward": 0.8433895707130432, "action": -1.0163004398345947}
{"mode": "train", "epochs": 4, "timestep": 7353, "ep_reward": 758.370361328125, "reward": 0.8197219371795654, "action": -1.3400547504425049}
{"mode": "train", "epochs": 4, "timestep": 7354, "ep_reward": 759.138671875, "reward": 0.7682977914810181, "action": -0.5670328140258789}
{"mode": "train", "epochs": 4, "timestep": 7355, "ep_reward": 759.8336181640625, "reward": 0.694939374923706, "action": -1.335625410079956}
{"mode": "train", "epochs": 4, "timestep": 7356, "ep_reward": 760.4088134765625, "reward": 0.5751804113388062, "action": -0.5564833879470825}
{"mode": "train", "epochs": 4, "timestep": 7357, "ep_reward": 760.8323364257812, "reward": 0.42355042695999146, "action": -0.5215302109718323}
{"mode": "train", "epochs": 4, "timestep": 7358, "ep_reward": 761.149169921875, "reward": 0.3168172836303711, "action": -0.5769806504249573}
{"mode": "train", "epochs": 4, "timestep": 7359, "ep_reward": 761.3495483398438, "reward": 0.2003815770149231, "action": -0.7218096256256104}
{"mode": "train", "epochs": 4, "timestep": 7360, "ep_reward": 761.413330078125, "reward": 0.06378990411758423, "action": -1.7925612926483154}
{"mode": "train", "epochs": 4, "timestep": 7361, "ep_reward": 761.4677124023438, "reward": 0.05436134338378906, "action": -0.22763359546661377}
{"mode": "train", "epochs": 4, "timestep": 7362, "ep_reward": 761.6685791015625, "reward": 0.2008606195449829, "action": -0.4519280195236206}
{"mode": "train", "epochs": 4, "timestep": 7363, "ep_reward": 762.0145263671875, "reward": 0.3459314703941345, "action": -1.0994033813476562}
{"mode": "train", "epochs": 4, "timestep": 7364, "ep_reward": 762.4906616210938, "reward": 0.47611796855926514, "action": -0.21304535865783691}
{"mode": "train", "epochs": 4, "timestep": 7365, "ep_reward": 763.092041015625, "reward": 0.6014009118080139, "action": -0.8343778848648071}
{"mode": "train", "epochs": 4, "timestep": 7366, "ep_reward": 763.7902221679688, "reward": 0.6981743574142456, "action": -0.5461760759353638}
{"mode": "train", "epochs": 4, "timestep": 7367, "ep_reward": 764.5661010742188, "reward": 0.7758594751358032, "action": -0.3173946738243103}
{"mode": "train", "epochs": 4, "timestep": 7368, "ep_reward": 765.4005737304688, "reward": 0.834484875202179, "action": -1.7967443466186523}
{"mode": "train", "epochs": 4, "timestep": 7369, "ep_reward": 766.2650756835938, "reward": 0.864483118057251, "action": -0.883711576461792}
{"mode": "train", "epochs": 4, "timestep": 7370, "ep_reward": 767.1525268554688, "reward": 0.8874344825744629, "action": -1.2077381610870361}
{"mode": "train", "epochs": 4, "timestep": 7371, "ep_reward": 768.0474243164062, "reward": 0.8948943018913269, "action": -1.0621206760406494}
{"mode": "train", "epochs": 4, "timestep": 7372, "ep_reward": 768.9378662109375, "reward": 0.8904157876968384, "action": -1.364300012588501}
{"mode": "train", "epochs": 4, "timestep": 7373, "ep_reward": 769.8068237304688, "reward": 0.8689570426940918, "action": -1.0597178936004639}
{"mode": "train", "epochs": 4, "timestep": 7374, "ep_reward": 770.6386108398438, "reward": 0.8317813873291016, "action": -1.0668730735778809}
{"mode": "train", "epochs": 4, "timestep": 7375, "ep_reward": 771.409912109375, "reward": 0.7713009119033813, "action": -0.7550715208053589}
{"mode": "train", "epochs": 4, "timestep": 7376, "ep_reward": 772.0945434570312, "reward": 0.6846387386322021, "action": -1.1687839031219482}
{"mode": "train", "epochs": 4, "timestep": 7377, "ep_reward": 772.6513671875, "reward": 0.5568264126777649, "action": -1.2576162815093994}
{"mode": "train", "epochs": 4, "timestep": 7378, "ep_reward": 773.03759765625, "reward": 0.38620609045028687, "action": -0.9048416614532471}
{"mode": "train", "epochs": 4, "timestep": 7379, "ep_reward": 773.308837890625, "reward": 0.27125412225723267, "action": -1.498969554901123}
{"mode": "train", "epochs": 4, "timestep": 7380, "ep_reward": 773.45556640625, "reward": 0.1467382311820984, "action": -0.40244507789611816}
{"mode": "train", "epochs": 4, "timestep": 7381, "ep_reward": 773.4576416015625, "reward": 0.0020539164543151855, "action": -0.8846458792686462}
{"mode": "train", "epochs": 4, "timestep": 7382, "ep_reward": 773.5709838867188, "reward": 0.11335784196853638, "action": -0.916424572467804}
{"mode": "train", "epochs": 4, "timestep": 7383, "ep_reward": 773.8240356445312, "reward": 0.25305867195129395, "action": -0.7031258344650269}
{"mode": "train", "epochs": 4, "timestep": 7384, "ep_reward": 774.2190551757812, "reward": 0.39500176906585693, "action": -0.5453650951385498}
{"mode": "train", "epochs": 4, "timestep": 7385, "ep_reward": 774.746826171875, "reward": 0.5277998447418213, "action": -0.798958420753479}
{"mode": "train", "epochs": 4, "timestep": 7386, "ep_reward": 775.3855590820312, "reward": 0.6387101411819458, "action": -0.8598169088363647}
{"mode": "train", "epochs": 4, "timestep": 7387, "ep_reward": 776.1124877929688, "reward": 0.7269408702850342, "action": -1.3292292356491089}
{"mode": "train", "epochs": 4, "timestep": 7388, "ep_reward": 776.9016723632812, "reward": 0.7892090082168579, "action": -1.4552184343338013}
{"mode": "train", "epochs": 4, "timestep": 7389, "ep_reward": 777.73291015625, "reward": 0.8312497138977051, "action": -1.9417285919189453}
{"mode": "train", "epochs": 4, "timestep": 7390, "ep_reward": 778.5852661132812, "reward": 0.85233074426651, "action": -0.7750554084777832}
{"mode": "train", "epochs": 4, "timestep": 7391, "ep_reward": 779.4521484375, "reward": 0.866880476474762, "action": -0.6648761034011841}
{"mode": "train", "epochs": 4, "timestep": 7392, "ep_reward": 780.3180541992188, "reward": 0.8658819794654846, "action": -1.4466832876205444}
{"mode": "train", "epochs": 4, "timestep": 7393, "ep_reward": 781.1585083007812, "reward": 0.8404375314712524, "action": -0.7607290148735046}
{"mode": "train", "epochs": 4, "timestep": 7394, "ep_reward": 781.9581909179688, "reward": 0.7996923923492432, "action": -0.9543132185935974}
{"mode": "train", "epochs": 4, "timestep": 7395, "ep_reward": 782.6885986328125, "reward": 0.7303830981254578, "action": -0.7881933450698853}
{"mode": "train", "epochs": 4, "timestep": 7396, "ep_reward": 783.3182983398438, "reward": 0.6296756267547607, "action": -0.5863865613937378}
{"mode": "train", "epochs": 4, "timestep": 7397, "ep_reward": 783.8114624023438, "reward": 0.4931591749191284, "action": -0.6632609963417053}
{"mode": "train", "epochs": 4, "timestep": 7398, "ep_reward": 784.15576171875, "reward": 0.34427595138549805, "action": -1.2455458641052246}
{"mode": "train", "epochs": 4, "timestep": 7399, "ep_reward": 784.3888549804688, "reward": 0.23306775093078613, "action": -1.7338297367095947}
{"mode": "train", "epochs": 4, "timestep": 7400, "ep_reward": 784.490966796875, "reward": 0.10211223363876343, "action": -0.6533038020133972}
{"mode": "train", "epochs": 4, "timestep": 7401, "ep_reward": 784.50537109375, "reward": 0.014396488666534424, "action": -1.0161336660385132}
{"mode": "train", "epochs": 4, "timestep": 7402, "ep_reward": 784.662841796875, "reward": 0.15745431184768677, "action": -0.8552160859107971}
{"mode": "train", "epochs": 4, "timestep": 7403, "ep_reward": 784.9617309570312, "reward": 0.2989184260368347, "action": -1.1671266555786133}
{"mode": "train", "epochs": 4, "timestep": 7404, "ep_reward": 785.3945922851562, "reward": 0.4328804016113281, "action": -1.654651403427124}
{"mode": "train", "epochs": 4, "timestep": 7405, "ep_reward": 785.9436645507812, "reward": 0.5490435361862183, "action": -0.8733422160148621}
{"mode": "train", "epochs": 4, "timestep": 7406, "ep_reward": 786.5989990234375, "reward": 0.655342161655426, "action": -0.606591522693634}
{"mode": "train", "epochs": 4, "timestep": 7407, "ep_reward": 787.3397216796875, "reward": 0.7407143115997314, "action": -0.9603264331817627}
{"mode": "train", "epochs": 4, "timestep": 7408, "ep_reward": 788.1393432617188, "reward": 0.7996032238006592, "action": -1.0838264226913452}
{"mode": "train", "epochs": 4, "timestep": 7409, "ep_reward": 788.9766235351562, "reward": 0.8372586369514465, "action": -1.308915138244629}
{"mode": "train", "epochs": 4, "timestep": 7410, "ep_reward": 789.8317260742188, "reward": 0.8551117181777954, "action": -0.8962475657463074}
{"mode": "train", "epochs": 4, "timestep": 7411, "ep_reward": 790.6909790039062, "reward": 0.8592326641082764, "action": -1.6058542728424072}
{"mode": "train", "epochs": 4, "timestep": 7412, "ep_reward": 791.5299072265625, "reward": 0.8389019966125488, "action": -0.9688166975975037}
{"mode": "train", "epochs": 4, "timestep": 7413, "ep_reward": 792.3326416015625, "reward": 0.8027180433273315, "action": -1.0098899602890015}
{"mode": "train", "epochs": 4, "timestep": 7414, "ep_reward": 793.0722045898438, "reward": 0.7395578026771545, "action": -1.0938756465911865}
{"mode": "train", "epochs": 4, "timestep": 7415, "ep_reward": 793.714111328125, "reward": 0.6419147253036499, "action": -1.115565538406372}
{"mode": "train", "epochs": 4, "timestep": 7416, "ep_reward": 794.2175903320312, "reward": 0.5034844875335693, "action": -0.07882809638977051}
{"mode": "train", "epochs": 4, "timestep": 7417, "ep_reward": 794.5823974609375, "reward": 0.3648297190666199, "action": -0.24306684732437134}
{"mode": "train", "epochs": 4, "timestep": 7418, "ep_reward": 794.840087890625, "reward": 0.2576606273651123, "action": -1.7281007766723633}
{"mode": "train", "epochs": 4, "timestep": 7419, "ep_reward": 794.9708862304688, "reward": 0.1307728886604309, "action": -1.1919000148773193}
{"mode": "train", "epochs": 4, "timestep": 7420, "ep_reward": 794.9547119140625, "reward": -0.016190052032470703, "action": -1.0334430932998657}
{"mode": "train", "epochs": 4, "timestep": 7421, "ep_reward": 795.0841674804688, "reward": 0.12942743301391602, "action": -1.6240947246551514}
{"mode": "train", "epochs": 4, "timestep": 7422, "ep_reward": 795.3449096679688, "reward": 0.26072245836257935, "action": -0.9465084671974182}
{"mode": "train", "epochs": 4, "timestep": 7423, "ep_reward": 795.7456665039062, "reward": 0.4007740616798401, "action": -1.1762861013412476}
{"mode": "train", "epochs": 4, "timestep": 7424, "ep_reward": 796.272216796875, "reward": 0.5265740752220154, "action": -1.7205402851104736}
{"mode": "train", "epochs": 4, "timestep": 7425, "ep_reward": 796.9000854492188, "reward": 0.6278519034385681, "action": -1.2970319986343384}
{"mode": "train", "epochs": 4, "timestep": 7426, "ep_reward": 797.6121826171875, "reward": 0.7121263146400452, "action": -0.2334917187690735}
{"mode": "train", "epochs": 4, "timestep": 7427, "ep_reward": 798.3953857421875, "reward": 0.7832071185112, "action": -1.5198578834533691}
{"mode": "train", "epochs": 4, "timestep": 7428, "ep_reward": 799.2149658203125, "reward": 0.8195523619651794, "action": -1.834507942199707}
{"mode": "train", "epochs": 4, "timestep": 7429, "ep_reward": 800.0487670898438, "reward": 0.8338049650192261, "action": -0.3820279836654663}
{"mode": "train", "epochs": 4, "timestep": 7430, "ep_reward": 800.8907470703125, "reward": 0.8419607877731323, "action": -0.6816384792327881}
{"mode": "train", "epochs": 4, "timestep": 7431, "ep_reward": 801.7179565429688, "reward": 0.8272019624710083, "action": -0.6755505800247192}
{"mode": "train", "epochs": 4, "timestep": 7432, "ep_reward": 802.5078125, "reward": 0.7898294925689697, "action": -1.2600841522216797}
{"mode": "train", "epochs": 4, "timestep": 7433, "ep_reward": 803.2259521484375, "reward": 0.7181228995323181, "action": -1.108217716217041}
{"mode": "train", "epochs": 4, "timestep": 7434, "ep_reward": 803.8381958007812, "reward": 0.6122411489486694, "action": -0.7985295057296753}
{"mode": "train", "epochs": 4, "timestep": 7435, "ep_reward": 804.30712890625, "reward": 0.468911349773407, "action": -1.0968806743621826}
{"mode": "train", "epochs": 4, "timestep": 7436, "ep_reward": 804.6533813476562, "reward": 0.3462236523628235, "action": -0.8234646320343018}
{"mode": "train", "epochs": 4, "timestep": 7437, "ep_reward": 804.888916015625, "reward": 0.2355174422264099, "action": -0.3206039071083069}
{"mode": "train", "epochs": 4, "timestep": 7438, "ep_reward": 804.99365234375, "reward": 0.10471582412719727, "action": -1.0314338207244873}
{"mode": "train", "epochs": 4, "timestep": 7439, "ep_reward": 805.0052490234375, "reward": 0.011586964130401611, "action": -0.022165894508361816}
{"mode": "train", "epochs": 4, "timestep": 7440, "ep_reward": 805.1643676757812, "reward": 0.1591443419456482, "action": -1.5182433128356934}
{"mode": "train", "epochs": 4, "timestep": 7441, "ep_reward": 805.4558715820312, "reward": 0.2915027141571045, "action": -1.1573182344436646}
{"mode": "train", "epochs": 4, "timestep": 7442, "ep_reward": 805.882568359375, "reward": 0.4267173409461975, "action": -0.3926318287849426}
{"mode": "train", "epochs": 4, "timestep": 7443, "ep_reward": 806.4406127929688, "reward": 0.5580555200576782, "action": -1.4986071586608887}
{"mode": "train", "epochs": 4, "timestep": 7444, "ep_reward": 807.0968627929688, "reward": 0.656243085861206, "action": -1.020752191543579}
{"mode": "train", "epochs": 4, "timestep": 7445, "ep_reward": 807.8346557617188, "reward": 0.7377643585205078, "action": -0.9877763390541077}
{"mode": "train", "epochs": 4, "timestep": 7446, "ep_reward": 808.632080078125, "reward": 0.7973960638046265, "action": -0.13630801439285278}
{"mode": "train", "epochs": 4, "timestep": 7447, "ep_reward": 809.4760131835938, "reward": 0.843948245048523, "action": -1.6172997951507568}
{"mode": "train", "epochs": 4, "timestep": 7448, "ep_reward": 810.3359375, "reward": 0.8599380850791931, "action": -1.4173908233642578}
{"mode": "train", "epochs": 4, "timestep": 7449, "ep_reward": 811.1971435546875, "reward": 0.8611856698989868, "action": -1.2914271354675293}
{"mode": "train", "epochs": 4, "timestep": 7450, "ep_reward": 812.04296875, "reward": 0.8458099365234375, "action": -0.7703989744186401}
{"mode": "train", "epochs": 4, "timestep": 7451, "ep_reward": 812.8577270507812, "reward": 0.8147404193878174, "action": -0.910691499710083}
{"mode": "train", "epochs": 4, "timestep": 7452, "ep_reward": 813.6152954101562, "reward": 0.75758296251297, "action": 0.21621215343475342}
{"mode": "train", "epochs": 4, "timestep": 7453, "ep_reward": 814.2988891601562, "reward": 0.6836138367652893, "action": 0.1067037582397461}
{"mode": "train", "epochs": 4, "timestep": 7454, "ep_reward": 814.8746337890625, "reward": 0.5757243037223816, "action": -0.8713251352310181}
{"mode": "train", "epochs": 4, "timestep": 7455, "ep_reward": 815.29150390625, "reward": 0.4168831706047058, "action": -0.19192570447921753}
{"mode": "train", "epochs": 4, "timestep": 7456, "ep_reward": 815.5803833007812, "reward": 0.2888907194137573, "action": -1.171142578125}
{"mode": "train", "epochs": 4, "timestep": 7457, "ep_reward": 815.7476806640625, "reward": 0.16732007265090942, "action": -1.3820559978485107}
{"mode": "train", "epochs": 4, "timestep": 7458, "ep_reward": 815.7735595703125, "reward": 0.025898456573486328, "action": -0.272085964679718}
{"mode": "train", "epochs": 4, "timestep": 7459, "ep_reward": 815.8648681640625, "reward": 0.09131622314453125, "action": -1.6171770095825195}
{"mode": "train", "epochs": 4, "timestep": 7460, "ep_reward": 816.0887451171875, "reward": 0.22389280796051025, "action": -1.8165637254714966}
{"mode": "train", "epochs": 4, "timestep": 7461, "ep_reward": 816.4429931640625, "reward": 0.3542332649230957, "action": -0.7970462441444397}
{"mode": "train", "epochs": 4, "timestep": 7462, "ep_reward": 816.9334106445312, "reward": 0.4904189705848694, "action": -1.169150948524475}
{"mode": "train", "epochs": 4, "timestep": 7463, "ep_reward": 817.537353515625, "reward": 0.6039657592773438, "action": -1.3152140378952026}
{"mode": "train", "epochs": 4, "timestep": 7464, "ep_reward": 818.23095703125, "reward": 0.6936295628547668, "action": -1.2201465368270874}
{"mode": "train", "epochs": 4, "timestep": 7465, "ep_reward": 818.991943359375, "reward": 0.7610166668891907, "action": -0.34625244140625}
{"mode": "train", "epochs": 4, "timestep": 7466, "ep_reward": 819.8059692382812, "reward": 0.8139967918395996, "action": -1.4178683757781982}
{"mode": "train", "epochs": 4, "timestep": 7467, "ep_reward": 820.642333984375, "reward": 0.8363540172576904, "action": -0.4268144369125366}
{"mode": "train", "epochs": 4, "timestep": 7468, "ep_reward": 821.4910278320312, "reward": 0.8487168550491333, "action": -0.25629550218582153}
{"mode": "train", "epochs": 4, "timestep": 7469, "ep_reward": 822.3346557617188, "reward": 0.8436540365219116, "action": -1.1059165000915527}
{"mode": "train", "epochs": 4, "timestep": 7470, "ep_reward": 823.1444702148438, "reward": 0.8098429441452026, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7471, "ep_reward": 823.8844604492188, "reward": 0.7400193214416504, "action": -0.9285246133804321}
{"mode": "train", "epochs": 4, "timestep": 7472, "ep_reward": 824.5318603515625, "reward": 0.6473860144615173, "action": -1.7885246276855469}
{"mode": "train", "epochs": 4, "timestep": 7473, "ep_reward": 825.0336303710938, "reward": 0.5017656087875366, "action": -1.3483355045318604}
{"mode": "train", "epochs": 4, "timestep": 7474, "ep_reward": 825.4075317382812, "reward": 0.3738936185836792, "action": -1.0681766271591187}
{"mode": "train", "epochs": 4, "timestep": 7475, "ep_reward": 825.67626953125, "reward": 0.268754780292511, "action": -1.4175822734832764}
{"mode": "train", "epochs": 4, "timestep": 7476, "ep_reward": 825.820068359375, "reward": 0.14378678798675537, "action": -0.3927963376045227}
{"mode": "train", "epochs": 4, "timestep": 7477, "ep_reward": 825.8187866210938, "reward": -0.001311182975769043, "action": -0.6235237121582031}
{"mode": "train", "epochs": 4, "timestep": 7478, "ep_reward": 825.9352416992188, "reward": 0.11645674705505371, "action": -0.19865012168884277}
{"mode": "train", "epochs": 4, "timestep": 7479, "ep_reward": 826.2003784179688, "reward": 0.2651168704032898, "action": -0.618028461933136}
{"mode": "train", "epochs": 4, "timestep": 7480, "ep_reward": 826.6063842773438, "reward": 0.4060250520706177, "action": -0.7815039157867432}
{"mode": "train", "epochs": 4, "timestep": 7481, "ep_reward": 827.1402587890625, "reward": 0.5338758826255798, "action": -1.5178756713867188}
{"mode": "train", "epochs": 4, "timestep": 7482, "ep_reward": 827.7764892578125, "reward": 0.6362124681472778, "action": -0.5841439962387085}
{"mode": "train", "epochs": 4, "timestep": 7483, "ep_reward": 828.504150390625, "reward": 0.7276346683502197, "action": -1.203384280204773}
{"mode": "train", "epochs": 4, "timestep": 7484, "ep_reward": 829.29541015625, "reward": 0.7912840247154236, "action": -0.3934440016746521}
{"mode": "train", "epochs": 4, "timestep": 7485, "ep_reward": 830.1378784179688, "reward": 0.8424689769744873, "action": -0.7900997996330261}
{"mode": "train", "epochs": 4, "timestep": 7486, "ep_reward": 831.0108032226562, "reward": 0.8729414939880371, "action": -1.4827311038970947}
{"mode": "train", "epochs": 4, "timestep": 7487, "ep_reward": 831.89453125, "reward": 0.8837010264396667, "action": -0.23445546627044678}
{"mode": "train", "epochs": 4, "timestep": 7488, "ep_reward": 832.7847900390625, "reward": 0.8902429938316345, "action": -1.183437705039978}
{"mode": "train", "epochs": 4, "timestep": 7489, "ep_reward": 833.6599731445312, "reward": 0.8751779198646545, "action": -0.5572222471237183}
{"mode": "train", "epochs": 4, "timestep": 7490, "ep_reward": 834.5086669921875, "reward": 0.8486881852149963, "action": -0.014191806316375732}
{"mode": "train", "epochs": 4, "timestep": 7491, "ep_reward": 835.31640625, "reward": 0.8077316880226135, "action": -0.33232367038726807}
{"mode": "train", "epochs": 4, "timestep": 7492, "ep_reward": 836.056396484375, "reward": 0.7399810552597046, "action": -0.9285790920257568}
{"mode": "train", "epochs": 4, "timestep": 7493, "ep_reward": 836.6912841796875, "reward": 0.6349168419837952, "action": -0.6855365037918091}
{"mode": "train", "epochs": 4, "timestep": 7494, "ep_reward": 837.187255859375, "reward": 0.49596935510635376, "action": -1.2314162254333496}
{"mode": "train", "epochs": 4, "timestep": 7495, "ep_reward": 837.5116577148438, "reward": 0.32437586784362793, "action": -1.4913874864578247}
{"mode": "train", "epochs": 4, "timestep": 7496, "ep_reward": 837.720947265625, "reward": 0.20929348468780518, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7497, "ep_reward": 837.7954711914062, "reward": 0.07453727722167969, "action": -0.7511585354804993}
{"mode": "train", "epochs": 4, "timestep": 7498, "ep_reward": 837.8389282226562, "reward": 0.043483197689056396, "action": -1.2585890293121338}
{"mode": "train", "epochs": 4, "timestep": 7499, "ep_reward": 838.0216064453125, "reward": 0.18269556760787964, "action": -1.0693793296813965}
{"mode": "train", "epochs": 4, "timestep": 7500, "ep_reward": 838.3436279296875, "reward": 0.3219956159591675, "action": -0.7728691101074219}
{"mode": "train", "epochs": 4, "timestep": 7501, "ep_reward": 838.8034057617188, "reward": 0.4597766399383545, "action": -0.8021372556686401}
{"mode": "train", "epochs": 4, "timestep": 7502, "ep_reward": 839.3851928710938, "reward": 0.5817856788635254, "action": -0.9630770683288574}
{"mode": "train", "epochs": 4, "timestep": 7503, "ep_reward": 840.0661010742188, "reward": 0.6809038519859314, "action": -0.4000570774078369}
{"mode": "train", "epochs": 4, "timestep": 7504, "ep_reward": 840.82861328125, "reward": 0.7625080347061157, "action": -1.4937189817428589}
{"mode": "train", "epochs": 4, "timestep": 7505, "ep_reward": 841.640869140625, "reward": 0.8122805953025818, "action": -1.1296292543411255}
{"mode": "train", "epochs": 4, "timestep": 7506, "ep_reward": 842.4878540039062, "reward": 0.8469715118408203, "action": -0.6920033097267151}
{"mode": "train", "epochs": 4, "timestep": 7507, "ep_reward": 843.356201171875, "reward": 0.8683739304542542, "action": -0.526329517364502}
{"mode": "train", "epochs": 4, "timestep": 7508, "ep_reward": 844.2313232421875, "reward": 0.8750942945480347, "action": -1.721132755279541}
{"mode": "train", "epochs": 4, "timestep": 7509, "ep_reward": 845.0870361328125, "reward": 0.8557052612304688, "action": -0.5736021399497986}
{"mode": "train", "epochs": 4, "timestep": 7510, "ep_reward": 845.9141845703125, "reward": 0.8271295428276062, "action": -0.833835780620575}
{"mode": "train", "epochs": 4, "timestep": 7511, "ep_reward": 846.687255859375, "reward": 0.7731002569198608, "action": -0.6836299300193787}
{"mode": "train", "epochs": 4, "timestep": 7512, "ep_reward": 847.3788452148438, "reward": 0.6916117668151855, "action": -1.1883432865142822}
{"mode": "train", "epochs": 4, "timestep": 7513, "ep_reward": 847.9467163085938, "reward": 0.5678689479827881, "action": -1.1387248039245605}
{"mode": "train", "epochs": 4, "timestep": 7514, "ep_reward": 848.3494262695312, "reward": 0.4026912450790405, "action": -1.1653703451156616}
{"mode": "train", "epochs": 4, "timestep": 7515, "ep_reward": 848.6390380859375, "reward": 0.2896060347557068, "action": -1.7393145561218262}
{"mode": "train", "epochs": 4, "timestep": 7516, "ep_reward": 848.8073120117188, "reward": 0.16825592517852783, "action": -1.5447876453399658}
{"mode": "train", "epochs": 4, "timestep": 7517, "ep_reward": 848.834228515625, "reward": 0.02691471576690674, "action": -1.2704198360443115}
{"mode": "train", "epochs": 4, "timestep": 7518, "ep_reward": 848.924560546875, "reward": 0.09034335613250732, "action": -1.1889806985855103}
{"mode": "train", "epochs": 4, "timestep": 7519, "ep_reward": 849.1505126953125, "reward": 0.22595053911209106, "action": -1.0372366905212402}
{"mode": "train", "epochs": 4, "timestep": 7520, "ep_reward": 849.5158081054688, "reward": 0.3652923107147217, "action": -1.4319977760314941}
{"mode": "train", "epochs": 4, "timestep": 7521, "ep_reward": 850.0074462890625, "reward": 0.49166595935821533, "action": -1.3276028633117676}
{"mode": "train", "epochs": 4, "timestep": 7522, "ep_reward": 850.6105346679688, "reward": 0.6030580997467041, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7523, "ep_reward": 851.2965087890625, "reward": 0.6859871745109558, "action": -1.7009880542755127}
{"mode": "train", "epochs": 4, "timestep": 7524, "ep_reward": 852.0465087890625, "reward": 0.7500097155570984, "action": -1.4416375160217285}
{"mode": "train", "epochs": 4, "timestep": 7525, "ep_reward": 852.8406982421875, "reward": 0.7941792011260986, "action": -0.8632215261459351}
{"mode": "train", "epochs": 4, "timestep": 7526, "ep_reward": 853.66259765625, "reward": 0.8218837380409241, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7527, "ep_reward": 854.47998046875, "reward": 0.8173812031745911, "action": -1.2100926637649536}
{"mode": "train", "epochs": 4, "timestep": 7528, "ep_reward": 855.27734375, "reward": 0.7973602414131165, "action": -0.4420284032821655}
{"mode": "train", "epochs": 4, "timestep": 7529, "ep_reward": 856.0364379882812, "reward": 0.759121835231781, "action": -0.13252735137939453}
{"mode": "train", "epochs": 4, "timestep": 7530, "ep_reward": 856.7308959960938, "reward": 0.6944304704666138, "action": -0.6396799683570862}
{"mode": "train", "epochs": 4, "timestep": 7531, "ep_reward": 857.3186645507812, "reward": 0.5877804756164551, "action": -0.8742420673370361}
{"mode": "train", "epochs": 4, "timestep": 7532, "ep_reward": 857.7544555664062, "reward": 0.4357703924179077, "action": -0.8531538844108582}
{"mode": "train", "epochs": 4, "timestep": 7533, "ep_reward": 858.086181640625, "reward": 0.33173441886901855, "action": -1.3023360967636108}
{"mode": "train", "epochs": 4, "timestep": 7534, "ep_reward": 858.304443359375, "reward": 0.21826189756393433, "action": -0.43955498933792114}
{"mode": "train", "epochs": 4, "timestep": 7535, "ep_reward": 858.38916015625, "reward": 0.08469444513320923, "action": -0.46971648931503296}
{"mode": "train", "epochs": 4, "timestep": 7536, "ep_reward": 858.422119140625, "reward": 0.03298872709274292, "action": -1.0040048360824585}
{"mode": "train", "epochs": 4, "timestep": 7537, "ep_reward": 858.595703125, "reward": 0.173569917678833, "action": -1.0715408325195312}
{"mode": "train", "epochs": 4, "timestep": 7538, "ep_reward": 858.9083251953125, "reward": 0.3126360774040222, "action": -1.3006072044372559}
{"mode": "train", "epochs": 4, "timestep": 7539, "ep_reward": 859.3529663085938, "reward": 0.44463837146759033, "action": -1.4509886503219604}
{"mode": "train", "epochs": 4, "timestep": 7540, "ep_reward": 859.914794921875, "reward": 0.5618131756782532, "action": -0.7725282311439514}
{"mode": "train", "epochs": 4, "timestep": 7541, "ep_reward": 860.5813598632812, "reward": 0.6665640473365784, "action": -0.5818296074867249}
{"mode": "train", "epochs": 4, "timestep": 7542, "ep_reward": 861.3305053710938, "reward": 0.7491634488105774, "action": -0.2585752010345459}
{"mode": "train", "epochs": 4, "timestep": 7543, "ep_reward": 862.1419067382812, "reward": 0.8114010095596313, "action": -0.7223132848739624}
{"mode": "train", "epochs": 4, "timestep": 7544, "ep_reward": 862.9909057617188, "reward": 0.8490197062492371, "action": -1.1473538875579834}
{"mode": "train", "epochs": 4, "timestep": 7545, "ep_reward": 863.8568115234375, "reward": 0.8659186959266663, "action": -1.3277732133865356}
{"mode": "train", "epochs": 4, "timestep": 7546, "ep_reward": 864.7221069335938, "reward": 0.8653014302253723, "action": -0.23903387784957886}
{"mode": "train", "epochs": 4, "timestep": 7547, "ep_reward": 865.5791625976562, "reward": 0.8570801019668579, "action": -0.9417702555656433}
{"mode": "train", "epochs": 4, "timestep": 7548, "ep_reward": 866.4027709960938, "reward": 0.8236180543899536, "action": -1.5777080059051514}
{"mode": "train", "epochs": 4, "timestep": 7549, "ep_reward": 867.1620483398438, "reward": 0.7592889070510864, "action": -1.157296895980835}
{"mode": "train", "epochs": 4, "timestep": 7550, "ep_reward": 867.8292236328125, "reward": 0.6671814918518066, "action": -0.2747325301170349}
{"mode": "train", "epochs": 4, "timestep": 7551, "ep_reward": 868.378173828125, "reward": 0.5489500761032104, "action": -1.556746006011963}
{"mode": "train", "epochs": 4, "timestep": 7552, "ep_reward": 868.7573852539062, "reward": 0.3792099952697754, "action": -1.1451793909072876}
{"mode": "train", "epochs": 4, "timestep": 7553, "ep_reward": 869.0326538085938, "reward": 0.27525079250335693, "action": -1.1571569442749023}
{"mode": "train", "epochs": 4, "timestep": 7554, "ep_reward": 869.1839599609375, "reward": 0.15130507946014404, "action": -1.0779458284378052}
{"mode": "train", "epochs": 4, "timestep": 7555, "ep_reward": 869.1912231445312, "reward": 0.0072730183601379395, "action": -1.5413105487823486}
{"mode": "train", "epochs": 4, "timestep": 7556, "ep_reward": 869.2998046875, "reward": 0.1085767149925232, "action": -0.4538639187812805}
{"mode": "train", "epochs": 4, "timestep": 7557, "ep_reward": 869.5537109375, "reward": 0.253876268863678, "action": -0.7172292470932007}
{"mode": "train", "epochs": 4, "timestep": 7558, "ep_reward": 869.9483642578125, "reward": 0.3946424722671509, "action": -0.2733442783355713}
{"mode": "train", "epochs": 4, "timestep": 7559, "ep_reward": 870.478271484375, "reward": 0.5299332141876221, "action": -0.954833447933197}
{"mode": "train", "epochs": 4, "timestep": 7560, "ep_reward": 871.1168823242188, "reward": 0.6386181116104126, "action": -1.1670559644699097}
{"mode": "train", "epochs": 4, "timestep": 7561, "ep_reward": 871.84130859375, "reward": 0.7244017124176025, "action": -0.46840745210647583}
{"mode": "train", "epochs": 4, "timestep": 7562, "ep_reward": 872.6366577148438, "reward": 0.7953586578369141, "action": -1.5082499980926514}
{"mode": "train", "epochs": 4, "timestep": 7563, "ep_reward": 873.474609375, "reward": 0.83796226978302, "action": -0.49012380838394165}
{"mode": "train", "epochs": 4, "timestep": 7564, "ep_reward": 874.3470458984375, "reward": 0.8724173307418823, "action": -0.8069710731506348}
{"mode": "train", "epochs": 4, "timestep": 7565, "ep_reward": 875.2366333007812, "reward": 0.8896067142486572, "action": -0.6693248748779297}
{"mode": "train", "epochs": 4, "timestep": 7566, "ep_reward": 876.131103515625, "reward": 0.894453763961792, "action": -1.3944106101989746}
{"mode": "train", "epochs": 4, "timestep": 7567, "ep_reward": 877.0112915039062, "reward": 0.8802083730697632, "action": 0.28666746616363525}
{"mode": "train", "epochs": 4, "timestep": 7568, "ep_reward": 877.87548828125, "reward": 0.8641712069511414, "action": -1.055793046951294}
{"mode": "train", "epochs": 4, "timestep": 7569, "ep_reward": 878.6940307617188, "reward": 0.8185449838638306, "action": -0.992387592792511}
{"mode": "train", "epochs": 4, "timestep": 7570, "ep_reward": 879.4428100585938, "reward": 0.7487819194793701, "action": -0.2851525545120239}
{"mode": "train", "epochs": 4, "timestep": 7571, "ep_reward": 880.0993041992188, "reward": 0.6564695239067078, "action": -1.3184632062911987}
{"mode": "train", "epochs": 4, "timestep": 7572, "ep_reward": 880.6145629882812, "reward": 0.5152652263641357, "action": -0.4606265425682068}
{"mode": "train", "epochs": 4, "timestep": 7573, "ep_reward": 880.9616088867188, "reward": 0.3470200300216675, "action": -1.5986859798431396}
{"mode": "train", "epochs": 4, "timestep": 7574, "ep_reward": 881.191650390625, "reward": 0.23006582260131836, "action": -0.9626455307006836}
{"mode": "train", "epochs": 4, "timestep": 7575, "ep_reward": 881.2900390625, "reward": 0.09837877750396729, "action": -1.3402704000473022}
{"mode": "train", "epochs": 4, "timestep": 7576, "ep_reward": 881.308349609375, "reward": 0.01828700304031372, "action": -1.3633191585540771}
{"mode": "train", "epochs": 4, "timestep": 7577, "ep_reward": 881.46923828125, "reward": 0.16088300943374634, "action": -0.8312704563140869}
{"mode": "train", "epochs": 4, "timestep": 7578, "ep_reward": 881.7720336914062, "reward": 0.3027713894844055, "action": -0.6233655214309692}
{"mode": "train", "epochs": 4, "timestep": 7579, "ep_reward": 882.2150268554688, "reward": 0.4429889917373657, "action": -1.3014429807662964}
{"mode": "train", "epochs": 4, "timestep": 7580, "ep_reward": 882.7764282226562, "reward": 0.561403751373291, "action": -1.2166942358016968}
{"mode": "train", "epochs": 4, "timestep": 7581, "ep_reward": 883.4383544921875, "reward": 0.661933422088623, "action": -0.5936539769172668}
{"mode": "train", "epochs": 4, "timestep": 7582, "ep_reward": 884.1847534179688, "reward": 0.746379017829895, "action": -1.404498815536499}
{"mode": "train", "epochs": 4, "timestep": 7583, "ep_reward": 884.9856567382812, "reward": 0.8009135127067566, "action": -1.7192072868347168}
{"mode": "train", "epochs": 4, "timestep": 7584, "ep_reward": 885.8194580078125, "reward": 0.8338007926940918, "action": -1.184049367904663}
{"mode": "train", "epochs": 4, "timestep": 7585, "ep_reward": 886.6732788085938, "reward": 0.8537904620170593, "action": -0.07717126607894897}
{"mode": "train", "epochs": 4, "timestep": 7586, "ep_reward": 887.539306640625, "reward": 0.866029679775238, "action": -1.0525176525115967}
{"mode": "train", "epochs": 4, "timestep": 7587, "ep_reward": 888.3919677734375, "reward": 0.8526333570480347, "action": -1.2088475227355957}
{"mode": "train", "epochs": 4, "timestep": 7588, "ep_reward": 889.2098999023438, "reward": 0.8179622292518616, "action": -0.7883361577987671}
{"mode": "train", "epochs": 4, "timestep": 7589, "ep_reward": 889.97265625, "reward": 0.7627601623535156, "action": -1.3874411582946777}
{"mode": "train", "epochs": 4, "timestep": 7590, "ep_reward": 890.642333984375, "reward": 0.6697076559066772, "action": -1.0534336566925049}
{"mode": "train", "epochs": 4, "timestep": 7591, "ep_reward": 891.1839599609375, "reward": 0.5416387915611267, "action": -0.9120666980743408}
{"mode": "train", "epochs": 4, "timestep": 7592, "ep_reward": 891.566650390625, "reward": 0.3826783299446106, "action": -0.5465291738510132}
{"mode": "train", "epochs": 4, "timestep": 7593, "ep_reward": 891.8460693359375, "reward": 0.27940237522125244, "action": -1.0176633596420288}
{"mode": "train", "epochs": 4, "timestep": 7594, "ep_reward": 892.0023193359375, "reward": 0.15623492002487183, "action": -0.22113186120986938}
{"mode": "train", "epochs": 4, "timestep": 7595, "ep_reward": 892.0152587890625, "reward": 0.012928307056427002, "action": -1.1385005712509155}
{"mode": "train", "epochs": 4, "timestep": 7596, "ep_reward": 892.11865234375, "reward": 0.10340583324432373, "action": -1.0582166910171509}
{"mode": "train", "epochs": 4, "timestep": 7597, "ep_reward": 892.3596801757812, "reward": 0.24102842807769775, "action": -1.0579322576522827}
{"mode": "train", "epochs": 4, "timestep": 7598, "ep_reward": 892.7391357421875, "reward": 0.3794434666633606, "action": -0.4402403235435486}
{"mode": "train", "epochs": 4, "timestep": 7599, "ep_reward": 893.2548828125, "reward": 0.5157721042633057, "action": -0.8465099930763245}
{"mode": "train", "epochs": 4, "timestep": 7600, "ep_reward": 893.8831787109375, "reward": 0.6283056735992432, "action": -1.2016100883483887}
{"mode": "train", "epochs": 4, "timestep": 7601, "ep_reward": 894.5985107421875, "reward": 0.7153388261795044, "action": -0.6285858154296875}
{"mode": "train", "epochs": 4, "timestep": 7602, "ep_reward": 895.3844604492188, "reward": 0.7859215140342712, "action": -0.39442193508148193}
{"mode": "train", "epochs": 4, "timestep": 7603, "ep_reward": 896.221923828125, "reward": 0.8374544978141785, "action": -0.8568832874298096}
{"mode": "train", "epochs": 4, "timestep": 7604, "ep_reward": 897.0888671875, "reward": 0.8669561147689819, "action": -1.978340983390808}
{"mode": "train", "epochs": 4, "timestep": 7605, "ep_reward": 897.9613037109375, "reward": 0.8724324703216553, "action": -1.0127029418945312}
{"mode": "train", "epochs": 4, "timestep": 7606, "ep_reward": 898.8316040039062, "reward": 0.8703197836875916, "action": -1.1821298599243164}
{"mode": "train", "epochs": 4, "timestep": 7607, "ep_reward": 899.6814575195312, "reward": 0.8498657941818237, "action": -0.4568406939506531}
{"mode": "train", "epochs": 4, "timestep": 7608, "ep_reward": 900.4974975585938, "reward": 0.8160486221313477, "action": -0.9609256982803345}
{"mode": "train", "epochs": 4, "timestep": 7609, "ep_reward": 901.2504272460938, "reward": 0.7529393434524536, "action": -0.3775625228881836}
{"mode": "train", "epochs": 4, "timestep": 7610, "ep_reward": 901.9161987304688, "reward": 0.6657726764678955, "action": -0.6419780254364014}
{"mode": "train", "epochs": 4, "timestep": 7611, "ep_reward": 902.455810546875, "reward": 0.5396044850349426, "action": -1.4665387868881226}
{"mode": "train", "epochs": 4, "timestep": 7612, "ep_reward": 902.8216552734375, "reward": 0.36587220430374146, "action": -1.1748363971710205}
{"mode": "train", "epochs": 4, "timestep": 7613, "ep_reward": 903.0808715820312, "reward": 0.25919264554977417, "action": -0.43582797050476074}
{"mode": "train", "epochs": 4, "timestep": 7614, "ep_reward": 903.2132568359375, "reward": 0.1324002742767334, "action": -0.9032193422317505}
{"mode": "train", "epochs": 4, "timestep": 7615, "ep_reward": 903.1988525390625, "reward": -0.014407157897949219, "action": -1.300572156906128}
{"mode": "train", "epochs": 4, "timestep": 7616, "ep_reward": 903.3267822265625, "reward": 0.1279253363609314, "action": -1.0776047706604004}
{"mode": "train", "epochs": 4, "timestep": 7617, "ep_reward": 903.5928344726562, "reward": 0.2660248279571533, "action": -0.6104416847229004}
{"mode": "train", "epochs": 4, "timestep": 7618, "ep_reward": 904.0016479492188, "reward": 0.40883976221084595, "action": -0.7756160497665405}
{"mode": "train", "epochs": 4, "timestep": 7619, "ep_reward": 904.5391845703125, "reward": 0.537509560585022, "action": -1.1082203388214111}
{"mode": "train", "epochs": 4, "timestep": 7620, "ep_reward": 905.1826782226562, "reward": 0.64351886510849, "action": -1.127718448638916}
{"mode": "train", "epochs": 4, "timestep": 7621, "ep_reward": 905.9103393554688, "reward": 0.7276767492294312, "action": -1.3240195512771606}
{"mode": "train", "epochs": 4, "timestep": 7622, "ep_reward": 906.6987915039062, "reward": 0.788425087928772, "action": -1.0465911626815796}
{"mode": "train", "epochs": 4, "timestep": 7623, "ep_reward": 907.5307006835938, "reward": 0.8319142460823059, "action": -0.6407373547554016}
{"mode": "train", "epochs": 4, "timestep": 7624, "ep_reward": 908.3914184570312, "reward": 0.8607422709465027, "action": -0.8446847796440125}
{"mode": "train", "epochs": 4, "timestep": 7625, "ep_reward": 909.2628173828125, "reward": 0.871385931968689, "action": -0.8670742511749268}
{"mode": "train", "epochs": 4, "timestep": 7626, "ep_reward": 910.12841796875, "reward": 0.8656303286552429, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7627, "ep_reward": 910.960205078125, "reward": 0.8318146467208862, "action": -0.5955923199653625}
{"mode": "train", "epochs": 4, "timestep": 7628, "ep_reward": 911.7483520507812, "reward": 0.7881565093994141, "action": 0.07635986804962158}
{"mode": "train", "epochs": 4, "timestep": 7629, "ep_reward": 912.4737548828125, "reward": 0.7253737449645996, "action": -0.8013957142829895}
{"mode": "train", "epochs": 4, "timestep": 7630, "ep_reward": 913.0943603515625, "reward": 0.6205823421478271, "action": -0.9761819243431091}
{"mode": "train", "epochs": 4, "timestep": 7631, "ep_reward": 913.5685424804688, "reward": 0.47421085834503174, "action": -1.470276951789856}
{"mode": "train", "epochs": 4, "timestep": 7632, "ep_reward": 913.898681640625, "reward": 0.33014076948165894, "action": -1.1740601062774658}
{"mode": "train", "epochs": 4, "timestep": 7633, "ep_reward": 914.1149291992188, "reward": 0.21624672412872314, "action": -1.2817782163619995}
{"mode": "train", "epochs": 4, "timestep": 7634, "ep_reward": 914.1973266601562, "reward": 0.0823904275894165, "action": -1.14645254611969}
{"mode": "train", "epochs": 4, "timestep": 7635, "ep_reward": 914.2326049804688, "reward": 0.03529888391494751, "action": -1.2192840576171875}
{"mode": "train", "epochs": 4, "timestep": 7636, "ep_reward": 914.408203125, "reward": 0.1756100058555603, "action": -0.9853366017341614}
{"mode": "train", "epochs": 4, "timestep": 7637, "ep_reward": 914.723876953125, "reward": 0.31568318605422974, "action": -1.7679369449615479}
{"mode": "train", "epochs": 4, "timestep": 7638, "ep_reward": 915.1657104492188, "reward": 0.4418228268623352, "action": -1.174088954925537}
{"mode": "train", "epochs": 4, "timestep": 7639, "ep_reward": 915.7282104492188, "reward": 0.5625248551368713, "action": -1.953873634338379}
{"mode": "train", "epochs": 4, "timestep": 7640, "ep_reward": 916.3826293945312, "reward": 0.6544484496116638, "action": -1.1319414377212524}
{"mode": "train", "epochs": 4, "timestep": 7641, "ep_reward": 917.1155395507812, "reward": 0.732934832572937, "action": -1.1584635972976685}
{"mode": "train", "epochs": 4, "timestep": 7642, "ep_reward": 917.9031982421875, "reward": 0.7876328825950623, "action": -0.9067245125770569}
{"mode": "train", "epochs": 4, "timestep": 7643, "ep_reward": 918.7259521484375, "reward": 0.8227633237838745, "action": -1.5896828174591064}
{"mode": "train", "epochs": 4, "timestep": 7644, "ep_reward": 919.5571899414062, "reward": 0.8312156200408936, "action": -0.3539121150970459}
{"mode": "train", "epochs": 4, "timestep": 7645, "ep_reward": 920.3880615234375, "reward": 0.8308491706848145, "action": -0.49330997467041016}
{"mode": "train", "epochs": 4, "timestep": 7646, "ep_reward": 921.1954345703125, "reward": 0.8073973059654236, "action": -1.1911494731903076}
{"mode": "train", "epochs": 4, "timestep": 7647, "ep_reward": 921.946533203125, "reward": 0.751114010810852, "action": -0.6834876537322998}
{"mode": "train", "epochs": 4, "timestep": 7648, "ep_reward": 922.6149291992188, "reward": 0.6684252619743347, "action": -0.6414293050765991}
{"mode": "train", "epochs": 4, "timestep": 7649, "ep_reward": 923.1633911132812, "reward": 0.5484448671340942, "action": -1.5177419185638428}
{"mode": "train", "epochs": 4, "timestep": 7650, "ep_reward": 923.5571899414062, "reward": 0.39378249645233154, "action": -1.2175896167755127}
{"mode": "train", "epochs": 4, "timestep": 7651, "ep_reward": 923.8501586914062, "reward": 0.29296624660491943, "action": -1.318976640701294}
{"mode": "train", "epochs": 4, "timestep": 7652, "ep_reward": 924.0223999023438, "reward": 0.17221689224243164, "action": -0.966684103012085}
{"mode": "train", "epochs": 4, "timestep": 7653, "ep_reward": 924.0538330078125, "reward": 0.031443774700164795, "action": -0.7206618785858154}
{"mode": "train", "epochs": 4, "timestep": 7654, "ep_reward": 924.1399536132812, "reward": 0.08613693714141846, "action": -1.067145824432373}
{"mode": "train", "epochs": 4, "timestep": 7655, "ep_reward": 924.3631591796875, "reward": 0.22318315505981445, "action": -0.5682920813560486}
{"mode": "train", "epochs": 4, "timestep": 7656, "ep_reward": 924.7313232421875, "reward": 0.36815065145492554, "action": -0.9923244118690491}
{"mode": "train", "epochs": 4, "timestep": 7657, "ep_reward": 925.2301025390625, "reward": 0.49877285957336426, "action": -0.25549834966659546}
{"mode": "train", "epochs": 4, "timestep": 7658, "ep_reward": 925.8505249023438, "reward": 0.6204155683517456, "action": -1.3812904357910156}
{"mode": "train", "epochs": 4, "timestep": 7659, "ep_reward": 926.5582275390625, "reward": 0.7076820135116577, "action": -0.7160506248474121}
{"mode": "train", "epochs": 4, "timestep": 7660, "ep_reward": 927.3380737304688, "reward": 0.7798463106155396, "action": -1.6376430988311768}
{"mode": "train", "epochs": 4, "timestep": 7661, "ep_reward": 928.16162109375, "reward": 0.8235549330711365, "action": -0.012881577014923096}
{"mode": "train", "epochs": 4, "timestep": 7662, "ep_reward": 929.0248413085938, "reward": 0.8632349371910095, "action": -0.14046192169189453}
{"mode": "train", "epochs": 4, "timestep": 7663, "ep_reward": 929.9100952148438, "reward": 0.8852478861808777, "action": 0.15592634677886963}
{"mode": "train", "epochs": 4, "timestep": 7664, "ep_reward": 930.8052978515625, "reward": 0.8951790928840637, "action": -1.5056185722351074}
{"mode": "train", "epochs": 4, "timestep": 7665, "ep_reward": 931.6837768554688, "reward": 0.8785091638565063, "action": -1.774584412574768}
{"mode": "train", "epochs": 4, "timestep": 7666, "ep_reward": 932.526123046875, "reward": 0.8423432111740112, "action": -0.48431938886642456}
{"mode": "train", "epochs": 4, "timestep": 7667, "ep_reward": 933.3222045898438, "reward": 0.7960807085037231, "action": -0.9743338823318481}
{"mode": "train", "epochs": 4, "timestep": 7668, "ep_reward": 934.0404663085938, "reward": 0.7182654142379761, "action": -1.3066189289093018}
{"mode": "train", "epochs": 4, "timestep": 7669, "ep_reward": 934.6422729492188, "reward": 0.6018365621566772, "action": -1.2581332921981812}
{"mode": "train", "epochs": 4, "timestep": 7670, "ep_reward": 935.0868530273438, "reward": 0.4445698857307434, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7671, "ep_reward": 935.3973388671875, "reward": 0.3104982376098633, "action": 0.17483794689178467}
{"mode": "train", "epochs": 4, "timestep": 7672, "ep_reward": 935.590087890625, "reward": 0.19275766611099243, "action": -1.4645311832427979}
{"mode": "train", "epochs": 4, "timestep": 7673, "ep_reward": 935.6453247070312, "reward": 0.05524486303329468, "action": -0.7902398705482483}
{"mode": "train", "epochs": 4, "timestep": 7674, "ep_reward": 935.7083740234375, "reward": 0.06303143501281738, "action": -0.8712766766548157}
{"mode": "train", "epochs": 4, "timestep": 7675, "ep_reward": 935.909912109375, "reward": 0.20156800746917725, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7676, "ep_reward": 936.239013671875, "reward": 0.32908129692077637, "action": -0.8792851567268372}
{"mode": "train", "epochs": 4, "timestep": 7677, "ep_reward": 936.7052612304688, "reward": 0.46626126766204834, "action": -1.4588886499404907}
{"mode": "train", "epochs": 4, "timestep": 7678, "ep_reward": 937.28564453125, "reward": 0.5803602933883667, "action": -1.3507965803146362}
{"mode": "train", "epochs": 4, "timestep": 7679, "ep_reward": 937.96044921875, "reward": 0.6747965812683105, "action": -0.8329009413719177}
{"mode": "train", "epochs": 4, "timestep": 7680, "ep_reward": 938.7114868164062, "reward": 0.751017153263092, "action": -0.6697773337364197}
{"mode": "train", "epochs": 4, "timestep": 7681, "ep_reward": 939.5167846679688, "reward": 0.8052724003791809, "action": -0.8615176677703857}
{"mode": "train", "epochs": 4, "timestep": 7682, "ep_reward": 940.3534545898438, "reward": 0.8366588950157166, "action": -0.47759419679641724}
{"mode": "train", "epochs": 4, "timestep": 7683, "ep_reward": 941.2056884765625, "reward": 0.8522465229034424, "action": -1.832288384437561}
{"mode": "train", "epochs": 4, "timestep": 7684, "ep_reward": 942.0426025390625, "reward": 0.8369372487068176, "action": -1.2370257377624512}
{"mode": "train", "epochs": 4, "timestep": 7685, "ep_reward": 942.8478393554688, "reward": 0.8052520155906677, "action": -1.3704710006713867}
{"mode": "train", "epochs": 4, "timestep": 7686, "ep_reward": 943.59326171875, "reward": 0.7454280853271484, "action": -0.831379771232605}
{"mode": "train", "epochs": 4, "timestep": 7687, "ep_reward": 944.2517700195312, "reward": 0.6585385799407959, "action": -0.14678096771240234}
{"mode": "train", "epochs": 4, "timestep": 7688, "ep_reward": 944.7944946289062, "reward": 0.5427476167678833, "action": -0.857479453086853}
{"mode": "train", "epochs": 4, "timestep": 7689, "ep_reward": 945.183349609375, "reward": 0.388843297958374, "action": -0.734923243522644}
{"mode": "train", "epochs": 4, "timestep": 7690, "ep_reward": 945.47021484375, "reward": 0.2868956923484802, "action": -1.1192156076431274}
{"mode": "train", "epochs": 4, "timestep": 7691, "ep_reward": 945.6351318359375, "reward": 0.16491204500198364, "action": -1.582141399383545}
{"mode": "train", "epochs": 4, "timestep": 7692, "ep_reward": 945.658203125, "reward": 0.023097217082977295, "action": -1.00681734085083}
{"mode": "train", "epochs": 4, "timestep": 7693, "ep_reward": 945.7522583007812, "reward": 0.09404754638671875, "action": -0.5344904661178589}
{"mode": "train", "epochs": 4, "timestep": 7694, "ep_reward": 945.9901733398438, "reward": 0.23790216445922852, "action": -1.0652748346328735}
{"mode": "train", "epochs": 4, "timestep": 7695, "ep_reward": 946.3654174804688, "reward": 0.37524640560150146, "action": -0.21000128984451294}
{"mode": "train", "epochs": 4, "timestep": 7696, "ep_reward": 946.8792724609375, "reward": 0.5138533115386963, "action": -1.5709242820739746}
{"mode": "train", "epochs": 4, "timestep": 7697, "ep_reward": 947.4981689453125, "reward": 0.6188923120498657, "action": -1.0766676664352417}
{"mode": "train", "epochs": 4, "timestep": 7698, "ep_reward": 948.2074584960938, "reward": 0.709291934967041, "action": -0.2843812108039856}
{"mode": "train", "epochs": 4, "timestep": 7699, "ep_reward": 948.9923706054688, "reward": 0.7848817706108093, "action": -0.8939244151115417}
{"mode": "train", "epochs": 4, "timestep": 7700, "ep_reward": 949.8262329101562, "reward": 0.8338716626167297, "action": -0.2218807339668274}
{"mode": "train", "epochs": 4, "timestep": 7701, "ep_reward": 950.6968383789062, "reward": 0.8706023693084717, "action": -1.1099380254745483}
{"mode": "train", "epochs": 4, "timestep": 7702, "ep_reward": 951.58203125, "reward": 0.8851866722106934, "action": 0.1943451166152954}
{"mode": "train", "epochs": 4, "timestep": 7703, "ep_reward": 952.4780883789062, "reward": 0.8960801959037781, "action": -0.813569188117981}
{"mode": "train", "epochs": 4, "timestep": 7704, "ep_reward": 953.364013671875, "reward": 0.8859245777130127, "action": -0.3206844925880432}
{"mode": "train", "epochs": 4, "timestep": 7705, "ep_reward": 954.228759765625, "reward": 0.8647213578224182, "action": -1.3962444067001343}
{"mode": "train", "epochs": 4, "timestep": 7706, "ep_reward": 955.04443359375, "reward": 0.8156554102897644, "action": -0.5337471961975098}
{"mode": "train", "epochs": 4, "timestep": 7707, "ep_reward": 955.79443359375, "reward": 0.7500254511833191, "action": -0.1808912754058838}
{"mode": "train", "epochs": 4, "timestep": 7708, "ep_reward": 956.45361328125, "reward": 0.6591552495956421, "action": -1.0226945877075195}
{"mode": "train", "epochs": 4, "timestep": 7709, "ep_reward": 956.9765625, "reward": 0.5229431390762329, "action": -0.685534656047821}
{"mode": "train", "epochs": 4, "timestep": 7710, "ep_reward": 957.3296508789062, "reward": 0.35310113430023193, "action": -0.1566307544708252}
{"mode": "train", "epochs": 4, "timestep": 7711, "ep_reward": 957.5609130859375, "reward": 0.23128128051757812, "action": 0.1354081630706787}
{"mode": "train", "epochs": 4, "timestep": 7712, "ep_reward": 957.6607055664062, "reward": 0.09979003667831421, "action": -0.795147180557251}
{"mode": "train", "epochs": 4, "timestep": 7713, "ep_reward": 957.6776733398438, "reward": 0.016944825649261475, "action": -0.6542036533355713}
{"mode": "train", "epochs": 4, "timestep": 7714, "ep_reward": 957.8372192382812, "reward": 0.15954190492630005, "action": -1.5511894226074219}
{"mode": "train", "epochs": 4, "timestep": 7715, "ep_reward": 958.1296997070312, "reward": 0.29249024391174316, "action": -0.12533414363861084}
{"mode": "train", "epochs": 4, "timestep": 7716, "ep_reward": 958.5702514648438, "reward": 0.4405786395072937, "action": -1.6448192596435547}
{"mode": "train", "epochs": 4, "timestep": 7717, "ep_reward": 959.1259765625, "reward": 0.5557137727737427, "action": -0.4711458086967468}
{"mode": "train", "epochs": 4, "timestep": 7718, "ep_reward": 959.7908325195312, "reward": 0.6648728847503662, "action": -1.3926031589508057}
{"mode": "train", "epochs": 4, "timestep": 7719, "ep_reward": 960.5319213867188, "reward": 0.7410842180252075, "action": -1.071154236793518}
{"mode": "train", "epochs": 4, "timestep": 7720, "ep_reward": 961.3309326171875, "reward": 0.7990052700042725, "action": -0.8840961456298828}
{"mode": "train", "epochs": 4, "timestep": 7721, "ep_reward": 962.1694946289062, "reward": 0.8385900259017944, "action": -0.6481802463531494}
{"mode": "train", "epochs": 4, "timestep": 7722, "ep_reward": 963.0316162109375, "reward": 0.8621505498886108, "action": -0.7129091620445251}
{"mode": "train", "epochs": 4, "timestep": 7723, "ep_reward": 963.9000244140625, "reward": 0.8684301376342773, "action": -1.5430727005004883}
{"mode": "train", "epochs": 4, "timestep": 7724, "ep_reward": 964.750732421875, "reward": 0.850684404373169, "action": -1.077000379562378}
{"mode": "train", "epochs": 4, "timestep": 7725, "ep_reward": 965.5675048828125, "reward": 0.8167966604232788, "action": -1.3502711057662964}
{"mode": "train", "epochs": 4, "timestep": 7726, "ep_reward": 966.3223876953125, "reward": 0.7548953890800476, "action": -0.7974758744239807}
{"mode": "train", "epochs": 4, "timestep": 7727, "ep_reward": 966.9896240234375, "reward": 0.6672173738479614, "action": -0.19031459093093872}
{"mode": "train", "epochs": 4, "timestep": 7728, "ep_reward": 967.5404663085938, "reward": 0.5508444905281067, "action": -0.6730849742889404}
{"mode": "train", "epochs": 4, "timestep": 7729, "ep_reward": 967.928955078125, "reward": 0.38849568367004395, "action": -1.2043797969818115}
{"mode": "train", "epochs": 4, "timestep": 7730, "ep_reward": 968.2080078125, "reward": 0.27902400493621826, "action": -1.9758881330490112}
{"mode": "train", "epochs": 4, "timestep": 7731, "ep_reward": 968.3639526367188, "reward": 0.15594828128814697, "action": -0.8503516316413879}
{"mode": "train", "epochs": 4, "timestep": 7732, "ep_reward": 968.3765869140625, "reward": 0.012644171714782715, "action": -1.0760762691497803}
{"mode": "train", "epochs": 4, "timestep": 7733, "ep_reward": 968.480224609375, "reward": 0.10364556312561035, "action": -1.3282067775726318}
{"mode": "train", "epochs": 4, "timestep": 7734, "ep_reward": 968.7181396484375, "reward": 0.2379370927810669, "action": -0.7870245575904846}
{"mode": "train", "epochs": 4, "timestep": 7735, "ep_reward": 969.0984497070312, "reward": 0.3802919387817383, "action": -0.9536553621292114}
{"mode": "train", "epochs": 4, "timestep": 7736, "ep_reward": 969.6089477539062, "reward": 0.5105018615722656, "action": -1.6541132926940918}
{"mode": "train", "epochs": 4, "timestep": 7737, "ep_reward": 970.2241821289062, "reward": 0.6152634620666504, "action": -1.6256091594696045}
{"mode": "train", "epochs": 4, "timestep": 7738, "ep_reward": 970.9239501953125, "reward": 0.6997607350349426, "action": -1.5365681648254395}
{"mode": "train", "epochs": 4, "timestep": 7739, "ep_reward": 971.6870727539062, "reward": 0.7630938291549683, "action": -0.9486019611358643}
{"mode": "train", "epochs": 4, "timestep": 7740, "ep_reward": 972.497314453125, "reward": 0.810259222984314, "action": -1.1489143371582031}
{"mode": "train", "epochs": 4, "timestep": 7741, "ep_reward": 973.3323364257812, "reward": 0.8350074887275696, "action": -0.8113852739334106}
{"mode": "train", "epochs": 4, "timestep": 7742, "ep_reward": 974.17578125, "reward": 0.8434475064277649, "action": -0.9085904955863953}
{"mode": "train", "epochs": 4, "timestep": 7743, "ep_reward": 975.0070190429688, "reward": 0.8312321901321411, "action": -0.7580304145812988}
{"mode": "train", "epochs": 4, "timestep": 7744, "ep_reward": 975.8053588867188, "reward": 0.7983313202857971, "action": -0.8727054595947266}
{"mode": "train", "epochs": 4, "timestep": 7745, "ep_reward": 976.54296875, "reward": 0.737601101398468, "action": -0.27367842197418213}
{"mode": "train", "epochs": 4, "timestep": 7746, "ep_reward": 977.1945190429688, "reward": 0.6515635251998901, "action": -1.1739864349365234}
{"mode": "train", "epochs": 4, "timestep": 7747, "ep_reward": 977.7099609375, "reward": 0.5154604911804199, "action": -0.8853771090507507}
{"mode": "train", "epochs": 4, "timestep": 7748, "ep_reward": 978.080810546875, "reward": 0.37084877490997314, "action": -0.5896555781364441}
{"mode": "train", "epochs": 4, "timestep": 7749, "ep_reward": 978.3458251953125, "reward": 0.265028178691864, "action": -1.2667746543884277}
{"mode": "train", "epochs": 4, "timestep": 7750, "ep_reward": 978.4851684570312, "reward": 0.13936841487884521, "action": -0.5002740621566772}
{"mode": "train", "epochs": 4, "timestep": 7751, "ep_reward": 978.4786987304688, "reward": -0.0064994096755981445, "action": -1.478448510169983}
{"mode": "train", "epochs": 4, "timestep": 7752, "ep_reward": 978.5996704101562, "reward": 0.12094736099243164, "action": -0.9297105669975281}
{"mode": "train", "epochs": 4, "timestep": 7753, "ep_reward": 978.8602905273438, "reward": 0.2606455683708191, "action": -1.137681245803833}
{"mode": "train", "epochs": 4, "timestep": 7754, "ep_reward": 979.2573852539062, "reward": 0.3970752954483032, "action": 0.13163459300994873}
{"mode": "train", "epochs": 4, "timestep": 7755, "ep_reward": 979.7952270507812, "reward": 0.5378134250640869, "action": -0.6241276860237122}
{"mode": "train", "epochs": 4, "timestep": 7756, "ep_reward": 980.4439086914062, "reward": 0.6486914753913879, "action": -1.1059070825576782}
{"mode": "train", "epochs": 4, "timestep": 7757, "ep_reward": 981.1763916015625, "reward": 0.7325121164321899, "action": -1.667698860168457}
{"mode": "train", "epochs": 4, "timestep": 7758, "ep_reward": 981.9669189453125, "reward": 0.7905101776123047, "action": -1.7031819820404053}
{"mode": "train", "epochs": 4, "timestep": 7759, "ep_reward": 982.7968139648438, "reward": 0.8299251794815063, "action": -0.8602374792098999}
{"mode": "train", "epochs": 4, "timestep": 7760, "ep_reward": 983.656005859375, "reward": 0.8592145442962646, "action": -1.060795783996582}
{"mode": "train", "epochs": 4, "timestep": 7761, "ep_reward": 984.5264892578125, "reward": 0.8704776167869568, "action": -1.369828224182129}
{"mode": "train", "epochs": 4, "timestep": 7762, "ep_reward": 985.3897094726562, "reward": 0.8632088303565979, "action": -0.085793137550354}
{"mode": "train", "epochs": 4, "timestep": 7763, "ep_reward": 986.2393798828125, "reward": 0.8496523499488831, "action": -0.7288820743560791}
{"mode": "train", "epochs": 4, "timestep": 7764, "ep_reward": 987.0499267578125, "reward": 0.8105418682098389, "action": -0.9957195520401001}
{"mode": "train", "epochs": 4, "timestep": 7765, "ep_reward": 987.7933349609375, "reward": 0.7433980703353882, "action": -1.2315948009490967}
{"mode": "train", "epochs": 4, "timestep": 7766, "ep_reward": 988.4340209960938, "reward": 0.6407018303871155, "action": -0.8198928833007812}
{"mode": "train", "epochs": 4, "timestep": 7767, "ep_reward": 988.9380493164062, "reward": 0.5040427446365356, "action": -0.4261539578437805}
{"mode": "train", "epochs": 4, "timestep": 7768, "ep_reward": 989.288330078125, "reward": 0.3503111004829407, "action": -0.678739070892334}
{"mode": "train", "epochs": 4, "timestep": 7769, "ep_reward": 989.5286865234375, "reward": 0.24035179615020752, "action": -0.8839552402496338}
{"mode": "train", "epochs": 4, "timestep": 7770, "ep_reward": 989.638916015625, "reward": 0.11020886898040771, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7771, "ep_reward": 989.6441650390625, "reward": 0.005259990692138672, "action": -1.367069959640503}
{"mode": "train", "epochs": 4, "timestep": 7772, "ep_reward": 989.7937622070312, "reward": 0.14959263801574707, "action": -0.5063416957855225}
{"mode": "train", "epochs": 4, "timestep": 7773, "ep_reward": 990.0889282226562, "reward": 0.29516690969467163, "action": -1.3984793424606323}
{"mode": "train", "epochs": 4, "timestep": 7774, "ep_reward": 990.5150146484375, "reward": 0.42608344554901123, "action": -0.6083904504776001}
{"mode": "train", "epochs": 4, "timestep": 7775, "ep_reward": 991.0697631835938, "reward": 0.5547537207603455, "action": -0.927428126335144}
{"mode": "train", "epochs": 4, "timestep": 7776, "ep_reward": 991.7293090820312, "reward": 0.6595321893692017, "action": -0.8356618285179138}
{"mode": "train", "epochs": 4, "timestep": 7777, "ep_reward": 992.4720458984375, "reward": 0.7427472472190857, "action": -1.5220069885253906}
{"mode": "train", "epochs": 4, "timestep": 7778, "ep_reward": 993.2701416015625, "reward": 0.798069179058075, "action": -1.3218809366226196}
{"mode": "train", "epochs": 4, "timestep": 7779, "ep_reward": 994.1064453125, "reward": 0.8362916111946106, "action": -1.413006067276001}
{"mode": "train", "epochs": 4, "timestep": 7780, "ep_reward": 994.9627685546875, "reward": 0.856350839138031, "action": -1.2068312168121338}
{"mode": "train", "epochs": 4, "timestep": 7781, "ep_reward": 995.8240966796875, "reward": 0.8613530397415161, "action": -1.616347312927246}
{"mode": "train", "epochs": 4, "timestep": 7782, "ep_reward": 996.6692504882812, "reward": 0.8451691269874573, "action": -0.7323161363601685}
{"mode": "train", "epochs": 4, "timestep": 7783, "ep_reward": 997.48583984375, "reward": 0.8165748119354248, "action": -0.41345739364624023}
{"mode": "train", "epochs": 4, "timestep": 7784, "ep_reward": 998.2531127929688, "reward": 0.7672722339630127, "action": -0.9333317875862122}
{"mode": "train", "epochs": 4, "timestep": 7785, "ep_reward": 998.9356689453125, "reward": 0.6825582981109619, "action": -1.6631972789764404}
{"mode": "train", "epochs": 4, "timestep": 7786, "ep_reward": 999.48583984375, "reward": 0.5501974821090698, "action": -1.1964399814605713}
{"mode": "train", "epochs": 4, "timestep": 7787, "ep_reward": 999.8760375976562, "reward": 0.3901691436767578, "action": -1.6561335325241089}
{"mode": "train", "epochs": 4, "timestep": 7788, "ep_reward": 1000.164794921875, "reward": 0.2887394428253174, "action": -0.5241870880126953}
{"mode": "train", "epochs": 4, "timestep": 7789, "ep_reward": 1000.3319091796875, "reward": 0.16714322566986084, "action": -0.6565976142883301}
{"mode": "train", "epochs": 4, "timestep": 7790, "ep_reward": 1000.357421875, "reward": 0.02554309368133545, "action": -0.7823077440261841}
{"mode": "train", "epochs": 4, "timestep": 7791, "ep_reward": 1000.4491577148438, "reward": 0.09176003932952881, "action": -0.7292554974555969}
{"mode": "train", "epochs": 4, "timestep": 7792, "ep_reward": 1000.6823120117188, "reward": 0.23314225673675537, "action": -0.8991267085075378}
{"mode": "train", "epochs": 4, "timestep": 7793, "ep_reward": 1001.0552978515625, "reward": 0.372996985912323, "action": -1.0548337697982788}
{"mode": "train", "epochs": 4, "timestep": 7794, "ep_reward": 1001.5575561523438, "reward": 0.5022884011268616, "action": -1.266315221786499}
{"mode": "train", "epochs": 4, "timestep": 7795, "ep_reward": 1002.1700439453125, "reward": 0.6125016212463379, "action": -1.7733361721038818}
{"mode": "train", "epochs": 4, "timestep": 7796, "ep_reward": 1002.8668212890625, "reward": 0.6967504024505615, "action": -1.6808607578277588}
{"mode": "train", "epochs": 4, "timestep": 7797, "ep_reward": 1003.627685546875, "reward": 0.7608751058578491, "action": -0.26851850748062134}
{"mode": "train", "epochs": 4, "timestep": 7798, "ep_reward": 1004.444580078125, "reward": 0.8168981075286865, "action": -0.8588457107543945}
{"mode": "train", "epochs": 4, "timestep": 7799, "ep_reward": 1005.2916870117188, "reward": 0.8471193909645081, "action": -0.9351411461830139}
{"mode": "train", "epochs": 4, "timestep": 7800, "ep_reward": 1006.1505126953125, "reward": 0.8588215112686157, "action": -1.26483154296875}
{"mode": "train", "epochs": 4, "timestep": 7801, "ep_reward": 1007.00048828125, "reward": 0.8499587774276733, "action": -1.56546151638031}
{"mode": "train", "epochs": 4, "timestep": 7802, "ep_reward": 1007.818603515625, "reward": 0.8181375861167908, "action": -1.379087209701538}
{"mode": "train", "epochs": 4, "timestep": 7803, "ep_reward": 1008.5813598632812, "reward": 0.7627789974212646, "action": -0.6163948774337769}
{"mode": "train", "epochs": 4, "timestep": 7804, "ep_reward": 1009.2661743164062, "reward": 0.6848053336143494, "action": -0.8402512073516846}
{"mode": "train", "epochs": 4, "timestep": 7805, "ep_reward": 1009.8335571289062, "reward": 0.5673966407775879, "action": 0.03197920322418213}
{"mode": "train", "epochs": 4, "timestep": 7806, "ep_reward": 1010.2557983398438, "reward": 0.4222257733345032, "action": -1.5013465881347656}
{"mode": "train", "epochs": 4, "timestep": 7807, "ep_reward": 1010.5615844726562, "reward": 0.30578291416168213, "action": -0.9764125943183899}
{"mode": "train", "epochs": 4, "timestep": 7808, "ep_reward": 1010.7487182617188, "reward": 0.18711739778518677, "action": -1.978606104850769}
{"mode": "train", "epochs": 4, "timestep": 7809, "ep_reward": 1010.79736328125, "reward": 0.04864943027496338, "action": -1.9177333116531372}
{"mode": "train", "epochs": 4, "timestep": 7810, "ep_reward": 1010.8666381835938, "reward": 0.06927824020385742, "action": -1.4589625597000122}
{"mode": "train", "epochs": 4, "timestep": 7811, "ep_reward": 1011.0716552734375, "reward": 0.20504337549209595, "action": -0.9688279628753662}
{"mode": "train", "epochs": 4, "timestep": 7812, "ep_reward": 1011.4173583984375, "reward": 0.3457334041595459, "action": -1.4241292476654053}
{"mode": "train", "epochs": 4, "timestep": 7813, "ep_reward": 1011.8914184570312, "reward": 0.47403454780578613, "action": -0.24499797821044922}
{"mode": "train", "epochs": 4, "timestep": 7814, "ep_reward": 1012.4917602539062, "reward": 0.600333571434021, "action": -1.378589153289795}
{"mode": "train", "epochs": 4, "timestep": 7815, "ep_reward": 1013.1830444335938, "reward": 0.6912537813186646, "action": -0.9014602303504944}
{"mode": "train", "epochs": 4, "timestep": 7816, "ep_reward": 1013.9478149414062, "reward": 0.7647744417190552, "action": -0.6350415349006653}
{"mode": "train", "epochs": 4, "timestep": 7817, "ep_reward": 1014.7666625976562, "reward": 0.8188778758049011, "action": -0.2645989656448364}
{"mode": "train", "epochs": 4, "timestep": 7818, "ep_reward": 1015.6229858398438, "reward": 0.856341540813446, "action": -1.7584540843963623}
{"mode": "train", "epochs": 4, "timestep": 7819, "ep_reward": 1016.4873657226562, "reward": 0.8643773794174194, "action": -1.913219928741455}
{"mode": "train", "epochs": 4, "timestep": 7820, "ep_reward": 1017.3418579101562, "reward": 0.8544933199882507, "action": -1.3787188529968262}
{"mode": "train", "epochs": 4, "timestep": 7821, "ep_reward": 1018.171875, "reward": 0.8300296068191528, "action": -0.7987664937973022}
{"mode": "train", "epochs": 4, "timestep": 7822, "ep_reward": 1018.9601440429688, "reward": 0.788249135017395, "action": -0.7630800008773804}
{"mode": "train", "epochs": 4, "timestep": 7823, "ep_reward": 1019.67919921875, "reward": 0.7190777063369751, "action": -1.2543662786483765}
{"mode": "train", "epochs": 4, "timestep": 7824, "ep_reward": 1020.2882080078125, "reward": 0.6090219616889954, "action": -1.2108606100082397}
{"mode": "train", "epochs": 4, "timestep": 7825, "ep_reward": 1020.745361328125, "reward": 0.4571569561958313, "action": -0.20488357543945312}
{"mode": "train", "epochs": 4, "timestep": 7826, "ep_reward": 1021.08154296875, "reward": 0.3361651301383972, "action": -1.10807466506958}
{"mode": "train", "epochs": 4, "timestep": 7827, "ep_reward": 1021.3049926757812, "reward": 0.223463773727417, "action": -0.9442508816719055}
{"mode": "train", "epochs": 4, "timestep": 7828, "ep_reward": 1021.3956909179688, "reward": 0.09068340063095093, "action": -1.335082769393921}
{"mode": "train", "epochs": 4, "timestep": 7829, "ep_reward": 1021.4223022460938, "reward": 0.02659386396408081, "action": -0.8772817850112915}
{"mode": "train", "epochs": 4, "timestep": 7830, "ep_reward": 1021.5902709960938, "reward": 0.16798001527786255, "action": -1.3312698602676392}
{"mode": "train", "epochs": 4, "timestep": 7831, "ep_reward": 1021.89404296875, "reward": 0.30377042293548584, "action": -1.0415284633636475}
{"mode": "train", "epochs": 4, "timestep": 7832, "ep_reward": 1022.333984375, "reward": 0.4399595260620117, "action": -0.6241873502731323}
{"mode": "train", "epochs": 4, "timestep": 7833, "ep_reward": 1022.9010009765625, "reward": 0.5670191049575806, "action": -1.2865865230560303}
{"mode": "train", "epochs": 4, "timestep": 7834, "ep_reward": 1023.5665893554688, "reward": 0.6656008958816528, "action": -1.0043259859085083}
{"mode": "train", "epochs": 4, "timestep": 7835, "ep_reward": 1024.311279296875, "reward": 0.7446491122245789, "action": -1.7402987480163574}
{"mode": "train", "epochs": 4, "timestep": 7836, "ep_reward": 1025.1060791015625, "reward": 0.7947421073913574, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7837, "ep_reward": 1025.92919921875, "reward": 0.8231330513954163, "action": -0.6875569224357605}
{"mode": "train", "epochs": 4, "timestep": 7838, "ep_reward": 1026.7735595703125, "reward": 0.8443273305892944, "action": -1.3054903745651245}
{"mode": "train", "epochs": 4, "timestep": 7839, "ep_reward": 1027.6143798828125, "reward": 0.8407819867134094, "action": -1.365952491760254}
{"mode": "train", "epochs": 4, "timestep": 7840, "ep_reward": 1028.43017578125, "reward": 0.8157650828361511, "action": -1.5420688390731812}
{"mode": "train", "epochs": 4, "timestep": 7841, "ep_reward": 1029.1937255859375, "reward": 0.7635746002197266, "action": -0.46493613719940186}
{"mode": "train", "epochs": 4, "timestep": 7842, "ep_reward": 1029.885986328125, "reward": 0.6922885179519653, "action": -1.0985280275344849}
{"mode": "train", "epochs": 4, "timestep": 7843, "ep_reward": 1030.4622802734375, "reward": 0.5763142108917236, "action": -0.9223839640617371}
{"mode": "train", "epochs": 4, "timestep": 7844, "ep_reward": 1030.8817138671875, "reward": 0.41948145627975464, "action": -0.49797946214675903}
{"mode": "train", "epochs": 4, "timestep": 7845, "ep_reward": 1031.2020263671875, "reward": 0.32036834955215454, "action": -0.9780693054199219}
{"mode": "train", "epochs": 4, "timestep": 7846, "ep_reward": 1031.40673828125, "reward": 0.2046712040901184, "action": -0.034138381481170654}
{"mode": "train", "epochs": 4, "timestep": 7847, "ep_reward": 1031.4755859375, "reward": 0.06890201568603516, "action": -0.40055638551712036}
{"mode": "train", "epochs": 4, "timestep": 7848, "ep_reward": 1031.52490234375, "reward": 0.04937177896499634, "action": -0.5067610740661621}
{"mode": "train", "epochs": 4, "timestep": 7849, "ep_reward": 1031.717041015625, "reward": 0.19214612245559692, "action": -1.3888449668884277}
{"mode": "train", "epochs": 4, "timestep": 7850, "ep_reward": 1032.043701171875, "reward": 0.32666683197021484, "action": -0.8239520192146301}
{"mode": "train", "epochs": 4, "timestep": 7851, "ep_reward": 1032.5072021484375, "reward": 0.46347516775131226, "action": -0.730600893497467}
{"mode": "train", "epochs": 4, "timestep": 7852, "ep_reward": 1033.093017578125, "reward": 0.5857894420623779, "action": -0.5268988609313965}
{"mode": "train", "epochs": 4, "timestep": 7853, "ep_reward": 1033.781494140625, "reward": 0.6884850263595581, "action": -0.5713279247283936}
{"mode": "train", "epochs": 4, "timestep": 7854, "ep_reward": 1034.548583984375, "reward": 0.767136812210083, "action": -0.3557943105697632}
{"mode": "train", "epochs": 4, "timestep": 7855, "ep_reward": 1035.374267578125, "reward": 0.8256769180297852, "action": -1.835507869720459}
{"mode": "train", "epochs": 4, "timestep": 7856, "ep_reward": 1036.22802734375, "reward": 0.853704571723938, "action": -1.2584898471832275}
{"mode": "train", "epochs": 4, "timestep": 7857, "ep_reward": 1037.0989990234375, "reward": 0.8709882497787476, "action": -1.0106602907180786}
{"mode": "train", "epochs": 4, "timestep": 7858, "ep_reward": 1037.97412109375, "reward": 0.8750926852226257, "action": 0.0929112434387207}
{"mode": "train", "epochs": 4, "timestep": 7859, "ep_reward": 1038.846923828125, "reward": 0.872788667678833, "action": -1.1348762512207031}
{"mode": "train", "epochs": 4, "timestep": 7860, "ep_reward": 1039.690185546875, "reward": 0.8432865738868713, "action": -0.5600060820579529}
{"mode": "train", "epochs": 4, "timestep": 7861, "ep_reward": 1040.488037109375, "reward": 0.7978792190551758, "action": -1.2651958465576172}
{"mode": "train", "epochs": 4, "timestep": 7862, "ep_reward": 1041.20654296875, "reward": 0.7184470891952515, "action": -0.589587390422821}
{"mode": "train", "epochs": 4, "timestep": 7863, "ep_reward": 1041.8193359375, "reward": 0.612774133682251, "action": -1.0320441722869873}
{"mode": "train", "epochs": 4, "timestep": 7864, "ep_reward": 1042.2818603515625, "reward": 0.46252185106277466, "action": -1.4591844081878662}
{"mode": "train", "epochs": 4, "timestep": 7865, "ep_reward": 1042.600341796875, "reward": 0.318477988243103, "action": -1.1776260137557983}
{"mode": "train", "epochs": 4, "timestep": 7866, "ep_reward": 1042.802734375, "reward": 0.20236879587173462, "action": -1.18120276927948}
{"mode": "train", "epochs": 4, "timestep": 7867, "ep_reward": 1042.868896484375, "reward": 0.06611871719360352, "action": -1.90256929397583}
{"mode": "train", "epochs": 4, "timestep": 7868, "ep_reward": 1042.9207763671875, "reward": 0.05191826820373535, "action": -1.1108678579330444}
{"mode": "train", "epochs": 4, "timestep": 7869, "ep_reward": 1043.1107177734375, "reward": 0.1899241805076599, "action": -1.4627023935317993}
{"mode": "train", "epochs": 4, "timestep": 7870, "ep_reward": 1043.43505859375, "reward": 0.3243866562843323, "action": -1.1721081733703613}
{"mode": "train", "epochs": 4, "timestep": 7871, "ep_reward": 1043.8929443359375, "reward": 0.457908034324646, "action": -0.7553702592849731}
{"mode": "train", "epochs": 4, "timestep": 7872, "ep_reward": 1044.47412109375, "reward": 0.5812302827835083, "action": -0.4198622703552246}
{"mode": "train", "epochs": 4, "timestep": 7873, "ep_reward": 1045.15966796875, "reward": 0.6855218410491943, "action": -1.768782377243042}
{"mode": "train", "epochs": 4, "timestep": 7874, "ep_reward": 1045.9122314453125, "reward": 0.7525627613067627, "action": -1.179853916168213}
{"mode": "train", "epochs": 4, "timestep": 7875, "ep_reward": 1046.7166748046875, "reward": 0.8044403791427612, "action": -0.33277714252471924}
{"mode": "train", "epochs": 4, "timestep": 7876, "ep_reward": 1047.5601806640625, "reward": 0.843519926071167, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7877, "ep_reward": 1048.4100341796875, "reward": 0.8498467803001404, "action": -1.1396055221557617}
{"mode": "train", "epochs": 4, "timestep": 7878, "ep_reward": 1049.255615234375, "reward": 0.8456020951271057, "action": -0.6424084305763245}
{"mode": "train", "epochs": 4, "timestep": 7879, "ep_reward": 1050.0816650390625, "reward": 0.8260973691940308, "action": -0.5630096197128296}
{"mode": "train", "epochs": 4, "timestep": 7880, "ep_reward": 1050.8663330078125, "reward": 0.7846682667732239, "action": -0.4758440852165222}
{"mode": "train", "epochs": 4, "timestep": 7881, "ep_reward": 1051.5830078125, "reward": 0.7167260646820068, "action": -0.9550064206123352}
{"mode": "train", "epochs": 4, "timestep": 7882, "ep_reward": 1052.1920166015625, "reward": 0.6090678572654724, "action": 0.20212340354919434}
{"mode": "train", "epochs": 4, "timestep": 7883, "ep_reward": 1052.6705322265625, "reward": 0.47852951288223267, "action": -1.8817415237426758}
{"mode": "train", "epochs": 4, "timestep": 7884, "ep_reward": 1053.0045166015625, "reward": 0.33401578664779663, "action": -1.2151800394058228}
{"mode": "train", "epochs": 4, "timestep": 7885, "ep_reward": 1053.2254638671875, "reward": 0.22095388174057007, "action": -0.5252598524093628}
{"mode": "train", "epochs": 4, "timestep": 7886, "ep_reward": 1053.3133544921875, "reward": 0.08783090114593506, "action": 0.11538517475128174}
{"mode": "train", "epochs": 4, "timestep": 7887, "ep_reward": 1053.3431396484375, "reward": 0.02976304292678833, "action": -0.4778432250022888}
{"mode": "train", "epochs": 4, "timestep": 7888, "ep_reward": 1053.515380859375, "reward": 0.17229074239730835, "action": -1.2051069736480713}
{"mode": "train", "epochs": 4, "timestep": 7889, "ep_reward": 1053.8248291015625, "reward": 0.30944138765335083, "action": -0.26864147186279297}
{"mode": "train", "epochs": 4, "timestep": 7890, "ep_reward": 1054.2786865234375, "reward": 0.45389121770858765, "action": -1.512561559677124}
{"mode": "train", "epochs": 4, "timestep": 7891, "ep_reward": 1054.84716796875, "reward": 0.5685060024261475, "action": -1.2390265464782715}
{"mode": "train", "epochs": 4, "timestep": 7892, "ep_reward": 1055.5145263671875, "reward": 0.6674164533615112, "action": -0.22186881303787231}
{"mode": "train", "epochs": 4, "timestep": 7893, "ep_reward": 1056.2684326171875, "reward": 0.7539189457893372, "action": -0.6668278574943542}
{"mode": "train", "epochs": 4, "timestep": 7894, "ep_reward": 1057.0814208984375, "reward": 0.8130452632904053, "action": -1.1715009212493896}
{"mode": "train", "epochs": 4, "timestep": 7895, "ep_reward": 1057.9300537109375, "reward": 0.848605751991272, "action": -1.4001693725585938}
{"mode": "train", "epochs": 4, "timestep": 7896, "ep_reward": 1058.7958984375, "reward": 0.8658610582351685, "action": -0.9941135048866272}
{"mode": "train", "epochs": 4, "timestep": 7897, "ep_reward": 1059.6666259765625, "reward": 0.8707537651062012, "action": -0.6095736026763916}
{"mode": "train", "epochs": 4, "timestep": 7898, "ep_reward": 1060.5291748046875, "reward": 0.8625607490539551, "action": -1.3624767065048218}
{"mode": "train", "epochs": 4, "timestep": 7899, "ep_reward": 1061.3585205078125, "reward": 0.8293101787567139, "action": -0.8452796936035156}
{"mode": "train", "epochs": 4, "timestep": 7900, "ep_reward": 1062.1361083984375, "reward": 0.777580738067627, "action": -1.056588053703308}
{"mode": "train", "epochs": 4, "timestep": 7901, "ep_reward": 1062.83056640625, "reward": 0.694416880607605, "action": -0.33924734592437744}
{"mode": "train", "epochs": 4, "timestep": 7902, "ep_reward": 1063.415283203125, "reward": 0.5846999883651733, "action": -1.1531776189804077}
{"mode": "train", "epochs": 4, "timestep": 7903, "ep_reward": 1063.839599609375, "reward": 0.4243089556694031, "action": -0.6078313589096069}
{"mode": "train", "epochs": 4, "timestep": 7904, "ep_reward": 1064.1407470703125, "reward": 0.30114322900772095, "action": -1.4924448728561401}
{"mode": "train", "epochs": 4, "timestep": 7905, "ep_reward": 1064.3226318359375, "reward": 0.1818733811378479, "action": -1.207290768623352}
{"mode": "train", "epochs": 4, "timestep": 7906, "ep_reward": 1064.365234375, "reward": 0.04263085126876831, "action": -0.4593811631202698}
{"mode": "train", "epochs": 4, "timestep": 7907, "ep_reward": 1064.440673828125, "reward": 0.07549339532852173, "action": -0.1358860731124878}
{"mode": "train", "epochs": 4, "timestep": 7908, "ep_reward": 1064.6644287109375, "reward": 0.22376924753189087, "action": -0.40365511178970337}
{"mode": "train", "epochs": 4, "timestep": 7909, "ep_reward": 1065.032958984375, "reward": 0.36848747730255127, "action": -1.45931077003479}
{"mode": "train", "epochs": 4, "timestep": 7910, "ep_reward": 1065.5252685546875, "reward": 0.4923078417778015, "action": -0.7219526767730713}
{"mode": "train", "epochs": 4, "timestep": 7911, "ep_reward": 1066.1348876953125, "reward": 0.6096369028091431, "action": -1.7709410190582275}
{"mode": "train", "epochs": 4, "timestep": 7912, "ep_reward": 1066.8302001953125, "reward": 0.6953021287918091, "action": -1.6703355312347412}
{"mode": "train", "epochs": 4, "timestep": 7913, "ep_reward": 1067.592041015625, "reward": 0.7618514895439148, "action": -1.4610947370529175}
{"mode": "train", "epochs": 4, "timestep": 7914, "ep_reward": 1068.40234375, "reward": 0.8102806210517883, "action": -1.735666275024414}
{"mode": "train", "epochs": 4, "timestep": 7915, "ep_reward": 1069.239990234375, "reward": 0.8376086354255676, "action": -1.1641401052474976}
{"mode": "train", "epochs": 4, "timestep": 7916, "ep_reward": 1070.092041015625, "reward": 0.8520557880401611, "action": -1.4751477241516113}
{"mode": "train", "epochs": 4, "timestep": 7917, "ep_reward": 1070.937744140625, "reward": 0.8456709980964661, "action": -0.9271573424339294}
{"mode": "train", "epochs": 4, "timestep": 7918, "ep_reward": 1071.761962890625, "reward": 0.8242421746253967, "action": -1.0721534490585327}
{"mode": "train", "epochs": 4, "timestep": 7919, "ep_reward": 1072.5396728515625, "reward": 0.7776930928230286, "action": -1.3857553005218506}
{"mode": "train", "epochs": 4, "timestep": 7920, "ep_reward": 1073.2373046875, "reward": 0.6976032257080078, "action": -0.6904233694076538}
{"mode": "train", "epochs": 4, "timestep": 7921, "ep_reward": 1073.826171875, "reward": 0.5888161063194275, "action": -1.3430551290512085}
{"mode": "train", "epochs": 4, "timestep": 7922, "ep_reward": 1074.2547607421875, "reward": 0.42854464054107666, "action": 0.008414864540100098}
{"mode": "train", "epochs": 4, "timestep": 7923, "ep_reward": 1074.57861328125, "reward": 0.3238677978515625, "action": -0.8793265223503113}
{"mode": "train", "epochs": 4, "timestep": 7924, "ep_reward": 1074.787353515625, "reward": 0.2087949514389038, "action": -0.6474725604057312}
{"mode": "train", "epochs": 4, "timestep": 7925, "ep_reward": 1074.861083984375, "reward": 0.0737236738204956, "action": -0.019640982151031494}
{"mode": "train", "epochs": 4, "timestep": 7926, "ep_reward": 1074.9053955078125, "reward": 0.044328272342681885, "action": -1.4864810705184937}
{"mode": "train", "epochs": 4, "timestep": 7927, "ep_reward": 1075.0887451171875, "reward": 0.18329638242721558, "action": -1.9846208095550537}
{"mode": "train", "epochs": 4, "timestep": 7928, "ep_reward": 1075.4000244140625, "reward": 0.31122756004333496, "action": -0.6867275834083557}
{"mode": "train", "epochs": 4, "timestep": 7929, "ep_reward": 1075.8524169921875, "reward": 0.4523545503616333, "action": -0.6160385608673096}
{"mode": "train", "epochs": 4, "timestep": 7930, "ep_reward": 1076.4305419921875, "reward": 0.5780799388885498, "action": -0.49030864238739014}
{"mode": "train", "epochs": 4, "timestep": 7931, "ep_reward": 1077.113037109375, "reward": 0.6824939250946045, "action": -0.9736599922180176}
{"mode": "train", "epochs": 4, "timestep": 7932, "ep_reward": 1077.87109375, "reward": 0.7580556869506836, "action": -0.28520911931991577}
{"mode": "train", "epochs": 4, "timestep": 7933, "ep_reward": 1078.6890869140625, "reward": 0.8179337978363037, "action": -0.802932858467102}
{"mode": "train", "epochs": 4, "timestep": 7934, "ep_reward": 1079.5426025390625, "reward": 0.8535045385360718, "action": -0.7015288472175598}
{"mode": "train", "epochs": 4, "timestep": 7935, "ep_reward": 1080.4158935546875, "reward": 0.8732421398162842, "action": -0.7929174900054932}
{"mode": "train", "epochs": 4, "timestep": 7936, "ep_reward": 1081.2928466796875, "reward": 0.876893937587738, "action": -0.5812126398086548}
{"mode": "train", "epochs": 4, "timestep": 7937, "ep_reward": 1082.1595458984375, "reward": 0.8666994571685791, "action": -0.6719878911972046}
{"mode": "train", "epochs": 4, "timestep": 7938, "ep_reward": 1082.9976806640625, "reward": 0.8381769061088562, "action": -1.0167677402496338}
{"mode": "train", "epochs": 4, "timestep": 7939, "ep_reward": 1083.7822265625, "reward": 0.7845363616943359, "action": -0.832823634147644}
{"mode": "train", "epochs": 4, "timestep": 7940, "ep_reward": 1084.48681640625, "reward": 0.7045334577560425, "action": -0.8923933506011963}
{"mode": "train", "epochs": 4, "timestep": 7941, "ep_reward": 1085.0758056640625, "reward": 0.589037299156189, "action": -1.224146842956543}
{"mode": "train", "epochs": 4, "timestep": 7942, "ep_reward": 1085.50439453125, "reward": 0.42854148149490356, "action": -0.8539210557937622}
{"mode": "train", "epochs": 4, "timestep": 7943, "ep_reward": 1085.8045654296875, "reward": 0.3001859784126282, "action": -1.04673433303833}
{"mode": "train", "epochs": 4, "timestep": 7944, "ep_reward": 1085.9852294921875, "reward": 0.18067830801010132, "action": -1.0605648756027222}
{"mode": "train", "epochs": 4, "timestep": 7945, "ep_reward": 1086.0262451171875, "reward": 0.041045546531677246, "action": -1.7647523880004883}
{"mode": "train", "epochs": 4, "timestep": 7946, "ep_reward": 1086.1029052734375, "reward": 0.07666671276092529, "action": -1.7336817979812622}
{"mode": "train", "epochs": 4, "timestep": 7947, "ep_reward": 1086.314453125, "reward": 0.21151721477508545, "action": -0.20592325925827026}
{"mode": "train", "epochs": 4, "timestep": 7948, "ep_reward": 1086.6761474609375, "reward": 0.3616967797279358, "action": -0.6814789175987244}
{"mode": "train", "epochs": 4, "timestep": 7949, "ep_reward": 1087.17236328125, "reward": 0.4962650537490845, "action": -0.7236294150352478}
{"mode": "train", "epochs": 4, "timestep": 7950, "ep_reward": 1087.7855224609375, "reward": 0.6131985187530518, "action": -0.846777081489563}
{"mode": "train", "epochs": 4, "timestep": 7951, "ep_reward": 1088.49267578125, "reward": 0.7071588039398193, "action": -1.1942780017852783}
{"mode": "train", "epochs": 4, "timestep": 7952, "ep_reward": 1089.2686767578125, "reward": 0.7759594917297363, "action": -0.8657039403915405}
{"mode": "train", "epochs": 4, "timestep": 7953, "ep_reward": 1090.096435546875, "reward": 0.8277363181114197, "action": -0.7293930053710938}
{"mode": "train", "epochs": 4, "timestep": 7954, "ep_reward": 1090.9591064453125, "reward": 0.8626300096511841, "action": -1.0601556301116943}
{"mode": "train", "epochs": 4, "timestep": 7955, "ep_reward": 1091.8385009765625, "reward": 0.8793475031852722, "action": 0.19578337669372559}
{"mode": "train", "epochs": 4, "timestep": 7956, "ep_reward": 1092.7298583984375, "reward": 0.8913432359695435, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7957, "ep_reward": 1093.6016845703125, "reward": 0.8717877268791199, "action": -1.8276435136795044}
{"mode": "train", "epochs": 4, "timestep": 7958, "ep_reward": 1094.4368896484375, "reward": 0.8352022171020508, "action": -0.8532655835151672}
{"mode": "train", "epochs": 4, "timestep": 7959, "ep_reward": 1095.221435546875, "reward": 0.7845683693885803, "action": -0.5789119601249695}
{"mode": "train", "epochs": 4, "timestep": 7960, "ep_reward": 1095.9305419921875, "reward": 0.7090681791305542, "action": -1.1178547143936157}
{"mode": "train", "epochs": 4, "timestep": 7961, "ep_reward": 1096.5233154296875, "reward": 0.5927172899246216, "action": -0.8217284083366394}
{"mode": "train", "epochs": 4, "timestep": 7962, "ep_reward": 1096.9632568359375, "reward": 0.43988752365112305, "action": -1.5481081008911133}
{"mode": "train", "epochs": 4, "timestep": 7963, "ep_reward": 1097.270751953125, "reward": 0.307495653629303, "action": -1.327230453491211}
{"mode": "train", "epochs": 4, "timestep": 7964, "ep_reward": 1097.4599609375, "reward": 0.18920087814331055, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7965, "ep_reward": 1097.5111083984375, "reward": 0.05111771821975708, "action": -1.677676796913147}
{"mode": "train", "epochs": 4, "timestep": 7966, "ep_reward": 1097.578125, "reward": 0.06703382730484009, "action": 0.228937029838562}
{"mode": "train", "epochs": 4, "timestep": 7967, "ep_reward": 1097.797607421875, "reward": 0.21948027610778809, "action": -1.2150965929031372}
{"mode": "train", "epochs": 4, "timestep": 7968, "ep_reward": 1098.1514892578125, "reward": 0.3539143204689026, "action": -0.21183526515960693}
{"mode": "train", "epochs": 4, "timestep": 7969, "ep_reward": 1098.645263671875, "reward": 0.49376171827316284, "action": -1.5337934494018555}
{"mode": "train", "epochs": 4, "timestep": 7970, "ep_reward": 1099.2471923828125, "reward": 0.601965069770813, "action": -1.5834746360778809}
{"mode": "train", "epochs": 4, "timestep": 7971, "ep_reward": 1099.9383544921875, "reward": 0.6911176443099976, "action": -1.039773941040039}
{"mode": "train", "epochs": 4, "timestep": 7972, "ep_reward": 1100.703125, "reward": 0.7647751569747925, "action": -1.3889200687408447}
{"mode": "train", "epochs": 4, "timestep": 7973, "ep_reward": 1101.517822265625, "reward": 0.8147278428077698, "action": -0.9409183263778687}
{"mode": "train", "epochs": 4, "timestep": 7974, "ep_reward": 1102.3680419921875, "reward": 0.8502619862556458, "action": -0.38827866315841675}
{"mode": "train", "epochs": 4, "timestep": 7975, "ep_reward": 1103.241455078125, "reward": 0.8733876943588257, "action": -1.4187252521514893}
{"mode": "train", "epochs": 4, "timestep": 7976, "ep_reward": 1104.1141357421875, "reward": 0.8726627826690674, "action": -0.9547272324562073}
{"mode": "train", "epochs": 4, "timestep": 7977, "ep_reward": 1104.9735107421875, "reward": 0.859326958656311, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7978, "ep_reward": 1105.79052734375, "reward": 0.817034900188446, "action": -1.4801710844039917}
{"mode": "train", "epochs": 4, "timestep": 7979, "ep_reward": 1106.5438232421875, "reward": 0.7533501386642456, "action": -0.5988894701004028}
{"mode": "train", "epochs": 4, "timestep": 7980, "ep_reward": 1107.2110595703125, "reward": 0.6672863960266113, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7981, "ep_reward": 1107.7349853515625, "reward": 0.523876428604126, "action": -1.5734590291976929}
{"mode": "train", "epochs": 4, "timestep": 7982, "ep_reward": 1108.1124267578125, "reward": 0.37750160694122314, "action": -0.9913304448127747}
{"mode": "train", "epochs": 4, "timestep": 7983, "ep_reward": 1108.3856201171875, "reward": 0.27322953939437866, "action": -0.012226760387420654}
{"mode": "train", "epochs": 4, "timestep": 7984, "ep_reward": 1108.5343017578125, "reward": 0.14864367246627808, "action": -2.0}
{"mode": "train", "epochs": 4, "timestep": 7985, "ep_reward": 1108.538818359375, "reward": 0.004522740840911865, "action": -0.7222325801849365}
{"mode": "train", "epochs": 4, "timestep": 7986, "ep_reward": 1108.6500244140625, "reward": 0.11115610599517822, "action": -0.8730563521385193}
{"mode": "train", "epochs": 4, "timestep": 7987, "ep_reward": 1108.9013671875, "reward": 0.25133323669433594, "action": -0.7548912167549133}
{"mode": "train", "epochs": 4, "timestep": 7988, "ep_reward": 1109.2939453125, "reward": 0.39258378744125366, "action": -1.013460636138916}
{"mode": "train", "epochs": 4, "timestep": 7989, "ep_reward": 1109.8143310546875, "reward": 0.5203531384468079, "action": -0.8171135783195496}
{"mode": "train", "epochs": 4, "timestep": 7990, "ep_reward": 1110.44677734375, "reward": 0.6324340105056763, "action": -1.1254067420959473}
{"mode": "train", "epochs": 4, "timestep": 7991, "ep_reward": 1111.166015625, "reward": 0.7191902995109558, "action": -1.386101484298706}
{"mode": "train", "epochs": 4, "timestep": 7992, "ep_reward": 1111.947998046875, "reward": 0.7819401025772095, "action": -0.5991470813751221}
{"mode": "train", "epochs": 4, "timestep": 7993, "ep_reward": 1112.779541015625, "reward": 0.8315929770469666, "action": -1.2732081413269043}
{"mode": "train", "epochs": 4, "timestep": 7994, "ep_reward": 1113.63671875, "reward": 0.8572317957878113, "action": -0.8008346557617188}
{"mode": "train", "epochs": 4, "timestep": 7995, "ep_reward": 1114.507080078125, "reward": 0.8704161643981934, "action": -1.5909545421600342}
{"mode": "train", "epochs": 4, "timestep": 7996, "ep_reward": 1115.367919921875, "reward": 0.8608988523483276, "action": -0.6392784118652344}
{"mode": "train", "epochs": 4, "timestep": 7997, "ep_reward": 1116.20947265625, "reward": 0.8415385484695435, "action": -0.891342043876648}
{"mode": "train", "epochs": 4, "timestep": 7998, "ep_reward": 1117.0081787109375, "reward": 0.7986553907394409, "action": -1.126340389251709}
{"mode": "train", "epochs": 4, "timestep": 7999, "ep_reward": 1117.7344970703125, "reward": 0.7262895107269287, "action": -0.6214392185211182}
{"mode": "train", "epochs": 4, "timestep": 8000, "ep_reward": 1118.360595703125, "reward": 0.6261396408081055, "action": -0.5194594860076904}
{"mode": "train", "epochs": 5, "timestep": 8001, "ep_reward": 0.9886523485183716, "reward": 0.9886523485183716, "action": -0.5287061929702759}
{"mode": "train", "epochs": 5, "timestep": 8002, "ep_reward": 1.978938341140747, "reward": 0.9902859330177307, "action": -0.7976968288421631}
{"mode": "train", "epochs": 5, "timestep": 8003, "ep_reward": 2.96985125541687, "reward": 0.9909129738807678, "action": -0.9682167768478394}
{"mode": "train", "epochs": 5, "timestep": 8004, "ep_reward": 3.9608428478240967, "reward": 0.9909915328025818, "action": 0.05342844873666763}
{"mode": "train", "epochs": 5, "timestep": 8005, "ep_reward": 4.950407981872559, "reward": 0.9895651936531067, "action": 1.2087689638137817}
{"mode": "train", "epochs": 5, "timestep": 8006, "ep_reward": 5.934823513031006, "reward": 0.9844153523445129, "action": 0.7715572118759155}
{"mode": "train", "epochs": 5, "timestep": 8007, "ep_reward": 6.910316467285156, "reward": 0.9754930138587952, "action": 1.2697556018829346}
{"mode": "train", "epochs": 5, "timestep": 8008, "ep_reward": 7.869790554046631, "reward": 0.9594740271568298, "action": 1.2349388599395752}
{"mode": "train", "epochs": 5, "timestep": 8009, "ep_reward": 8.80453872680664, "reward": 0.9347484111785889, "action": 0.9322264790534973}
{"mode": "train", "epochs": 5, "timestep": 8010, "ep_reward": 9.70419979095459, "reward": 0.8996608853340149, "action": 0.23881173133850098}
{"mode": "train", "epochs": 5, "timestep": 8011, "ep_reward": 10.55836009979248, "reward": 0.8541605472564697, "action": 0.9127610921859741}
{"mode": "train", "epochs": 5, "timestep": 8012, "ep_reward": 11.343050003051758, "reward": 0.7846900820732117, "action": 0.6979213356971741}
{"mode": "train", "epochs": 5, "timestep": 8013, "ep_reward": 12.034737586975098, "reward": 0.6916874647140503, "action": 1.4955997467041016}
{"mode": "train", "epochs": 5, "timestep": 8014, "ep_reward": 12.594212532043457, "reward": 0.5594749450683594, "action": 0.5559214949607849}
{"mode": "train", "epochs": 5, "timestep": 8015, "ep_reward": 13.001005172729492, "reward": 0.40679246187210083, "action": 0.7415190935134888}
{"mode": "train", "epochs": 5, "timestep": 8016, "ep_reward": 13.227566719055176, "reward": 0.22656112909317017, "action": 0.5781662464141846}
{"mode": "train", "epochs": 5, "timestep": 8017, "ep_reward": 13.28646183013916, "reward": 0.0588950514793396, "action": 0.4675687551498413}
{"mode": "train", "epochs": 5, "timestep": 8018, "ep_reward": 13.345844268798828, "reward": 0.059382855892181396, "action": 1.1810581684112549}
{"mode": "train", "epochs": 5, "timestep": 8019, "ep_reward": 13.542280197143555, "reward": 0.1964360475540161, "action": 1.100672960281372}
{"mode": "train", "epochs": 5, "timestep": 8020, "ep_reward": 13.877726554870605, "reward": 0.33544617891311646, "action": 1.2624971866607666}
{"mode": "train", "epochs": 5, "timestep": 8021, "ep_reward": 14.344111442565918, "reward": 0.4663850665092468, "action": 1.8698487281799316}
{"mode": "train", "epochs": 5, "timestep": 8022, "ep_reward": 14.919933319091797, "reward": 0.5758218765258789, "action": 0.6023841500282288}
{"mode": "train", "epochs": 5, "timestep": 8023, "ep_reward": 15.599056243896484, "reward": 0.679122805595398, "action": 1.041102647781372}
{"mode": "train", "epochs": 5, "timestep": 8024, "ep_reward": 16.352346420288086, "reward": 0.7532898783683777, "action": 0.8782771229743958}
{"mode": "train", "epochs": 5, "timestep": 8025, "ep_reward": 17.158594131469727, "reward": 0.8062474727630615, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8026, "ep_reward": 17.987459182739258, "reward": 0.8288655877113342, "action": 0.7400051951408386}
{"mode": "train", "epochs": 5, "timestep": 8027, "ep_reward": 18.831262588500977, "reward": 0.8438025712966919, "action": 1.5113871097564697}
{"mode": "train", "epochs": 5, "timestep": 8028, "ep_reward": 19.663320541381836, "reward": 0.8320587277412415, "action": 1.2313642501831055}
{"mode": "train", "epochs": 5, "timestep": 8029, "ep_reward": 20.463964462280273, "reward": 0.8006436228752136, "action": 1.130522608757019}
{"mode": "train", "epochs": 5, "timestep": 8030, "ep_reward": 21.207107543945312, "reward": 0.7431429624557495, "action": 1.5232412815093994}
{"mode": "train", "epochs": 5, "timestep": 8031, "ep_reward": 21.85384750366211, "reward": 0.6467406749725342, "action": 1.1544512510299683}
{"mode": "train", "epochs": 5, "timestep": 8032, "ep_reward": 22.366756439208984, "reward": 0.512908935546875, "action": 0.6302589178085327}
{"mode": "train", "epochs": 5, "timestep": 8033, "ep_reward": 22.751340866088867, "reward": 0.3845837712287903, "action": 1.2786556482315063}
{"mode": "train", "epochs": 5, "timestep": 8034, "ep_reward": 23.03297233581543, "reward": 0.2816321849822998, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8035, "ep_reward": 23.191957473754883, "reward": 0.15898513793945312, "action": 1.2214490175247192}
{"mode": "train", "epochs": 5, "timestep": 8036, "ep_reward": 23.20813751220703, "reward": 0.016180098056793213, "action": 1.2300708293914795}
{"mode": "train", "epochs": 5, "timestep": 8037, "ep_reward": 23.308565139770508, "reward": 0.10042697191238403, "action": 0.7894423604011536}
{"mode": "train", "epochs": 5, "timestep": 8038, "ep_reward": 23.5499267578125, "reward": 0.24136245250701904, "action": 0.4229862093925476}
{"mode": "train", "epochs": 5, "timestep": 8039, "ep_reward": 23.93671417236328, "reward": 0.3867875933647156, "action": 1.1666651964187622}
{"mode": "train", "epochs": 5, "timestep": 8040, "ep_reward": 24.449670791625977, "reward": 0.5129566192626953, "action": 0.9133020043373108}
{"mode": "train", "epochs": 5, "timestep": 8041, "ep_reward": 25.07485008239746, "reward": 0.6251790523529053, "action": 1.308139443397522}
{"mode": "train", "epochs": 5, "timestep": 8042, "ep_reward": 25.78680419921875, "reward": 0.7119544744491577, "action": 0.8576125502586365}
{"mode": "train", "epochs": 5, "timestep": 8043, "ep_reward": 26.568344116210938, "reward": 0.7815398573875427, "action": -0.004643917083740234}
{"mode": "train", "epochs": 5, "timestep": 8044, "ep_reward": 27.405982971191406, "reward": 0.8376396894454956, "action": 0.8608970046043396}
{"mode": "train", "epochs": 5, "timestep": 8045, "ep_reward": 28.27406883239746, "reward": 0.8680854439735413, "action": 0.8019852638244629}
{"mode": "train", "epochs": 5, "timestep": 8046, "ep_reward": 29.1579647064209, "reward": 0.8838953971862793, "action": 0.8070370554924011}
{"mode": "train", "epochs": 5, "timestep": 8047, "ep_reward": 30.04344940185547, "reward": 0.8854844570159912, "action": 1.2818832397460938}
{"mode": "train", "epochs": 5, "timestep": 8048, "ep_reward": 30.91184425354004, "reward": 0.8683943152427673, "action": 1.077474594116211}
{"mode": "train", "epochs": 5, "timestep": 8049, "ep_reward": 31.746870040893555, "reward": 0.8350256681442261, "action": 0.5438659191131592}
{"mode": "train", "epochs": 5, "timestep": 8050, "ep_reward": 32.5313835144043, "reward": 0.7845116853713989, "action": 0.8305885195732117}
{"mode": "train", "epochs": 5, "timestep": 8051, "ep_reward": 33.23486328125, "reward": 0.7034815549850464, "action": 0.6044788360595703}
{"mode": "train", "epochs": 5, "timestep": 8052, "ep_reward": 33.82587814331055, "reward": 0.5910135507583618, "action": 1.0901415348052979}
{"mode": "train", "epochs": 5, "timestep": 8053, "ep_reward": 34.258853912353516, "reward": 0.4329755902290344, "action": 0.9171472787857056}
{"mode": "train", "epochs": 5, "timestep": 8054, "ep_reward": 34.55604934692383, "reward": 0.29719531536102295, "action": 1.021371841430664}
{"mode": "train", "epochs": 5, "timestep": 8055, "ep_reward": 34.733158111572266, "reward": 0.17710959911346436, "action": 1.3114356994628906}
{"mode": "train", "epochs": 5, "timestep": 8056, "ep_reward": 34.77021789550781, "reward": 0.0370597243309021, "action": 1.3506062030792236}
{"mode": "train", "epochs": 5, "timestep": 8057, "ep_reward": 34.850955963134766, "reward": 0.08073657751083374, "action": 0.6858547329902649}
{"mode": "train", "epochs": 5, "timestep": 8058, "ep_reward": 35.07329177856445, "reward": 0.2223362922668457, "action": 0.8741647005081177}
{"mode": "train", "epochs": 5, "timestep": 8059, "ep_reward": 35.43601608276367, "reward": 0.36272525787353516, "action": 1.2287708520889282}
{"mode": "train", "epochs": 5, "timestep": 8060, "ep_reward": 35.92695236206055, "reward": 0.49093544483184814, "action": 1.3335332870483398}
{"mode": "train", "epochs": 5, "timestep": 8061, "ep_reward": 36.52938461303711, "reward": 0.6024309396743774, "action": 0.5914852023124695}
{"mode": "train", "epochs": 5, "timestep": 8062, "ep_reward": 37.229923248291016, "reward": 0.700537383556366, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8063, "ep_reward": 37.99201583862305, "reward": 0.7620916366577148, "action": 0.466630220413208}
{"mode": "train", "epochs": 5, "timestep": 8064, "ep_reward": 38.80949783325195, "reward": 0.8174825310707092, "action": 1.3532344102859497}
{"mode": "train", "epochs": 5, "timestep": 8065, "ep_reward": 39.65461730957031, "reward": 0.8451201915740967, "action": 1.974870204925537}
{"mode": "train", "epochs": 5, "timestep": 8066, "ep_reward": 40.504661560058594, "reward": 0.8500432968139648, "action": 0.6926759481430054}
{"mode": "train", "epochs": 5, "timestep": 8067, "ep_reward": 41.352657318115234, "reward": 0.8479958772659302, "action": 1.6526522636413574}
{"mode": "train", "epochs": 5, "timestep": 8068, "ep_reward": 42.16963577270508, "reward": 0.8169786930084229, "action": 0.3810167908668518}
{"mode": "train", "epochs": 5, "timestep": 8069, "ep_reward": 42.94381332397461, "reward": 0.7741776704788208, "action": 0.9053142070770264}
{"mode": "train", "epochs": 5, "timestep": 8070, "ep_reward": 43.640380859375, "reward": 0.6965681910514832, "action": 1.5560479164123535}
{"mode": "train", "epochs": 5, "timestep": 8071, "ep_reward": 44.21366500854492, "reward": 0.5732823610305786, "action": 1.1203163862228394}
{"mode": "train", "epochs": 5, "timestep": 8072, "ep_reward": 44.62522506713867, "reward": 0.4115590453147888, "action": 0.9383900165557861}
{"mode": "train", "epochs": 5, "timestep": 8073, "ep_reward": 44.93747329711914, "reward": 0.3122496008872986, "action": 0.8662756085395813}
{"mode": "train", "epochs": 5, "timestep": 8074, "ep_reward": 45.13247299194336, "reward": 0.19500070810317993, "action": 0.5647866725921631}
{"mode": "train", "epochs": 5, "timestep": 8075, "ep_reward": 45.190162658691406, "reward": 0.05768853425979614, "action": 0.9484468102455139}
{"mode": "train", "epochs": 5, "timestep": 8076, "ep_reward": 45.2507438659668, "reward": 0.0605815052986145, "action": 0.8995792865753174}
{"mode": "train", "epochs": 5, "timestep": 8077, "ep_reward": 45.449432373046875, "reward": 0.1986899971961975, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8078, "ep_reward": 45.7757568359375, "reward": 0.326323926448822, "action": 0.8938955664634705}
{"mode": "train", "epochs": 5, "timestep": 8079, "ep_reward": 46.23942565917969, "reward": 0.46367067098617554, "action": 1.1753473281860352}
{"mode": "train", "epochs": 5, "timestep": 8080, "ep_reward": 46.82086181640625, "reward": 0.5814348459243774, "action": 1.0224483013153076}
{"mode": "train", "epochs": 5, "timestep": 8081, "ep_reward": 47.50009536743164, "reward": 0.6792337894439697, "action": 1.0018181800842285}
{"mode": "train", "epochs": 5, "timestep": 8082, "ep_reward": 48.25355529785156, "reward": 0.7534596920013428, "action": 0.6575353145599365}
{"mode": "train", "epochs": 5, "timestep": 8083, "ep_reward": 49.06167984008789, "reward": 0.8081227540969849, "action": 0.8910650014877319}
{"mode": "train", "epochs": 5, "timestep": 8084, "ep_reward": 49.90163040161133, "reward": 0.8399494886398315, "action": 0.7415213584899902}
{"mode": "train", "epochs": 5, "timestep": 8085, "ep_reward": 50.75596618652344, "reward": 0.8543341755867004, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8086, "ep_reward": 51.59528350830078, "reward": 0.839317262172699, "action": 0.12927985191345215}
{"mode": "train", "epochs": 5, "timestep": 8087, "ep_reward": 52.41637420654297, "reward": 0.8210889101028442, "action": -0.0043468475341796875}
{"mode": "train", "epochs": 5, "timestep": 8088, "ep_reward": 53.198028564453125, "reward": 0.7816555500030518, "action": 1.0031092166900635}
{"mode": "train", "epochs": 5, "timestep": 8089, "ep_reward": 53.90159225463867, "reward": 0.7035641074180603, "action": 1.3998653888702393}
{"mode": "train", "epochs": 5, "timestep": 8090, "ep_reward": 54.48552703857422, "reward": 0.5839332342147827, "action": 0.6462152600288391}
{"mode": "train", "epochs": 5, "timestep": 8091, "ep_reward": 54.91802978515625, "reward": 0.4325021505355835, "action": 1.2517895698547363}
{"mode": "train", "epochs": 5, "timestep": 8092, "ep_reward": 55.232669830322266, "reward": 0.3146408200263977, "action": 1.3099162578582764}
{"mode": "train", "epochs": 5, "timestep": 8093, "ep_reward": 55.43052673339844, "reward": 0.19785702228546143, "action": 1.0818978548049927}
{"mode": "train", "epochs": 5, "timestep": 8094, "ep_reward": 55.49147415161133, "reward": 0.06094890832901001, "action": 1.6173949241638184}
{"mode": "train", "epochs": 5, "timestep": 8095, "ep_reward": 55.54856491088867, "reward": 0.057091593742370605, "action": 1.656813144683838}
{"mode": "train", "epochs": 5, "timestep": 8096, "ep_reward": 55.742919921875, "reward": 0.1943543553352356, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8097, "ep_reward": 56.065120697021484, "reward": 0.3222004771232605, "action": 1.0066543817520142}
{"mode": "train", "epochs": 5, "timestep": 8098, "ep_reward": 56.52385711669922, "reward": 0.45873773097991943, "action": 0.37885040044784546}
{"mode": "train", "epochs": 5, "timestep": 8099, "ep_reward": 57.11016082763672, "reward": 0.586305558681488, "action": 1.0608148574829102}
{"mode": "train", "epochs": 5, "timestep": 8100, "ep_reward": 57.79317092895508, "reward": 0.6830108165740967, "action": 0.9533131718635559}
{"mode": "train", "epochs": 5, "timestep": 8101, "ep_reward": 58.55067825317383, "reward": 0.7575058937072754, "action": 1.0569905042648315}
{"mode": "train", "epochs": 5, "timestep": 8102, "ep_reward": 59.35929870605469, "reward": 0.8086223006248474, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8103, "ep_reward": 60.19096374511719, "reward": 0.8316633105278015, "action": 1.0591589212417603}
{"mode": "train", "epochs": 5, "timestep": 8104, "ep_reward": 61.03529739379883, "reward": 0.8443340063095093, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8105, "ep_reward": 61.86428451538086, "reward": 0.8289887309074402, "action": 0.5399825572967529}
{"mode": "train", "epochs": 5, "timestep": 8106, "ep_reward": 62.66970443725586, "reward": 0.8054201602935791, "action": 0.39222007989883423}
{"mode": "train", "epochs": 5, "timestep": 8107, "ep_reward": 63.428009033203125, "reward": 0.7583054304122925, "action": 0.8031059503555298}
{"mode": "train", "epochs": 5, "timestep": 8108, "ep_reward": 64.10388946533203, "reward": 0.6758838295936584, "action": 1.71687912940979}
{"mode": "train", "epochs": 5, "timestep": 8109, "ep_reward": 64.64619445800781, "reward": 0.5423040390014648, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8110, "ep_reward": 65.04156494140625, "reward": 0.3953700661659241, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8111, "ep_reward": 65.33663177490234, "reward": 0.2950642704963684, "action": 1.4889025688171387}
{"mode": "train", "epochs": 5, "timestep": 8112, "ep_reward": 65.51126861572266, "reward": 0.17463505268096924, "action": 1.5512052774429321}
{"mode": "train", "epochs": 5, "timestep": 8113, "ep_reward": 65.5455322265625, "reward": 0.03425997495651245, "action": 1.3142470121383667}
{"mode": "train", "epochs": 5, "timestep": 8114, "ep_reward": 65.62896728515625, "reward": 0.08343124389648438, "action": 0.6127049922943115}
{"mode": "train", "epochs": 5, "timestep": 8115, "ep_reward": 65.85498809814453, "reward": 0.22602307796478271, "action": 0.8487860560417175}
{"mode": "train", "epochs": 5, "timestep": 8116, "ep_reward": 66.22147369384766, "reward": 0.3664872646331787, "action": 0.8970693349838257}
{"mode": "train", "epochs": 5, "timestep": 8117, "ep_reward": 66.71959686279297, "reward": 0.4981241226196289, "action": 0.46086812019348145}
{"mode": "train", "epochs": 5, "timestep": 8118, "ep_reward": 67.33702850341797, "reward": 0.617434024810791, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8119, "ep_reward": 68.03633117675781, "reward": 0.6993061304092407, "action": 0.7374438047409058}
{"mode": "train", "epochs": 5, "timestep": 8120, "ep_reward": 68.80928802490234, "reward": 0.7729560732841492, "action": 1.3916678428649902}
{"mode": "train", "epochs": 5, "timestep": 8121, "ep_reward": 69.6289291381836, "reward": 0.8196412324905396, "action": 1.1643836498260498}
{"mode": "train", "epochs": 5, "timestep": 8122, "ep_reward": 70.47903442382812, "reward": 0.8501049876213074, "action": 1.1730543375015259}
{"mode": "train", "epochs": 5, "timestep": 8123, "ep_reward": 71.342529296875, "reward": 0.8634917736053467, "action": 1.802875280380249}
{"mode": "train", "epochs": 5, "timestep": 8124, "ep_reward": 72.19738006591797, "reward": 0.8548522591590881, "action": 0.7225871086120605}
{"mode": "train", "epochs": 5, "timestep": 8125, "ep_reward": 73.03426361083984, "reward": 0.8368821144104004, "action": 1.5366833209991455}
{"mode": "train", "epochs": 5, "timestep": 8126, "ep_reward": 73.82317352294922, "reward": 0.7889106273651123, "action": 0.5313770771026611}
{"mode": "train", "epochs": 5, "timestep": 8127, "ep_reward": 74.54651641845703, "reward": 0.7233413457870483, "action": 0.436370313167572}
{"mode": "train", "epochs": 5, "timestep": 8128, "ep_reward": 75.17256164550781, "reward": 0.6260442733764648, "action": 1.105682611465454}
{"mode": "train", "epochs": 5, "timestep": 8129, "ep_reward": 75.6531982421875, "reward": 0.48063892126083374, "action": 1.2607738971710205}
{"mode": "train", "epochs": 5, "timestep": 8130, "ep_reward": 75.99652862548828, "reward": 0.34332966804504395, "action": 1.034630298614502}
{"mode": "train", "epochs": 5, "timestep": 8131, "ep_reward": 76.22858428955078, "reward": 0.23205924034118652, "action": 0.6296120882034302}
{"mode": "train", "epochs": 5, "timestep": 8132, "ep_reward": 76.32933044433594, "reward": 0.10074663162231445, "action": 0.6280590295791626}
{"mode": "train", "epochs": 5, "timestep": 8133, "ep_reward": 76.34507751464844, "reward": 0.01574850082397461, "action": 1.773366928100586}
{"mode": "train", "epochs": 5, "timestep": 8134, "ep_reward": 76.5037841796875, "reward": 0.15870529413223267, "action": 1.1818937063217163}
{"mode": "train", "epochs": 5, "timestep": 8135, "ep_reward": 76.79985809326172, "reward": 0.29607582092285156, "action": 1.5981371402740479}
{"mode": "train", "epochs": 5, "timestep": 8136, "ep_reward": 77.2255630493164, "reward": 0.4257039427757263, "action": 0.9074825644493103}
{"mode": "train", "epochs": 5, "timestep": 8137, "ep_reward": 77.77725219726562, "reward": 0.5516858100891113, "action": 1.6694570779800415}
{"mode": "train", "epochs": 5, "timestep": 8138, "ep_reward": 78.42607879638672, "reward": 0.6488231420516968, "action": 1.6801167726516724}
{"mode": "train", "epochs": 5, "timestep": 8139, "ep_reward": 79.15023040771484, "reward": 0.7241536974906921, "action": 0.1858246922492981}
{"mode": "train", "epochs": 5, "timestep": 8140, "ep_reward": 79.94161987304688, "reward": 0.7913892865180969, "action": 0.08850687742233276}
{"mode": "train", "epochs": 5, "timestep": 8141, "ep_reward": 80.77820587158203, "reward": 0.8365864157676697, "action": 0.3447358012199402}
{"mode": "train", "epochs": 5, "timestep": 8142, "ep_reward": 81.63819122314453, "reward": 0.8599830865859985, "action": 0.9981650710105896}
{"mode": "train", "epochs": 5, "timestep": 8143, "ep_reward": 82.49873352050781, "reward": 0.8605388402938843, "action": 0.4566027522087097}
{"mode": "train", "epochs": 5, "timestep": 8144, "ep_reward": 83.34687042236328, "reward": 0.8481331467628479, "action": 0.9558601975440979}
{"mode": "train", "epochs": 5, "timestep": 8145, "ep_reward": 84.15789031982422, "reward": 0.811019241809845, "action": 0.7619907855987549}
{"mode": "train", "epochs": 5, "timestep": 8146, "ep_reward": 84.90853881835938, "reward": 0.7506477236747742, "action": 0.7889556884765625}
{"mode": "train", "epochs": 5, "timestep": 8147, "ep_reward": 85.56722259521484, "reward": 0.6586823463439941, "action": 0.944370448589325}
{"mode": "train", "epochs": 5, "timestep": 8148, "ep_reward": 86.09394073486328, "reward": 0.5267207622528076, "action": 1.5965359210968018}
{"mode": "train", "epochs": 5, "timestep": 8149, "ep_reward": 86.46085357666016, "reward": 0.36691057682037354, "action": 1.4456297159194946}
{"mode": "train", "epochs": 5, "timestep": 8150, "ep_reward": 86.72135925292969, "reward": 0.2605091333389282, "action": 0.0016303062438964844}
{"mode": "train", "epochs": 5, "timestep": 8151, "ep_reward": 86.85530853271484, "reward": 0.13394802808761597, "action": 0.6792726516723633}
{"mode": "train", "epochs": 5, "timestep": 8152, "ep_reward": 86.84270477294922, "reward": -0.01260232925415039, "action": 0.8657277822494507}
{"mode": "train", "epochs": 5, "timestep": 8153, "ep_reward": 86.96914672851562, "reward": 0.1264391541481018, "action": 0.6773723363876343}
{"mode": "train", "epochs": 5, "timestep": 8154, "ep_reward": 87.23860168457031, "reward": 0.2694573998451233, "action": 0.5979933738708496}
{"mode": "train", "epochs": 5, "timestep": 8155, "ep_reward": 87.64995574951172, "reward": 0.4113529324531555, "action": 1.3613944053649902}
{"mode": "train", "epochs": 5, "timestep": 8156, "ep_reward": 88.18260955810547, "reward": 0.5326554179191589, "action": 1.5090765953063965}
{"mode": "train", "epochs": 5, "timestep": 8157, "ep_reward": 88.81792449951172, "reward": 0.6353135704994202, "action": 1.132261872291565}
{"mode": "train", "epochs": 5, "timestep": 8158, "ep_reward": 89.53890228271484, "reward": 0.7209750413894653, "action": 0.6184161305427551}
{"mode": "train", "epochs": 5, "timestep": 8159, "ep_reward": 90.3280029296875, "reward": 0.7890990972518921, "action": 0.979402482509613}
{"mode": "train", "epochs": 5, "timestep": 8160, "ep_reward": 91.16100311279297, "reward": 0.8330010175704956, "action": 0.9652432203292847}
{"mode": "train", "epochs": 5, "timestep": 8161, "ep_reward": 92.01998138427734, "reward": 0.8589810132980347, "action": 1.2452621459960938}
{"mode": "train", "epochs": 5, "timestep": 8162, "ep_reward": 92.88603973388672, "reward": 0.8660576343536377, "action": 1.7192705869674683}
{"mode": "train", "epochs": 5, "timestep": 8163, "ep_reward": 93.73831176757812, "reward": 0.8522697687149048, "action": 0.7249056696891785}
{"mode": "train", "epochs": 5, "timestep": 8164, "ep_reward": 94.5661392211914, "reward": 0.8278253674507141, "action": 1.2681626081466675}
{"mode": "train", "epochs": 5, "timestep": 8165, "ep_reward": 95.34091186523438, "reward": 0.7747746706008911, "action": 0.11571091413497925}
{"mode": "train", "epochs": 5, "timestep": 8166, "ep_reward": 96.04630279541016, "reward": 0.7053907513618469, "action": 0.744064450263977}
{"mode": "train", "epochs": 5, "timestep": 8167, "ep_reward": 96.64107513427734, "reward": 0.5947701930999756, "action": 0.872974157333374}
{"mode": "train", "epochs": 5, "timestep": 8168, "ep_reward": 97.08338165283203, "reward": 0.4423028230667114, "action": 1.110148549079895}
{"mode": "train", "epochs": 5, "timestep": 8169, "ep_reward": 97.3980712890625, "reward": 0.3146914839744568, "action": 0.9802398085594177}
{"mode": "train", "epochs": 5, "timestep": 8170, "ep_reward": 97.5959701538086, "reward": 0.1978980302810669, "action": 0.7562052011489868}
{"mode": "train", "epochs": 5, "timestep": 8171, "ep_reward": 97.65703582763672, "reward": 0.061068594455718994, "action": 0.8698791265487671}
{"mode": "train", "epochs": 5, "timestep": 8172, "ep_reward": 97.71420288085938, "reward": 0.05716806650161743, "action": 1.214504599571228}
{"mode": "train", "epochs": 5, "timestep": 8173, "ep_reward": 97.90876007080078, "reward": 0.19455641508102417, "action": 0.8583528995513916}
{"mode": "train", "epochs": 5, "timestep": 8174, "ep_reward": 98.24533081054688, "reward": 0.3365745544433594, "action": 0.9977319240570068}
{"mode": "train", "epochs": 5, "timestep": 8175, "ep_reward": 98.71566772460938, "reward": 0.4703402519226074, "action": 0.9899561405181885}
{"mode": "train", "epochs": 5, "timestep": 8176, "ep_reward": 99.3044204711914, "reward": 0.5887527465820312, "action": 1.1477084159851074}
{"mode": "train", "epochs": 5, "timestep": 8177, "ep_reward": 99.98876190185547, "reward": 0.6843421459197998, "action": 1.3949373960494995}
{"mode": "train", "epochs": 5, "timestep": 8178, "ep_reward": 100.74401092529297, "reward": 0.7552517652511597, "action": -0.22987937927246094}
{"mode": "train", "epochs": 5, "timestep": 8179, "ep_reward": 101.56344604492188, "reward": 0.8194366693496704, "action": 1.0928963422775269}
{"mode": "train", "epochs": 5, "timestep": 8180, "ep_reward": 102.41508483886719, "reward": 0.8516358733177185, "action": 0.6239808797836304}
{"mode": "train", "epochs": 5, "timestep": 8181, "ep_reward": 103.28610229492188, "reward": 0.8710189461708069, "action": 0.9521229267120361}
{"mode": "train", "epochs": 5, "timestep": 8182, "ep_reward": 104.157958984375, "reward": 0.8718552589416504, "action": 1.475921392440796}
{"mode": "train", "epochs": 5, "timestep": 8183, "ep_reward": 105.00933837890625, "reward": 0.8513797521591187, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8184, "ep_reward": 105.81429290771484, "reward": 0.804956316947937, "action": 1.0518007278442383}
{"mode": "train", "epochs": 5, "timestep": 8185, "ep_reward": 106.55484771728516, "reward": 0.740552544593811, "action": 1.0389001369476318}
{"mode": "train", "epochs": 5, "timestep": 8186, "ep_reward": 107.19786071777344, "reward": 0.643014132976532, "action": 0.9039987325668335}
{"mode": "train", "epochs": 5, "timestep": 8187, "ep_reward": 107.70527648925781, "reward": 0.5074127912521362, "action": 1.6241910457611084}
{"mode": "train", "epochs": 5, "timestep": 8188, "ep_reward": 108.06777954101562, "reward": 0.3625040054321289, "action": 1.304624080657959}
{"mode": "train", "epochs": 5, "timestep": 8189, "ep_reward": 108.3228759765625, "reward": 0.2550956606864929, "action": 1.0510642528533936}
{"mode": "train", "epochs": 5, "timestep": 8190, "ep_reward": 108.45059204101562, "reward": 0.1277133822441101, "action": 0.2949333190917969}
{"mode": "train", "epochs": 5, "timestep": 8191, "ep_reward": 108.43653106689453, "reward": -0.014061808586120605, "action": 1.1439787149429321}
{"mode": "train", "epochs": 5, "timestep": 8192, "ep_reward": 108.56919860839844, "reward": 0.13266688585281372, "action": 1.0377583503723145}
{"mode": "train", "epochs": 5, "timestep": 8193, "ep_reward": 108.84043884277344, "reward": 0.271240234375, "action": 1.605755090713501}
{"mode": "train", "epochs": 5, "timestep": 8194, "ep_reward": 109.24219512939453, "reward": 0.4017574191093445, "action": 0.3394966125488281}
{"mode": "train", "epochs": 5, "timestep": 8195, "ep_reward": 109.77943420410156, "reward": 0.5372384190559387, "action": 0.943822979927063}
{"mode": "train", "epochs": 5, "timestep": 8196, "ep_reward": 110.42454528808594, "reward": 0.645107626914978, "action": 0.33663660287857056}
{"mode": "train", "epochs": 5, "timestep": 8197, "ep_reward": 111.16078186035156, "reward": 0.7362359762191772, "action": 0.5725117921829224}
{"mode": "train", "epochs": 5, "timestep": 8198, "ep_reward": 111.96248626708984, "reward": 0.8017043471336365, "action": -0.24125194549560547}
{"mode": "train", "epochs": 5, "timestep": 8199, "ep_reward": 112.81599426269531, "reward": 0.8535053730010986, "action": 1.1037009954452515}
{"mode": "train", "epochs": 5, "timestep": 8200, "ep_reward": 113.69327545166016, "reward": 0.8772775530815125, "action": 0.8424398303031921}
{"mode": "train", "epochs": 5, "timestep": 8201, "ep_reward": 114.58221435546875, "reward": 0.8889413475990295, "action": 1.065250277519226}
{"mode": "train", "epochs": 5, "timestep": 8202, "ep_reward": 115.46737670898438, "reward": 0.885159969329834, "action": 1.042600154876709}
{"mode": "train", "epochs": 5, "timestep": 8203, "ep_reward": 116.33380126953125, "reward": 0.866421639919281, "action": 1.3841291666030884}
{"mode": "train", "epochs": 5, "timestep": 8204, "ep_reward": 117.15995788574219, "reward": 0.8261532187461853, "action": 0.7973150610923767}
{"mode": "train", "epochs": 5, "timestep": 8205, "ep_reward": 117.92731475830078, "reward": 0.7673561573028564, "action": 1.8715922832489014}
{"mode": "train", "epochs": 5, "timestep": 8206, "ep_reward": 118.59300994873047, "reward": 0.6656988263130188, "action": 0.6180928349494934}
{"mode": "train", "epochs": 5, "timestep": 8207, "ep_reward": 119.13357543945312, "reward": 0.54056715965271, "action": 1.2859113216400146}
{"mode": "train", "epochs": 5, "timestep": 8208, "ep_reward": 119.50353240966797, "reward": 0.3699548840522766, "action": 1.1982866525650024}
{"mode": "train", "epochs": 5, "timestep": 8209, "ep_reward": 119.76748657226562, "reward": 0.26395338773727417, "action": 1.7135248184204102}
{"mode": "train", "epochs": 5, "timestep": 8210, "ep_reward": 119.90565490722656, "reward": 0.1381712555885315, "action": 0.9611784815788269}
{"mode": "train", "epochs": 5, "timestep": 8211, "ep_reward": 119.8979263305664, "reward": -0.007729649543762207, "action": 0.8988999724388123}
{"mode": "train", "epochs": 5, "timestep": 8212, "ep_reward": 120.0199203491211, "reward": 0.12199234962463379, "action": 1.6474486589431763}
{"mode": "train", "epochs": 5, "timestep": 8213, "ep_reward": 120.27253723144531, "reward": 0.25261545181274414, "action": 1.9468517303466797}
{"mode": "train", "epochs": 5, "timestep": 8214, "ep_reward": 120.65325927734375, "reward": 0.38072365522384644, "action": 1.1852631568908691}
{"mode": "train", "epochs": 5, "timestep": 8215, "ep_reward": 121.16291046142578, "reward": 0.5096520185470581, "action": 1.6434804201126099}
{"mode": "train", "epochs": 5, "timestep": 8216, "ep_reward": 121.77742004394531, "reward": 0.6145131587982178, "action": 1.212570071220398}
{"mode": "train", "epochs": 5, "timestep": 8217, "ep_reward": 122.47889709472656, "reward": 0.7014801502227783, "action": 1.014247179031372}
{"mode": "train", "epochs": 5, "timestep": 8218, "ep_reward": 123.244873046875, "reward": 0.7659749984741211, "action": 0.6646438837051392}
{"mode": "train", "epochs": 5, "timestep": 8219, "ep_reward": 124.05517578125, "reward": 0.8103038668632507, "action": 1.5213795900344849}
{"mode": "train", "epochs": 5, "timestep": 8220, "ep_reward": 124.88013458251953, "reward": 0.8249595165252686, "action": 1.003755807876587}
{"mode": "train", "epochs": 5, "timestep": 8221, "ep_reward": 125.70345306396484, "reward": 0.823318362236023, "action": 1.834609031677246}
{"mode": "train", "epochs": 5, "timestep": 8222, "ep_reward": 126.49359130859375, "reward": 0.7901354432106018, "action": 0.9461114406585693}
{"mode": "train", "epochs": 5, "timestep": 8223, "ep_reward": 127.23158264160156, "reward": 0.7379934787750244, "action": 0.04396003484725952}
{"mode": "train", "epochs": 5, "timestep": 8224, "ep_reward": 127.89552307128906, "reward": 0.6639412641525269, "action": 0.7895786762237549}
{"mode": "train", "epochs": 5, "timestep": 8225, "ep_reward": 128.43792724609375, "reward": 0.5424085855484009, "action": 1.175441861152649}
{"mode": "train", "epochs": 5, "timestep": 8226, "ep_reward": 128.8370819091797, "reward": 0.3991488814353943, "action": 1.0123850107192993}
{"mode": "train", "epochs": 5, "timestep": 8227, "ep_reward": 129.13661193847656, "reward": 0.29953110218048096, "action": 1.0037094354629517}
{"mode": "train", "epochs": 5, "timestep": 8228, "ep_reward": 129.3165283203125, "reward": 0.1799219250679016, "action": 0.920612633228302}
{"mode": "train", "epochs": 5, "timestep": 8229, "ep_reward": 129.3568572998047, "reward": 0.040335774421691895, "action": 0.5643547773361206}
{"mode": "train", "epochs": 5, "timestep": 8230, "ep_reward": 129.43443298339844, "reward": 0.07756978273391724, "action": 1.4519625902175903}
{"mode": "train", "epochs": 5, "timestep": 8231, "ep_reward": 129.6466064453125, "reward": 0.21217256784439087, "action": 1.057120680809021}
{"mode": "train", "epochs": 5, "timestep": 8232, "ep_reward": 129.99853515625, "reward": 0.35192179679870605, "action": 0.46804165840148926}
{"mode": "train", "epochs": 5, "timestep": 8233, "ep_reward": 130.4895782470703, "reward": 0.49104785919189453, "action": 1.1347763538360596}
{"mode": "train", "epochs": 5, "timestep": 8234, "ep_reward": 131.09429931640625, "reward": 0.6047190427780151, "action": -0.20340466499328613}
{"mode": "train", "epochs": 5, "timestep": 8235, "ep_reward": 131.80462646484375, "reward": 0.7103204727172852, "action": 1.7075258493423462}
{"mode": "train", "epochs": 5, "timestep": 8236, "ep_reward": 132.57798767089844, "reward": 0.7733559012413025, "action": 1.0779087543487549}
{"mode": "train", "epochs": 5, "timestep": 8237, "ep_reward": 133.40042114257812, "reward": 0.8224371671676636, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8238, "ep_reward": 134.24612426757812, "reward": 0.8457040190696716, "action": 0.7298260927200317}
{"mode": "train", "epochs": 5, "timestep": 8239, "ep_reward": 135.1090850830078, "reward": 0.8629601001739502, "action": 0.8097085952758789}
{"mode": "train", "epochs": 5, "timestep": 8240, "ep_reward": 135.97181701660156, "reward": 0.8627384901046753, "action": 0.77269047498703}
{"mode": "train", "epochs": 5, "timestep": 8241, "ep_reward": 136.8169403076172, "reward": 0.8451242446899414, "action": 1.208730697631836}
{"mode": "train", "epochs": 5, "timestep": 8242, "ep_reward": 137.61940002441406, "reward": 0.8024592995643616, "action": 1.219029426574707}
{"mode": "train", "epochs": 5, "timestep": 8243, "ep_reward": 138.3519287109375, "reward": 0.7325258851051331, "action": 0.9604778289794922}
{"mode": "train", "epochs": 5, "timestep": 8244, "ep_reward": 138.9834747314453, "reward": 0.6315515041351318, "action": 0.5178751945495605}
{"mode": "train", "epochs": 5, "timestep": 8245, "ep_reward": 139.48069763183594, "reward": 0.49722856283187866, "action": 1.848031997680664}
{"mode": "train", "epochs": 5, "timestep": 8246, "ep_reward": 139.83120727539062, "reward": 0.35050493478775024, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8247, "ep_reward": 140.07208251953125, "reward": 0.2408822774887085, "action": 0.6099916696548462}
{"mode": "train", "epochs": 5, "timestep": 8248, "ep_reward": 140.18304443359375, "reward": 0.11096656322479248, "action": 1.1966006755828857}
{"mode": "train", "epochs": 5, "timestep": 8249, "ep_reward": 140.18760681152344, "reward": 0.004568576812744141, "action": 1.5015232563018799}
{"mode": "train", "epochs": 5, "timestep": 8250, "ep_reward": 140.3365936279297, "reward": 0.14898496866226196, "action": 0.7501953840255737}
{"mode": "train", "epochs": 5, "timestep": 8251, "ep_reward": 140.6280517578125, "reward": 0.29145264625549316, "action": 1.7965292930603027}
{"mode": "train", "epochs": 5, "timestep": 8252, "ep_reward": 141.0462188720703, "reward": 0.41817164421081543, "action": 1.0643153190612793}
{"mode": "train", "epochs": 5, "timestep": 8253, "ep_reward": 141.58929443359375, "reward": 0.5430679321289062, "action": 1.947347640991211}
{"mode": "train", "epochs": 5, "timestep": 8254, "ep_reward": 142.2283172607422, "reward": 0.639024019241333, "action": 0.7597097158432007}
{"mode": "train", "epochs": 5, "timestep": 8255, "ep_reward": 142.95423889160156, "reward": 0.7259202003479004, "action": 0.735496997833252}
{"mode": "train", "epochs": 5, "timestep": 8256, "ep_reward": 143.74327087402344, "reward": 0.7890376448631287, "action": 0.09103959798812866}
{"mode": "train", "epochs": 5, "timestep": 8257, "ep_reward": 144.5792999267578, "reward": 0.836028516292572, "action": 1.4857468605041504}
{"mode": "train", "epochs": 5, "timestep": 8258, "ep_reward": 145.43093872070312, "reward": 0.8516391515731812, "action": 1.132318377494812}
{"mode": "train", "epochs": 5, "timestep": 8259, "ep_reward": 146.28359985351562, "reward": 0.8526556491851807, "action": 1.283196210861206}
{"mode": "train", "epochs": 5, "timestep": 8260, "ep_reward": 147.1167449951172, "reward": 0.8331429362297058, "action": 1.8813726902008057}
{"mode": "train", "epochs": 5, "timestep": 8261, "ep_reward": 147.9014129638672, "reward": 0.7846629023551941, "action": 0.5617415904998779}
{"mode": "train", "epochs": 5, "timestep": 8262, "ep_reward": 148.62252807617188, "reward": 0.7211086750030518, "action": 0.6144623756408691}
{"mode": "train", "epochs": 5, "timestep": 8263, "ep_reward": 149.24575805664062, "reward": 0.6232280731201172, "action": 0.6277769207954407}
{"mode": "train", "epochs": 5, "timestep": 8264, "ep_reward": 149.7314910888672, "reward": 0.4857359528541565, "action": 0.891083300113678}
{"mode": "train", "epochs": 5, "timestep": 8265, "ep_reward": 150.08267211914062, "reward": 0.3511773347854614, "action": 1.9875215291976929}
{"mode": "train", "epochs": 5, "timestep": 8266, "ep_reward": 150.32421875, "reward": 0.2415447235107422, "action": 1.6212396621704102}
{"mode": "train", "epochs": 5, "timestep": 8267, "ep_reward": 150.43621826171875, "reward": 0.11199307441711426, "action": -0.09821975231170654}
{"mode": "train", "epochs": 5, "timestep": 8268, "ep_reward": 150.4397735595703, "reward": 0.0035480260848999023, "action": 1.4193177223205566}
{"mode": "train", "epochs": 5, "timestep": 8269, "ep_reward": 150.58782958984375, "reward": 0.14804953336715698, "action": 1.0522634983062744}
{"mode": "train", "epochs": 5, "timestep": 8270, "ep_reward": 150.87460327148438, "reward": 0.28677529096603394, "action": 1.73357093334198}
{"mode": "train", "epochs": 5, "timestep": 8271, "ep_reward": 151.2896728515625, "reward": 0.4150620102882385, "action": -0.2701139450073242}
{"mode": "train", "epochs": 5, "timestep": 8272, "ep_reward": 151.84559631347656, "reward": 0.5559214353561401, "action": 0.9115745425224304}
{"mode": "train", "epochs": 5, "timestep": 8273, "ep_reward": 152.5060272216797, "reward": 0.6604372262954712, "action": 1.972923755645752}
{"mode": "train", "epochs": 5, "timestep": 8274, "ep_reward": 153.2386016845703, "reward": 0.7325711846351624, "action": 1.0682904720306396}
{"mode": "train", "epochs": 5, "timestep": 8275, "ep_reward": 154.03146362304688, "reward": 0.7928634881973267, "action": 0.8165839910507202}
{"mode": "train", "epochs": 5, "timestep": 8276, "ep_reward": 154.8662567138672, "reward": 0.8347961902618408, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8277, "ep_reward": 155.71466064453125, "reward": 0.8484002947807312, "action": 1.1541178226470947}
{"mode": "train", "epochs": 5, "timestep": 8278, "ep_reward": 156.5662384033203, "reward": 0.8515783548355103, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8279, "ep_reward": 157.39410400390625, "reward": 0.8278676271438599, "action": 0.9702927470207214}
{"mode": "train", "epochs": 5, "timestep": 8280, "ep_reward": 158.18482971191406, "reward": 0.7907264828681946, "action": 0.42667222023010254}
{"mode": "train", "epochs": 5, "timestep": 8281, "ep_reward": 158.91690063476562, "reward": 0.7320784330368042, "action": 1.2166718244552612}
{"mode": "train", "epochs": 5, "timestep": 8282, "ep_reward": 159.5474090576172, "reward": 0.6305148601531982, "action": 1.4444503784179688}
{"mode": "train", "epochs": 5, "timestep": 8283, "ep_reward": 160.03097534179688, "reward": 0.483568012714386, "action": 0.6224618554115295}
{"mode": "train", "epochs": 5, "timestep": 8284, "ep_reward": 160.3900909423828, "reward": 0.35912156105041504, "action": 1.812506914138794}
{"mode": "train", "epochs": 5, "timestep": 8285, "ep_reward": 160.64125061035156, "reward": 0.25116604566574097, "action": 0.8341958522796631}
{"mode": "train", "epochs": 5, "timestep": 8286, "ep_reward": 160.76429748535156, "reward": 0.1230509877204895, "action": 0.8104814887046814}
{"mode": "train", "epochs": 5, "timestep": 8287, "ep_reward": 160.7555389404297, "reward": -0.008765459060668945, "action": 0.7646234035491943}
{"mode": "train", "epochs": 5, "timestep": 8288, "ep_reward": 160.8927001953125, "reward": 0.13716459274291992, "action": 1.5449554920196533}
{"mode": "train", "epochs": 5, "timestep": 8289, "ep_reward": 161.16226196289062, "reward": 0.26955950260162354, "action": 1.4863252639770508}
{"mode": "train", "epochs": 5, "timestep": 8290, "ep_reward": 161.5647430419922, "reward": 0.4024796485900879, "action": 0.9695457220077515}
{"mode": "train", "epochs": 5, "timestep": 8291, "ep_reward": 162.09571838378906, "reward": 0.5309762954711914, "action": 1.1250863075256348}
{"mode": "train", "epochs": 5, "timestep": 8292, "ep_reward": 162.73362731933594, "reward": 0.6379082202911377, "action": 0.9252652525901794}
{"mode": "train", "epochs": 5, "timestep": 8293, "ep_reward": 163.45742797851562, "reward": 0.7238037586212158, "action": 0.6687435507774353}
{"mode": "train", "epochs": 5, "timestep": 8294, "ep_reward": 164.24603271484375, "reward": 0.7886122465133667, "action": 0.5054274797439575}
{"mode": "train", "epochs": 5, "timestep": 8295, "ep_reward": 165.0791473388672, "reward": 0.8331130743026733, "action": 0.9272481799125671}
{"mode": "train", "epochs": 5, "timestep": 8296, "ep_reward": 165.933837890625, "reward": 0.8546933531761169, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8297, "ep_reward": 166.78329467773438, "reward": 0.849449634552002, "action": 1.7214024066925049}
{"mode": "train", "epochs": 5, "timestep": 8298, "ep_reward": 167.61033630371094, "reward": 0.8270471692085266, "action": 0.8920127153396606}
{"mode": "train", "epochs": 5, "timestep": 8299, "ep_reward": 168.39971923828125, "reward": 0.78937828540802, "action": 0.7200409173965454}
{"mode": "train", "epochs": 5, "timestep": 8300, "ep_reward": 169.1256103515625, "reward": 0.7258850336074829, "action": 0.5324035882949829}
{"mode": "train", "epochs": 5, "timestep": 8301, "ep_reward": 169.7568359375, "reward": 0.6312291622161865, "action": 0.10476571321487427}
{"mode": "train", "epochs": 5, "timestep": 8302, "ep_reward": 170.26132202148438, "reward": 0.5044859647750854, "action": 0.2668299078941345}
{"mode": "train", "epochs": 5, "timestep": 8303, "ep_reward": 170.61947631835938, "reward": 0.3581586480140686, "action": 0.07433527708053589}
{"mode": "train", "epochs": 5, "timestep": 8304, "ep_reward": 170.8691864013672, "reward": 0.24970364570617676, "action": 1.2664591073989868}
{"mode": "train", "epochs": 5, "timestep": 8305, "ep_reward": 170.99049377441406, "reward": 0.1213117241859436, "action": 1.4800899028778076}
{"mode": "train", "epochs": 5, "timestep": 8306, "ep_reward": 170.98353576660156, "reward": -0.006960391998291016, "action": 1.1676230430603027}
{"mode": "train", "epochs": 5, "timestep": 8307, "ep_reward": 171.1223907470703, "reward": 0.13884931802749634, "action": 1.1340818405151367}
{"mode": "train", "epochs": 5, "timestep": 8308, "ep_reward": 171.39891052246094, "reward": 0.2765262722969055, "action": 0.44404369592666626}
{"mode": "train", "epochs": 5, "timestep": 8309, "ep_reward": 171.81985473632812, "reward": 0.4209481477737427, "action": 0.8045061826705933}
{"mode": "train", "epochs": 5, "timestep": 8310, "ep_reward": 172.36756896972656, "reward": 0.5477087497711182, "action": 1.3635773658752441}
{"mode": "train", "epochs": 5, "timestep": 8311, "ep_reward": 173.01675415039062, "reward": 0.6491829752922058, "action": 1.5082952976226807}
{"mode": "train", "epochs": 5, "timestep": 8312, "ep_reward": 173.7449493408203, "reward": 0.728193998336792, "action": 1.3556506633758545}
{"mode": "train", "epochs": 5, "timestep": 8313, "ep_reward": 174.53253173828125, "reward": 0.7875882983207703, "action": 0.6969196200370789}
{"mode": "train", "epochs": 5, "timestep": 8314, "ep_reward": 175.36512756347656, "reward": 0.8325997591018677, "action": 1.4668989181518555}
{"mode": "train", "epochs": 5, "timestep": 8315, "ep_reward": 176.21755981445312, "reward": 0.8524397611618042, "action": 1.464751124382019}
{"mode": "train", "epochs": 5, "timestep": 8316, "ep_reward": 177.0727081298828, "reward": 0.8551518321037292, "action": 0.9047330021858215}
{"mode": "train", "epochs": 5, "timestep": 8317, "ep_reward": 177.9171600341797, "reward": 0.8444443941116333, "action": 1.844533920288086}
{"mode": "train", "epochs": 5, "timestep": 8318, "ep_reward": 178.72073364257812, "reward": 0.8035660982131958, "action": 1.9835546016693115}
{"mode": "train", "epochs": 5, "timestep": 8319, "ep_reward": 179.45347595214844, "reward": 0.7327439188957214, "action": 0.5986896753311157}
{"mode": "train", "epochs": 5, "timestep": 8320, "ep_reward": 180.09625244140625, "reward": 0.6427745223045349, "action": 1.6837759017944336}
{"mode": "train", "epochs": 5, "timestep": 8321, "ep_reward": 180.59365844726562, "reward": 0.4974045157432556, "action": 0.14528816938400269}
{"mode": "train", "epochs": 5, "timestep": 8322, "ep_reward": 180.9656219482422, "reward": 0.3719603419303894, "action": 0.9911003112792969}
{"mode": "train", "epochs": 5, "timestep": 8323, "ep_reward": 181.23214721679688, "reward": 0.2665191888809204, "action": 0.3572544455528259}
{"mode": "train", "epochs": 5, "timestep": 8324, "ep_reward": 181.3730926513672, "reward": 0.1409447193145752, "action": 1.1850166320800781}
{"mode": "train", "epochs": 5, "timestep": 8325, "ep_reward": 181.3685760498047, "reward": -0.004521489143371582, "action": 0.9719634652137756}
{"mode": "train", "epochs": 5, "timestep": 8326, "ep_reward": 181.48776245117188, "reward": 0.11918914318084717, "action": 1.3415342569351196}
{"mode": "train", "epochs": 5, "timestep": 8327, "ep_reward": 181.74148559570312, "reward": 0.2537257671356201, "action": 1.0517792701721191}
{"mode": "train", "epochs": 5, "timestep": 8328, "ep_reward": 182.13375854492188, "reward": 0.3922656178474426, "action": 0.8716982007026672}
{"mode": "train", "epochs": 5, "timestep": 8329, "ep_reward": 182.65625, "reward": 0.5224975347518921, "action": 1.0725549459457397}
{"mode": "train", "epochs": 5, "timestep": 8330, "ep_reward": 183.287841796875, "reward": 0.631590723991394, "action": 1.0105466842651367}
{"mode": "train", "epochs": 5, "timestep": 8331, "ep_reward": 184.00677490234375, "reward": 0.7189331650733948, "action": 1.3414545059204102}
{"mode": "train", "epochs": 5, "timestep": 8332, "ep_reward": 184.7871856689453, "reward": 0.7804107069969177, "action": 1.756913661956787}
{"mode": "train", "epochs": 5, "timestep": 8333, "ep_reward": 185.60496520996094, "reward": 0.8177841305732727, "action": 0.9182654619216919}
{"mode": "train", "epochs": 5, "timestep": 8334, "ep_reward": 186.44859313964844, "reward": 0.8436261415481567, "action": 1.5240647792816162}
{"mode": "train", "epochs": 5, "timestep": 8335, "ep_reward": 187.29420471191406, "reward": 0.8456175327301025, "action": 0.004121243953704834}
{"mode": "train", "epochs": 5, "timestep": 8336, "ep_reward": 188.13645935058594, "reward": 0.8422585725784302, "action": 1.8124587535858154}
{"mode": "train", "epochs": 5, "timestep": 8337, "ep_reward": 188.93711853027344, "reward": 0.8006552457809448, "action": 0.6221445798873901}
{"mode": "train", "epochs": 5, "timestep": 8338, "ep_reward": 189.6812744140625, "reward": 0.7441495656967163, "action": 1.1107568740844727}
{"mode": "train", "epochs": 5, "timestep": 8339, "ep_reward": 190.33078002929688, "reward": 0.6495031118392944, "action": 0.3273742198944092}
{"mode": "train", "epochs": 5, "timestep": 8340, "ep_reward": 190.85693359375, "reward": 0.5261611342430115, "action": 1.5830941200256348}
{"mode": "train", "epochs": 5, "timestep": 8341, "ep_reward": 191.23184204101562, "reward": 0.37491005659103394, "action": 1.539489984512329}
{"mode": "train", "epochs": 5, "timestep": 8342, "ep_reward": 191.5018768310547, "reward": 0.27003777027130127, "action": 1.6195244789123535}
{"mode": "train", "epochs": 5, "timestep": 8343, "ep_reward": 191.6470947265625, "reward": 0.1452164649963379, "action": 1.4342373609542847}
{"mode": "train", "epochs": 5, "timestep": 8344, "ep_reward": 191.6475067138672, "reward": 0.0004120469093322754, "action": 1.1044031381607056}
{"mode": "train", "epochs": 5, "timestep": 8345, "ep_reward": 191.76222229003906, "reward": 0.11471569538116455, "action": 1.5582141876220703}
{"mode": "train", "epochs": 5, "timestep": 8346, "ep_reward": 192.0085906982422, "reward": 0.2463703155517578, "action": 1.398175597190857}
{"mode": "train", "epochs": 5, "timestep": 8347, "ep_reward": 192.3899688720703, "reward": 0.38138288259506226, "action": 0.8881571292877197}
{"mode": "train", "epochs": 5, "timestep": 8348, "ep_reward": 192.9031219482422, "reward": 0.513148307800293, "action": 1.6257400512695312}
{"mode": "train", "epochs": 5, "timestep": 8349, "ep_reward": 193.5208740234375, "reward": 0.6177453398704529, "action": 1.5553886890411377}
{"mode": "train", "epochs": 5, "timestep": 8350, "ep_reward": 194.22250366210938, "reward": 0.7016369700431824, "action": 0.8914116621017456}
{"mode": "train", "epochs": 5, "timestep": 8351, "ep_reward": 194.99151611328125, "reward": 0.7690093517303467, "action": 1.2597211599349976}
{"mode": "train", "epochs": 5, "timestep": 8352, "ep_reward": 195.80148315429688, "reward": 0.8099640607833862, "action": 1.8535335063934326}
{"mode": "train", "epochs": 5, "timestep": 8353, "ep_reward": 196.6263427734375, "reward": 0.8248547315597534, "action": 0.9487442374229431}
{"mode": "train", "epochs": 5, "timestep": 8354, "ep_reward": 197.4540252685547, "reward": 0.8276863098144531, "action": 0.6731031537055969}
{"mode": "train", "epochs": 5, "timestep": 8355, "ep_reward": 198.26519775390625, "reward": 0.8111717104911804, "action": 1.7224962711334229}
{"mode": "train", "epochs": 5, "timestep": 8356, "ep_reward": 199.02345275878906, "reward": 0.7582509517669678, "action": 1.1303279399871826}
{"mode": "train", "epochs": 5, "timestep": 8357, "ep_reward": 199.7025146484375, "reward": 0.6790679097175598, "action": 0.9808162450790405}
{"mode": "train", "epochs": 5, "timestep": 8358, "ep_reward": 200.2649383544922, "reward": 0.5624296069145203, "action": 1.52740478515625}
{"mode": "train", "epochs": 5, "timestep": 8359, "ep_reward": 200.68138122558594, "reward": 0.4164354205131531, "action": 0.3782894015312195}
{"mode": "train", "epochs": 5, "timestep": 8360, "ep_reward": 201.0020751953125, "reward": 0.3206866979598999, "action": 1.0617353916168213}
{"mode": "train", "epochs": 5, "timestep": 8361, "ep_reward": 201.2069854736328, "reward": 0.2049163579940796, "action": 1.5666173696517944}
{"mode": "train", "epochs": 5, "timestep": 8362, "ep_reward": 201.27626037597656, "reward": 0.06928145885467529, "action": 1.2701737880706787}
{"mode": "train", "epochs": 5, "timestep": 8363, "ep_reward": 201.32508850097656, "reward": 0.04882359504699707, "action": 1.107287883758545}
{"mode": "train", "epochs": 5, "timestep": 8364, "ep_reward": 201.51231384277344, "reward": 0.18723034858703613, "action": 1.5105324983596802}
{"mode": "train", "epochs": 5, "timestep": 8365, "ep_reward": 201.83322143554688, "reward": 0.3209041953086853, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8366, "ep_reward": 202.2779083251953, "reward": 0.4446907043457031, "action": 1.1668182611465454}
{"mode": "train", "epochs": 5, "timestep": 8367, "ep_reward": 202.8435821533203, "reward": 0.5656764507293701, "action": -0.06772398948669434}
{"mode": "train", "epochs": 5, "timestep": 8368, "ep_reward": 203.5216064453125, "reward": 0.6780277490615845, "action": 0.9424551725387573}
{"mode": "train", "epochs": 5, "timestep": 8369, "ep_reward": 204.27529907226562, "reward": 0.7536985278129578, "action": 0.36673325300216675}
{"mode": "train", "epochs": 5, "timestep": 8370, "ep_reward": 205.087158203125, "reward": 0.8118516802787781, "action": 1.7155885696411133}
{"mode": "train", "epochs": 5, "timestep": 8371, "ep_reward": 205.9248809814453, "reward": 0.8377208113670349, "action": 0.7037755250930786}
{"mode": "train", "epochs": 5, "timestep": 8372, "ep_reward": 206.7792510986328, "reward": 0.8543639779090881, "action": 1.5355980396270752}
{"mode": "train", "epochs": 5, "timestep": 8373, "ep_reward": 207.624755859375, "reward": 0.8455089330673218, "action": 1.3710602521896362}
{"mode": "train", "epochs": 5, "timestep": 8374, "ep_reward": 208.44244384765625, "reward": 0.8176919221878052, "action": 0.4480329155921936}
{"mode": "train", "epochs": 5, "timestep": 8375, "ep_reward": 209.2173309326172, "reward": 0.7748836874961853, "action": 0.9785527586936951}
{"mode": "train", "epochs": 5, "timestep": 8376, "ep_reward": 209.9144744873047, "reward": 0.6971399784088135, "action": 1.2300297021865845}
{"mode": "train", "epochs": 5, "timestep": 8377, "ep_reward": 210.49343872070312, "reward": 0.5789579153060913, "action": 1.7530992031097412}
{"mode": "train", "epochs": 5, "timestep": 8378, "ep_reward": 210.9049072265625, "reward": 0.411470890045166, "action": 1.2335985898971558}
{"mode": "train", "epochs": 5, "timestep": 8379, "ep_reward": 211.21961975097656, "reward": 0.31470930576324463, "action": 0.783015787601471}
{"mode": "train", "epochs": 5, "timestep": 8380, "ep_reward": 211.41749572753906, "reward": 0.19787651300430298, "action": 0.9174187183380127}
{"mode": "train", "epochs": 5, "timestep": 8381, "ep_reward": 211.47853088378906, "reward": 0.061037659645080566, "action": 1.07883882522583}
{"mode": "train", "epochs": 5, "timestep": 8382, "ep_reward": 211.53578186035156, "reward": 0.05725681781768799, "action": 0.3782918453216553}
{"mode": "train", "epochs": 5, "timestep": 8383, "ep_reward": 211.73770141601562, "reward": 0.20192056894302368, "action": 1.0539530515670776}
{"mode": "train", "epochs": 5, "timestep": 8384, "ep_reward": 212.07772827148438, "reward": 0.34001994132995605, "action": 1.0470850467681885}
{"mode": "train", "epochs": 5, "timestep": 8385, "ep_reward": 212.5500030517578, "reward": 0.47226983308792114, "action": 1.3896781206130981}
{"mode": "train", "epochs": 5, "timestep": 8386, "ep_reward": 213.1358642578125, "reward": 0.5858594179153442, "action": 0.9750115275382996}
{"mode": "train", "epochs": 5, "timestep": 8387, "ep_reward": 213.81964111328125, "reward": 0.6837757229804993, "action": 1.57794189453125}
{"mode": "train", "epochs": 5, "timestep": 8388, "ep_reward": 214.5727996826172, "reward": 0.7531551122665405, "action": 1.6711801290512085}
{"mode": "train", "epochs": 5, "timestep": 8389, "ep_reward": 215.3737030029297, "reward": 0.8009021878242493, "action": 1.6282371282577515}
{"mode": "train", "epochs": 5, "timestep": 8390, "ep_reward": 216.20323181152344, "reward": 0.8295327425003052, "action": 1.524158239364624}
{"mode": "train", "epochs": 5, "timestep": 8391, "ep_reward": 217.04345703125, "reward": 0.8402203321456909, "action": 1.1734275817871094}
{"mode": "train", "epochs": 5, "timestep": 8392, "ep_reward": 217.87802124023438, "reward": 0.8345680236816406, "action": 1.253055453300476}
{"mode": "train", "epochs": 5, "timestep": 8393, "ep_reward": 218.6842498779297, "reward": 0.8062335848808289, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8394, "ep_reward": 219.42721557617188, "reward": 0.742964506149292, "action": 1.076752781867981}
{"mode": "train", "epochs": 5, "timestep": 8395, "ep_reward": 220.08248901367188, "reward": 0.6552798748016357, "action": 1.288909912109375}
{"mode": "train", "epochs": 5, "timestep": 8396, "ep_reward": 220.60606384277344, "reward": 0.5235822796821594, "action": 0.1134149432182312}
{"mode": "train", "epochs": 5, "timestep": 8397, "ep_reward": 221.00022888183594, "reward": 0.3941713571548462, "action": 1.4634275436401367}
{"mode": "train", "epochs": 5, "timestep": 8398, "ep_reward": 221.29379272460938, "reward": 0.2935618758201599, "action": 0.7781940698623657}
{"mode": "train", "epochs": 5, "timestep": 8399, "ep_reward": 221.4666748046875, "reward": 0.1728750467300415, "action": 0.5631131529808044}
{"mode": "train", "epochs": 5, "timestep": 8400, "ep_reward": 221.49884033203125, "reward": 0.032165706157684326, "action": 0.6308808326721191}
{"mode": "train", "epochs": 5, "timestep": 8401, "ep_reward": 221.58433532714844, "reward": 0.08550238609313965, "action": 0.6480444669723511}
{"mode": "train", "epochs": 5, "timestep": 8402, "ep_reward": 221.8120574951172, "reward": 0.22772973775863647, "action": 0.7180958986282349}
{"mode": "train", "epochs": 5, "timestep": 8403, "ep_reward": 222.1818389892578, "reward": 0.3697764277458191, "action": 1.0647685527801514}
{"mode": "train", "epochs": 5, "timestep": 8404, "ep_reward": 222.68080139160156, "reward": 0.49895739555358887, "action": 1.2692203521728516}
{"mode": "train", "epochs": 5, "timestep": 8405, "ep_reward": 223.29049682617188, "reward": 0.6096987128257751, "action": 1.2558939456939697}
{"mode": "train", "epochs": 5, "timestep": 8406, "ep_reward": 223.99058532714844, "reward": 0.7000899910926819, "action": 0.2509337067604065}
{"mode": "train", "epochs": 5, "timestep": 8407, "ep_reward": 224.7684326171875, "reward": 0.7778491973876953, "action": 0.11115723848342896}
{"mode": "train", "epochs": 5, "timestep": 8408, "ep_reward": 225.60281372070312, "reward": 0.8343779444694519, "action": 0.9055228233337402}
{"mode": "train", "epochs": 5, "timestep": 8409, "ep_reward": 226.46861267089844, "reward": 0.8657964468002319, "action": 0.5796668529510498}
{"mode": "train", "epochs": 5, "timestep": 8410, "ep_reward": 227.35304260253906, "reward": 0.8844335079193115, "action": 1.2663650512695312}
{"mode": "train", "epochs": 5, "timestep": 8411, "ep_reward": 228.2366943359375, "reward": 0.8836444020271301, "action": 0.7438359260559082}
{"mode": "train", "epochs": 5, "timestep": 8412, "ep_reward": 229.1088104248047, "reward": 0.8721228837966919, "action": 1.1870366334915161}
{"mode": "train", "epochs": 5, "timestep": 8413, "ep_reward": 229.9484100341797, "reward": 0.8396008610725403, "action": 0.5207722187042236}
{"mode": "train", "epochs": 5, "timestep": 8414, "ep_reward": 230.74000549316406, "reward": 0.7915998101234436, "action": 0.7874206304550171}
{"mode": "train", "epochs": 5, "timestep": 8415, "ep_reward": 231.4541015625, "reward": 0.7140991687774658, "action": 1.0720865726470947}
{"mode": "train", "epochs": 5, "timestep": 8416, "ep_reward": 232.05319213867188, "reward": 0.599086344242096, "action": 1.150399923324585}
{"mode": "train", "epochs": 5, "timestep": 8417, "ep_reward": 232.495849609375, "reward": 0.44265639781951904, "action": 1.209702730178833}
{"mode": "train", "epochs": 5, "timestep": 8418, "ep_reward": 232.80184936523438, "reward": 0.30600130558013916, "action": 1.4537262916564941}
{"mode": "train", "epochs": 5, "timestep": 8419, "ep_reward": 232.98948669433594, "reward": 0.1876370906829834, "action": 1.126767873764038}
{"mode": "train", "epochs": 5, "timestep": 8420, "ep_reward": 233.0387725830078, "reward": 0.04928308725357056, "action": 0.5210603475570679}
{"mode": "train", "epochs": 5, "timestep": 8421, "ep_reward": 233.10760498046875, "reward": 0.06882917881011963, "action": 1.5896883010864258}
{"mode": "train", "epochs": 5, "timestep": 8422, "ep_reward": 233.3122100830078, "reward": 0.20461076498031616, "action": 1.360482096672058}
{"mode": "train", "epochs": 5, "timestep": 8423, "ep_reward": 233.6527862548828, "reward": 0.3405788540840149, "action": 0.019069254398345947}
{"mode": "train", "epochs": 5, "timestep": 8424, "ep_reward": 234.13914489746094, "reward": 0.48635220527648926, "action": 1.195857048034668}
{"mode": "train", "epochs": 5, "timestep": 8425, "ep_reward": 234.73907470703125, "reward": 0.5999252796173096, "action": 1.2443180084228516}
{"mode": "train", "epochs": 5, "timestep": 8426, "ep_reward": 235.43142700195312, "reward": 0.6923598647117615, "action": 0.9174729585647583}
{"mode": "train", "epochs": 5, "timestep": 8427, "ep_reward": 236.19723510742188, "reward": 0.7658144235610962, "action": 0.10364055633544922}
{"mode": "train", "epochs": 5, "timestep": 8428, "ep_reward": 237.02191162109375, "reward": 0.8246697783470154, "action": 1.4239968061447144}
{"mode": "train", "epochs": 5, "timestep": 8429, "ep_reward": 237.8748321533203, "reward": 0.8529179096221924, "action": 0.8034310340881348}
{"mode": "train", "epochs": 5, "timestep": 8430, "ep_reward": 238.744873046875, "reward": 0.8700341582298279, "action": 0.2979281544685364}
{"mode": "train", "epochs": 5, "timestep": 8431, "ep_reward": 239.62030029296875, "reward": 0.875421404838562, "action": 1.5879197120666504}
{"mode": "train", "epochs": 5, "timestep": 8432, "ep_reward": 240.4739990234375, "reward": 0.8536978960037231, "action": 1.1355957984924316}
{"mode": "train", "epochs": 5, "timestep": 8433, "ep_reward": 241.28977966308594, "reward": 0.8157816529273987, "action": 0.7129659652709961}
{"mode": "train", "epochs": 5, "timestep": 8434, "ep_reward": 242.04690551757812, "reward": 0.7571231722831726, "action": 1.780269980430603}
{"mode": "train", "epochs": 5, "timestep": 8435, "ep_reward": 242.70140075683594, "reward": 0.6544921398162842, "action": 0.5130128860473633}
{"mode": "train", "epochs": 5, "timestep": 8436, "ep_reward": 243.2296142578125, "reward": 0.5282157063484192, "action": 1.552782416343689}
{"mode": "train", "epochs": 5, "timestep": 8437, "ep_reward": 243.59829711914062, "reward": 0.3686829209327698, "action": 1.143566608428955}
{"mode": "train", "epochs": 5, "timestep": 8438, "ep_reward": 243.8607940673828, "reward": 0.26249754428863525, "action": 1.2329999208450317}
{"mode": "train", "epochs": 5, "timestep": 8439, "ep_reward": 243.99716186523438, "reward": 0.13637322187423706, "action": 0.8753069639205933}
{"mode": "train", "epochs": 5, "timestep": 8440, "ep_reward": 243.9873504638672, "reward": -0.009814262390136719, "action": 1.016100287437439}
{"mode": "train", "epochs": 5, "timestep": 8441, "ep_reward": 244.111328125, "reward": 0.12397688627243042, "action": 0.4968390464782715}
{"mode": "train", "epochs": 5, "timestep": 8442, "ep_reward": 244.38040161132812, "reward": 0.26907986402511597, "action": 1.294624924659729}
{"mode": "train", "epochs": 5, "timestep": 8443, "ep_reward": 244.78280639648438, "reward": 0.4023992419242859, "action": 0.6543362140655518}
{"mode": "train", "epochs": 5, "timestep": 8444, "ep_reward": 245.3161163330078, "reward": 0.5333024263381958, "action": 0.8494235277175903}
{"mode": "train", "epochs": 5, "timestep": 8445, "ep_reward": 245.95892333984375, "reward": 0.6428070664405823, "action": 0.5743502378463745}
{"mode": "train", "epochs": 5, "timestep": 8446, "ep_reward": 246.6916046142578, "reward": 0.7326852083206177, "action": 0.841134250164032}
{"mode": "train", "epochs": 5, "timestep": 8447, "ep_reward": 247.48916625976562, "reward": 0.7975609302520752, "action": 1.2975668907165527}
{"mode": "train", "epochs": 5, "timestep": 8448, "ep_reward": 248.32815551757812, "reward": 0.8389835357666016, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8449, "ep_reward": 249.1864776611328, "reward": 0.8583243489265442, "action": 0.5751771926879883}
{"mode": "train", "epochs": 5, "timestep": 8450, "ep_reward": 250.06015014648438, "reward": 0.8736712336540222, "action": 0.9035513401031494}
{"mode": "train", "epochs": 5, "timestep": 8451, "ep_reward": 250.93080139160156, "reward": 0.870646595954895, "action": 0.8193281888961792}
{"mode": "train", "epochs": 5, "timestep": 8452, "ep_reward": 251.78236389160156, "reward": 0.8515664339065552, "action": 0.5513882637023926}
{"mode": "train", "epochs": 5, "timestep": 8453, "ep_reward": 252.59767150878906, "reward": 0.8153069615364075, "action": 0.34450340270996094}
{"mode": "train", "epochs": 5, "timestep": 8454, "ep_reward": 253.35498046875, "reward": 0.7573032975196838, "action": 1.3838053941726685}
{"mode": "train", "epochs": 5, "timestep": 8455, "ep_reward": 254.01214599609375, "reward": 0.6571699380874634, "action": 1.0026719570159912}
{"mode": "train", "epochs": 5, "timestep": 8456, "ep_reward": 254.5350341796875, "reward": 0.5228886008262634, "action": 0.5015445947647095}
{"mode": "train", "epochs": 5, "timestep": 8457, "ep_reward": 254.89395141601562, "reward": 0.3589165210723877, "action": 1.5521631240844727}
{"mode": "train", "epochs": 5, "timestep": 8458, "ep_reward": 255.144775390625, "reward": 0.25082969665527344, "action": 1.0531675815582275}
{"mode": "train", "epochs": 5, "timestep": 8459, "ep_reward": 255.2675018310547, "reward": 0.12272137403488159, "action": 0.4033392667770386}
{"mode": "train", "epochs": 5, "timestep": 8460, "ep_reward": 255.25892639160156, "reward": -0.008574724197387695, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8461, "ep_reward": 255.39657592773438, "reward": 0.13764601945877075, "action": 0.5293512344360352}
{"mode": "train", "epochs": 5, "timestep": 8462, "ep_reward": 255.67930603027344, "reward": 0.2827370762825012, "action": 0.8653451204299927}
{"mode": "train", "epochs": 5, "timestep": 8463, "ep_reward": 256.0998229980469, "reward": 0.4205177426338196, "action": 1.482999563217163}
{"mode": "train", "epochs": 5, "timestep": 8464, "ep_reward": 256.63934326171875, "reward": 0.5395141839981079, "action": 1.523356318473816}
{"mode": "train", "epochs": 5, "timestep": 8465, "ep_reward": 257.280029296875, "reward": 0.6406715512275696, "action": 1.8401811122894287}
{"mode": "train", "epochs": 5, "timestep": 8466, "ep_reward": 257.99786376953125, "reward": 0.717827558517456, "action": 0.45053040981292725}
{"mode": "train", "epochs": 5, "timestep": 8467, "ep_reward": 258.78460693359375, "reward": 0.7867490649223328, "action": 1.078476905822754}
{"mode": "train", "epochs": 5, "timestep": 8468, "ep_reward": 259.61273193359375, "reward": 0.828132152557373, "action": 0.488281786441803}
{"mode": "train", "epochs": 5, "timestep": 8469, "ep_reward": 260.4685363769531, "reward": 0.8558077812194824, "action": 1.293505072593689}
{"mode": "train", "epochs": 5, "timestep": 8470, "ep_reward": 261.3277282714844, "reward": 0.8591815233230591, "action": 1.021424651145935}
{"mode": "train", "epochs": 5, "timestep": 8471, "ep_reward": 262.1747741699219, "reward": 0.8470308780670166, "action": 1.5744963884353638}
{"mode": "train", "epochs": 5, "timestep": 8472, "ep_reward": 262.9837341308594, "reward": 0.8089688420295715, "action": 1.1321916580200195}
{"mode": "train", "epochs": 5, "timestep": 8473, "ep_reward": 263.7326354980469, "reward": 0.7489129304885864, "action": 0.5237694382667542}
{"mode": "train", "epochs": 5, "timestep": 8474, "ep_reward": 264.3963623046875, "reward": 0.6637325882911682, "action": 1.6664481163024902}
{"mode": "train", "epochs": 5, "timestep": 8475, "ep_reward": 264.9211120605469, "reward": 0.5247395038604736, "action": 1.3613513708114624}
{"mode": "train", "epochs": 5, "timestep": 8476, "ep_reward": 265.3005065917969, "reward": 0.379391074180603, "action": 0.5943964719772339}
{"mode": "train", "epochs": 5, "timestep": 8477, "ep_reward": 265.5759582519531, "reward": 0.275459885597229, "action": 0.5874384045600891}
{"mode": "train", "epochs": 5, "timestep": 8478, "ep_reward": 265.7274475097656, "reward": 0.15149033069610596, "action": 0.9809257388114929}
{"mode": "train", "epochs": 5, "timestep": 8479, "ep_reward": 265.7350158691406, "reward": 0.0075585246086120605, "action": 0.992716908454895}
{"mode": "train", "epochs": 5, "timestep": 8480, "ep_reward": 265.84332275390625, "reward": 0.10829800367355347, "action": 1.330916166305542}
{"mode": "train", "epochs": 5, "timestep": 8481, "ep_reward": 266.0859680175781, "reward": 0.24264782667160034, "action": 1.175858736038208}
{"mode": "train", "epochs": 5, "timestep": 8482, "ep_reward": 266.46600341796875, "reward": 0.38002973794937134, "action": 1.273762822151184}
{"mode": "train", "epochs": 5, "timestep": 8483, "ep_reward": 266.9731140136719, "reward": 0.5071148872375488, "action": 0.6292163133621216}
{"mode": "train", "epochs": 5, "timestep": 8484, "ep_reward": 267.59674072265625, "reward": 0.6236205101013184, "action": 1.7029590606689453}
{"mode": "train", "epochs": 5, "timestep": 8485, "ep_reward": 268.3023681640625, "reward": 0.7056401371955872, "action": 1.7553961277008057}
{"mode": "train", "epochs": 5, "timestep": 8486, "ep_reward": 269.0679016113281, "reward": 0.7655425667762756, "action": 0.9219663739204407}
{"mode": "train", "epochs": 5, "timestep": 8487, "ep_reward": 269.87982177734375, "reward": 0.8119109869003296, "action": 1.6777665615081787}
{"mode": "train", "epochs": 5, "timestep": 8488, "ep_reward": 270.7107849121094, "reward": 0.8309733867645264, "action": 0.23705387115478516}
{"mode": "train", "epochs": 5, "timestep": 8489, "ep_reward": 271.554443359375, "reward": 0.8436688780784607, "action": 1.2950481176376343}
{"mode": "train", "epochs": 5, "timestep": 8490, "ep_reward": 272.3809509277344, "reward": 0.8265000581741333, "action": 0.6315308809280396}
{"mode": "train", "epochs": 5, "timestep": 8491, "ep_reward": 273.1738586425781, "reward": 0.7929219603538513, "action": 1.1713751554489136}
{"mode": "train", "epochs": 5, "timestep": 8492, "ep_reward": 273.8999328613281, "reward": 0.7260870337486267, "action": 0.43133533000946045}
{"mode": "train", "epochs": 5, "timestep": 8493, "ep_reward": 274.53387451171875, "reward": 0.6339342594146729, "action": 0.8899379372596741}
{"mode": "train", "epochs": 5, "timestep": 8494, "ep_reward": 275.0303649902344, "reward": 0.4964783787727356, "action": 0.31869906187057495}
{"mode": "train", "epochs": 5, "timestep": 8495, "ep_reward": 275.39141845703125, "reward": 0.36106258630752563, "action": 1.02802312374115}
{"mode": "train", "epochs": 5, "timestep": 8496, "ep_reward": 275.644775390625, "reward": 0.253362238407135, "action": 0.5548356175422668}
{"mode": "train", "epochs": 5, "timestep": 8497, "ep_reward": 275.770263671875, "reward": 0.12547993659973145, "action": 1.575002908706665}
{"mode": "train", "epochs": 5, "timestep": 8498, "ep_reward": 275.7586364746094, "reward": -0.011614561080932617, "action": 0.2002364993095398}
{"mode": "train", "epochs": 5, "timestep": 8499, "ep_reward": 275.893310546875, "reward": 0.13467752933502197, "action": 1.3834900856018066}
{"mode": "train", "epochs": 5, "timestep": 8500, "ep_reward": 276.1623840332031, "reward": 0.2690882682800293, "action": 1.0890188217163086}
{"mode": "train", "epochs": 5, "timestep": 8501, "ep_reward": 276.5689697265625, "reward": 0.40658140182495117, "action": 0.9382651448249817}
{"mode": "train", "epochs": 5, "timestep": 8502, "ep_reward": 277.1033935546875, "reward": 0.5344371795654297, "action": 1.2032564878463745}
{"mode": "train", "epochs": 5, "timestep": 8503, "ep_reward": 277.743408203125, "reward": 0.6400076150894165, "action": 0.7828509211540222}
{"mode": "train", "epochs": 5, "timestep": 8504, "ep_reward": 278.4708251953125, "reward": 0.7274221181869507, "action": 0.7076976299285889}
{"mode": "train", "epochs": 5, "timestep": 8505, "ep_reward": 279.2630310058594, "reward": 0.7921918034553528, "action": 1.2466294765472412}
{"mode": "train", "epochs": 5, "timestep": 8506, "ep_reward": 280.0942687988281, "reward": 0.8312370181083679, "action": 1.4864144325256348}
{"mode": "train", "epochs": 5, "timestep": 8507, "ep_reward": 280.9443664550781, "reward": 0.8500850200653076, "action": 1.274305820465088}
{"mode": "train", "epochs": 5, "timestep": 8508, "ep_reward": 281.7976379394531, "reward": 0.8532769083976746, "action": 0.6447775363922119}
{"mode": "train", "epochs": 5, "timestep": 8509, "ep_reward": 282.6412658691406, "reward": 0.8436277508735657, "action": 1.1343464851379395}
{"mode": "train", "epochs": 5, "timestep": 8510, "ep_reward": 283.4499206542969, "reward": 0.8086565732955933, "action": 0.7331170439720154}
{"mode": "train", "epochs": 5, "timestep": 8511, "ep_reward": 284.2021179199219, "reward": 0.7521970272064209, "action": 0.22205233573913574}
{"mode": "train", "epochs": 5, "timestep": 8512, "ep_reward": 284.87322998046875, "reward": 0.6711081266403198, "action": 0.5787671804428101}
{"mode": "train", "epochs": 5, "timestep": 8513, "ep_reward": 285.4231262207031, "reward": 0.5498819351196289, "action": 0.6796650886535645}
{"mode": "train", "epochs": 5, "timestep": 8514, "ep_reward": 285.8103332519531, "reward": 0.38721930980682373, "action": 0.7322704195976257}
{"mode": "train", "epochs": 5, "timestep": 8515, "ep_reward": 286.0889587402344, "reward": 0.27862513065338135, "action": -0.3355642557144165}
{"mode": "train", "epochs": 5, "timestep": 8516, "ep_reward": 286.24420166015625, "reward": 0.15525424480438232, "action": -0.14526855945587158}
{"mode": "train", "epochs": 5, "timestep": 8517, "ep_reward": 286.2560729980469, "reward": 0.011866390705108643, "action": 0.45942986011505127}
{"mode": "train", "epochs": 5, "timestep": 8518, "ep_reward": 286.3605041503906, "reward": 0.10444563627243042, "action": 1.0444765090942383}
{"mode": "train", "epochs": 5, "timestep": 8519, "ep_reward": 286.60272216796875, "reward": 0.24220716953277588, "action": 1.4641454219818115}
{"mode": "train", "epochs": 5, "timestep": 8520, "ep_reward": 286.97821044921875, "reward": 0.37549257278442383, "action": 1.3384459018707275}
{"mode": "train", "epochs": 5, "timestep": 8521, "ep_reward": 287.4804382324219, "reward": 0.5022227764129639, "action": 1.2412049770355225}
{"mode": "train", "epochs": 5, "timestep": 8522, "ep_reward": 288.0933532714844, "reward": 0.6129100322723389, "action": 1.6287224292755127}
{"mode": "train", "epochs": 5, "timestep": 8523, "ep_reward": 288.79095458984375, "reward": 0.6975995302200317, "action": 0.6606037616729736}
{"mode": "train", "epochs": 5, "timestep": 8524, "ep_reward": 289.5600280761719, "reward": 0.7690712809562683, "action": 1.5247223377227783}
{"mode": "train", "epochs": 5, "timestep": 8525, "ep_reward": 290.3697814941406, "reward": 0.8097575902938843, "action": -0.018562912940979004}
{"mode": "train", "epochs": 5, "timestep": 8526, "ep_reward": 291.2142028808594, "reward": 0.8444228172302246, "action": -0.015475630760192871}
{"mode": "train", "epochs": 5, "timestep": 8527, "ep_reward": 292.07403564453125, "reward": 0.8598477840423584, "action": 0.6745669841766357}
{"mode": "train", "epochs": 5, "timestep": 8528, "ep_reward": 292.9253234863281, "reward": 0.8513027429580688, "action": 1.311500072479248}
{"mode": "train", "epochs": 5, "timestep": 8529, "ep_reward": 293.7423400878906, "reward": 0.8170219659805298, "action": 1.3283710479736328}
{"mode": "train", "epochs": 5, "timestep": 8530, "ep_reward": 294.49951171875, "reward": 0.7571694850921631, "action": 0.3448331356048584}
{"mode": "train", "epochs": 5, "timestep": 8531, "ep_reward": 295.1767272949219, "reward": 0.677219033241272, "action": 1.0188837051391602}
{"mode": "train", "epochs": 5, "timestep": 8532, "ep_reward": 295.7290344238281, "reward": 0.5522985458374023, "action": 0.8868635296821594}
{"mode": "train", "epochs": 5, "timestep": 8533, "ep_reward": 296.11663818359375, "reward": 0.3875976800918579, "action": 1.2285841703414917}
{"mode": "train", "epochs": 5, "timestep": 8534, "ep_reward": 296.4020690917969, "reward": 0.2854449152946472, "action": 1.2334599494934082}
{"mode": "train", "epochs": 5, "timestep": 8535, "ep_reward": 296.5653381347656, "reward": 0.16327893733978271, "action": 1.32405686378479}
{"mode": "train", "epochs": 5, "timestep": 8536, "ep_reward": 296.5865478515625, "reward": 0.021195948123931885, "action": 0.8178939819335938}
{"mode": "train", "epochs": 5, "timestep": 8537, "ep_reward": 296.6822204589844, "reward": 0.09566795825958252, "action": 1.7171694040298462}
{"mode": "train", "epochs": 5, "timestep": 8538, "ep_reward": 296.9099426269531, "reward": 0.22773021459579468, "action": 1.4250469207763672}
{"mode": "train", "epochs": 5, "timestep": 8539, "ep_reward": 297.2729187011719, "reward": 0.36296796798706055, "action": 0.34632885456085205}
{"mode": "train", "epochs": 5, "timestep": 8540, "ep_reward": 297.7759704589844, "reward": 0.5030508637428284, "action": 1.7055144309997559}
{"mode": "train", "epochs": 5, "timestep": 8541, "ep_reward": 298.3843688964844, "reward": 0.6083998680114746, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8542, "ep_reward": 299.0747375488281, "reward": 0.6903626918792725, "action": 0.3776063323020935}
{"mode": "train", "epochs": 5, "timestep": 8543, "ep_reward": 299.8410949707031, "reward": 0.7663652300834656, "action": 0.7581878900527954}
{"mode": "train", "epochs": 5, "timestep": 8544, "ep_reward": 300.6562194824219, "reward": 0.8151299357414246, "action": 0.43290817737579346}
{"mode": "train", "epochs": 5, "timestep": 8545, "ep_reward": 301.50250244140625, "reward": 0.846290111541748, "action": 1.603773832321167}
{"mode": "train", "epochs": 5, "timestep": 8546, "ep_reward": 302.3511657714844, "reward": 0.8486613631248474, "action": 1.0790306329727173}
{"mode": "train", "epochs": 5, "timestep": 8547, "ep_reward": 303.18792724609375, "reward": 0.8367596864700317, "action": 0.5789318084716797}
{"mode": "train", "epochs": 5, "timestep": 8548, "ep_reward": 303.9962158203125, "reward": 0.8082908391952515, "action": 1.0218806266784668}
{"mode": "train", "epochs": 5, "timestep": 8549, "ep_reward": 304.7459716796875, "reward": 0.7497551441192627, "action": 1.3740839958190918}
{"mode": "train", "epochs": 5, "timestep": 8550, "ep_reward": 305.4001770019531, "reward": 0.6542022228240967, "action": 0.6086956262588501}
{"mode": "train", "epochs": 5, "timestep": 8551, "ep_reward": 305.928955078125, "reward": 0.5287684202194214, "action": 1.1812573671340942}
{"mode": "train", "epochs": 5, "timestep": 8552, "ep_reward": 306.30877685546875, "reward": 0.37983542680740356, "action": 1.3423171043395996}
{"mode": "train", "epochs": 5, "timestep": 8553, "ep_reward": 306.5848083496094, "reward": 0.2760167717933655, "action": 1.3482269048690796}
{"mode": "train", "epochs": 5, "timestep": 8554, "ep_reward": 306.73712158203125, "reward": 0.15230423212051392, "action": 0.3825710415840149}
{"mode": "train", "epochs": 5, "timestep": 8555, "ep_reward": 306.74560546875, "reward": 0.008478105068206787, "action": 0.5479575395584106}
{"mode": "train", "epochs": 5, "timestep": 8556, "ep_reward": 306.8531188964844, "reward": 0.10751944780349731, "action": 1.1996779441833496}
{"mode": "train", "epochs": 5, "timestep": 8557, "ep_reward": 307.0966491699219, "reward": 0.24353140592575073, "action": 0.7979342937469482}
{"mode": "train", "epochs": 5, "timestep": 8558, "ep_reward": 307.4818115234375, "reward": 0.38514965772628784, "action": 1.6673790216445923}
{"mode": "train", "epochs": 5, "timestep": 8559, "ep_reward": 307.9883117675781, "reward": 0.5065021514892578, "action": 1.4503039121627808}
{"mode": "train", "epochs": 5, "timestep": 8560, "ep_reward": 308.6023864746094, "reward": 0.6140793561935425, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8561, "ep_reward": 309.2970275878906, "reward": 0.6946407556533813, "action": 1.04579496383667}
{"mode": "train", "epochs": 5, "timestep": 8562, "ep_reward": 310.0597229003906, "reward": 0.7626890540122986, "action": 0.7587969303131104}
{"mode": "train", "epochs": 5, "timestep": 8563, "ep_reward": 310.87030029296875, "reward": 0.8105695247650146, "action": 0.5521687865257263}
{"mode": "train", "epochs": 5, "timestep": 8564, "ep_reward": 311.70941162109375, "reward": 0.8391213417053223, "action": 1.8059478998184204}
{"mode": "train", "epochs": 5, "timestep": 8565, "ep_reward": 312.5462646484375, "reward": 0.8368483781814575, "action": 1.0353349447250366}
{"mode": "train", "epochs": 5, "timestep": 8566, "ep_reward": 313.3673095703125, "reward": 0.821053147315979, "action": 0.7352561354637146}
{"mode": "train", "epochs": 5, "timestep": 8567, "ep_reward": 314.1518859863281, "reward": 0.784564733505249, "action": 1.7338833808898926}
{"mode": "train", "epochs": 5, "timestep": 8568, "ep_reward": 314.8597106933594, "reward": 0.7078271508216858, "action": 1.3598434925079346}
{"mode": "train", "epochs": 5, "timestep": 8569, "ep_reward": 315.456787109375, "reward": 0.5970916152000427, "action": 1.0852625370025635}
{"mode": "train", "epochs": 5, "timestep": 8570, "ep_reward": 315.9024963378906, "reward": 0.4457007050514221, "action": 1.7220003604888916}
{"mode": "train", "epochs": 5, "timestep": 8571, "ep_reward": 316.24749755859375, "reward": 0.3449926972389221, "action": 0.03350859880447388}
{"mode": "train", "epochs": 5, "timestep": 8572, "ep_reward": 316.4814453125, "reward": 0.23393911123275757, "action": 0.9717161655426025}
{"mode": "train", "epochs": 5, "timestep": 8573, "ep_reward": 316.5844421386719, "reward": 0.10300278663635254, "action": 0.14624816179275513}
{"mode": "train", "epochs": 5, "timestep": 8574, "ep_reward": 316.59796142578125, "reward": 0.013506174087524414, "action": 0.5020970106124878}
{"mode": "train", "epochs": 5, "timestep": 8575, "ep_reward": 316.7546081542969, "reward": 0.15666157007217407, "action": 0.5950652360916138}
{"mode": "train", "epochs": 5, "timestep": 8576, "ep_reward": 317.0558776855469, "reward": 0.30127209424972534, "action": 1.456037163734436}
{"mode": "train", "epochs": 5, "timestep": 8577, "ep_reward": 317.4871826171875, "reward": 0.4313111901283264, "action": 1.0137180089950562}
{"mode": "train", "epochs": 5, "timestep": 8578, "ep_reward": 318.0421447753906, "reward": 0.5549525618553162, "action": 0.48269879817962646}
{"mode": "train", "epochs": 5, "timestep": 8579, "ep_reward": 318.7063293457031, "reward": 0.664171576499939, "action": 1.3615483045578003}
{"mode": "train", "epochs": 5, "timestep": 8580, "ep_reward": 319.447509765625, "reward": 0.7411803007125854, "action": 0.9729073643684387}
{"mode": "train", "epochs": 5, "timestep": 8581, "ep_reward": 320.2479248046875, "reward": 0.8004187941551208, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8582, "ep_reward": 321.0791931152344, "reward": 0.8312707543373108, "action": 0.06024998426437378}
{"mode": "train", "epochs": 5, "timestep": 8583, "ep_reward": 321.94036865234375, "reward": 0.8611809611320496, "action": 0.9157723188400269}
{"mode": "train", "epochs": 5, "timestep": 8584, "ep_reward": 322.80712890625, "reward": 0.8667657375335693, "action": 0.16866493225097656}
{"mode": "train", "epochs": 5, "timestep": 8585, "ep_reward": 323.669189453125, "reward": 0.8620495796203613, "action": 1.348995327949524}
{"mode": "train", "epochs": 5, "timestep": 8586, "ep_reward": 324.4975280761719, "reward": 0.8283416628837585, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8587, "ep_reward": 325.2610168457031, "reward": 0.7634819149971008, "action": 0.9884437918663025}
{"mode": "train", "epochs": 5, "timestep": 8588, "ep_reward": 325.93817138671875, "reward": 0.6771469116210938, "action": 1.2802246809005737}
{"mode": "train", "epochs": 5, "timestep": 8589, "ep_reward": 326.4869079589844, "reward": 0.5487506985664368, "action": 1.0126224756240845}
{"mode": "train", "epochs": 5, "timestep": 8590, "ep_reward": 326.87579345703125, "reward": 0.38887596130371094, "action": 1.117721438407898}
{"mode": "train", "epochs": 5, "timestep": 8591, "ep_reward": 327.1628112792969, "reward": 0.28702348470687866, "action": 0.9184890985488892}
{"mode": "train", "epochs": 5, "timestep": 8592, "ep_reward": 327.32794189453125, "reward": 0.1651320457458496, "action": 1.0364680290222168}
{"mode": "train", "epochs": 5, "timestep": 8593, "ep_reward": 327.35113525390625, "reward": 0.023195743560791016, "action": 1.4246246814727783}
{"mode": "train", "epochs": 5, "timestep": 8594, "ep_reward": 327.44488525390625, "reward": 0.0937618613243103, "action": 1.5017902851104736}
{"mode": "train", "epochs": 5, "timestep": 8595, "ep_reward": 327.67095947265625, "reward": 0.22606009244918823, "action": 1.3963024616241455}
{"mode": "train", "epochs": 5, "timestep": 8596, "ep_reward": 328.0326232910156, "reward": 0.3616533875465393, "action": 0.3683852553367615}
{"mode": "train", "epochs": 5, "timestep": 8597, "ep_reward": 328.5341491699219, "reward": 0.5015130639076233, "action": 1.8852124214172363}
{"mode": "train", "epochs": 5, "timestep": 8598, "ep_reward": 329.1394958496094, "reward": 0.605340838432312, "action": 0.8400872945785522}
{"mode": "train", "epochs": 5, "timestep": 8599, "ep_reward": 329.83935546875, "reward": 0.6998657584190369, "action": 0.1625041365623474}
{"mode": "train", "epochs": 5, "timestep": 8600, "ep_reward": 330.6160888671875, "reward": 0.7767208814620972, "action": 1.0540646314620972}
{"mode": "train", "epochs": 5, "timestep": 8601, "ep_reward": 331.4386291503906, "reward": 0.8225275278091431, "action": 1.305160403251648}
{"mode": "train", "epochs": 5, "timestep": 8602, "ep_reward": 332.2859802246094, "reward": 0.8473580479621887, "action": 0.4363722801208496}
{"mode": "train", "epochs": 5, "timestep": 8603, "ep_reward": 333.1481018066406, "reward": 0.8621344566345215, "action": 0.8956689238548279}
{"mode": "train", "epochs": 5, "timestep": 8604, "ep_reward": 334.0037841796875, "reward": 0.8556703925132751, "action": 0.3800060749053955}
{"mode": "train", "epochs": 5, "timestep": 8605, "ep_reward": 334.83905029296875, "reward": 0.835259199142456, "action": 0.6228152513504028}
{"mode": "train", "epochs": 5, "timestep": 8606, "ep_reward": 335.6300354003906, "reward": 0.7909761667251587, "action": 1.0546525716781616}
{"mode": "train", "epochs": 5, "timestep": 8607, "ep_reward": 336.34466552734375, "reward": 0.7146384119987488, "action": 1.2014305591583252}
{"mode": "train", "epochs": 5, "timestep": 8608, "ep_reward": 336.9456481933594, "reward": 0.6009875535964966, "action": 1.658923625946045}
{"mode": "train", "epochs": 5, "timestep": 8609, "ep_reward": 337.3838195800781, "reward": 0.43817657232284546, "action": 1.4167518615722656}
{"mode": "train", "epochs": 5, "timestep": 8610, "ep_reward": 337.70391845703125, "reward": 0.3200899362564087, "action": 1.9329688549041748}
{"mode": "train", "epochs": 5, "timestep": 8611, "ep_reward": 337.908447265625, "reward": 0.2045155167579651, "action": 0.8094881772994995}
{"mode": "train", "epochs": 5, "timestep": 8612, "ep_reward": 337.9771423339844, "reward": 0.0687066912651062, "action": 1.1552097797393799}
{"mode": "train", "epochs": 5, "timestep": 8613, "ep_reward": 338.0264587402344, "reward": 0.04932701587677002, "action": 1.667057991027832}
{"mode": "train", "epochs": 5, "timestep": 8614, "ep_reward": 338.2143249511719, "reward": 0.18786227703094482, "action": 0.6659116744995117}
{"mode": "train", "epochs": 5, "timestep": 8615, "ep_reward": 338.5465393066406, "reward": 0.33220523595809937, "action": 0.7168570756912231}
{"mode": "train", "epochs": 5, "timestep": 8616, "ep_reward": 339.01568603515625, "reward": 0.4691494107246399, "action": 1.5572376251220703}
{"mode": "train", "epochs": 5, "timestep": 8617, "ep_reward": 339.5969543457031, "reward": 0.581271231174469, "action": 1.0059679746627808}
{"mode": "train", "epochs": 5, "timestep": 8618, "ep_reward": 340.27679443359375, "reward": 0.6798421144485474, "action": 1.4433917999267578}
{"mode": "train", "epochs": 5, "timestep": 8619, "ep_reward": 341.0282287597656, "reward": 0.7514386177062988, "action": 1.823496699333191}
{"mode": "train", "epochs": 5, "timestep": 8620, "ep_reward": 341.8269348144531, "reward": 0.7987170219421387, "action": 0.5283983945846558}
{"mode": "train", "epochs": 5, "timestep": 8621, "ep_reward": 342.6649475097656, "reward": 0.8380149602890015, "action": 1.3907678127288818}
{"mode": "train", "epochs": 5, "timestep": 8622, "ep_reward": 343.51593017578125, "reward": 0.850970447063446, "action": 1.2733876705169678}
{"mode": "train", "epochs": 5, "timestep": 8623, "ep_reward": 344.36279296875, "reward": 0.8468592166900635, "action": 1.0977976322174072}
{"mode": "train", "epochs": 5, "timestep": 8624, "ep_reward": 345.18707275390625, "reward": 0.824280858039856, "action": 1.782848596572876}
{"mode": "train", "epochs": 5, "timestep": 8625, "ep_reward": 345.95758056640625, "reward": 0.7705135345458984, "action": 1.152662992477417}
{"mode": "train", "epochs": 5, "timestep": 8626, "ep_reward": 346.649658203125, "reward": 0.6920777559280396, "action": 0.06117779016494751}
{"mode": "train", "epochs": 5, "timestep": 8627, "ep_reward": 347.2407531738281, "reward": 0.5910884737968445, "action": 0.3407106399536133}
{"mode": "train", "epochs": 5, "timestep": 8628, "ep_reward": 347.6882019042969, "reward": 0.44745934009552, "action": 0.9125478863716125}
{"mode": "train", "epochs": 5, "timestep": 8629, "ep_reward": 348.0142822265625, "reward": 0.32607555389404297, "action": 0.8679500818252563}
{"mode": "train", "epochs": 5, "timestep": 8630, "ep_reward": 348.2256774902344, "reward": 0.21139919757843018, "action": 0.9696533679962158}
{"mode": "train", "epochs": 5, "timestep": 8631, "ep_reward": 348.3023376464844, "reward": 0.0766674280166626, "action": 1.4226139783859253}
{"mode": "train", "epochs": 5, "timestep": 8632, "ep_reward": 348.3435974121094, "reward": 0.04126185178756714, "action": 0.688742458820343}
{"mode": "train", "epochs": 5, "timestep": 8633, "ep_reward": 348.525146484375, "reward": 0.18156194686889648, "action": 1.0017971992492676}
{"mode": "train", "epochs": 5, "timestep": 8634, "ep_reward": 348.84649658203125, "reward": 0.3213590383529663, "action": 1.6623083353042603}
{"mode": "train", "epochs": 5, "timestep": 8635, "ep_reward": 349.294921875, "reward": 0.4484107494354248, "action": 0.4828163981437683}
{"mode": "train", "epochs": 5, "timestep": 8636, "ep_reward": 349.8709411621094, "reward": 0.5760184526443481, "action": 1.3510735034942627}
{"mode": "train", "epochs": 5, "timestep": 8637, "ep_reward": 350.5430603027344, "reward": 0.6721326112747192, "action": 0.5485113859176636}
{"mode": "train", "epochs": 5, "timestep": 8638, "ep_reward": 351.29681396484375, "reward": 0.753746747970581, "action": 0.9660747647285461}
{"mode": "train", "epochs": 5, "timestep": 8639, "ep_reward": 352.1054992675781, "reward": 0.8086968064308167, "action": 0.10470551252365112}
{"mode": "train", "epochs": 5, "timestep": 8640, "ep_reward": 352.956787109375, "reward": 0.8512911200523376, "action": 0.5991557836532593}
{"mode": "train", "epochs": 5, "timestep": 8641, "ep_reward": 353.82879638671875, "reward": 0.8720220327377319, "action": 0.8163185119628906}
{"mode": "train", "epochs": 5, "timestep": 8642, "ep_reward": 354.7042236328125, "reward": 0.8754193186759949, "action": 0.7130467891693115}
{"mode": "train", "epochs": 5, "timestep": 8643, "ep_reward": 355.5679931640625, "reward": 0.8637755513191223, "action": 1.2422807216644287}
{"mode": "train", "epochs": 5, "timestep": 8644, "ep_reward": 356.3970031738281, "reward": 0.828995943069458, "action": 1.727371335029602}
{"mode": "train", "epochs": 5, "timestep": 8645, "ep_reward": 357.16192626953125, "reward": 0.7649083137512207, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8646, "ep_reward": 357.8260498046875, "reward": 0.6641201972961426, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8647, "ep_reward": 358.3463134765625, "reward": 0.5202772617340088, "action": 1.0480241775512695}
{"mode": "train", "epochs": 5, "timestep": 8648, "ep_reward": 358.72509765625, "reward": 0.37878942489624023, "action": 0.5634921789169312}
{"mode": "train", "epochs": 5, "timestep": 8649, "ep_reward": 358.99981689453125, "reward": 0.27472084760665894, "action": 0.6731669902801514}
{"mode": "train", "epochs": 5, "timestep": 8650, "ep_reward": 359.15032958984375, "reward": 0.15050983428955078, "action": 1.6961755752563477}
{"mode": "train", "epochs": 5, "timestep": 8651, "ep_reward": 359.15679931640625, "reward": 0.006479501724243164, "action": 1.5558521747589111}
{"mode": "train", "epochs": 5, "timestep": 8652, "ep_reward": 359.2660827636719, "reward": 0.10929238796234131, "action": 0.5183187127113342}
{"mode": "train", "epochs": 5, "timestep": 8653, "ep_reward": 359.5198669433594, "reward": 0.25378984212875366, "action": 0.9225941896438599}
{"mode": "train", "epochs": 5, "timestep": 8654, "ep_reward": 359.91204833984375, "reward": 0.39219385385513306, "action": 0.8996294736862183}
{"mode": "train", "epochs": 5, "timestep": 8655, "ep_reward": 360.4330749511719, "reward": 0.5210225582122803, "action": 1.2296420335769653}
{"mode": "train", "epochs": 5, "timestep": 8656, "ep_reward": 361.0614929199219, "reward": 0.6284133195877075, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8657, "ep_reward": 361.7687683105469, "reward": 0.707290530204773, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8658, "ep_reward": 362.5347900390625, "reward": 0.7660123109817505, "action": 0.7586163282394409}
{"mode": "train", "epochs": 5, "timestep": 8659, "ep_reward": 363.3506774902344, "reward": 0.8158861994743347, "action": 0.1623765230178833}
{"mode": "train", "epochs": 5, "timestep": 8660, "ep_reward": 364.2013854980469, "reward": 0.8507223129272461, "action": 1.4956830739974976}
{"mode": "train", "epochs": 5, "timestep": 8661, "ep_reward": 365.0574035644531, "reward": 0.8560305833816528, "action": 0.6702691912651062}
{"mode": "train", "epochs": 5, "timestep": 8662, "ep_reward": 365.90814208984375, "reward": 0.8507372140884399, "action": 1.2061907052993774}
{"mode": "train", "epochs": 5, "timestep": 8663, "ep_reward": 366.728759765625, "reward": 0.8206273913383484, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8664, "ep_reward": 367.4858093261719, "reward": 0.7570643424987793, "action": 1.4456119537353516}
{"mode": "train", "epochs": 5, "timestep": 8665, "ep_reward": 368.15142822265625, "reward": 0.6656208038330078, "action": 1.3893892765045166}
{"mode": "train", "epochs": 5, "timestep": 8666, "ep_reward": 368.68524169921875, "reward": 0.5338044166564941, "action": 1.58382248878479}
{"mode": "train", "epochs": 5, "timestep": 8667, "ep_reward": 369.0771179199219, "reward": 0.39186185598373413, "action": 1.3730124235153198}
{"mode": "train", "epochs": 5, "timestep": 8668, "ep_reward": 369.36785888671875, "reward": 0.2907290458679199, "action": 0.7357000112533569}
{"mode": "train", "epochs": 5, "timestep": 8669, "ep_reward": 369.5373229980469, "reward": 0.16947394609451294, "action": 1.0792553424835205}
{"mode": "train", "epochs": 5, "timestep": 8670, "ep_reward": 369.5655822753906, "reward": 0.02825760841369629, "action": 1.084848403930664}
{"mode": "train", "epochs": 5, "timestep": 8671, "ep_reward": 369.6547546386719, "reward": 0.0891650915145874, "action": 0.6249285340309143}
{"mode": "train", "epochs": 5, "timestep": 8672, "ep_reward": 369.8865661621094, "reward": 0.231803297996521, "action": 0.5670479536056519}
{"mode": "train", "epochs": 5, "timestep": 8673, "ep_reward": 370.2618713378906, "reward": 0.3753182888031006, "action": 1.9512364864349365}
{"mode": "train", "epochs": 5, "timestep": 8674, "ep_reward": 370.7553405761719, "reward": 0.49345457553863525, "action": 1.846816897392273}
{"mode": "train", "epochs": 5, "timestep": 8675, "ep_reward": 371.3543395996094, "reward": 0.598990797996521, "action": -0.6391100883483887}
{"mode": "train", "epochs": 5, "timestep": 8676, "ep_reward": 372.0643615722656, "reward": 0.7100257873535156, "action": 1.0009055137634277}
{"mode": "train", "epochs": 5, "timestep": 8677, "ep_reward": 372.8431396484375, "reward": 0.7787836194038391, "action": 0.3872091770172119}
{"mode": "train", "epochs": 5, "timestep": 8678, "ep_reward": 373.67535400390625, "reward": 0.832215428352356, "action": 0.43304044008255005}
{"mode": "train", "epochs": 5, "timestep": 8679, "ep_reward": 374.5418395996094, "reward": 0.8664735555648804, "action": 1.509148359298706}
{"mode": "train", "epochs": 5, "timestep": 8680, "ep_reward": 375.4184875488281, "reward": 0.8766629695892334, "action": 0.36500173807144165}
{"mode": "train", "epochs": 5, "timestep": 8681, "ep_reward": 376.2997741699219, "reward": 0.8812932968139648, "action": 0.12688708305358887}
{"mode": "train", "epochs": 5, "timestep": 8682, "ep_reward": 377.1726379394531, "reward": 0.8728591203689575, "action": 0.9390283823013306}
{"mode": "train", "epochs": 5, "timestep": 8683, "ep_reward": 378.0133972167969, "reward": 0.8407495021820068, "action": 0.7212604284286499}
{"mode": "train", "epochs": 5, "timestep": 8684, "ep_reward": 378.80255126953125, "reward": 0.7891451120376587, "action": 0.2984301447868347}
{"mode": "train", "epochs": 5, "timestep": 8685, "ep_reward": 379.517822265625, "reward": 0.7152825593948364, "action": 1.8572344779968262}
{"mode": "train", "epochs": 5, "timestep": 8686, "ep_reward": 380.1065673828125, "reward": 0.5887546539306641, "action": 1.9897785186767578}
{"mode": "train", "epochs": 5, "timestep": 8687, "ep_reward": 380.5223388671875, "reward": 0.41577500104904175, "action": 1.3069047927856445}
{"mode": "train", "epochs": 5, "timestep": 8688, "ep_reward": 380.8186340332031, "reward": 0.2962864637374878, "action": 0.9726283550262451}
{"mode": "train", "epochs": 5, "timestep": 8689, "ep_reward": 380.9947509765625, "reward": 0.1761035919189453, "action": 0.7410702705383301}
{"mode": "train", "epochs": 5, "timestep": 8690, "ep_reward": 381.0306396484375, "reward": 0.03589034080505371, "action": 0.8040167093276978}
{"mode": "train", "epochs": 5, "timestep": 8691, "ep_reward": 381.112548828125, "reward": 0.08192157745361328, "action": 0.7462818622589111}
{"mode": "train", "epochs": 5, "timestep": 8692, "ep_reward": 381.3352966308594, "reward": 0.22275513410568237, "action": 1.2612667083740234}
{"mode": "train", "epochs": 5, "timestep": 8693, "ep_reward": 381.6936950683594, "reward": 0.3583914041519165, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8694, "ep_reward": 382.172119140625, "reward": 0.47843557596206665, "action": 1.6050472259521484}
{"mode": "train", "epochs": 5, "timestep": 8695, "ep_reward": 382.7611999511719, "reward": 0.5890952944755554, "action": 0.8396867513656616}
{"mode": "train", "epochs": 5, "timestep": 8696, "ep_reward": 383.4478759765625, "reward": 0.6866720914840698, "action": 1.7930548191070557}
{"mode": "train", "epochs": 5, "timestep": 8697, "ep_reward": 384.1983642578125, "reward": 0.7504948377609253, "action": 0.6875936985015869}
{"mode": "train", "epochs": 5, "timestep": 8698, "ep_reward": 385.0012512207031, "reward": 0.802882969379425, "action": 0.7295334339141846}
{"mode": "train", "epochs": 5, "timestep": 8699, "ep_reward": 385.8343200683594, "reward": 0.8330715894699097, "action": 1.6526942253112793}
{"mode": "train", "epochs": 5, "timestep": 8700, "ep_reward": 386.669189453125, "reward": 0.8348775506019592, "action": 1.5734734535217285}
{"mode": "train", "epochs": 5, "timestep": 8701, "ep_reward": 387.485595703125, "reward": 0.8164011240005493, "action": 1.002640724182129}
{"mode": "train", "epochs": 5, "timestep": 8702, "ep_reward": 388.2647399902344, "reward": 0.7791357040405273, "action": 0.88613361120224}
{"mode": "train", "epochs": 5, "timestep": 8703, "ep_reward": 388.9784851074219, "reward": 0.7137593030929565, "action": 1.7118446826934814}
{"mode": "train", "epochs": 5, "timestep": 8704, "ep_reward": 389.5796813964844, "reward": 0.6011998653411865, "action": 0.9576424360275269}
{"mode": "train", "epochs": 5, "timestep": 8705, "ep_reward": 390.0337829589844, "reward": 0.454115092754364, "action": 0.789330780506134}
{"mode": "train", "epochs": 5, "timestep": 8706, "ep_reward": 390.3857421875, "reward": 0.3519687056541443, "action": 1.1214170455932617}
{"mode": "train", "epochs": 5, "timestep": 8707, "ep_reward": 390.628173828125, "reward": 0.24243569374084473, "action": 0.6157524585723877}
{"mode": "train", "epochs": 5, "timestep": 8708, "ep_reward": 390.74090576171875, "reward": 0.11272811889648438, "action": 1.5181233882904053}
{"mode": "train", "epochs": 5, "timestep": 8709, "ep_reward": 390.7435607910156, "reward": 0.0026673078536987305, "action": 0.7120808362960815}
{"mode": "train", "epochs": 5, "timestep": 8710, "ep_reward": 390.89080810546875, "reward": 0.14724582433700562, "action": 0.588650107383728}
{"mode": "train", "epochs": 5, "timestep": 8711, "ep_reward": 391.18267822265625, "reward": 0.2918582558631897, "action": 0.4322078227996826}
{"mode": "train", "epochs": 5, "timestep": 8712, "ep_reward": 391.6171875, "reward": 0.434501588344574, "action": 0.9258245229721069}
{"mode": "train", "epochs": 5, "timestep": 8713, "ep_reward": 392.1747741699219, "reward": 0.5575960874557495, "action": 1.949296236038208}
{"mode": "train", "epochs": 5, "timestep": 8714, "ep_reward": 392.82611083984375, "reward": 0.65134197473526, "action": 1.282071828842163}
{"mode": "train", "epochs": 5, "timestep": 8715, "ep_reward": 393.5581970214844, "reward": 0.7320762872695923, "action": 0.6235342025756836}
{"mode": "train", "epochs": 5, "timestep": 8716, "ep_reward": 394.3553771972656, "reward": 0.7971842288970947, "action": 1.2386037111282349}
{"mode": "train", "epochs": 5, "timestep": 8717, "ep_reward": 395.19195556640625, "reward": 0.8365733027458191, "action": 0.006692230701446533}
{"mode": "train", "epochs": 5, "timestep": 8718, "ep_reward": 396.060546875, "reward": 0.8685906529426575, "action": 1.202262282371521}
{"mode": "train", "epochs": 5, "timestep": 8719, "ep_reward": 396.9352111816406, "reward": 0.8746601343154907, "action": 1.519629716873169}
{"mode": "train", "epochs": 5, "timestep": 8720, "ep_reward": 397.79754638671875, "reward": 0.8623470067977905, "action": 0.5531305074691772}
{"mode": "train", "epochs": 5, "timestep": 8721, "ep_reward": 398.6378479003906, "reward": 0.8402947187423706, "action": 1.2103549242019653}
{"mode": "train", "epochs": 5, "timestep": 8722, "ep_reward": 399.4283142089844, "reward": 0.7904758453369141, "action": 0.7331432104110718}
{"mode": "train", "epochs": 5, "timestep": 8723, "ep_reward": 400.1459655761719, "reward": 0.7176550030708313, "action": 1.5618257522583008}
{"mode": "train", "epochs": 5, "timestep": 8724, "ep_reward": 400.7458801269531, "reward": 0.5999221801757812, "action": 0.5376025438308716}
{"mode": "train", "epochs": 5, "timestep": 8725, "ep_reward": 401.20050048828125, "reward": 0.45463359355926514, "action": 1.196994662284851}
{"mode": "train", "epochs": 5, "timestep": 8726, "ep_reward": 401.52252197265625, "reward": 0.3220288157463074, "action": 1.006811261177063}
{"mode": "train", "epochs": 5, "timestep": 8727, "ep_reward": 401.72918701171875, "reward": 0.20665687322616577, "action": 0.22841155529022217}
{"mode": "train", "epochs": 5, "timestep": 8728, "ep_reward": 401.8003845214844, "reward": 0.07118993997573853, "action": 0.7876935601234436}
{"mode": "train", "epochs": 5, "timestep": 8729, "ep_reward": 401.8472595214844, "reward": 0.046885550022125244, "action": 1.4249005317687988}
{"mode": "train", "epochs": 5, "timestep": 8730, "ep_reward": 402.0329284667969, "reward": 0.185660719871521, "action": 1.1031296253204346}
{"mode": "train", "epochs": 5, "timestep": 8731, "ep_reward": 402.3575134277344, "reward": 0.3245975971221924, "action": 0.5185798406600952}
{"mode": "train", "epochs": 5, "timestep": 8732, "ep_reward": 402.8227844238281, "reward": 0.4652658700942993, "action": 0.7864780426025391}
{"mode": "train", "epochs": 5, "timestep": 8733, "ep_reward": 403.4092712402344, "reward": 0.586482048034668, "action": 1.2842381000518799}
{"mode": "train", "epochs": 5, "timestep": 8734, "ep_reward": 404.0907287597656, "reward": 0.6814541816711426, "action": 0.6840320825576782}
{"mode": "train", "epochs": 5, "timestep": 8735, "ep_reward": 404.8510437011719, "reward": 0.7603020071983337, "action": 0.8030143976211548}
{"mode": "train", "epochs": 5, "timestep": 8736, "ep_reward": 405.6671142578125, "reward": 0.8160563707351685, "action": 1.2468273639678955}
{"mode": "train", "epochs": 5, "timestep": 8737, "ep_reward": 406.5161437988281, "reward": 0.8490333557128906, "action": 1.5670790672302246}
{"mode": "train", "epochs": 5, "timestep": 8738, "ep_reward": 407.37890625, "reward": 0.8627668619155884, "action": 1.6180517673492432}
{"mode": "train", "epochs": 5, "timestep": 8739, "ep_reward": 408.2386169433594, "reward": 0.8597226738929749, "action": 1.1965241432189941}
{"mode": "train", "epochs": 5, "timestep": 8740, "ep_reward": 409.0808410644531, "reward": 0.8422259092330933, "action": 1.0587642192840576}
{"mode": "train", "epochs": 5, "timestep": 8741, "ep_reward": 409.88555908203125, "reward": 0.8047282695770264, "action": 0.9324697256088257}
{"mode": "train", "epochs": 5, "timestep": 8742, "ep_reward": 410.62774658203125, "reward": 0.7421847581863403, "action": 1.2472963333129883}
{"mode": "train", "epochs": 5, "timestep": 8743, "ep_reward": 411.2705078125, "reward": 0.6427692770957947, "action": 0.5916076898574829}
{"mode": "train", "epochs": 5, "timestep": 8744, "ep_reward": 411.7828063964844, "reward": 0.5122838020324707, "action": 0.5783921480178833}
{"mode": "train", "epochs": 5, "timestep": 8745, "ep_reward": 412.1475524902344, "reward": 0.3647441267967224, "action": 0.1967601180076599}
{"mode": "train", "epochs": 5, "timestep": 8746, "ep_reward": 412.4052429199219, "reward": 0.2576819062232971, "action": 0.9847903847694397}
{"mode": "train", "epochs": 5, "timestep": 8747, "ep_reward": 412.53594970703125, "reward": 0.13069862127304077, "action": 0.8047623634338379}
{"mode": "train", "epochs": 5, "timestep": 8748, "ep_reward": 412.5196228027344, "reward": -0.016315460205078125, "action": 0.9088575839996338}
{"mode": "train", "epochs": 5, "timestep": 8749, "ep_reward": 412.6493225097656, "reward": 0.12970829010009766, "action": 0.33028340339660645}
{"mode": "train", "epochs": 5, "timestep": 8750, "ep_reward": 412.9263610839844, "reward": 0.277046263217926, "action": 0.9992076754570007}
{"mode": "train", "epochs": 5, "timestep": 8751, "ep_reward": 413.33953857421875, "reward": 0.4131826162338257, "action": 0.9900903701782227}
{"mode": "train", "epochs": 5, "timestep": 8752, "ep_reward": 413.8780822753906, "reward": 0.5385416150093079, "action": 1.1459980010986328}
{"mode": "train", "epochs": 5, "timestep": 8753, "ep_reward": 414.5220947265625, "reward": 0.6440141201019287, "action": 0.6887544393539429}
{"mode": "train", "epochs": 5, "timestep": 8754, "ep_reward": 415.2544860839844, "reward": 0.7323876619338989, "action": 1.316253662109375}
{"mode": "train", "epochs": 5, "timestep": 8755, "ep_reward": 416.0473937988281, "reward": 0.7929177284240723, "action": 0.4771130681037903}
{"mode": "train", "epochs": 5, "timestep": 8756, "ep_reward": 416.8887023925781, "reward": 0.8413166999816895, "action": 0.4812586307525635}
{"mode": "train", "epochs": 5, "timestep": 8757, "ep_reward": 417.7605895996094, "reward": 0.8718782067298889, "action": 0.7715325355529785}
{"mode": "train", "epochs": 5, "timestep": 8758, "ep_reward": 418.6455383300781, "reward": 0.8849545121192932, "action": 0.9326902031898499}
{"mode": "train", "epochs": 5, "timestep": 8759, "ep_reward": 419.5281677246094, "reward": 0.8826322555541992, "action": 0.1722903847694397}
{"mode": "train", "epochs": 5, "timestep": 8760, "ep_reward": 420.3997497558594, "reward": 0.871569037437439, "action": 0.27009809017181396}
{"mode": "train", "epochs": 5, "timestep": 8761, "ep_reward": 421.24267578125, "reward": 0.8429399728775024, "action": 1.9708898067474365}
{"mode": "train", "epochs": 5, "timestep": 8762, "ep_reward": 422.0191955566406, "reward": 0.7765292525291443, "action": 1.5597920417785645}
{"mode": "train", "epochs": 5, "timestep": 8763, "ep_reward": 422.7016906738281, "reward": 0.682502269744873, "action": 0.9983160495758057}
{"mode": "train", "epochs": 5, "timestep": 8764, "ep_reward": 423.2590026855469, "reward": 0.5572971105575562, "action": 1.4765212535858154}
{"mode": "train", "epochs": 5, "timestep": 8765, "ep_reward": 423.642333984375, "reward": 0.38333356380462646, "action": 0.7931033372879028}
{"mode": "train", "epochs": 5, "timestep": 8766, "ep_reward": 423.91802978515625, "reward": 0.2756958603858948, "action": 1.4754444360733032}
{"mode": "train", "epochs": 5, "timestep": 8767, "ep_reward": 424.0697326660156, "reward": 0.1517125368118286, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8768, "ep_reward": 424.07763671875, "reward": 0.00789332389831543, "action": 1.7900973558425903}
{"mode": "train", "epochs": 5, "timestep": 8769, "ep_reward": 424.18560791015625, "reward": 0.10796135663986206, "action": 0.5026834011077881}
{"mode": "train", "epochs": 5, "timestep": 8770, "ep_reward": 424.43804931640625, "reward": 0.2524566054344177, "action": 1.8590290546417236}
{"mode": "train", "epochs": 5, "timestep": 8771, "ep_reward": 424.81768798828125, "reward": 0.37963616847991943, "action": 0.15786278247833252}
{"mode": "train", "epochs": 5, "timestep": 8772, "ep_reward": 425.3371887207031, "reward": 0.5194981098175049, "action": 0.21209388971328735}
{"mode": "train", "epochs": 5, "timestep": 8773, "ep_reward": 425.97515869140625, "reward": 0.6379749178886414, "action": 1.4999644756317139}
{"mode": "train", "epochs": 5, "timestep": 8774, "ep_reward": 426.695556640625, "reward": 0.7204036712646484, "action": 0.9714637398719788}
{"mode": "train", "epochs": 5, "timestep": 8775, "ep_reward": 427.48248291015625, "reward": 0.7869393229484558, "action": 1.748538851737976}
{"mode": "train", "epochs": 5, "timestep": 8776, "ep_reward": 428.309326171875, "reward": 0.8268543481826782, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8777, "ep_reward": 429.1568603515625, "reward": 0.8475325703620911, "action": 1.3790414333343506}
{"mode": "train", "epochs": 5, "timestep": 8778, "ep_reward": 430.0135192871094, "reward": 0.856653094291687, "action": 0.8326190710067749}
{"mode": "train", "epochs": 5, "timestep": 8779, "ep_reward": 430.86651611328125, "reward": 0.8529993295669556, "action": 0.38123035430908203}
{"mode": "train", "epochs": 5, "timestep": 8780, "ep_reward": 431.7009582519531, "reward": 0.8344288468360901, "action": 1.8429893255233765}
{"mode": "train", "epochs": 5, "timestep": 8781, "ep_reward": 432.4800109863281, "reward": 0.7790613770484924, "action": 0.8901517391204834}
{"mode": "train", "epochs": 5, "timestep": 8782, "ep_reward": 433.1834716796875, "reward": 0.703468382358551, "action": 1.4536443948745728}
{"mode": "train", "epochs": 5, "timestep": 8783, "ep_reward": 433.767578125, "reward": 0.5841166973114014, "action": 1.330835223197937}
{"mode": "train", "epochs": 5, "timestep": 8784, "ep_reward": 434.1898193359375, "reward": 0.4222472906112671, "action": 0.5728092193603516}
{"mode": "train", "epochs": 5, "timestep": 8785, "ep_reward": 434.5080871582031, "reward": 0.3182806372642517, "action": 0.3580061197280884}
{"mode": "train", "epochs": 5, "timestep": 8786, "ep_reward": 434.7102355957031, "reward": 0.20213693380355835, "action": 0.10035717487335205}
{"mode": "train", "epochs": 5, "timestep": 8787, "ep_reward": 434.776123046875, "reward": 0.06588321924209595, "action": 1.2893407344818115}
{"mode": "train", "epochs": 5, "timestep": 8788, "ep_reward": 434.8283386230469, "reward": 0.052224040031433105, "action": 1.4002983570098877}
{"mode": "train", "epochs": 5, "timestep": 8789, "ep_reward": 435.0186767578125, "reward": 0.1903415322303772, "action": 0.40648818016052246}
{"mode": "train", "epochs": 5, "timestep": 8790, "ep_reward": 435.3565673828125, "reward": 0.3378946781158447, "action": 0.7106759548187256}
{"mode": "train", "epochs": 5, "timestep": 8791, "ep_reward": 435.8307800292969, "reward": 0.47420167922973633, "action": 0.6602572202682495}
{"mode": "train", "epochs": 5, "timestep": 8792, "ep_reward": 436.426025390625, "reward": 0.5952535271644592, "action": -0.25422751903533936}
{"mode": "train", "epochs": 5, "timestep": 8793, "ep_reward": 437.1297302246094, "reward": 0.7037195563316345, "action": 0.7672068476676941}
{"mode": "train", "epochs": 5, "timestep": 8794, "ep_reward": 437.9079895019531, "reward": 0.7782605886459351, "action": 0.5200390815734863}
{"mode": "train", "epochs": 5, "timestep": 8795, "ep_reward": 438.7427673339844, "reward": 0.8347843289375305, "action": 0.8264949321746826}
{"mode": "train", "epochs": 5, "timestep": 8796, "ep_reward": 439.6143798828125, "reward": 0.8716229796409607, "action": 0.627711296081543}
{"mode": "train", "epochs": 5, "timestep": 8797, "ep_reward": 440.5100402832031, "reward": 0.8956573009490967, "action": 1.2074283361434937}
{"mode": "train", "epochs": 5, "timestep": 8798, "ep_reward": 441.4132080078125, "reward": 0.9031581282615662, "action": 1.88053297996521}
{"mode": "train", "epochs": 5, "timestep": 8799, "ep_reward": 442.3070068359375, "reward": 0.8938049077987671, "action": 1.3193690776824951}
{"mode": "train", "epochs": 5, "timestep": 8800, "ep_reward": 443.181396484375, "reward": 0.8743962049484253, "action": 0.5059224367141724}
{"mode": "train", "epochs": 5, "timestep": 8801, "ep_reward": 444.026123046875, "reward": 0.8447219729423523, "action": 1.0686668157577515}
{"mode": "train", "epochs": 5, "timestep": 8802, "ep_reward": 444.8149108886719, "reward": 0.7887787818908691, "action": 1.4931755065917969}
{"mode": "train", "epochs": 5, "timestep": 8803, "ep_reward": 445.514404296875, "reward": 0.6994891166687012, "action": 1.700052261352539}
{"mode": "train", "epochs": 5, "timestep": 8804, "ep_reward": 446.0842590332031, "reward": 0.5698645114898682, "action": 1.2101447582244873}
{"mode": "train", "epochs": 5, "timestep": 8805, "ep_reward": 446.48822021484375, "reward": 0.40394872426986694, "action": 0.30302953720092773}
{"mode": "train", "epochs": 5, "timestep": 8806, "ep_reward": 446.7743225097656, "reward": 0.2860959768295288, "action": 0.729816198348999}
{"mode": "train", "epochs": 5, "timestep": 8807, "ep_reward": 446.9383850097656, "reward": 0.16404736042022705, "action": 0.7552862167358398}
{"mode": "train", "epochs": 5, "timestep": 8808, "ep_reward": 446.9603576660156, "reward": 0.0219842791557312, "action": 0.9205856323242188}
{"mode": "train", "epochs": 5, "timestep": 8809, "ep_reward": 447.0554504394531, "reward": 0.09508460760116577, "action": 0.5771937370300293}
{"mode": "train", "epochs": 5, "timestep": 8810, "ep_reward": 447.2939453125, "reward": 0.23849862813949585, "action": 0.4197586178779602}
{"mode": "train", "epochs": 5, "timestep": 8811, "ep_reward": 447.6774597167969, "reward": 0.38350534439086914, "action": 1.6390326023101807}
{"mode": "train", "epochs": 5, "timestep": 8812, "ep_reward": 448.1817932128906, "reward": 0.5043448209762573, "action": 1.220124363899231}
{"mode": "train", "epochs": 5, "timestep": 8813, "ep_reward": 448.7966613769531, "reward": 0.6148682832717896, "action": 0.6555346250534058}
{"mode": "train", "epochs": 5, "timestep": 8814, "ep_reward": 449.5066833496094, "reward": 0.7100224494934082, "action": 0.43082118034362793}
{"mode": "train", "epochs": 5, "timestep": 8815, "ep_reward": 450.2906494140625, "reward": 0.7839704751968384, "action": 0.6635037660598755}
{"mode": "train", "epochs": 5, "timestep": 8816, "ep_reward": 451.125, "reward": 0.8343502879142761, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8817, "ep_reward": 451.9814147949219, "reward": 0.8564015030860901, "action": 0.8251535296440125}
{"mode": "train", "epochs": 5, "timestep": 8818, "ep_reward": 452.85382080078125, "reward": 0.8724059462547302, "action": 1.2644436359405518}
{"mode": "train", "epochs": 5, "timestep": 8819, "ep_reward": 453.7230224609375, "reward": 0.8691918849945068, "action": 0.8921015858650208}
{"mode": "train", "epochs": 5, "timestep": 8820, "ep_reward": 454.5751647949219, "reward": 0.8521523475646973, "action": 1.3121693134307861}
{"mode": "train", "epochs": 5, "timestep": 8821, "ep_reward": 455.3863525390625, "reward": 0.8111736178398132, "action": 0.04896235466003418}
{"mode": "train", "epochs": 5, "timestep": 8822, "ep_reward": 456.1445007324219, "reward": 0.7581356763839722, "action": 0.9687361121177673}
{"mode": "train", "epochs": 5, "timestep": 8823, "ep_reward": 456.8096923828125, "reward": 0.6652040481567383, "action": 1.2964205741882324}
{"mode": "train", "epochs": 5, "timestep": 8824, "ep_reward": 457.3395080566406, "reward": 0.5298271179199219, "action": 0.27528661489486694}
{"mode": "train", "epochs": 5, "timestep": 8825, "ep_reward": 457.7078857421875, "reward": 0.3683778643608093, "action": 0.7020293474197388}
{"mode": "train", "epochs": 5, "timestep": 8826, "ep_reward": 457.96868896484375, "reward": 0.26079708337783813, "action": 1.0826293230056763}
{"mode": "train", "epochs": 5, "timestep": 8827, "ep_reward": 458.10308837890625, "reward": 0.13439440727233887, "action": 0.3651565909385681}
{"mode": "train", "epochs": 5, "timestep": 8828, "ep_reward": 458.0908508300781, "reward": -0.01225137710571289, "action": 1.730675458908081}
{"mode": "train", "epochs": 5, "timestep": 8829, "ep_reward": 458.2168273925781, "reward": 0.12596410512924194, "action": 1.050353765487671}
{"mode": "train", "epochs": 5, "timestep": 8830, "ep_reward": 458.4811706542969, "reward": 0.2643480896949768, "action": 0.6586475372314453}
{"mode": "train", "epochs": 5, "timestep": 8831, "ep_reward": 458.8877868652344, "reward": 0.40662407875061035, "action": 0.5432901382446289}
{"mode": "train", "epochs": 5, "timestep": 8832, "ep_reward": 459.4258117675781, "reward": 0.5380102396011353, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8833, "ep_reward": 460.0604553222656, "reward": 0.6346395015716553, "action": 0.7290446758270264}
{"mode": "train", "epochs": 5, "timestep": 8834, "ep_reward": 460.7846984863281, "reward": 0.7242578268051147, "action": 1.1635960340499878}
{"mode": "train", "epochs": 5, "timestep": 8835, "ep_reward": 461.5716247558594, "reward": 0.7869259715080261, "action": 0.8050944805145264}
{"mode": "train", "epochs": 5, "timestep": 8836, "ep_reward": 462.404052734375, "reward": 0.8324201107025146, "action": 1.4176342487335205}
{"mode": "train", "epochs": 5, "timestep": 8837, "ep_reward": 463.2586364746094, "reward": 0.8545724153518677, "action": 0.3085394501686096}
{"mode": "train", "epochs": 5, "timestep": 8838, "ep_reward": 464.1280517578125, "reward": 0.8694159388542175, "action": 0.31197136640548706}
{"mode": "train", "epochs": 5, "timestep": 8839, "ep_reward": 464.9959411621094, "reward": 0.8678998351097107, "action": 0.7920627593994141}
{"mode": "train", "epochs": 5, "timestep": 8840, "ep_reward": 465.84100341796875, "reward": 0.8450505137443542, "action": 0.9843470454216003}
{"mode": "train", "epochs": 5, "timestep": 8841, "ep_reward": 466.6404113769531, "reward": 0.7994186282157898, "action": 1.2588812112808228}
{"mode": "train", "epochs": 5, "timestep": 8842, "ep_reward": 467.3639831542969, "reward": 0.72357577085495, "action": 1.5863652229309082}
{"mode": "train", "epochs": 5, "timestep": 8843, "ep_reward": 467.97216796875, "reward": 0.6081752777099609, "action": 0.25454026460647583}
{"mode": "train", "epochs": 5, "timestep": 8844, "ep_reward": 468.4422607421875, "reward": 0.4701031446456909, "action": 0.32694780826568604}
{"mode": "train", "epochs": 5, "timestep": 8845, "ep_reward": 468.7720947265625, "reward": 0.32984912395477295, "action": 1.0617755651474}
{"mode": "train", "epochs": 5, "timestep": 8846, "ep_reward": 468.988037109375, "reward": 0.21595561504364014, "action": 0.6616388559341431}
{"mode": "train", "epochs": 5, "timestep": 8847, "ep_reward": 469.0700378417969, "reward": 0.08198970556259155, "action": 0.9571224451065063}
{"mode": "train", "epochs": 5, "timestep": 8848, "ep_reward": 469.1057434082031, "reward": 0.03570985794067383, "action": 1.4219355583190918}
{"mode": "train", "epochs": 5, "timestep": 8849, "ep_reward": 469.2817077636719, "reward": 0.17596888542175293, "action": 1.179902195930481}
{"mode": "train", "epochs": 5, "timestep": 8850, "ep_reward": 469.5954284667969, "reward": 0.3137357831001282, "action": 1.2267794609069824}
{"mode": "train", "epochs": 5, "timestep": 8851, "ep_reward": 470.04229736328125, "reward": 0.44686609506607056, "action": 0.1325322389602661}
{"mode": "train", "epochs": 5, "timestep": 8852, "ep_reward": 470.6207580566406, "reward": 0.5784685015678406, "action": 1.2664709091186523}
{"mode": "train", "epochs": 5, "timestep": 8853, "ep_reward": 471.2958679199219, "reward": 0.6751202344894409, "action": 1.170648217201233}
{"mode": "train", "epochs": 5, "timestep": 8854, "ep_reward": 472.0467529296875, "reward": 0.7508881688117981, "action": 0.5213099122047424}
{"mode": "train", "epochs": 5, "timestep": 8855, "ep_reward": 472.8576965332031, "reward": 0.8109393119812012, "action": 1.0614341497421265}
{"mode": "train", "epochs": 5, "timestep": 8856, "ep_reward": 473.7040710449219, "reward": 0.8463752269744873, "action": 1.1320933103561401}
{"mode": "train", "epochs": 5, "timestep": 8857, "ep_reward": 474.5682678222656, "reward": 0.864189624786377, "action": 1.0213912725448608}
{"mode": "train", "epochs": 5, "timestep": 8858, "ep_reward": 475.4349365234375, "reward": 0.8666759133338928, "action": 1.180768609046936}
{"mode": "train", "epochs": 5, "timestep": 8859, "ep_reward": 476.28564453125, "reward": 0.8507000803947449, "action": 0.8001753687858582}
{"mode": "train", "epochs": 5, "timestep": 8860, "ep_reward": 477.10382080078125, "reward": 0.818183422088623, "action": 1.3404593467712402}
{"mode": "train", "epochs": 5, "timestep": 8861, "ep_reward": 477.8592224121094, "reward": 0.7553971409797668, "action": 1.2738945484161377}
{"mode": "train", "epochs": 5, "timestep": 8862, "ep_reward": 478.5198669433594, "reward": 0.6606395244598389, "action": 1.2027270793914795}
{"mode": "train", "epochs": 5, "timestep": 8863, "ep_reward": 479.0467529296875, "reward": 0.5268838405609131, "action": 1.435430884361267}
{"mode": "train", "epochs": 5, "timestep": 8864, "ep_reward": 479.4219665527344, "reward": 0.37521129846572876, "action": 1.1774005889892578}
{"mode": "train", "epochs": 5, "timestep": 8865, "ep_reward": 479.6924133300781, "reward": 0.2704424262046814, "action": 0.9102199077606201}
{"mode": "train", "epochs": 5, "timestep": 8866, "ep_reward": 479.837890625, "reward": 0.1454629898071289, "action": 1.910391092300415}
{"mode": "train", "epochs": 5, "timestep": 8867, "ep_reward": 479.83868408203125, "reward": 0.0007963180541992188, "action": 1.2151851654052734}
{"mode": "train", "epochs": 5, "timestep": 8868, "ep_reward": 479.95318603515625, "reward": 0.11449021100997925, "action": 0.47947490215301514}
{"mode": "train", "epochs": 5, "timestep": 8869, "ep_reward": 480.2127990722656, "reward": 0.2596082091331482, "action": 0.9705186486244202}
{"mode": "train", "epochs": 5, "timestep": 8870, "ep_reward": 480.60980224609375, "reward": 0.3969918489456177, "action": 1.747750997543335}
{"mode": "train", "epochs": 5, "timestep": 8871, "ep_reward": 481.12554931640625, "reward": 0.5157400369644165, "action": 0.7186183929443359}
{"mode": "train", "epochs": 5, "timestep": 8872, "ep_reward": 481.7551574707031, "reward": 0.6295977830886841, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8873, "ep_reward": 482.4632263183594, "reward": 0.7080657482147217, "action": 0.8289655447006226}
{"mode": "train", "epochs": 5, "timestep": 8874, "ep_reward": 483.2401123046875, "reward": 0.776901125907898, "action": -0.6307203769683838}
{"mode": "train", "epochs": 5, "timestep": 8875, "ep_reward": 484.0766296386719, "reward": 0.8365259170532227, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8876, "ep_reward": 484.930908203125, "reward": 0.8542811870574951, "action": 1.5844024419784546}
{"mode": "train", "epochs": 5, "timestep": 8877, "ep_reward": 485.79010009765625, "reward": 0.8591877222061157, "action": 0.7377142906188965}
{"mode": "train", "epochs": 5, "timestep": 8878, "ep_reward": 486.64404296875, "reward": 0.8539387583732605, "action": 1.556542158126831}
{"mode": "train", "epochs": 5, "timestep": 8879, "ep_reward": 487.4656982421875, "reward": 0.8216491937637329, "action": 1.6843953132629395}
{"mode": "train", "epochs": 5, "timestep": 8880, "ep_reward": 488.2283935546875, "reward": 0.7626943588256836, "action": 1.2582151889801025}
{"mode": "train", "epochs": 5, "timestep": 8881, "ep_reward": 488.904296875, "reward": 0.6758899688720703, "action": 1.0578861236572266}
{"mode": "train", "epochs": 5, "timestep": 8882, "ep_reward": 489.4567565917969, "reward": 0.5524464845657349, "action": 1.3308395147323608}
{"mode": "train", "epochs": 5, "timestep": 8883, "ep_reward": 489.85467529296875, "reward": 0.3979036211967468, "action": 0.8942133784294128}
{"mode": "train", "epochs": 5, "timestep": 8884, "ep_reward": 490.1527404785156, "reward": 0.2980539798736572, "action": 0.18420016765594482}
{"mode": "train", "epochs": 5, "timestep": 8885, "ep_reward": 490.3307800292969, "reward": 0.17805147171020508, "action": 1.3130338191986084}
{"mode": "train", "epochs": 5, "timestep": 8886, "ep_reward": 490.36895751953125, "reward": 0.03817790746688843, "action": 1.1664295196533203}
{"mode": "train", "epochs": 5, "timestep": 8887, "ep_reward": 490.4486083984375, "reward": 0.07965195178985596, "action": 1.0169347524642944}
{"mode": "train", "epochs": 5, "timestep": 8888, "ep_reward": 490.6657409667969, "reward": 0.217140793800354, "action": 0.4251670837402344}
{"mode": "train", "epochs": 5, "timestep": 8889, "ep_reward": 491.02972412109375, "reward": 0.3639853000640869, "action": 0.3680689334869385}
{"mode": "train", "epochs": 5, "timestep": 8890, "ep_reward": 491.5316467285156, "reward": 0.5019112825393677, "action": 0.5600425004959106}
{"mode": "train", "epochs": 5, "timestep": 8891, "ep_reward": 492.1510925292969, "reward": 0.619441568851471, "action": 1.3481218814849854}
{"mode": "train", "epochs": 5, "timestep": 8892, "ep_reward": 492.8584899902344, "reward": 0.7073870301246643, "action": 1.4984828233718872}
{"mode": "train", "epochs": 5, "timestep": 8893, "ep_reward": 493.6319274902344, "reward": 0.7734237909317017, "action": 1.2088658809661865}
{"mode": "train", "epochs": 5, "timestep": 8894, "ep_reward": 494.4544677734375, "reward": 0.8225317597389221, "action": 1.612577199935913}
{"mode": "train", "epochs": 5, "timestep": 8895, "ep_reward": 495.3050231933594, "reward": 0.8505419492721558, "action": 0.9117122888565063}
{"mode": "train", "epochs": 5, "timestep": 8896, "ep_reward": 496.1731262207031, "reward": 0.8680882453918457, "action": 0.7493953704833984}
{"mode": "train", "epochs": 5, "timestep": 8897, "ep_reward": 497.0440979003906, "reward": 0.870965838432312, "action": 1.3362153768539429}
{"mode": "train", "epochs": 5, "timestep": 8898, "ep_reward": 497.8961181640625, "reward": 0.852012038230896, "action": 1.7657561302185059}
{"mode": "train", "epochs": 5, "timestep": 8899, "ep_reward": 498.7044982910156, "reward": 0.8083670139312744, "action": 1.1537494659423828}
{"mode": "train", "epochs": 5, "timestep": 8900, "ep_reward": 499.4483642578125, "reward": 0.7438733577728271, "action": 1.1289002895355225}
{"mode": "train", "epochs": 5, "timestep": 8901, "ep_reward": 500.0947265625, "reward": 0.6463745832443237, "action": 1.0138874053955078}
{"mode": "train", "epochs": 5, "timestep": 8902, "ep_reward": 500.6051940917969, "reward": 0.5104619264602661, "action": 0.13866078853607178}
{"mode": "train", "epochs": 5, "timestep": 8903, "ep_reward": 500.97015380859375, "reward": 0.3649628758430481, "action": 0.7415385842323303}
{"mode": "train", "epochs": 5, "timestep": 8904, "ep_reward": 501.2281799316406, "reward": 0.25802457332611084, "action": 0.5693008899688721}
{"mode": "train", "epochs": 5, "timestep": 8905, "ep_reward": 501.3592224121094, "reward": 0.13103729486465454, "action": 0.9446674585342407}
{"mode": "train", "epochs": 5, "timestep": 8906, "ep_reward": 501.34320068359375, "reward": -0.01602649688720703, "action": 1.6416833400726318}
{"mode": "train", "epochs": 5, "timestep": 8907, "ep_reward": 501.47247314453125, "reward": 0.1292710304260254, "action": 1.1970062255859375}
{"mode": "train", "epochs": 5, "timestep": 8908, "ep_reward": 501.73828125, "reward": 0.2657974362373352, "action": 1.5320274829864502}
{"mode": "train", "epochs": 5, "timestep": 8909, "ep_reward": 502.1358947753906, "reward": 0.39762306213378906, "action": 1.4160356521606445}
{"mode": "train", "epochs": 5, "timestep": 8910, "ep_reward": 502.6571044921875, "reward": 0.5212133526802063, "action": 1.2869904041290283}
{"mode": "train", "epochs": 5, "timestep": 8911, "ep_reward": 503.2851867675781, "reward": 0.6280927658081055, "action": 1.363021969795227}
{"mode": "train", "epochs": 5, "timestep": 8912, "ep_reward": 503.9967956542969, "reward": 0.7116218209266663, "action": 0.5907078981399536}
{"mode": "train", "epochs": 5, "timestep": 8913, "ep_reward": 504.7762756347656, "reward": 0.7794749140739441, "action": 0.21629679203033447}
{"mode": "train", "epochs": 5, "timestep": 8914, "ep_reward": 505.604248046875, "reward": 0.8279727697372437, "action": 0.7022311687469482}
{"mode": "train", "epochs": 5, "timestep": 8915, "ep_reward": 506.456298828125, "reward": 0.8520549535751343, "action": 1.2851641178131104}
{"mode": "train", "epochs": 5, "timestep": 8916, "ep_reward": 507.3094787597656, "reward": 0.8531669974327087, "action": 1.1603550910949707}
{"mode": "train", "epochs": 5, "timestep": 8917, "ep_reward": 508.1461181640625, "reward": 0.8366419076919556, "action": 0.45481419563293457}
{"mode": "train", "epochs": 5, "timestep": 8918, "ep_reward": 508.9515380859375, "reward": 0.8054294586181641, "action": 0.6594951152801514}
{"mode": "train", "epochs": 5, "timestep": 8919, "ep_reward": 509.6983947753906, "reward": 0.7468597888946533, "action": 0.7515261173248291}
{"mode": "train", "epochs": 5, "timestep": 8920, "ep_reward": 510.3540954589844, "reward": 0.6556982398033142, "action": 0.36465537548065186}
{"mode": "train", "epochs": 5, "timestep": 8921, "ep_reward": 510.88629150390625, "reward": 0.5321817398071289, "action": 1.7683501243591309}
{"mode": "train", "epochs": 5, "timestep": 8922, "ep_reward": 511.2572021484375, "reward": 0.37090182304382324, "action": 0.10953694581985474}
{"mode": "train", "epochs": 5, "timestep": 8923, "ep_reward": 511.5222473144531, "reward": 0.26504480838775635, "action": 1.4494234323501587}
{"mode": "train", "epochs": 5, "timestep": 8924, "ep_reward": 511.6615905761719, "reward": 0.13935357332229614, "action": 1.2437723875045776}
{"mode": "train", "epochs": 5, "timestep": 8925, "ep_reward": 511.6553039550781, "reward": -0.006279349327087402, "action": 0.26285868883132935}
{"mode": "train", "epochs": 5, "timestep": 8926, "ep_reward": 511.776123046875, "reward": 0.12080830335617065, "action": 1.2929872274398804}
{"mode": "train", "epochs": 5, "timestep": 8927, "ep_reward": 512.0320434570312, "reward": 0.25592154264450073, "action": 1.4916558265686035}
{"mode": "train", "epochs": 5, "timestep": 8928, "ep_reward": 512.4209594726562, "reward": 0.3889055848121643, "action": 0.8224475383758545}
{"mode": "train", "epochs": 5, "timestep": 8929, "ep_reward": 512.9414672851562, "reward": 0.5205228328704834, "action": 0.7878382205963135}
{"mode": "train", "epochs": 5, "timestep": 8930, "ep_reward": 513.5745239257812, "reward": 0.6330742835998535, "action": 0.5569515824317932}
{"mode": "train", "epochs": 5, "timestep": 8931, "ep_reward": 514.299072265625, "reward": 0.7245241403579712, "action": 0.8481382131576538}
{"mode": "train", "epochs": 5, "timestep": 8932, "ep_reward": 515.0887451171875, "reward": 0.7896468043327332, "action": 0.765831708908081}
{"mode": "train", "epochs": 5, "timestep": 8933, "ep_reward": 515.9234619140625, "reward": 0.8347153663635254, "action": 1.329667568206787}
{"mode": "train", "epochs": 5, "timestep": 8934, "ep_reward": 516.7803955078125, "reward": 0.8569304943084717, "action": 1.126698613166809}
{"mode": "train", "epochs": 5, "timestep": 8935, "ep_reward": 517.6446533203125, "reward": 0.8642823696136475, "action": 1.2526466846466064}
{"mode": "train", "epochs": 5, "timestep": 8936, "ep_reward": 518.4982299804688, "reward": 0.8535577654838562, "action": 0.4097527265548706}
{"mode": "train", "epochs": 5, "timestep": 8937, "ep_reward": 519.32958984375, "reward": 0.8313313722610474, "action": 1.270938515663147}
{"mode": "train", "epochs": 5, "timestep": 8938, "ep_reward": 520.107666015625, "reward": 0.778060257434845, "action": 1.1382899284362793}
{"mode": "train", "epochs": 5, "timestep": 8939, "ep_reward": 520.8038940429688, "reward": 0.696229100227356, "action": 0.9972476363182068}
{"mode": "train", "epochs": 5, "timestep": 8940, "ep_reward": 521.3831787109375, "reward": 0.5792657136917114, "action": 1.1327683925628662}
{"mode": "train", "epochs": 5, "timestep": 8941, "ep_reward": 521.8013305664062, "reward": 0.4181440472602844, "action": 1.727327585220337}
{"mode": "train", "epochs": 5, "timestep": 8942, "ep_reward": 522.1084594726562, "reward": 0.3071248531341553, "action": 1.4275822639465332}
{"mode": "train", "epochs": 5, "timestep": 8943, "ep_reward": 522.29736328125, "reward": 0.18892693519592285, "action": 1.355947494506836}
{"mode": "train", "epochs": 5, "timestep": 8944, "ep_reward": 522.34814453125, "reward": 0.0508076548576355, "action": 0.6242607235908508}
{"mode": "train", "epochs": 5, "timestep": 8945, "ep_reward": 522.41552734375, "reward": 0.06738817691802979, "action": 1.2159075736999512}
{"mode": "train", "epochs": 5, "timestep": 8946, "ep_reward": 522.6187744140625, "reward": 0.20327556133270264, "action": 1.554140329360962}
{"mode": "train", "epochs": 5, "timestep": 8947, "ep_reward": 522.9554443359375, "reward": 0.33668768405914307, "action": 1.519079566001892}
{"mode": "train", "epochs": 5, "timestep": 8948, "ep_reward": 523.4207153320312, "reward": 0.46529752016067505, "action": 0.9439480304718018}
{"mode": "train", "epochs": 5, "timestep": 8949, "ep_reward": 524.0062255859375, "reward": 0.5854995250701904, "action": 1.2014219760894775}
{"mode": "train", "epochs": 5, "timestep": 8950, "ep_reward": 524.6865844726562, "reward": 0.6803781986236572, "action": 1.492835521697998}
{"mode": "train", "epochs": 5, "timestep": 8951, "ep_reward": 525.435546875, "reward": 0.7489398717880249, "action": 0.5603342056274414}
{"mode": "train", "epochs": 5, "timestep": 8952, "ep_reward": 526.2392578125, "reward": 0.8037328124046326, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8953, "ep_reward": 527.063232421875, "reward": 0.823995053768158, "action": 0.27019137144088745}
{"mode": "train", "epochs": 5, "timestep": 8954, "ep_reward": 527.903564453125, "reward": 0.840355634689331, "action": 1.5400710105895996}
{"mode": "train", "epochs": 5, "timestep": 8955, "ep_reward": 528.7280883789062, "reward": 0.8245307803153992, "action": 0.2496209740638733}
{"mode": "train", "epochs": 5, "timestep": 8956, "ep_reward": 529.5266723632812, "reward": 0.7985858917236328, "action": 1.247709035873413}
{"mode": "train", "epochs": 5, "timestep": 8957, "ep_reward": 530.26220703125, "reward": 0.7355422973632812, "action": 0.1900152564048767}
{"mode": "train", "epochs": 5, "timestep": 8958, "ep_reward": 530.9139404296875, "reward": 0.6517528295516968, "action": 1.4638464450836182}
{"mode": "train", "epochs": 5, "timestep": 8959, "ep_reward": 531.426025390625, "reward": 0.5120550394058228, "action": 1.9889988899230957}
{"mode": "train", "epochs": 5, "timestep": 8960, "ep_reward": 531.8010864257812, "reward": 0.3750537633895874, "action": 1.3553533554077148}
{"mode": "train", "epochs": 5, "timestep": 8961, "ep_reward": 532.0713500976562, "reward": 0.2702353000640869, "action": 1.278687596321106}
{"mode": "train", "epochs": 5, "timestep": 8962, "ep_reward": 532.2168579101562, "reward": 0.14549940824508667, "action": 0.35054898262023926}
{"mode": "train", "epochs": 5, "timestep": 8963, "ep_reward": 532.217529296875, "reward": 0.000659644603729248, "action": 0.5300499200820923}
{"mode": "train", "epochs": 5, "timestep": 8964, "ep_reward": 532.3321533203125, "reward": 0.11465132236480713, "action": 0.8337867259979248}
{"mode": "train", "epochs": 5, "timestep": 8965, "ep_reward": 532.5874633789062, "reward": 0.2552978992462158, "action": 1.543379783630371}
{"mode": "train", "epochs": 5, "timestep": 8966, "ep_reward": 532.9740600585938, "reward": 0.38659024238586426, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 8967, "ep_reward": 533.4783935546875, "reward": 0.50433349609375, "action": 0.6946961879730225}
{"mode": "train", "epochs": 5, "timestep": 8968, "ep_reward": 534.09912109375, "reward": 0.6206986904144287, "action": 1.552504301071167}
{"mode": "train", "epochs": 5, "timestep": 8969, "ep_reward": 534.803466796875, "reward": 0.7043461799621582, "action": 1.2046277523040771}
{"mode": "train", "epochs": 5, "timestep": 8970, "ep_reward": 535.5723266601562, "reward": 0.7688744068145752, "action": 0.06654655933380127}
{"mode": "train", "epochs": 5, "timestep": 8971, "ep_reward": 536.3941040039062, "reward": 0.8217513561248779, "action": 0.5189557075500488}
{"mode": "train", "epochs": 5, "timestep": 8972, "ep_reward": 537.2438354492188, "reward": 0.8497256636619568, "action": 0.5194058418273926}
{"mode": "train", "epochs": 5, "timestep": 8973, "ep_reward": 538.1033935546875, "reward": 0.8595885038375854, "action": 0.5634366273880005}
{"mode": "train", "epochs": 5, "timestep": 8974, "ep_reward": 538.9547729492188, "reward": 0.8513668179512024, "action": 0.9150364995002747}
{"mode": "train", "epochs": 5, "timestep": 8975, "ep_reward": 539.7752075195312, "reward": 0.820415198802948, "action": 0.2484203577041626}
{"mode": "train", "epochs": 5, "timestep": 8976, "ep_reward": 540.5477905273438, "reward": 0.772596538066864, "action": 1.2303344011306763}
{"mode": "train", "epochs": 5, "timestep": 8977, "ep_reward": 541.2327880859375, "reward": 0.684972882270813, "action": 0.8487519025802612}
{"mode": "train", "epochs": 5, "timestep": 8978, "ep_reward": 541.7974853515625, "reward": 0.564717173576355, "action": 1.304030179977417}
{"mode": "train", "epochs": 5, "timestep": 8979, "ep_reward": 542.193603515625, "reward": 0.3961006999015808, "action": 0.9162740707397461}
{"mode": "train", "epochs": 5, "timestep": 8980, "ep_reward": 542.483642578125, "reward": 0.2900125980377197, "action": 1.2295769453048706}
{"mode": "train", "epochs": 5, "timestep": 8981, "ep_reward": 542.6524047851562, "reward": 0.16874146461486816, "action": 0.7110679745674133}
{"mode": "train", "epochs": 5, "timestep": 8982, "ep_reward": 542.6798095703125, "reward": 0.027391135692596436, "action": 0.8807886838912964}
{"mode": "train", "epochs": 5, "timestep": 8983, "ep_reward": 542.7697143554688, "reward": 0.08990037441253662, "action": 1.4491965770721436}
{"mode": "train", "epochs": 5, "timestep": 8984, "ep_reward": 542.9925537109375, "reward": 0.2228514552116394, "action": 0.19689607620239258}
{"mode": "train", "epochs": 5, "timestep": 8985, "ep_reward": 543.36572265625, "reward": 0.3731675148010254, "action": 0.6281172037124634}
{"mode": "train", "epochs": 5, "timestep": 8986, "ep_reward": 543.8731689453125, "reward": 0.5074182152748108, "action": 0.5399854779243469}
{"mode": "train", "epochs": 5, "timestep": 8987, "ep_reward": 544.4976806640625, "reward": 0.6245262026786804, "action": 0.7980250716209412}
{"mode": "train", "epochs": 5, "timestep": 8988, "ep_reward": 545.2142333984375, "reward": 0.7165662050247192, "action": 1.1644093990325928}
{"mode": "train", "epochs": 5, "timestep": 8989, "ep_reward": 545.9974975585938, "reward": 0.7832885980606079, "action": 1.4109721183776855}
{"mode": "train", "epochs": 5, "timestep": 8990, "ep_reward": 546.8261108398438, "reward": 0.8285962343215942, "action": 0.5899238586425781}
{"mode": "train", "epochs": 5, "timestep": 8991, "ep_reward": 547.6893310546875, "reward": 0.8632118701934814, "action": 1.837590217590332}
{"mode": "train", "epochs": 5, "timestep": 8992, "ep_reward": 548.5614013671875, "reward": 0.8720971345901489, "action": 1.8728291988372803}
{"mode": "train", "epochs": 5, "timestep": 8993, "ep_reward": 549.4267578125, "reward": 0.865359902381897, "action": 0.7906343936920166}
{"mode": "train", "epochs": 5, "timestep": 8994, "ep_reward": 550.2771606445312, "reward": 0.85042405128479, "action": 1.2953314781188965}
{"mode": "train", "epochs": 5, "timestep": 8995, "ep_reward": 551.0878295898438, "reward": 0.8106539845466614, "action": 0.448628306388855}
{"mode": "train", "epochs": 5, "timestep": 8996, "ep_reward": 551.8419799804688, "reward": 0.754131555557251, "action": 1.033976435661316}
{"mode": "train", "epochs": 5, "timestep": 8997, "ep_reward": 552.5020751953125, "reward": 0.6600841283798218, "action": 1.6717770099639893}
{"mode": "train", "epochs": 5, "timestep": 8998, "ep_reward": 553.0201416015625, "reward": 0.5180619955062866, "action": 0.7376899719238281}
{"mode": "train", "epochs": 5, "timestep": 8999, "ep_reward": 553.3875122070312, "reward": 0.3674008250236511, "action": 1.793733835220337}
{"mode": "train", "epochs": 5, "timestep": 9000, "ep_reward": 553.6486206054688, "reward": 0.26112639904022217, "action": 0.9954237341880798}
{"mode": "train", "epochs": 5, "timestep": 9001, "ep_reward": 553.7833862304688, "reward": 0.1347581148147583, "action": 0.5262638926506042}
{"mode": "train", "epochs": 5, "timestep": 9002, "ep_reward": 553.7715454101562, "reward": -0.011819243431091309, "action": 1.7076027393341064}
{"mode": "train", "epochs": 5, "timestep": 9003, "ep_reward": 553.8971557617188, "reward": 0.12559568881988525, "action": 0.9901212453842163}
{"mode": "train", "epochs": 5, "timestep": 9004, "ep_reward": 554.1616821289062, "reward": 0.26455157995224, "action": 1.740554690361023}
{"mode": "train", "epochs": 5, "timestep": 9005, "ep_reward": 554.5552368164062, "reward": 0.393563449382782, "action": 1.047763705253601}
{"mode": "train", "epochs": 5, "timestep": 9006, "ep_reward": 555.0770874023438, "reward": 0.5218661427497864, "action": 1.4841750860214233}
{"mode": "train", "epochs": 5, "timestep": 9007, "ep_reward": 555.7036743164062, "reward": 0.6266034245491028, "action": 0.9295965433120728}
{"mode": "train", "epochs": 5, "timestep": 9008, "ep_reward": 556.4188232421875, "reward": 0.7151232957839966, "action": 0.7281415462493896}
{"mode": "train", "epochs": 5, "timestep": 9009, "ep_reward": 557.2006225585938, "reward": 0.7818135023117065, "action": 1.0185967683792114}
{"mode": "train", "epochs": 5, "timestep": 9010, "ep_reward": 558.0245361328125, "reward": 0.8239166736602783, "action": 1.0168529748916626}
{"mode": "train", "epochs": 5, "timestep": 9011, "ep_reward": 558.8711547851562, "reward": 0.84662264585495, "action": 1.644195318222046}
{"mode": "train", "epochs": 5, "timestep": 9012, "ep_reward": 559.7166748046875, "reward": 0.8455244302749634, "action": 0.8250418901443481}
{"mode": "train", "epochs": 5, "timestep": 9013, "ep_reward": 560.5490112304688, "reward": 0.8323158025741577, "action": 1.106153964996338}
{"mode": "train", "epochs": 5, "timestep": 9014, "ep_reward": 561.3430786132812, "reward": 0.7940736413002014, "action": 0.8659222722053528}
{"mode": "train", "epochs": 5, "timestep": 9015, "ep_reward": 562.073974609375, "reward": 0.7308670282363892, "action": 0.34853291511535645}
{"mode": "train", "epochs": 5, "timestep": 9016, "ep_reward": 562.71484375, "reward": 0.6408417224884033, "action": 0.49631571769714355}
{"mode": "train", "epochs": 5, "timestep": 9017, "ep_reward": 563.22607421875, "reward": 0.5112130641937256, "action": -0.0787426233291626}
{"mode": "train", "epochs": 5, "timestep": 9018, "ep_reward": 563.5897827148438, "reward": 0.3637133836746216, "action": 0.9017035961151123}
{"mode": "train", "epochs": 5, "timestep": 9019, "ep_reward": 563.8463134765625, "reward": 0.2565169930458069, "action": 0.8083951473236084}
{"mode": "train", "epochs": 5, "timestep": 9020, "ep_reward": 563.9756469726562, "reward": 0.12930631637573242, "action": 0.8560700416564941}
{"mode": "train", "epochs": 5, "timestep": 9021, "ep_reward": 563.9596557617188, "reward": -0.015972018241882324, "action": 1.4065483808517456}
{"mode": "train", "epochs": 5, "timestep": 9022, "ep_reward": 564.0907592773438, "reward": 0.13110142946243286, "action": -0.05514049530029297}
{"mode": "train", "epochs": 5, "timestep": 9023, "ep_reward": 564.3739013671875, "reward": 0.28315114974975586, "action": 1.319578766822815}
{"mode": "train", "epochs": 5, "timestep": 9024, "ep_reward": 564.7883911132812, "reward": 0.4145107865333557, "action": 0.636441707611084}
{"mode": "train", "epochs": 5, "timestep": 9025, "ep_reward": 565.3319702148438, "reward": 0.5435636043548584, "action": 1.174408197402954}
{"mode": "train", "epochs": 5, "timestep": 9026, "ep_reward": 565.979736328125, "reward": 0.6477947235107422, "action": 0.9274893999099731}
{"mode": "train", "epochs": 5, "timestep": 9027, "ep_reward": 566.7130126953125, "reward": 0.7332866191864014, "action": 1.4847924709320068}
{"mode": "train", "epochs": 5, "timestep": 9028, "ep_reward": 567.50537109375, "reward": 0.792388379573822, "action": 1.1410205364227295}
{"mode": "train", "epochs": 5, "timestep": 9029, "ep_reward": 568.3410034179688, "reward": 0.8356243371963501, "action": 1.0276752710342407}
{"mode": "train", "epochs": 5, "timestep": 9030, "ep_reward": 569.2033081054688, "reward": 0.8622960448265076, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 9031, "ep_reward": 570.0685424804688, "reward": 0.865217387676239, "action": 1.3695807456970215}
{"mode": "train", "epochs": 5, "timestep": 9032, "ep_reward": 570.9253540039062, "reward": 0.8567880392074585, "action": 0.8865023255348206}
{"mode": "train", "epochs": 5, "timestep": 9033, "ep_reward": 571.7592163085938, "reward": 0.833856999874115, "action": 0.8445999622344971}
{"mode": "train", "epochs": 5, "timestep": 9034, "ep_reward": 572.5482177734375, "reward": 0.7890191674232483, "action": 1.358933687210083}
{"mode": "train", "epochs": 5, "timestep": 9035, "ep_reward": 573.2584228515625, "reward": 0.7102351188659668, "action": 1.2671340703964233}
{"mode": "train", "epochs": 5, "timestep": 9036, "ep_reward": 573.8541259765625, "reward": 0.5956860780715942, "action": 1.4463114738464355}
{"mode": "train", "epochs": 5, "timestep": 9037, "ep_reward": 574.2894897460938, "reward": 0.43535667657852173, "action": 0.5625}
{"mode": "train", "epochs": 5, "timestep": 9038, "ep_reward": 574.6129150390625, "reward": 0.3234502077102661, "action": 1.4425345659255981}
{"mode": "train", "epochs": 5, "timestep": 9039, "ep_reward": 574.8212890625, "reward": 0.2083655595779419, "action": 1.0228705406188965}
{"mode": "train", "epochs": 5, "timestep": 9040, "ep_reward": 574.8945922851562, "reward": 0.07327497005462646, "action": 0.34117794036865234}
{"mode": "train", "epochs": 5, "timestep": 9041, "ep_reward": 574.9393310546875, "reward": 0.04475271701812744, "action": 1.5788958072662354}
{"mode": "train", "epochs": 5, "timestep": 9042, "ep_reward": 575.1231689453125, "reward": 0.1838362216949463, "action": 1.1258327960968018}
{"mode": "train", "epochs": 5, "timestep": 9043, "ep_reward": 575.445556640625, "reward": 0.32241398096084595, "action": 1.091277003288269}
{"mode": "train", "epochs": 5, "timestep": 9044, "ep_reward": 575.902099609375, "reward": 0.45651525259017944, "action": 0.34070420265197754}
{"mode": "train", "epochs": 5, "timestep": 9045, "ep_reward": 576.4864501953125, "reward": 0.5843384265899658, "action": 0.9098174571990967}
{"mode": "train", "epochs": 5, "timestep": 9046, "ep_reward": 577.169921875, "reward": 0.6834446787834167, "action": 0.9620830416679382}
{"mode": "train", "epochs": 5, "timestep": 9047, "ep_reward": 577.9293212890625, "reward": 0.7594059705734253, "action": 0.3664137125015259}
{"mode": "train", "epochs": 5, "timestep": 9048, "ep_reward": 578.748291015625, "reward": 0.8189898133277893, "action": 1.62703537940979}
{"mode": "train", "epochs": 5, "timestep": 9049, "ep_reward": 579.5969848632812, "reward": 0.8486901521682739, "action": 1.4743643999099731}
{"mode": "train", "epochs": 5, "timestep": 9050, "ep_reward": 580.4603881835938, "reward": 0.8634210824966431, "action": 1.2229211330413818}
{"mode": "train", "epochs": 5, "timestep": 9051, "ep_reward": 581.3244018554688, "reward": 0.8640013337135315, "action": 1.2673935890197754}
{"mode": "train", "epochs": 5, "timestep": 9052, "ep_reward": 582.1710815429688, "reward": 0.8466635942459106, "action": 1.034901738166809}
{"mode": "train", "epochs": 5, "timestep": 9053, "ep_reward": 582.9818725585938, "reward": 0.8107669353485107, "action": 0.7490829229354858}
{"mode": "train", "epochs": 5, "timestep": 9054, "ep_reward": 583.734375, "reward": 0.7524853944778442, "action": 0.5292738676071167}
{"mode": "train", "epochs": 5, "timestep": 9055, "ep_reward": 584.4003295898438, "reward": 0.6659352779388428, "action": 0.3919897675514221}
{"mode": "train", "epochs": 5, "timestep": 9056, "ep_reward": 584.9454345703125, "reward": 0.5451171398162842, "action": 0.8407412767410278}
{"mode": "train", "epochs": 5, "timestep": 9057, "ep_reward": 585.32373046875, "reward": 0.3783116936683655, "action": 0.7837624549865723}
{"mode": "train", "epochs": 5, "timestep": 9058, "ep_reward": 585.5947265625, "reward": 0.270966112613678, "action": 0.2123848795890808}
{"mode": "train", "epochs": 5, "timestep": 9059, "ep_reward": 585.7408447265625, "reward": 0.14613819122314453, "action": 1.329039454460144}
{"mode": "train", "epochs": 5, "timestep": 9060, "ep_reward": 585.7422485351562, "reward": 0.0014244914054870605, "action": 1.2914233207702637}
{"mode": "train", "epochs": 5, "timestep": 9061, "ep_reward": 585.8560791015625, "reward": 0.11384963989257812, "action": 1.1192208528518677}
{"mode": "train", "epochs": 5, "timestep": 9062, "ep_reward": 586.1070556640625, "reward": 0.2509920597076416, "action": 1.1967861652374268}
{"mode": "train", "epochs": 5, "timestep": 9063, "ep_reward": 586.4945068359375, "reward": 0.38744664192199707, "action": 0.7209030389785767}
{"mode": "train", "epochs": 5, "timestep": 9064, "ep_reward": 587.0143432617188, "reward": 0.5198441743850708, "action": 1.2482304573059082}
{"mode": "train", "epochs": 5, "timestep": 9065, "ep_reward": 587.641845703125, "reward": 0.6274746656417847, "action": 1.2522664070129395}
{"mode": "train", "epochs": 5, "timestep": 9066, "ep_reward": 588.3554077148438, "reward": 0.7135382890701294, "action": 0.17899006605148315}
{"mode": "train", "epochs": 5, "timestep": 9067, "ep_reward": 589.142578125, "reward": 0.7871521711349487, "action": 1.289229393005371}
{"mode": "train", "epochs": 5, "timestep": 9068, "ep_reward": 589.9715576171875, "reward": 0.8289796113967896, "action": 1.0800576210021973}
{"mode": "train", "epochs": 5, "timestep": 9069, "ep_reward": 590.8261108398438, "reward": 0.8545377254486084, "action": 1.4416407346725464}
{"mode": "train", "epochs": 5, "timestep": 9070, "ep_reward": 591.6862182617188, "reward": 0.8600963354110718, "action": 1.396159052848816}
{"mode": "train", "epochs": 5, "timestep": 9071, "ep_reward": 592.5347900390625, "reward": 0.8485717177391052, "action": 0.10334396362304688}
{"mode": "train", "epochs": 5, "timestep": 9072, "ep_reward": 593.3640747070312, "reward": 0.8293044567108154, "action": 1.4627330303192139}
{"mode": "train", "epochs": 5, "timestep": 9073, "ep_reward": 594.137939453125, "reward": 0.7738767862319946, "action": 0.9346731305122375}
{"mode": "train", "epochs": 5, "timestep": 9074, "ep_reward": 594.8316040039062, "reward": 0.6936572790145874, "action": 1.4188284873962402}
{"mode": "train", "epochs": 5, "timestep": 9075, "ep_reward": 595.4014892578125, "reward": 0.5699145197868347, "action": 1.637411117553711}
{"mode": "train", "epochs": 5, "timestep": 9076, "ep_reward": 595.8040771484375, "reward": 0.4026152491569519, "action": 1.3412628173828125}
{"mode": "train", "epochs": 5, "timestep": 9077, "ep_reward": 596.1077880859375, "reward": 0.3037274479866028, "action": 1.6548967361450195}
{"mode": "train", "epochs": 5, "timestep": 9078, "ep_reward": 596.2927856445312, "reward": 0.18501877784729004, "action": 0.9071840047836304}
{"mode": "train", "epochs": 5, "timestep": 9079, "ep_reward": 596.3388061523438, "reward": 0.04602903127670288, "action": 1.8475589752197266}
{"mode": "train", "epochs": 5, "timestep": 9080, "ep_reward": 596.4107055664062, "reward": 0.07189220190048218, "action": 1.1933749914169312}
{"mode": "train", "epochs": 5, "timestep": 9081, "ep_reward": 596.6179809570312, "reward": 0.207283616065979, "action": 0.6389741897583008}
{"mode": "train", "epochs": 5, "timestep": 9082, "ep_reward": 596.9700927734375, "reward": 0.3521323800086975, "action": 0.7089834213256836}
{"mode": "train", "epochs": 5, "timestep": 9083, "ep_reward": 597.4578247070312, "reward": 0.48773878812789917, "action": 1.2906723022460938}
{"mode": "train", "epochs": 5, "timestep": 9084, "ep_reward": 598.0579223632812, "reward": 0.6000779271125793, "action": 1.0712897777557373}
{"mode": "train", "epochs": 5, "timestep": 9085, "ep_reward": 598.7520751953125, "reward": 0.694137692451477, "action": 1.345855474472046}
{"mode": "train", "epochs": 5, "timestep": 9086, "ep_reward": 599.5153198242188, "reward": 0.7632590532302856, "action": 0.35663992166519165}
{"mode": "train", "epochs": 5, "timestep": 9087, "ep_reward": 600.3353881835938, "reward": 0.8200727701187134, "action": 1.9097883701324463}
{"mode": "train", "epochs": 5, "timestep": 9088, "ep_reward": 601.1795654296875, "reward": 0.8441570997238159, "action": 0.8472647666931152}
{"mode": "train", "epochs": 5, "timestep": 9089, "ep_reward": 602.0397338867188, "reward": 0.8601677417755127, "action": 1.5847476720809937}
{"mode": "train", "epochs": 5, "timestep": 9090, "ep_reward": 602.8922729492188, "reward": 0.852550208568573, "action": 1.2232320308685303}
{"mode": "train", "epochs": 5, "timestep": 9091, "ep_reward": 603.7208862304688, "reward": 0.8286293148994446, "action": 1.70878005027771}
{"mode": "train", "epochs": 5, "timestep": 9092, "ep_reward": 604.4970092773438, "reward": 0.7761310338973999, "action": 0.12670129537582397}
{"mode": "train", "epochs": 5, "timestep": 9093, "ep_reward": 605.2083129882812, "reward": 0.7113112807273865, "action": 1.5335252285003662}
{"mode": "train", "epochs": 5, "timestep": 9094, "ep_reward": 605.8027954101562, "reward": 0.5944696664810181, "action": 0.29657649993896484}
{"mode": "train", "epochs": 5, "timestep": 9095, "ep_reward": 606.2554931640625, "reward": 0.45272690057754517, "action": 0.8630325794219971}
{"mode": "train", "epochs": 5, "timestep": 9096, "ep_reward": 606.5850830078125, "reward": 0.3296127915382385, "action": 0.1430235505104065}
{"mode": "train", "epochs": 5, "timestep": 9097, "ep_reward": 606.8005981445312, "reward": 0.21551990509033203, "action": 1.2575984001159668}
{"mode": "train", "epochs": 5, "timestep": 9098, "ep_reward": 606.8821411132812, "reward": 0.0815231204032898, "action": 1.269998550415039}
{"mode": "train", "epochs": 5, "timestep": 9099, "ep_reward": 606.9183959960938, "reward": 0.03624242544174194, "action": 0.7494328618049622}
{"mode": "train", "epochs": 5, "timestep": 9100, "ep_reward": 607.0947875976562, "reward": 0.17640697956085205, "action": 0.7106077075004578}
{"mode": "train", "epochs": 5, "timestep": 9101, "ep_reward": 607.4148559570312, "reward": 0.3200652003288269, "action": -0.38639402389526367}
{"mode": "train", "epochs": 5, "timestep": 9102, "ep_reward": 607.8855590820312, "reward": 0.4706832766532898, "action": 1.7394177913665771}
{"mode": "train", "epochs": 5, "timestep": 9103, "ep_reward": 608.4655151367188, "reward": 0.5799540281295776, "action": 1.5023133754730225}
{"mode": "train", "epochs": 5, "timestep": 9104, "ep_reward": 609.1396484375, "reward": 0.674115777015686, "action": 1.1586779356002808}
{"mode": "train", "epochs": 5, "timestep": 9105, "ep_reward": 609.8904418945312, "reward": 0.7507787942886353, "action": 0.3372225761413574}
{"mode": "train", "epochs": 5, "timestep": 9106, "ep_reward": 610.7037963867188, "reward": 0.8133570551872253, "action": 1.4773753881454468}
{"mode": "train", "epochs": 5, "timestep": 9107, "ep_reward": 611.5504760742188, "reward": 0.8466616272926331, "action": 0.9238299131393433}
{"mode": "train", "epochs": 5, "timestep": 9108, "ep_reward": 612.4186401367188, "reward": 0.8681459426879883, "action": 0.5739579796791077}
{"mode": "train", "epochs": 5, "timestep": 9109, "ep_reward": 613.29541015625, "reward": 0.8767824172973633, "action": 1.1265382766723633}
{"mode": "train", "epochs": 5, "timestep": 9110, "ep_reward": 614.16064453125, "reward": 0.8652552366256714, "action": 0.00039207935333251953}
{"mode": "train", "epochs": 5, "timestep": 9111, "ep_reward": 615.0067749023438, "reward": 0.84611576795578, "action": 0.9995396733283997}
{"mode": "train", "epochs": 5, "timestep": 9112, "ep_reward": 615.8042602539062, "reward": 0.797494649887085, "action": -0.03780972957611084}
{"mode": "train", "epochs": 5, "timestep": 9113, "ep_reward": 616.5381469726562, "reward": 0.7338736653327942, "action": 0.5382193326950073}
{"mode": "train", "epochs": 5, "timestep": 9114, "ep_reward": 617.171630859375, "reward": 0.6334942579269409, "action": 0.519416093826294}
{"mode": "train", "epochs": 5, "timestep": 9115, "ep_reward": 617.6687622070312, "reward": 0.49711573123931885, "action": 1.095455527305603}
{"mode": "train", "epochs": 5, "timestep": 9116, "ep_reward": 617.9984130859375, "reward": 0.3296801447868347, "action": 0.3737773299217224}
{"mode": "train", "epochs": 5, "timestep": 9117, "ep_reward": 618.2139892578125, "reward": 0.21558856964111328, "action": 1.3811023235321045}
{"mode": "train", "epochs": 5, "timestep": 9118, "ep_reward": 618.2955932617188, "reward": 0.0815855860710144, "action": 1.5061365365982056}
{"mode": "train", "epochs": 5, "timestep": 9119, "ep_reward": 618.33154296875, "reward": 0.03597468137741089, "action": 1.766292691230774}
{"mode": "train", "epochs": 5, "timestep": 9120, "ep_reward": 618.5078125, "reward": 0.17627418041229248, "action": 1.0639784336090088}
{"mode": "train", "epochs": 5, "timestep": 9121, "ep_reward": 618.8233642578125, "reward": 0.31552523374557495, "action": 0.922070324420929}
{"mode": "train", "epochs": 5, "timestep": 9122, "ep_reward": 619.2752685546875, "reward": 0.4519212245941162, "action": 0.9789249897003174}
{"mode": "train", "epochs": 5, "timestep": 9123, "ep_reward": 619.8484497070312, "reward": 0.573196291923523, "action": 0.5377717614173889}
{"mode": "train", "epochs": 5, "timestep": 9124, "ep_reward": 620.5267333984375, "reward": 0.6782729625701904, "action": 0.8800753951072693}
{"mode": "train", "epochs": 5, "timestep": 9125, "ep_reward": 621.2828979492188, "reward": 0.7561429142951965, "action": 1.7494196891784668}
{"mode": "train", "epochs": 5, "timestep": 9126, "ep_reward": 622.0878295898438, "reward": 0.8049072623252869, "action": 0.9906489849090576}
{"mode": "train", "epochs": 5, "timestep": 9127, "ep_reward": 622.9295043945312, "reward": 0.8417038917541504, "action": 0.9960914850234985}
{"mode": "train", "epochs": 5, "timestep": 9128, "ep_reward": 623.7902221679688, "reward": 0.8607363700866699, "action": 1.3835182189941406}
{"mode": "train", "epochs": 5, "timestep": 9129, "ep_reward": 624.6497802734375, "reward": 0.8595825433731079, "action": 1.8333120346069336}
{"mode": "train", "epochs": 5, "timestep": 9130, "ep_reward": 625.4857788085938, "reward": 0.8360108137130737, "action": 1.4970085620880127}
{"mode": "train", "epochs": 5, "timestep": 9131, "ep_reward": 626.2783813476562, "reward": 0.7925910353660583, "action": 1.6455358266830444}
{"mode": "train", "epochs": 5, "timestep": 9132, "ep_reward": 626.99658203125, "reward": 0.7182222604751587, "action": 1.8911705017089844}
{"mode": "train", "epochs": 5, "timestep": 9133, "ep_reward": 627.5993041992188, "reward": 0.6027358770370483, "action": 0.8086042404174805}
{"mode": "train", "epochs": 5, "timestep": 9134, "ep_reward": 628.0568237304688, "reward": 0.4575210213661194, "action": 1.052858829498291}
{"mode": "train", "epochs": 5, "timestep": 9135, "ep_reward": 628.4047241210938, "reward": 0.34787237644195557, "action": 0.7401094436645508}
{"mode": "train", "epochs": 5, "timestep": 9136, "ep_reward": 628.6421508789062, "reward": 0.23745280504226685, "action": 0.7769779562950134}
{"mode": "train", "epochs": 5, "timestep": 9137, "ep_reward": 628.7490844726562, "reward": 0.10691851377487183, "action": 1.5834569931030273}
{"mode": "train", "epochs": 5, "timestep": 9138, "ep_reward": 628.758056640625, "reward": 0.008975327014923096, "action": 1.3069103956222534}
{"mode": "train", "epochs": 5, "timestep": 9139, "ep_reward": 628.9108276367188, "reward": 0.15275877714157104, "action": 1.0086939334869385}
{"mode": "train", "epochs": 5, "timestep": 9140, "ep_reward": 629.2030639648438, "reward": 0.2922644019126892, "action": 0.8760924935340881}
{"mode": "train", "epochs": 5, "timestep": 9141, "ep_reward": 629.633544921875, "reward": 0.4304872155189514, "action": 0.5341232419013977}
{"mode": "train", "epochs": 5, "timestep": 9142, "ep_reward": 630.1929931640625, "reward": 0.5594534873962402, "action": 0.6350149512290955}
{"mode": "train", "epochs": 5, "timestep": 9143, "ep_reward": 630.8592529296875, "reward": 0.666276216506958, "action": 1.254866123199463}
{"mode": "train", "epochs": 5, "timestep": 9144, "ep_reward": 631.603515625, "reward": 0.7442373037338257, "action": 1.5092086791992188}
{"mode": "train", "epochs": 5, "timestep": 9145, "ep_reward": 632.40283203125, "reward": 0.7992904782295227, "action": 0.6624863147735596}
{"mode": "train", "epochs": 5, "timestep": 9146, "ep_reward": 633.24560546875, "reward": 0.8427566289901733, "action": 0.23198211193084717}
{"mode": "train", "epochs": 5, "timestep": 9147, "ep_reward": 634.11767578125, "reward": 0.8720470666885376, "action": 0.8388299345970154}
{"mode": "train", "epochs": 5, "timestep": 9148, "ep_reward": 634.99853515625, "reward": 0.8808643221855164, "action": 1.2199206352233887}
{"mode": "train", "epochs": 5, "timestep": 9149, "ep_reward": 635.8701782226562, "reward": 0.8716482520103455, "action": 0.8388652205467224}
{"mode": "train", "epochs": 5, "timestep": 9150, "ep_reward": 636.7188110351562, "reward": 0.848650336265564, "action": 1.0420666933059692}
{"mode": "train", "epochs": 5, "timestep": 9151, "ep_reward": 637.5220336914062, "reward": 0.8032183647155762, "action": 0.6634608507156372}
{"mode": "train", "epochs": 5, "timestep": 9152, "ep_reward": 638.257568359375, "reward": 0.7355133295059204, "action": 1.0159506797790527}
{"mode": "train", "epochs": 5, "timestep": 9153, "ep_reward": 638.8887329101562, "reward": 0.6311935186386108, "action": 1.668846607208252}
{"mode": "train", "epochs": 5, "timestep": 9154, "ep_reward": 639.366455078125, "reward": 0.47771984338760376, "action": 0.44849640130996704}
{"mode": "train", "epochs": 5, "timestep": 9155, "ep_reward": 639.7026977539062, "reward": 0.3362138867378235, "action": 1.0219403505325317}
{"mode": "train", "epochs": 5, "timestep": 9156, "ep_reward": 639.9260864257812, "reward": 0.223396897315979, "action": 1.6810429096221924}
{"mode": "train", "epochs": 5, "timestep": 9157, "ep_reward": 640.0169067382812, "reward": 0.09080231189727783, "action": 1.0290274620056152}
{"mode": "train", "epochs": 5, "timestep": 9158, "ep_reward": 640.0433959960938, "reward": 0.02647620439529419, "action": 1.1026395559310913}
{"mode": "train", "epochs": 5, "timestep": 9159, "ep_reward": 640.2113037109375, "reward": 0.1679326295852661, "action": 1.0598653554916382}
{"mode": "train", "epochs": 5, "timestep": 9160, "ep_reward": 640.5184326171875, "reward": 0.30710893869400024, "action": 0.7891705632209778}
{"mode": "train", "epochs": 5, "timestep": 9161, "ep_reward": 640.9640502929688, "reward": 0.4456157088279724, "action": 0.7147725820541382}
{"mode": "train", "epochs": 5, "timestep": 9162, "ep_reward": 641.5345458984375, "reward": 0.5705245137214661, "action": 1.055127739906311}
{"mode": "train", "epochs": 5, "timestep": 9163, "ep_reward": 642.2055053710938, "reward": 0.670952558517456, "action": 0.8900635242462158}
{"mode": "train", "epochs": 5, "timestep": 9164, "ep_reward": 642.9562377929688, "reward": 0.7507023811340332, "action": 0.8329079747200012}
{"mode": "train", "epochs": 5, "timestep": 9165, "ep_reward": 643.765380859375, "reward": 0.8091555833816528, "action": 0.9976357817649841}
{"mode": "train", "epochs": 5, "timestep": 9166, "ep_reward": 644.6122436523438, "reward": 0.8468486070632935, "action": 0.8216038346290588}
{"mode": "train", "epochs": 5, "timestep": 9167, "ep_reward": 645.4813232421875, "reward": 0.8690823316574097, "action": 0.8881396651268005}
{"mode": "train", "epochs": 5, "timestep": 9168, "ep_reward": 646.3564453125, "reward": 0.87514728307724, "action": 0.9438042640686035}
{"mode": "train", "epochs": 5, "timestep": 9169, "ep_reward": 647.221435546875, "reward": 0.8649908304214478, "action": 0.6488533020019531}
{"mode": "train", "epochs": 5, "timestep": 9170, "ep_reward": 648.0610961914062, "reward": 0.8396854400634766, "action": 0.3106483221054077}
{"mode": "train", "epochs": 5, "timestep": 9171, "ep_reward": 648.8577880859375, "reward": 0.7966765761375427, "action": 0.6635674238204956}
{"mode": "train", "epochs": 5, "timestep": 9172, "ep_reward": 649.581787109375, "reward": 0.7240290641784668, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 9173, "ep_reward": 650.1827392578125, "reward": 0.6009582281112671, "action": 0.33149194717407227}
{"mode": "train", "epochs": 5, "timestep": 9174, "ep_reward": 650.6414794921875, "reward": 0.4587594270706177, "action": 0.34733474254608154}
{"mode": "train", "epochs": 5, "timestep": 9175, "ep_reward": 650.959228515625, "reward": 0.3177388310432434, "action": 1.7378000020980835}
{"mode": "train", "epochs": 5, "timestep": 9176, "ep_reward": 651.1609497070312, "reward": 0.2017081379890442, "action": 0.08069968223571777}
{"mode": "train", "epochs": 5, "timestep": 9177, "ep_reward": 651.226318359375, "reward": 0.06536048650741577, "action": 1.4403431415557861}
{"mode": "train", "epochs": 5, "timestep": 9178, "ep_reward": 651.2791748046875, "reward": 0.052842676639556885, "action": -0.3341022729873657}
{"mode": "train", "epochs": 5, "timestep": 9179, "ep_reward": 651.4854125976562, "reward": 0.2062298059463501, "action": 0.23177802562713623}
{"mode": "train", "epochs": 5, "timestep": 9180, "ep_reward": 651.8378295898438, "reward": 0.3524364233016968, "action": 1.0336121320724487}
{"mode": "train", "epochs": 5, "timestep": 9181, "ep_reward": 652.3193969726562, "reward": 0.48157912492752075, "action": 1.0799188613891602}
{"mode": "train", "epochs": 5, "timestep": 9182, "ep_reward": 652.9156494140625, "reward": 0.5962563753128052, "action": 1.0271565914154053}
{"mode": "train", "epochs": 5, "timestep": 9183, "ep_reward": 653.607666015625, "reward": 0.6920250654220581, "action": 1.785515308380127}
{"mode": "train", "epochs": 5, "timestep": 9184, "ep_reward": 654.36767578125, "reward": 0.7600142359733582, "action": 1.3463702201843262}
{"mode": "train", "epochs": 5, "timestep": 9185, "ep_reward": 655.1807250976562, "reward": 0.8130490779876709, "action": 0.824019193649292}
{"mode": "train", "epochs": 5, "timestep": 9186, "ep_reward": 656.0331420898438, "reward": 0.8524301052093506, "action": 0.0798298716545105}
{"mode": "train", "epochs": 5, "timestep": 9187, "ep_reward": 656.9143676757812, "reward": 0.8812252879142761, "action": 0.4720914959907532}
{"mode": "train", "epochs": 5, "timestep": 9188, "ep_reward": 657.8065795898438, "reward": 0.892191469669342, "action": 1.7584856748580933}
{"mode": "train", "epochs": 5, "timestep": 9189, "ep_reward": 658.6861572265625, "reward": 0.879570722579956, "action": 1.04265558719635}
{"mode": "train", "epochs": 5, "timestep": 9190, "ep_reward": 659.5426635742188, "reward": 0.8564946055412292, "action": 0.56105637550354}
{"mode": "train", "epochs": 5, "timestep": 9191, "ep_reward": 660.361083984375, "reward": 0.8184221982955933, "action": 0.6633245944976807}
{"mode": "train", "epochs": 5, "timestep": 9192, "ep_reward": 661.1166381835938, "reward": 0.7555516958236694, "action": 1.295881986618042}
{"mode": "train", "epochs": 5, "timestep": 9193, "ep_reward": 661.771240234375, "reward": 0.6546202301979065, "action": 1.212327241897583}
{"mode": "train", "epochs": 5, "timestep": 9194, "ep_reward": 662.2869873046875, "reward": 0.5157256126403809, "action": 0.2038125991821289}
{"mode": "train", "epochs": 5, "timestep": 9195, "ep_reward": 662.6390380859375, "reward": 0.3520733118057251, "action": 1.053168773651123}
{"mode": "train", "epochs": 5, "timestep": 9196, "ep_reward": 662.8814086914062, "reward": 0.24238371849060059, "action": 1.7444524765014648}
{"mode": "train", "epochs": 5, "timestep": 9197, "ep_reward": 662.994384765625, "reward": 0.1129838228225708, "action": 0.593104362487793}
{"mode": "train", "epochs": 5, "timestep": 9198, "ep_reward": 662.9968872070312, "reward": 0.0024996399879455566, "action": 0.9071848392486572}
{"mode": "train", "epochs": 5, "timestep": 9199, "ep_reward": 663.14404296875, "reward": 0.14712762832641602, "action": 0.41948384046554565}
{"mode": "train", "epochs": 5, "timestep": 9200, "ep_reward": 663.4376220703125, "reward": 0.29360753297805786, "action": 1.8929612636566162}
{"mode": "train", "epochs": 5, "timestep": 9201, "ep_reward": 663.8561401367188, "reward": 0.4185275435447693, "action": 0.8716005086898804}
{"mode": "train", "epochs": 5, "timestep": 9202, "ep_reward": 664.401611328125, "reward": 0.545486569404602, "action": 1.3887171745300293}
{"mode": "train", "epochs": 5, "timestep": 9203, "ep_reward": 665.0487060546875, "reward": 0.6471198797225952, "action": 0.5230445861816406}
{"mode": "train", "epochs": 5, "timestep": 9204, "ep_reward": 665.7841796875, "reward": 0.7354569435119629, "action": -0.2946993112564087}
{"mode": "train", "epochs": 5, "timestep": 9205, "ep_reward": 666.5916137695312, "reward": 0.8074041604995728, "action": 1.0404270887374878}
{"mode": "train", "epochs": 5, "timestep": 9206, "ep_reward": 667.4379272460938, "reward": 0.8463180065155029, "action": 1.8120062351226807}
{"mode": "train", "epochs": 5, "timestep": 9207, "ep_reward": 668.3004150390625, "reward": 0.8624703884124756, "action": 0.6344583034515381}
{"mode": "train", "epochs": 5, "timestep": 9208, "ep_reward": 669.1729736328125, "reward": 0.8725854754447937, "action": 0.788840651512146}
{"mode": "train", "epochs": 5, "timestep": 9209, "ep_reward": 670.0382690429688, "reward": 0.8652834892272949, "action": 1.638343334197998}
{"mode": "train", "epochs": 5, "timestep": 9210, "ep_reward": 670.8707275390625, "reward": 0.8324286341667175, "action": 0.3736411929130554}
{"mode": "train", "epochs": 5, "timestep": 9211, "ep_reward": 671.65966796875, "reward": 0.7889108061790466, "action": 0.9083338975906372}
{"mode": "train", "epochs": 5, "timestep": 9212, "ep_reward": 672.3722534179688, "reward": 0.7125735878944397, "action": 1.1450103521347046}
{"mode": "train", "epochs": 5, "timestep": 9213, "ep_reward": 672.9705200195312, "reward": 0.5982873439788818, "action": 1.1738709211349487}
{"mode": "train", "epochs": 5, "timestep": 9214, "ep_reward": 673.4125366210938, "reward": 0.44199419021606445, "action": 1.5706415176391602}
{"mode": "train", "epochs": 5, "timestep": 9215, "ep_reward": 673.7285766601562, "reward": 0.31602972745895386, "action": 1.0603541135787964}
{"mode": "train", "epochs": 5, "timestep": 9216, "ep_reward": 673.9280395507812, "reward": 0.1994333267211914, "action": 1.290507197380066}
{"mode": "train", "epochs": 5, "timestep": 9217, "ep_reward": 673.990966796875, "reward": 0.06295323371887207, "action": 0.5955990552902222}
{"mode": "train", "epochs": 5, "timestep": 9218, "ep_reward": 674.0463256835938, "reward": 0.05533647537231445, "action": 0.9085861444473267}
{"mode": "train", "epochs": 5, "timestep": 9219, "ep_reward": 674.2396240234375, "reward": 0.1932794451713562, "action": 1.477439045906067}
{"mode": "train", "epochs": 5, "timestep": 9220, "ep_reward": 674.5671997070312, "reward": 0.3275644779205322, "action": 0.7802944779396057}
{"mode": "train", "epochs": 5, "timestep": 9221, "ep_reward": 675.0325927734375, "reward": 0.46538347005844116, "action": 1.6264967918395996}
{"mode": "train", "epochs": 5, "timestep": 9222, "ep_reward": 675.6102294921875, "reward": 0.577653706073761, "action": 0.7551581263542175}
{"mode": "train", "epochs": 5, "timestep": 9223, "ep_reward": 676.2893676757812, "reward": 0.6791588664054871, "action": 1.1590170860290527}
{"mode": "train", "epochs": 5, "timestep": 9224, "ep_reward": 677.0419921875, "reward": 0.7526353001594543, "action": 0.4100043773651123}
{"mode": "train", "epochs": 5, "timestep": 9225, "ep_reward": 677.852783203125, "reward": 0.810784637928009, "action": 0.711628794670105}
{"mode": "train", "epochs": 5, "timestep": 9226, "ep_reward": 678.6982421875, "reward": 0.845486044883728, "action": 1.179736614227295}
{"mode": "train", "epochs": 5, "timestep": 9227, "ep_reward": 679.5565795898438, "reward": 0.8583139181137085, "action": 0.7788828611373901}
{"mode": "train", "epochs": 5, "timestep": 9228, "ep_reward": 680.4139404296875, "reward": 0.85735023021698, "action": 0.846411406993866}
{"mode": "train", "epochs": 5, "timestep": 9229, "ep_reward": 681.2511596679688, "reward": 0.8372349143028259, "action": 1.5869872570037842}
{"mode": "train", "epochs": 5, "timestep": 9230, "ep_reward": 682.0388793945312, "reward": 0.7877054214477539, "action": 0.5399501323699951}
{"mode": "train", "epochs": 5, "timestep": 9231, "ep_reward": 682.7596435546875, "reward": 0.7207503318786621, "action": 1.0437053442001343}
{"mode": "train", "epochs": 5, "timestep": 9232, "ep_reward": 683.3734741210938, "reward": 0.6138226985931396, "action": 0.45606380701065063}
{"mode": "train", "epochs": 5, "timestep": 9233, "ep_reward": 683.8482666015625, "reward": 0.47480374574661255, "action": 1.5631184577941895}
{"mode": "train", "epochs": 5, "timestep": 9234, "ep_reward": 684.186279296875, "reward": 0.3380311131477356, "action": 1.1024987697601318}
{"mode": "train", "epochs": 5, "timestep": 9235, "ep_reward": 684.4119262695312, "reward": 0.22564834356307983, "action": 1.3249447345733643}
{"mode": "train", "epochs": 5, "timestep": 9236, "ep_reward": 684.5052490234375, "reward": 0.09334468841552734, "action": 1.018396258354187}
{"mode": "train", "epochs": 5, "timestep": 9237, "ep_reward": 684.5289916992188, "reward": 0.023760676383972168, "action": 1.1874191761016846}
{"mode": "train", "epochs": 5, "timestep": 9238, "ep_reward": 684.694580078125, "reward": 0.1655745506286621, "action": 1.1414724588394165}
{"mode": "train", "epochs": 5, "timestep": 9239, "ep_reward": 684.998291015625, "reward": 0.3037099242210388, "action": 0.6867952346801758}
{"mode": "train", "epochs": 5, "timestep": 9240, "ep_reward": 685.4419555664062, "reward": 0.4436744451522827, "action": 1.4988486766815186}
{"mode": "train", "epochs": 5, "timestep": 9241, "ep_reward": 686.0020751953125, "reward": 0.5601028203964233, "action": 0.9471926093101501}
{"mode": "train", "epochs": 5, "timestep": 9242, "ep_reward": 686.6654663085938, "reward": 0.6633871793746948, "action": 1.6754019260406494}
{"mode": "train", "epochs": 5, "timestep": 9243, "ep_reward": 687.4020385742188, "reward": 0.7365764379501343, "action": 1.454049825668335}
{"mode": "train", "epochs": 5, "timestep": 9244, "ep_reward": 688.1925048828125, "reward": 0.7904512882232666, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 9245, "ep_reward": 689.0116577148438, "reward": 0.8191688656806946, "action": 0.2691000699996948}
{"mode": "train", "epochs": 5, "timestep": 9246, "ep_reward": 689.8557739257812, "reward": 0.844103217124939, "action": 1.7488983869552612}
{"mode": "train", "epochs": 5, "timestep": 9247, "ep_reward": 690.6918334960938, "reward": 0.8360890746116638, "action": 1.528005838394165}
{"mode": "train", "epochs": 5, "timestep": 9248, "ep_reward": 691.5003662109375, "reward": 0.8085384368896484, "action": 0.5447980165481567}
{"mode": "train", "epochs": 5, "timestep": 9249, "ep_reward": 692.2659301757812, "reward": 0.7655594348907471, "action": 1.0556647777557373}
{"mode": "train", "epochs": 5, "timestep": 9250, "ep_reward": 692.9523315429688, "reward": 0.6864291429519653, "action": 0.6293147206306458}
{"mode": "train", "epochs": 5, "timestep": 9251, "ep_reward": 693.5274658203125, "reward": 0.5751161575317383, "action": 1.2894682884216309}
{"mode": "train", "epochs": 5, "timestep": 9252, "ep_reward": 693.9406127929688, "reward": 0.4131436347961426, "action": 0.7994016408920288}
{"mode": "train", "epochs": 5, "timestep": 9253, "ep_reward": 694.25732421875, "reward": 0.3167290687561035, "action": 0.4300791025161743}
{"mode": "train", "epochs": 5, "timestep": 9254, "ep_reward": 694.4575805664062, "reward": 0.2002590298652649, "action": 0.7936314940452576}
{"mode": "train", "epochs": 5, "timestep": 9255, "ep_reward": 694.5213623046875, "reward": 0.06378531455993652, "action": 1.0689438581466675}
{"mode": "train", "epochs": 5, "timestep": 9256, "ep_reward": 694.5757446289062, "reward": 0.05438113212585449, "action": 1.3783026933670044}
{"mode": "train", "epochs": 5, "timestep": 9257, "ep_reward": 694.7678833007812, "reward": 0.19216293096542358, "action": 0.9032384157180786}
{"mode": "train", "epochs": 5, "timestep": 9258, "ep_reward": 695.1013793945312, "reward": 0.33351194858551025, "action": 1.5497689247131348}
{"mode": "train", "epochs": 5, "timestep": 9259, "ep_reward": 695.5623779296875, "reward": 0.4609820246696472, "action": 1.3148164749145508}
{"mode": "train", "epochs": 5, "timestep": 9260, "ep_reward": 696.1396484375, "reward": 0.5772705078125, "action": 1.9049360752105713}
{"mode": "train", "epochs": 5, "timestep": 9261, "ep_reward": 696.806396484375, "reward": 0.6667298078536987, "action": 1.6321742534637451}
{"mode": "train", "epochs": 5, "timestep": 9262, "ep_reward": 697.5435180664062, "reward": 0.7371326088905334, "action": 1.0360429286956787}
{"mode": "train", "epochs": 5, "timestep": 9263, "ep_reward": 698.3341674804688, "reward": 0.7906507253646851, "action": 0.976503849029541}
{"mode": "train", "epochs": 5, "timestep": 9264, "ep_reward": 699.1568603515625, "reward": 0.8226755857467651, "action": 1.1626240015029907}
{"mode": "train", "epochs": 5, "timestep": 9265, "ep_reward": 699.9890747070312, "reward": 0.832241415977478, "action": 1.6426937580108643}
{"mode": "train", "epochs": 5, "timestep": 9266, "ep_reward": 700.8049926757812, "reward": 0.8159481287002563, "action": 1.8874857425689697}
{"mode": "train", "epochs": 5, "timestep": 9267, "ep_reward": 701.5768432617188, "reward": 0.7718710899353027, "action": 1.7833071947097778}
{"mode": "train", "epochs": 5, "timestep": 9268, "ep_reward": 702.2736206054688, "reward": 0.6967639923095703, "action": 0.2565939426422119}
{"mode": "train", "epochs": 5, "timestep": 9269, "ep_reward": 702.8762817382812, "reward": 0.6026431322097778, "action": 0.6794747114181519}
{"mode": "train", "epochs": 5, "timestep": 9270, "ep_reward": 703.3374633789062, "reward": 0.46119749546051025, "action": -0.2554609775543213}
{"mode": "train", "epochs": 5, "timestep": 9271, "ep_reward": 703.6942138671875, "reward": 0.3567352294921875, "action": 1.1137070655822754}
{"mode": "train", "epochs": 5, "timestep": 9272, "ep_reward": 703.9421997070312, "reward": 0.24798035621643066, "action": 1.8165030479431152}
{"mode": "train", "epochs": 5, "timestep": 9273, "ep_reward": 704.0616455078125, "reward": 0.11941653490066528, "action": 1.5201754570007324}
{"mode": "train", "epochs": 5, "timestep": 9274, "ep_reward": 704.056884765625, "reward": -0.004774332046508789, "action": 0.5373556613922119}
{"mode": "train", "epochs": 5, "timestep": 9275, "ep_reward": 704.1976318359375, "reward": 0.1407240629196167, "action": 0.8918432593345642}
{"mode": "train", "epochs": 5, "timestep": 9276, "ep_reward": 704.4788208007812, "reward": 0.28120875358581543, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 9277, "ep_reward": 704.8848266601562, "reward": 0.40600764751434326, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 9278, "ep_reward": 705.4066772460938, "reward": 0.5218648910522461, "action": 1.536659598350525}
{"mode": "train", "epochs": 5, "timestep": 9279, "ep_reward": 706.032470703125, "reward": 0.6257662773132324, "action": 0.3087884187698364}
{"mode": "train", "epochs": 5, "timestep": 9280, "ep_reward": 706.7518310546875, "reward": 0.7193365097045898, "action": 1.6265435218811035}
{"mode": "train", "epochs": 5, "timestep": 9281, "ep_reward": 707.5263061523438, "reward": 0.7744765281677246, "action": 0.9242462515830994}
{"mode": "train", "epochs": 5, "timestep": 9282, "ep_reward": 708.3406982421875, "reward": 0.8144209384918213, "action": 1.662794828414917}
{"mode": "train", "epochs": 5, "timestep": 9283, "ep_reward": 709.1671752929688, "reward": 0.8264939785003662, "action": 1.2494364976882935}
{"mode": "train", "epochs": 5, "timestep": 9284, "ep_reward": 709.9886474609375, "reward": 0.8215016722679138, "action": 0.7550874948501587}
{"mode": "train", "epochs": 5, "timestep": 9285, "ep_reward": 710.7870483398438, "reward": 0.7984098196029663, "action": 0.8898599743843079}
{"mode": "train", "epochs": 5, "timestep": 9286, "ep_reward": 711.5343017578125, "reward": 0.7472313642501831, "action": 1.3690869808197021}
{"mode": "train", "epochs": 5, "timestep": 9287, "ep_reward": 712.19140625, "reward": 0.6571130752563477, "action": 0.975986897945404}
{"mode": "train", "epochs": 5, "timestep": 9288, "ep_reward": 712.7223510742188, "reward": 0.530972957611084, "action": 0.7787022590637207}
{"mode": "train", "epochs": 5, "timestep": 9289, "ep_reward": 713.1190185546875, "reward": 0.39669156074523926, "action": 0.8508796095848083}
{"mode": "train", "epochs": 5, "timestep": 9290, "ep_reward": 713.4155883789062, "reward": 0.2965460419654846, "action": 0.6057380437850952}
{"mode": "train", "epochs": 5, "timestep": 9291, "ep_reward": 713.5917358398438, "reward": 0.17615187168121338, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 9292, "ep_reward": 713.6279907226562, "reward": 0.03623145818710327, "action": 0.24856746196746826}
{"mode": "train", "epochs": 5, "timestep": 9293, "ep_reward": 713.7094116210938, "reward": 0.0814240574836731, "action": 1.961074709892273}
{"mode": "train", "epochs": 5, "timestep": 9294, "ep_reward": 713.9248046875, "reward": 0.21540355682373047, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 9295, "ep_reward": 714.2682495117188, "reward": 0.3434637188911438, "action": 0.5008095502853394}
{"mode": "train", "epochs": 5, "timestep": 9296, "ep_reward": 714.752685546875, "reward": 0.48442602157592773, "action": 0.6464925408363342}
{"mode": "train", "epochs": 5, "timestep": 9297, "ep_reward": 715.3573608398438, "reward": 0.604685366153717, "action": 1.5240870714187622}
{"mode": "train", "epochs": 5, "timestep": 9298, "ep_reward": 716.0499267578125, "reward": 0.6925646066665649, "action": 1.7372219562530518}
{"mode": "train", "epochs": 5, "timestep": 9299, "ep_reward": 716.8062133789062, "reward": 0.7562692761421204, "action": 0.5576505064964294}
{"mode": "train", "epochs": 5, "timestep": 9300, "ep_reward": 717.61572265625, "reward": 0.8094933032989502, "action": 0.9551421403884888}
{"mode": "train", "epochs": 5, "timestep": 9301, "ep_reward": 718.4537963867188, "reward": 0.8380549550056458, "action": 0.9855170845985413}
{"mode": "train", "epochs": 5, "timestep": 9302, "ep_reward": 719.3012084960938, "reward": 0.8473910093307495, "action": 0.8393925428390503}
{"mode": "train", "epochs": 5, "timestep": 9303, "ep_reward": 720.1400756835938, "reward": 0.8388887643814087, "action": 1.5394009351730347}
{"mode": "train", "epochs": 5, "timestep": 9304, "ep_reward": 720.942138671875, "reward": 0.8020921945571899, "action": 1.3535020351409912}
{"mode": "train", "epochs": 5, "timestep": 9305, "ep_reward": 721.6818237304688, "reward": 0.7396634817123413, "action": 1.138351321220398}
{"mode": "train", "epochs": 5, "timestep": 9306, "ep_reward": 722.3272705078125, "reward": 0.6454317569732666, "action": -0.3026841878890991}
{"mode": "train", "epochs": 5, "timestep": 9307, "ep_reward": 722.8590698242188, "reward": 0.5318199992179871, "action": 1.145981788635254}
{"mode": "train", "epochs": 5, "timestep": 9308, "ep_reward": 723.2392578125, "reward": 0.38017648458480835, "action": 1.3334572315216064}
{"mode": "train", "epochs": 5, "timestep": 9309, "ep_reward": 723.5158081054688, "reward": 0.2765249013900757, "action": 0.5279455184936523}
{"mode": "train", "epochs": 5, "timestep": 9310, "ep_reward": 723.6685180664062, "reward": 0.15272271633148193, "action": 1.0952961444854736}
{"mode": "train", "epochs": 5, "timestep": 9311, "ep_reward": 723.677490234375, "reward": 0.0089949369430542, "action": 0.9697698950767517}
{"mode": "train", "epochs": 5, "timestep": 9312, "ep_reward": 723.7845458984375, "reward": 0.10707587003707886, "action": 0.6362326145172119}
{"mode": "train", "epochs": 5, "timestep": 9313, "ep_reward": 724.0346069335938, "reward": 0.25007057189941406, "action": 0.8299344778060913}
{"mode": "train", "epochs": 5, "timestep": 9314, "ep_reward": 724.4246215820312, "reward": 0.38998889923095703, "action": 0.8064857721328735}
{"mode": "train", "epochs": 5, "timestep": 9315, "ep_reward": 724.94482421875, "reward": 0.5201796293258667, "action": 0.9737428426742554}
{"mode": "train", "epochs": 5, "timestep": 9316, "ep_reward": 725.575439453125, "reward": 0.6306300163269043, "action": 0.3082317113876343}
{"mode": "train", "epochs": 5, "timestep": 9317, "ep_reward": 726.30126953125, "reward": 0.725854218006134, "action": 0.9693925380706787}
{"mode": "train", "epochs": 5, "timestep": 9318, "ep_reward": 727.0931396484375, "reward": 0.7918720245361328, "action": 1.503998041152954}
{"mode": "train", "epochs": 5, "timestep": 9319, "ep_reward": 727.9273071289062, "reward": 0.8341403007507324, "action": 1.1221588850021362}
{"mode": "train", "epochs": 5, "timestep": 9320, "ep_reward": 728.7901611328125, "reward": 0.8628829717636108, "action": 1.0812081098556519}
{"mode": "train", "epochs": 5, "timestep": 9321, "ep_reward": 729.6666259765625, "reward": 0.8764607310295105, "action": 1.229469895362854}
{"mode": "train", "epochs": 5, "timestep": 9322, "ep_reward": 730.5404663085938, "reward": 0.8738556504249573, "action": 0.6276212930679321}
{"mode": "train", "epochs": 5, "timestep": 9323, "ep_reward": 731.4005737304688, "reward": 0.8601322174072266, "action": 0.006127715110778809}
{"mode": "train", "epochs": 5, "timestep": 9324, "ep_reward": 732.2344360351562, "reward": 0.8338690996170044, "action": 1.4783860445022583}
{"mode": "train", "epochs": 5, "timestep": 9325, "ep_reward": 733.0057373046875, "reward": 0.7712860107421875, "action": 0.895092248916626}
{"mode": "train", "epochs": 5, "timestep": 9326, "ep_reward": 733.6900634765625, "reward": 0.6843029856681824, "action": 1.7699618339538574}
{"mode": "train", "epochs": 5, "timestep": 9327, "ep_reward": 734.2386474609375, "reward": 0.5485612154006958, "action": 1.8289024829864502}
{"mode": "train", "epochs": 5, "timestep": 9328, "ep_reward": 734.61767578125, "reward": 0.3790034055709839, "action": 1.108285903930664}
{"mode": "train", "epochs": 5, "timestep": 9329, "ep_reward": 734.8927001953125, "reward": 0.27500057220458984, "action": 1.1108797788619995}
{"mode": "train", "epochs": 5, "timestep": 9330, "ep_reward": 735.0437622070312, "reward": 0.151047945022583, "action": 0.668134868144989}
{"mode": "train", "epochs": 5, "timestep": 9331, "ep_reward": 735.05078125, "reward": 0.007006824016571045, "action": 1.0412853956222534}
{"mode": "train", "epochs": 5, "timestep": 9332, "ep_reward": 735.15966796875, "reward": 0.10889267921447754, "action": 0.45162367820739746}
{"mode": "train", "epochs": 5, "timestep": 9333, "ep_reward": 735.4138793945312, "reward": 0.2542330026626587, "action": 0.601488471031189}
{"mode": "train", "epochs": 5, "timestep": 9334, "ep_reward": 735.8102416992188, "reward": 0.3963615894317627, "action": 0.0020255446434020996}
{"mode": "train", "epochs": 5, "timestep": 9335, "ep_reward": 736.3446044921875, "reward": 0.5343672633171082, "action": 0.08731770515441895}
{"mode": "train", "epochs": 5, "timestep": 9336, "ep_reward": 736.9955444335938, "reward": 0.6509160995483398, "action": 0.821943461894989}
{"mode": "train", "epochs": 5, "timestep": 9337, "ep_reward": 737.733154296875, "reward": 0.7376151084899902, "action": 1.056097149848938}
{"mode": "train", "epochs": 5, "timestep": 9338, "ep_reward": 738.5350341796875, "reward": 0.801875650882721, "action": 1.2860020399093628}
{"mode": "train", "epochs": 5, "timestep": 9339, "ep_reward": 739.3815307617188, "reward": 0.8465121388435364, "action": 1.3057712316513062}
{"mode": "train", "epochs": 5, "timestep": 9340, "ep_reward": 740.2575073242188, "reward": 0.8759658336639404, "action": 0.1481282114982605}
{"mode": "train", "epochs": 5, "timestep": 9341, "ep_reward": 741.1577758789062, "reward": 0.9002936482429504, "action": 0.9219817519187927}
{"mode": "train", "epochs": 5, "timestep": 9342, "ep_reward": 742.0645141601562, "reward": 0.9067597985267639, "action": 1.8015332221984863}
{"mode": "train", "epochs": 5, "timestep": 9343, "ep_reward": 742.9596557617188, "reward": 0.8951365947723389, "action": 1.267148733139038}
{"mode": "train", "epochs": 5, "timestep": 9344, "ep_reward": 743.832763671875, "reward": 0.8730921149253845, "action": 1.271844506263733}
{"mode": "train", "epochs": 5, "timestep": 9345, "ep_reward": 744.665771484375, "reward": 0.8329923748970032, "action": 1.1681286096572876}
{"mode": "train", "epochs": 5, "timestep": 9346, "ep_reward": 745.4360961914062, "reward": 0.7703347206115723, "action": 0.7509810328483582}
{"mode": "train", "epochs": 5, "timestep": 9347, "ep_reward": 746.118408203125, "reward": 0.6823252439498901, "action": 1.6770823001861572}
{"mode": "train", "epochs": 5, "timestep": 9348, "ep_reward": 746.6642456054688, "reward": 0.5458253622055054, "action": 1.914106845855713}
{"mode": "train", "epochs": 5, "timestep": 9349, "ep_reward": 747.0335083007812, "reward": 0.36924898624420166, "action": 0.6207530498504639}
{"mode": "train", "epochs": 5, "timestep": 9350, "ep_reward": 747.2966918945312, "reward": 0.2631949186325073, "action": 0.43486207723617554}
{"mode": "train", "epochs": 5, "timestep": 9351, "ep_reward": 747.4337768554688, "reward": 0.1370919942855835, "action": 0.88582444190979}
{"mode": "train", "epochs": 5, "timestep": 9352, "ep_reward": 747.4248046875, "reward": -0.008993983268737793, "action": 1.0581153631210327}
{"mode": "train", "epochs": 5, "timestep": 9353, "ep_reward": 747.5480346679688, "reward": 0.12325483560562134, "action": 0.3418813943862915}
{"mode": "train", "epochs": 5, "timestep": 9354, "ep_reward": 747.8182983398438, "reward": 0.27029305696487427, "action": 0.9880543947219849}
{"mode": "train", "epochs": 5, "timestep": 9355, "ep_reward": 748.22509765625, "reward": 0.40679872035980225, "action": 1.5079011917114258}
{"mode": "train", "epochs": 5, "timestep": 9356, "ep_reward": 748.752197265625, "reward": 0.5271122455596924, "action": 0.5812154412269592}
{"mode": "train", "epochs": 5, "timestep": 9357, "ep_reward": 749.3926391601562, "reward": 0.6404694318771362, "action": 1.4206453561782837}
{"mode": "train", "epochs": 5, "timestep": 9358, "ep_reward": 750.115234375, "reward": 0.7226125001907349, "action": 1.3762952089309692}
{"mode": "train", "epochs": 5, "timestep": 9359, "ep_reward": 750.8993530273438, "reward": 0.7841385006904602, "action": 1.0783054828643799}
{"mode": "train", "epochs": 5, "timestep": 9360, "ep_reward": 751.7277221679688, "reward": 0.8283799886703491, "action": 1.2182097434997559}
{"mode": "train", "epochs": 5, "timestep": 9361, "ep_reward": 752.580810546875, "reward": 0.8530920743942261, "action": 1.5672264099121094}
{"mode": "train", "epochs": 5, "timestep": 9362, "ep_reward": 753.438720703125, "reward": 0.8579268455505371, "action": 0.815297544002533}
{"mode": "train", "epochs": 5, "timestep": 9363, "ep_reward": 754.2904052734375, "reward": 0.8516658544540405, "action": 1.287575602531433}
{"mode": "train", "epochs": 5, "timestep": 9364, "ep_reward": 755.1118774414062, "reward": 0.8214508295059204, "action": 0.6763061881065369}
{"mode": "train", "epochs": 5, "timestep": 9365, "ep_reward": 755.8851928710938, "reward": 0.773294985294342, "action": 0.09784668684005737}
{"mode": "train", "epochs": 5, "timestep": 9366, "ep_reward": 756.5884399414062, "reward": 0.7032637000083923, "action": 1.0594594478607178}
{"mode": "train", "epochs": 5, "timestep": 9367, "ep_reward": 757.17578125, "reward": 0.5873152017593384, "action": 0.5453857183456421}
{"mode": "train", "epochs": 5, "timestep": 9368, "ep_reward": 757.6136474609375, "reward": 0.43787240982055664, "action": 1.5179665088653564}
{"mode": "train", "epochs": 5, "timestep": 9369, "ep_reward": 757.9249267578125, "reward": 0.31129753589630127, "action": 0.5827805995941162}
{"mode": "train", "epochs": 5, "timestep": 9370, "ep_reward": 758.11865234375, "reward": 0.19373774528503418, "action": 1.4132087230682373}
{"mode": "train", "epochs": 5, "timestep": 9371, "ep_reward": 758.1748046875, "reward": 0.056160032749176025, "action": 1.9877398014068604}
{"mode": "train", "epochs": 5, "timestep": 9372, "ep_reward": 758.2366943359375, "reward": 0.06191718578338623, "action": 0.852480411529541}
{"mode": "train", "epochs": 5, "timestep": 9373, "ep_reward": 758.4375610351562, "reward": 0.2008659839630127, "action": 0.7454699873924255}
{"mode": "train", "epochs": 5, "timestep": 9374, "ep_reward": 758.78125, "reward": 0.34366345405578613, "action": 1.9895024299621582}
{"mode": "train", "epochs": 5, "timestep": 9375, "ep_reward": 759.24609375, "reward": 0.46483272314071655, "action": 0.75958251953125}
{"mode": "train", "epochs": 5, "timestep": 9376, "ep_reward": 759.8330688476562, "reward": 0.58698570728302, "action": 0.9291248321533203}
{"mode": "train", "epochs": 5, "timestep": 9377, "ep_reward": 760.5179443359375, "reward": 0.6848610043525696, "action": 1.6993165016174316}
{"mode": "train", "epochs": 5, "timestep": 9378, "ep_reward": 761.2699584960938, "reward": 0.7519931197166443, "action": 1.7070014476776123}
{"mode": "train", "epochs": 5, "timestep": 9379, "ep_reward": 762.068115234375, "reward": 0.798134982585907, "action": 0.5743528604507446}
{"mode": "train", "epochs": 5, "timestep": 9380, "ep_reward": 762.902587890625, "reward": 0.8344874978065491, "action": 0.1850338578224182}
{"mode": "train", "epochs": 5, "timestep": 9381, "ep_reward": 763.7573852539062, "reward": 0.8547681570053101, "action": 1.3497196435928345}
{"mode": "train", "epochs": 5, "timestep": 9382, "ep_reward": 764.603759765625, "reward": 0.8463752865791321, "action": 1.2977129220962524}
{"mode": "train", "epochs": 5, "timestep": 9383, "ep_reward": 765.421875, "reward": 0.8180932402610779, "action": 0.8033403754234314}
{"mode": "train", "epochs": 5, "timestep": 9384, "ep_reward": 766.192138671875, "reward": 0.7702845335006714, "action": 0.23770785331726074}
{"mode": "train", "epochs": 5, "timestep": 9385, "ep_reward": 766.8919067382812, "reward": 0.699796199798584, "action": 0.13319820165634155}
{"mode": "train", "epochs": 5, "timestep": 9386, "ep_reward": 767.4890747070312, "reward": 0.5971464514732361, "action": 0.25018155574798584}
{"mode": "train", "epochs": 5, "timestep": 9387, "ep_reward": 767.944580078125, "reward": 0.4554954767227173, "action": 0.4802057147026062}
{"mode": "train", "epochs": 5, "timestep": 9388, "ep_reward": 768.2637329101562, "reward": 0.3191453814506531, "action": 1.8061022758483887}
{"mode": "train", "epochs": 5, "timestep": 9389, "ep_reward": 768.4671020507812, "reward": 0.20336699485778809, "action": 0.7062127590179443}
{"mode": "train", "epochs": 5, "timestep": 9390, "ep_reward": 768.5343017578125, "reward": 0.06719779968261719, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 9391, "ep_reward": 768.5850830078125, "reward": 0.05077528953552246, "action": 1.20099675655365}
{"mode": "train", "epochs": 5, "timestep": 9392, "ep_reward": 768.7741088867188, "reward": 0.18901735544204712, "action": 0.92386794090271}
{"mode": "train", "epochs": 5, "timestep": 9393, "ep_reward": 769.1041870117188, "reward": 0.3300884962081909, "action": 1.4758410453796387}
{"mode": "train", "epochs": 5, "timestep": 9394, "ep_reward": 769.56298828125, "reward": 0.4587708115577698, "action": 0.7556664943695068}
{"mode": "train", "epochs": 5, "timestep": 9395, "ep_reward": 770.144775390625, "reward": 0.5817955732345581, "action": 0.8012895584106445}
{"mode": "train", "epochs": 5, "timestep": 9396, "ep_reward": 770.8270874023438, "reward": 0.682289719581604, "action": 1.090300440788269}
{"mode": "train", "epochs": 5, "timestep": 9397, "ep_reward": 771.5835571289062, "reward": 0.7564630508422852, "action": 1.7103419303894043}
{"mode": "train", "epochs": 5, "timestep": 9398, "ep_reward": 772.3870849609375, "reward": 0.8035385608673096, "action": 1.4058821201324463}
{"mode": "train", "epochs": 5, "timestep": 9399, "ep_reward": 773.2212524414062, "reward": 0.8341953158378601, "action": 1.0267632007598877}
{"mode": "train", "epochs": 5, "timestep": 9400, "ep_reward": 774.071044921875, "reward": 0.8497920036315918, "action": 0.036596834659576416}
{"mode": "train", "epochs": 5, "timestep": 9401, "ep_reward": 774.9271240234375, "reward": 0.8560535907745361, "action": 0.40953266620635986}
{"mode": "train", "epochs": 5, "timestep": 9402, "ep_reward": 775.7677001953125, "reward": 0.8405471444129944, "action": 1.1371095180511475}
{"mode": "train", "epochs": 5, "timestep": 9403, "ep_reward": 776.5646362304688, "reward": 0.7969278693199158, "action": 0.410713791847229}
{"mode": "train", "epochs": 5, "timestep": 9404, "ep_reward": 777.2988891601562, "reward": 0.7342539429664612, "action": -0.02818441390991211}
{"mode": "train", "epochs": 5, "timestep": 9405, "ep_reward": 777.94482421875, "reward": 0.6459411382675171, "action": 0.6844267845153809}
{"mode": "train", "epochs": 5, "timestep": 9406, "ep_reward": 778.4573974609375, "reward": 0.5125945806503296, "action": 0.6649987697601318}
{"mode": "train", "epochs": 5, "timestep": 9407, "ep_reward": 778.8086547851562, "reward": 0.35127365589141846, "action": 0.6921247243881226}
{"mode": "train", "epochs": 5, "timestep": 9408, "ep_reward": 779.0501708984375, "reward": 0.24150657653808594, "action": 0.9784297943115234}
{"mode": "train", "epochs": 5, "timestep": 9409, "ep_reward": 779.161865234375, "reward": 0.11168849468231201, "action": 1.504403829574585}
{"mode": "train", "epochs": 5, "timestep": 9410, "ep_reward": 779.1656494140625, "reward": 0.00379180908203125, "action": 0.9812881350517273}
{"mode": "train", "epochs": 5, "timestep": 9411, "ep_reward": 779.3139038085938, "reward": 0.14825981855392456, "action": 0.42516374588012695}
{"mode": "train", "epochs": 5, "timestep": 9412, "ep_reward": 779.6088256835938, "reward": 0.2949034571647644, "action": 0.5318413972854614}
{"mode": "train", "epochs": 5, "timestep": 9413, "ep_reward": 780.0445556640625, "reward": 0.43573856353759766, "action": 1.7632038593292236}
{"mode": "train", "epochs": 5, "timestep": 9414, "ep_reward": 780.5941162109375, "reward": 0.5495749711990356, "action": 0.8678079843521118}
{"mode": "train", "epochs": 5, "timestep": 9415, "ep_reward": 781.25, "reward": 0.6558560132980347, "action": 1.366361141204834}
{"mode": "train", "epochs": 5, "timestep": 9416, "ep_reward": 781.9849243164062, "reward": 0.7349288463592529, "action": 0.770699143409729}
{"mode": "train", "epochs": 5, "timestep": 9417, "ep_reward": 782.7830810546875, "reward": 0.7981843948364258, "action": 1.226356029510498}
{"mode": "train", "epochs": 5, "timestep": 9418, "ep_reward": 783.6205444335938, "reward": 0.8374736309051514, "action": 0.21056294441223145}
{"mode": "train", "epochs": 5, "timestep": 9419, "ep_reward": 784.4880981445312, "reward": 0.8675747513771057, "action": 1.7381482124328613}
{"mode": "train", "epochs": 5, "timestep": 9420, "ep_reward": 785.3573608398438, "reward": 0.8692365288734436, "action": -0.16535687446594238}
{"mode": "train", "epochs": 5, "timestep": 9421, "ep_reward": 786.2280883789062, "reward": 0.8706996440887451, "action": 1.6858959197998047}
{"mode": "train", "epochs": 5, "timestep": 9422, "ep_reward": 787.067138671875, "reward": 0.8390617370605469, "action": 0.0716966986656189}
{"mode": "train", "epochs": 5, "timestep": 9423, "ep_reward": 787.8680419921875, "reward": 0.800905168056488, "action": 0.9934369325637817}
{"mode": "train", "epochs": 5, "timestep": 9424, "ep_reward": 788.5958251953125, "reward": 0.7277666330337524, "action": -0.10537517070770264}
{"mode": "train", "epochs": 5, "timestep": 9425, "ep_reward": 789.2314453125, "reward": 0.6355913877487183, "action": 0.9245325326919556}
{"mode": "train", "epochs": 5, "timestep": 9426, "ep_reward": 789.7255859375, "reward": 0.49415361881256104, "action": 1.0255076885223389}
{"mode": "train", "epochs": 5, "timestep": 9427, "ep_reward": 790.0598754882812, "reward": 0.3343043923377991, "action": 0.658502459526062}
{"mode": "train", "epochs": 5, "timestep": 9428, "ep_reward": 790.2810668945312, "reward": 0.2212093472480774, "action": 0.7796538472175598}
{"mode": "train", "epochs": 5, "timestep": 9429, "ep_reward": 790.369140625, "reward": 0.08809083700180054, "action": 1.0801265239715576}
{"mode": "train", "epochs": 5, "timestep": 9430, "ep_reward": 790.3984375, "reward": 0.029308438301086426, "action": 1.3080369234085083}
{"mode": "train", "epochs": 5, "timestep": 9431, "ep_reward": 790.5689086914062, "reward": 0.17045515775680542, "action": 0.7183125019073486}
{"mode": "train", "epochs": 5, "timestep": 9432, "ep_reward": 790.8828125, "reward": 0.31390392780303955, "action": 0.6565055847167969}
{"mode": "train", "epochs": 5, "timestep": 9433, "ep_reward": 791.3357543945312, "reward": 0.4529157876968384, "action": 0.9645583629608154}
{"mode": "train", "epochs": 5, "timestep": 9434, "ep_reward": 791.9095458984375, "reward": 0.5737671852111816, "action": 0.6041984558105469}
{"mode": "train", "epochs": 5, "timestep": 9435, "ep_reward": 792.5877075195312, "reward": 0.6781695485115051, "action": 0.8686670064926147}
{"mode": "train", "epochs": 5, "timestep": 9436, "ep_reward": 793.3447265625, "reward": 0.7570458054542542, "action": 0.4294026494026184}
{"mode": "train", "epochs": 5, "timestep": 9437, "ep_reward": 794.1632080078125, "reward": 0.8184647560119629, "action": 0.1182628870010376}
{"mode": "train", "epochs": 5, "timestep": 9438, "ep_reward": 795.0262451171875, "reward": 0.8630227446556091, "action": 0.8948923349380493}
{"mode": "train", "epochs": 5, "timestep": 9439, "ep_reward": 795.9118041992188, "reward": 0.8855832815170288, "action": 0.8932717442512512}
{"mode": "train", "epochs": 5, "timestep": 9440, "ep_reward": 796.8065185546875, "reward": 0.8947293162345886, "action": 1.2557425498962402}
{"mode": "train", "epochs": 5, "timestep": 9441, "ep_reward": 797.694580078125, "reward": 0.888053834438324, "action": 0.741646945476532}
{"mode": "train", "epochs": 5, "timestep": 9442, "ep_reward": 798.5653686523438, "reward": 0.8707587122917175, "action": 0.5720846652984619}
{"mode": "train", "epochs": 5, "timestep": 9443, "ep_reward": 799.403076171875, "reward": 0.8377057909965515, "action": 0.5578384399414062}
{"mode": "train", "epochs": 5, "timestep": 9444, "ep_reward": 800.1864013671875, "reward": 0.783342719078064, "action": 1.3922315835952759}
{"mode": "train", "epochs": 5, "timestep": 9445, "ep_reward": 800.8782958984375, "reward": 0.6918721795082092, "action": 1.4563219547271729}
{"mode": "train", "epochs": 5, "timestep": 9446, "ep_reward": 801.4405517578125, "reward": 0.5622267127037048, "action": 0.5692760944366455}
{"mode": "train", "epochs": 5, "timestep": 9447, "ep_reward": 801.8447875976562, "reward": 0.40423136949539185, "action": 1.391205906867981}
{"mode": "train", "epochs": 5, "timestep": 9448, "ep_reward": 802.1207275390625, "reward": 0.27592796087265015, "action": 1.1000404357910156}
{"mode": "train", "epochs": 5, "timestep": 9449, "ep_reward": 802.2727661132812, "reward": 0.15204381942749023, "action": 1.3885661363601685}
{"mode": "train", "epochs": 5, "timestep": 9450, "ep_reward": 802.2810668945312, "reward": 0.008325576782226562, "action": 0.0021293163299560547}
{"mode": "train", "epochs": 5, "timestep": 9451, "ep_reward": 802.3887939453125, "reward": 0.10775595903396606, "action": 0.39292168617248535}
{"mode": "train", "epochs": 5, "timestep": 9452, "ep_reward": 802.642578125, "reward": 0.25379031896591187, "action": 0.6661543250083923}
{"mode": "train", "epochs": 5, "timestep": 9453, "ep_reward": 803.0375366210938, "reward": 0.3949497938156128, "action": 1.2212705612182617}
{"mode": "train", "epochs": 5, "timestep": 9454, "ep_reward": 803.5570678710938, "reward": 0.5195138454437256, "action": 0.20034992694854736}
{"mode": "train", "epochs": 5, "timestep": 9455, "ep_reward": 804.1950073242188, "reward": 0.6379598379135132, "action": 1.6175510883331299}
{"mode": "train", "epochs": 5, "timestep": 9456, "ep_reward": 804.91455078125, "reward": 0.7195401191711426, "action": 0.41120946407318115}
{"mode": "train", "epochs": 5, "timestep": 9457, "ep_reward": 805.706298828125, "reward": 0.7917594313621521, "action": 0.8233882784843445}
{"mode": "train", "epochs": 5, "timestep": 9458, "ep_reward": 806.5460815429688, "reward": 0.8397628664970398, "action": 1.5113877058029175}
{"mode": "train", "epochs": 5, "timestep": 9459, "ep_reward": 807.4115600585938, "reward": 0.8654987215995789, "action": 1.0289868116378784}
{"mode": "train", "epochs": 5, "timestep": 9460, "ep_reward": 808.2916870117188, "reward": 0.8801496028900146, "action": 1.5960612297058105}
{"mode": "train", "epochs": 5, "timestep": 9461, "ep_reward": 809.1675415039062, "reward": 0.8758366703987122, "action": 0.3997924327850342}
{"mode": "train", "epochs": 5, "timestep": 9462, "ep_reward": 810.0330200195312, "reward": 0.8654534220695496, "action": 1.5533936023712158}
{"mode": "train", "epochs": 5, "timestep": 9463, "ep_reward": 810.8598022460938, "reward": 0.8267539739608765, "action": 0.715004563331604}
{"mode": "train", "epochs": 5, "timestep": 9464, "ep_reward": 811.6320190429688, "reward": 0.7721960544586182, "action": 0.7952381372451782}
{"mode": "train", "epochs": 5, "timestep": 9465, "ep_reward": 812.3197631835938, "reward": 0.6877465844154358, "action": 0.6918613910675049}
{"mode": "train", "epochs": 5, "timestep": 9466, "ep_reward": 812.888916015625, "reward": 0.5691268444061279, "action": 0.8531966805458069}
{"mode": "train", "epochs": 5, "timestep": 9467, "ep_reward": 813.297607421875, "reward": 0.4087105989456177, "action": 0.7407153844833374}
{"mode": "train", "epochs": 5, "timestep": 9468, "ep_reward": 813.5826416015625, "reward": 0.28501826524734497, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 9469, "ep_reward": 813.7456665039062, "reward": 0.1630319356918335, "action": 0.7624810338020325}
{"mode": "train", "epochs": 5, "timestep": 9470, "ep_reward": 813.7664794921875, "reward": 0.020828723907470703, "action": 0.8031352758407593}
{"mode": "train", "epochs": 5, "timestep": 9471, "ep_reward": 813.8624877929688, "reward": 0.09603840112686157, "action": 1.588748574256897}
{"mode": "train", "epochs": 5, "timestep": 9472, "ep_reward": 814.0906372070312, "reward": 0.2281290888786316, "action": 0.6139813661575317}
{"mode": "train", "epochs": 5, "timestep": 9473, "ep_reward": 814.4638061523438, "reward": 0.3731921911239624, "action": 1.671080470085144}
{"mode": "train", "epochs": 5, "timestep": 9474, "ep_reward": 814.959716796875, "reward": 0.49594026803970337, "action": 0.690049409866333}
{"mode": "train", "epochs": 5, "timestep": 9475, "ep_reward": 815.5736083984375, "reward": 0.6138719320297241, "action": 0.6377135515213013}
{"mode": "train", "epochs": 5, "timestep": 9476, "ep_reward": 816.2825317382812, "reward": 0.7089383602142334, "action": 0.760684609413147}
{"mode": "train", "epochs": 5, "timestep": 9477, "ep_reward": 817.0615844726562, "reward": 0.7790364027023315, "action": 0.6306551694869995}
{"mode": "train", "epochs": 5, "timestep": 9478, "ep_reward": 817.8904418945312, "reward": 0.8288552165031433, "action": 0.28767699003219604}
{"mode": "train", "epochs": 5, "timestep": 9479, "ep_reward": 818.7531127929688, "reward": 0.8626989722251892, "action": 0.37452876567840576}
{"mode": "train", "epochs": 5, "timestep": 9480, "ep_reward": 819.6323852539062, "reward": 0.8792802691459656, "action": 1.063443660736084}
{"mode": "train", "epochs": 5, "timestep": 9481, "ep_reward": 820.5076904296875, "reward": 0.8752846717834473, "action": 0.3208543062210083}
{"mode": "train", "epochs": 5, "timestep": 9482, "ep_reward": 821.3692016601562, "reward": 0.8615356683731079, "action": 0.33316606283187866}
{"mode": "train", "epochs": 5, "timestep": 9483, "ep_reward": 822.1988525390625, "reward": 0.8296694755554199, "action": 1.4678102731704712}
{"mode": "train", "epochs": 5, "timestep": 9484, "ep_reward": 822.9625854492188, "reward": 0.7637298107147217, "action": 1.3931981325149536}
{"mode": "train", "epochs": 5, "timestep": 9485, "ep_reward": 823.629150390625, "reward": 0.666588544845581, "action": 0.6488972306251526}
{"mode": "train", "epochs": 5, "timestep": 9486, "ep_reward": 824.1700439453125, "reward": 0.540905773639679, "action": 0.9136536717414856}
{"mode": "train", "epochs": 5, "timestep": 9487, "ep_reward": 824.5414428710938, "reward": 0.3714117407798767, "action": 1.9810236692428589}
{"mode": "train", "epochs": 5, "timestep": 9488, "ep_reward": 824.803466796875, "reward": 0.26201802492141724, "action": 1.002042531967163}
{"mode": "train", "epochs": 5, "timestep": 9489, "ep_reward": 824.9392700195312, "reward": 0.13581478595733643, "action": 0.3209543824195862}
{"mode": "train", "epochs": 5, "timestep": 9490, "ep_reward": 824.9287719726562, "reward": -0.010527253150939941, "action": 1.1968144178390503}
{"mode": "train", "epochs": 5, "timestep": 9491, "ep_reward": 825.0531005859375, "reward": 0.12434971332550049, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 9492, "ep_reward": 825.3055419921875, "reward": 0.25246018171310425, "action": 0.7622203230857849}
{"mode": "train", "epochs": 5, "timestep": 9493, "ep_reward": 825.701171875, "reward": 0.3956499695777893, "action": 1.032373070716858}
{"mode": "train", "epochs": 5, "timestep": 9494, "ep_reward": 826.2250366210938, "reward": 0.5238677859306335, "action": 1.2460873126983643}
{"mode": "train", "epochs": 5, "timestep": 9495, "ep_reward": 826.8557739257812, "reward": 0.6307345628738403, "action": 1.604741096496582}
{"mode": "train", "epochs": 5, "timestep": 9496, "ep_reward": 827.5674438476562, "reward": 0.7116551399230957, "action": 1.5098265409469604}
{"mode": "train", "epochs": 5, "timestep": 9497, "ep_reward": 828.338623046875, "reward": 0.7712074518203735, "action": 1.5153533220291138}
{"mode": "train", "epochs": 5, "timestep": 9498, "ep_reward": 829.1478271484375, "reward": 0.8092138171195984, "action": 0.893315315246582}
{"mode": "train", "epochs": 5, "timestep": 9499, "ep_reward": 829.9803466796875, "reward": 0.8325055241584778, "action": 0.48478472232818604}
{"mode": "train", "epochs": 5, "timestep": 9500, "ep_reward": 830.8197631835938, "reward": 0.8394120931625366, "action": 1.3260962963104248}
{"mode": "train", "epochs": 5, "timestep": 9501, "ep_reward": 831.6373291015625, "reward": 0.8175936937332153, "action": 1.2596322298049927}
{"mode": "train", "epochs": 5, "timestep": 9502, "ep_reward": 832.408935546875, "reward": 0.7716280817985535, "action": 1.293354868888855}
{"mode": "train", "epochs": 5, "timestep": 9503, "ep_reward": 833.1032104492188, "reward": 0.6942743062973022, "action": 1.0987046957015991}
{"mode": "train", "epochs": 5, "timestep": 9504, "ep_reward": 833.6840209960938, "reward": 0.5808255076408386, "action": 1.7453546524047852}
{"mode": "train", "epochs": 5, "timestep": 9505, "ep_reward": 834.1072998046875, "reward": 0.4232914447784424, "action": 1.6195435523986816}
{"mode": "train", "epochs": 5, "timestep": 9506, "ep_reward": 834.4367065429688, "reward": 0.3294224739074707, "action": -0.010064125061035156}
{"mode": "train", "epochs": 5, "timestep": 9507, "ep_reward": 834.6519165039062, "reward": 0.21519231796264648, "action": 1.779586911201477}
{"mode": "train", "epochs": 5, "timestep": 9508, "ep_reward": 834.7332763671875, "reward": 0.08133751153945923, "action": 0.5814917087554932}
{"mode": "train", "epochs": 5, "timestep": 9509, "ep_reward": 834.769775390625, "reward": 0.03649640083312988, "action": 0.9607570171356201}
{"mode": "train", "epochs": 5, "timestep": 9510, "ep_reward": 834.9464111328125, "reward": 0.17663079500198364, "action": 0.870721161365509}
{"mode": "train", "epochs": 5, "timestep": 9511, "ep_reward": 835.2647094726562, "reward": 0.31831997632980347, "action": 0.2607128620147705}
{"mode": "train", "epochs": 5, "timestep": 9512, "ep_reward": 835.7266235351562, "reward": 0.46190333366394043, "action": 1.469547152519226}
{"mode": "train", "epochs": 5, "timestep": 9513, "ep_reward": 836.3024291992188, "reward": 0.5757930278778076, "action": 1.2656095027923584}
{"mode": "train", "epochs": 5, "timestep": 9514, "ep_reward": 836.9754638671875, "reward": 0.6730313897132874, "action": 0.896084189414978}
{"mode": "train", "epochs": 5, "timestep": 9515, "ep_reward": 837.7273559570312, "reward": 0.7518900632858276, "action": 1.3584647178649902}
{"mode": "train", "epochs": 5, "timestep": 9516, "ep_reward": 838.5322265625, "reward": 0.8048933744430542, "action": 0.4474039077758789}
{"mode": "train", "epochs": 5, "timestep": 9517, "ep_reward": 839.3787841796875, "reward": 0.8465631008148193, "action": 0.817345142364502}
{"mode": "train", "epochs": 5, "timestep": 9518, "ep_reward": 840.2461547851562, "reward": 0.8673787117004395, "action": 1.245835542678833}
{"mode": "train", "epochs": 5, "timestep": 9519, "ep_reward": 841.1148071289062, "reward": 0.8686566948890686, "action": 1.3318438529968262}
{"mode": "train", "epochs": 5, "timestep": 9520, "ep_reward": 841.9669799804688, "reward": 0.852191150188446, "action": 1.7264028787612915}
{"mode": "train", "epochs": 5, "timestep": 9521, "ep_reward": 842.7786254882812, "reward": 0.8116416931152344, "action": 0.7039788365364075}
{"mode": "train", "epochs": 5, "timestep": 9522, "ep_reward": 843.5341186523438, "reward": 0.7554726004600525, "action": 0.841587483882904}
{"mode": "train", "epochs": 5, "timestep": 9523, "ep_reward": 844.2008666992188, "reward": 0.6667547225952148, "action": 1.1016175746917725}
{"mode": "train", "epochs": 5, "timestep": 9524, "ep_reward": 844.7373046875, "reward": 0.5364466309547424, "action": 1.3604955673217773}
{"mode": "train", "epochs": 5, "timestep": 9525, "ep_reward": 845.1156616210938, "reward": 0.37836945056915283, "action": 1.4476962089538574}
{"mode": "train", "epochs": 5, "timestep": 9526, "ep_reward": 845.3900146484375, "reward": 0.274349570274353, "action": 0.6347219944000244}
{"mode": "train", "epochs": 5, "timestep": 9527, "ep_reward": 845.5402221679688, "reward": 0.1502123475074768, "action": 0.7718712091445923}
{"mode": "train", "epochs": 5, "timestep": 9528, "ep_reward": 845.5462036132812, "reward": 0.005973160266876221, "action": 1.559291124343872}
{"mode": "train", "epochs": 5, "timestep": 9529, "ep_reward": 845.6559448242188, "reward": 0.1097375750541687, "action": 0.7076578140258789}
{"mode": "train", "epochs": 5, "timestep": 9530, "ep_reward": 845.9078979492188, "reward": 0.2519260048866272, "action": 0.7220087051391602}
{"mode": "train", "epochs": 5, "timestep": 9531, "ep_reward": 846.3010864257812, "reward": 0.3931996822357178, "action": 0.9864986538887024}
{"mode": "train", "epochs": 5, "timestep": 9532, "ep_reward": 846.822021484375, "reward": 0.5209251642227173, "action": 1.2618045806884766}
{"mode": "train", "epochs": 5, "timestep": 9533, "ep_reward": 847.4501953125, "reward": 0.628160834312439, "action": 1.230327844619751}
{"mode": "train", "epochs": 5, "timestep": 9534, "ep_reward": 848.1648559570312, "reward": 0.7146525382995605, "action": 1.7635490894317627}
{"mode": "train", "epochs": 5, "timestep": 9535, "ep_reward": 848.9395751953125, "reward": 0.7747076749801636, "action": 0.34743553400039673}
{"mode": "train", "epochs": 5, "timestep": 9536, "ep_reward": 849.7669677734375, "reward": 0.8274073004722595, "action": 1.2737293243408203}
{"mode": "train", "epochs": 5, "timestep": 9537, "ep_reward": 850.6199340820312, "reward": 0.852947473526001, "action": 0.9396684765815735}
{"mode": "train", "epochs": 5, "timestep": 9538, "ep_reward": 851.4844360351562, "reward": 0.8644866943359375, "action": 0.9761998057365417}
{"mode": "train", "epochs": 5, "timestep": 9539, "ep_reward": 852.3433837890625, "reward": 0.8589337468147278, "action": 0.6802141070365906}
{"mode": "train", "epochs": 5, "timestep": 9540, "ep_reward": 853.1810302734375, "reward": 0.8376486301422119, "action": 1.1544567346572876}
{"mode": "train", "epochs": 5, "timestep": 9541, "ep_reward": 853.970947265625, "reward": 0.7899162173271179, "action": 1.0812898874282837}
{"mode": "train", "epochs": 5, "timestep": 9542, "ep_reward": 854.6854858398438, "reward": 0.7145504951477051, "action": 1.0292085409164429}
{"mode": "train", "epochs": 5, "timestep": 9543, "ep_reward": 855.289794921875, "reward": 0.6043391227722168, "action": 1.5595905780792236}
{"mode": "train", "epochs": 5, "timestep": 9544, "ep_reward": 855.7343139648438, "reward": 0.444537878036499, "action": 1.2243363857269287}
{"mode": "train", "epochs": 5, "timestep": 9545, "ep_reward": 856.0602416992188, "reward": 0.3259086012840271, "action": -0.12891149520874023}
{"mode": "train", "epochs": 5, "timestep": 9546, "ep_reward": 856.2714233398438, "reward": 0.2111823558807373, "action": 0.5920748710632324}
{"mode": "train", "epochs": 5, "timestep": 9547, "ep_reward": 856.3477172851562, "reward": 0.07629472017288208, "action": 1.8100277185440063}
{"mode": "train", "epochs": 5, "timestep": 9548, "ep_reward": 856.3892822265625, "reward": 0.04158353805541992, "action": 0.44125640392303467}
{"mode": "train", "epochs": 5, "timestep": 9549, "ep_reward": 856.57421875, "reward": 0.1849178671836853, "action": 1.3918092250823975}
{"mode": "train", "epochs": 5, "timestep": 9550, "ep_reward": 856.8936767578125, "reward": 0.319449245929718, "action": 0.324509859085083}
{"mode": "train", "epochs": 5, "timestep": 9551, "ep_reward": 857.3563232421875, "reward": 0.462624728679657, "action": 1.2985961437225342}
{"mode": "train", "epochs": 5, "timestep": 9552, "ep_reward": 857.9348754882812, "reward": 0.5785316228866577, "action": 0.6345754265785217}
{"mode": "train", "epochs": 5, "timestep": 9553, "ep_reward": 858.616455078125, "reward": 0.681578516960144, "action": 1.0660581588745117}
{"mode": "train", "epochs": 5, "timestep": 9554, "ep_reward": 859.3736572265625, "reward": 0.7572274208068848, "action": 1.0389639139175415}
{"mode": "train", "epochs": 5, "timestep": 9555, "ep_reward": 860.1856689453125, "reward": 0.812019407749176, "action": 1.04569673538208}
{"mode": "train", "epochs": 5, "timestep": 9556, "ep_reward": 861.0335693359375, "reward": 0.8478870987892151, "action": 0.5550864934921265}
{"mode": "train", "epochs": 5, "timestep": 9557, "ep_reward": 861.9043579101562, "reward": 0.8707611560821533, "action": 1.6878646612167358}
{"mode": "train", "epochs": 5, "timestep": 9558, "ep_reward": 862.7731323242188, "reward": 0.8687782883644104, "action": 0.5402287244796753}
{"mode": "train", "epochs": 5, "timestep": 9559, "ep_reward": 863.6329345703125, "reward": 0.8598145842552185, "action": 1.4860284328460693}
{"mode": "train", "epochs": 5, "timestep": 9560, "ep_reward": 864.45654296875, "reward": 0.8235803246498108, "action": 0.3964961767196655}
{"mode": "train", "epochs": 5, "timestep": 9561, "ep_reward": 865.2306518554688, "reward": 0.7741326689720154, "action": 1.2492969036102295}
{"mode": "train", "epochs": 5, "timestep": 9562, "ep_reward": 865.9168701171875, "reward": 0.6861886978149414, "action": 1.5734469890594482}
{"mode": "train", "epochs": 5, "timestep": 9563, "ep_reward": 866.4725952148438, "reward": 0.5557239055633545, "action": 0.5514532923698425}
{"mode": "train", "epochs": 5, "timestep": 9564, "ep_reward": 866.8695068359375, "reward": 0.39688271284103394, "action": 2.0}
{"mode": "train", "epochs": 5, "timestep": 9565, "ep_reward": 867.157470703125, "reward": 0.2879846692085266, "action": 1.7356672286987305}
{"mode": "train", "epochs": 5, "timestep": 9566, "ep_reward": 867.3239135742188, "reward": 0.16645967960357666, "action": 0.7190161347389221}
{"mode": "train", "epochs": 5, "timestep": 9567, "ep_reward": 867.3485717773438, "reward": 0.024641871452331543, "action": 1.6479456424713135}
{"mode": "train", "epochs": 5, "timestep": 9568, "ep_reward": 867.4410400390625, "reward": 0.09246116876602173, "action": 0.8464793562889099}
{"mode": "train", "epochs": 5, "timestep": 9569, "ep_reward": 867.6734008789062, "reward": 0.2323836088180542, "action": 1.1269867420196533}
{"mode": "train", "epochs": 5, "timestep": 9570, "ep_reward": 868.043212890625, "reward": 0.3698214292526245, "action": 0.2627944350242615}
{"mode": "train", "epochs": 5, "timestep": 9571, "ep_reward": 868.5523071289062, "reward": 0.5090650916099548, "action": 0.40192312002182007}
{"mode": "train", "epochs": 5, "timestep": 9572, "ep_reward": 869.1795654296875, "reward": 0.6272656917572021, "action": 1.3929495811462402}
{"mode": "train", "epochs": 5, "timestep": 9573, "ep_reward": 869.8927001953125, "reward": 0.7131199836730957, "action": 0.6097550392150879}
{"mode": "train", "epochs": 5, "timestep": 9574, "ep_reward": 870.677978515625, "reward": 0.7852654457092285, "action": 0.6151001453399658}
{"mode": "train", "epochs": 5, "timestep": 9575, "ep_reward": 871.5145874023438, "reward": 0.8366201519966125, "action": 1.0193428993225098}
{"mode": "train", "epochs": 5, "timestep": 9576, "ep_reward": 872.3816528320312, "reward": 0.8670364022254944, "action": 1.940829873085022}
{"mode": "train", "epochs": 5, "timestep": 9577, "ep_reward": 873.2571411132812, "reward": 0.8754706382751465, "action": 1.3458929061889648}
{"mode": "train", "epochs": 5, "timestep": 9578, "ep_reward": 874.1309814453125, "reward": 0.8738598823547363, "action": 0.8737525343894958}
{"mode": "train", "epochs": 5, "timestep": 9579, "ep_reward": 874.9910278320312, "reward": 0.8600174188613892, "action": 0.5402345061302185}
{"mode": "train", "epochs": 5, "timestep": 9580, "ep_reward": 875.82177734375, "reward": 0.8307297229766846, "action": 0.12364321947097778}
{"mode": "train", "epochs": 5, "timestep": 9581, "ep_reward": 876.6055297851562, "reward": 0.7837519645690918, "action": 0.8004130721092224}
{"mode": "train", "epochs": 5, "timestep": 9582, "ep_reward": 877.30810546875, "reward": 0.7025980949401855, "action": 1.3838021755218506}
{"mode": "train", "epochs": 5, "timestep": 9583, "ep_reward": 877.8870849609375, "reward": 0.5789806842803955, "action": 0.24086487293243408}
{"mode": "train", "epochs": 5, "timestep": 9584, "ep_reward": 878.3181762695312, "reward": 0.4311167001724243, "action": 1.515589952468872}
{"mode": "train", "epochs": 5, "timestep": 9585, "ep_reward": 878.6127319335938, "reward": 0.2945353388786316, "action": 0.8117061257362366}
{"mode": "train", "epochs": 5, "timestep": 9586, "ep_reward": 878.7867431640625, "reward": 0.1740044355392456, "action": 0.7358038425445557}
{"mode": "train", "epochs": 5, "timestep": 9587, "ep_reward": 878.8202514648438, "reward": 0.03348284959793091, "action": 0.7769392728805542}
{"mode": "train", "epochs": 5, "timestep": 9588, "ep_reward": 878.9044799804688, "reward": 0.08422189950942993, "action": 0.896753191947937}
{"mode": "train", "epochs": 5, "timestep": 9589, "ep_reward": 879.1278076171875, "reward": 0.22330951690673828, "action": 0.7624225616455078}
{"mode": "train", "epochs": 5, "timestep": 9590, "ep_reward": 879.4932861328125, "reward": 0.3654709458351135, "action": 1.3978416919708252}
{"mode": "train", "epochs": 5, "timestep": 9591, "ep_reward": 879.9848022460938, "reward": 0.4915076494216919, "action": 1.719214677810669}
{"mode": "train", "epochs": 5, "timestep": 9592, "ep_reward": 880.5834350585938, "reward": 0.5986289978027344, "action": 1.5463478565216064}
{"mode": "train", "epochs": 5, "timestep": 9593, "ep_reward": 881.2708740234375, "reward": 0.6874622106552124, "action": 1.8117831945419312}
{"mode": "train", "epochs": 5, "timestep": 9594, "ep_reward": 882.0223388671875, "reward": 0.7514674663543701, "action": 0.8496026992797852}
{"mode": "train", "epochs": 5, "timestep": 9595, "ep_reward": 882.8251953125, "reward": 0.8028680086135864, "action": 1.2564572095870972}
