{"mode": "train", "epochs": 1, "timestep": 1, "ep_reward": 0.9525167942047119, "reward": 0.9525167942047119, "action": 0.4974375367164612}
{"mode": "train", "epochs": 1, "timestep": 2, "ep_reward": 1.8906300067901611, "reward": 0.938113272190094, "action": -0.3193070888519287}
{"mode": "train", "epochs": 1, "timestep": 3, "ep_reward": 2.8075287342071533, "reward": 0.916898787021637, "action": -0.13784828782081604}
{"mode": "train", "epochs": 1, "timestep": 4, "ep_reward": 3.692248582839966, "reward": 0.8847198486328125, "action": -0.6671757698059082}
{"mode": "train", "epochs": 1, "timestep": 5, "ep_reward": 4.535121917724609, "reward": 0.8428733944892883, "action": -0.6879284381866455}
{"mode": "train", "epochs": 1, "timestep": 6, "ep_reward": 5.321985721588135, "reward": 0.7868636250495911, "action": -0.8889577388763428}
{"mode": "train", "epochs": 1, "timestep": 7, "ep_reward": 6.037909984588623, "reward": 0.7159241437911987, "action": -0.908950686454773}
{"mode": "train", "epochs": 1, "timestep": 8, "ep_reward": 6.665557384490967, "reward": 0.6276472806930542, "action": -0.4885571300983429}
{"mode": "train", "epochs": 1, "timestep": 9, "ep_reward": 7.18268346786499, "reward": 0.517126202583313, "action": -0.39766842126846313}
{"mode": "train", "epochs": 1, "timestep": 10, "ep_reward": 7.572327613830566, "reward": 0.38964396715164185, "action": 0.2899406850337982}
{"mode": "train", "epochs": 1, "timestep": 11, "ep_reward": 7.814688205718994, "reward": 0.2423606514930725, "action": -0.25979581475257874}
{"mode": "train", "epochs": 1, "timestep": 12, "ep_reward": 7.914575576782227, "reward": 0.09988713264465332, "action": -1.188008189201355}
{"mode": "train", "epochs": 1, "timestep": 13, "ep_reward": 8.151208877563477, "reward": 0.23663330078125, "action": -0.3275028169155121}
{"mode": "train", "epochs": 1, "timestep": 14, "ep_reward": 8.51506233215332, "reward": 0.3638538122177124, "action": -1.1029175519943237}
{"mode": "train", "epochs": 1, "timestep": 15, "ep_reward": 9.008005142211914, "reward": 0.49294257164001465, "action": -0.041113972663879395}
{"mode": "train", "epochs": 1, "timestep": 16, "ep_reward": 9.607272148132324, "reward": 0.5992673635482788, "action": -0.8139733672142029}
{"mode": "train", "epochs": 1, "timestep": 17, "ep_reward": 10.302948951721191, "reward": 0.6956765651702881, "action": -0.7081363201141357}
{"mode": "train", "epochs": 1, "timestep": 18, "ep_reward": 11.074155807495117, "reward": 0.7712068557739258, "action": -0.5641698241233826}
{"mode": "train", "epochs": 1, "timestep": 19, "ep_reward": 11.900630950927734, "reward": 0.8264753818511963, "action": -0.34753483533859253}
{"mode": "train", "epochs": 1, "timestep": 20, "ep_reward": 12.764081001281738, "reward": 0.8634496331214905, "action": -0.4425998628139496}
{"mode": "train", "epochs": 1, "timestep": 21, "ep_reward": 13.649128913879395, "reward": 0.8850481510162354, "action": -0.38280922174453735}
{"mode": "train", "epochs": 1, "timestep": 22, "ep_reward": 14.541086196899414, "reward": 0.8919570446014404, "action": -0.34849512577056885}
{"mode": "train", "epochs": 1, "timestep": 23, "ep_reward": 15.425869941711426, "reward": 0.8847840428352356, "action": 0.2037207931280136}
{"mode": "train", "epochs": 1, "timestep": 24, "ep_reward": 16.291011810302734, "reward": 0.865141749382019, "action": 0.23219823837280273}
{"mode": "train", "epochs": 1, "timestep": 25, "ep_reward": 17.123140335083008, "reward": 0.8321290016174316, "action": 0.025765080004930496}
{"mode": "train", "epochs": 1, "timestep": 26, "ep_reward": 17.905832290649414, "reward": 0.7826924324035645, "action": 0.18955087661743164}
{"mode": "train", "epochs": 1, "timestep": 27, "ep_reward": 18.622779846191406, "reward": 0.7169484496116638, "action": -0.06904225796461105}
{"mode": "train", "epochs": 1, "timestep": 28, "ep_reward": 19.253507614135742, "reward": 0.6307277679443359, "action": 0.7112687826156616}
{"mode": "train", "epochs": 1, "timestep": 29, "ep_reward": 19.788223266601562, "reward": 0.5347161293029785, "action": 0.4974192678928375}
{"mode": "train", "epochs": 1, "timestep": 30, "ep_reward": 20.212310791015625, "reward": 0.4240879416465759, "action": 0.5246663689613342}
{"mode": "train", "epochs": 1, "timestep": 31, "ep_reward": 20.5185546875, "reward": 0.30624449253082275, "action": 0.062251463532447815}
{"mode": "train", "epochs": 1, "timestep": 32, "ep_reward": 20.6998291015625, "reward": 0.18127351999282837, "action": 0.29899460077285767}
{"mode": "train", "epochs": 1, "timestep": 33, "ep_reward": 20.967945098876953, "reward": 0.2681151032447815, "action": -0.5270965695381165}
{"mode": "train", "epochs": 1, "timestep": 34, "ep_reward": 21.34221839904785, "reward": 0.37427401542663574, "action": 0.31591495871543884}
{"mode": "train", "epochs": 1, "timestep": 35, "ep_reward": 21.827911376953125, "reward": 0.48569369316101074, "action": 0.3947851061820984}
{"mode": "train", "epochs": 1, "timestep": 36, "ep_reward": 22.41590118408203, "reward": 0.5879902839660645, "action": 0.928680956363678}
{"mode": "train", "epochs": 1, "timestep": 37, "ep_reward": 23.094852447509766, "reward": 0.6789513826370239, "action": 0.28918197751045227}
{"mode": "train", "epochs": 1, "timestep": 38, "ep_reward": 23.842727661132812, "reward": 0.7478748559951782, "action": -0.03783464431762695}
{"mode": "train", "epochs": 1, "timestep": 39, "ep_reward": 24.641408920288086, "reward": 0.7986818552017212, "action": 0.15549598634243011}
{"mode": "train", "epochs": 1, "timestep": 40, "ep_reward": 25.475826263427734, "reward": 0.8344182968139648, "action": 0.2640320956707001}
{"mode": "train", "epochs": 1, "timestep": 41, "ep_reward": 26.33053207397461, "reward": 0.8547050952911377, "action": 0.8193211555480957}
{"mode": "train", "epochs": 1, "timestep": 42, "ep_reward": 27.189552307128906, "reward": 0.8590192794799805, "action": 0.043298378586769104}
{"mode": "train", "epochs": 1, "timestep": 43, "ep_reward": 28.037384033203125, "reward": 0.8478326797485352, "action": -0.4317627251148224}
{"mode": "train", "epochs": 1, "timestep": 44, "ep_reward": 28.861209869384766, "reward": 0.8238258361816406, "action": 0.3162509799003601}
{"mode": "train", "epochs": 1, "timestep": 45, "ep_reward": 29.642885208129883, "reward": 0.7816747426986694, "action": -0.7155202031135559}
{"mode": "train", "epochs": 1, "timestep": 46, "ep_reward": 30.37165641784668, "reward": 0.7287704944610596, "action": -0.07857123017311096}
{"mode": "train", "epochs": 1, "timestep": 47, "ep_reward": 31.02773666381836, "reward": 0.6560810804367065, "action": -0.25123077630996704}
{"mode": "train", "epochs": 1, "timestep": 48, "ep_reward": 31.596172332763672, "reward": 0.5684359073638916, "action": 0.537216305732727}
{"mode": "train", "epochs": 1, "timestep": 49, "ep_reward": 32.05438232421875, "reward": 0.45820868015289307, "action": -0.07301226258277893}
{"mode": "train", "epochs": 1, "timestep": 50, "ep_reward": 32.39720153808594, "reward": 0.34282100200653076, "action": 0.467225581407547}
{"mode": "train", "epochs": 1, "timestep": 51, "ep_reward": 32.613609313964844, "reward": 0.21640729904174805, "action": 0.6949917674064636}
{"mode": "train", "epochs": 1, "timestep": 52, "ep_reward": 32.862545013427734, "reward": 0.24893414974212646, "action": -0.7805324792861938}
{"mode": "train", "epochs": 1, "timestep": 53, "ep_reward": 33.22785568237305, "reward": 0.36530935764312744, "action": -0.41528183221817017}
{"mode": "train", "epochs": 1, "timestep": 54, "ep_reward": 33.70199966430664, "reward": 0.4741436839103699, "action": -0.2512941360473633}
{"mode": "train", "epochs": 1, "timestep": 55, "ep_reward": 34.274993896484375, "reward": 0.5729936361312866, "action": -0.655883252620697}
{"mode": "train", "epochs": 1, "timestep": 56, "ep_reward": 34.936283111572266, "reward": 0.6612908840179443, "action": -1.4345358610153198}
{"mode": "train", "epochs": 1, "timestep": 57, "ep_reward": 35.67193603515625, "reward": 0.7356517910957336, "action": 0.18352621793746948}
{"mode": "train", "epochs": 1, "timestep": 58, "ep_reward": 36.45580291748047, "reward": 0.7838661074638367, "action": -0.3284141421318054}
{"mode": "train", "epochs": 1, "timestep": 59, "ep_reward": 37.273929595947266, "reward": 0.8181279897689819, "action": -0.7949990034103394}
{"mode": "train", "epochs": 1, "timestep": 60, "ep_reward": 38.10987854003906, "reward": 0.8359503149986267, "action": 0.41004714369773865}
{"mode": "train", "epochs": 1, "timestep": 61, "ep_reward": 38.94757080078125, "reward": 0.8376907110214233, "action": 0.6546068787574768}
{"mode": "train", "epochs": 1, "timestep": 62, "ep_reward": 39.77482223510742, "reward": 0.8272514343261719, "action": 0.29719680547714233}
{"mode": "train", "epochs": 1, "timestep": 63, "ep_reward": 40.57777404785156, "reward": 0.8029507398605347, "action": -0.2894165813922882}
{"mode": "train", "epochs": 1, "timestep": 64, "ep_reward": 41.3385124206543, "reward": 0.760739266872406, "action": 0.38311532139778137}
{"mode": "train", "epochs": 1, "timestep": 65, "ep_reward": 42.043968200683594, "reward": 0.7054556608200073, "action": -0.14978498220443726}
{"mode": "train", "epochs": 1, "timestep": 66, "ep_reward": 42.67446517944336, "reward": 0.630496621131897, "action": -0.08614510297775269}
{"mode": "train", "epochs": 1, "timestep": 67, "ep_reward": 43.21409225463867, "reward": 0.5396277904510498, "action": -0.6849663257598877}
{"mode": "train", "epochs": 1, "timestep": 68, "ep_reward": 43.642574310302734, "reward": 0.428483784198761, "action": 1.0360196828842163}
{"mode": "train", "epochs": 1, "timestep": 69, "ep_reward": 43.97016143798828, "reward": 0.3275877833366394, "action": 0.34931355714797974}
{"mode": "train", "epochs": 1, "timestep": 70, "ep_reward": 44.1897087097168, "reward": 0.21954822540283203, "action": 0.6077462434768677}
{"mode": "train", "epochs": 1, "timestep": 71, "ep_reward": 44.496028900146484, "reward": 0.3063203692436218, "action": 0.2982630729675293}
{"mode": "train", "epochs": 1, "timestep": 72, "ep_reward": 44.902198791503906, "reward": 0.40617090463638306, "action": 0.5676612257957458}
{"mode": "train", "epochs": 1, "timestep": 73, "ep_reward": 45.405738830566406, "reward": 0.5035387277603149, "action": -0.10495539009571075}
{"mode": "train", "epochs": 1, "timestep": 74, "ep_reward": 45.993309020996094, "reward": 0.5875685811042786, "action": 0.11155861616134644}
{"mode": "train", "epochs": 1, "timestep": 75, "ep_reward": 46.65519332885742, "reward": 0.6618841886520386, "action": -0.1850922703742981}
{"mode": "train", "epochs": 1, "timestep": 76, "ep_reward": 47.376407623291016, "reward": 0.7212124466896057, "action": 0.2959511876106262}
{"mode": "train", "epochs": 1, "timestep": 77, "ep_reward": 48.1440544128418, "reward": 0.767647922039032, "action": -0.47249120473861694}
{"mode": "train", "epochs": 1, "timestep": 78, "ep_reward": 48.94117736816406, "reward": 0.7971237897872925, "action": 0.2563582956790924}
{"mode": "train", "epochs": 1, "timestep": 79, "ep_reward": 49.75453186035156, "reward": 0.813355565071106, "action": -0.4376416504383087}
{"mode": "train", "epochs": 1, "timestep": 80, "ep_reward": 50.569427490234375, "reward": 0.8148945569992065, "action": -0.22891058027744293}
{"mode": "train", "epochs": 1, "timestep": 81, "ep_reward": 51.37213897705078, "reward": 0.8027129173278809, "action": -0.18221014738082886}
{"mode": "train", "epochs": 1, "timestep": 82, "ep_reward": 52.14805603027344, "reward": 0.7759186029434204, "action": -1.1467366218566895}
{"mode": "train", "epochs": 1, "timestep": 83, "ep_reward": 52.88788604736328, "reward": 0.7398291826248169, "action": -0.21703791618347168}
{"mode": "train", "epochs": 1, "timestep": 84, "ep_reward": 53.57400894165039, "reward": 0.6861215829849243, "action": -0.567412257194519}
{"mode": "train", "epochs": 1, "timestep": 85, "ep_reward": 54.19459533691406, "reward": 0.6205851435661316, "action": -0.07005831599235535}
{"mode": "train", "epochs": 1, "timestep": 86, "ep_reward": 54.73306655883789, "reward": 0.5384724140167236, "action": -0.25232750177383423}
{"mode": "train", "epochs": 1, "timestep": 87, "ep_reward": 55.18006134033203, "reward": 0.4469958543777466, "action": -0.20195768773555756}
{"mode": "train", "epochs": 1, "timestep": 88, "ep_reward": 55.52865219116211, "reward": 0.3485925793647766, "action": -0.6776372790336609}
{"mode": "train", "epochs": 1, "timestep": 89, "ep_reward": 55.78303909301758, "reward": 0.2543860673904419, "action": -0.6515203714370728}
{"mode": "train", "epochs": 1, "timestep": 90, "ep_reward": 56.10791015625, "reward": 0.3248724341392517, "action": 0.014473378658294678}
{"mode": "train", "epochs": 1, "timestep": 91, "ep_reward": 56.52098846435547, "reward": 0.4130767583847046, "action": 0.18851113319396973}
{"mode": "train", "epochs": 1, "timestep": 92, "ep_reward": 57.01841354370117, "reward": 0.4974237084388733, "action": -0.33805346488952637}
{"mode": "train", "epochs": 1, "timestep": 93, "ep_reward": 57.596622467041016, "reward": 0.5782100558280945, "action": -1.3499386310577393}
{"mode": "train", "epochs": 1, "timestep": 94, "ep_reward": 58.248008728027344, "reward": 0.651386559009552, "action": -1.567850112915039}
{"mode": "train", "epochs": 1, "timestep": 95, "ep_reward": 58.954734802246094, "reward": 0.7067252397537231, "action": -0.24694494903087616}
{"mode": "train", "epochs": 1, "timestep": 96, "ep_reward": 59.6948356628418, "reward": 0.7401008605957031, "action": -0.3590492010116577}
{"mode": "train", "epochs": 1, "timestep": 97, "ep_reward": 60.4529914855957, "reward": 0.7581559419631958, "action": -0.026677846908569336}
{"mode": "train", "epochs": 1, "timestep": 98, "ep_reward": 61.21376419067383, "reward": 0.7607710361480713, "action": 0.31100553274154663}
{"mode": "train", "epochs": 1, "timestep": 99, "ep_reward": 61.9634895324707, "reward": 0.7497268915176392, "action": 0.28646963834762573}
{"mode": "train", "epochs": 1, "timestep": 100, "ep_reward": 62.688697814941406, "reward": 0.7252101302146912, "action": -0.06102516129612923}
{"mode": "train", "epochs": 1, "timestep": 101, "ep_reward": 63.37395095825195, "reward": 0.6852529644966125, "action": 0.06980637460947037}
{"mode": "train", "epochs": 1, "timestep": 102, "ep_reward": 64.00550079345703, "reward": 0.6315464973449707, "action": 0.6157256364822388}
{"mode": "train", "epochs": 1, "timestep": 103, "ep_reward": 64.57487487792969, "reward": 0.5693759918212891, "action": -0.18296639621257782}
{"mode": "train", "epochs": 1, "timestep": 104, "ep_reward": 65.06625366210938, "reward": 0.491380512714386, "action": 0.16099168360233307}
{"mode": "train", "epochs": 1, "timestep": 105, "ep_reward": 65.47428894042969, "reward": 0.4080328345298767, "action": 0.03309095650911331}
{"mode": "train", "epochs": 1, "timestep": 106, "ep_reward": 65.79419708251953, "reward": 0.31990742683410645, "action": 0.6377894282341003}
{"mode": "train", "epochs": 1, "timestep": 107, "ep_reward": 66.10363006591797, "reward": 0.30943435430526733, "action": 0.10967966914176941}
{"mode": "train", "epochs": 1, "timestep": 108, "ep_reward": 66.49264526367188, "reward": 0.38901156187057495, "action": 0.3555757403373718}
{"mode": "train", "epochs": 1, "timestep": 109, "ep_reward": 66.96058654785156, "reward": 0.46794360876083374, "action": 0.2920985519886017}
{"mode": "train", "epochs": 1, "timestep": 110, "ep_reward": 67.50125122070312, "reward": 0.540666401386261, "action": -0.046615153551101685}
{"mode": "train", "epochs": 1, "timestep": 111, "ep_reward": 68.10462951660156, "reward": 0.6033796668052673, "action": 0.37309789657592773}
{"mode": "train", "epochs": 1, "timestep": 112, "ep_reward": 68.7616958618164, "reward": 0.6570643186569214, "action": 0.31883707642555237}
{"mode": "train", "epochs": 1, "timestep": 113, "ep_reward": 69.4587631225586, "reward": 0.6970709562301636, "action": 0.663118839263916}
{"mode": "train", "epochs": 1, "timestep": 114, "ep_reward": 70.1814193725586, "reward": 0.7226547002792358, "action": 0.11633370071649551}
{"mode": "train", "epochs": 1, "timestep": 115, "ep_reward": 70.91373443603516, "reward": 0.7323171496391296, "action": 0.5849923491477966}
{"mode": "train", "epochs": 1, "timestep": 116, "ep_reward": 71.64002227783203, "reward": 0.7262850999832153, "action": -0.7761964797973633}
{"mode": "train", "epochs": 1, "timestep": 117, "ep_reward": 72.34901428222656, "reward": 0.7089888453483582, "action": 0.2406643033027649}
{"mode": "train", "epochs": 1, "timestep": 118, "ep_reward": 73.02490234375, "reward": 0.6758900880813599, "action": -1.0915069580078125}
{"mode": "train", "epochs": 1, "timestep": 119, "ep_reward": 73.66149139404297, "reward": 0.6365889310836792, "action": -0.820501446723938}
{"mode": "train", "epochs": 1, "timestep": 120, "ep_reward": 74.24888610839844, "reward": 0.587393045425415, "action": 0.543595552444458}
{"mode": "train", "epochs": 1, "timestep": 121, "ep_reward": 74.76868438720703, "reward": 0.5198003649711609, "action": -0.07918816804885864}
{"mode": "train", "epochs": 1, "timestep": 122, "ep_reward": 75.21570587158203, "reward": 0.4470195174217224, "action": -0.7188975214958191}
{"mode": "train", "epochs": 1, "timestep": 123, "ep_reward": 75.59129333496094, "reward": 0.3755902647972107, "action": -0.3030630350112915}
{"mode": "train", "epochs": 1, "timestep": 124, "ep_reward": 75.89209747314453, "reward": 0.30080562829971313, "action": -1.6015583276748657}
{"mode": "train", "epochs": 1, "timestep": 125, "ep_reward": 76.26373291015625, "reward": 0.3716386556625366, "action": 0.15962716937065125}
{"mode": "train", "epochs": 1, "timestep": 126, "ep_reward": 76.70024871826172, "reward": 0.4365195035934448, "action": -0.9075415730476379}
{"mode": "train", "epochs": 1, "timestep": 127, "ep_reward": 77.20270538330078, "reward": 0.5024588704109192, "action": -1.0254684686660767}
{"mode": "train", "epochs": 1, "timestep": 128, "ep_reward": 77.7624740600586, "reward": 0.5597656965255737, "action": -0.5974770784378052}
{"mode": "train", "epochs": 1, "timestep": 129, "ep_reward": 78.36699676513672, "reward": 0.6045249104499817, "action": -0.4437839984893799}
{"mode": "train", "epochs": 1, "timestep": 130, "ep_reward": 79.00425720214844, "reward": 0.6372593641281128, "action": -0.1450800895690918}
{"mode": "train", "epochs": 1, "timestep": 131, "ep_reward": 79.661865234375, "reward": 0.6576091051101685, "action": -0.21728578209877014}
{"mode": "train", "epochs": 1, "timestep": 132, "ep_reward": 80.32766723632812, "reward": 0.6658056378364563, "action": 0.4158066511154175}
{"mode": "train", "epochs": 1, "timestep": 133, "ep_reward": 80.99065399169922, "reward": 0.6629830598831177, "action": -0.22196760773658752}
{"mode": "train", "epochs": 1, "timestep": 134, "ep_reward": 81.63839721679688, "reward": 0.6477446556091309, "action": 0.1032320111989975}
{"mode": "train", "epochs": 1, "timestep": 135, "ep_reward": 82.2599105834961, "reward": 0.6215108633041382, "action": -0.005103789269924164}
{"mode": "train", "epochs": 1, "timestep": 136, "ep_reward": 82.84410095214844, "reward": 0.5841938257217407, "action": 0.07381907850503922}
{"mode": "train", "epochs": 1, "timestep": 137, "ep_reward": 83.38175201416016, "reward": 0.5376541018486023, "action": 0.08869174122810364}
{"mode": "train", "epochs": 1, "timestep": 138, "ep_reward": 83.86528778076172, "reward": 0.48353683948516846, "action": 0.14654292166233063}
{"mode": "train", "epochs": 1, "timestep": 139, "ep_reward": 84.28977966308594, "reward": 0.4244953989982605, "action": -0.6220888495445251}
{"mode": "train", "epochs": 1, "timestep": 140, "ep_reward": 84.6461410522461, "reward": 0.35636502504348755, "action": -0.2854381799697876}
{"mode": "train", "epochs": 1, "timestep": 141, "ep_reward": 84.99292755126953, "reward": 0.3467845320701599, "action": 0.4601903259754181}
{"mode": "train", "epochs": 1, "timestep": 142, "ep_reward": 85.4025650024414, "reward": 0.4096337556838989, "action": -0.23467622697353363}
{"mode": "train", "epochs": 1, "timestep": 143, "ep_reward": 85.86991119384766, "reward": 0.4673461318016052, "action": 0.1182655543088913}
{"mode": "train", "epochs": 1, "timestep": 144, "ep_reward": 86.3926010131836, "reward": 0.522691011428833, "action": -0.7958847284317017}
{"mode": "train", "epochs": 1, "timestep": 145, "ep_reward": 86.96214294433594, "reward": 0.5695383548736572, "action": 0.02537435106933117}
{"mode": "train", "epochs": 1, "timestep": 146, "ep_reward": 87.5743637084961, "reward": 0.61222243309021, "action": -0.3476353585720062}
{"mode": "train", "epochs": 1, "timestep": 147, "ep_reward": 88.21907043457031, "reward": 0.6447051763534546, "action": 0.6011538505554199}
{"mode": "train", "epochs": 1, "timestep": 148, "ep_reward": 88.88627624511719, "reward": 0.6672065854072571, "action": -1.0221720933914185}
{"mode": "train", "epochs": 1, "timestep": 149, "ep_reward": 89.56401062011719, "reward": 0.6777350902557373, "action": -0.3903704583644867}
{"mode": "train", "epochs": 1, "timestep": 150, "ep_reward": 90.2427749633789, "reward": 0.6787673234939575, "action": 0.11202142387628555}
{"mode": "train", "epochs": 1, "timestep": 151, "ep_reward": 90.91021728515625, "reward": 0.667442798614502, "action": 0.07392534613609314}
{"mode": "train", "epochs": 1, "timestep": 152, "ep_reward": 91.55376434326172, "reward": 0.6435461640357971, "action": -0.4907737076282501}
{"mode": "train", "epochs": 1, "timestep": 153, "ep_reward": 92.16446685791016, "reward": 0.6107010245323181, "action": -0.011492922902107239}
{"mode": "train", "epochs": 1, "timestep": 154, "ep_reward": 92.73052215576172, "reward": 0.5660576820373535, "action": 0.1303938925266266}
{"mode": "train", "epochs": 1, "timestep": 155, "ep_reward": 93.24166870117188, "reward": 0.5111461877822876, "action": -0.013170838356018066}
{"mode": "train", "epochs": 1, "timestep": 156, "ep_reward": 93.69135284423828, "reward": 0.44968611001968384, "action": -0.9028711915016174}
{"mode": "train", "epochs": 1, "timestep": 157, "ep_reward": 94.08289337158203, "reward": 0.3915426731109619, "action": -0.4972197115421295}
{"mode": "train", "epochs": 1, "timestep": 158, "ep_reward": 94.41413116455078, "reward": 0.331240177154541, "action": -0.717578649520874}
{"mode": "train", "epochs": 1, "timestep": 159, "ep_reward": 94.79278564453125, "reward": 0.378653347492218, "action": 0.3265579640865326}
{"mode": "train", "epochs": 1, "timestep": 160, "ep_reward": 95.22679138183594, "reward": 0.43400418758392334, "action": -0.2375066578388214}
{"mode": "train", "epochs": 1, "timestep": 161, "ep_reward": 95.71598052978516, "reward": 0.4891897439956665, "action": -0.4838520884513855}
{"mode": "train", "epochs": 1, "timestep": 162, "ep_reward": 96.2552261352539, "reward": 0.539246141910553, "action": -0.5772567391395569}
{"mode": "train", "epochs": 1, "timestep": 163, "ep_reward": 96.83601379394531, "reward": 0.5807887315750122, "action": 0.6447874307632446}
{"mode": "train", "epochs": 1, "timestep": 164, "ep_reward": 97.44721221923828, "reward": 0.6111955046653748, "action": -0.5660591125488281}
{"mode": "train", "epochs": 1, "timestep": 165, "ep_reward": 98.0811996459961, "reward": 0.6339845657348633, "action": -0.943589448928833}
{"mode": "train", "epochs": 1, "timestep": 166, "ep_reward": 98.72455596923828, "reward": 0.6433576345443726, "action": 0.3669954538345337}
{"mode": "train", "epochs": 1, "timestep": 167, "ep_reward": 99.36569213867188, "reward": 0.6411350965499878, "action": -1.1058082580566406}
{"mode": "train", "epochs": 1, "timestep": 168, "ep_reward": 99.98990631103516, "reward": 0.6242122650146484, "action": 0.3305298388004303}
{"mode": "train", "epochs": 1, "timestep": 169, "ep_reward": 100.5886001586914, "reward": 0.5986964106559753, "action": -0.3165671229362488}
{"mode": "train", "epochs": 1, "timestep": 170, "ep_reward": 101.14952850341797, "reward": 0.5609310269355774, "action": 1.1863898038864136}
{"mode": "train", "epochs": 1, "timestep": 171, "ep_reward": 101.67266845703125, "reward": 0.5231420993804932, "action": 0.08922823518514633}
{"mode": "train", "epochs": 1, "timestep": 172, "ep_reward": 102.1478271484375, "reward": 0.4751565456390381, "action": -0.3744170367717743}
{"mode": "train", "epochs": 1, "timestep": 173, "ep_reward": 102.56688690185547, "reward": 0.4190622568130493, "action": 0.21792761981487274}
{"mode": "train", "epochs": 1, "timestep": 174, "ep_reward": 102.93070220947266, "reward": 0.36381345987319946, "action": -0.0029748468659818172}
{"mode": "train", "epochs": 1, "timestep": 175, "ep_reward": 103.29229736328125, "reward": 0.36159515380859375, "action": 0.5968891382217407}
{"mode": "train", "epochs": 1, "timestep": 176, "ep_reward": 103.70830535888672, "reward": 0.4160112738609314, "action": 0.1903638243675232}
{"mode": "train", "epochs": 1, "timestep": 177, "ep_reward": 104.17427062988281, "reward": 0.46596264839172363, "action": -0.7223814725875854}
{"mode": "train", "epochs": 1, "timestep": 178, "ep_reward": 104.68437194824219, "reward": 0.510098397731781, "action": 0.35607314109802246}
{"mode": "train", "epochs": 1, "timestep": 179, "ep_reward": 105.2369384765625, "reward": 0.5525653958320618, "action": -0.06084684655070305}
{"mode": "train", "epochs": 1, "timestep": 180, "ep_reward": 105.8231430053711, "reward": 0.5862032175064087, "action": -0.610320508480072}
{"mode": "train", "epochs": 1, "timestep": 181, "ep_reward": 106.43472290039062, "reward": 0.6115802526473999, "action": 0.2658562958240509}
{"mode": "train", "epochs": 1, "timestep": 182, "ep_reward": 107.06371307373047, "reward": 0.6289933919906616, "action": 0.12657774984836578}
{"mode": "train", "epochs": 1, "timestep": 183, "ep_reward": 107.69900512695312, "reward": 0.6352949142456055, "action": 0.018336087465286255}
{"mode": "train", "epochs": 1, "timestep": 184, "ep_reward": 108.32978057861328, "reward": 0.6307745575904846, "action": -0.3103589415550232}
{"mode": "train", "epochs": 1, "timestep": 185, "ep_reward": 108.94661712646484, "reward": 0.6168347597122192, "action": 0.04122914373874664}
{"mode": "train", "epochs": 1, "timestep": 186, "ep_reward": 109.53892517089844, "reward": 0.5923075675964355, "action": 0.3943854868412018}
{"mode": "train", "epochs": 1, "timestep": 187, "ep_reward": 110.09507751464844, "reward": 0.556151270866394, "action": -0.44751840829849243}
{"mode": "train", "epochs": 1, "timestep": 188, "ep_reward": 110.61048889160156, "reward": 0.5154085755348206, "action": -1.2605828046798706}
{"mode": "train", "epochs": 1, "timestep": 189, "ep_reward": 111.0859146118164, "reward": 0.47542423009872437, "action": -0.4837910532951355}
{"mode": "train", "epochs": 1, "timestep": 190, "ep_reward": 111.5154037475586, "reward": 0.42948752641677856, "action": -0.5903270244598389}
{"mode": "train", "epochs": 1, "timestep": 191, "ep_reward": 111.89863586425781, "reward": 0.38323575258255005, "action": -0.9705967903137207}
{"mode": "train", "epochs": 1, "timestep": 192, "ep_reward": 112.25823211669922, "reward": 0.35959845781326294, "action": -0.7630505561828613}
{"mode": "train", "epochs": 1, "timestep": 193, "ep_reward": 112.66284942626953, "reward": 0.40461522340774536, "action": -0.22075988352298737}
{"mode": "train", "epochs": 1, "timestep": 194, "ep_reward": 113.10836791992188, "reward": 0.4455219507217407, "action": -0.17128433287143707}
{"mode": "train", "epochs": 1, "timestep": 195, "ep_reward": 113.59136199951172, "reward": 0.48299670219421387, "action": -0.30213648080825806}
{"mode": "train", "epochs": 1, "timestep": 196, "ep_reward": 114.1070556640625, "reward": 0.5156903862953186, "action": -1.2249829769134521}
{"mode": "train", "epochs": 1, "timestep": 197, "ep_reward": 114.64868927001953, "reward": 0.54163658618927, "action": -0.23026885092258453}
{"mode": "train", "epochs": 1, "timestep": 198, "ep_reward": 115.2060546875, "reward": 0.5573661923408508, "action": -0.45720142126083374}
{"mode": "train", "epochs": 1, "timestep": 199, "ep_reward": 115.77066040039062, "reward": 0.5646044015884399, "action": -0.3763076663017273}
{"mode": "train", "epochs": 1, "timestep": 200, "ep_reward": 116.33336639404297, "reward": 0.5627065300941467, "action": 0.44659972190856934}
{"mode": "train", "epochs": 1, "timestep": 201, "ep_reward": 116.88794708251953, "reward": 0.5545777082443237, "action": -0.4204890727996826}
{"mode": "train", "epochs": 1, "timestep": 202, "ep_reward": 117.42529296875, "reward": 0.5373450517654419, "action": -0.6317299008369446}
{"mode": "train", "epochs": 1, "timestep": 203, "ep_reward": 117.93598937988281, "reward": 0.51069575548172, "action": 0.8624045848846436}
{"mode": "train", "epochs": 1, "timestep": 204, "ep_reward": 118.41992950439453, "reward": 0.48393940925598145, "action": 1.46477210521698}
{"mode": "train", "epochs": 1, "timestep": 205, "ep_reward": 118.87895965576172, "reward": 0.4590280055999756, "action": 0.1866610050201416}
{"mode": "train", "epochs": 1, "timestep": 206, "ep_reward": 119.30703735351562, "reward": 0.42807501554489136, "action": 0.525622546672821}
{"mode": "train", "epochs": 1, "timestep": 207, "ep_reward": 119.70465087890625, "reward": 0.39761650562286377, "action": 0.17021381855010986}
{"mode": "train", "epochs": 1, "timestep": 208, "ep_reward": 120.07286834716797, "reward": 0.36821895837783813, "action": 0.7430610060691833}
{"mode": "train", "epochs": 1, "timestep": 209, "ep_reward": 120.47222137451172, "reward": 0.3993496894836426, "action": -0.5591940879821777}
{"mode": "train", "epochs": 1, "timestep": 210, "ep_reward": 120.8997573852539, "reward": 0.42753344774246216, "action": -0.8992372155189514}
{"mode": "train", "epochs": 1, "timestep": 211, "ep_reward": 121.35526275634766, "reward": 0.45550477504730225, "action": 0.7916133999824524}
{"mode": "train", "epochs": 1, "timestep": 212, "ep_reward": 121.83831024169922, "reward": 0.4830465316772461, "action": 0.1577560305595398}
{"mode": "train", "epochs": 1, "timestep": 213, "ep_reward": 122.34249877929688, "reward": 0.5041855573654175, "action": 0.6299905776977539}
{"mode": "train", "epochs": 1, "timestep": 214, "ep_reward": 122.8617935180664, "reward": 0.5192954540252686, "action": -0.49824345111846924}
{"mode": "train", "epochs": 1, "timestep": 215, "ep_reward": 123.39041900634766, "reward": 0.5286221504211426, "action": -0.35174593329429626}
{"mode": "train", "epochs": 1, "timestep": 216, "ep_reward": 123.92383575439453, "reward": 0.5334197282791138, "action": -0.3090054392814636}
{"mode": "train", "epochs": 1, "timestep": 217, "ep_reward": 124.45699310302734, "reward": 0.5331543684005737, "action": 0.6653357744216919}
{"mode": "train", "epochs": 1, "timestep": 218, "ep_reward": 124.98164367675781, "reward": 0.5246505737304688, "action": -0.5288065671920776}
{"mode": "train", "epochs": 1, "timestep": 219, "ep_reward": 125.49398803710938, "reward": 0.5123453140258789, "action": -0.08488459140062332}
{"mode": "train", "epochs": 1, "timestep": 220, "ep_reward": 125.98844909667969, "reward": 0.49446141719818115, "action": -0.9554063677787781}
{"mode": "train", "epochs": 1, "timestep": 221, "ep_reward": 126.46469116210938, "reward": 0.4762384295463562, "action": -0.3186225891113281}
{"mode": "train", "epochs": 1, "timestep": 222, "ep_reward": 126.91871643066406, "reward": 0.45402806997299194, "action": -0.7723385691642761}
{"mode": "train", "epochs": 1, "timestep": 223, "ep_reward": 127.35086059570312, "reward": 0.4321473240852356, "action": -0.19471900165081024}
{"mode": "train", "epochs": 1, "timestep": 224, "ep_reward": 127.75834655761719, "reward": 0.4074857831001282, "action": 1.0640485286712646}
{"mode": "train", "epochs": 1, "timestep": 225, "ep_reward": 128.1338653564453, "reward": 0.3755236864089966, "action": -0.043809279799461365}
{"mode": "train", "epochs": 1, "timestep": 226, "ep_reward": 128.52630615234375, "reward": 0.39244014024734497, "action": -1.2990946769714355}
{"mode": "train", "epochs": 1, "timestep": 227, "ep_reward": 128.9462890625, "reward": 0.41997820138931274, "action": -0.007332354784011841}
{"mode": "train", "epochs": 1, "timestep": 228, "ep_reward": 129.38885498046875, "reward": 0.44256508350372314, "action": -0.4713135063648224}
{"mode": "train", "epochs": 1, "timestep": 229, "ep_reward": 129.85118103027344, "reward": 0.46232444047927856, "action": 0.8094176054000854}
{"mode": "train", "epochs": 1, "timestep": 230, "ep_reward": 130.33013916015625, "reward": 0.4789571762084961, "action": 0.30726853013038635}
{"mode": "train", "epochs": 1, "timestep": 231, "ep_reward": 130.82379150390625, "reward": 0.49364906549453735, "action": 0.2141362726688385}
{"mode": "train", "epochs": 1, "timestep": 232, "ep_reward": 131.3285675048828, "reward": 0.5047721862792969, "action": -0.41228240728378296}
{"mode": "train", "epochs": 1, "timestep": 233, "ep_reward": 131.83900451660156, "reward": 0.5104299783706665, "action": 0.13414587080478668}
{"mode": "train", "epochs": 1, "timestep": 234, "ep_reward": 132.349853515625, "reward": 0.5108509659767151, "action": -0.3589108884334564}
{"mode": "train", "epochs": 1, "timestep": 235, "ep_reward": 132.85484313964844, "reward": 0.5049837827682495, "action": -0.15701019763946533}
{"mode": "train", "epochs": 1, "timestep": 236, "ep_reward": 133.34828186035156, "reward": 0.49343568086624146, "action": 1.0070713758468628}
{"mode": "train", "epochs": 1, "timestep": 237, "ep_reward": 133.82981872558594, "reward": 0.481536328792572, "action": -0.4593578577041626}
{"mode": "train", "epochs": 1, "timestep": 238, "ep_reward": 134.2923126220703, "reward": 0.46249622106552124, "action": -0.8694748878479004}
{"mode": "train", "epochs": 1, "timestep": 239, "ep_reward": 134.7287139892578, "reward": 0.4363937973976135, "action": 0.9837648868560791}
{"mode": "train", "epochs": 1, "timestep": 240, "ep_reward": 135.14341735839844, "reward": 0.4146977663040161, "action": 0.002340458333492279}
{"mode": "train", "epochs": 1, "timestep": 241, "ep_reward": 135.53282165527344, "reward": 0.3894033432006836, "action": 0.7718027234077454}
{"mode": "train", "epochs": 1, "timestep": 242, "ep_reward": 135.91412353515625, "reward": 0.38130104541778564, "action": -0.24110755324363708}
{"mode": "train", "epochs": 1, "timestep": 243, "ep_reward": 136.31817626953125, "reward": 0.40404975414276123, "action": 0.14760029315948486}
{"mode": "train", "epochs": 1, "timestep": 244, "ep_reward": 136.7445068359375, "reward": 0.4263353943824768, "action": -0.4510732591152191}
{"mode": "train", "epochs": 1, "timestep": 245, "ep_reward": 137.19146728515625, "reward": 0.44695478677749634, "action": 0.23402966558933258}
{"mode": "train", "epochs": 1, "timestep": 246, "ep_reward": 137.65719604492188, "reward": 0.46573466062545776, "action": 0.7965661287307739}
{"mode": "train", "epochs": 1, "timestep": 247, "ep_reward": 138.13690185546875, "reward": 0.47970473766326904, "action": -0.11458452045917511}
{"mode": "train", "epochs": 1, "timestep": 248, "ep_reward": 138.62562561035156, "reward": 0.48872870206832886, "action": -0.40281808376312256}
{"mode": "train", "epochs": 1, "timestep": 249, "ep_reward": 139.1201629638672, "reward": 0.49454420804977417, "action": -0.43014609813690186}
{"mode": "train", "epochs": 1, "timestep": 250, "ep_reward": 139.61746215820312, "reward": 0.4972941279411316, "action": -0.38426128029823303}
{"mode": "train", "epochs": 1, "timestep": 251, "ep_reward": 140.11419677734375, "reward": 0.49674099683761597, "action": -0.48955726623535156}
{"mode": "train", "epochs": 1, "timestep": 252, "ep_reward": 140.60740661621094, "reward": 0.49321162700653076, "action": -0.035206183791160583}
{"mode": "train", "epochs": 1, "timestep": 253, "ep_reward": 141.0926513671875, "reward": 0.48523837327957153, "action": 0.875472903251648}
{"mode": "train", "epochs": 1, "timestep": 254, "ep_reward": 141.56231689453125, "reward": 0.4696594476699829, "action": -0.11211825162172318}
{"mode": "train", "epochs": 1, "timestep": 255, "ep_reward": 142.01397705078125, "reward": 0.4516618251800537, "action": -0.3095088601112366}
{"mode": "train", "epochs": 1, "timestep": 256, "ep_reward": 142.44601440429688, "reward": 0.43203872442245483, "action": -0.7844880819320679}
{"mode": "train", "epochs": 1, "timestep": 257, "ep_reward": 142.8596649169922, "reward": 0.41365230083465576, "action": 0.2219056487083435}
{"mode": "train", "epochs": 1, "timestep": 258, "ep_reward": 143.25106811523438, "reward": 0.39141011238098145, "action": -0.7480258345603943}
{"mode": "train", "epochs": 1, "timestep": 259, "ep_reward": 143.63185119628906, "reward": 0.38078147172927856, "action": -0.3481455445289612}
{"mode": "train", "epochs": 1, "timestep": 260, "ep_reward": 144.0316925048828, "reward": 0.3998410701751709, "action": -0.47795695066452026}
{"mode": "train", "epochs": 1, "timestep": 261, "ep_reward": 144.4486846923828, "reward": 0.4169885516166687, "action": -0.5657420754432678}
{"mode": "train", "epochs": 1, "timestep": 262, "ep_reward": 144.87986755371094, "reward": 0.4311825633049011, "action": 0.0021661370992660522}
{"mode": "train", "epochs": 1, "timestep": 263, "ep_reward": 145.3224639892578, "reward": 0.44260311126708984, "action": -0.9389129877090454}
{"mode": "train", "epochs": 1, "timestep": 264, "ep_reward": 145.7723388671875, "reward": 0.44986844062805176, "action": -0.44050586223602295}
{"mode": "train", "epochs": 1, "timestep": 265, "ep_reward": 146.22483825683594, "reward": 0.45250391960144043, "action": 0.17016001045703888}
{"mode": "train", "epochs": 1, "timestep": 266, "ep_reward": 146.67747497558594, "reward": 0.45263445377349854, "action": -0.4045369625091553}
{"mode": "train", "epochs": 1, "timestep": 267, "ep_reward": 147.1262969970703, "reward": 0.44882673025131226, "action": -0.05920445919036865}
{"mode": "train", "epochs": 1, "timestep": 268, "ep_reward": 147.56851196289062, "reward": 0.4422123432159424, "action": 0.1616334170103073}
{"mode": "train", "epochs": 1, "timestep": 269, "ep_reward": 148.00233459472656, "reward": 0.4338206648826599, "action": -0.6793962121009827}
{"mode": "train", "epochs": 1, "timestep": 270, "ep_reward": 148.4229278564453, "reward": 0.4205968379974365, "action": -1.2269805669784546}
{"mode": "train", "epochs": 1, "timestep": 271, "ep_reward": 148.82415771484375, "reward": 0.40122848749160767, "action": -0.36321860551834106}
{"mode": "train", "epochs": 1, "timestep": 272, "ep_reward": 149.205078125, "reward": 0.3809143900871277, "action": -0.3138059675693512}
{"mode": "train", "epochs": 1, "timestep": 273, "ep_reward": 149.59791564941406, "reward": 0.3928394913673401, "action": -0.30111876130104065}
{"mode": "train", "epochs": 1, "timestep": 274, "ep_reward": 150.01080322265625, "reward": 0.41289305686950684, "action": 0.6771584153175354}
{"mode": "train", "epochs": 1, "timestep": 275, "ep_reward": 150.4424285888672, "reward": 0.43161845207214355, "action": -1.0060486793518066}
{"mode": "train", "epochs": 1, "timestep": 276, "ep_reward": 150.89085388183594, "reward": 0.4484299421310425, "action": 0.4981171786785126}
{"mode": "train", "epochs": 1, "timestep": 277, "ep_reward": 151.35462951660156, "reward": 0.4637719392776489, "action": -0.34621524810791016}
{"mode": "train", "epochs": 1, "timestep": 278, "ep_reward": 151.83029174804688, "reward": 0.47565919160842896, "action": -0.006556212902069092}
{"mode": "train", "epochs": 1, "timestep": 279, "ep_reward": 152.3146514892578, "reward": 0.48435258865356445, "action": 0.28222179412841797}
{"mode": "train", "epochs": 1, "timestep": 280, "ep_reward": 152.80300903320312, "reward": 0.4883500933647156, "action": -0.4884747266769409}
{"mode": "train", "epochs": 1, "timestep": 281, "ep_reward": 153.292236328125, "reward": 0.4892236590385437, "action": -0.4502209424972534}
{"mode": "train", "epochs": 1, "timestep": 282, "ep_reward": 153.779541015625, "reward": 0.48730289936065674, "action": -0.732818067073822}
{"mode": "train", "epochs": 1, "timestep": 283, "ep_reward": 154.2631378173828, "reward": 0.48359084129333496, "action": 0.08485981822013855}
{"mode": "train", "epochs": 1, "timestep": 284, "ep_reward": 154.73854064941406, "reward": 0.4753955602645874, "action": -0.18544715642929077}
{"mode": "train", "epochs": 1, "timestep": 285, "ep_reward": 155.20269775390625, "reward": 0.4641595482826233, "action": -0.2419314831495285}
{"mode": "train", "epochs": 1, "timestep": 286, "ep_reward": 155.65306091308594, "reward": 0.45036548376083374, "action": -1.119658350944519}
{"mode": "train", "epochs": 1, "timestep": 287, "ep_reward": 156.09144592285156, "reward": 0.4383918046951294, "action": -0.2964581847190857}
{"mode": "train", "epochs": 1, "timestep": 288, "ep_reward": 156.51541137695312, "reward": 0.42395806312561035, "action": -1.291926383972168}
{"mode": "train", "epochs": 1, "timestep": 289, "ep_reward": 156.92852783203125, "reward": 0.41311246156692505, "action": 0.5939726233482361}
{"mode": "train", "epochs": 1, "timestep": 290, "ep_reward": 157.3253173828125, "reward": 0.39679020643234253, "action": -1.4074145555496216}
{"mode": "train", "epochs": 1, "timestep": 291, "ep_reward": 157.7121124267578, "reward": 0.3867919445037842, "action": -0.7209876775741577}
{"mode": "train", "epochs": 1, "timestep": 292, "ep_reward": 158.0975799560547, "reward": 0.3854702115058899, "action": 0.47355687618255615}
{"mode": "train", "epochs": 1, "timestep": 293, "ep_reward": 158.49362182617188, "reward": 0.39603787660598755, "action": 0.3578832745552063}
{"mode": "train", "epochs": 1, "timestep": 294, "ep_reward": 158.90084838867188, "reward": 0.40722721815109253, "action": -0.2915957570075989}
{"mode": "train", "epochs": 1, "timestep": 295, "ep_reward": 159.31814575195312, "reward": 0.4173046946525574, "action": -0.6760048866271973}
{"mode": "train", "epochs": 1, "timestep": 296, "ep_reward": 159.74241638183594, "reward": 0.42427074909210205, "action": -1.2128784656524658}
{"mode": "train", "epochs": 1, "timestep": 297, "ep_reward": 160.16854858398438, "reward": 0.4261367917060852, "action": -0.41425392031669617}
{"mode": "train", "epochs": 1, "timestep": 298, "ep_reward": 160.5930633544922, "reward": 0.4245142936706543, "action": -0.252368688583374}
{"mode": "train", "epochs": 1, "timestep": 299, "ep_reward": 161.0135040283203, "reward": 0.42043691873550415, "action": 0.45597678422927856}
{"mode": "train", "epochs": 1, "timestep": 300, "ep_reward": 161.4299774169922, "reward": 0.41647934913635254, "action": 0.35082268714904785}
{"mode": "train", "epochs": 1, "timestep": 301, "ep_reward": 161.84222412109375, "reward": 0.4122471213340759, "action": -0.266979455947876}
{"mode": "train", "epochs": 1, "timestep": 302, "ep_reward": 162.24806213378906, "reward": 0.40584075450897217, "action": -0.290282279253006}
{"mode": "train", "epochs": 1, "timestep": 303, "ep_reward": 162.6456756591797, "reward": 0.39761608839035034, "action": 0.2583470344543457}
{"mode": "train", "epochs": 1, "timestep": 304, "ep_reward": 163.03561401367188, "reward": 0.3899334669113159, "action": -0.6825351715087891}
{"mode": "train", "epochs": 1, "timestep": 305, "ep_reward": 163.41937255859375, "reward": 0.3837614059448242, "action": -0.1250743865966797}
{"mode": "train", "epochs": 1, "timestep": 306, "ep_reward": 163.81333923339844, "reward": 0.39396893978118896, "action": -0.06337527185678482}
{"mode": "train", "epochs": 1, "timestep": 307, "ep_reward": 164.21730041503906, "reward": 0.40396392345428467, "action": 0.7247186899185181}
{"mode": "train", "epochs": 1, "timestep": 308, "ep_reward": 164.6290740966797, "reward": 0.41176795959472656, "action": 0.0433603934943676}
{"mode": "train", "epochs": 1, "timestep": 309, "ep_reward": 165.04678344726562, "reward": 0.4177045226097107, "action": 0.5207938551902771}
{"mode": "train", "epochs": 1, "timestep": 310, "ep_reward": 165.46780395507812, "reward": 0.42101818323135376, "action": 0.21311916410923004}
{"mode": "train", "epochs": 1, "timestep": 311, "ep_reward": 165.88980102539062, "reward": 0.42200446128845215, "action": -0.6181785464286804}
{"mode": "train", "epochs": 1, "timestep": 312, "ep_reward": 166.31300354003906, "reward": 0.4232003092765808, "action": 0.5935621857643127}
{"mode": "train", "epochs": 1, "timestep": 313, "ep_reward": 166.73422241210938, "reward": 0.4212157130241394, "action": -0.1898074597120285}
{"mode": "train", "epochs": 1, "timestep": 314, "ep_reward": 167.1524658203125, "reward": 0.41824525594711304, "action": 1.0593712329864502}
{"mode": "train", "epochs": 1, "timestep": 315, "ep_reward": 167.56285095214844, "reward": 0.41038066148757935, "action": 0.114241823554039}
{"mode": "train", "epochs": 1, "timestep": 316, "ep_reward": 167.9642333984375, "reward": 0.40138691663742065, "action": 0.4909537732601166}
{"mode": "train", "epochs": 1, "timestep": 317, "ep_reward": 168.35403442382812, "reward": 0.3898058533668518, "action": 0.954299807548523}
{"mode": "train", "epochs": 1, "timestep": 318, "ep_reward": 168.73934936523438, "reward": 0.3853132724761963, "action": 0.39798128604888916}
{"mode": "train", "epochs": 1, "timestep": 319, "ep_reward": 169.13912963867188, "reward": 0.3997734785079956, "action": -0.28486543893814087}
{"mode": "train", "epochs": 1, "timestep": 320, "ep_reward": 169.5528106689453, "reward": 0.4136831760406494, "action": 0.3374004662036896}
{"mode": "train", "epochs": 1, "timestep": 321, "ep_reward": 169.9793701171875, "reward": 0.42655646800994873, "action": 0.3642016649246216}
{"mode": "train", "epochs": 1, "timestep": 322, "ep_reward": 170.41818237304688, "reward": 0.4388046860694885, "action": -0.2475156933069229}
{"mode": "train", "epochs": 1, "timestep": 323, "ep_reward": 170.86708068847656, "reward": 0.44890379905700684, "action": -0.2303364872932434}
{"mode": "train", "epochs": 1, "timestep": 324, "ep_reward": 171.3227081298828, "reward": 0.4556313753128052, "action": 0.6307169198989868}
{"mode": "train", "epochs": 1, "timestep": 325, "ep_reward": 171.78353881835938, "reward": 0.46082407236099243, "action": -0.15344145894050598}
{"mode": "train", "epochs": 1, "timestep": 326, "ep_reward": 172.24644470214844, "reward": 0.4629119038581848, "action": 0.9846992492675781}
{"mode": "train", "epochs": 1, "timestep": 327, "ep_reward": 172.71099853515625, "reward": 0.46455198526382446, "action": 0.3339942693710327}
{"mode": "train", "epochs": 1, "timestep": 328, "ep_reward": 173.1750946044922, "reward": 0.4641000032424927, "action": 1.0553466081619263}
{"mode": "train", "epochs": 1, "timestep": 329, "ep_reward": 173.63882446289062, "reward": 0.46372294425964355, "action": 0.1651799976825714}
{"mode": "train", "epochs": 1, "timestep": 330, "ep_reward": 174.09950256347656, "reward": 0.4606783986091614, "action": 0.290440171957016}
{"mode": "train", "epochs": 1, "timestep": 331, "ep_reward": 174.5549774169922, "reward": 0.4554796814918518, "action": 0.4994049072265625}
{"mode": "train", "epochs": 1, "timestep": 332, "ep_reward": 175.00379943847656, "reward": 0.4488164186477661, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 333, "ep_reward": 175.4503173828125, "reward": 0.44651609659194946, "action": 0.704390287399292}
{"mode": "train", "epochs": 1, "timestep": 334, "ep_reward": 175.89340209960938, "reward": 0.44307857751846313, "action": 0.6658583879470825}
{"mode": "train", "epochs": 1, "timestep": 335, "ep_reward": 176.3325958251953, "reward": 0.43919628858566284, "action": 1.440081000328064}
{"mode": "train", "epochs": 1, "timestep": 336, "ep_reward": 176.77029418945312, "reward": 0.4377039074897766, "action": 0.9449504613876343}
{"mode": "train", "epochs": 1, "timestep": 337, "ep_reward": 177.2069091796875, "reward": 0.4366190433502197, "action": 1.0762557983398438}
{"mode": "train", "epochs": 1, "timestep": 338, "ep_reward": 177.64352416992188, "reward": 0.4366128444671631, "action": 1.0609633922576904}
{"mode": "train", "epochs": 1, "timestep": 339, "ep_reward": 178.08116149902344, "reward": 0.4376317262649536, "action": 0.7339673638343811}
{"mode": "train", "epochs": 1, "timestep": 340, "ep_reward": 178.5198974609375, "reward": 0.4387337565422058, "action": 0.125882089138031}
{"mode": "train", "epochs": 1, "timestep": 341, "ep_reward": 178.9580078125, "reward": 0.4381038546562195, "action": 0.811320960521698}
{"mode": "train", "epochs": 1, "timestep": 342, "ep_reward": 179.39578247070312, "reward": 0.43777334690093994, "action": 0.8501666784286499}
{"mode": "train", "epochs": 1, "timestep": 343, "ep_reward": 179.83358764648438, "reward": 0.4377979040145874, "action": 1.1725457906723022}
{"mode": "train", "epochs": 1, "timestep": 344, "ep_reward": 180.27279663085938, "reward": 0.43920546770095825, "action": 0.32893991470336914}
{"mode": "train", "epochs": 1, "timestep": 345, "ep_reward": 180.71224975585938, "reward": 0.43945372104644775, "action": 0.6765327453613281}
{"mode": "train", "epochs": 1, "timestep": 346, "ep_reward": 181.15162658691406, "reward": 0.4393734931945801, "action": 1.755252718925476}
{"mode": "train", "epochs": 1, "timestep": 347, "ep_reward": 181.5939483642578, "reward": 0.44232839345932007, "action": 0.706354022026062}
{"mode": "train", "epochs": 1, "timestep": 348, "ep_reward": 182.03907775878906, "reward": 0.44512951374053955, "action": 0.3378933072090149}
{"mode": "train", "epochs": 1, "timestep": 349, "ep_reward": 182.4856719970703, "reward": 0.44659972190856934, "action": 1.1025278568267822}
{"mode": "train", "epochs": 1, "timestep": 350, "ep_reward": 182.9344024658203, "reward": 0.4487377405166626, "action": 1.208446979522705}
{"mode": "train", "epochs": 1, "timestep": 351, "ep_reward": 183.38623046875, "reward": 0.45182663202285767, "action": 1.152769684791565}
{"mode": "train", "epochs": 1, "timestep": 352, "ep_reward": 183.84176635742188, "reward": 0.45553725957870483, "action": 1.5546379089355469}
{"mode": "train", "epochs": 1, "timestep": 353, "ep_reward": 184.30258178710938, "reward": 0.4608214497566223, "action": 1.2516285181045532}
{"mode": "train", "epochs": 1, "timestep": 354, "ep_reward": 184.76947021484375, "reward": 0.46689027547836304, "action": 0.3741297125816345}
{"mode": "train", "epochs": 1, "timestep": 355, "ep_reward": 185.24073791503906, "reward": 0.4712716341018677, "action": 1.2576892375946045}
{"mode": "train", "epochs": 1, "timestep": 356, "ep_reward": 185.71633911132812, "reward": 0.4756072759628296, "action": 0.9633270502090454}
{"mode": "train", "epochs": 1, "timestep": 357, "ep_reward": 186.1956787109375, "reward": 0.47934484481811523, "action": 0.9405992031097412}
{"mode": "train", "epochs": 1, "timestep": 358, "ep_reward": 186.67791748046875, "reward": 0.4822425842285156, "action": 0.19369959831237793}
{"mode": "train", "epochs": 1, "timestep": 359, "ep_reward": 187.15988159179688, "reward": 0.481969952583313, "action": 1.5825133323669434}
{"mode": "train", "epochs": 1, "timestep": 360, "ep_reward": 187.6425018310547, "reward": 0.4826192259788513, "action": 0.2494814395904541}
{"mode": "train", "epochs": 1, "timestep": 361, "ep_reward": 188.1226043701172, "reward": 0.4801063537597656, "action": 0.9813017845153809}
{"mode": "train", "epochs": 1, "timestep": 362, "ep_reward": 188.5994873046875, "reward": 0.4768795371055603, "action": 0.8552152514457703}
{"mode": "train", "epochs": 1, "timestep": 363, "ep_reward": 189.0719757080078, "reward": 0.47249549627304077, "action": 1.2081753015518188}
{"mode": "train", "epochs": 1, "timestep": 364, "ep_reward": 189.5404052734375, "reward": 0.46842527389526367, "action": 0.8907539248466492}
{"mode": "train", "epochs": 1, "timestep": 365, "ep_reward": 190.00387573242188, "reward": 0.46347248554229736, "action": 1.3951157331466675}
{"mode": "train", "epochs": 1, "timestep": 366, "ep_reward": 190.46372985839844, "reward": 0.45985954999923706, "action": 0.5249797701835632}
{"mode": "train", "epochs": 1, "timestep": 367, "ep_reward": 190.9181671142578, "reward": 0.45443642139434814, "action": 0.29947429895401}
{"mode": "train", "epochs": 1, "timestep": 368, "ep_reward": 191.3651885986328, "reward": 0.4470181465148926, "action": 0.5231961607933044}
{"mode": "train", "epochs": 1, "timestep": 369, "ep_reward": 191.80397033691406, "reward": 0.4387814402580261, "action": 0.9523741602897644}
{"mode": "train", "epochs": 1, "timestep": 370, "ep_reward": 192.23553466796875, "reward": 0.43156349658966064, "action": 0.7167274951934814}
{"mode": "train", "epochs": 1, "timestep": 371, "ep_reward": 192.65985107421875, "reward": 0.42430973052978516, "action": 1.2781381607055664}
{"mode": "train", "epochs": 1, "timestep": 372, "ep_reward": 193.0794677734375, "reward": 0.41961002349853516, "action": 0.9919226169586182}
{"mode": "train", "epochs": 1, "timestep": 373, "ep_reward": 193.49562072753906, "reward": 0.41614943742752075, "action": 0.3682645559310913}
{"mode": "train", "epochs": 1, "timestep": 374, "ep_reward": 193.90782165527344, "reward": 0.41220128536224365, "action": 0.364361047744751}
{"mode": "train", "epochs": 1, "timestep": 375, "ep_reward": 194.31602478027344, "reward": 0.4082094430923462, "action": 0.540898859500885}
{"mode": "train", "epochs": 1, "timestep": 376, "ep_reward": 194.72091674804688, "reward": 0.4048980474472046, "action": 0.7862821221351624}
{"mode": "train", "epochs": 1, "timestep": 377, "ep_reward": 195.1240234375, "reward": 0.4031062126159668, "action": 0.8344519138336182}
{"mode": "train", "epochs": 1, "timestep": 378, "ep_reward": 195.52685546875, "reward": 0.4028319716453552, "action": 1.4528487920761108}
{"mode": "train", "epochs": 1, "timestep": 379, "ep_reward": 195.93283081054688, "reward": 0.40597033500671387, "action": 0.8228719234466553}
{"mode": "train", "epochs": 1, "timestep": 380, "ep_reward": 196.34335327148438, "reward": 0.4105234146118164, "action": 0.5079814195632935}
{"mode": "train", "epochs": 1, "timestep": 381, "ep_reward": 196.7589569091797, "reward": 0.41560840606689453, "action": 0.1863425374031067}
{"mode": "train", "epochs": 1, "timestep": 382, "ep_reward": 197.1791229248047, "reward": 0.4201638698577881, "action": 0.13153380155563354}
{"mode": "train", "epochs": 1, "timestep": 383, "ep_reward": 197.60279846191406, "reward": 0.4236688017845154, "action": 0.9743688702583313}
{"mode": "train", "epochs": 1, "timestep": 384, "ep_reward": 198.03102111816406, "reward": 0.4282234311103821, "action": 0.422854483127594}
{"mode": "train", "epochs": 1, "timestep": 385, "ep_reward": 198.4634246826172, "reward": 0.43240177631378174, "action": 1.2914786338806152}
{"mode": "train", "epochs": 1, "timestep": 386, "ep_reward": 198.90150451660156, "reward": 0.43807852268218994, "action": 1.2783141136169434}
{"mode": "train", "epochs": 1, "timestep": 387, "ep_reward": 199.34678649902344, "reward": 0.4452829360961914, "action": 0.8360673785209656}
{"mode": "train", "epochs": 1, "timestep": 388, "ep_reward": 199.79945373535156, "reward": 0.4526636600494385, "action": 1.6083998680114746}
{"mode": "train", "epochs": 1, "timestep": 389, "ep_reward": 200.26089477539062, "reward": 0.4614364504814148, "action": 1.5297678709030151}
{"mode": "train", "epochs": 1, "timestep": 390, "ep_reward": 200.73251342773438, "reward": 0.47162455320358276, "action": 0.8389536142349243}
{"mode": "train", "epochs": 1, "timestep": 391, "ep_reward": 201.21408081054688, "reward": 0.4815598726272583, "action": 0.2521933317184448}
{"mode": "train", "epochs": 1, "timestep": 392, "ep_reward": 201.703125, "reward": 0.48905134201049805, "action": 0.32745474576950073}
{"mode": "train", "epochs": 1, "timestep": 393, "ep_reward": 202.19644165039062, "reward": 0.4933154582977295, "action": 0.4146385192871094}
{"mode": "train", "epochs": 1, "timestep": 394, "ep_reward": 202.69091796875, "reward": 0.4944753646850586, "action": 0.3591252565383911}
{"mode": "train", "epochs": 1, "timestep": 395, "ep_reward": 203.18313598632812, "reward": 0.4922245740890503, "action": 1.5151286125183105}
{"mode": "train", "epochs": 1, "timestep": 396, "ep_reward": 203.67355346679688, "reward": 0.4904218912124634, "action": 1.345997929573059}
{"mode": "train", "epochs": 1, "timestep": 397, "ep_reward": 204.1620330810547, "reward": 0.4884791374206543, "action": 0.35477566719055176}
{"mode": "train", "epochs": 1, "timestep": 398, "ep_reward": 204.64512634277344, "reward": 0.48309803009033203, "action": 1.8066835403442383}
{"mode": "train", "epochs": 1, "timestep": 399, "ep_reward": 205.12490844726562, "reward": 0.479783296585083, "action": 1.8054182529449463}
{"mode": "train", "epochs": 1, "timestep": 400, "ep_reward": 205.6028289794922, "reward": 0.47791779041290283, "action": 1.4149470329284668}
{"mode": "train", "epochs": 1, "timestep": 401, "ep_reward": 206.07923889160156, "reward": 0.4764118790626526, "action": -0.5267540812492371}
{"mode": "train", "epochs": 1, "timestep": 402, "ep_reward": 206.5485076904297, "reward": 0.4692714810371399, "action": 0.36412209272384644}
{"mode": "train", "epochs": 1, "timestep": 403, "ep_reward": 207.00848388671875, "reward": 0.45997893810272217, "action": 1.3609576225280762}
{"mode": "train", "epochs": 1, "timestep": 404, "ep_reward": 207.4611358642578, "reward": 0.45265352725982666, "action": 0.12844550609588623}
{"mode": "train", "epochs": 1, "timestep": 405, "ep_reward": 207.90293884277344, "reward": 0.4417954683303833, "action": 1.583980679512024}
{"mode": "train", "epochs": 1, "timestep": 406, "ep_reward": 208.3376922607422, "reward": 0.43475621938705444, "action": 1.0723304748535156}
{"mode": "train", "epochs": 1, "timestep": 407, "ep_reward": 208.76589965820312, "reward": 0.42820245027542114, "action": 1.3526861667633057}
{"mode": "train", "epochs": 1, "timestep": 408, "ep_reward": 209.18994140625, "reward": 0.4240475296974182, "action": 0.5980757474899292}
{"mode": "train", "epochs": 1, "timestep": 409, "ep_reward": 209.60940551757812, "reward": 0.4194616675376892, "action": 1.400733470916748}
{"mode": "train", "epochs": 1, "timestep": 410, "ep_reward": 210.02737426757812, "reward": 0.41796553134918213, "action": 0.6934012174606323}
{"mode": "train", "epochs": 1, "timestep": 411, "ep_reward": 210.44415283203125, "reward": 0.4167761206626892, "action": 1.049048662185669}
{"mode": "train", "epochs": 1, "timestep": 412, "ep_reward": 210.861572265625, "reward": 0.41741836071014404, "action": 0.5048118829727173}
{"mode": "train", "epochs": 1, "timestep": 413, "ep_reward": 211.27963256835938, "reward": 0.41806650161743164, "action": 1.3459322452545166}
{"mode": "train", "epochs": 1, "timestep": 414, "ep_reward": 211.70083618164062, "reward": 0.4212031364440918, "action": 1.262921929359436}
{"mode": "train", "epochs": 1, "timestep": 415, "ep_reward": 212.127197265625, "reward": 0.4263553023338318, "action": 1.191084623336792}
{"mode": "train", "epochs": 1, "timestep": 416, "ep_reward": 212.56040954589844, "reward": 0.43321144580841064, "action": 0.8895447850227356}
{"mode": "train", "epochs": 1, "timestep": 417, "ep_reward": 213.00123596191406, "reward": 0.44082552194595337, "action": 1.0355050563812256}
{"mode": "train", "epochs": 1, "timestep": 418, "ep_reward": 213.45033264160156, "reward": 0.4491027593612671, "action": 1.0502489805221558}
{"mode": "train", "epochs": 1, "timestep": 419, "ep_reward": 213.9082489013672, "reward": 0.45792102813720703, "action": 0.4128103256225586}
{"mode": "train", "epochs": 1, "timestep": 420, "ep_reward": 214.37387084960938, "reward": 0.4656190872192383, "action": 0.7607179880142212}
{"mode": "train", "epochs": 1, "timestep": 421, "ep_reward": 214.84603881835938, "reward": 0.4721611738204956, "action": 0.5026705861091614}
{"mode": "train", "epochs": 1, "timestep": 422, "ep_reward": 215.3229217529297, "reward": 0.4768853783607483, "action": 1.217155933380127}
{"mode": "train", "epochs": 1, "timestep": 423, "ep_reward": 215.80413818359375, "reward": 0.4812222123146057, "action": 1.3984150886535645}
{"mode": "train", "epochs": 1, "timestep": 424, "ep_reward": 216.29000854492188, "reward": 0.4858764410018921, "action": 0.7830158472061157}
{"mode": "train", "epochs": 1, "timestep": 425, "ep_reward": 216.77914428710938, "reward": 0.48913758993148804, "action": 1.0576211214065552}
{"mode": "train", "epochs": 1, "timestep": 426, "ep_reward": 217.27052307128906, "reward": 0.49137628078460693, "action": 1.0461440086364746}
{"mode": "train", "epochs": 1, "timestep": 427, "ep_reward": 217.76309204101562, "reward": 0.49257344007492065, "action": 0.9870356321334839}
{"mode": "train", "epochs": 1, "timestep": 428, "ep_reward": 218.255615234375, "reward": 0.49252045154571533, "action": 0.8773869872093201}
{"mode": "train", "epochs": 1, "timestep": 429, "ep_reward": 218.74636840820312, "reward": 0.49075961112976074, "action": 1.615065336227417}
{"mode": "train", "epochs": 1, "timestep": 430, "ep_reward": 219.23623657226562, "reward": 0.4898609519004822, "action": 0.5116217136383057}
{"mode": "train", "epochs": 1, "timestep": 431, "ep_reward": 219.722412109375, "reward": 0.486172080039978, "action": 0.5861555933952332}
{"mode": "train", "epochs": 1, "timestep": 432, "ep_reward": 220.20263671875, "reward": 0.4802287817001343, "action": 0.740242063999176}
{"mode": "train", "epochs": 1, "timestep": 433, "ep_reward": 220.67543029785156, "reward": 0.4727872610092163, "action": 0.8677839040756226}
{"mode": "train", "epochs": 1, "timestep": 434, "ep_reward": 221.1400146484375, "reward": 0.46457844972610474, "action": 0.36040133237838745}
{"mode": "train", "epochs": 1, "timestep": 435, "ep_reward": 221.5936737060547, "reward": 0.4536621570587158, "action": 1.8139994144439697}
{"mode": "train", "epochs": 1, "timestep": 436, "ep_reward": 222.04052734375, "reward": 0.4468536376953125, "action": 1.058082938194275}
{"mode": "train", "epochs": 1, "timestep": 437, "ep_reward": 222.4803466796875, "reward": 0.4398152828216553, "action": 1.1652500629425049}
{"mode": "train", "epochs": 1, "timestep": 438, "ep_reward": 222.91445922851562, "reward": 0.4341050386428833, "action": -0.45758551359176636}
{"mode": "train", "epochs": 1, "timestep": 439, "ep_reward": 223.33827209472656, "reward": 0.42381441593170166, "action": 1.558268427848816}
{"mode": "train", "epochs": 1, "timestep": 440, "ep_reward": 223.75648498535156, "reward": 0.41821593046188354, "action": 1.0313646793365479}
{"mode": "train", "epochs": 1, "timestep": 441, "ep_reward": 224.17013549804688, "reward": 0.4136470556259155, "action": 1.10934317111969}
{"mode": "train", "epochs": 1, "timestep": 442, "ep_reward": 224.58114624023438, "reward": 0.41101109981536865, "action": 1.4472640752792358}
{"mode": "train", "epochs": 1, "timestep": 443, "ep_reward": 224.99266052246094, "reward": 0.4115180969238281, "action": 0.6801410913467407}
{"mode": "train", "epochs": 1, "timestep": 444, "ep_reward": 225.4051971435547, "reward": 0.41253405809402466, "action": 1.6161551475524902}
{"mode": "train", "epochs": 1, "timestep": 445, "ep_reward": 225.82225036621094, "reward": 0.4170491099357605, "action": -0.26343590021133423}
{"mode": "train", "epochs": 1, "timestep": 446, "ep_reward": 226.2419891357422, "reward": 0.41973990201950073, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 447, "ep_reward": 226.668212890625, "reward": 0.4262300729751587, "action": 0.7672784328460693}
{"mode": "train", "epochs": 1, "timestep": 448, "ep_reward": 227.10183715820312, "reward": 0.4336315989494324, "action": 0.4690791070461273}
{"mode": "train", "epochs": 1, "timestep": 449, "ep_reward": 227.54248046875, "reward": 0.4406476616859436, "action": 0.9429696798324585}
{"mode": "train", "epochs": 1, "timestep": 450, "ep_reward": 227.99041748046875, "reward": 0.44794023036956787, "action": 0.49208489060401917}
{"mode": "train", "epochs": 1, "timestep": 451, "ep_reward": 228.44491577148438, "reward": 0.4545050859451294, "action": 0.6719251871109009}
{"mode": "train", "epochs": 1, "timestep": 452, "ep_reward": 228.90505981445312, "reward": 0.46014857292175293, "action": 1.2313783168792725}
{"mode": "train", "epochs": 1, "timestep": 453, "ep_reward": 229.37115478515625, "reward": 0.46609026193618774, "action": 1.477332353591919}
{"mode": "train", "epochs": 1, "timestep": 454, "ep_reward": 229.84422302246094, "reward": 0.47306299209594727, "action": 0.5401307344436646}
{"mode": "train", "epochs": 1, "timestep": 455, "ep_reward": 230.32289123535156, "reward": 0.4786617159843445, "action": 1.506273865699768}
{"mode": "train", "epochs": 1, "timestep": 456, "ep_reward": 230.80746459960938, "reward": 0.48457175493240356, "action": 0.5907928943634033}
{"mode": "train", "epochs": 1, "timestep": 457, "ep_reward": 231.2962188720703, "reward": 0.48874759674072266, "action": 1.3695831298828125}
{"mode": "train", "epochs": 1, "timestep": 458, "ep_reward": 231.7888641357422, "reward": 0.4926493167877197, "action": 0.6933944225311279}
{"mode": "train", "epochs": 1, "timestep": 459, "ep_reward": 232.28343200683594, "reward": 0.4945734739303589, "action": 1.351245641708374}
{"mode": "train", "epochs": 1, "timestep": 460, "ep_reward": 232.77947998046875, "reward": 0.4960528016090393, "action": 1.4056326150894165}
{"mode": "train", "epochs": 1, "timestep": 461, "ep_reward": 233.27674865722656, "reward": 0.49726641178131104, "action": 1.6255476474761963}
{"mode": "train", "epochs": 1, "timestep": 462, "ep_reward": 233.77560424804688, "reward": 0.49885261058807373, "action": 1.383988857269287}
{"mode": "train", "epochs": 1, "timestep": 463, "ep_reward": 234.27566528320312, "reward": 0.500053882598877, "action": 1.3607072830200195}
{"mode": "train", "epochs": 1, "timestep": 464, "ep_reward": 234.77651977539062, "reward": 0.5008581280708313, "action": 0.5914500951766968}
{"mode": "train", "epochs": 1, "timestep": 465, "ep_reward": 235.27548217773438, "reward": 0.4989628195762634, "action": -0.19640135765075684}
{"mode": "train", "epochs": 1, "timestep": 466, "ep_reward": 235.7672119140625, "reward": 0.4917335510253906, "action": 0.5888108015060425}
{"mode": "train", "epochs": 1, "timestep": 467, "ep_reward": 236.24945068359375, "reward": 0.4822348356246948, "action": 0.9048332571983337}
{"mode": "train", "epochs": 1, "timestep": 468, "ep_reward": 236.72125244140625, "reward": 0.4717997908592224, "action": 1.1263779401779175}
{"mode": "train", "epochs": 1, "timestep": 469, "ep_reward": 237.18272399902344, "reward": 0.46147382259368896, "action": 1.1022907495498657}
{"mode": "train", "epochs": 1, "timestep": 470, "ep_reward": 237.63404846191406, "reward": 0.4513281583786011, "action": 0.9215526580810547}
{"mode": "train", "epochs": 1, "timestep": 471, "ep_reward": 238.074951171875, "reward": 0.4408975839614868, "action": 1.7447484731674194}
{"mode": "train", "epochs": 1, "timestep": 472, "ep_reward": 238.5092315673828, "reward": 0.4342809319496155, "action": 0.4063184857368469}
{"mode": "train", "epochs": 1, "timestep": 473, "ep_reward": 238.9346923828125, "reward": 0.42545926570892334, "action": 1.4002623558044434}
{"mode": "train", "epochs": 1, "timestep": 474, "ep_reward": 239.35467529296875, "reward": 0.41999053955078125, "action": 0.6809161901473999}
{"mode": "train", "epochs": 1, "timestep": 475, "ep_reward": 239.76905822753906, "reward": 0.41437995433807373, "action": 1.3555153608322144}
{"mode": "train", "epochs": 1, "timestep": 476, "ep_reward": 240.1807861328125, "reward": 0.4117274880409241, "action": 1.8684451580047607}
{"mode": "train", "epochs": 1, "timestep": 477, "ep_reward": 240.59414672851562, "reward": 0.41335898637771606, "action": 0.9200425148010254}
{"mode": "train", "epochs": 1, "timestep": 478, "ep_reward": 241.01026916503906, "reward": 0.41612744331359863, "action": 0.8191571235656738}
{"mode": "train", "epochs": 1, "timestep": 479, "ep_reward": 241.43026733398438, "reward": 0.42000019550323486, "action": 0.5038747787475586}
{"mode": "train", "epochs": 1, "timestep": 480, "ep_reward": 241.8540802001953, "reward": 0.42380958795547485, "action": 1.9238805770874023}
{"mode": "train", "epochs": 1, "timestep": 481, "ep_reward": 242.28518676757812, "reward": 0.4310992956161499, "action": 1.0892823934555054}
{"mode": "train", "epochs": 1, "timestep": 482, "ep_reward": 242.72500610351562, "reward": 0.439816951751709, "action": 1.512777328491211}
{"mode": "train", "epochs": 1, "timestep": 483, "ep_reward": 243.17520141601562, "reward": 0.45020121335983276, "action": 1.700684666633606}
{"mode": "train", "epochs": 1, "timestep": 484, "ep_reward": 243.6377716064453, "reward": 0.46257346868515015, "action": 1.1535457372665405}
{"mode": "train", "epochs": 1, "timestep": 485, "ep_reward": 244.11358642578125, "reward": 0.475810170173645, "action": 0.7904662489891052}
{"mode": "train", "epochs": 1, "timestep": 486, "ep_reward": 244.60166931152344, "reward": 0.4880770444869995, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 487, "ep_reward": 245.10238647460938, "reward": 0.5007197260856628, "action": 1.2645578384399414}
{"mode": "train", "epochs": 1, "timestep": 488, "ep_reward": 245.6157684326172, "reward": 0.5133804082870483, "action": 1.2998663187026978}
{"mode": "train", "epochs": 1, "timestep": 489, "ep_reward": 246.140625, "reward": 0.5248500108718872, "action": 1.1354308128356934}
{"mode": "train", "epochs": 1, "timestep": 490, "ep_reward": 246.67503356933594, "reward": 0.5344122648239136, "action": 1.3698101043701172}
{"mode": "train", "epochs": 1, "timestep": 491, "ep_reward": 247.21701049804688, "reward": 0.5419721603393555, "action": 1.5663220882415771}
{"mode": "train", "epochs": 1, "timestep": 492, "ep_reward": 247.76502990722656, "reward": 0.5480220317840576, "action": 1.0275121927261353}
{"mode": "train", "epochs": 1, "timestep": 493, "ep_reward": 248.31625366210938, "reward": 0.5512313842773438, "action": 0.11856359243392944}
{"mode": "train", "epochs": 1, "timestep": 494, "ep_reward": 248.86471557617188, "reward": 0.5484676361083984, "action": 0.9159224629402161}
{"mode": "train", "epochs": 1, "timestep": 495, "ep_reward": 249.40655517578125, "reward": 0.5418362617492676, "action": 1.3929264545440674}
{"mode": "train", "epochs": 1, "timestep": 496, "ep_reward": 249.93994140625, "reward": 0.5333861708641052, "action": 1.7452548742294312}
{"mode": "train", "epochs": 1, "timestep": 497, "ep_reward": 250.46458435058594, "reward": 0.5246438384056091, "action": 1.3560285568237305}
{"mode": "train", "epochs": 1, "timestep": 498, "ep_reward": 250.97872924804688, "reward": 0.5141504406929016, "action": 0.07642233371734619}
{"mode": "train", "epochs": 1, "timestep": 499, "ep_reward": 251.47598266601562, "reward": 0.49725157022476196, "action": 0.9240657687187195}
{"mode": "train", "epochs": 1, "timestep": 500, "ep_reward": 251.9556427001953, "reward": 0.47966688871383667, "action": 0.757226824760437}
{"mode": "train", "epochs": 1, "timestep": 501, "ep_reward": 252.41583251953125, "reward": 0.460188090801239, "action": 0.7863047122955322}
{"mode": "train", "epochs": 1, "timestep": 502, "ep_reward": 252.85586547851562, "reward": 0.4400287866592407, "action": 0.3426429033279419}
{"mode": "train", "epochs": 1, "timestep": 503, "ep_reward": 253.27340698242188, "reward": 0.41753387451171875, "action": 1.5743358135223389}
{"mode": "train", "epochs": 1, "timestep": 504, "ep_reward": 253.67433166503906, "reward": 0.40092790126800537, "action": 0.44967466592788696}
{"mode": "train", "epochs": 1, "timestep": 505, "ep_reward": 254.0568084716797, "reward": 0.3824821710586548, "action": 0.9455462098121643}
{"mode": "train", "epochs": 1, "timestep": 506, "ep_reward": 254.4465789794922, "reward": 0.389764666557312, "action": 1.5159296989440918}
{"mode": "train", "epochs": 1, "timestep": 507, "ep_reward": 254.849853515625, "reward": 0.40327852964401245, "action": 1.1521624326705933}
{"mode": "train", "epochs": 1, "timestep": 508, "ep_reward": 255.26141357421875, "reward": 0.41156405210494995, "action": 1.2704439163208008}
{"mode": "train", "epochs": 1, "timestep": 509, "ep_reward": 255.6760711669922, "reward": 0.41465502977371216, "action": 0.6027835607528687}
{"mode": "train", "epochs": 1, "timestep": 510, "ep_reward": 256.09014892578125, "reward": 0.414090096950531, "action": 0.7269008159637451}
{"mode": "train", "epochs": 1, "timestep": 511, "ep_reward": 256.5001220703125, "reward": 0.4099724292755127, "action": 0.671419620513916}
{"mode": "train", "epochs": 1, "timestep": 512, "ep_reward": 256.9027404785156, "reward": 0.402614951133728, "action": 0.49039843678474426}
{"mode": "train", "epochs": 1, "timestep": 513, "ep_reward": 257.29571533203125, "reward": 0.39297205209732056, "action": 0.4660795331001282}
{"mode": "train", "epochs": 1, "timestep": 514, "ep_reward": 257.67706298828125, "reward": 0.3813595771789551, "action": 1.3413540124893188}
{"mode": "train", "epochs": 1, "timestep": 515, "ep_reward": 258.07110595703125, "reward": 0.39402925968170166, "action": 1.118774652481079}
{"mode": "train", "epochs": 1, "timestep": 516, "ep_reward": 258.4810791015625, "reward": 0.40996861457824707, "action": 0.73990797996521}
{"mode": "train", "epochs": 1, "timestep": 517, "ep_reward": 258.90850830078125, "reward": 0.42742741107940674, "action": 0.6616197824478149}
{"mode": "train", "epochs": 1, "timestep": 518, "ep_reward": 259.3537292480469, "reward": 0.4452075958251953, "action": 0.13972407579421997}
{"mode": "train", "epochs": 1, "timestep": 519, "ep_reward": 259.8156433105469, "reward": 0.4619086980819702, "action": 0.4235301911830902}
{"mode": "train", "epochs": 1, "timestep": 520, "ep_reward": 260.29193115234375, "reward": 0.4762750267982483, "action": 1.09663987159729}
{"mode": "train", "epochs": 1, "timestep": 521, "ep_reward": 260.7812194824219, "reward": 0.4892957806587219, "action": 1.280098795890808}
{"mode": "train", "epochs": 1, "timestep": 522, "ep_reward": 261.2829284667969, "reward": 0.5017210245132446, "action": 1.3756465911865234}
{"mode": "train", "epochs": 1, "timestep": 523, "ep_reward": 261.7964782714844, "reward": 0.5135627388954163, "action": 0.87851881980896}
{"mode": "train", "epochs": 1, "timestep": 524, "ep_reward": 262.32012939453125, "reward": 0.5236458778381348, "action": 0.46382656693458557}
{"mode": "train", "epochs": 1, "timestep": 525, "ep_reward": 262.8501281738281, "reward": 0.5300118327140808, "action": 1.3266043663024902}
{"mode": "train", "epochs": 1, "timestep": 526, "ep_reward": 263.38427734375, "reward": 0.5341377258300781, "action": 0.4550739526748657}
{"mode": "train", "epochs": 1, "timestep": 527, "ep_reward": 263.91845703125, "reward": 0.5341841578483582, "action": 0.36386823654174805}
{"mode": "train", "epochs": 1, "timestep": 528, "ep_reward": 264.44769287109375, "reward": 0.5292220115661621, "action": 1.2457979917526245}
{"mode": "train", "epochs": 1, "timestep": 529, "ep_reward": 264.9700927734375, "reward": 0.5223926901817322, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 530, "ep_reward": 265.4868469238281, "reward": 0.516741156578064, "action": 0.9846346974372864}
{"mode": "train", "epochs": 1, "timestep": 531, "ep_reward": 265.9948425292969, "reward": 0.508010745048523, "action": 1.5145587921142578}
{"mode": "train", "epochs": 1, "timestep": 532, "ep_reward": 266.49432373046875, "reward": 0.499487042427063, "action": 0.3490988612174988}
{"mode": "train", "epochs": 1, "timestep": 533, "ep_reward": 266.98046875, "reward": 0.48614388704299927, "action": 1.9308401346206665}
{"mode": "train", "epochs": 1, "timestep": 534, "ep_reward": 267.4568786621094, "reward": 0.4764171838760376, "action": 1.1606314182281494}
{"mode": "train", "epochs": 1, "timestep": 535, "ep_reward": 267.92236328125, "reward": 0.46547389030456543, "action": 0.9790193438529968}
{"mode": "train", "epochs": 1, "timestep": 536, "ep_reward": 268.3762512207031, "reward": 0.4538782835006714, "action": 1.674346923828125}
{"mode": "train", "epochs": 1, "timestep": 537, "ep_reward": 268.821533203125, "reward": 0.44528907537460327, "action": 1.0882357358932495}
{"mode": "train", "epochs": 1, "timestep": 538, "ep_reward": 269.25823974609375, "reward": 0.4366934895515442, "action": 1.2526119947433472}
{"mode": "train", "epochs": 1, "timestep": 539, "ep_reward": 269.6879577636719, "reward": 0.4297330975532532, "action": 1.4916822910308838}
{"mode": "train", "epochs": 1, "timestep": 540, "ep_reward": 270.1133728027344, "reward": 0.42541927099227905, "action": 1.056905746459961}
{"mode": "train", "epochs": 1, "timestep": 541, "ep_reward": 270.5353088378906, "reward": 0.4219479560852051, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 542, "ep_reward": 270.958251953125, "reward": 0.4229430556297302, "action": 1.8146848678588867}
{"mode": "train", "epochs": 1, "timestep": 543, "ep_reward": 271.3854675292969, "reward": 0.42722195386886597, "action": 0.6819919943809509}
{"mode": "train", "epochs": 1, "timestep": 544, "ep_reward": 271.8173522949219, "reward": 0.4318968653678894, "action": 0.6348934173583984}
{"mode": "train", "epochs": 1, "timestep": 545, "ep_reward": 272.2539367675781, "reward": 0.43657296895980835, "action": 0.834435760974884}
{"mode": "train", "epochs": 1, "timestep": 546, "ep_reward": 272.6955261230469, "reward": 0.44160354137420654, "action": 0.060779571533203125}
{"mode": "train", "epochs": 1, "timestep": 547, "ep_reward": 273.1403503417969, "reward": 0.4448186755180359, "action": 1.4671835899353027}
{"mode": "train", "epochs": 1, "timestep": 548, "ep_reward": 273.5899353027344, "reward": 0.4495725631713867, "action": 0.38164079189300537}
{"mode": "train", "epochs": 1, "timestep": 549, "ep_reward": 274.043212890625, "reward": 0.45329153537750244, "action": 0.461758553981781}
{"mode": "train", "epochs": 1, "timestep": 550, "ep_reward": 274.4987487792969, "reward": 0.45553356409072876, "action": 1.5330370664596558}
{"mode": "train", "epochs": 1, "timestep": 551, "ep_reward": 274.9580078125, "reward": 0.4592694640159607, "action": 1.1427571773529053}
{"mode": "train", "epochs": 1, "timestep": 552, "ep_reward": 275.4215087890625, "reward": 0.4635047912597656, "action": 0.5658930540084839}
{"mode": "train", "epochs": 1, "timestep": 553, "ep_reward": 275.8880615234375, "reward": 0.466561496257782, "action": 0.5284422039985657}
{"mode": "train", "epochs": 1, "timestep": 554, "ep_reward": 276.3560791015625, "reward": 0.468015193939209, "action": 0.3575553297996521}
{"mode": "train", "epochs": 1, "timestep": 555, "ep_reward": 276.8233337402344, "reward": 0.4672418236732483, "action": 1.0027849674224854}
{"mode": "train", "epochs": 1, "timestep": 556, "ep_reward": 277.2894592285156, "reward": 0.4661121368408203, "action": 1.6526092290878296}
{"mode": "train", "epochs": 1, "timestep": 557, "ep_reward": 277.7562255859375, "reward": 0.4667676091194153, "action": 0.9936956763267517}
{"mode": "train", "epochs": 1, "timestep": 558, "ep_reward": 278.2232971191406, "reward": 0.46705836057662964, "action": 0.6814473867416382}
{"mode": "train", "epochs": 1, "timestep": 559, "ep_reward": 278.68939208984375, "reward": 0.46609699726104736, "action": 1.1856647729873657}
{"mode": "train", "epochs": 1, "timestep": 560, "ep_reward": 279.15484619140625, "reward": 0.4654518961906433, "action": 1.3963793516159058}
{"mode": "train", "epochs": 1, "timestep": 561, "ep_reward": 279.62060546875, "reward": 0.46577131748199463, "action": 0.9847540259361267}
{"mode": "train", "epochs": 1, "timestep": 562, "ep_reward": 280.0863342285156, "reward": 0.4657294750213623, "action": 1.1934075355529785}
{"mode": "train", "epochs": 1, "timestep": 563, "ep_reward": 280.55218505859375, "reward": 0.4658583998680115, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 564, "ep_reward": 281.02081298828125, "reward": 0.46862006187438965, "action": 1.4769147634506226}
{"mode": "train", "epochs": 1, "timestep": 565, "ep_reward": 281.4931945800781, "reward": 0.4723842144012451, "action": -0.2126491665840149}
{"mode": "train", "epochs": 1, "timestep": 566, "ep_reward": 281.9657897949219, "reward": 0.4726102352142334, "action": 0.43563854694366455}
{"mode": "train", "epochs": 1, "timestep": 567, "ep_reward": 282.4361877441406, "reward": 0.4704020619392395, "action": 1.2724418640136719}
{"mode": "train", "epochs": 1, "timestep": 568, "ep_reward": 282.9048156738281, "reward": 0.4686262011528015, "action": 1.8087501525878906}
{"mode": "train", "epochs": 1, "timestep": 569, "ep_reward": 283.37384033203125, "reward": 0.46903306245803833, "action": 0.6651773452758789}
{"mode": "train", "epochs": 1, "timestep": 570, "ep_reward": 283.8416748046875, "reward": 0.4678495526313782, "action": 1.3186721801757812}
{"mode": "train", "epochs": 1, "timestep": 571, "ep_reward": 284.3091125488281, "reward": 0.467451810836792, "action": 0.4094688296318054}
{"mode": "train", "epochs": 1, "timestep": 572, "ep_reward": 284.77392578125, "reward": 0.4648064374923706, "action": 1.4731749296188354}
{"mode": "train", "epochs": 1, "timestep": 573, "ep_reward": 285.23760986328125, "reward": 0.46368348598480225, "action": 0.5322598218917847}
{"mode": "train", "epochs": 1, "timestep": 574, "ep_reward": 285.69842529296875, "reward": 0.46080148220062256, "action": 0.7587112784385681}
{"mode": "train", "epochs": 1, "timestep": 575, "ep_reward": 286.1556091308594, "reward": 0.45718348026275635, "action": 1.240305781364441}
{"mode": "train", "epochs": 1, "timestep": 576, "ep_reward": 286.6101989746094, "reward": 0.454597532749176, "action": 0.6567303538322449}
{"mode": "train", "epochs": 1, "timestep": 577, "ep_reward": 287.0611267089844, "reward": 0.45092374086380005, "action": 1.2259867191314697}
{"mode": "train", "epochs": 1, "timestep": 578, "ep_reward": 287.50958251953125, "reward": 0.4484463930130005, "action": 1.1921775341033936}
{"mode": "train", "epochs": 1, "timestep": 579, "ep_reward": 287.9564208984375, "reward": 0.4468364715576172, "action": 1.4054220914840698}
{"mode": "train", "epochs": 1, "timestep": 580, "ep_reward": 288.40338134765625, "reward": 0.44696080684661865, "action": -0.0010570883750915527}
{"mode": "train", "epochs": 1, "timestep": 581, "ep_reward": 288.8477783203125, "reward": 0.44438791275024414, "action": 1.2709622383117676}
{"mode": "train", "epochs": 1, "timestep": 582, "ep_reward": 289.291259765625, "reward": 0.4434884190559387, "action": 0.6463000178337097}
{"mode": "train", "epochs": 1, "timestep": 583, "ep_reward": 289.733154296875, "reward": 0.44189929962158203, "action": 1.5568444728851318}
{"mode": "train", "epochs": 1, "timestep": 584, "ep_reward": 290.1759948730469, "reward": 0.44282639026641846, "action": 0.5444955825805664}
{"mode": "train", "epochs": 1, "timestep": 585, "ep_reward": 290.61895751953125, "reward": 0.44296592473983765, "action": 0.3366524577140808}
{"mode": "train", "epochs": 1, "timestep": 586, "ep_reward": 291.06060791015625, "reward": 0.4416634440422058, "action": 1.6473124027252197}
{"mode": "train", "epochs": 1, "timestep": 587, "ep_reward": 291.5037536621094, "reward": 0.44314682483673096, "action": 0.7285349369049072}
{"mode": "train", "epochs": 1, "timestep": 588, "ep_reward": 291.94805908203125, "reward": 0.44431424140930176, "action": 1.1442394256591797}
{"mode": "train", "epochs": 1, "timestep": 589, "ep_reward": 292.39453125, "reward": 0.4464731216430664, "action": 0.8041355609893799}
{"mode": "train", "epochs": 1, "timestep": 590, "ep_reward": 292.8429870605469, "reward": 0.4484673738479614, "action": 1.6123313903808594}
{"mode": "train", "epochs": 1, "timestep": 591, "ep_reward": 293.2954406738281, "reward": 0.45245444774627686, "action": 1.527173399925232}
{"mode": "train", "epochs": 1, "timestep": 592, "ep_reward": 293.7534484863281, "reward": 0.4580000042915344, "action": 1.7170565128326416}
{"mode": "train", "epochs": 1, "timestep": 593, "ep_reward": 294.2189025878906, "reward": 0.4654553532600403, "action": 1.152876853942871}
{"mode": "train", "epochs": 1, "timestep": 594, "ep_reward": 294.69232177734375, "reward": 0.4734261631965637, "action": 0.7377858757972717}
{"mode": "train", "epochs": 1, "timestep": 595, "ep_reward": 295.17279052734375, "reward": 0.4804689884185791, "action": 0.2244550585746765}
{"mode": "train", "epochs": 1, "timestep": 596, "ep_reward": 295.6575622558594, "reward": 0.48477429151535034, "action": 0.7258026599884033}
{"mode": "train", "epochs": 1, "timestep": 597, "ep_reward": 296.1446228027344, "reward": 0.4870593547821045, "action": 0.7187649011611938}
{"mode": "train", "epochs": 1, "timestep": 598, "ep_reward": 296.632080078125, "reward": 0.48745763301849365, "action": 1.0468508005142212}
{"mode": "train", "epochs": 1, "timestep": 599, "ep_reward": 297.1188659667969, "reward": 0.4868001341819763, "action": 1.7851996421813965}
{"mode": "train", "epochs": 1, "timestep": 600, "ep_reward": 297.60638427734375, "reward": 0.4875214099884033, "action": 1.1253128051757812}
{"mode": "train", "epochs": 1, "timestep": 601, "ep_reward": 298.0939025878906, "reward": 0.4875320792198181, "action": 0.42645132541656494}
{"mode": "train", "epochs": 1, "timestep": 602, "ep_reward": 298.57861328125, "reward": 0.484708309173584, "action": 1.2305710315704346}
{"mode": "train", "epochs": 1, "timestep": 603, "ep_reward": 299.0604248046875, "reward": 0.48180800676345825, "action": 0.9772294163703918}
{"mode": "train", "epochs": 1, "timestep": 604, "ep_reward": 299.538330078125, "reward": 0.4779079556465149, "action": 1.0157185792922974}
{"mode": "train", "epochs": 1, "timestep": 605, "ep_reward": 300.0116882324219, "reward": 0.47336477041244507, "action": 1.1267503499984741}
{"mode": "train", "epochs": 1, "timestep": 606, "ep_reward": 300.4804382324219, "reward": 0.4687483310699463, "action": 0.8874312043190002}
{"mode": "train", "epochs": 1, "timestep": 607, "ep_reward": 300.9438171386719, "reward": 0.46337318420410156, "action": 0.3385070562362671}
{"mode": "train", "epochs": 1, "timestep": 608, "ep_reward": 301.39935302734375, "reward": 0.4555288553237915, "action": 1.165578842163086}
{"mode": "train", "epochs": 1, "timestep": 609, "ep_reward": 301.8482971191406, "reward": 0.44894206523895264, "action": 0.8180899024009705}
{"mode": "train", "epochs": 1, "timestep": 610, "ep_reward": 302.2902526855469, "reward": 0.4419625401496887, "action": 0.6233939528465271}
{"mode": "train", "epochs": 1, "timestep": 611, "ep_reward": 302.72467041015625, "reward": 0.4344070553779602, "action": 0.716912031173706}
{"mode": "train", "epochs": 1, "timestep": 612, "ep_reward": 303.151611328125, "reward": 0.42695367336273193, "action": 1.4839375019073486}
{"mode": "train", "epochs": 1, "timestep": 613, "ep_reward": 303.5743713378906, "reward": 0.4227457046508789, "action": 0.829952597618103}
{"mode": "train", "epochs": 1, "timestep": 614, "ep_reward": 303.9932861328125, "reward": 0.4189172387123108, "action": 0.6929638981819153}
{"mode": "train", "epochs": 1, "timestep": 615, "ep_reward": 304.4089050292969, "reward": 0.41562551259994507, "action": 1.0149542093276978}
{"mode": "train", "epochs": 1, "timestep": 616, "ep_reward": 304.82305908203125, "reward": 0.4141676425933838, "action": 0.5890569686889648}
{"mode": "train", "epochs": 1, "timestep": 617, "ep_reward": 305.2361755371094, "reward": 0.4131084084510803, "action": -0.0629625916481018}
{"mode": "train", "epochs": 1, "timestep": 618, "ep_reward": 305.6468200683594, "reward": 0.4106323719024658, "action": -0.05234217643737793}
{"mode": "train", "epochs": 1, "timestep": 619, "ep_reward": 306.0536804199219, "reward": 0.4068721532821655, "action": 0.9982710480690002}
{"mode": "train", "epochs": 1, "timestep": 620, "ep_reward": 306.4590148925781, "reward": 0.4053495526313782, "action": 1.6240109205245972}
{"mode": "train", "epochs": 1, "timestep": 621, "ep_reward": 306.86669921875, "reward": 0.4076891541481018, "action": 0.8748620748519897}
{"mode": "train", "epochs": 1, "timestep": 622, "ep_reward": 307.2779541015625, "reward": 0.41124969720840454, "action": 1.7331125736236572}
{"mode": "train", "epochs": 1, "timestep": 623, "ep_reward": 307.69635009765625, "reward": 0.41840076446533203, "action": 0.5933205485343933}
{"mode": "train", "epochs": 1, "timestep": 624, "ep_reward": 308.1226806640625, "reward": 0.42632198333740234, "action": 1.053792119026184}
{"mode": "train", "epochs": 1, "timestep": 625, "ep_reward": 308.557861328125, "reward": 0.43517762422561646, "action": 1.5954387187957764}
{"mode": "train", "epochs": 1, "timestep": 626, "ep_reward": 309.0039978027344, "reward": 0.44612830877304077, "action": 0.8426933884620667}
{"mode": "train", "epochs": 1, "timestep": 627, "ep_reward": 309.4617614746094, "reward": 0.4577598571777344, "action": 0.9584576487541199}
{"mode": "train", "epochs": 1, "timestep": 628, "ep_reward": 309.930908203125, "reward": 0.46915268898010254, "action": 1.2342387437820435}
{"mode": "train", "epochs": 1, "timestep": 629, "ep_reward": 310.4114685058594, "reward": 0.48056262731552124, "action": 0.889275848865509}
{"mode": "train", "epochs": 1, "timestep": 630, "ep_reward": 310.902587890625, "reward": 0.4911261200904846, "action": 1.5930237770080566}
{"mode": "train", "epochs": 1, "timestep": 631, "ep_reward": 311.4040832519531, "reward": 0.5014803409576416, "action": 1.377707600593567}
{"mode": "train", "epochs": 1, "timestep": 632, "ep_reward": 311.9155578613281, "reward": 0.511470377445221, "action": 1.6031908988952637}
{"mode": "train", "epochs": 1, "timestep": 633, "ep_reward": 312.43658447265625, "reward": 0.5210367441177368, "action": 1.3336915969848633}
{"mode": "train", "epochs": 1, "timestep": 634, "ep_reward": 312.96612548828125, "reward": 0.5295273065567017, "action": 1.161181926727295}
{"mode": "train", "epochs": 1, "timestep": 635, "ep_reward": 313.502197265625, "reward": 0.5360621213912964, "action": 0.7398673295974731}
{"mode": "train", "epochs": 1, "timestep": 636, "ep_reward": 314.0413818359375, "reward": 0.5391912460327148, "action": 0.9670183658599854}
{"mode": "train", "epochs": 1, "timestep": 637, "ep_reward": 314.580322265625, "reward": 0.5389404296875, "action": 1.7439055442810059}
{"mode": "train", "epochs": 1, "timestep": 638, "ep_reward": 315.1183166503906, "reward": 0.5379942059516907, "action": 0.7065087556838989}
{"mode": "train", "epochs": 1, "timestep": 639, "ep_reward": 315.6513366699219, "reward": 0.533012866973877, "action": 1.0952883958816528}
{"mode": "train", "epochs": 1, "timestep": 640, "ep_reward": 316.17694091796875, "reward": 0.525607705116272, "action": 1.0393180847167969}
{"mode": "train", "epochs": 1, "timestep": 641, "ep_reward": 316.6925048828125, "reward": 0.5155576467514038, "action": 1.9091007709503174}
{"mode": "train", "epochs": 1, "timestep": 642, "ep_reward": 317.19952392578125, "reward": 0.5070321559906006, "action": 0.2172410488128662}
{"mode": "train", "epochs": 1, "timestep": 643, "ep_reward": 317.6921081542969, "reward": 0.4925733804702759, "action": 0.40650540590286255}
{"mode": "train", "epochs": 1, "timestep": 644, "ep_reward": 318.1671447753906, "reward": 0.47503530979156494, "action": 0.956088125705719}
{"mode": "train", "epochs": 1, "timestep": 645, "ep_reward": 318.6247253417969, "reward": 0.4575696587562561, "action": 0.3869894742965698}
{"mode": "train", "epochs": 1, "timestep": 646, "ep_reward": 319.0619201660156, "reward": 0.4371987581253052, "action": 1.1529039144515991}
{"mode": "train", "epochs": 1, "timestep": 647, "ep_reward": 319.4814758300781, "reward": 0.4195576310157776, "action": 0.5441317558288574}
{"mode": "train", "epochs": 1, "timestep": 648, "ep_reward": 319.88232421875, "reward": 0.4008415937423706, "action": 0.6482670307159424}
{"mode": "train", "epochs": 1, "timestep": 649, "ep_reward": 320.26568603515625, "reward": 0.3833625316619873, "action": 1.4299312829971313}
{"mode": "train", "epochs": 1, "timestep": 650, "ep_reward": 320.6539611816406, "reward": 0.3882881999015808, "action": 0.8082966804504395}
{"mode": "train", "epochs": 1, "timestep": 651, "ep_reward": 321.05474853515625, "reward": 0.40078651905059814, "action": 0.901600182056427}
{"mode": "train", "epochs": 1, "timestep": 652, "ep_reward": 321.46453857421875, "reward": 0.40978795289993286, "action": 1.1659128665924072}
{"mode": "train", "epochs": 1, "timestep": 653, "ep_reward": 321.8787841796875, "reward": 0.41424494981765747, "action": 0.5167756676673889}
{"mode": "train", "epochs": 1, "timestep": 654, "ep_reward": 322.2940979003906, "reward": 0.41531825065612793, "action": 0.7117122411727905}
{"mode": "train", "epochs": 1, "timestep": 655, "ep_reward": 322.7068176269531, "reward": 0.41270899772644043, "action": 1.855722188949585}
{"mode": "train", "epochs": 1, "timestep": 656, "ep_reward": 323.1097106933594, "reward": 0.40288591384887695, "action": -0.10880935192108154}
{"mode": "train", "epochs": 1, "timestep": 657, "ep_reward": 323.5030822753906, "reward": 0.39338433742523193, "action": 0.31787002086639404}
{"mode": "train", "epochs": 1, "timestep": 658, "ep_reward": 323.88519287109375, "reward": 0.3821210265159607, "action": 0.4749446511268616}
{"mode": "train", "epochs": 1, "timestep": 659, "ep_reward": 324.27716064453125, "reward": 0.39197099208831787, "action": 1.0618152618408203}
{"mode": "train", "epochs": 1, "timestep": 660, "ep_reward": 324.6826477050781, "reward": 0.4054824709892273, "action": 1.41579270362854}
{"mode": "train", "epochs": 1, "timestep": 661, "ep_reward": 325.10394287109375, "reward": 0.42129606008529663, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 662, "ep_reward": 325.5440673828125, "reward": 0.4401360750198364, "action": 0.4869000315666199}
{"mode": "train", "epochs": 1, "timestep": 663, "ep_reward": 326.0049133300781, "reward": 0.4608449339866638, "action": 0.8815293312072754}
{"mode": "train", "epochs": 1, "timestep": 664, "ep_reward": 326.4851989746094, "reward": 0.4802709221839905, "action": 1.1545097827911377}
{"mode": "train", "epochs": 1, "timestep": 665, "ep_reward": 326.9840393066406, "reward": 0.49884194135665894, "action": 0.4299965500831604}
{"mode": "train", "epochs": 1, "timestep": 666, "ep_reward": 327.4996337890625, "reward": 0.51560378074646, "action": 0.23622053861618042}
{"mode": "train", "epochs": 1, "timestep": 667, "ep_reward": 328.02777099609375, "reward": 0.5281393527984619, "action": 0.7829506397247314}
{"mode": "train", "epochs": 1, "timestep": 668, "ep_reward": 328.5643310546875, "reward": 0.5365609526634216, "action": 1.2620748281478882}
{"mode": "train", "epochs": 1, "timestep": 669, "ep_reward": 329.1068115234375, "reward": 0.5424652695655823, "action": 0.8146195411682129}
{"mode": "train", "epochs": 1, "timestep": 670, "ep_reward": 329.65179443359375, "reward": 0.5449968576431274, "action": 0.3332299590110779}
{"mode": "train", "epochs": 1, "timestep": 671, "ep_reward": 330.194091796875, "reward": 0.5423029661178589, "action": 0.4924740195274353}
{"mode": "train", "epochs": 1, "timestep": 672, "ep_reward": 330.72869873046875, "reward": 0.5346091389656067, "action": 1.3511677980422974}
{"mode": "train", "epochs": 1, "timestep": 673, "ep_reward": 331.25433349609375, "reward": 0.5256203413009644, "action": 0.409484326839447}
{"mode": "train", "epochs": 1, "timestep": 674, "ep_reward": 331.76556396484375, "reward": 0.5112175941467285, "action": 1.7426495552062988}
{"mode": "train", "epochs": 1, "timestep": 675, "ep_reward": 332.2642822265625, "reward": 0.4987218379974365, "action": 0.7130032181739807}
{"mode": "train", "epochs": 1, "timestep": 676, "ep_reward": 332.74639892578125, "reward": 0.4821281433105469, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 677, "ep_reward": 333.2160949707031, "reward": 0.46970826387405396, "action": 0.5165083408355713}
{"mode": "train", "epochs": 1, "timestep": 678, "ep_reward": 333.66912841796875, "reward": 0.4530336856842041, "action": 1.0087419748306274}
{"mode": "train", "epochs": 1, "timestep": 679, "ep_reward": 334.1064453125, "reward": 0.43731361627578735, "action": 1.1916766166687012}
{"mode": "train", "epochs": 1, "timestep": 680, "ep_reward": 334.52972412109375, "reward": 0.42327868938446045, "action": 0.5166209936141968}
{"mode": "train", "epochs": 1, "timestep": 681, "ep_reward": 334.9377746582031, "reward": 0.4080612063407898, "action": 0.8867078423500061}
{"mode": "train", "epochs": 1, "timestep": 682, "ep_reward": 335.33270263671875, "reward": 0.3949360251426697, "action": 1.2487528324127197}
{"mode": "train", "epochs": 1, "timestep": 683, "ep_reward": 335.7179260253906, "reward": 0.38521283864974976, "action": 1.8647621870040894}
{"mode": "train", "epochs": 1, "timestep": 684, "ep_reward": 336.10174560546875, "reward": 0.38382983207702637, "action": 1.7549906969070435}
{"mode": "train", "epochs": 1, "timestep": 685, "ep_reward": 336.4866027832031, "reward": 0.384871244430542, "action": 0.9329785704612732}
{"mode": "train", "epochs": 1, "timestep": 686, "ep_reward": 336.8702087402344, "reward": 0.38362014293670654, "action": 1.0880147218704224}
{"mode": "train", "epochs": 1, "timestep": 687, "ep_reward": 337.2590026855469, "reward": 0.3887813091278076, "action": 1.1547460556030273}
{"mode": "train", "epochs": 1, "timestep": 688, "ep_reward": 337.6556396484375, "reward": 0.39662688970565796, "action": 1.7504775524139404}
{"mode": "train", "epochs": 1, "timestep": 689, "ep_reward": 338.0638732910156, "reward": 0.40823590755462646, "action": 0.9790892601013184}
{"mode": "train", "epochs": 1, "timestep": 690, "ep_reward": 338.48602294921875, "reward": 0.42216062545776367, "action": 0.7037964463233948}
{"mode": "train", "epochs": 1, "timestep": 691, "ep_reward": 338.9228820800781, "reward": 0.43687254190444946, "action": 1.0682427883148193}
{"mode": "train", "epochs": 1, "timestep": 692, "ep_reward": 339.375, "reward": 0.45210516452789307, "action": 0.27502626180648804}
{"mode": "train", "epochs": 1, "timestep": 693, "ep_reward": 339.8416748046875, "reward": 0.46668916940689087, "action": 0.25433069467544556}
{"mode": "train", "epochs": 1, "timestep": 694, "ep_reward": 340.32049560546875, "reward": 0.4788103699684143, "action": 0.42534828186035156}
{"mode": "train", "epochs": 1, "timestep": 695, "ep_reward": 340.80865478515625, "reward": 0.48816967010498047, "action": 1.3772884607315063}
{"mode": "train", "epochs": 1, "timestep": 696, "ep_reward": 341.305419921875, "reward": 0.49675416946411133, "action": 0.3337553143501282}
{"mode": "train", "epochs": 1, "timestep": 697, "ep_reward": 341.8082275390625, "reward": 0.50279700756073, "action": 1.1480600833892822}
{"mode": "train", "epochs": 1, "timestep": 698, "ep_reward": 342.3153381347656, "reward": 0.5071084499359131, "action": 1.053615689277649}
{"mode": "train", "epochs": 1, "timestep": 699, "ep_reward": 342.8250427246094, "reward": 0.5097072124481201, "action": 1.7869046926498413}
{"mode": "train", "epochs": 1, "timestep": 700, "ep_reward": 343.3375549316406, "reward": 0.5125010013580322, "action": 1.7029178142547607}
{"mode": "train", "epochs": 1, "timestep": 701, "ep_reward": 343.85296630859375, "reward": 0.5153988003730774, "action": 0.9685312509536743}
{"mode": "train", "epochs": 1, "timestep": 702, "ep_reward": 344.3692626953125, "reward": 0.5162913203239441, "action": 0.8059330582618713}
{"mode": "train", "epochs": 1, "timestep": 703, "ep_reward": 344.88372802734375, "reward": 0.514451265335083, "action": 1.0080372095108032}
{"mode": "train", "epochs": 1, "timestep": 704, "ep_reward": 345.39422607421875, "reward": 0.5105065107345581, "action": 1.3827110528945923}
{"mode": "train", "epochs": 1, "timestep": 705, "ep_reward": 345.900146484375, "reward": 0.5059119462966919, "action": 1.196278691291809}
{"mode": "train", "epochs": 1, "timestep": 706, "ep_reward": 346.40020751953125, "reward": 0.5000687837600708, "action": 0.8801140189170837}
{"mode": "train", "epochs": 1, "timestep": 707, "ep_reward": 346.89227294921875, "reward": 0.492073655128479, "action": 1.295941948890686}
{"mode": "train", "epochs": 1, "timestep": 708, "ep_reward": 347.376220703125, "reward": 0.48394161462783813, "action": 1.6484942436218262}
{"mode": "train", "epochs": 1, "timestep": 709, "ep_reward": 347.8533630371094, "reward": 0.4771420359611511, "action": 0.7373895645141602}
{"mode": "train", "epochs": 1, "timestep": 710, "ep_reward": 348.32135009765625, "reward": 0.4679897427558899, "action": 1.553741455078125}
{"mode": "train", "epochs": 1, "timestep": 711, "ep_reward": 348.78228759765625, "reward": 0.4609317183494568, "action": 0.7261812090873718}
{"mode": "train", "epochs": 1, "timestep": 712, "ep_reward": 349.2345275878906, "reward": 0.4522317051887512, "action": 0.9755985736846924}
{"mode": "train", "epochs": 1, "timestep": 713, "ep_reward": 349.6784362792969, "reward": 0.4439002275466919, "action": 1.3074959516525269}
{"mode": "train", "epochs": 1, "timestep": 714, "ep_reward": 350.1157531738281, "reward": 0.43730688095092773, "action": 1.2279680967330933}
{"mode": "train", "epochs": 1, "timestep": 715, "ep_reward": 350.5478515625, "reward": 0.43210238218307495, "action": 0.7305148839950562}
{"mode": "train", "epochs": 1, "timestep": 716, "ep_reward": 350.97454833984375, "reward": 0.4266868829727173, "action": 1.4548863172531128}
{"mode": "train", "epochs": 1, "timestep": 717, "ep_reward": 351.3988342285156, "reward": 0.42429500818252563, "action": 0.4128161668777466}
{"mode": "train", "epochs": 1, "timestep": 718, "ep_reward": 351.81988525390625, "reward": 0.42104023694992065, "action": 0.17651337385177612}
{"mode": "train", "epochs": 1, "timestep": 719, "ep_reward": 352.2366027832031, "reward": 0.4167320728302002, "action": 0.9596089124679565}
{"mode": "train", "epochs": 1, "timestep": 720, "ep_reward": 352.65087890625, "reward": 0.4142630696296692, "action": 0.8641579747200012}
{"mode": "train", "epochs": 1, "timestep": 721, "ep_reward": 353.0639343261719, "reward": 0.4130525588989258, "action": 0.4515600800514221}
{"mode": "train", "epochs": 1, "timestep": 722, "ep_reward": 353.4757995605469, "reward": 0.41187626123428345, "action": 0.8997571468353271}
{"mode": "train", "epochs": 1, "timestep": 723, "ep_reward": 353.8880920410156, "reward": 0.41230088472366333, "action": 0.5680090188980103}
{"mode": "train", "epochs": 1, "timestep": 724, "ep_reward": 354.3012390136719, "reward": 0.41314369440078735, "action": 1.2141969203948975}
{"mode": "train", "epochs": 1, "timestep": 725, "ep_reward": 354.71759033203125, "reward": 0.4163573384284973, "action": 0.2322368621826172}
{"mode": "train", "epochs": 1, "timestep": 726, "ep_reward": 355.13653564453125, "reward": 0.41893529891967773, "action": 1.806390404701233}
{"mode": "train", "epochs": 1, "timestep": 727, "ep_reward": 355.5614318847656, "reward": 0.4248960018157959, "action": 1.6050419807434082}
{"mode": "train", "epochs": 1, "timestep": 728, "ep_reward": 355.9950866699219, "reward": 0.43366098403930664, "action": 0.6387308835983276}
{"mode": "train", "epochs": 1, "timestep": 729, "ep_reward": 356.43792724609375, "reward": 0.442828893661499, "action": 1.6684377193450928}
{"mode": "train", "epochs": 1, "timestep": 730, "ep_reward": 356.8914489746094, "reward": 0.45352816581726074, "action": 1.6579433679580688}
{"mode": "train", "epochs": 1, "timestep": 731, "ep_reward": 357.3575439453125, "reward": 0.4660906195640564, "action": 1.4321458339691162}
{"mode": "train", "epochs": 1, "timestep": 732, "ep_reward": 357.83734130859375, "reward": 0.4798102378845215, "action": 0.8243719339370728}
{"mode": "train", "epochs": 1, "timestep": 733, "ep_reward": 358.3304443359375, "reward": 0.4930897355079651, "action": 0.17456269264221191}
{"mode": "train", "epochs": 1, "timestep": 734, "ep_reward": 358.8338928222656, "reward": 0.5034525990486145, "action": 1.0075762271881104}
{"mode": "train", "epochs": 1, "timestep": 735, "ep_reward": 359.3451232910156, "reward": 0.5112321376800537, "action": 1.1611158847808838}
{"mode": "train", "epochs": 1, "timestep": 736, "ep_reward": 359.86260986328125, "reward": 0.5174932479858398, "action": 0.4591001272201538}
{"mode": "train", "epochs": 1, "timestep": 737, "ep_reward": 360.3829650878906, "reward": 0.5203491449356079, "action": 1.0865123271942139}
{"mode": "train", "epochs": 1, "timestep": 738, "ep_reward": 360.9039306640625, "reward": 0.5209510922431946, "action": 0.5105000138282776}
{"mode": "train", "epochs": 1, "timestep": 739, "ep_reward": 361.4216003417969, "reward": 0.5176610946655273, "action": 1.5554335117340088}
{"mode": "train", "epochs": 1, "timestep": 740, "ep_reward": 361.9356689453125, "reward": 0.514069676399231, "action": 1.163313627243042}
{"mode": "train", "epochs": 1, "timestep": 741, "ep_reward": 362.4444580078125, "reward": 0.508777916431427, "action": 0.5710972547531128}
{"mode": "train", "epochs": 1, "timestep": 742, "ep_reward": 362.94439697265625, "reward": 0.4999285936355591, "action": 1.2091387510299683}
{"mode": "train", "epochs": 1, "timestep": 743, "ep_reward": 363.43499755859375, "reward": 0.49059945344924927, "action": 1.245968222618103}
{"mode": "train", "epochs": 1, "timestep": 744, "ep_reward": 363.9158630371094, "reward": 0.4808661937713623, "action": 0.7952954769134521}
{"mode": "train", "epochs": 1, "timestep": 745, "ep_reward": 364.3851013183594, "reward": 0.4692251682281494, "action": 0.7744472026824951}
{"mode": "train", "epochs": 1, "timestep": 746, "ep_reward": 364.8416442871094, "reward": 0.4565289616584778, "action": 0.1652504801750183}
{"mode": "train", "epochs": 1, "timestep": 747, "ep_reward": 365.28228759765625, "reward": 0.4406324625015259, "action": 0.6850982904434204}
{"mode": "train", "epochs": 1, "timestep": 748, "ep_reward": 365.70745849609375, "reward": 0.42518025636672974, "action": 0.97252357006073}
{"mode": "train", "epochs": 1, "timestep": 749, "ep_reward": 366.1187744140625, "reward": 0.41131240129470825, "action": 1.2286382913589478}
{"mode": "train", "epochs": 1, "timestep": 750, "ep_reward": 366.51904296875, "reward": 0.4002542495727539, "action": 0.7141031622886658}
{"mode": "train", "epochs": 1, "timestep": 751, "ep_reward": 366.9088439941406, "reward": 0.3898080587387085, "action": 0.7540891766548157}
{"mode": "train", "epochs": 1, "timestep": 752, "ep_reward": 367.291015625, "reward": 0.3821601867675781, "action": 1.238067626953125}
{"mode": "train", "epochs": 1, "timestep": 753, "ep_reward": 367.6795959472656, "reward": 0.38859009742736816, "action": 0.9637052416801453}
{"mode": "train", "epochs": 1, "timestep": 754, "ep_reward": 368.071044921875, "reward": 0.3914572596549988, "action": 0.8173052072525024}
{"mode": "train", "epochs": 1, "timestep": 755, "ep_reward": 368.4622802734375, "reward": 0.39125049114227295, "action": 1.2040013074874878}
{"mode": "train", "epochs": 1, "timestep": 756, "ep_reward": 368.8492126464844, "reward": 0.3869263529777527, "action": 0.903445303440094}
{"mode": "train", "epochs": 1, "timestep": 757, "ep_reward": 369.2343444824219, "reward": 0.38513070344924927, "action": 0.9438672065734863}
{"mode": "train", "epochs": 1, "timestep": 758, "ep_reward": 369.6283264160156, "reward": 0.3939818739891052, "action": 0.6858540773391724}
{"mode": "train", "epochs": 1, "timestep": 759, "ep_reward": 370.0328063964844, "reward": 0.4044666290283203, "action": 0.46913057565689087}
{"mode": "train", "epochs": 1, "timestep": 760, "ep_reward": 370.4483947753906, "reward": 0.4155992269515991, "action": 1.0764600038528442}
{"mode": "train", "epochs": 1, "timestep": 761, "ep_reward": 370.87628173828125, "reward": 0.42787331342697144, "action": 1.1889121532440186}
{"mode": "train", "epochs": 1, "timestep": 762, "ep_reward": 371.3178405761719, "reward": 0.4415736794471741, "action": 1.2485206127166748}
{"mode": "train", "epochs": 1, "timestep": 763, "ep_reward": 371.77423095703125, "reward": 0.45639121532440186, "action": 1.4315168857574463}
{"mode": "train", "epochs": 1, "timestep": 764, "ep_reward": 372.2464904785156, "reward": 0.47224515676498413, "action": 0.469510018825531}
{"mode": "train", "epochs": 1, "timestep": 765, "ep_reward": 372.73406982421875, "reward": 0.4875792860984802, "action": 0.3461957573890686}
{"mode": "train", "epochs": 1, "timestep": 766, "ep_reward": 373.2340087890625, "reward": 0.49993324279785156, "action": 1.5648610591888428}
{"mode": "train", "epochs": 1, "timestep": 767, "ep_reward": 373.7448425292969, "reward": 0.5108435153961182, "action": 1.6930201053619385}
{"mode": "train", "epochs": 1, "timestep": 768, "ep_reward": 374.2665100097656, "reward": 0.5216587781906128, "action": 1.4285471439361572}
{"mode": "train", "epochs": 1, "timestep": 769, "ep_reward": 374.7982482910156, "reward": 0.5317355394363403, "action": 0.6125718355178833}
{"mode": "train", "epochs": 1, "timestep": 770, "ep_reward": 375.33685302734375, "reward": 0.5385967493057251, "action": 1.8591291904449463}
{"mode": "train", "epochs": 1, "timestep": 771, "ep_reward": 375.8810729980469, "reward": 0.5442225337028503, "action": 0.7506309747695923}
{"mode": "train", "epochs": 1, "timestep": 772, "ep_reward": 376.4275817871094, "reward": 0.5465131402015686, "action": 1.0108288526535034}
{"mode": "train", "epochs": 1, "timestep": 773, "ep_reward": 376.972900390625, "reward": 0.5453277826309204, "action": 1.4887628555297852}
{"mode": "train", "epochs": 1, "timestep": 774, "ep_reward": 377.5153503417969, "reward": 0.5424622297286987, "action": 0.6340798139572144}
{"mode": "train", "epochs": 1, "timestep": 775, "ep_reward": 378.0504455566406, "reward": 0.5350937843322754, "action": 0.32645201683044434}
{"mode": "train", "epochs": 1, "timestep": 776, "ep_reward": 378.57281494140625, "reward": 0.5223770141601562, "action": 0.7461471557617188}
{"mode": "train", "epochs": 1, "timestep": 777, "ep_reward": 379.07940673828125, "reward": 0.5065785646438599, "action": 1.5720351934432983}
{"mode": "train", "epochs": 1, "timestep": 778, "ep_reward": 379.5712585449219, "reward": 0.4918615221977234, "action": 0.8929327726364136}
{"mode": "train", "epochs": 1, "timestep": 779, "ep_reward": 380.045654296875, "reward": 0.47440576553344727, "action": 0.9107352495193481}
{"mode": "train", "epochs": 1, "timestep": 780, "ep_reward": 380.501708984375, "reward": 0.4560431241989136, "action": 0.9561073780059814}
{"mode": "train", "epochs": 1, "timestep": 781, "ep_reward": 380.93939208984375, "reward": 0.4376884698867798, "action": 0.8452815413475037}
{"mode": "train", "epochs": 1, "timestep": 782, "ep_reward": 381.3588562011719, "reward": 0.4194597601890564, "action": -0.2668899893760681}
{"mode": "train", "epochs": 1, "timestep": 783, "ep_reward": 381.7555847167969, "reward": 0.3967397212982178, "action": 1.3634923696517944}
{"mode": "train", "epochs": 1, "timestep": 784, "ep_reward": 382.13623046875, "reward": 0.3806579113006592, "action": 1.1700975894927979}
{"mode": "train", "epochs": 1, "timestep": 785, "ep_reward": 382.52752685546875, "reward": 0.3912913203239441, "action": 1.2895219326019287}
{"mode": "train", "epochs": 1, "timestep": 786, "ep_reward": 382.93121337890625, "reward": 0.4036768674850464, "action": 1.516631841659546}
{"mode": "train", "epochs": 1, "timestep": 787, "ep_reward": 383.3417663574219, "reward": 0.41054409742355347, "action": 0.8483254909515381}
{"mode": "train", "epochs": 1, "timestep": 788, "ep_reward": 383.75457763671875, "reward": 0.4128262400627136, "action": 1.018357753753662}
{"mode": "train", "epochs": 1, "timestep": 789, "ep_reward": 384.165283203125, "reward": 0.41069287061691284, "action": 0.5975074768066406}
{"mode": "train", "epochs": 1, "timestep": 790, "ep_reward": 384.57061767578125, "reward": 0.4053381085395813, "action": 1.47278892993927}
{"mode": "train", "epochs": 1, "timestep": 791, "ep_reward": 384.964599609375, "reward": 0.3939839005470276, "action": 1.4988350868225098}
{"mode": "train", "epochs": 1, "timestep": 792, "ep_reward": 385.3464050292969, "reward": 0.38180381059646606, "action": 0.5467514395713806}
{"mode": "train", "epochs": 1, "timestep": 793, "ep_reward": 385.743896484375, "reward": 0.3974926471710205, "action": 0.6933712959289551}
{"mode": "train", "epochs": 1, "timestep": 794, "ep_reward": 386.1581115722656, "reward": 0.41422510147094727, "action": 1.2740132808685303}
{"mode": "train", "epochs": 1, "timestep": 795, "ep_reward": 386.5904541015625, "reward": 0.43234145641326904, "action": 1.012769341468811}
{"mode": "train", "epochs": 1, "timestep": 796, "ep_reward": 387.0422668457031, "reward": 0.45182520151138306, "action": 0.519607663154602}
{"mode": "train", "epochs": 1, "timestep": 797, "ep_reward": 387.5132751464844, "reward": 0.4709952473640442, "action": 1.443068504333496}
{"mode": "train", "epochs": 1, "timestep": 798, "ep_reward": 388.0024719238281, "reward": 0.4891865849494934, "action": 1.4677433967590332}
{"mode": "train", "epochs": 1, "timestep": 799, "ep_reward": 388.510009765625, "reward": 0.507552981376648, "action": 0.3582932949066162}
{"mode": "train", "epochs": 1, "timestep": 800, "ep_reward": 389.0342712402344, "reward": 0.5242482423782349, "action": 0.8937960863113403}
{"mode": "train", "epochs": 1, "timestep": 801, "ep_reward": 389.57147216796875, "reward": 0.5371865630149841, "action": 1.0370204448699951}
{"mode": "train", "epochs": 1, "timestep": 802, "ep_reward": 390.1185607910156, "reward": 0.5470808148384094, "action": 1.104371428489685}
{"mode": "train", "epochs": 1, "timestep": 803, "ep_reward": 390.6724853515625, "reward": 0.5539342164993286, "action": 0.8136050701141357}
{"mode": "train", "epochs": 1, "timestep": 804, "ep_reward": 391.22930908203125, "reward": 0.5568368434906006, "action": 0.9221426248550415}
{"mode": "train", "epochs": 1, "timestep": 805, "ep_reward": 391.784912109375, "reward": 0.5555892586708069, "action": 1.6435673236846924}
{"mode": "train", "epochs": 1, "timestep": 806, "ep_reward": 392.3376770019531, "reward": 0.5527780652046204, "action": -0.13398641347885132}
{"mode": "train", "epochs": 1, "timestep": 807, "ep_reward": 392.8799743652344, "reward": 0.5422977209091187, "action": 0.9837179183959961}
{"mode": "train", "epochs": 1, "timestep": 808, "ep_reward": 393.408935546875, "reward": 0.528967022895813, "action": 1.6796035766601562}
{"mode": "train", "epochs": 1, "timestep": 809, "ep_reward": 393.92474365234375, "reward": 0.5158030986785889, "action": 1.457503080368042}
{"mode": "train", "epochs": 1, "timestep": 810, "ep_reward": 394.42626953125, "reward": 0.5015348196029663, "action": 0.5025119781494141}
{"mode": "train", "epochs": 1, "timestep": 811, "ep_reward": 394.9087829589844, "reward": 0.4825146198272705, "action": 1.4879467487335205}
{"mode": "train", "epochs": 1, "timestep": 812, "ep_reward": 395.3744812011719, "reward": 0.46568357944488525, "action": 1.1354782581329346}
{"mode": "train", "epochs": 1, "timestep": 813, "ep_reward": 395.82275390625, "reward": 0.4482874870300293, "action": 0.6887087225914001}
{"mode": "train", "epochs": 1, "timestep": 814, "ep_reward": 396.2522888183594, "reward": 0.4295312762260437, "action": 0.2832990288734436}
{"mode": "train", "epochs": 1, "timestep": 815, "ep_reward": 396.6612548828125, "reward": 0.408971905708313, "action": 0.4368666410446167}
{"mode": "train", "epochs": 1, "timestep": 816, "ep_reward": 397.0501708984375, "reward": 0.3889200687408447, "action": -0.2557713985443115}
{"mode": "train", "epochs": 1, "timestep": 817, "ep_reward": 397.4346008300781, "reward": 0.38443344831466675, "action": 1.3634907007217407}
{"mode": "train", "epochs": 1, "timestep": 818, "ep_reward": 397.8389892578125, "reward": 0.40437614917755127, "action": -0.5979453325271606}
{"mode": "train", "epochs": 1, "timestep": 819, "ep_reward": 398.2604675292969, "reward": 0.4214751124382019, "action": 1.0749667882919312}
{"mode": "train", "epochs": 1, "timestep": 820, "ep_reward": 398.6971130371094, "reward": 0.4366462826728821, "action": 1.205788254737854}
{"mode": "train", "epochs": 1, "timestep": 821, "ep_reward": 399.1429443359375, "reward": 0.4458376169204712, "action": 0.5965666770935059}
{"mode": "train", "epochs": 1, "timestep": 822, "ep_reward": 399.59271240234375, "reward": 0.44977396726608276, "action": 0.570136308670044}
{"mode": "train", "epochs": 1, "timestep": 823, "ep_reward": 400.0417785644531, "reward": 0.44907426834106445, "action": 1.0531797409057617}
{"mode": "train", "epochs": 1, "timestep": 824, "ep_reward": 400.4839782714844, "reward": 0.4422001242637634, "action": 1.297724962234497}
{"mode": "train", "epochs": 1, "timestep": 825, "ep_reward": 400.91229248046875, "reward": 0.4283190369606018, "action": 0.7408727407455444}
{"mode": "train", "epochs": 1, "timestep": 826, "ep_reward": 401.3224182128906, "reward": 0.41012442111968994, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 827, "ep_reward": 401.7047424316406, "reward": 0.382335901260376, "action": 1.0575025081634521}
{"mode": "train", "epochs": 1, "timestep": 828, "ep_reward": 402.0943603515625, "reward": 0.38962364196777344, "action": 1.6911466121673584}
{"mode": "train", "epochs": 1, "timestep": 829, "ep_reward": 402.51055908203125, "reward": 0.41619259119033813, "action": 1.2413073778152466}
{"mode": "train", "epochs": 1, "timestep": 830, "ep_reward": 402.95623779296875, "reward": 0.44569188356399536, "action": 1.5032665729522705}
{"mode": "train", "epochs": 1, "timestep": 831, "ep_reward": 403.4322814941406, "reward": 0.4760531187057495, "action": 0.7952532768249512}
{"mode": "train", "epochs": 1, "timestep": 832, "ep_reward": 403.93951416015625, "reward": 0.5072198510169983, "action": 0.8221052885055542}
{"mode": "train", "epochs": 1, "timestep": 833, "ep_reward": 404.4752502441406, "reward": 0.5357425808906555, "action": 1.3278398513793945}
{"mode": "train", "epochs": 1, "timestep": 834, "ep_reward": 405.0360412597656, "reward": 0.5607878565788269, "action": 1.0382100343704224}
{"mode": "train", "epochs": 1, "timestep": 835, "ep_reward": 405.6188049316406, "reward": 0.5827559232711792, "action": 1.202222466468811}
{"mode": "train", "epochs": 1, "timestep": 836, "ep_reward": 406.2189636230469, "reward": 0.6001563668251038, "action": 1.535523533821106}
{"mode": "train", "epochs": 1, "timestep": 837, "ep_reward": 406.83233642578125, "reward": 0.6133625507354736, "action": -0.3982556462287903}
{"mode": "train", "epochs": 1, "timestep": 838, "ep_reward": 407.4513244628906, "reward": 0.6189838647842407, "action": 0.7683621644973755}
{"mode": "train", "epochs": 1, "timestep": 839, "ep_reward": 408.06756591796875, "reward": 0.6162516474723816, "action": 1.3272242546081543}
{"mode": "train", "epochs": 1, "timestep": 840, "ep_reward": 408.6760559082031, "reward": 0.6084756851196289, "action": 1.2336291074752808}
{"mode": "train", "epochs": 1, "timestep": 841, "ep_reward": 409.2716979980469, "reward": 0.595634937286377, "action": 0.6914574503898621}
{"mode": "train", "epochs": 1, "timestep": 842, "ep_reward": 409.847412109375, "reward": 0.5757021903991699, "action": 0.9257991313934326}
{"mode": "train", "epochs": 1, "timestep": 843, "ep_reward": 410.3984680175781, "reward": 0.5510479211807251, "action": 0.4153815507888794}
{"mode": "train", "epochs": 1, "timestep": 844, "ep_reward": 410.9178466796875, "reward": 0.5193682909011841, "action": 0.19426840543746948}
{"mode": "train", "epochs": 1, "timestep": 845, "ep_reward": 411.399169921875, "reward": 0.48132628202438354, "action": 1.7360138893127441}
{"mode": "train", "epochs": 1, "timestep": 846, "ep_reward": 411.8485412597656, "reward": 0.4493677616119385, "action": 0.5664821863174438}
{"mode": "train", "epochs": 1, "timestep": 847, "ep_reward": 412.260498046875, "reward": 0.411964476108551, "action": 1.2124706506729126}
{"mode": "train", "epochs": 1, "timestep": 848, "ep_reward": 412.63946533203125, "reward": 0.37898051738739014, "action": 1.171793818473816}
{"mode": "train", "epochs": 1, "timestep": 849, "ep_reward": 413.020751953125, "reward": 0.38129639625549316, "action": 1.5809416770935059}
{"mode": "train", "epochs": 1, "timestep": 850, "ep_reward": 413.43450927734375, "reward": 0.41374796628952026, "action": 0.8768156170845032}
{"mode": "train", "epochs": 1, "timestep": 851, "ep_reward": 413.87420654296875, "reward": 0.43968355655670166, "action": 1.6370643377304077}
{"mode": "train", "epochs": 1, "timestep": 852, "ep_reward": 414.333984375, "reward": 0.459766149520874, "action": 1.1699780225753784}
{"mode": "train", "epochs": 1, "timestep": 853, "ep_reward": 414.80548095703125, "reward": 0.47149473428726196, "action": 1.3265883922576904}
{"mode": "train", "epochs": 1, "timestep": 854, "ep_reward": 415.2806396484375, "reward": 0.47514939308166504, "action": 0.5738924145698547}
{"mode": "train", "epochs": 1, "timestep": 855, "ep_reward": 415.7529296875, "reward": 0.47230440378189087, "action": 1.2342138290405273}
{"mode": "train", "epochs": 1, "timestep": 856, "ep_reward": 416.2144775390625, "reward": 0.4615475535392761, "action": 0.8897714614868164}
{"mode": "train", "epochs": 1, "timestep": 857, "ep_reward": 416.65887451171875, "reward": 0.4444116950035095, "action": 0.6593591570854187}
{"mode": "train", "epochs": 1, "timestep": 858, "ep_reward": 417.0812683105469, "reward": 0.42238849401474, "action": 1.8567078113555908}
{"mode": "train", "epochs": 1, "timestep": 859, "ep_reward": 417.4715576171875, "reward": 0.3903018832206726, "action": 1.0091652870178223}
{"mode": "train", "epochs": 1, "timestep": 860, "ep_reward": 417.8504333496094, "reward": 0.3788895010948181, "action": 1.1396522521972656}
{"mode": "train", "epochs": 1, "timestep": 861, "ep_reward": 418.2594909667969, "reward": 0.4090467691421509, "action": 1.1362035274505615}
{"mode": "train", "epochs": 1, "timestep": 862, "ep_reward": 418.7005920410156, "reward": 0.44111180305480957, "action": 0.022677183151245117}
{"mode": "train", "epochs": 1, "timestep": 863, "ep_reward": 419.175048828125, "reward": 0.4744715690612793, "action": 0.8498198986053467}
{"mode": "train", "epochs": 1, "timestep": 864, "ep_reward": 419.6790771484375, "reward": 0.5040236711502075, "action": 0.3729589581489563}
{"mode": "train", "epochs": 1, "timestep": 865, "ep_reward": 420.2103576660156, "reward": 0.5312753915786743, "action": 0.9253050088882446}
{"mode": "train", "epochs": 1, "timestep": 866, "ep_reward": 420.7643127441406, "reward": 0.5539404153823853, "action": 0.9146011471748352}
{"mode": "train", "epochs": 1, "timestep": 867, "ep_reward": 421.3370361328125, "reward": 0.5727135539054871, "action": 0.8676818609237671}
{"mode": "train", "epochs": 1, "timestep": 868, "ep_reward": 421.9238586425781, "reward": 0.5868192315101624, "action": 0.7046442031860352}
{"mode": "train", "epochs": 1, "timestep": 869, "ep_reward": 422.5191955566406, "reward": 0.5953331589698792, "action": 0.6450186371803284}
{"mode": "train", "epochs": 1, "timestep": 870, "ep_reward": 423.1165771484375, "reward": 0.5973907113075256, "action": 1.3580574989318848}
{"mode": "train", "epochs": 1, "timestep": 871, "ep_reward": 423.7115478515625, "reward": 0.5949613451957703, "action": 1.1923352479934692}
{"mode": "train", "epochs": 1, "timestep": 872, "ep_reward": 424.29937744140625, "reward": 0.587822675704956, "action": 1.6635686159133911}
{"mode": "train", "epochs": 1, "timestep": 873, "ep_reward": 424.87750244140625, "reward": 0.5781108140945435, "action": 1.1178416013717651}
{"mode": "train", "epochs": 1, "timestep": 874, "ep_reward": 425.4410705566406, "reward": 0.5635751485824585, "action": 1.387222170829773}
{"mode": "train", "epochs": 1, "timestep": 875, "ep_reward": 425.987548828125, "reward": 0.5464893579483032, "action": 0.7808483242988586}
{"mode": "train", "epochs": 1, "timestep": 876, "ep_reward": 426.5117492675781, "reward": 0.5241998434066772, "action": 0.13539570569992065}
{"mode": "train", "epochs": 1, "timestep": 877, "ep_reward": 427.00677490234375, "reward": 0.4950122833251953, "action": 0.34477484226226807}
{"mode": "train", "epochs": 1, "timestep": 878, "ep_reward": 427.4690246582031, "reward": 0.4622395634651184, "action": 1.7185299396514893}
{"mode": "train", "epochs": 1, "timestep": 879, "ep_reward": 427.904296875, "reward": 0.4352794289588928, "action": 1.2915599346160889}
{"mode": "train", "epochs": 1, "timestep": 880, "ep_reward": 428.3128356933594, "reward": 0.40853726863861084, "action": 0.8004926443099976}
{"mode": "train", "epochs": 1, "timestep": 881, "ep_reward": 428.6943664550781, "reward": 0.3815397620201111, "action": 0.44118499755859375}
{"mode": "train", "epochs": 1, "timestep": 882, "ep_reward": 429.0810852050781, "reward": 0.3867167830467224, "action": 0.5811238288879395}
{"mode": "train", "epochs": 1, "timestep": 883, "ep_reward": 429.4944152832031, "reward": 0.41333937644958496, "action": 0.7822993993759155}
{"mode": "train", "epochs": 1, "timestep": 884, "ep_reward": 429.9311828613281, "reward": 0.43675780296325684, "action": 0.6633087992668152}
{"mode": "train", "epochs": 1, "timestep": 885, "ep_reward": 430.38671875, "reward": 0.4555414319038391, "action": 0.8186711072921753}
{"mode": "train", "epochs": 1, "timestep": 886, "ep_reward": 430.8556213378906, "reward": 0.4688888192176819, "action": 1.3880650997161865}
{"mode": "train", "epochs": 1, "timestep": 887, "ep_reward": 431.3304138183594, "reward": 0.4747840166091919, "action": 1.1144145727157593}
{"mode": "train", "epochs": 1, "timestep": 888, "ep_reward": 431.802978515625, "reward": 0.47255373001098633, "action": 1.1920971870422363}
{"mode": "train", "epochs": 1, "timestep": 889, "ep_reward": 432.2651672363281, "reward": 0.4621937870979309, "action": 1.738222599029541}
{"mode": "train", "epochs": 1, "timestep": 890, "ep_reward": 432.7071533203125, "reward": 0.4419923424720764, "action": 0.5303272008895874}
{"mode": "train", "epochs": 1, "timestep": 891, "ep_reward": 433.1257019042969, "reward": 0.41853344440460205, "action": 0.9146016836166382}
{"mode": "train", "epochs": 1, "timestep": 892, "ep_reward": 433.5152893066406, "reward": 0.389599084854126, "action": 1.3582065105438232}
{"mode": "train", "epochs": 1, "timestep": 893, "ep_reward": 433.8959045410156, "reward": 0.38062626123428345, "action": 1.2334070205688477}
{"mode": "train", "epochs": 1, "timestep": 894, "ep_reward": 434.306396484375, "reward": 0.4104838967323303, "action": 1.077945590019226}
{"mode": "train", "epochs": 1, "timestep": 895, "ep_reward": 434.7486877441406, "reward": 0.44230419397354126, "action": 1.717587947845459}
{"mode": "train", "epochs": 1, "timestep": 896, "ep_reward": 435.22314453125, "reward": 0.4744487404823303, "action": 0.07278376817703247}
{"mode": "train", "epochs": 1, "timestep": 897, "ep_reward": 435.7317810058594, "reward": 0.5086342096328735, "action": 1.4150341749191284}
{"mode": "train", "epochs": 1, "timestep": 898, "ep_reward": 436.269287109375, "reward": 0.5375210642814636, "action": 1.4673130512237549}
{"mode": "train", "epochs": 1, "timestep": 899, "ep_reward": 436.8337707519531, "reward": 0.5644934177398682, "action": 1.4606776237487793}
{"mode": "train", "epochs": 1, "timestep": 900, "ep_reward": 437.4226379394531, "reward": 0.5888590216636658, "action": 0.6365653276443481}
{"mode": "train", "epochs": 1, "timestep": 901, "ep_reward": 438.0318603515625, "reward": 0.6092208623886108, "action": 0.9298126697540283}
{"mode": "train", "epochs": 1, "timestep": 902, "ep_reward": 438.6546936035156, "reward": 0.6228259801864624, "action": 1.3806251287460327}
{"mode": "train", "epochs": 1, "timestep": 903, "ep_reward": 439.2854919433594, "reward": 0.6307843923568726, "action": 0.8851498961448669}
{"mode": "train", "epochs": 1, "timestep": 904, "ep_reward": 439.91778564453125, "reward": 0.6322879791259766, "action": 1.4119808673858643}
{"mode": "train", "epochs": 1, "timestep": 905, "ep_reward": 440.5460510253906, "reward": 0.6282541751861572, "action": 1.4875283241271973}
{"mode": "train", "epochs": 1, "timestep": 906, "ep_reward": 441.1654968261719, "reward": 0.6194497346878052, "action": 0.30786341428756714}
{"mode": "train", "epochs": 1, "timestep": 907, "ep_reward": 441.7666320800781, "reward": 0.6011295318603516, "action": 1.2165712118148804}
{"mode": "train", "epochs": 1, "timestep": 908, "ep_reward": 442.34552001953125, "reward": 0.5788800716400146, "action": 0.3422013521194458}
{"mode": "train", "epochs": 1, "timestep": 909, "ep_reward": 442.8930358886719, "reward": 0.5475070476531982, "action": 1.4184871912002563}
{"mode": "train", "epochs": 1, "timestep": 910, "ep_reward": 443.4092102050781, "reward": 0.5161846876144409, "action": 1.5604393482208252}
{"mode": "train", "epochs": 1, "timestep": 911, "ep_reward": 443.8936767578125, "reward": 0.4844703674316406, "action": 0.45379185676574707}
{"mode": "train", "epochs": 1, "timestep": 912, "ep_reward": 444.3397216796875, "reward": 0.4460597038269043, "action": -0.13925844430923462}
{"mode": "train", "epochs": 1, "timestep": 913, "ep_reward": 444.7416076660156, "reward": 0.4018906354904175, "action": 1.4498941898345947}
{"mode": "train", "epochs": 1, "timestep": 914, "ep_reward": 445.108642578125, "reward": 0.36702674627304077, "action": 1.0589011907577515}
{"mode": "train", "epochs": 1, "timestep": 915, "ep_reward": 445.49761962890625, "reward": 0.3889918327331543, "action": 1.1056777238845825}
{"mode": "train", "epochs": 1, "timestep": 916, "ep_reward": 445.9222106933594, "reward": 0.42459362745285034, "action": 1.0951054096221924}
{"mode": "train", "epochs": 1, "timestep": 917, "ep_reward": 446.376953125, "reward": 0.45475584268569946, "action": 0.8984370231628418}
{"mode": "train", "epochs": 1, "timestep": 918, "ep_reward": 446.85528564453125, "reward": 0.47833532094955444, "action": 0.5194069743156433}
{"mode": "train", "epochs": 1, "timestep": 919, "ep_reward": 447.3504943847656, "reward": 0.4952148199081421, "action": 1.3900222778320312}
{"mode": "train", "epochs": 1, "timestep": 920, "ep_reward": 447.8547668457031, "reward": 0.5042781829833984, "action": 0.7213642001152039}
{"mode": "train", "epochs": 1, "timestep": 921, "ep_reward": 448.3594970703125, "reward": 0.5047318935394287, "action": 0.972696840763092}
{"mode": "train", "epochs": 1, "timestep": 922, "ep_reward": 448.8560791015625, "reward": 0.4965711236000061, "action": 1.6504567861557007}
{"mode": "train", "epochs": 1, "timestep": 923, "ep_reward": 449.33319091796875, "reward": 0.47712278366088867, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 924, "ep_reward": 449.7786560058594, "reward": 0.44547349214553833, "action": 0.8660093545913696}
{"mode": "train", "epochs": 1, "timestep": 925, "ep_reward": 450.188232421875, "reward": 0.409582257270813, "action": 1.0332227945327759}
{"mode": "train", "epochs": 1, "timestep": 926, "ep_reward": 450.5563049316406, "reward": 0.36807572841644287, "action": 1.287461519241333}
{"mode": "train", "epochs": 1, "timestep": 927, "ep_reward": 450.94549560546875, "reward": 0.38919419050216675, "action": 0.6277163028717041}
{"mode": "train", "epochs": 1, "timestep": 928, "ep_reward": 451.3735656738281, "reward": 0.42808353900909424, "action": 1.414224624633789}
{"mode": "train", "epochs": 1, "timestep": 929, "ep_reward": 451.8395080566406, "reward": 0.465931236743927, "action": 0.4360530972480774}
{"mode": "train", "epochs": 1, "timestep": 930, "ep_reward": 452.3447570800781, "reward": 0.5052467584609985, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 931, "ep_reward": 452.8840637207031, "reward": 0.5393111705780029, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 932, "ep_reward": 453.4570617675781, "reward": 0.5730023384094238, "action": 0.9241840839385986}
{"mode": "train", "epochs": 1, "timestep": 933, "ep_reward": 454.06292724609375, "reward": 0.605872392654419, "action": 1.0236926078796387}
{"mode": "train", "epochs": 1, "timestep": 934, "ep_reward": 454.6956481933594, "reward": 0.6327155232429504, "action": 0.2927125096321106}
{"mode": "train", "epochs": 1, "timestep": 935, "ep_reward": 455.34808349609375, "reward": 0.6524239778518677, "action": 1.475812554359436}
{"mode": "train", "epochs": 1, "timestep": 936, "ep_reward": 456.0118103027344, "reward": 0.6637241244316101, "action": 1.4468673467636108}
{"mode": "train", "epochs": 1, "timestep": 937, "ep_reward": 456.68072509765625, "reward": 0.6689240336418152, "action": 1.3243707418441772}
{"mode": "train", "epochs": 1, "timestep": 938, "ep_reward": 457.3481750488281, "reward": 0.6674396991729736, "action": 1.4454468488693237}
{"mode": "train", "epochs": 1, "timestep": 939, "ep_reward": 458.0078430175781, "reward": 0.6596651077270508, "action": 0.4505142569541931}
{"mode": "train", "epochs": 1, "timestep": 940, "ep_reward": 458.6495361328125, "reward": 0.6416923999786377, "action": 0.8630260229110718}
{"mode": "train", "epochs": 1, "timestep": 941, "ep_reward": 459.2657165527344, "reward": 0.6161783933639526, "action": 0.91635662317276}
{"mode": "train", "epochs": 1, "timestep": 942, "ep_reward": 459.8493957519531, "reward": 0.5836684107780457, "action": 1.3777133226394653}
{"mode": "train", "epochs": 1, "timestep": 943, "ep_reward": 460.3974609375, "reward": 0.5480647087097168, "action": 1.383117437362671}
{"mode": "train", "epochs": 1, "timestep": 944, "ep_reward": 460.906982421875, "reward": 0.5095171332359314, "action": 1.066346526145935}
{"mode": "train", "epochs": 1, "timestep": 945, "ep_reward": 461.37432861328125, "reward": 0.4673613905906677, "action": 0.08666151762008667}
{"mode": "train", "epochs": 1, "timestep": 946, "ep_reward": 461.7914733886719, "reward": 0.41715115308761597, "action": 1.7080507278442383}
{"mode": "train", "epochs": 1, "timestep": 947, "ep_reward": 462.168701171875, "reward": 0.37722378969192505, "action": 1.6277790069580078}
{"mode": "train", "epochs": 1, "timestep": 948, "ep_reward": 462.53753662109375, "reward": 0.36884039640426636, "action": 0.7795506715774536}
{"mode": "train", "epochs": 1, "timestep": 949, "ep_reward": 462.9476318359375, "reward": 0.41008734703063965, "action": 1.3281888961791992}
{"mode": "train", "epochs": 1, "timestep": 950, "ep_reward": 463.39556884765625, "reward": 0.4479498863220215, "action": 0.9318819642066956}
{"mode": "train", "epochs": 1, "timestep": 951, "ep_reward": 463.8739013671875, "reward": 0.47832781076431274, "action": 1.625622034072876}
{"mode": "train", "epochs": 1, "timestep": 952, "ep_reward": 464.37506103515625, "reward": 0.5011643171310425, "action": 0.8073373436927795}
{"mode": "train", "epochs": 1, "timestep": 953, "ep_reward": 464.8891906738281, "reward": 0.5141439437866211, "action": 0.607227623462677}
{"mode": "train", "epochs": 1, "timestep": 954, "ep_reward": 465.4084167480469, "reward": 0.5192164182662964, "action": -0.09843266010284424}
{"mode": "train", "epochs": 1, "timestep": 955, "ep_reward": 465.92669677734375, "reward": 0.5182816982269287, "action": 1.350882649421692}
{"mode": "train", "epochs": 1, "timestep": 956, "ep_reward": 466.43402099609375, "reward": 0.507337212562561, "action": 1.044821858406067}
{"mode": "train", "epochs": 1, "timestep": 957, "ep_reward": 466.9209899902344, "reward": 0.4869834780693054, "action": 1.526597499847412}
{"mode": "train", "epochs": 1, "timestep": 958, "ep_reward": 467.3766784667969, "reward": 0.45569533109664917, "action": 1.05409836769104}
{"mode": "train", "epochs": 1, "timestep": 959, "ep_reward": 467.7945556640625, "reward": 0.4178868532180786, "action": 0.8235056400299072}
{"mode": "train", "epochs": 1, "timestep": 960, "ep_reward": 468.1703796386719, "reward": 0.3758254051208496, "action": 1.1076613664627075}
{"mode": "train", "epochs": 1, "timestep": 961, "ep_reward": 468.5504455566406, "reward": 0.3800690770149231, "action": 1.0503488779067993}
{"mode": "train", "epochs": 1, "timestep": 962, "ep_reward": 468.9698486328125, "reward": 0.4193975329399109, "action": 0.7544603943824768}
{"mode": "train", "epochs": 1, "timestep": 963, "ep_reward": 469.43017578125, "reward": 0.46031510829925537, "action": 0.277091383934021}
{"mode": "train", "epochs": 1, "timestep": 964, "ep_reward": 469.9308166503906, "reward": 0.5006532669067383, "action": 1.3588131666183472}
{"mode": "train", "epochs": 1, "timestep": 965, "ep_reward": 470.466796875, "reward": 0.5359862446784973, "action": 0.7981600761413574}
{"mode": "train", "epochs": 1, "timestep": 966, "ep_reward": 471.0363464355469, "reward": 0.569563627243042, "action": 1.3772677183151245}
{"mode": "train", "epochs": 1, "timestep": 967, "ep_reward": 471.63427734375, "reward": 0.5979385375976562, "action": 1.0444021224975586}
{"mode": "train", "epochs": 1, "timestep": 968, "ep_reward": 472.25634765625, "reward": 0.6220650672912598, "action": 0.9896815419197083}
{"mode": "train", "epochs": 1, "timestep": 969, "ep_reward": 472.8963928222656, "reward": 0.6400573253631592, "action": 0.520026683807373}
{"mode": "train", "epochs": 1, "timestep": 970, "ep_reward": 473.5468444824219, "reward": 0.6504652500152588, "action": 0.359295129776001}
{"mode": "train", "epochs": 1, "timestep": 971, "ep_reward": 474.1982727050781, "reward": 0.6514352560043335, "action": 0.4391326308250427}
{"mode": "train", "epochs": 1, "timestep": 972, "ep_reward": 474.841064453125, "reward": 0.6428022980690002, "action": 0.7544928789138794}
{"mode": "train", "epochs": 1, "timestep": 973, "ep_reward": 475.4671325683594, "reward": 0.6260648965835571, "action": 0.8662457466125488}
{"mode": "train", "epochs": 1, "timestep": 974, "ep_reward": 476.06927490234375, "reward": 0.602138876914978, "action": 0.9613364934921265}
{"mode": "train", "epochs": 1, "timestep": 975, "ep_reward": 476.6414794921875, "reward": 0.5722190141677856, "action": -0.1323103904724121}
{"mode": "train", "epochs": 1, "timestep": 976, "ep_reward": 477.1717834472656, "reward": 0.5303075313568115, "action": 1.3806425333023071}
{"mode": "train", "epochs": 1, "timestep": 977, "ep_reward": 477.66259765625, "reward": 0.49082499742507935, "action": 1.8406383991241455}
{"mode": "train", "epochs": 1, "timestep": 978, "ep_reward": 478.1165771484375, "reward": 0.45396852493286133, "action": 0.6300632953643799}
{"mode": "train", "epochs": 1, "timestep": 979, "ep_reward": 478.52728271484375, "reward": 0.4107120633125305, "action": 1.3977948427200317}
{"mode": "train", "epochs": 1, "timestep": 980, "ep_reward": 478.90057373046875, "reward": 0.37330299615859985, "action": 0.2745600938796997}
{"mode": "train", "epochs": 1, "timestep": 981, "ep_reward": 479.2790222167969, "reward": 0.37844008207321167, "action": 0.5962345600128174}
{"mode": "train", "epochs": 1, "timestep": 982, "ep_reward": 479.6980285644531, "reward": 0.4190163016319275, "action": 1.755131721496582}
{"mode": "train", "epochs": 1, "timestep": 983, "ep_reward": 480.1548767089844, "reward": 0.456855833530426, "action": 1.0057919025421143}
{"mode": "train", "epochs": 1, "timestep": 984, "ep_reward": 480.6402587890625, "reward": 0.48537546396255493, "action": 0.6723755598068237}
{"mode": "train", "epochs": 1, "timestep": 985, "ep_reward": 481.1466369628906, "reward": 0.50636887550354, "action": 0.5219631791114807}
{"mode": "train", "epochs": 1, "timestep": 986, "ep_reward": 481.66656494140625, "reward": 0.5199253559112549, "action": 1.8207414150238037}
{"mode": "train", "epochs": 1, "timestep": 987, "ep_reward": 482.1899108886719, "reward": 0.5233393907546997, "action": 0.8465534448623657}
{"mode": "train", "epochs": 1, "timestep": 988, "ep_reward": 482.7063903808594, "reward": 0.5164749622344971, "action": 1.4491140842437744}
{"mode": "train", "epochs": 1, "timestep": 989, "ep_reward": 483.20477294921875, "reward": 0.4983903169631958, "action": 1.1677759885787964}
{"mode": "train", "epochs": 1, "timestep": 990, "ep_reward": 483.6756896972656, "reward": 0.470930814743042, "action": 0.6592222452163696}
{"mode": "train", "epochs": 1, "timestep": 991, "ep_reward": 484.1135559082031, "reward": 0.43788135051727295, "action": 0.005798280239105225}
{"mode": "train", "epochs": 1, "timestep": 992, "ep_reward": 484.51715087890625, "reward": 0.4036061763763428, "action": 1.6825612783432007}
{"mode": "train", "epochs": 1, "timestep": 993, "ep_reward": 484.8756408691406, "reward": 0.358498752117157, "action": 1.8949772119522095}
{"mode": "train", "epochs": 1, "timestep": 994, "ep_reward": 485.270751953125, "reward": 0.3951025605201721, "action": 0.24862587451934814}
{"mode": "train", "epochs": 1, "timestep": 995, "ep_reward": 485.70855712890625, "reward": 0.4378011226654053, "action": 1.4325714111328125}
{"mode": "train", "epochs": 1, "timestep": 996, "ep_reward": 486.1858825683594, "reward": 0.4773150086402893, "action": 0.2649218440055847}
{"mode": "train", "epochs": 1, "timestep": 997, "ep_reward": 486.7044372558594, "reward": 0.5185667276382446, "action": 0.11949610710144043}
{"mode": "train", "epochs": 1, "timestep": 998, "ep_reward": 487.259521484375, "reward": 0.5550732016563416, "action": 0.4603409767150879}
{"mode": "train", "epochs": 1, "timestep": 999, "ep_reward": 487.8442077636719, "reward": 0.5846751928329468, "action": -0.3248906135559082}
{"mode": "train", "epochs": 1, "timestep": 1000, "ep_reward": 488.451416015625, "reward": 0.6072075366973877, "action": 0.30121535062789917}
{"mode": "train", "epochs": 1, "timestep": 1001, "ep_reward": 489.0712585449219, "reward": 0.619849443435669, "action": 0.9370015859603882}
{"mode": "train", "epochs": 1, "timestep": 1002, "ep_reward": 489.6963195800781, "reward": 0.625072181224823, "action": 0.9537359476089478}
{"mode": "train", "epochs": 1, "timestep": 1003, "ep_reward": 490.3200988769531, "reward": 0.6237655878067017, "action": 0.8534893989562988}
{"mode": "train", "epochs": 1, "timestep": 1004, "ep_reward": 490.9356994628906, "reward": 0.6156017780303955, "action": 0.7273596525192261}
{"mode": "train", "epochs": 1, "timestep": 1005, "ep_reward": 491.5357666015625, "reward": 0.6000699996948242, "action": 1.7853939533233643}
{"mode": "train", "epochs": 1, "timestep": 1006, "ep_reward": 492.1185302734375, "reward": 0.5827776193618774, "action": 0.9513139724731445}
{"mode": "train", "epochs": 1, "timestep": 1007, "ep_reward": 492.6774597167969, "reward": 0.5589425563812256, "action": 0.43818432092666626}
{"mode": "train", "epochs": 1, "timestep": 1008, "ep_reward": 493.20526123046875, "reward": 0.5278060436248779, "action": 1.1197593212127686}
{"mode": "train", "epochs": 1, "timestep": 1009, "ep_reward": 493.70098876953125, "reward": 0.4957146644592285, "action": 0.36679166555404663}
{"mode": "train", "epochs": 1, "timestep": 1010, "ep_reward": 494.1582946777344, "reward": 0.45731985569000244, "action": 1.4269746541976929}
{"mode": "train", "epochs": 1, "timestep": 1011, "ep_reward": 494.5818786621094, "reward": 0.4235938787460327, "action": 0.41619646549224854}
{"mode": "train", "epochs": 1, "timestep": 1012, "ep_reward": 494.96722412109375, "reward": 0.3853302001953125, "action": 1.8704814910888672}
{"mode": "train", "epochs": 1, "timestep": 1013, "ep_reward": 495.33953857421875, "reward": 0.37230998277664185, "action": 0.30002230405807495}
{"mode": "train", "epochs": 1, "timestep": 1014, "ep_reward": 495.74468994140625, "reward": 0.4051635265350342, "action": 1.3278323411941528}
{"mode": "train", "epochs": 1, "timestep": 1015, "ep_reward": 496.1807556152344, "reward": 0.4360554814338684, "action": 1.7127554416656494}
{"mode": "train", "epochs": 1, "timestep": 1016, "ep_reward": 496.6407470703125, "reward": 0.4599876403808594, "action": 1.3650339841842651}
{"mode": "train", "epochs": 1, "timestep": 1017, "ep_reward": 497.1158142089844, "reward": 0.47506916522979736, "action": 0.3809766173362732}
{"mode": "train", "epochs": 1, "timestep": 1018, "ep_reward": 497.5991516113281, "reward": 0.483333945274353, "action": 1.0121665000915527}
{"mode": "train", "epochs": 1, "timestep": 1019, "ep_reward": 498.0838928222656, "reward": 0.48473894596099854, "action": 0.6107209920883179}
{"mode": "train", "epochs": 1, "timestep": 1020, "ep_reward": 498.5633239746094, "reward": 0.47943979501724243, "action": 1.3471941947937012}
{"mode": "train", "epochs": 1, "timestep": 1021, "ep_reward": 499.02862548828125, "reward": 0.46529632806777954, "action": 0.945569634437561}
{"mode": "train", "epochs": 1, "timestep": 1022, "ep_reward": 499.4728088378906, "reward": 0.4441940188407898, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1023, "ep_reward": 499.88458251953125, "reward": 0.411782443523407, "action": 1.052704930305481}
{"mode": "train", "epochs": 1, "timestep": 1024, "ep_reward": 500.260498046875, "reward": 0.37590640783309937, "action": 0.2679133415222168}
{"mode": "train", "epochs": 1, "timestep": 1025, "ep_reward": 500.6490173339844, "reward": 0.38853389024734497, "action": 1.8037045001983643}
{"mode": "train", "epochs": 1, "timestep": 1026, "ep_reward": 501.0689392089844, "reward": 0.4199351668357849, "action": 1.2181485891342163}
{"mode": "train", "epochs": 1, "timestep": 1027, "ep_reward": 501.5237121582031, "reward": 0.45478516817092896, "action": 0.8947091102600098}
{"mode": "train", "epochs": 1, "timestep": 1028, "ep_reward": 502.0140380859375, "reward": 0.49031364917755127, "action": 1.2372303009033203}
{"mode": "train", "epochs": 1, "timestep": 1029, "ep_reward": 502.5379638671875, "reward": 0.5239142775535583, "action": 0.8728302717208862}
{"mode": "train", "epochs": 1, "timestep": 1030, "ep_reward": 503.0936584472656, "reward": 0.5556982755661011, "action": 1.2912447452545166}
{"mode": "train", "epochs": 1, "timestep": 1031, "ep_reward": 503.6767272949219, "reward": 0.5830566883087158, "action": 1.7937510013580322}
{"mode": "train", "epochs": 1, "timestep": 1032, "ep_reward": 504.283447265625, "reward": 0.6067200899124146, "action": 0.46277517080307007}
{"mode": "train", "epochs": 1, "timestep": 1033, "ep_reward": 504.90985107421875, "reward": 0.626404345035553, "action": 1.4003723859786987}
{"mode": "train", "epochs": 1, "timestep": 1034, "ep_reward": 505.54888916015625, "reward": 0.6390343904495239, "action": 0.585623025894165}
{"mode": "train", "epochs": 1, "timestep": 1035, "ep_reward": 506.19354248046875, "reward": 0.6446453332901001, "action": 1.1368144750595093}
{"mode": "train", "epochs": 1, "timestep": 1036, "ep_reward": 506.8366394042969, "reward": 0.6431077122688293, "action": 0.9930168390274048}
{"mode": "train", "epochs": 1, "timestep": 1037, "ep_reward": 507.4711608886719, "reward": 0.6345277428627014, "action": 0.5234235525131226}
{"mode": "train", "epochs": 1, "timestep": 1038, "ep_reward": 508.08819580078125, "reward": 0.6170389652252197, "action": 1.230029582977295}
{"mode": "train", "epochs": 1, "timestep": 1039, "ep_reward": 508.6829833984375, "reward": 0.5947779417037964, "action": 0.5130500197410583}
{"mode": "train", "epochs": 1, "timestep": 1040, "ep_reward": 509.2464904785156, "reward": 0.5635153651237488, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1041, "ep_reward": 509.7813415527344, "reward": 0.5348598957061768, "action": 0.8027034401893616}
{"mode": "train", "epochs": 1, "timestep": 1042, "ep_reward": 510.2799072265625, "reward": 0.4985553026199341, "action": 0.007816433906555176}
{"mode": "train", "epochs": 1, "timestep": 1043, "ep_reward": 510.734130859375, "reward": 0.45423424243927, "action": 0.33891475200653076}
{"mode": "train", "epochs": 1, "timestep": 1044, "ep_reward": 511.1426086425781, "reward": 0.408491313457489, "action": 0.9888637065887451}
{"mode": "train", "epochs": 1, "timestep": 1045, "ep_reward": 511.509521484375, "reward": 0.3669123649597168, "action": 0.7145828604698181}
{"mode": "train", "epochs": 1, "timestep": 1046, "ep_reward": 511.890380859375, "reward": 0.38086748123168945, "action": 0.8480173349380493}
{"mode": "train", "epochs": 1, "timestep": 1047, "ep_reward": 512.313232421875, "reward": 0.4228803515434265, "action": 1.173882246017456}
{"mode": "train", "epochs": 1, "timestep": 1048, "ep_reward": 512.7738037109375, "reward": 0.4605918526649475, "action": 0.7359235286712646}
{"mode": "train", "epochs": 1, "timestep": 1049, "ep_reward": 513.2647705078125, "reward": 0.490958034992218, "action": 0.27393603324890137}
{"mode": "train", "epochs": 1, "timestep": 1050, "ep_reward": 513.779296875, "reward": 0.5145269632339478, "action": 0.39170610904693604}
{"mode": "train", "epochs": 1, "timestep": 1051, "ep_reward": 514.3109130859375, "reward": 0.5315994024276733, "action": 0.8478058576583862}
{"mode": "train", "epochs": 1, "timestep": 1052, "ep_reward": 514.8511352539062, "reward": 0.5402244329452515, "action": 1.590277910232544}
{"mode": "train", "epochs": 1, "timestep": 1053, "ep_reward": 515.3883056640625, "reward": 0.5371893644332886, "action": 0.4048306941986084}
{"mode": "train", "epochs": 1, "timestep": 1054, "ep_reward": 515.9136962890625, "reward": 0.5253709554672241, "action": 1.1377447843551636}
{"mode": "train", "epochs": 1, "timestep": 1055, "ep_reward": 516.41650390625, "reward": 0.502820611000061, "action": 0.04349970817565918}
{"mode": "train", "epochs": 1, "timestep": 1056, "ep_reward": 516.8926391601562, "reward": 0.47611159086227417, "action": 0.7158602476119995}
{"mode": "train", "epochs": 1, "timestep": 1057, "ep_reward": 517.3339233398438, "reward": 0.4412754774093628, "action": 0.8465556502342224}
{"mode": "train", "epochs": 1, "timestep": 1058, "ep_reward": 517.734130859375, "reward": 0.40019524097442627, "action": 0.8044546246528625}
{"mode": "train", "epochs": 1, "timestep": 1059, "ep_reward": 518.0912475585938, "reward": 0.35712456703186035, "action": 1.0251226425170898}
{"mode": "train", "epochs": 1, "timestep": 1060, "ep_reward": 518.4871215820312, "reward": 0.39587485790252686, "action": 1.5637812614440918}
{"mode": "train", "epochs": 1, "timestep": 1061, "ep_reward": 518.9227905273438, "reward": 0.43566346168518066, "action": 1.5888482332229614}
{"mode": "train", "epochs": 1, "timestep": 1062, "ep_reward": 519.4000244140625, "reward": 0.477217435836792, "action": 1.272621989250183}
{"mode": "train", "epochs": 1, "timestep": 1063, "ep_reward": 519.9198608398438, "reward": 0.5198169946670532, "action": 0.8021246790885925}
{"mode": "train", "epochs": 1, "timestep": 1064, "ep_reward": 520.4811401367188, "reward": 0.5612526535987854, "action": 0.4903640151023865}
{"mode": "train", "epochs": 1, "timestep": 1065, "ep_reward": 521.0792846679688, "reward": 0.5981411337852478, "action": 0.058455705642700195}
{"mode": "train", "epochs": 1, "timestep": 1066, "ep_reward": 521.7068481445312, "reward": 0.6275873184204102, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1067, "ep_reward": 522.3548583984375, "reward": 0.6480370163917542, "action": 1.0483078956604004}
{"mode": "train", "epochs": 1, "timestep": 1068, "ep_reward": 523.0186157226562, "reward": 0.6637740135192871, "action": 1.1345819234848022}
{"mode": "train", "epochs": 1, "timestep": 1069, "ep_reward": 523.690673828125, "reward": 0.6720709800720215, "action": 1.20271897315979}
{"mode": "train", "epochs": 1, "timestep": 1070, "ep_reward": 524.3637084960938, "reward": 0.6730599999427795, "action": 0.5046370029449463}
{"mode": "train", "epochs": 1, "timestep": 1071, "ep_reward": 525.0281372070312, "reward": 0.6644342541694641, "action": 1.1677591800689697}
{"mode": "train", "epochs": 1, "timestep": 1072, "ep_reward": 525.6766967773438, "reward": 0.6485465168952942, "action": 1.1738595962524414}
{"mode": "train", "epochs": 1, "timestep": 1073, "ep_reward": 526.3024291992188, "reward": 0.6257175207138062, "action": 0.6521269679069519}
{"mode": "train", "epochs": 1, "timestep": 1074, "ep_reward": 526.8960571289062, "reward": 0.5936568975448608, "action": 0.8425712585449219}
{"mode": "train", "epochs": 1, "timestep": 1075, "ep_reward": 527.4514770507812, "reward": 0.555443525314331, "action": 0.7462025880813599}
{"mode": "train", "epochs": 1, "timestep": 1076, "ep_reward": 527.9627075195312, "reward": 0.5112254619598389, "action": 1.4673237800598145}
{"mode": "train", "epochs": 1, "timestep": 1077, "ep_reward": 528.4312133789062, "reward": 0.4685019850730896, "action": 0.3850551247596741}
{"mode": "train", "epochs": 1, "timestep": 1078, "ep_reward": 528.8491821289062, "reward": 0.4179426431655884, "action": 1.532362937927246}
{"mode": "train", "epochs": 1, "timestep": 1079, "ep_reward": 529.224365234375, "reward": 0.37519776821136475, "action": 1.3418538570404053}
{"mode": "train", "epochs": 1, "timestep": 1080, "ep_reward": 529.5907592773438, "reward": 0.36640626192092896, "action": 1.1466408967971802}
{"mode": "train", "epochs": 1, "timestep": 1081, "ep_reward": 530.0020751953125, "reward": 0.4112997055053711, "action": 0.9575260281562805}
{"mode": "train", "epochs": 1, "timestep": 1082, "ep_reward": 530.4529418945312, "reward": 0.4508950114250183, "action": 1.0197619199752808}
{"mode": "train", "epochs": 1, "timestep": 1083, "ep_reward": 530.9373168945312, "reward": 0.4843703508377075, "action": 0.9999727010726929}
{"mode": "train", "epochs": 1, "timestep": 1084, "ep_reward": 531.4473266601562, "reward": 0.5100001692771912, "action": 1.033922553062439}
{"mode": "train", "epochs": 1, "timestep": 1085, "ep_reward": 531.9739379882812, "reward": 0.5266008973121643, "action": 1.3779723644256592}
{"mode": "train", "epochs": 1, "timestep": 1086, "ep_reward": 532.5064086914062, "reward": 0.532500147819519, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1087, "ep_reward": 533.0313720703125, "reward": 0.5249661207199097, "action": 0.7275227308273315}
{"mode": "train", "epochs": 1, "timestep": 1088, "ep_reward": 533.5394287109375, "reward": 0.5080591440200806, "action": 1.5345896482467651}
{"mode": "train", "epochs": 1, "timestep": 1089, "ep_reward": 534.0185546875, "reward": 0.4791197180747986, "action": 1.1636130809783936}
{"mode": "train", "epochs": 1, "timestep": 1090, "ep_reward": 534.4603881835938, "reward": 0.4418075680732727, "action": 1.0114003419876099}
{"mode": "train", "epochs": 1, "timestep": 1091, "ep_reward": 534.8585205078125, "reward": 0.3981155753135681, "action": 1.2921541929244995}
{"mode": "train", "epochs": 1, "timestep": 1092, "ep_reward": 535.2142944335938, "reward": 0.35577231645584106, "action": 0.7981472611427307}
{"mode": "train", "epochs": 1, "timestep": 1093, "ep_reward": 535.6119384765625, "reward": 0.39766925573349, "action": 1.1629352569580078}
{"mode": "train", "epochs": 1, "timestep": 1094, "ep_reward": 536.0520629882812, "reward": 0.4401072859764099, "action": 1.5225348472595215}
{"mode": "train", "epochs": 1, "timestep": 1095, "ep_reward": 536.53466796875, "reward": 0.4826059937477112, "action": 1.1147295236587524}
{"mode": "train", "epochs": 1, "timestep": 1096, "ep_reward": 537.0606689453125, "reward": 0.5259854793548584, "action": -0.0746801495552063}
{"mode": "train", "epochs": 1, "timestep": 1097, "ep_reward": 537.629150390625, "reward": 0.5684572458267212, "action": 0.8223799467086792}
{"mode": "train", "epochs": 1, "timestep": 1098, "ep_reward": 538.2311401367188, "reward": 0.6020091772079468, "action": 1.188070297241211}
{"mode": "train", "epochs": 1, "timestep": 1099, "ep_reward": 538.8604125976562, "reward": 0.6292502284049988, "action": 0.800537645816803}
{"mode": "train", "epochs": 1, "timestep": 1100, "ep_reward": 539.5108032226562, "reward": 0.6504009962081909, "action": 0.6925643086433411}
{"mode": "train", "epochs": 1, "timestep": 1101, "ep_reward": 540.1741333007812, "reward": 0.6633127927780151, "action": 1.4253196716308594}
{"mode": "train", "epochs": 1, "timestep": 1102, "ep_reward": 540.8429565429688, "reward": 0.668806254863739, "action": 1.1523876190185547}
{"mode": "train", "epochs": 1, "timestep": 1103, "ep_reward": 541.5099487304688, "reward": 0.6670221090316772, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1104, "ep_reward": 542.1705932617188, "reward": 0.6606523990631104, "action": 1.6136034727096558}
{"mode": "train", "epochs": 1, "timestep": 1105, "ep_reward": 542.8191528320312, "reward": 0.6485779881477356, "action": 0.8356824517250061}
{"mode": "train", "epochs": 1, "timestep": 1106, "ep_reward": 543.4468994140625, "reward": 0.6277663707733154, "action": 0.54822838306427}
{"mode": "train", "epochs": 1, "timestep": 1107, "ep_reward": 544.0445556640625, "reward": 0.5976664423942566, "action": 1.7497847080230713}
{"mode": "train", "epochs": 1, "timestep": 1108, "ep_reward": 544.611572265625, "reward": 0.5670025944709778, "action": 0.9302743673324585}
{"mode": "train", "epochs": 1, "timestep": 1109, "ep_reward": 545.140380859375, "reward": 0.528793215751648, "action": 0.6294090747833252}
{"mode": "train", "epochs": 1, "timestep": 1110, "ep_reward": 545.625, "reward": 0.48463642597198486, "action": 1.6804646253585815}
{"mode": "train", "epochs": 1, "timestep": 1111, "ep_reward": 546.0701293945312, "reward": 0.44514524936676025, "action": 0.7423000931739807}
{"mode": "train", "epochs": 1, "timestep": 1112, "ep_reward": 546.4710693359375, "reward": 0.4009379744529724, "action": -0.10743474960327148}
{"mode": "train", "epochs": 1, "timestep": 1113, "ep_reward": 546.8224487304688, "reward": 0.35140496492385864, "action": 1.063978672027588}
{"mode": "train", "epochs": 1, "timestep": 1114, "ep_reward": 547.212890625, "reward": 0.3904288411140442, "action": 1.7078933715820312}
{"mode": "train", "epochs": 1, "timestep": 1115, "ep_reward": 547.6480102539062, "reward": 0.4351244568824768, "action": 0.8440144658088684}
{"mode": "train", "epochs": 1, "timestep": 1116, "ep_reward": 548.119140625, "reward": 0.4711334705352783, "action": 0.060437023639678955}
{"mode": "train", "epochs": 1, "timestep": 1117, "ep_reward": 548.61962890625, "reward": 0.5005133748054504, "action": 0.7268946170806885}
{"mode": "train", "epochs": 1, "timestep": 1118, "ep_reward": 549.1442260742188, "reward": 0.5245773792266846, "action": 0.8918805122375488}
{"mode": "train", "epochs": 1, "timestep": 1119, "ep_reward": 549.68408203125, "reward": 0.539862871170044, "action": 1.2641923427581787}
{"mode": "train", "epochs": 1, "timestep": 1120, "ep_reward": 550.2286376953125, "reward": 0.5445270538330078, "action": 0.32837140560150146}
{"mode": "train", "epochs": 1, "timestep": 1121, "ep_reward": 550.7686767578125, "reward": 0.540048360824585, "action": 1.389020323753357}
{"mode": "train", "epochs": 1, "timestep": 1122, "ep_reward": 551.2925415039062, "reward": 0.5238539576530457, "action": 0.32039833068847656}
{"mode": "train", "epochs": 1, "timestep": 1123, "ep_reward": 551.7933349609375, "reward": 0.500767707824707, "action": 1.4796411991119385}
{"mode": "train", "epochs": 1, "timestep": 1124, "ep_reward": 552.2584838867188, "reward": 0.4651763439178467, "action": 0.5833424925804138}
{"mode": "train", "epochs": 1, "timestep": 1125, "ep_reward": 552.683837890625, "reward": 0.42537301778793335, "action": 0.7416434288024902}
{"mode": "train", "epochs": 1, "timestep": 1126, "ep_reward": 553.06396484375, "reward": 0.38012754917144775, "action": 1.1415414810180664}
{"mode": "train", "epochs": 1, "timestep": 1127, "ep_reward": 553.4345703125, "reward": 0.37060225009918213, "action": 0.7941343784332275}
{"mode": "train", "epochs": 1, "timestep": 1128, "ep_reward": 553.8478393554688, "reward": 0.41327154636383057, "action": 1.3429011106491089}
{"mode": "train", "epochs": 1, "timestep": 1129, "ep_reward": 554.3035278320312, "reward": 0.455716609954834, "action": 0.9610736966133118}
{"mode": "train", "epochs": 1, "timestep": 1130, "ep_reward": 554.8028564453125, "reward": 0.4993191957473755, "action": 1.5154144763946533}
{"mode": "train", "epochs": 1, "timestep": 1131, "ep_reward": 555.3429565429688, "reward": 0.540076494216919, "action": 0.8237723112106323}
{"mode": "train", "epochs": 1, "timestep": 1132, "ep_reward": 555.9227294921875, "reward": 0.5798027515411377, "action": 1.2153270244598389}
{"mode": "train", "epochs": 1, "timestep": 1133, "ep_reward": 556.536376953125, "reward": 0.6136693954467773, "action": 1.0671629905700684}
{"mode": "train", "epochs": 1, "timestep": 1134, "ep_reward": 557.1785888671875, "reward": 0.6422263979911804, "action": 0.22874897718429565}
{"mode": "train", "epochs": 1, "timestep": 1135, "ep_reward": 557.8419799804688, "reward": 0.663419246673584, "action": 1.9013938903808594}
{"mode": "train", "epochs": 1, "timestep": 1136, "ep_reward": 558.5181274414062, "reward": 0.6761482954025269, "action": 0.5724642276763916}
{"mode": "train", "epochs": 1, "timestep": 1137, "ep_reward": 559.1995849609375, "reward": 0.6814326643943787, "action": 1.3272318840026855}
{"mode": "train", "epochs": 1, "timestep": 1138, "ep_reward": 559.87841796875, "reward": 0.6788556575775146, "action": -0.1290982961654663}
{"mode": "train", "epochs": 1, "timestep": 1139, "ep_reward": 560.5422973632812, "reward": 0.6638985872268677, "action": 1.3020797967910767}
{"mode": "train", "epochs": 1, "timestep": 1140, "ep_reward": 561.1851806640625, "reward": 0.6428730487823486, "action": 0.7788286805152893}
{"mode": "train", "epochs": 1, "timestep": 1141, "ep_reward": 561.7977294921875, "reward": 0.6125659942626953, "action": 0.8517382144927979}
{"mode": "train", "epochs": 1, "timestep": 1142, "ep_reward": 562.3726196289062, "reward": 0.5748885273933411, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1143, "ep_reward": 562.91162109375, "reward": 0.5390169620513916, "action": 0.21944475173950195}
{"mode": "train", "epochs": 1, "timestep": 1144, "ep_reward": 563.401611328125, "reward": 0.4899752140045166, "action": 0.8574466705322266}
{"mode": "train", "epochs": 1, "timestep": 1145, "ep_reward": 563.8424682617188, "reward": 0.44088655710220337, "action": 0.4449161887168884}
{"mode": "train", "epochs": 1, "timestep": 1146, "ep_reward": 564.2303466796875, "reward": 0.3878820538520813, "action": 1.6927180290222168}
{"mode": "train", "epochs": 1, "timestep": 1147, "ep_reward": 564.5755615234375, "reward": 0.34523820877075195, "action": 1.1441714763641357}
{"mode": "train", "epochs": 1, "timestep": 1148, "ep_reward": 564.9688720703125, "reward": 0.39332324266433716, "action": 1.1953173875808716}
{"mode": "train", "epochs": 1, "timestep": 1149, "ep_reward": 565.4076538085938, "reward": 0.4387986660003662, "action": 0.8288429379463196}
{"mode": "train", "epochs": 1, "timestep": 1150, "ep_reward": 565.8851318359375, "reward": 0.47744905948638916, "action": 0.8892404437065125}
{"mode": "train", "epochs": 1, "timestep": 1151, "ep_reward": 566.3944091796875, "reward": 0.5092580318450928, "action": 0.8627923130989075}
{"mode": "train", "epochs": 1, "timestep": 1152, "ep_reward": 566.9270629882812, "reward": 0.5326337814331055, "action": 0.11894363164901733}
{"mode": "train", "epochs": 1, "timestep": 1153, "ep_reward": 567.4744262695312, "reward": 0.5473800897598267, "action": 1.4849480390548706}
{"mode": "train", "epochs": 1, "timestep": 1154, "ep_reward": 568.0266723632812, "reward": 0.5522612929344177, "action": 1.1983691453933716}
{"mode": "train", "epochs": 1, "timestep": 1155, "ep_reward": 568.571533203125, "reward": 0.5448352098464966, "action": 0.6895307302474976}
{"mode": "train", "epochs": 1, "timestep": 1156, "ep_reward": 569.0991821289062, "reward": 0.5276249647140503, "action": 1.036299228668213}
{"mode": "train", "epochs": 1, "timestep": 1157, "ep_reward": 569.5988159179688, "reward": 0.4996386170387268, "action": 1.5744034051895142}
{"mode": "train", "epochs": 1, "timestep": 1158, "ep_reward": 570.057861328125, "reward": 0.45905083417892456, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1159, "ep_reward": 570.4635620117188, "reward": 0.40571218729019165, "action": 0.6368826627731323}
{"mode": "train", "epochs": 1, "timestep": 1160, "ep_reward": 570.8165283203125, "reward": 0.3529702425003052, "action": 0.7085292339324951}
{"mode": "train", "epochs": 1, "timestep": 1161, "ep_reward": 571.2008056640625, "reward": 0.3842499852180481, "action": 0.727493166923523}
{"mode": "train", "epochs": 1, "timestep": 1162, "ep_reward": 571.6322021484375, "reward": 0.4313756227493286, "action": 1.58457612991333}
{"mode": "train", "epochs": 1, "timestep": 1163, "ep_reward": 572.1087646484375, "reward": 0.4765685796737671, "action": 0.9245724081993103}
{"mode": "train", "epochs": 1, "timestep": 1164, "ep_reward": 572.632080078125, "reward": 0.5233449339866638, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1165, "ep_reward": 573.1970825195312, "reward": 0.5649866461753845, "action": 1.591399073600769}
{"mode": "train", "epochs": 1, "timestep": 1166, "ep_reward": 573.8028564453125, "reward": 0.6057847738265991, "action": 1.0659393072128296}
{"mode": "train", "epochs": 1, "timestep": 1167, "ep_reward": 574.4458618164062, "reward": 0.6429774761199951, "action": 1.6779530048370361}
{"mode": "train", "epochs": 1, "timestep": 1168, "ep_reward": 575.1185913085938, "reward": 0.6727515459060669, "action": 1.0311822891235352}
{"mode": "train", "epochs": 1, "timestep": 1169, "ep_reward": 575.8152465820312, "reward": 0.6966433525085449, "action": 1.1919163465499878}
{"mode": "train", "epochs": 1, "timestep": 1170, "ep_reward": 576.527099609375, "reward": 0.7118371725082397, "action": 1.5537539720535278}
{"mode": "train", "epochs": 1, "timestep": 1171, "ep_reward": 577.246337890625, "reward": 0.719208836555481, "action": 0.2289106249809265}
{"mode": "train", "epochs": 1, "timestep": 1172, "ep_reward": 577.9622802734375, "reward": 0.7159152030944824, "action": 0.7282357215881348}
{"mode": "train", "epochs": 1, "timestep": 1173, "ep_reward": 578.6640625, "reward": 0.7017861604690552, "action": 0.4992632269859314}
{"mode": "train", "epochs": 1, "timestep": 1174, "ep_reward": 579.340087890625, "reward": 0.6760290861129761, "action": 1.2596869468688965}
{"mode": "train", "epochs": 1, "timestep": 1175, "ep_reward": 579.9835815429688, "reward": 0.6434797644615173, "action": 1.630108118057251}
{"mode": "train", "epochs": 1, "timestep": 1176, "ep_reward": 580.5896606445312, "reward": 0.6060782670974731, "action": 1.3728684186935425}
{"mode": "train", "epochs": 1, "timestep": 1177, "ep_reward": 581.15185546875, "reward": 0.56218421459198, "action": 0.9825311303138733}
{"mode": "train", "epochs": 1, "timestep": 1178, "ep_reward": 581.6629638671875, "reward": 0.5111320614814758, "action": 1.751075267791748}
{"mode": "train", "epochs": 1, "timestep": 1179, "ep_reward": 582.125732421875, "reward": 0.4627476930618286, "action": 1.6343928575515747}
{"mode": "train", "epochs": 1, "timestep": 1180, "ep_reward": 582.5404052734375, "reward": 0.4146711826324463, "action": 0.719361424446106}
{"mode": "train", "epochs": 1, "timestep": 1181, "ep_reward": 582.9024658203125, "reward": 0.3620471954345703, "action": 0.6533433198928833}
{"mode": "train", "epochs": 1, "timestep": 1182, "ep_reward": 583.2674560546875, "reward": 0.3650059103965759, "action": 1.3219355344772339}
{"mode": "train", "epochs": 1, "timestep": 1183, "ep_reward": 583.6861572265625, "reward": 0.41871178150177, "action": 0.39600878953933716}
{"mode": "train", "epochs": 1, "timestep": 1184, "ep_reward": 584.1509399414062, "reward": 0.46480584144592285, "action": 0.2285560965538025}
{"mode": "train", "epochs": 1, "timestep": 1185, "ep_reward": 584.65673828125, "reward": 0.5057723522186279, "action": 1.0951063632965088}
{"mode": "train", "epochs": 1, "timestep": 1186, "ep_reward": 585.1978149414062, "reward": 0.5410478711128235, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1187, "ep_reward": 585.7630004882812, "reward": 0.5651808977127075, "action": 0.6571029424667358}
{"mode": "train", "epochs": 1, "timestep": 1188, "ep_reward": 586.33837890625, "reward": 0.5753726959228516, "action": 0.9272502064704895}
{"mode": "train", "epochs": 1, "timestep": 1189, "ep_reward": 586.9125366210938, "reward": 0.5741620063781738, "action": 1.3114769458770752}
{"mode": "train", "epochs": 1, "timestep": 1190, "ep_reward": 587.4722290039062, "reward": 0.5597091317176819, "action": 0.7057561874389648}
{"mode": "train", "epochs": 1, "timestep": 1191, "ep_reward": 588.0069580078125, "reward": 0.5347452163696289, "action": 1.2232842445373535}
{"mode": "train", "epochs": 1, "timestep": 1192, "ep_reward": 588.5042114257812, "reward": 0.4972594976425171, "action": 1.0665944814682007}
{"mode": "train", "epochs": 1, "timestep": 1193, "ep_reward": 588.95458984375, "reward": 0.45038318634033203, "action": 0.32255232334136963}
{"mode": "train", "epochs": 1, "timestep": 1194, "ep_reward": 589.3556518554688, "reward": 0.40103447437286377, "action": 1.0497955083847046}
{"mode": "train", "epochs": 1, "timestep": 1195, "ep_reward": 589.6992797851562, "reward": 0.343631386756897, "action": 0.3007361888885498}
{"mode": "train", "epochs": 1, "timestep": 1196, "ep_reward": 590.0875244140625, "reward": 0.38823986053466797, "action": 1.707872748374939}
{"mode": "train", "epochs": 1, "timestep": 1197, "ep_reward": 590.5217895507812, "reward": 0.43424516916275024, "action": 1.270439624786377}
{"mode": "train", "epochs": 1, "timestep": 1198, "ep_reward": 591.0051879882812, "reward": 0.4833691120147705, "action": 1.0093412399291992}
{"mode": "train", "epochs": 1, "timestep": 1199, "ep_reward": 591.53759765625, "reward": 0.5324162244796753, "action": 0.15159392356872559}
{"mode": "train", "epochs": 1, "timestep": 1200, "ep_reward": 592.1173706054688, "reward": 0.5797949433326721, "action": 0.8569698333740234}
{"mode": "train", "epochs": 1, "timestep": 1201, "ep_reward": 592.7354736328125, "reward": 0.6180757284164429, "action": 1.9076839685440063}
{"mode": "train", "epochs": 1, "timestep": 1202, "ep_reward": 593.3843383789062, "reward": 0.648848295211792, "action": 0.7417138814926147}
{"mode": "train", "epochs": 1, "timestep": 1203, "ep_reward": 594.0597534179688, "reward": 0.6754310131072998, "action": 1.3181612491607666}
{"mode": "train", "epochs": 1, "timestep": 1204, "ep_reward": 594.7529907226562, "reward": 0.6932567358016968, "action": 0.595880389213562}
{"mode": "train", "epochs": 1, "timestep": 1205, "ep_reward": 595.4554443359375, "reward": 0.7024350166320801, "action": 1.4512646198272705}
{"mode": "train", "epochs": 1, "timestep": 1206, "ep_reward": 596.1586303710938, "reward": 0.7031744718551636, "action": -0.10488104820251465}
{"mode": "train", "epochs": 1, "timestep": 1207, "ep_reward": 596.8501586914062, "reward": 0.6915189623832703, "action": 0.9960010051727295}
{"mode": "train", "epochs": 1, "timestep": 1208, "ep_reward": 597.5213623046875, "reward": 0.6711814403533936, "action": 0.141762375831604}
{"mode": "train", "epochs": 1, "timestep": 1209, "ep_reward": 598.1590576171875, "reward": 0.6376700401306152, "action": 0.7405539155006409}
{"mode": "train", "epochs": 1, "timestep": 1210, "ep_reward": 598.7554931640625, "reward": 0.5964441895484924, "action": 1.6057875156402588}
{"mode": "train", "epochs": 1, "timestep": 1211, "ep_reward": 599.3092651367188, "reward": 0.5537919402122498, "action": 0.25404787063598633}
{"mode": "train", "epochs": 1, "timestep": 1212, "ep_reward": 599.8073120117188, "reward": 0.49805259704589844, "action": 0.7339804172515869}
{"mode": "train", "epochs": 1, "timestep": 1213, "ep_reward": 600.2479858398438, "reward": 0.4406512379646301, "action": 0.7213200926780701}
{"mode": "train", "epochs": 1, "timestep": 1214, "ep_reward": 600.6298828125, "reward": 0.38188040256500244, "action": -0.0198976993560791}
{"mode": "train", "epochs": 1, "timestep": 1215, "ep_reward": 600.9572143554688, "reward": 0.3273316025733948, "action": 1.7015905380249023}
{"mode": "train", "epochs": 1, "timestep": 1216, "ep_reward": 601.348876953125, "reward": 0.3916516900062561, "action": 1.1692910194396973}
{"mode": "train", "epochs": 1, "timestep": 1217, "ep_reward": 601.7969970703125, "reward": 0.44815051555633545, "action": 1.0625516176223755}
{"mode": "train", "epochs": 1, "timestep": 1218, "ep_reward": 602.2943115234375, "reward": 0.4973222613334656, "action": 1.4530237913131714}
{"mode": "train", "epochs": 1, "timestep": 1219, "ep_reward": 602.8323974609375, "reward": 0.5380741357803345, "action": 0.7680702805519104}
{"mode": "train", "epochs": 1, "timestep": 1220, "ep_reward": 603.3989868164062, "reward": 0.5665673017501831, "action": 0.5919515490531921}
{"mode": "train", "epochs": 1, "timestep": 1221, "ep_reward": 603.9834594726562, "reward": 0.5844946503639221, "action": 0.9937219619750977}
{"mode": "train", "epochs": 1, "timestep": 1222, "ep_reward": 604.5743408203125, "reward": 0.5908701419830322, "action": 1.1988521814346313}
{"mode": "train", "epochs": 1, "timestep": 1223, "ep_reward": 605.1581420898438, "reward": 0.5837843418121338, "action": 0.5088886022567749}
{"mode": "train", "epochs": 1, "timestep": 1224, "ep_reward": 605.723876953125, "reward": 0.565729558467865, "action": 0.7042442560195923}
{"mode": "train", "epochs": 1, "timestep": 1225, "ep_reward": 606.2604370117188, "reward": 0.536571741104126, "action": 0.7448679208755493}
{"mode": "train", "epochs": 1, "timestep": 1226, "ep_reward": 606.7576904296875, "reward": 0.49726879596710205, "action": 0.5900574922561646}
{"mode": "train", "epochs": 1, "timestep": 1227, "ep_reward": 607.2080078125, "reward": 0.45032113790512085, "action": 1.6943085193634033}
{"mode": "train", "epochs": 1, "timestep": 1228, "ep_reward": 607.5974731445312, "reward": 0.38945382833480835, "action": 1.1133760213851929}
{"mode": "train", "epochs": 1, "timestep": 1229, "ep_reward": 607.9361572265625, "reward": 0.33869463205337524, "action": 1.7063401937484741}
{"mode": "train", "epochs": 1, "timestep": 1230, "ep_reward": 608.324951171875, "reward": 0.38878941535949707, "action": 0.6352217197418213}
{"mode": "train", "epochs": 1, "timestep": 1231, "ep_reward": 608.7703247070312, "reward": 0.44539541006088257, "action": 1.2387306690216064}
{"mode": "train", "epochs": 1, "timestep": 1232, "ep_reward": 609.2694091796875, "reward": 0.49905943870544434, "action": 0.8977236151695251}
{"mode": "train", "epochs": 1, "timestep": 1233, "ep_reward": 609.8214111328125, "reward": 0.5519969463348389, "action": 1.5720067024230957}
{"mode": "train", "epochs": 1, "timestep": 1234, "ep_reward": 610.4202880859375, "reward": 0.5988692045211792, "action": 0.3572937846183777}
{"mode": "train", "epochs": 1, "timestep": 1235, "ep_reward": 611.0640258789062, "reward": 0.6437307000160217, "action": 1.4670453071594238}
{"mode": "train", "epochs": 1, "timestep": 1236, "ep_reward": 611.7416381835938, "reward": 0.6775929927825928, "action": 1.2112663984298706}
{"mode": "train", "epochs": 1, "timestep": 1237, "ep_reward": 612.4463500976562, "reward": 0.7047054767608643, "action": 1.1777807474136353}
{"mode": "train", "epochs": 1, "timestep": 1238, "ep_reward": 613.169677734375, "reward": 0.7233052253723145, "action": 1.7196670770645142}
{"mode": "train", "epochs": 1, "timestep": 1239, "ep_reward": 613.9033813476562, "reward": 0.7337130308151245, "action": 1.3740040063858032}
{"mode": "train", "epochs": 1, "timestep": 1240, "ep_reward": 614.6397705078125, "reward": 0.7363661527633667, "action": -0.2532007098197937}
{"mode": "train", "epochs": 1, "timestep": 1241, "ep_reward": 615.3653564453125, "reward": 0.7255924940109253, "action": 0.9498951435089111}
{"mode": "train", "epochs": 1, "timestep": 1242, "ep_reward": 616.070068359375, "reward": 0.7046918869018555, "action": 1.4414163827896118}
{"mode": "train", "epochs": 1, "timestep": 1243, "ep_reward": 616.7465209960938, "reward": 0.6764729022979736, "action": 0.9753090143203735}
{"mode": "train", "epochs": 1, "timestep": 1244, "ep_reward": 617.3843383789062, "reward": 0.637840211391449, "action": 1.1391899585723877}
{"mode": "train", "epochs": 1, "timestep": 1245, "ep_reward": 617.9762573242188, "reward": 0.5919036269187927, "action": 1.1524020433425903}
{"mode": "train", "epochs": 1, "timestep": 1246, "ep_reward": 618.5159301757812, "reward": 0.5396785140037537, "action": 1.2897448539733887}
{"mode": "train", "epochs": 1, "timestep": 1247, "ep_reward": 619.0001220703125, "reward": 0.4842056632041931, "action": 1.415534496307373}
{"mode": "train", "epochs": 1, "timestep": 1248, "ep_reward": 619.428466796875, "reward": 0.42834967374801636, "action": 0.9267997145652771}
{"mode": "train", "epochs": 1, "timestep": 1249, "ep_reward": 619.798095703125, "reward": 0.3696330785751343, "action": 0.4278906583786011}
{"mode": "train", "epochs": 1, "timestep": 1250, "ep_reward": 620.1360473632812, "reward": 0.33794713020324707, "action": 1.6854584217071533}
{"mode": "train", "epochs": 1, "timestep": 1251, "ep_reward": 620.5376586914062, "reward": 0.4016265273094177, "action": 0.8868593573570251}
{"mode": "train", "epochs": 1, "timestep": 1252, "ep_reward": 620.9942016601562, "reward": 0.456521213054657, "action": 1.1372339725494385}
{"mode": "train", "epochs": 1, "timestep": 1253, "ep_reward": 621.4996948242188, "reward": 0.5054883360862732, "action": 0.4196891188621521}
{"mode": "train", "epochs": 1, "timestep": 1254, "ep_reward": 622.0440063476562, "reward": 0.5442950129508972, "action": 0.6009293794631958}
{"mode": "train", "epochs": 1, "timestep": 1255, "ep_reward": 622.6187744140625, "reward": 0.5747803449630737, "action": -0.06653988361358643}
{"mode": "train", "epochs": 1, "timestep": 1256, "ep_reward": 623.2139282226562, "reward": 0.5951687097549438, "action": 1.5549495220184326}
{"mode": "train", "epochs": 1, "timestep": 1257, "ep_reward": 623.8185424804688, "reward": 0.604590892791748, "action": 1.0377185344696045}
{"mode": "train", "epochs": 1, "timestep": 1258, "ep_reward": 624.4178466796875, "reward": 0.599276602268219, "action": 1.2420474290847778}
{"mode": "train", "epochs": 1, "timestep": 1259, "ep_reward": 624.997314453125, "reward": 0.5794596672058105, "action": 0.6974936723709106}
{"mode": "train", "epochs": 1, "timestep": 1260, "ep_reward": 625.5455932617188, "reward": 0.5482592582702637, "action": 0.9508795738220215}
{"mode": "train", "epochs": 1, "timestep": 1261, "ep_reward": 626.0505981445312, "reward": 0.5049915313720703, "action": 0.45963913202285767}
{"mode": "train", "epochs": 1, "timestep": 1262, "ep_reward": 626.505615234375, "reward": 0.45503026247024536, "action": 1.5416713953018188}
{"mode": "train", "epochs": 1, "timestep": 1263, "ep_reward": 626.8965454101562, "reward": 0.39095258712768555, "action": 1.8897933959960938}
{"mode": "train", "epochs": 1, "timestep": 1264, "ep_reward": 627.2235717773438, "reward": 0.327006459236145, "action": 1.2840920686721802}
{"mode": "train", "epochs": 1, "timestep": 1265, "ep_reward": 627.6063842773438, "reward": 0.3828214406967163, "action": 0.022102415561676025}
{"mode": "train", "epochs": 1, "timestep": 1266, "ep_reward": 628.0518188476562, "reward": 0.44540834426879883, "action": 0.96526700258255}
{"mode": "train", "epochs": 1, "timestep": 1267, "ep_reward": 628.5538330078125, "reward": 0.5019869804382324, "action": 0.5831809043884277}
{"mode": "train", "epochs": 1, "timestep": 1268, "ep_reward": 629.1107788085938, "reward": 0.5569667816162109, "action": 1.7998785972595215}
{"mode": "train", "epochs": 1, "timestep": 1269, "ep_reward": 629.714111328125, "reward": 0.6033521890640259, "action": 0.5333945751190186}
{"mode": "train", "epochs": 1, "timestep": 1270, "ep_reward": 630.3626098632812, "reward": 0.6484962701797485, "action": 1.0980781316757202}
{"mode": "train", "epochs": 1, "timestep": 1271, "ep_reward": 631.0462036132812, "reward": 0.6836036443710327, "action": 0.9075438380241394}
{"mode": "train", "epochs": 1, "timestep": 1272, "ep_reward": 631.7566528320312, "reward": 0.7104606628417969, "action": 0.7068018913269043}
{"mode": "train", "epochs": 1, "timestep": 1273, "ep_reward": 632.4841918945312, "reward": 0.7275524139404297, "action": 0.5262147188186646}
{"mode": "train", "epochs": 1, "timestep": 1274, "ep_reward": 633.2177124023438, "reward": 0.7335448265075684, "action": 0.561295747756958}
{"mode": "train", "epochs": 1, "timestep": 1275, "ep_reward": 633.945556640625, "reward": 0.7278494238853455, "action": 1.082155704498291}
{"mode": "train", "epochs": 1, "timestep": 1276, "ep_reward": 634.6580810546875, "reward": 0.7124955654144287, "action": 1.0217931270599365}
{"mode": "train", "epochs": 1, "timestep": 1277, "ep_reward": 635.3453979492188, "reward": 0.6873257756233215, "action": 1.5270143747329712}
{"mode": "train", "epochs": 1, "timestep": 1278, "ep_reward": 636.0010986328125, "reward": 0.6556954383850098, "action": 1.3952265977859497}
{"mode": "train", "epochs": 1, "timestep": 1279, "ep_reward": 636.61767578125, "reward": 0.6165592670440674, "action": 0.9923349022865295}
{"mode": "train", "epochs": 1, "timestep": 1280, "ep_reward": 637.1861572265625, "reward": 0.5684785842895508, "action": 1.0068527460098267}
{"mode": "train", "epochs": 1, "timestep": 1281, "ep_reward": 637.7008056640625, "reward": 0.514624834060669, "action": 0.3208942413330078}
{"mode": "train", "epochs": 1, "timestep": 1282, "ep_reward": 638.152099609375, "reward": 0.45128756761550903, "action": 0.6487793326377869}
{"mode": "train", "epochs": 1, "timestep": 1283, "ep_reward": 638.539306640625, "reward": 0.3872114419937134, "action": 1.6428654193878174}
{"mode": "train", "epochs": 1, "timestep": 1284, "ep_reward": 638.8719482421875, "reward": 0.3326708674430847, "action": 1.6449397802352905}
{"mode": "train", "epochs": 1, "timestep": 1285, "ep_reward": 639.2488403320312, "reward": 0.3769189119338989, "action": 1.6096172332763672}
{"mode": "train", "epochs": 1, "timestep": 1286, "ep_reward": 639.6841430664062, "reward": 0.43529361486434937, "action": 1.0979079008102417}
{"mode": "train", "epochs": 1, "timestep": 1287, "ep_reward": 640.1688842773438, "reward": 0.48471134901046753, "action": 0.22122681140899658}
{"mode": "train", "epochs": 1, "timestep": 1288, "ep_reward": 640.6935424804688, "reward": 0.5246407985687256, "action": 1.8943958282470703}
{"mode": "train", "epochs": 1, "timestep": 1289, "ep_reward": 641.2520751953125, "reward": 0.5585150718688965, "action": 0.9882420301437378}
{"mode": "train", "epochs": 1, "timestep": 1290, "ep_reward": 641.8299560546875, "reward": 0.5778608918190002, "action": 0.9208760261535645}
{"mode": "train", "epochs": 1, "timestep": 1291, "ep_reward": 642.4151611328125, "reward": 0.5851747989654541, "action": 0.866848349571228}
{"mode": "train", "epochs": 1, "timestep": 1292, "ep_reward": 642.9954223632812, "reward": 0.5802723169326782, "action": 1.3478400707244873}
{"mode": "train", "epochs": 1, "timestep": 1293, "ep_reward": 643.5568237304688, "reward": 0.561423122882843, "action": 1.47097909450531}
{"mode": "train", "epochs": 1, "timestep": 1294, "ep_reward": 644.0851440429688, "reward": 0.528296947479248, "action": 1.213134765625}
{"mode": "train", "epochs": 1, "timestep": 1295, "ep_reward": 644.5687866210938, "reward": 0.483648419380188, "action": 1.4687398672103882}
{"mode": "train", "epochs": 1, "timestep": 1296, "ep_reward": 644.9959716796875, "reward": 0.42716068029403687, "action": 1.3376436233520508}
{"mode": "train", "epochs": 1, "timestep": 1297, "ep_reward": 645.3589477539062, "reward": 0.3629757761955261, "action": 1.5436275005340576}
{"mode": "train", "epochs": 1, "timestep": 1298, "ep_reward": 645.7134399414062, "reward": 0.3544769883155823, "action": 1.9049131870269775}
{"mode": "train", "epochs": 1, "timestep": 1299, "ep_reward": 646.1205444335938, "reward": 0.40712374448776245, "action": 1.6206989288330078}
{"mode": "train", "epochs": 1, "timestep": 1300, "ep_reward": 646.5845336914062, "reward": 0.46396970748901367, "action": -0.12000924348831177}
{"mode": "train", "epochs": 1, "timestep": 1301, "ep_reward": 647.1116943359375, "reward": 0.5271909236907959, "action": 1.5686962604522705}
{"mode": "train", "epochs": 1, "timestep": 1302, "ep_reward": 647.6902465820312, "reward": 0.578572690486908, "action": 1.1127376556396484}
{"mode": "train", "epochs": 1, "timestep": 1303, "ep_reward": 648.317626953125, "reward": 0.6273932456970215, "action": 1.3270519971847534}
{"mode": "train", "epochs": 1, "timestep": 1304, "ep_reward": 648.9867553710938, "reward": 0.6691074371337891, "action": 0.5253221392631531}
{"mode": "train", "epochs": 1, "timestep": 1305, "ep_reward": 649.6911010742188, "reward": 0.7043319344520569, "action": 1.3657373189926147}
{"mode": "train", "epochs": 1, "timestep": 1306, "ep_reward": 650.4193115234375, "reward": 0.728180468082428, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1307, "ep_reward": 651.1635131835938, "reward": 0.744181752204895, "action": 0.6343896389007568}
{"mode": "train", "epochs": 1, "timestep": 1308, "ep_reward": 651.9153442382812, "reward": 0.7518383264541626, "action": 1.0851589441299438}
{"mode": "train", "epochs": 1, "timestep": 1309, "ep_reward": 652.664306640625, "reward": 0.7489365935325623, "action": 1.232131838798523}
{"mode": "train", "epochs": 1, "timestep": 1310, "ep_reward": 653.4009399414062, "reward": 0.7366513609886169, "action": 0.6529345512390137}
{"mode": "train", "epochs": 1, "timestep": 1311, "ep_reward": 654.1133422851562, "reward": 0.7123856544494629, "action": 0.7545045614242554}
{"mode": "train", "epochs": 1, "timestep": 1312, "ep_reward": 654.79052734375, "reward": 0.6771833896636963, "action": 0.23528790473937988}
{"mode": "train", "epochs": 1, "timestep": 1313, "ep_reward": 655.4183349609375, "reward": 0.6278074979782104, "action": 1.2817209959030151}
{"mode": "train", "epochs": 1, "timestep": 1314, "ep_reward": 655.9930419921875, "reward": 0.5747305154800415, "action": 1.8726260662078857}
{"mode": "train", "epochs": 1, "timestep": 1315, "ep_reward": 656.5139770507812, "reward": 0.5209066867828369, "action": 1.730509877204895}
{"mode": "train", "epochs": 1, "timestep": 1316, "ep_reward": 656.978515625, "reward": 0.46455878019332886, "action": 0.8200547695159912}
{"mode": "train", "epochs": 1, "timestep": 1317, "ep_reward": 657.3792724609375, "reward": 0.4007287621498108, "action": 0.44761013984680176}
{"mode": "train", "epochs": 1, "timestep": 1318, "ep_reward": 657.713134765625, "reward": 0.3338469862937927, "action": 1.310683250427246}
{"mode": "train", "epochs": 1, "timestep": 1319, "ep_reward": 658.07373046875, "reward": 0.3606176972389221, "action": 0.898444414138794}
{"mode": "train", "epochs": 1, "timestep": 1320, "ep_reward": 658.4976196289062, "reward": 0.4238865375518799, "action": 0.8918589353561401}
{"mode": "train", "epochs": 1, "timestep": 1321, "ep_reward": 658.9795532226562, "reward": 0.48194098472595215, "action": 0.9503849744796753}
{"mode": "train", "epochs": 1, "timestep": 1322, "ep_reward": 659.511962890625, "reward": 0.5324040055274963, "action": 1.136702299118042}
{"mode": "train", "epochs": 1, "timestep": 1323, "ep_reward": 660.0848388671875, "reward": 0.5728724002838135, "action": 1.4109089374542236}
{"mode": "train", "epochs": 1, "timestep": 1324, "ep_reward": 660.685546875, "reward": 0.6006795167922974, "action": 0.8840396404266357}
{"mode": "train", "epochs": 1, "timestep": 1325, "ep_reward": 661.2994384765625, "reward": 0.6138947606086731, "action": 1.50554621219635}
{"mode": "train", "epochs": 1, "timestep": 1326, "ep_reward": 661.9116821289062, "reward": 0.612221360206604, "action": 1.003641128540039}
{"mode": "train", "epochs": 1, "timestep": 1327, "ep_reward": 662.507568359375, "reward": 0.5958827137947083, "action": 1.1495046615600586}
{"mode": "train", "epochs": 1, "timestep": 1328, "ep_reward": 663.0726318359375, "reward": 0.5650620460510254, "action": 1.2592754364013672}
{"mode": "train", "epochs": 1, "timestep": 1329, "ep_reward": 663.5927734375, "reward": 0.520147442817688, "action": 1.1351995468139648}
{"mode": "train", "epochs": 1, "timestep": 1330, "ep_reward": 664.056640625, "reward": 0.4638872742652893, "action": 0.8936207890510559}
{"mode": "train", "epochs": 1, "timestep": 1331, "ep_reward": 664.4569702148438, "reward": 0.4003114104270935, "action": 0.5291847586631775}
{"mode": "train", "epochs": 1, "timestep": 1332, "ep_reward": 664.79150390625, "reward": 0.33452802896499634, "action": 0.6840085983276367}
{"mode": "train", "epochs": 1, "timestep": 1333, "ep_reward": 665.1632690429688, "reward": 0.3717682361602783, "action": 0.6637952923774719}
{"mode": "train", "epochs": 1, "timestep": 1334, "ep_reward": 665.593017578125, "reward": 0.42975568771362305, "action": 1.3130874633789062}
{"mode": "train", "epochs": 1, "timestep": 1335, "ep_reward": 666.0781860351562, "reward": 0.4851646423339844, "action": 0.7653500437736511}
{"mode": "train", "epochs": 1, "timestep": 1336, "ep_reward": 666.6195678710938, "reward": 0.541365385055542, "action": 0.1276458501815796}
{"mode": "train", "epochs": 1, "timestep": 1337, "ep_reward": 667.2139892578125, "reward": 0.5944007635116577, "action": 1.2619144916534424}
{"mode": "train", "epochs": 1, "timestep": 1338, "ep_reward": 667.8505249023438, "reward": 0.6365377306938171, "action": 0.8595675230026245}
{"mode": "train", "epochs": 1, "timestep": 1339, "ep_reward": 668.5233154296875, "reward": 0.6727961897850037, "action": 0.7280909419059753}
{"mode": "train", "epochs": 1, "timestep": 1340, "ep_reward": 669.2235717773438, "reward": 0.700261652469635, "action": 0.5629023313522339}
{"mode": "train", "epochs": 1, "timestep": 1341, "ep_reward": 669.941162109375, "reward": 0.7175625562667847, "action": 0.7504576444625854}
{"mode": "train", "epochs": 1, "timestep": 1342, "ep_reward": 670.6651611328125, "reward": 0.7240197658538818, "action": 1.0401129722595215}
{"mode": "train", "epochs": 1, "timestep": 1343, "ep_reward": 671.3858642578125, "reward": 0.7207138538360596, "action": 0.4085577726364136}
{"mode": "train", "epochs": 1, "timestep": 1344, "ep_reward": 672.0912475585938, "reward": 0.7054106593132019, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1345, "ep_reward": 672.7769165039062, "reward": 0.6856797933578491, "action": 1.2298671007156372}
{"mode": "train", "epochs": 1, "timestep": 1346, "ep_reward": 673.433349609375, "reward": 0.6564304828643799, "action": 0.7900217175483704}
{"mode": "train", "epochs": 1, "timestep": 1347, "ep_reward": 674.0501098632812, "reward": 0.6167703866958618, "action": 1.2677345275878906}
{"mode": "train", "epochs": 1, "timestep": 1348, "ep_reward": 674.622314453125, "reward": 0.5722178816795349, "action": 0.605593204498291}
{"mode": "train", "epochs": 1, "timestep": 1349, "ep_reward": 675.1400756835938, "reward": 0.5177421569824219, "action": 0.02015531063079834}
{"mode": "train", "epochs": 1, "timestep": 1350, "ep_reward": 675.5931396484375, "reward": 0.45306795835494995, "action": 1.0545272827148438}
{"mode": "train", "epochs": 1, "timestep": 1351, "ep_reward": 675.9860229492188, "reward": 0.39288485050201416, "action": 0.5951686501502991}
{"mode": "train", "epochs": 1, "timestep": 1352, "ep_reward": 676.3162841796875, "reward": 0.3302529454231262, "action": 0.6775389313697815}
{"mode": "train", "epochs": 1, "timestep": 1353, "ep_reward": 676.6876831054688, "reward": 0.3714224100112915, "action": 1.5661401748657227}
{"mode": "train", "epochs": 1, "timestep": 1354, "ep_reward": 677.1226196289062, "reward": 0.43495428562164307, "action": 1.0767698287963867}
{"mode": "train", "epochs": 1, "timestep": 1355, "ep_reward": 677.6119995117188, "reward": 0.4893571734428406, "action": 0.8973603248596191}
{"mode": "train", "epochs": 1, "timestep": 1356, "ep_reward": 678.1468505859375, "reward": 0.5348238348960876, "action": 1.2966926097869873}
{"mode": "train", "epochs": 1, "timestep": 1357, "ep_reward": 678.7174682617188, "reward": 0.5705936551094055, "action": 1.1425827741622925}
{"mode": "train", "epochs": 1, "timestep": 1358, "ep_reward": 679.310791015625, "reward": 0.5932934284210205, "action": 0.2842303514480591}
{"mode": "train", "epochs": 1, "timestep": 1359, "ep_reward": 679.9144287109375, "reward": 0.6036666035652161, "action": 1.3636974096298218}
{"mode": "train", "epochs": 1, "timestep": 1360, "ep_reward": 680.515380859375, "reward": 0.6009625792503357, "action": 1.1087877750396729}
{"mode": "train", "epochs": 1, "timestep": 1361, "ep_reward": 681.099365234375, "reward": 0.5839964151382446, "action": 0.05099719762802124}
{"mode": "train", "epochs": 1, "timestep": 1362, "ep_reward": 681.6577758789062, "reward": 0.558425784111023, "action": 1.194101333618164}
{"mode": "train", "epochs": 1, "timestep": 1363, "ep_reward": 682.176025390625, "reward": 0.5182539820671082, "action": 0.9909669160842896}
{"mode": "train", "epochs": 1, "timestep": 1364, "ep_reward": 682.6438598632812, "reward": 0.4678107500076294, "action": 1.2504199743270874}
{"mode": "train", "epochs": 1, "timestep": 1365, "ep_reward": 683.0507202148438, "reward": 0.4068467617034912, "action": 1.2396166324615479}
{"mode": "train", "epochs": 1, "timestep": 1366, "ep_reward": 683.3898315429688, "reward": 0.3390958309173584, "action": 0.652329683303833}
{"mode": "train", "epochs": 1, "timestep": 1367, "ep_reward": 683.7611083984375, "reward": 0.3712615370750427, "action": 1.7494100332260132}
{"mode": "train", "epochs": 1, "timestep": 1368, "ep_reward": 684.1857299804688, "reward": 0.4246242642402649, "action": 0.9725176095962524}
{"mode": "train", "epochs": 1, "timestep": 1369, "ep_reward": 684.6685791015625, "reward": 0.4828537106513977, "action": 0.6807504296302795}
{"mode": "train", "epochs": 1, "timestep": 1370, "ep_reward": 685.2086791992188, "reward": 0.5400815010070801, "action": 1.4838972091674805}
{"mode": "train", "epochs": 1, "timestep": 1371, "ep_reward": 685.7989501953125, "reward": 0.5902885794639587, "action": 0.9316536784172058}
{"mode": "train", "epochs": 1, "timestep": 1372, "ep_reward": 686.4364013671875, "reward": 0.6374780535697937, "action": 0.7526939511299133}
{"mode": "train", "epochs": 1, "timestep": 1373, "ep_reward": 687.1134643554688, "reward": 0.6770431399345398, "action": 1.9797921180725098}
{"mode": "train", "epochs": 1, "timestep": 1374, "ep_reward": 687.8198852539062, "reward": 0.7063965201377869, "action": 0.6387098431587219}
{"mode": "train", "epochs": 1, "timestep": 1375, "ep_reward": 688.5498046875, "reward": 0.7298912405967712, "action": 1.439378261566162}
{"mode": "train", "epochs": 1, "timestep": 1376, "ep_reward": 689.2928466796875, "reward": 0.7430347204208374, "action": 0.8630408048629761}
{"mode": "train", "epochs": 1, "timestep": 1377, "ep_reward": 690.03955078125, "reward": 0.7467243075370789, "action": 1.2742325067520142}
{"mode": "train", "epochs": 1, "timestep": 1378, "ep_reward": 690.780517578125, "reward": 0.7409831285476685, "action": 0.45983654260635376}
{"mode": "train", "epochs": 1, "timestep": 1379, "ep_reward": 691.5035400390625, "reward": 0.7230061292648315, "action": 0.43667179346084595}
{"mode": "train", "epochs": 1, "timestep": 1380, "ep_reward": 692.1959838867188, "reward": 0.6924500465393066, "action": 1.3930773735046387}
{"mode": "train", "epochs": 1, "timestep": 1381, "ep_reward": 692.8516235351562, "reward": 0.6556696891784668, "action": 0.9577183127403259}
{"mode": "train", "epochs": 1, "timestep": 1382, "ep_reward": 693.4600219726562, "reward": 0.608394980430603, "action": 0.6645985245704651}
{"mode": "train", "epochs": 1, "timestep": 1383, "ep_reward": 694.0108032226562, "reward": 0.550757110118866, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1384, "ep_reward": 694.5083618164062, "reward": 0.497564435005188, "action": 1.4017890691757202}
{"mode": "train", "epochs": 1, "timestep": 1385, "ep_reward": 694.9476928710938, "reward": 0.4393005967140198, "action": 0.7187678813934326}
{"mode": "train", "epochs": 1, "timestep": 1386, "ep_reward": 695.3232421875, "reward": 0.37553834915161133, "action": 1.4623215198516846}
{"mode": "train", "epochs": 1, "timestep": 1387, "ep_reward": 695.6473388671875, "reward": 0.32407206296920776, "action": 1.356652021408081}
{"mode": "train", "epochs": 1, "timestep": 1388, "ep_reward": 696.03515625, "reward": 0.38784390687942505, "action": 0.9922006726264954}
{"mode": "train", "epochs": 1, "timestep": 1389, "ep_reward": 696.480712890625, "reward": 0.4455466866493225, "action": 0.7346946001052856}
{"mode": "train", "epochs": 1, "timestep": 1390, "ep_reward": 696.97705078125, "reward": 0.49635666608810425, "action": 1.2279037237167358}
{"mode": "train", "epochs": 1, "timestep": 1391, "ep_reward": 697.5171508789062, "reward": 0.5401208996772766, "action": 1.517264485359192}
{"mode": "train", "epochs": 1, "timestep": 1392, "ep_reward": 698.089599609375, "reward": 0.5724790096282959, "action": 1.1117991209030151}
{"mode": "train", "epochs": 1, "timestep": 1393, "ep_reward": 698.680419921875, "reward": 0.590847373008728, "action": 1.5013489723205566}
{"mode": "train", "epochs": 1, "timestep": 1394, "ep_reward": 699.275634765625, "reward": 0.5951894521713257, "action": 0.5964693427085876}
{"mode": "train", "epochs": 1, "timestep": 1395, "ep_reward": 699.8624877929688, "reward": 0.5868598222732544, "action": 1.099428653717041}
{"mode": "train", "epochs": 1, "timestep": 1396, "ep_reward": 700.4275512695312, "reward": 0.5650672912597656, "action": 1.7550814151763916}
{"mode": "train", "epochs": 1, "timestep": 1397, "ep_reward": 700.9544677734375, "reward": 0.5269439220428467, "action": 1.6694735288619995}
{"mode": "train", "epochs": 1, "timestep": 1398, "ep_reward": 701.4293823242188, "reward": 0.4749431014060974, "action": 0.5704840421676636}
{"mode": "train", "epochs": 1, "timestep": 1399, "ep_reward": 701.8486328125, "reward": 0.41924136877059937, "action": 0.6330461502075195}
{"mode": "train", "epochs": 1, "timestep": 1400, "ep_reward": 702.20703125, "reward": 0.35838913917541504, "action": 0.5797317624092102}
{"mode": "train", "epochs": 1, "timestep": 1401, "ep_reward": 702.569091796875, "reward": 0.36203819513320923, "action": 0.7879023551940918}
{"mode": "train", "epochs": 1, "timestep": 1402, "ep_reward": 702.9846801757812, "reward": 0.41558802127838135, "action": 1.5128841400146484}
{"mode": "train", "epochs": 1, "timestep": 1403, "ep_reward": 703.4520263671875, "reward": 0.4673680067062378, "action": 1.6742658615112305}
{"mode": "train", "epochs": 1, "timestep": 1404, "ep_reward": 703.9711303710938, "reward": 0.5190848112106323, "action": 0.9456222057342529}
{"mode": "train", "epochs": 1, "timestep": 1405, "ep_reward": 704.5428466796875, "reward": 0.5716902017593384, "action": 0.8609051704406738}
{"mode": "train", "epochs": 1, "timestep": 1406, "ep_reward": 705.1619873046875, "reward": 0.6191112995147705, "action": 1.685262680053711}
{"mode": "train", "epochs": 1, "timestep": 1407, "ep_reward": 705.8200073242188, "reward": 0.6580285429954529, "action": 1.2285734415054321}
{"mode": "train", "epochs": 1, "timestep": 1408, "ep_reward": 706.5118408203125, "reward": 0.691828727722168, "action": 0.38107532262802124}
{"mode": "train", "epochs": 1, "timestep": 1409, "ep_reward": 707.2295532226562, "reward": 0.7177180051803589, "action": 0.6220748424530029}
{"mode": "train", "epochs": 1, "timestep": 1410, "ep_reward": 707.9614868164062, "reward": 0.7319252490997314, "action": 0.22644764184951782}
{"mode": "train", "epochs": 1, "timestep": 1411, "ep_reward": 708.6954345703125, "reward": 0.7339747548103333, "action": 1.49118173122406}
{"mode": "train", "epochs": 1, "timestep": 1412, "ep_reward": 709.4224243164062, "reward": 0.726960301399231, "action": 0.8296610713005066}
{"mode": "train", "epochs": 1, "timestep": 1413, "ep_reward": 710.1317749023438, "reward": 0.7093296647071838, "action": 0.7886292934417725}
{"mode": "train", "epochs": 1, "timestep": 1414, "ep_reward": 710.812744140625, "reward": 0.6809787750244141, "action": 1.3974583148956299}
{"mode": "train", "epochs": 1, "timestep": 1415, "ep_reward": 711.4588012695312, "reward": 0.6460694074630737, "action": 1.2986832857131958}
{"mode": "train", "epochs": 1, "timestep": 1416, "ep_reward": 712.0623779296875, "reward": 0.603579044342041, "action": 0.5316434502601624}
{"mode": "train", "epochs": 1, "timestep": 1417, "ep_reward": 712.6115112304688, "reward": 0.5491421222686768, "action": 1.7466003894805908}
{"mode": "train", "epochs": 1, "timestep": 1418, "ep_reward": 713.109130859375, "reward": 0.4976232051849365, "action": 0.9712228178977966}
{"mode": "train", "epochs": 1, "timestep": 1419, "ep_reward": 713.5481567382812, "reward": 0.43902575969696045, "action": 1.0712968111038208}
{"mode": "train", "epochs": 1, "timestep": 1420, "ep_reward": 713.928955078125, "reward": 0.3808082342147827, "action": -0.19115686416625977}
{"mode": "train", "epochs": 1, "timestep": 1421, "ep_reward": 714.2529296875, "reward": 0.3239452838897705, "action": 0.48677098751068115}
{"mode": "train", "epochs": 1, "timestep": 1422, "ep_reward": 714.6396484375, "reward": 0.3867388963699341, "action": 1.0252102613449097}
{"mode": "train", "epochs": 1, "timestep": 1423, "ep_reward": 715.0885009765625, "reward": 0.4488266706466675, "action": 0.2219894528388977}
{"mode": "train", "epochs": 1, "timestep": 1424, "ep_reward": 715.5908813476562, "reward": 0.5023671984672546, "action": 0.16303741931915283}
{"mode": "train", "epochs": 1, "timestep": 1425, "ep_reward": 716.1404418945312, "reward": 0.5495548844337463, "action": 1.6135635375976562}
{"mode": "train", "epochs": 1, "timestep": 1426, "ep_reward": 716.7308959960938, "reward": 0.5904487371444702, "action": 0.691230297088623}
{"mode": "train", "epochs": 1, "timestep": 1427, "ep_reward": 717.3468017578125, "reward": 0.6159119009971619, "action": 0.35357993841171265}
{"mode": "train", "epochs": 1, "timestep": 1428, "ep_reward": 717.9759521484375, "reward": 0.6291755437850952, "action": -0.17827284336090088}
{"mode": "train", "epochs": 1, "timestep": 1429, "ep_reward": 718.6077880859375, "reward": 0.6318415403366089, "action": 0.4527099132537842}
{"mode": "train", "epochs": 1, "timestep": 1430, "ep_reward": 719.23046875, "reward": 0.6226617097854614, "action": 1.4193792343139648}
{"mode": "train", "epochs": 1, "timestep": 1431, "ep_reward": 719.8275756835938, "reward": 0.5971295833587646, "action": 0.43736350536346436}
{"mode": "train", "epochs": 1, "timestep": 1432, "ep_reward": 720.3885498046875, "reward": 0.5609546303749084, "action": 0.5361912250518799}
{"mode": "train", "epochs": 1, "timestep": 1433, "ep_reward": 720.90234375, "reward": 0.5138124823570251, "action": -0.20347589254379272}
{"mode": "train", "epochs": 1, "timestep": 1434, "ep_reward": 721.365478515625, "reward": 0.4631163477897644, "action": 0.916648805141449}
{"mode": "train", "epochs": 1, "timestep": 1435, "ep_reward": 721.765380859375, "reward": 0.39987969398498535, "action": 0.6015496850013733}
{"mode": "train", "epochs": 1, "timestep": 1436, "ep_reward": 722.0992431640625, "reward": 0.3338906168937683, "action": 1.2486714124679565}
{"mode": "train", "epochs": 1, "timestep": 1437, "ep_reward": 722.4702758789062, "reward": 0.37102949619293213, "action": 1.4083545207977295}
{"mode": "train", "epochs": 1, "timestep": 1438, "ep_reward": 722.8981323242188, "reward": 0.42785000801086426, "action": 0.6744341254234314}
{"mode": "train", "epochs": 1, "timestep": 1439, "ep_reward": 723.3866577148438, "reward": 0.4885043501853943, "action": 0.9470676779747009}
{"mode": "train", "epochs": 1, "timestep": 1440, "ep_reward": 723.9320068359375, "reward": 0.5453372001647949, "action": 1.0956830978393555}
{"mode": "train", "epochs": 1, "timestep": 1441, "ep_reward": 724.5294799804688, "reward": 0.5974709987640381, "action": 0.5239483118057251}
{"mode": "train", "epochs": 1, "timestep": 1442, "ep_reward": 725.1744995117188, "reward": 0.6450475454330444, "action": 0.6033207178115845}
{"mode": "train", "epochs": 1, "timestep": 1443, "ep_reward": 725.8574829101562, "reward": 0.6829897165298462, "action": 1.5181396007537842}
{"mode": "train", "epochs": 1, "timestep": 1444, "ep_reward": 726.56787109375, "reward": 0.7103633880615234, "action": 1.1378087997436523}
{"mode": "train", "epochs": 1, "timestep": 1445, "ep_reward": 727.2980346679688, "reward": 0.7301450967788696, "action": 1.1586421728134155}
{"mode": "train", "epochs": 1, "timestep": 1446, "ep_reward": 728.0386962890625, "reward": 0.7406783103942871, "action": 1.3945080041885376}
{"mode": "train", "epochs": 1, "timestep": 1447, "ep_reward": 728.7810668945312, "reward": 0.7423880100250244, "action": 1.0481337308883667}
{"mode": "train", "epochs": 1, "timestep": 1448, "ep_reward": 729.515625, "reward": 0.734533429145813, "action": 0.5629301071166992}
{"mode": "train", "epochs": 1, "timestep": 1449, "ep_reward": 730.2303466796875, "reward": 0.714745044708252, "action": 1.1821167469024658}
{"mode": "train", "epochs": 1, "timestep": 1450, "ep_reward": 730.916748046875, "reward": 0.6863718032836914, "action": 1.2042258977890015}
{"mode": "train", "epochs": 1, "timestep": 1451, "ep_reward": 731.5661010742188, "reward": 0.6493272185325623, "action": 0.6660023927688599}
{"mode": "train", "epochs": 1, "timestep": 1452, "ep_reward": 732.166748046875, "reward": 0.600623369216919, "action": 0.5505954027175903}
{"mode": "train", "epochs": 1, "timestep": 1453, "ep_reward": 732.7091064453125, "reward": 0.5423539280891418, "action": 0.20248770713806152}
{"mode": "train", "epochs": 1, "timestep": 1454, "ep_reward": 733.18310546875, "reward": 0.4740021228790283, "action": 1.03737473487854}
{"mode": "train", "epochs": 1, "timestep": 1455, "ep_reward": 733.5908813476562, "reward": 0.407778263092041, "action": 1.7952557802200317}
{"mode": "train", "epochs": 1, "timestep": 1456, "ep_reward": 733.9403076171875, "reward": 0.349401593208313, "action": 1.3049825429916382}
{"mode": "train", "epochs": 1, "timestep": 1457, "ep_reward": 734.2857055664062, "reward": 0.34539830684661865, "action": 0.7469481229782104}
{"mode": "train", "epochs": 1, "timestep": 1458, "ep_reward": 734.6943969726562, "reward": 0.4087030291557312, "action": 0.8904746770858765}
{"mode": "train", "epochs": 1, "timestep": 1459, "ep_reward": 735.1627807617188, "reward": 0.468376100063324, "action": 0.711658775806427}
{"mode": "train", "epochs": 1, "timestep": 1460, "ep_reward": 735.683349609375, "reward": 0.5205751657485962, "action": 1.0311833620071411}
{"mode": "train", "epochs": 1, "timestep": 1461, "ep_reward": 736.2478637695312, "reward": 0.5645053386688232, "action": 1.0800191164016724}
{"mode": "train", "epochs": 1, "timestep": 1462, "ep_reward": 736.8444213867188, "reward": 0.59654700756073, "action": 1.1762595176696777}
{"mode": "train", "epochs": 1, "timestep": 1463, "ep_reward": 737.4594116210938, "reward": 0.6150192022323608, "action": 1.0793577432632446}
{"mode": "train", "epochs": 1, "timestep": 1464, "ep_reward": 738.0782470703125, "reward": 0.6188627481460571, "action": 1.2548108100891113}
{"mode": "train", "epochs": 1, "timestep": 1465, "ep_reward": 738.6857299804688, "reward": 0.6074723601341248, "action": 1.0097637176513672}
{"mode": "train", "epochs": 1, "timestep": 1466, "ep_reward": 739.2676391601562, "reward": 0.581899106502533, "action": 0.362216055393219}
{"mode": "train", "epochs": 1, "timestep": 1467, "ep_reward": 739.8140869140625, "reward": 0.5464669466018677, "action": 1.0019690990447998}
{"mode": "train", "epochs": 1, "timestep": 1468, "ep_reward": 740.3117065429688, "reward": 0.4976080060005188, "action": 1.1649779081344604}
{"mode": "train", "epochs": 1, "timestep": 1469, "ep_reward": 740.7492065429688, "reward": 0.43747931718826294, "action": 0.5266633033752441}
{"mode": "train", "epochs": 1, "timestep": 1470, "ep_reward": 741.1235961914062, "reward": 0.3743957281112671, "action": 0.9453831315040588}
{"mode": "train", "epochs": 1, "timestep": 1471, "ep_reward": 741.4618530273438, "reward": 0.33827275037765503, "action": 1.1302683353424072}
{"mode": "train", "epochs": 1, "timestep": 1472, "ep_reward": 741.8563232421875, "reward": 0.39447659254074097, "action": 0.7549751996994019}
{"mode": "train", "epochs": 1, "timestep": 1473, "ep_reward": 742.3099365234375, "reward": 0.4536401629447937, "action": 1.4776135683059692}
{"mode": "train", "epochs": 1, "timestep": 1474, "ep_reward": 742.819091796875, "reward": 0.5091546773910522, "action": 1.4479912519454956}
{"mode": "train", "epochs": 1, "timestep": 1475, "ep_reward": 743.3823852539062, "reward": 0.5632833242416382, "action": 1.6530821323394775}
{"mode": "train", "epochs": 1, "timestep": 1476, "ep_reward": 743.9957885742188, "reward": 0.6134192943572998, "action": 0.6178317070007324}
{"mode": "train", "epochs": 1, "timestep": 1477, "ep_reward": 744.6570434570312, "reward": 0.6612709760665894, "action": 0.2637559175491333}
{"mode": "train", "epochs": 1, "timestep": 1478, "ep_reward": 745.35693359375, "reward": 0.6998986005783081, "action": 0.2919078469276428}
{"mode": "train", "epochs": 1, "timestep": 1479, "ep_reward": 746.083251953125, "reward": 0.7263035774230957, "action": 1.4737874269485474}
{"mode": "train", "epochs": 1, "timestep": 1480, "ep_reward": 746.824462890625, "reward": 0.7412285208702087, "action": 0.4616582989692688}
{"mode": "train", "epochs": 1, "timestep": 1481, "ep_reward": 747.5706787109375, "reward": 0.746235728263855, "action": 1.1267108917236328}
{"mode": "train", "epochs": 1, "timestep": 1482, "ep_reward": 748.3114624023438, "reward": 0.7407746315002441, "action": 1.322770357131958}
{"mode": "train", "epochs": 1, "timestep": 1483, "ep_reward": 749.037841796875, "reward": 0.7264070510864258, "action": 0.9355584383010864}
{"mode": "train", "epochs": 1, "timestep": 1484, "ep_reward": 749.7391967773438, "reward": 0.701328456401825, "action": 1.2167630195617676}
{"mode": "train", "epochs": 1, "timestep": 1485, "ep_reward": 750.406982421875, "reward": 0.6678073406219482, "action": 0.44735896587371826}
{"mode": "train", "epochs": 1, "timestep": 1486, "ep_reward": 751.027587890625, "reward": 0.6206308603286743, "action": 1.8601367473602295}
{"mode": "train", "epochs": 1, "timestep": 1487, "ep_reward": 751.6015625, "reward": 0.5739583969116211, "action": 0.5512794256210327}
{"mode": "train", "epochs": 1, "timestep": 1488, "ep_reward": 752.1148071289062, "reward": 0.5132662653923035, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1489, "ep_reward": 752.574462890625, "reward": 0.4596360921859741, "action": 0.7424873113632202}
{"mode": "train", "epochs": 1, "timestep": 1490, "ep_reward": 752.9710693359375, "reward": 0.3966215252876282, "action": 1.021332859992981}
{"mode": "train", "epochs": 1, "timestep": 1491, "ep_reward": 753.3076782226562, "reward": 0.33662450313568115, "action": 0.7174848914146423}
{"mode": "train", "epochs": 1, "timestep": 1492, "ep_reward": 753.6735229492188, "reward": 0.36581629514694214, "action": 0.8530752658843994}
{"mode": "train", "epochs": 1, "timestep": 1493, "ep_reward": 754.1008911132812, "reward": 0.42736685276031494, "action": 0.8408766388893127}
{"mode": "train", "epochs": 1, "timestep": 1494, "ep_reward": 754.5845947265625, "reward": 0.4836810827255249, "action": 1.3192925453186035}
{"mode": "train", "epochs": 1, "timestep": 1495, "ep_reward": 755.1177978515625, "reward": 0.5331923961639404, "action": 1.7071740627288818}
{"mode": "train", "epochs": 1, "timestep": 1496, "ep_reward": 755.6892700195312, "reward": 0.57145094871521, "action": 0.24015653133392334}
{"mode": "train", "epochs": 1, "timestep": 1497, "ep_reward": 756.2844848632812, "reward": 0.595215380191803, "action": 0.4780557155609131}
{"mode": "train", "epochs": 1, "timestep": 1498, "ep_reward": 756.8933715820312, "reward": 0.6088740229606628, "action": 0.552639365196228}
{"mode": "train", "epochs": 1, "timestep": 1499, "ep_reward": 757.5042114257812, "reward": 0.6108432412147522, "action": 1.4482899904251099}
{"mode": "train", "epochs": 1, "timestep": 1500, "ep_reward": 758.1021118164062, "reward": 0.5978862643241882, "action": 1.306269645690918}
{"mode": "train", "epochs": 1, "timestep": 1501, "ep_reward": 758.671875, "reward": 0.5697560906410217, "action": 1.1541354656219482}
{"mode": "train", "epochs": 1, "timestep": 1502, "ep_reward": 759.2001342773438, "reward": 0.5282458066940308, "action": 0.87952721118927}
{"mode": "train", "epochs": 1, "timestep": 1503, "ep_reward": 759.676513671875, "reward": 0.4763806462287903, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1504, "ep_reward": 760.0838012695312, "reward": 0.40727120637893677, "action": 1.50778329372406}
{"mode": "train", "epochs": 1, "timestep": 1505, "ep_reward": 760.4155883789062, "reward": 0.33181679248809814, "action": 1.538413405418396}
{"mode": "train", "epochs": 1, "timestep": 1506, "ep_reward": 760.7752685546875, "reward": 0.3596767783164978, "action": 1.5350103378295898}
{"mode": "train", "epochs": 1, "timestep": 1507, "ep_reward": 761.1953125, "reward": 0.4200518727302551, "action": 1.0863758325576782}
{"mode": "train", "epochs": 1, "timestep": 1508, "ep_reward": 761.6793212890625, "reward": 0.48399943113327026, "action": 0.6582590937614441}
{"mode": "train", "epochs": 1, "timestep": 1509, "ep_reward": 762.2269897460938, "reward": 0.5476976633071899, "action": 1.3033465147018433}
{"mode": "train", "epochs": 1, "timestep": 1510, "ep_reward": 762.8306884765625, "reward": 0.603705644607544, "action": 0.8873006701469421}
{"mode": "train", "epochs": 1, "timestep": 1511, "ep_reward": 763.4859008789062, "reward": 0.655237078666687, "action": 0.5528780221939087}
{"mode": "train", "epochs": 1, "timestep": 1512, "ep_reward": 764.1845703125, "reward": 0.6986508965492249, "action": 0.9982068538665771}
{"mode": "train", "epochs": 1, "timestep": 1513, "ep_reward": 764.9151000976562, "reward": 0.7305600643157959, "action": 1.105852484703064}
{"mode": "train", "epochs": 1, "timestep": 1514, "ep_reward": 765.6674194335938, "reward": 0.7523231506347656, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1515, "ep_reward": 766.4325561523438, "reward": 0.7651406526565552, "action": 1.233677625656128}
{"mode": "train", "epochs": 1, "timestep": 1516, "ep_reward": 767.2024536132812, "reward": 0.769869327545166, "action": 1.451109528541565}
{"mode": "train", "epochs": 1, "timestep": 1517, "ep_reward": 767.9680786132812, "reward": 0.7656345367431641, "action": 0.7812871932983398}
{"mode": "train", "epochs": 1, "timestep": 1518, "ep_reward": 768.7182006835938, "reward": 0.7501257061958313, "action": 0.45934396982192993}
{"mode": "train", "epochs": 1, "timestep": 1519, "ep_reward": 769.4396362304688, "reward": 0.7214430570602417, "action": 1.1120631694793701}
{"mode": "train", "epochs": 1, "timestep": 1520, "ep_reward": 770.1234741210938, "reward": 0.6838096380233765, "action": 1.2710673809051514}
{"mode": "train", "epochs": 1, "timestep": 1521, "ep_reward": 770.7611083984375, "reward": 0.6376272439956665, "action": 1.2171722650527954}
{"mode": "train", "epochs": 1, "timestep": 1522, "ep_reward": 771.3441772460938, "reward": 0.5830680131912231, "action": 1.1334173679351807}
{"mode": "train", "epochs": 1, "timestep": 1523, "ep_reward": 771.8656005859375, "reward": 0.5214248895645142, "action": 0.6102209091186523}
{"mode": "train", "epochs": 1, "timestep": 1524, "ep_reward": 772.3162231445312, "reward": 0.4506147503852844, "action": 1.3454631567001343}
{"mode": "train", "epochs": 1, "timestep": 1525, "ep_reward": 772.7001342773438, "reward": 0.38389307260513306, "action": 0.5525562167167664}
{"mode": "train", "epochs": 1, "timestep": 1526, "ep_reward": 773.0120239257812, "reward": 0.31191152334213257, "action": 1.2040952444076538}
{"mode": "train", "epochs": 1, "timestep": 1527, "ep_reward": 773.375244140625, "reward": 0.36324870586395264, "action": 0.9822493195533752}
{"mode": "train", "epochs": 1, "timestep": 1528, "ep_reward": 773.807861328125, "reward": 0.4326102137565613, "action": 0.6543929576873779}
{"mode": "train", "epochs": 1, "timestep": 1529, "ep_reward": 774.3026733398438, "reward": 0.49481910467147827, "action": 1.617430329322815}
{"mode": "train", "epochs": 1, "timestep": 1530, "ep_reward": 774.8544921875, "reward": 0.5517919063568115, "action": 0.19648414850234985}
{"mode": "train", "epochs": 1, "timestep": 1531, "ep_reward": 775.447509765625, "reward": 0.5930254459381104, "action": 0.9137524366378784}
{"mode": "train", "epochs": 1, "timestep": 1532, "ep_reward": 776.072265625, "reward": 0.624773383140564, "action": 0.5682500600814819}
{"mode": "train", "epochs": 1, "timestep": 1533, "ep_reward": 776.7150268554688, "reward": 0.642756462097168, "action": 0.5236507654190063}
{"mode": "train", "epochs": 1, "timestep": 1534, "ep_reward": 777.3626098632812, "reward": 0.6475748419761658, "action": 0.12019532918930054}
{"mode": "train", "epochs": 1, "timestep": 1535, "ep_reward": 778.002685546875, "reward": 0.6400663256645203, "action": 1.6553006172180176}
{"mode": "train", "epochs": 1, "timestep": 1536, "ep_reward": 778.6172485351562, "reward": 0.6145673990249634, "action": 1.7530416250228882}
{"mode": "train", "epochs": 1, "timestep": 1537, "ep_reward": 779.1875610351562, "reward": 0.5703321099281311, "action": 1.2960699796676636}
{"mode": "train", "epochs": 1, "timestep": 1538, "ep_reward": 779.6995239257812, "reward": 0.511959433555603, "action": 1.2100521326065063}
{"mode": "train", "epochs": 1, "timestep": 1539, "ep_reward": 780.1410522460938, "reward": 0.44153469800949097, "action": 0.10015219449996948}
{"mode": "train", "epochs": 1, "timestep": 1540, "ep_reward": 780.5128784179688, "reward": 0.3718205690383911, "action": 0.7629393339157104}
{"mode": "train", "epochs": 1, "timestep": 1541, "ep_reward": 780.8297119140625, "reward": 0.3168426752090454, "action": 1.0305266380310059}
{"mode": "train", "epochs": 1, "timestep": 1542, "ep_reward": 781.2095947265625, "reward": 0.3799058794975281, "action": 0.3381938934326172}
{"mode": "train", "epochs": 1, "timestep": 1543, "ep_reward": 781.6571655273438, "reward": 0.4475996494293213, "action": 1.1105033159255981}
{"mode": "train", "epochs": 1, "timestep": 1544, "ep_reward": 782.1670532226562, "reward": 0.5099048614501953, "action": 0.8470396995544434}
{"mode": "train", "epochs": 1, "timestep": 1545, "ep_reward": 782.737548828125, "reward": 0.5704874396324158, "action": 0.3665456771850586}
{"mode": "train", "epochs": 1, "timestep": 1546, "ep_reward": 783.3641357421875, "reward": 0.626575231552124, "action": 0.861125111579895}
{"mode": "train", "epochs": 1, "timestep": 1547, "ep_reward": 784.0360717773438, "reward": 0.6719540953636169, "action": 1.419135332107544}
{"mode": "train", "epochs": 1, "timestep": 1548, "ep_reward": 784.7435913085938, "reward": 0.7075472474098206, "action": 0.5908173322677612}
{"mode": "train", "epochs": 1, "timestep": 1549, "ep_reward": 785.4790649414062, "reward": 0.7354992628097534, "action": 1.4877957105636597}
{"mode": "train", "epochs": 1, "timestep": 1550, "ep_reward": 786.2315673828125, "reward": 0.7524739503860474, "action": 0.050866127014160156}
{"mode": "train", "epochs": 1, "timestep": 1551, "ep_reward": 786.9906005859375, "reward": 0.7590034008026123, "action": 0.5422495603561401}
{"mode": "train", "epochs": 1, "timestep": 1552, "ep_reward": 787.7431640625, "reward": 0.7525870203971863, "action": 0.7317652106285095}
{"mode": "train", "epochs": 1, "timestep": 1553, "ep_reward": 788.477783203125, "reward": 0.7346031665802002, "action": 0.8067065477371216}
{"mode": "train", "epochs": 1, "timestep": 1554, "ep_reward": 789.1831665039062, "reward": 0.7054132223129272, "action": 1.2717571258544922}
{"mode": "train", "epochs": 1, "timestep": 1555, "ep_reward": 789.851318359375, "reward": 0.6681398749351501, "action": 0.5716036558151245}
{"mode": "train", "epochs": 1, "timestep": 1556, "ep_reward": 790.4688720703125, "reward": 0.6175450086593628, "action": 0.17566817998886108}
{"mode": "train", "epochs": 1, "timestep": 1557, "ep_reward": 791.0225219726562, "reward": 0.5536706447601318, "action": 1.2823705673217773}
{"mode": "train", "epochs": 1, "timestep": 1558, "ep_reward": 791.5127563476562, "reward": 0.49024808406829834, "action": 0.7007566690444946}
{"mode": "train", "epochs": 1, "timestep": 1559, "ep_reward": 791.9317626953125, "reward": 0.4189761281013489, "action": 0.2791048288345337}
{"mode": "train", "epochs": 1, "timestep": 1560, "ep_reward": 792.27392578125, "reward": 0.3421474099159241, "action": 1.6882835626602173}
{"mode": "train", "epochs": 1, "timestep": 1561, "ep_reward": 792.6002807617188, "reward": 0.32632654905319214, "action": 1.257925033569336}
{"mode": "train", "epochs": 1, "timestep": 1562, "ep_reward": 792.9991455078125, "reward": 0.39886772632598877, "action": 1.2283544540405273}
{"mode": "train", "epochs": 1, "timestep": 1563, "ep_reward": 793.4649658203125, "reward": 0.4657931327819824, "action": 0.605431318283081}
{"mode": "train", "epochs": 1, "timestep": 1564, "ep_reward": 793.9877319335938, "reward": 0.5227651596069336, "action": 0.5785043239593506}
{"mode": "train", "epochs": 1, "timestep": 1565, "ep_reward": 794.5587768554688, "reward": 0.571036696434021, "action": 1.686227560043335}
{"mode": "train", "epochs": 1, "timestep": 1566, "ep_reward": 795.168701171875, "reward": 0.6099033951759338, "action": 0.47216737270355225}
{"mode": "train", "epochs": 1, "timestep": 1567, "ep_reward": 795.801025390625, "reward": 0.6323406100273132, "action": 0.9499090909957886}
{"mode": "train", "epochs": 1, "timestep": 1568, "ep_reward": 796.4425048828125, "reward": 0.64149010181427, "action": 1.8283989429473877}
{"mode": "train", "epochs": 1, "timestep": 1569, "ep_reward": 797.0757446289062, "reward": 0.6332293152809143, "action": 0.7802250385284424}
{"mode": "train", "epochs": 1, "timestep": 1570, "ep_reward": 797.685791015625, "reward": 0.6100559830665588, "action": 1.400448203086853}
{"mode": "train", "epochs": 1, "timestep": 1571, "ep_reward": 798.2555541992188, "reward": 0.5697746872901917, "action": 1.494822382926941}
{"mode": "train", "epochs": 1, "timestep": 1572, "ep_reward": 798.7691650390625, "reward": 0.5135857462882996, "action": 0.3794752359390259}
{"mode": "train", "epochs": 1, "timestep": 1573, "ep_reward": 799.2217407226562, "reward": 0.4525623917579651, "action": 0.4769454002380371}
{"mode": "train", "epochs": 1, "timestep": 1574, "ep_reward": 799.6063232421875, "reward": 0.38456428050994873, "action": 1.8475196361541748}
{"mode": "train", "epochs": 1, "timestep": 1575, "ep_reward": 799.9173583984375, "reward": 0.3110416531562805, "action": 1.0104866027832031}
{"mode": "train", "epochs": 1, "timestep": 1576, "ep_reward": 800.2914428710938, "reward": 0.374109148979187, "action": -0.4848915934562683}
{"mode": "train", "epochs": 1, "timestep": 1577, "ep_reward": 800.7366943359375, "reward": 0.44522392749786377, "action": 0.20768433809280396}
{"mode": "train", "epochs": 1, "timestep": 1578, "ep_reward": 801.24560546875, "reward": 0.5089014768600464, "action": 0.8812152147293091}
{"mode": "train", "epochs": 1, "timestep": 1579, "ep_reward": 801.810791015625, "reward": 0.5652159452438354, "action": 0.7835224270820618}
{"mode": "train", "epochs": 1, "timestep": 1580, "ep_reward": 802.42724609375, "reward": 0.6164517998695374, "action": 0.7524320483207703}
{"mode": "train", "epochs": 1, "timestep": 1581, "ep_reward": 803.0872802734375, "reward": 0.6600056886672974, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1582, "ep_reward": 803.780517578125, "reward": 0.6932345628738403, "action": 1.1703898906707764}
{"mode": "train", "epochs": 1, "timestep": 1583, "ep_reward": 804.5017700195312, "reward": 0.7212481498718262, "action": 1.651407241821289}
{"mode": "train", "epochs": 1, "timestep": 1584, "ep_reward": 805.2423095703125, "reward": 0.7405251264572144, "action": 0.14527028799057007}
{"mode": "train", "epochs": 1, "timestep": 1585, "ep_reward": 805.9927978515625, "reward": 0.7504713535308838, "action": 0.7106019258499146}
{"mode": "train", "epochs": 1, "timestep": 1586, "ep_reward": 806.7407836914062, "reward": 0.7479760050773621, "action": 1.6096441745758057}
{"mode": "train", "epochs": 1, "timestep": 1587, "ep_reward": 807.4779052734375, "reward": 0.737123966217041, "action": 1.6986799240112305}
{"mode": "train", "epochs": 1, "timestep": 1588, "ep_reward": 808.1966552734375, "reward": 0.7187417149543762, "action": 1.401160478591919}
{"mode": "train", "epochs": 1, "timestep": 1589, "ep_reward": 808.8880615234375, "reward": 0.691428005695343, "action": 1.1092808246612549}
{"mode": "train", "epochs": 1, "timestep": 1590, "ep_reward": 809.542236328125, "reward": 0.6541473865509033, "action": 1.4750638008117676}
{"mode": "train", "epochs": 1, "timestep": 1591, "ep_reward": 810.153076171875, "reward": 0.610825777053833, "action": 1.5633835792541504}
{"mode": "train", "epochs": 1, "timestep": 1592, "ep_reward": 810.7154541015625, "reward": 0.5623975992202759, "action": 0.7070119380950928}
{"mode": "train", "epochs": 1, "timestep": 1593, "ep_reward": 811.2186889648438, "reward": 0.5032492876052856, "action": 0.8002045154571533}
{"mode": "train", "epochs": 1, "timestep": 1594, "ep_reward": 811.6590576171875, "reward": 0.44037771224975586, "action": 0.6603469848632812}
{"mode": "train", "epochs": 1, "timestep": 1595, "ep_reward": 812.0338134765625, "reward": 0.37473028898239136, "action": 1.460487723350525}
{"mode": "train", "epochs": 1, "timestep": 1596, "ep_reward": 812.3541259765625, "reward": 0.32030659914016724, "action": 1.2654645442962646}
{"mode": "train", "epochs": 1, "timestep": 1597, "ep_reward": 812.739501953125, "reward": 0.3853600025177002, "action": 1.539771318435669}
{"mode": "train", "epochs": 1, "timestep": 1598, "ep_reward": 813.1858520507812, "reward": 0.4463590383529663, "action": 1.0105180740356445}
{"mode": "train", "epochs": 1, "timestep": 1599, "ep_reward": 813.6836547851562, "reward": 0.49782711267471313, "action": 1.2869781255722046}
{"mode": "train", "epochs": 1, "timestep": 1600, "ep_reward": 814.224609375, "reward": 0.5409765839576721, "action": 0.30530136823654175}
{"mode": "train", "epochs": 1, "timestep": 1601, "ep_reward": 814.7965698242188, "reward": 0.5719395875930786, "action": 1.8006629943847656}
{"mode": "train", "epochs": 1, "timestep": 1602, "ep_reward": 815.3895874023438, "reward": 0.5929949283599854, "action": 0.9413695931434631}
{"mode": "train", "epochs": 1, "timestep": 1603, "ep_reward": 815.9886474609375, "reward": 0.5990873575210571, "action": 0.5278075933456421}
{"mode": "train", "epochs": 1, "timestep": 1604, "ep_reward": 816.5819702148438, "reward": 0.5933166742324829, "action": 0.7471216917037964}
{"mode": "train", "epochs": 1, "timestep": 1605, "ep_reward": 817.1574096679688, "reward": 0.5754610300064087, "action": 1.048548698425293}
{"mode": "train", "epochs": 1, "timestep": 1606, "ep_reward": 817.7017211914062, "reward": 0.5443407893180847, "action": 1.7896536588668823}
{"mode": "train", "epochs": 1, "timestep": 1607, "ep_reward": 818.1985473632812, "reward": 0.49684637784957886, "action": 1.4930462837219238}
{"mode": "train", "epochs": 1, "timestep": 1608, "ep_reward": 818.6365966796875, "reward": 0.43807393312454224, "action": 0.5550320148468018}
{"mode": "train", "epochs": 1, "timestep": 1609, "ep_reward": 819.013916015625, "reward": 0.37729328870773315, "action": 1.1072887182235718}
{"mode": "train", "epochs": 1, "timestep": 1610, "ep_reward": 819.3546752929688, "reward": 0.34076565504074097, "action": 1.78493070602417}
{"mode": "train", "epochs": 1, "timestep": 1611, "ep_reward": 819.7481079101562, "reward": 0.393444299697876, "action": 1.2183252573013306}
{"mode": "train", "epochs": 1, "timestep": 1612, "ep_reward": 820.1994018554688, "reward": 0.4513240456581116, "action": 1.142530918121338}
{"mode": "train", "epochs": 1, "timestep": 1613, "ep_reward": 820.7088623046875, "reward": 0.5094563961029053, "action": 1.1801364421844482}
{"mode": "train", "epochs": 1, "timestep": 1614, "ep_reward": 821.27392578125, "reward": 0.5650501251220703, "action": 1.248673677444458}
{"mode": "train", "epochs": 1, "timestep": 1615, "ep_reward": 821.8899536132812, "reward": 0.6160446405410767, "action": 1.1241382360458374}
{"mode": "train", "epochs": 1, "timestep": 1616, "ep_reward": 822.55126953125, "reward": 0.6613174080848694, "action": 0.7865839004516602}
{"mode": "train", "epochs": 1, "timestep": 1617, "ep_reward": 823.25048828125, "reward": 0.6992425322532654, "action": 0.4672940969467163}
{"mode": "train", "epochs": 1, "timestep": 1618, "ep_reward": 823.9776611328125, "reward": 0.7271841764450073, "action": 1.316765546798706}
{"mode": "train", "epochs": 1, "timestep": 1619, "ep_reward": 824.7213745117188, "reward": 0.743730902671814, "action": 1.5124218463897705}
{"mode": "train", "epochs": 1, "timestep": 1620, "ep_reward": 825.4732055664062, "reward": 0.751820981502533, "action": 0.4613535404205322}
{"mode": "train", "epochs": 1, "timestep": 1621, "ep_reward": 826.222412109375, "reward": 0.7491801381111145, "action": 0.601752758026123}
{"mode": "train", "epochs": 1, "timestep": 1622, "ep_reward": 826.9569091796875, "reward": 0.7345066070556641, "action": 1.0548381805419922}
{"mode": "train", "epochs": 1, "timestep": 1623, "ep_reward": 827.6669311523438, "reward": 0.7100151181221008, "action": 1.1496882438659668}
{"mode": "train", "epochs": 1, "timestep": 1624, "ep_reward": 828.3432006835938, "reward": 0.6762523651123047, "action": 0.12959694862365723}
{"mode": "train", "epochs": 1, "timestep": 1625, "ep_reward": 828.9699096679688, "reward": 0.6266915798187256, "action": 1.106619119644165}
{"mode": "train", "epochs": 1, "timestep": 1626, "ep_reward": 829.5426025390625, "reward": 0.5726801753044128, "action": 0.5114189386367798}
{"mode": "train", "epochs": 1, "timestep": 1627, "ep_reward": 830.0499877929688, "reward": 0.5073993802070618, "action": 0.5818283557891846}
{"mode": "train", "epochs": 1, "timestep": 1628, "ep_reward": 830.48681640625, "reward": 0.43684685230255127, "action": 0.04561668634414673}
{"mode": "train", "epochs": 1, "timestep": 1629, "ep_reward": 830.8453369140625, "reward": 0.3585458993911743, "action": 1.099854588508606}
{"mode": "train", "epochs": 1, "timestep": 1630, "ep_reward": 831.1527709960938, "reward": 0.30746132135391235, "action": 0.7248989939689636}
{"mode": "train", "epochs": 1, "timestep": 1631, "ep_reward": 831.5330810546875, "reward": 0.3802875280380249, "action": 0.9123247265815735}
{"mode": "train", "epochs": 1, "timestep": 1632, "ep_reward": 831.98388671875, "reward": 0.4507984519004822, "action": 0.2220035195350647}
{"mode": "train", "epochs": 1, "timestep": 1633, "ep_reward": 832.496337890625, "reward": 0.5124281048774719, "action": 1.2593473196029663}
{"mode": "train", "epochs": 1, "timestep": 1634, "ep_reward": 833.0660400390625, "reward": 0.569717526435852, "action": 1.408060908317566}
{"mode": "train", "epochs": 1, "timestep": 1635, "ep_reward": 833.6798706054688, "reward": 0.6138235330581665, "action": 0.8558740019798279}
{"mode": "train", "epochs": 1, "timestep": 1636, "ep_reward": 834.3218383789062, "reward": 0.6419639587402344, "action": 0.9078978896141052}
{"mode": "train", "epochs": 1, "timestep": 1637, "ep_reward": 834.9771118164062, "reward": 0.6552994251251221, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1638, "ep_reward": 835.6277465820312, "reward": 0.6506391167640686, "action": 0.890576958656311}
{"mode": "train", "epochs": 1, "timestep": 1639, "ep_reward": 836.2572021484375, "reward": 0.6294251680374146, "action": 1.5594053268432617}
{"mode": "train", "epochs": 1, "timestep": 1640, "ep_reward": 836.846923828125, "reward": 0.5897269248962402, "action": 0.2722664475440979}
{"mode": "train", "epochs": 1, "timestep": 1641, "ep_reward": 837.38818359375, "reward": 0.5412334203720093, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1642, "ep_reward": 837.8584594726562, "reward": 0.47027790546417236, "action": 1.0469979047775269}
{"mode": "train", "epochs": 1, "timestep": 1643, "ep_reward": 838.2517700195312, "reward": 0.3933148980140686, "action": 0.745640218257904}
{"mode": "train", "epochs": 1, "timestep": 1644, "ep_reward": 838.5645751953125, "reward": 0.31278741359710693, "action": 1.2452565431594849}
{"mode": "train", "epochs": 1, "timestep": 1645, "ep_reward": 838.9166870117188, "reward": 0.3521280884742737, "action": -0.02552497386932373}
{"mode": "train", "epochs": 1, "timestep": 1646, "ep_reward": 839.3418579101562, "reward": 0.4251623749732971, "action": 0.6229159235954285}
{"mode": "train", "epochs": 1, "timestep": 1647, "ep_reward": 839.8344116210938, "reward": 0.49256545305252075, "action": 1.8153151273727417}
{"mode": "train", "epochs": 1, "timestep": 1648, "ep_reward": 840.3864135742188, "reward": 0.5519905090332031, "action": 0.43294650316238403}
{"mode": "train", "epochs": 1, "timestep": 1649, "ep_reward": 841.0003662109375, "reward": 0.613925576210022, "action": 0.5581976175308228}
{"mode": "train", "epochs": 1, "timestep": 1650, "ep_reward": 841.666748046875, "reward": 0.6664049625396729, "action": 0.14034658670425415}
{"mode": "train", "epochs": 1, "timestep": 1651, "ep_reward": 842.3759765625, "reward": 0.7092492580413818, "action": 0.929721474647522}
{"mode": "train", "epochs": 1, "timestep": 1652, "ep_reward": 843.1144409179688, "reward": 0.7384624481201172, "action": 1.6580228805541992}
{"mode": "train", "epochs": 1, "timestep": 1653, "ep_reward": 843.871826171875, "reward": 0.7574095726013184, "action": 1.946397304534912}
{"mode": "train", "epochs": 1, "timestep": 1654, "ep_reward": 844.6406860351562, "reward": 0.7688583135604858, "action": 1.0635640621185303}
{"mode": "train", "epochs": 1, "timestep": 1655, "ep_reward": 845.412353515625, "reward": 0.7716946601867676, "action": 1.038619041442871}
{"mode": "train", "epochs": 1, "timestep": 1656, "ep_reward": 846.1765747070312, "reward": 0.7641985416412354, "action": 0.3574957251548767}
{"mode": "train", "epochs": 1, "timestep": 1657, "ep_reward": 846.919921875, "reward": 0.7433420419692993, "action": 1.4079684019088745}
{"mode": "train", "epochs": 1, "timestep": 1658, "ep_reward": 847.634521484375, "reward": 0.7145960330963135, "action": 1.294584035873413}
{"mode": "train", "epochs": 1, "timestep": 1659, "ep_reward": 848.310791015625, "reward": 0.676275372505188, "action": 0.8242995142936707}
{"mode": "train", "epochs": 1, "timestep": 1660, "ep_reward": 848.9365844726562, "reward": 0.6257825493812561, "action": 1.394452691078186}
{"mode": "train", "epochs": 1, "timestep": 1661, "ep_reward": 849.507080078125, "reward": 0.5704919695854187, "action": 0.9206397533416748}
{"mode": "train", "epochs": 1, "timestep": 1662, "ep_reward": 850.0128784179688, "reward": 0.5057884454727173, "action": 0.8640787601470947}
{"mode": "train", "epochs": 1, "timestep": 1663, "ep_reward": 850.4487915039062, "reward": 0.43590712547302246, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1664, "ep_reward": 850.8244018554688, "reward": 0.37562984228134155, "action": 1.1854846477508545}
{"mode": "train", "epochs": 1, "timestep": 1665, "ep_reward": 851.1368408203125, "reward": 0.31245607137680054, "action": 1.1241120100021362}
{"mode": "train", "epochs": 1, "timestep": 1666, "ep_reward": 851.5136108398438, "reward": 0.3767831325531006, "action": 1.6123961210250854}
{"mode": "train", "epochs": 1, "timestep": 1667, "ep_reward": 851.9569091796875, "reward": 0.443290650844574, "action": 1.5038622617721558}
{"mode": "train", "epochs": 1, "timestep": 1668, "ep_reward": 852.4577026367188, "reward": 0.5008071064949036, "action": 1.1590898036956787}
{"mode": "train", "epochs": 1, "timestep": 1669, "ep_reward": 853.0045776367188, "reward": 0.5468865633010864, "action": 1.027764916419983}
{"mode": "train", "epochs": 1, "timestep": 1670, "ep_reward": 853.5858154296875, "reward": 0.5812214016914368, "action": 1.5579439401626587}
{"mode": "train", "epochs": 1, "timestep": 1671, "ep_reward": 854.1884155273438, "reward": 0.6026053428649902, "action": 1.8132904767990112}
{"mode": "train", "epochs": 1, "timestep": 1672, "ep_reward": 854.7960815429688, "reward": 0.6076595783233643, "action": -0.48460114002227783}
{"mode": "train", "epochs": 1, "timestep": 1673, "ep_reward": 855.3982543945312, "reward": 0.6021703481674194, "action": 1.5649163722991943}
{"mode": "train", "epochs": 1, "timestep": 1674, "ep_reward": 855.9794311523438, "reward": 0.5811962485313416, "action": 1.8676632642745972}
{"mode": "train", "epochs": 1, "timestep": 1675, "ep_reward": 856.5222778320312, "reward": 0.5428361892700195, "action": 1.4129910469055176}
{"mode": "train", "epochs": 1, "timestep": 1676, "ep_reward": 857.0136108398438, "reward": 0.4913617968559265, "action": 1.725087285041809}
{"mode": "train", "epochs": 1, "timestep": 1677, "ep_reward": 857.4393310546875, "reward": 0.42571836709976196, "action": 1.9021857976913452}
{"mode": "train", "epochs": 1, "timestep": 1678, "ep_reward": 857.78759765625, "reward": 0.34829145669937134, "action": 1.7172999382019043}
{"mode": "train", "epochs": 1, "timestep": 1679, "ep_reward": 858.1304321289062, "reward": 0.34284693002700806, "action": 1.2348872423171997}
{"mode": "train", "epochs": 1, "timestep": 1680, "ep_reward": 858.5357055664062, "reward": 0.40528935194015503, "action": 0.772994875907898}
{"mode": "train", "epochs": 1, "timestep": 1681, "ep_reward": 859.0068359375, "reward": 0.47113388776779175, "action": 0.6568605899810791}
{"mode": "train", "epochs": 1, "timestep": 1682, "ep_reward": 859.5420532226562, "reward": 0.5352155566215515, "action": 0.9538016319274902}
{"mode": "train", "epochs": 1, "timestep": 1683, "ep_reward": 860.13525390625, "reward": 0.5932266712188721, "action": 0.6826953887939453}
{"mode": "train", "epochs": 1, "timestep": 1684, "ep_reward": 860.7808227539062, "reward": 0.6455976366996765, "action": 0.795142650604248}
{"mode": "train", "epochs": 1, "timestep": 1685, "ep_reward": 861.4694213867188, "reward": 0.6885960102081299, "action": 1.3723400831222534}
{"mode": "train", "epochs": 1, "timestep": 1686, "ep_reward": 862.190673828125, "reward": 0.7212294340133667, "action": 0.6283454895019531}
{"mode": "train", "epochs": 1, "timestep": 1687, "ep_reward": 862.9361572265625, "reward": 0.7455031871795654, "action": 1.4813796281814575}
{"mode": "train", "epochs": 1, "timestep": 1688, "ep_reward": 863.6949462890625, "reward": 0.7587900757789612, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1689, "ep_reward": 864.4595336914062, "reward": 0.7646065354347229, "action": 0.6363180875778198}
{"mode": "train", "epochs": 1, "timestep": 1690, "ep_reward": 865.2198486328125, "reward": 0.7602988481521606, "action": 0.4227750301361084}
{"mode": "train", "epochs": 1, "timestep": 1691, "ep_reward": 865.9629516601562, "reward": 0.7431155443191528, "action": 1.2352713346481323}
{"mode": "train", "epochs": 1, "timestep": 1692, "ep_reward": 866.6799926757812, "reward": 0.7170392870903015, "action": 0.2733426094055176}
{"mode": "train", "epochs": 1, "timestep": 1693, "ep_reward": 867.3557739257812, "reward": 0.6757999658584595, "action": 0.25335144996643066}
{"mode": "train", "epochs": 1, "timestep": 1694, "ep_reward": 867.97705078125, "reward": 0.6212546825408936, "action": 1.8917592763900757}
{"mode": "train", "epochs": 1, "timestep": 1695, "ep_reward": 868.54541015625, "reward": 0.568352997303009, "action": 1.630495548248291}
{"mode": "train", "epochs": 1, "timestep": 1696, "ep_reward": 869.0551147460938, "reward": 0.5096741318702698, "action": 1.7737860679626465}
{"mode": "train", "epochs": 1, "timestep": 1697, "ep_reward": 869.5054931640625, "reward": 0.45040321350097656, "action": 1.2016642093658447}
{"mode": "train", "epochs": 1, "timestep": 1698, "ep_reward": 869.892578125, "reward": 0.38707494735717773, "action": 0.7429574728012085}
{"mode": "train", "epochs": 1, "timestep": 1699, "ep_reward": 870.2141723632812, "reward": 0.32160162925720215, "action": 1.1869425773620605}
{"mode": "train", "epochs": 1, "timestep": 1700, "ep_reward": 870.5846557617188, "reward": 0.3704809546470642, "action": 0.6766164302825928}
{"mode": "train", "epochs": 1, "timestep": 1701, "ep_reward": 871.0182495117188, "reward": 0.4336191415786743, "action": 0.8921413421630859}
{"mode": "train", "epochs": 1, "timestep": 1702, "ep_reward": 871.5107421875, "reward": 0.4924716353416443, "action": 0.7004731893539429}
{"mode": "train", "epochs": 1, "timestep": 1703, "ep_reward": 872.053466796875, "reward": 0.542715847492218, "action": 1.1975629329681396}
{"mode": "train", "epochs": 1, "timestep": 1704, "ep_reward": 872.6373291015625, "reward": 0.5838323831558228, "action": 1.2429141998291016}
{"mode": "train", "epochs": 1, "timestep": 1705, "ep_reward": 873.248779296875, "reward": 0.611465573310852, "action": 1.00544273853302}
{"mode": "train", "epochs": 1, "timestep": 1706, "ep_reward": 873.8732299804688, "reward": 0.6244602799415588, "action": 1.130979061126709}
{"mode": "train", "epochs": 1, "timestep": 1707, "ep_reward": 874.4959716796875, "reward": 0.6227213740348816, "action": 0.4828779697418213}
{"mode": "train", "epochs": 1, "timestep": 1708, "ep_reward": 875.1040649414062, "reward": 0.6080706715583801, "action": 1.2821124792099}
{"mode": "train", "epochs": 1, "timestep": 1709, "ep_reward": 875.6818237304688, "reward": 0.5777715444564819, "action": -0.5892040133476257}
{"mode": "train", "epochs": 1, "timestep": 1710, "ep_reward": 876.2255859375, "reward": 0.543758749961853, "action": 1.049286127090454}
{"mode": "train", "epochs": 1, "timestep": 1711, "ep_reward": 876.7193603515625, "reward": 0.4937646985054016, "action": 0.5924795866012573}
{"mode": "train", "epochs": 1, "timestep": 1712, "ep_reward": 877.1563110351562, "reward": 0.43695181608200073, "action": 1.2481087446212769}
{"mode": "train", "epochs": 1, "timestep": 1713, "ep_reward": 877.5255126953125, "reward": 0.369174599647522, "action": 0.12169694900512695}
{"mode": "train", "epochs": 1, "timestep": 1714, "ep_reward": 877.8683471679688, "reward": 0.34282898902893066, "action": 1.5304827690124512}
{"mode": "train", "epochs": 1, "timestep": 1715, "ep_reward": 878.2648315429688, "reward": 0.39647942781448364, "action": 1.3814349174499512}
{"mode": "train", "epochs": 1, "timestep": 1716, "ep_reward": 878.7181396484375, "reward": 0.45333635807037354, "action": 0.7358678579330444}
{"mode": "train", "epochs": 1, "timestep": 1717, "ep_reward": 879.2307739257812, "reward": 0.5126630067825317, "action": 1.277195930480957}
{"mode": "train", "epochs": 1, "timestep": 1718, "ep_reward": 879.7972412109375, "reward": 0.5664970278739929, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1719, "ep_reward": 880.4115600585938, "reward": 0.614336371421814, "action": 1.4491866827011108}
{"mode": "train", "epochs": 1, "timestep": 1720, "ep_reward": 881.0714721679688, "reward": 0.659902811050415, "action": 0.0862116813659668}
{"mode": "train", "epochs": 1, "timestep": 1721, "ep_reward": 881.7723388671875, "reward": 0.7008668184280396, "action": 0.3474277853965759}
{"mode": "train", "epochs": 1, "timestep": 1722, "ep_reward": 882.5010986328125, "reward": 0.7287821769714355, "action": 0.9555879831314087}
{"mode": "train", "epochs": 1, "timestep": 1723, "ep_reward": 883.245849609375, "reward": 0.7447400689125061, "action": 0.8077957630157471}
{"mode": "train", "epochs": 1, "timestep": 1724, "ep_reward": 883.99609375, "reward": 0.7502371072769165, "action": 0.7853473424911499}
{"mode": "train", "epochs": 1, "timestep": 1725, "ep_reward": 884.7407836914062, "reward": 0.744662880897522, "action": 1.2471152544021606}
{"mode": "train", "epochs": 1, "timestep": 1726, "ep_reward": 885.4705200195312, "reward": 0.7297170162200928, "action": 1.1694250106811523}
{"mode": "train", "epochs": 1, "timestep": 1727, "ep_reward": 886.1756591796875, "reward": 0.7051094770431519, "action": 1.3995991945266724}
{"mode": "train", "epochs": 1, "timestep": 1728, "ep_reward": 886.8482666015625, "reward": 0.6726036071777344, "action": 0.27514004707336426}
{"mode": "train", "epochs": 1, "timestep": 1729, "ep_reward": 887.4730834960938, "reward": 0.6247974038124084, "action": 1.3731459379196167}
{"mode": "train", "epochs": 1, "timestep": 1730, "ep_reward": 888.0472412109375, "reward": 0.5741450786590576, "action": 0.901652991771698}
{"mode": "train", "epochs": 1, "timestep": 1731, "ep_reward": 888.5615844726562, "reward": 0.5143542885780334, "action": 1.7216873168945312}
{"mode": "train", "epochs": 1, "timestep": 1732, "ep_reward": 889.0188598632812, "reward": 0.45730090141296387, "action": 1.3088841438293457}
{"mode": "train", "epochs": 1, "timestep": 1733, "ep_reward": 889.416259765625, "reward": 0.3973897099494934, "action": 1.3247853517532349}
{"mode": "train", "epochs": 1, "timestep": 1734, "ep_reward": 889.7559814453125, "reward": 0.3397248387336731, "action": 1.7445881366729736}
{"mode": "train", "epochs": 1, "timestep": 1735, "ep_reward": 890.1233520507812, "reward": 0.3673930764198303, "action": 1.1818711757659912}
{"mode": "train", "epochs": 1, "timestep": 1736, "ep_reward": 890.5493774414062, "reward": 0.42602115869522095, "action": 0.5553374290466309}
{"mode": "train", "epochs": 1, "timestep": 1737, "ep_reward": 891.0266723632812, "reward": 0.47726553678512573, "action": 0.5290869474411011}
{"mode": "train", "epochs": 1, "timestep": 1738, "ep_reward": 891.549072265625, "reward": 0.5223959684371948, "action": 0.5942884683609009}
{"mode": "train", "epochs": 1, "timestep": 1739, "ep_reward": 892.1087036132812, "reward": 0.5596115589141846, "action": 1.1890814304351807}
{"mode": "train", "epochs": 1, "timestep": 1740, "ep_reward": 892.6956176757812, "reward": 0.5869422554969788, "action": 1.5512633323669434}
{"mode": "train", "epochs": 1, "timestep": 1741, "ep_reward": 893.2960815429688, "reward": 0.6004401445388794, "action": 0.18973445892333984}
{"mode": "train", "epochs": 1, "timestep": 1742, "ep_reward": 893.8973999023438, "reward": 0.6013447642326355, "action": 0.964982807636261}
{"mode": "train", "epochs": 1, "timestep": 1743, "ep_reward": 894.487060546875, "reward": 0.5896511077880859, "action": 1.127340316772461}
{"mode": "train", "epochs": 1, "timestep": 1744, "ep_reward": 895.0511474609375, "reward": 0.5640743970870972, "action": 1.360386610031128}
{"mode": "train", "epochs": 1, "timestep": 1745, "ep_reward": 895.5753173828125, "reward": 0.5241550207138062, "action": 1.1472680568695068}
{"mode": "train", "epochs": 1, "timestep": 1746, "ep_reward": 896.0482788085938, "reward": 0.4729464650154114, "action": 1.4755374193191528}
{"mode": "train", "epochs": 1, "timestep": 1747, "ep_reward": 896.4580078125, "reward": 0.409710168838501, "action": 1.3900086879730225}
{"mode": "train", "epochs": 1, "timestep": 1748, "ep_reward": 896.797119140625, "reward": 0.3391011953353882, "action": 0.9421044588088989}
{"mode": "train", "epochs": 1, "timestep": 1749, "ep_reward": 897.1625366210938, "reward": 0.36540424823760986, "action": 1.0434188842773438}
{"mode": "train", "epochs": 1, "timestep": 1750, "ep_reward": 897.5857543945312, "reward": 0.4232366681098938, "action": 1.535675287246704}
{"mode": "train", "epochs": 1, "timestep": 1751, "ep_reward": 898.0657958984375, "reward": 0.4800397753715515, "action": 0.8948144316673279}
{"mode": "train", "epochs": 1, "timestep": 1752, "ep_reward": 898.6046142578125, "reward": 0.5388028621673584, "action": 0.4965694546699524}
{"mode": "train", "epochs": 1, "timestep": 1753, "ep_reward": 899.1990356445312, "reward": 0.5944002270698547, "action": 0.7481629252433777}
{"mode": "train", "epochs": 1, "timestep": 1754, "ep_reward": 899.8406982421875, "reward": 0.6416492462158203, "action": 1.0789285898208618}
{"mode": "train", "epochs": 1, "timestep": 1755, "ep_reward": 900.5206909179688, "reward": 0.6800019145011902, "action": 0.3206372857093811}
{"mode": "train", "epochs": 1, "timestep": 1756, "ep_reward": 901.23095703125, "reward": 0.710288405418396, "action": 1.6801502704620361}
{"mode": "train", "epochs": 1, "timestep": 1757, "ep_reward": 901.960205078125, "reward": 0.7292490601539612, "action": 0.4451698064804077}
{"mode": "train", "epochs": 1, "timestep": 1758, "ep_reward": 902.6995849609375, "reward": 0.7393879890441895, "action": 1.6533150672912598}
{"mode": "train", "epochs": 1, "timestep": 1759, "ep_reward": 903.4398193359375, "reward": 0.7402560710906982, "action": 0.11686772108078003}
{"mode": "train", "epochs": 1, "timestep": 1760, "ep_reward": 904.1685791015625, "reward": 0.7287427186965942, "action": 0.12640374898910522}
{"mode": "train", "epochs": 1, "timestep": 1761, "ep_reward": 904.8720092773438, "reward": 0.7034452557563782, "action": 1.1201064586639404}
{"mode": "train", "epochs": 1, "timestep": 1762, "ep_reward": 905.542236328125, "reward": 0.670235276222229, "action": 0.9676902294158936}
{"mode": "train", "epochs": 1, "timestep": 1763, "ep_reward": 906.1694946289062, "reward": 0.6272417306900024, "action": 0.7506142854690552}
{"mode": "train", "epochs": 1, "timestep": 1764, "ep_reward": 906.7437744140625, "reward": 0.5742911100387573, "action": 0.9882076978683472}
{"mode": "train", "epochs": 1, "timestep": 1765, "ep_reward": 907.259521484375, "reward": 0.5157678127288818, "action": 1.407161831855774}
{"mode": "train", "epochs": 1, "timestep": 1766, "ep_reward": 907.7162475585938, "reward": 0.4567413926124573, "action": 1.038831353187561}
{"mode": "train", "epochs": 1, "timestep": 1767, "ep_reward": 908.1105346679688, "reward": 0.3942919373512268, "action": 0.934345006942749}
{"mode": "train", "epochs": 1, "timestep": 1768, "ep_reward": 908.44287109375, "reward": 0.3323372006416321, "action": 1.0026443004608154}
{"mode": "train", "epochs": 1, "timestep": 1769, "ep_reward": 908.8095092773438, "reward": 0.3666677474975586, "action": 0.3512433171272278}
{"mode": "train", "epochs": 1, "timestep": 1770, "ep_reward": 909.2366943359375, "reward": 0.42720335721969604, "action": 1.3219188451766968}
{"mode": "train", "epochs": 1, "timestep": 1771, "ep_reward": 909.7235107421875, "reward": 0.4868117570877075, "action": 0.8396620154380798}
{"mode": "train", "epochs": 1, "timestep": 1772, "ep_reward": 910.2593383789062, "reward": 0.5358524322509766, "action": 1.7565569877624512}
{"mode": "train", "epochs": 1, "timestep": 1773, "ep_reward": 910.835205078125, "reward": 0.5758899450302124, "action": 1.401158332824707}
{"mode": "train", "epochs": 1, "timestep": 1774, "ep_reward": 911.4356689453125, "reward": 0.6004908084869385, "action": 0.8774012327194214}
{"mode": "train", "epochs": 1, "timestep": 1775, "ep_reward": 912.0464477539062, "reward": 0.6107807755470276, "action": 0.8809448480606079}
{"mode": "train", "epochs": 1, "timestep": 1776, "ep_reward": 912.6542358398438, "reward": 0.6077883243560791, "action": 0.7421237230300903}
{"mode": "train", "epochs": 1, "timestep": 1777, "ep_reward": 913.2462158203125, "reward": 0.5919514894485474, "action": 0.6094050407409668}
{"mode": "train", "epochs": 1, "timestep": 1778, "ep_reward": 913.8106079101562, "reward": 0.564385712146759, "action": 0.8611729741096497}
{"mode": "train", "epochs": 1, "timestep": 1779, "ep_reward": 914.3350830078125, "reward": 0.5244513750076294, "action": 1.3405297994613647}
{"mode": "train", "epochs": 1, "timestep": 1780, "ep_reward": 914.805908203125, "reward": 0.4708196520805359, "action": 1.1922637224197388}
{"mode": "train", "epochs": 1, "timestep": 1781, "ep_reward": 915.2138061523438, "reward": 0.40789276361465454, "action": 1.520119071006775}
{"mode": "train", "epochs": 1, "timestep": 1782, "ep_reward": 915.5491943359375, "reward": 0.33539319038391113, "action": 0.797461748123169}
{"mode": "train", "epochs": 1, "timestep": 1783, "ep_reward": 915.91552734375, "reward": 0.36635857820510864, "action": 1.3526880741119385}
{"mode": "train", "epochs": 1, "timestep": 1784, "ep_reward": 916.3392333984375, "reward": 0.42373204231262207, "action": 0.15846073627471924}
{"mode": "train", "epochs": 1, "timestep": 1785, "ep_reward": 916.8258056640625, "reward": 0.48655498027801514, "action": 0.6481237411499023}
{"mode": "train", "epochs": 1, "timestep": 1786, "ep_reward": 917.3692626953125, "reward": 0.543470025062561, "action": 0.2074795961380005}
{"mode": "train", "epochs": 1, "timestep": 1787, "ep_reward": 917.9655151367188, "reward": 0.5962514877319336, "action": 1.2321338653564453}
{"mode": "train", "epochs": 1, "timestep": 1788, "ep_reward": 918.6040649414062, "reward": 0.6385681629180908, "action": 0.15425467491149902}
{"mode": "train", "epochs": 1, "timestep": 1789, "ep_reward": 919.2796630859375, "reward": 0.6755694150924683, "action": 0.47749048471450806}
{"mode": "train", "epochs": 1, "timestep": 1790, "ep_reward": 919.9805297851562, "reward": 0.7008779048919678, "action": 0.6988098621368408}
{"mode": "train", "epochs": 1, "timestep": 1791, "ep_reward": 920.6958618164062, "reward": 0.7153488397598267, "action": 0.8414804935455322}
{"mode": "train", "epochs": 1, "timestep": 1792, "ep_reward": 921.4152221679688, "reward": 0.7193691730499268, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1793, "ep_reward": 922.1318359375, "reward": 0.7166387438774109, "action": 0.8421322703361511}
{"mode": "train", "epochs": 1, "timestep": 1794, "ep_reward": 922.8358764648438, "reward": 0.7040424346923828, "action": 0.7588269710540771}
{"mode": "train", "epochs": 1, "timestep": 1795, "ep_reward": 923.516845703125, "reward": 0.6809582114219666, "action": 1.3132445812225342}
{"mode": "train", "epochs": 1, "timestep": 1796, "ep_reward": 924.167724609375, "reward": 0.6508669853210449, "action": 1.1879501342773438}
{"mode": "train", "epochs": 1, "timestep": 1797, "ep_reward": 924.7805786132812, "reward": 0.6128536462783813, "action": 0.743871808052063}
{"mode": "train", "epochs": 1, "timestep": 1798, "ep_reward": 925.345703125, "reward": 0.5651305913925171, "action": 1.2407958507537842}
{"mode": "train", "epochs": 1, "timestep": 1799, "ep_reward": 925.8602294921875, "reward": 0.5145465135574341, "action": 1.4379217624664307}
{"mode": "train", "epochs": 1, "timestep": 1800, "ep_reward": 926.3230590820312, "reward": 0.4628590941429138, "action": 0.8133348226547241}
{"mode": "train", "epochs": 1, "timestep": 1801, "ep_reward": 926.7291870117188, "reward": 0.40613019466400146, "action": 0.47626519203186035}
{"mode": "train", "epochs": 1, "timestep": 1802, "ep_reward": 927.076171875, "reward": 0.34697264432907104, "action": 1.3813750743865967}
{"mode": "train", "epochs": 1, "timestep": 1803, "ep_reward": 927.4449462890625, "reward": 0.36874866485595703, "action": 0.5694990754127502}
{"mode": "train", "epochs": 1, "timestep": 1804, "ep_reward": 927.8684692382812, "reward": 0.42351996898651123, "action": 1.153821349143982}
{"mode": "train", "epochs": 1, "timestep": 1805, "ep_reward": 928.3440551757812, "reward": 0.47556233406066895, "action": 0.9721494317054749}
{"mode": "train", "epochs": 1, "timestep": 1806, "ep_reward": 928.8632202148438, "reward": 0.5191718339920044, "action": 0.9426630139350891}
{"mode": "train", "epochs": 1, "timestep": 1807, "ep_reward": 929.41650390625, "reward": 0.5532989501953125, "action": 1.1821728944778442}
{"mode": "train", "epochs": 1, "timestep": 1808, "ep_reward": 929.992919921875, "reward": 0.5764375925064087, "action": 1.3385628461837769}
{"mode": "train", "epochs": 1, "timestep": 1809, "ep_reward": 930.5791625976562, "reward": 0.5862306952476501, "action": 1.999316930770874}
{"mode": "train", "epochs": 1, "timestep": 1810, "ep_reward": 931.1591796875, "reward": 0.5800408124923706, "action": 1.3540503978729248}
{"mode": "train", "epochs": 1, "timestep": 1811, "ep_reward": 931.7183227539062, "reward": 0.5591453313827515, "action": 0.7508319616317749}
{"mode": "train", "epochs": 1, "timestep": 1812, "ep_reward": 932.2459716796875, "reward": 0.5276601314544678, "action": 1.2447391748428345}
{"mode": "train", "epochs": 1, "timestep": 1813, "ep_reward": 932.7293090820312, "reward": 0.4833402633666992, "action": 1.6058648824691772}
{"mode": "train", "epochs": 1, "timestep": 1814, "ep_reward": 933.15576171875, "reward": 0.42645686864852905, "action": 0.5121574401855469}
{"mode": "train", "epochs": 1, "timestep": 1815, "ep_reward": 933.524658203125, "reward": 0.36887967586517334, "action": 1.1188650131225586}
{"mode": "train", "epochs": 1, "timestep": 1816, "ep_reward": 933.8811645507812, "reward": 0.35648113489151, "action": 0.547505259513855}
{"mode": "train", "epochs": 1, "timestep": 1817, "ep_reward": 934.2913208007812, "reward": 0.41015028953552246, "action": 1.5304405689239502}
{"mode": "train", "epochs": 1, "timestep": 1818, "ep_reward": 934.75244140625, "reward": 0.4611390233039856, "action": 0.8861031532287598}
{"mode": "train", "epochs": 1, "timestep": 1819, "ep_reward": 935.2669677734375, "reward": 0.5145233869552612, "action": 1.0891644954681396}
{"mode": "train", "epochs": 1, "timestep": 1820, "ep_reward": 935.8311767578125, "reward": 0.5642246603965759, "action": 1.4076861143112183}
{"mode": "train", "epochs": 1, "timestep": 1821, "ep_reward": 936.4400024414062, "reward": 0.6088295578956604, "action": 1.5034149885177612}
{"mode": "train", "epochs": 1, "timestep": 1822, "ep_reward": 937.08837890625, "reward": 0.6483465433120728, "action": 1.008726954460144}
{"mode": "train", "epochs": 1, "timestep": 1823, "ep_reward": 937.7708129882812, "reward": 0.6824188828468323, "action": 1.1631057262420654}
{"mode": "train", "epochs": 1, "timestep": 1824, "ep_reward": 938.4786987304688, "reward": 0.7078863382339478, "action": 0.9760211706161499}
{"mode": "train", "epochs": 1, "timestep": 1825, "ep_reward": 939.203369140625, "reward": 0.7246658802032471, "action": 0.2844180464744568}
{"mode": "train", "epochs": 1, "timestep": 1826, "ep_reward": 939.9340209960938, "reward": 0.7306257486343384, "action": 0.7994314432144165}
{"mode": "train", "epochs": 1, "timestep": 1827, "ep_reward": 940.6592407226562, "reward": 0.7252311706542969, "action": 1.5379118919372559}
{"mode": "train", "epochs": 1, "timestep": 1828, "ep_reward": 941.371337890625, "reward": 0.712103545665741, "action": 0.5103535056114197}
{"mode": "train", "epochs": 1, "timestep": 1829, "ep_reward": 942.0579223632812, "reward": 0.6866066455841064, "action": 0.7797224521636963}
{"mode": "train", "epochs": 1, "timestep": 1830, "ep_reward": 942.709228515625, "reward": 0.6513293981552124, "action": 0.18171370029449463}
{"mode": "train", "epochs": 1, "timestep": 1831, "ep_reward": 943.3115844726562, "reward": 0.6023864150047302, "action": 1.6879403591156006}
{"mode": "train", "epochs": 1, "timestep": 1832, "ep_reward": 943.865966796875, "reward": 0.554395318031311, "action": 0.8338043689727783}
{"mode": "train", "epochs": 1, "timestep": 1833, "ep_reward": 944.3623657226562, "reward": 0.49637287855148315, "action": 1.6220283508300781}
{"mode": "train", "epochs": 1, "timestep": 1834, "ep_reward": 944.8038940429688, "reward": 0.4415549039840698, "action": 0.11268007755279541}
{"mode": "train", "epochs": 1, "timestep": 1835, "ep_reward": 945.1787109375, "reward": 0.37484580278396606, "action": 1.2297040224075317}
{"mode": "train", "epochs": 1, "timestep": 1836, "ep_reward": 945.50439453125, "reward": 0.32569533586502075, "action": 0.9602745175361633}
{"mode": "train", "epochs": 1, "timestep": 1837, "ep_reward": 945.8928833007812, "reward": 0.38849306106567383, "action": 0.9139723181724548}
{"mode": "train", "epochs": 1, "timestep": 1838, "ep_reward": 946.340087890625, "reward": 0.4472031593322754, "action": 1.5349514484405518}
{"mode": "train", "epochs": 1, "timestep": 1839, "ep_reward": 946.8410034179688, "reward": 0.5009271502494812, "action": 1.656358003616333}
{"mode": "train", "epochs": 1, "timestep": 1840, "ep_reward": 947.3848876953125, "reward": 0.5438582897186279, "action": 0.7638633251190186}
{"mode": "train", "epochs": 1, "timestep": 1841, "ep_reward": 947.9580688476562, "reward": 0.5731649994850159, "action": 1.3636441230773926}
{"mode": "train", "epochs": 1, "timestep": 1842, "ep_reward": 948.5490112304688, "reward": 0.590968668460846, "action": 0.9864751696586609}
{"mode": "train", "epochs": 1, "timestep": 1843, "ep_reward": 949.14404296875, "reward": 0.5950080156326294, "action": 1.2975988388061523}
{"mode": "train", "epochs": 1, "timestep": 1844, "ep_reward": 949.72900390625, "reward": 0.5849887132644653, "action": 0.8471009135246277}
{"mode": "train", "epochs": 1, "timestep": 1845, "ep_reward": 950.2913818359375, "reward": 0.5623493194580078, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1846, "ep_reward": 950.8134155273438, "reward": 0.5220509171485901, "action": 0.8793702721595764}
{"mode": "train", "epochs": 1, "timestep": 1847, "ep_reward": 951.2870483398438, "reward": 0.47363823652267456, "action": 0.7879629135131836}
{"mode": "train", "epochs": 1, "timestep": 1848, "ep_reward": 951.7045288085938, "reward": 0.41750138998031616, "action": 1.5427250862121582}
{"mode": "train", "epochs": 1, "timestep": 1849, "ep_reward": 952.0543823242188, "reward": 0.349876344203949, "action": 1.369165301322937}
{"mode": "train", "epochs": 1, "timestep": 1850, "ep_reward": 952.416748046875, "reward": 0.36233848333358765, "action": 1.3881772756576538}
{"mode": "train", "epochs": 1, "timestep": 1851, "ep_reward": 952.83447265625, "reward": 0.41774076223373413, "action": 1.0104647874832153}
{"mode": "train", "epochs": 1, "timestep": 1852, "ep_reward": 953.3104858398438, "reward": 0.47599297761917114, "action": 1.342837929725647}
{"mode": "train", "epochs": 1, "timestep": 1853, "ep_reward": 953.84228515625, "reward": 0.5317992568016052, "action": 0.6516112089157104}
{"mode": "train", "epochs": 1, "timestep": 1854, "ep_reward": 954.42919921875, "reward": 0.5869387984275818, "action": 1.1196688413619995}
{"mode": "train", "epochs": 1, "timestep": 1855, "ep_reward": 955.0632934570312, "reward": 0.6340892314910889, "action": 1.1108105182647705}
{"mode": "train", "epochs": 1, "timestep": 1856, "ep_reward": 955.737548828125, "reward": 0.6742284297943115, "action": 1.5590181350708008}
{"mode": "train", "epochs": 1, "timestep": 1857, "ep_reward": 956.4434204101562, "reward": 0.7058717012405396, "action": 0.9587858319282532}
{"mode": "train", "epochs": 1, "timestep": 1858, "ep_reward": 957.1736450195312, "reward": 0.7302314639091492, "action": 1.4382412433624268}
{"mode": "train", "epochs": 1, "timestep": 1859, "ep_reward": 957.918701171875, "reward": 0.7450295090675354, "action": 1.1014564037322998}
{"mode": "train", "epochs": 1, "timestep": 1860, "ep_reward": 958.6696166992188, "reward": 0.7508850693702698, "action": 0.9651926755905151}
{"mode": "train", "epochs": 1, "timestep": 1861, "ep_reward": 959.4161987304688, "reward": 0.7466088533401489, "action": 0.652786374092102}
{"mode": "train", "epochs": 1, "timestep": 1862, "ep_reward": 960.1468505859375, "reward": 0.7306519746780396, "action": 1.5442438125610352}
{"mode": "train", "epochs": 1, "timestep": 1863, "ep_reward": 960.854248046875, "reward": 0.7073836326599121, "action": 0.6866453886032104}
{"mode": "train", "epochs": 1, "timestep": 1864, "ep_reward": 961.5255737304688, "reward": 0.6713535189628601, "action": 0.945529580116272}
{"mode": "train", "epochs": 1, "timestep": 1865, "ep_reward": 962.15185546875, "reward": 0.6262540817260742, "action": 1.5485292673110962}
{"mode": "train", "epochs": 1, "timestep": 1866, "ep_reward": 962.7291259765625, "reward": 0.5772495269775391, "action": 0.8152002096176147}
{"mode": "train", "epochs": 1, "timestep": 1867, "ep_reward": 963.2467651367188, "reward": 0.5176485776901245, "action": 1.282435655593872}
{"mode": "train", "epochs": 1, "timestep": 1868, "ep_reward": 963.7040405273438, "reward": 0.4572763442993164, "action": 0.3556496500968933}
{"mode": "train", "epochs": 1, "timestep": 1869, "ep_reward": 964.091796875, "reward": 0.3877325654029846, "action": 1.5943471193313599}
{"mode": "train", "epochs": 1, "timestep": 1870, "ep_reward": 964.4210205078125, "reward": 0.3292510509490967, "action": 1.0609560012817383}
{"mode": "train", "epochs": 1, "timestep": 1871, "ep_reward": 964.7884521484375, "reward": 0.3674308657646179, "action": 1.2315759658813477}
{"mode": "train", "epochs": 1, "timestep": 1872, "ep_reward": 965.2196044921875, "reward": 0.43115633726119995, "action": 0.8363609313964844}
{"mode": "train", "epochs": 1, "timestep": 1873, "ep_reward": 965.7068481445312, "reward": 0.48723918199539185, "action": 1.0174381732940674}
{"mode": "train", "epochs": 1, "timestep": 1874, "ep_reward": 966.2427978515625, "reward": 0.5359551906585693, "action": 1.0248229503631592}
{"mode": "train", "epochs": 1, "timestep": 1875, "ep_reward": 966.81689453125, "reward": 0.5741161704063416, "action": 1.240140438079834}
{"mode": "train", "epochs": 1, "timestep": 1876, "ep_reward": 967.4169311523438, "reward": 0.6000066995620728, "action": 1.0370770692825317}
{"mode": "train", "epochs": 1, "timestep": 1877, "ep_reward": 968.02880859375, "reward": 0.6118873357772827, "action": 0.15411019325256348}
{"mode": "train", "epochs": 1, "timestep": 1878, "ep_reward": 968.6406860351562, "reward": 0.6118958592414856, "action": 0.7662655711174011}
{"mode": "train", "epochs": 1, "timestep": 1879, "ep_reward": 969.240234375, "reward": 0.5995281934738159, "action": -0.03303247690200806}
{"mode": "train", "epochs": 1, "timestep": 1880, "ep_reward": 969.8182373046875, "reward": 0.5779910683631897, "action": 0.8079264163970947}
{"mode": "train", "epochs": 1, "timestep": 1881, "ep_reward": 970.361572265625, "reward": 0.5433337092399597, "action": 1.3549764156341553}
{"mode": "train", "epochs": 1, "timestep": 1882, "ep_reward": 970.8558349609375, "reward": 0.494268536567688, "action": 1.080891489982605}
{"mode": "train", "epochs": 1, "timestep": 1883, "ep_reward": 971.2915649414062, "reward": 0.4357544183731079, "action": 0.9960507750511169}
{"mode": "train", "epochs": 1, "timestep": 1884, "ep_reward": 971.661865234375, "reward": 0.3703143000602722, "action": 0.6138414144515991}
{"mode": "train", "epochs": 1, "timestep": 1885, "ep_reward": 972.0050048828125, "reward": 0.3431565761566162, "action": 0.7187467813491821}
{"mode": "train", "epochs": 1, "timestep": 1886, "ep_reward": 972.4048461914062, "reward": 0.3998308777809143, "action": 0.2678372859954834}
{"mode": "train", "epochs": 1, "timestep": 1887, "ep_reward": 972.8632202148438, "reward": 0.4583820700645447, "action": 1.6789976358413696}
{"mode": "train", "epochs": 1, "timestep": 1888, "ep_reward": 973.3734130859375, "reward": 0.5101940631866455, "action": 0.6853231191635132}
{"mode": "train", "epochs": 1, "timestep": 1889, "ep_reward": 973.9373779296875, "reward": 0.5639674663543701, "action": 0.903701663017273}
{"mode": "train", "epochs": 1, "timestep": 1890, "ep_reward": 974.5488891601562, "reward": 0.6115261912345886, "action": 0.15451675653457642}
{"mode": "train", "epochs": 1, "timestep": 1891, "ep_reward": 975.2023315429688, "reward": 0.6534574031829834, "action": 0.5392332077026367}
{"mode": "train", "epochs": 1, "timestep": 1892, "ep_reward": 975.8864135742188, "reward": 0.6841031312942505, "action": 1.5355470180511475}
{"mode": "train", "epochs": 1, "timestep": 1893, "ep_reward": 976.5912475585938, "reward": 0.7048144340515137, "action": 0.6858744621276855}
{"mode": "train", "epochs": 1, "timestep": 1894, "ep_reward": 977.3087158203125, "reward": 0.7174974679946899, "action": 0.992781400680542}
{"mode": "train", "epochs": 1, "timestep": 1895, "ep_reward": 978.0287475585938, "reward": 0.7200485467910767, "action": 1.743040919303894}
{"mode": "train", "epochs": 1, "timestep": 1896, "ep_reward": 978.743896484375, "reward": 0.7151626348495483, "action": 1.8749507665634155}
{"mode": "train", "epochs": 1, "timestep": 1897, "ep_reward": 979.4479370117188, "reward": 0.7040644288063049, "action": 1.1276047229766846}
{"mode": "train", "epochs": 1, "timestep": 1898, "ep_reward": 980.1315307617188, "reward": 0.6836186647415161, "action": 0.39902883768081665}
{"mode": "train", "epochs": 1, "timestep": 1899, "ep_reward": 980.7821655273438, "reward": 0.650632381439209, "action": 1.4217846393585205}
{"mode": "train", "epochs": 1, "timestep": 1900, "ep_reward": 981.3954467773438, "reward": 0.613296627998352, "action": 0.9469612836837769}
{"mode": "train", "epochs": 1, "timestep": 1901, "ep_reward": 981.9623413085938, "reward": 0.5669105052947998, "action": 1.1483205556869507}
{"mode": "train", "epochs": 1, "timestep": 1902, "ep_reward": 982.478515625, "reward": 0.5161970853805542, "action": 0.7157210111618042}
{"mode": "train", "epochs": 1, "timestep": 1903, "ep_reward": 982.937255859375, "reward": 0.4587569236755371, "action": 1.3970553874969482}
{"mode": "train", "epochs": 1, "timestep": 1904, "ep_reward": 983.3421630859375, "reward": 0.4049103856086731, "action": 1.1436092853546143}
{"mode": "train", "epochs": 1, "timestep": 1905, "ep_reward": 983.693359375, "reward": 0.3512078523635864, "action": 1.5628547668457031}
{"mode": "train", "epochs": 1, "timestep": 1906, "ep_reward": 984.062744140625, "reward": 0.3693978190422058, "action": 1.6572428941726685}
{"mode": "train", "epochs": 1, "timestep": 1907, "ep_reward": 984.4868774414062, "reward": 0.4241517186164856, "action": 0.5570883750915527}
{"mode": "train", "epochs": 1, "timestep": 1908, "ep_reward": 984.9564819335938, "reward": 0.4695768356323242, "action": 0.9982416033744812}
{"mode": "train", "epochs": 1, "timestep": 1909, "ep_reward": 985.46630859375, "reward": 0.5098032355308533, "action": 0.8401603698730469}
{"mode": "train", "epochs": 1, "timestep": 1910, "ep_reward": 986.0072021484375, "reward": 0.5408669710159302, "action": 1.514251470565796}
{"mode": "train", "epochs": 1, "timestep": 1911, "ep_reward": 986.5687866210938, "reward": 0.5615739822387695, "action": 1.823952317237854}
{"mode": "train", "epochs": 1, "timestep": 1912, "ep_reward": 987.1369018554688, "reward": 0.5681338310241699, "action": 0.6272487044334412}
{"mode": "train", "epochs": 1, "timestep": 1913, "ep_reward": 987.6995239257812, "reward": 0.5626503229141235, "action": 0.9359158873558044}
{"mode": "train", "epochs": 1, "timestep": 1914, "ep_reward": 988.2452392578125, "reward": 0.5457078218460083, "action": 1.5878349542617798}
{"mode": "train", "epochs": 1, "timestep": 1915, "ep_reward": 988.759765625, "reward": 0.5145250558853149, "action": 2.0}
{"mode": "train", "epochs": 1, "timestep": 1916, "ep_reward": 989.2279663085938, "reward": 0.4682169556617737, "action": 1.2330586910247803}
{"mode": "train", "epochs": 1, "timestep": 1917, "ep_reward": 989.6424560546875, "reward": 0.4144982099533081, "action": 1.3855301141738892}
{"mode": "train", "epochs": 1, "timestep": 1918, "ep_reward": 989.9952392578125, "reward": 0.3527712821960449, "action": 0.798406720161438}
{"mode": "train", "epochs": 1, "timestep": 1919, "ep_reward": 990.3677368164062, "reward": 0.3724783658981323, "action": 1.1978602409362793}
{"mode": "train", "epochs": 1, "timestep": 1920, "ep_reward": 990.7911987304688, "reward": 0.4234567880630493, "action": 0.47153210639953613}
{"mode": "train", "epochs": 1, "timestep": 1921, "ep_reward": 991.2686157226562, "reward": 0.4774141311645508, "action": 1.450089931488037}
{"mode": "train", "epochs": 1, "timestep": 1922, "ep_reward": 991.794677734375, "reward": 0.5260918140411377, "action": 1.5258963108062744}
{"mode": "train", "epochs": 1, "timestep": 1923, "ep_reward": 992.3674926757812, "reward": 0.5727967023849487, "action": 0.9067655801773071}
{"mode": "train", "epochs": 1, "timestep": 1924, "ep_reward": 992.9846801757812, "reward": 0.6171807050704956, "action": 1.9588513374328613}
{"mode": "train", "epochs": 1, "timestep": 1925, "ep_reward": 993.6380615234375, "reward": 0.6533682942390442, "action": 1.047045111656189}
{"mode": "train", "epochs": 1, "timestep": 1926, "ep_reward": 994.3236694335938, "reward": 0.6856322288513184, "action": 1.8604152202606201}
{"mode": "train", "epochs": 1, "timestep": 1927, "ep_reward": 995.0330200195312, "reward": 0.709352970123291, "action": 1.3378040790557861}
{"mode": "train", "epochs": 1, "timestep": 1928, "ep_reward": 995.759521484375, "reward": 0.7265157699584961, "action": 1.5599591732025146}
{"mode": "train", "epochs": 1, "timestep": 1929, "ep_reward": 996.4950561523438, "reward": 0.7355576753616333, "action": 1.6336393356323242}
{"mode": "train", "epochs": 1, "timestep": 1930, "ep_reward": 997.2320556640625, "reward": 0.7369897365570068, "action": 1.4837895631790161}
{"mode": "train", "epochs": 1, "timestep": 1931, "ep_reward": 997.9625244140625, "reward": 0.7304853200912476, "action": -0.574471116065979}
{"mode": "train", "epochs": 1, "timestep": 1932, "ep_reward": 998.6702270507812, "reward": 0.7076974511146545, "action": 0.618342399597168}
{"mode": "train", "epochs": 1, "timestep": 1933, "ep_reward": 999.3448486328125, "reward": 0.674625039100647, "action": 0.9271749258041382}
{"mode": "train", "epochs": 1, "timestep": 1934, "ep_reward": 999.9774169921875, "reward": 0.6325883269309998, "action": 1.1760485172271729}
{"mode": "train", "epochs": 1, "timestep": 1935, "ep_reward": 1000.5611572265625, "reward": 0.5837302207946777, "action": 1.0681527853012085}
{"mode": "train", "epochs": 1, "timestep": 1936, "ep_reward": 1001.089111328125, "reward": 0.5279816389083862, "action": 0.44298529624938965}
{"mode": "train", "epochs": 1, "timestep": 1937, "ep_reward": 1001.5516967773438, "reward": 0.4625685214996338, "action": -0.09326601028442383}
{"mode": "train", "epochs": 1, "timestep": 1938, "ep_reward": 1001.93994140625, "reward": 0.38827401399612427, "action": 1.302786946296692}
{"mode": "train", "epochs": 1, "timestep": 1939, "ep_reward": 1002.2649536132812, "reward": 0.3250197172164917, "action": 0.9989747405052185}
{"mode": "train", "epochs": 1, "timestep": 1940, "ep_reward": 1002.6270751953125, "reward": 0.3621066212654114, "action": 1.1802594661712646}
{"mode": "train", "epochs": 1, "timestep": 1941, "ep_reward": 1003.0560913085938, "reward": 0.42903202772140503, "action": 1.1147661209106445}
{"mode": "train", "epochs": 1, "timestep": 1942, "ep_reward": 1003.5453491210938, "reward": 0.489249587059021, "action": 1.2599436044692993}
{"mode": "train", "epochs": 1, "timestep": 1943, "ep_reward": 1004.086181640625, "reward": 0.5408209562301636, "action": 1.1340084075927734}
{"mode": "train", "epochs": 1, "timestep": 1944, "ep_reward": 1004.6666870117188, "reward": 0.5805236101150513, "action": 0.08521580696105957}
{"mode": "train", "epochs": 1, "timestep": 1945, "ep_reward": 1005.27392578125, "reward": 0.6072521209716797, "action": 1.0479017496109009}
{"mode": "train", "epochs": 1, "timestep": 1946, "ep_reward": 1005.8971557617188, "reward": 0.6232235431671143, "action": 1.5562915802001953}
{"mode": "train", "epochs": 1, "timestep": 1947, "ep_reward": 1006.5206909179688, "reward": 0.6235560178756714, "action": 0.5538080930709839}
{"mode": "train", "epochs": 1, "timestep": 1948, "ep_reward": 1007.130859375, "reward": 0.6101741790771484, "action": 0.9345799088478088}
{"mode": "train", "epochs": 1, "timestep": 1949, "ep_reward": 1007.7135009765625, "reward": 0.5826659798622131, "action": 1.4087843894958496}
{"mode": "train", "epochs": 1, "timestep": 1950, "ep_reward": 1008.252685546875, "reward": 0.539202868938446, "action": 1.2524793148040771}
{"mode": "train", "epochs": 1, "timestep": 1951, "ep_reward": 1008.7356567382812, "reward": 0.4830012917518616, "action": 0.39567261934280396}
{"mode": "train", "epochs": 1, "timestep": 1952, "ep_reward": 1009.1582641601562, "reward": 0.4226234555244446, "action": 1.5930345058441162}
{"mode": "train", "epochs": 1, "timestep": 1953, "ep_reward": 1009.5059204101562, "reward": 0.3476288914680481, "action": 1.2453227043151855}
{"mode": "train", "epochs": 1, "timestep": 1954, "ep_reward": 1009.8534545898438, "reward": 0.3475145697593689, "action": 0.6062645316123962}
{"mode": "train", "epochs": 1, "timestep": 1955, "ep_reward": 1010.2640380859375, "reward": 0.41058051586151123, "action": 0.6702075004577637}
{"mode": "train", "epochs": 1, "timestep": 1956, "ep_reward": 1010.7371826171875, "reward": 0.47313350439071655, "action": 1.450480580329895}
{"mode": "train", "epochs": 1, "timestep": 1957, "ep_reward": 1011.267822265625, "reward": 0.5306165218353271, "action": 1.1960278749465942}
{"mode": "train", "epochs": 1, "timestep": 1958, "ep_reward": 1011.8543701171875, "reward": 0.5865654945373535, "action": 0.7339585423469543}
{"mode": "train", "epochs": 1, "timestep": 1959, "ep_reward": 1012.4928588867188, "reward": 0.6384817361831665, "action": 0.8983601331710815}
{"mode": "train", "epochs": 1, "timestep": 1960, "ep_reward": 1013.1741943359375, "reward": 0.6813416481018066, "action": 1.7320787906646729}
{"mode": "train", "epochs": 1, "timestep": 1961, "ep_reward": 1013.8883666992188, "reward": 0.7141858339309692, "action": 0.48248928785324097}
{"mode": "train", "epochs": 1, "timestep": 1962, "ep_reward": 1014.6288452148438, "reward": 0.7405067682266235, "action": 0.24927979707717896}
{"mode": "train", "epochs": 1, "timestep": 1963, "ep_reward": 1015.3833618164062, "reward": 0.7545134425163269, "action": 0.8238720297813416}
{"mode": "train", "epochs": 1, "timestep": 1964, "ep_reward": 1016.1397094726562, "reward": 0.7563704252243042, "action": 0.9397199153900146}
{"mode": "train", "epochs": 1, "timestep": 1965, "ep_reward": 1016.8872680664062, "reward": 0.7475732564926147, "action": 0.5007601380348206}
{"mode": "train", "epochs": 1, "timestep": 1966, "ep_reward": 1017.6134643554688, "reward": 0.7262017726898193, "action": 1.4262566566467285}
{"mode": "train", "epochs": 1, "timestep": 1967, "ep_reward": 1018.3108520507812, "reward": 0.6973689794540405, "action": 0.9820718765258789}
{"mode": "train", "epochs": 1, "timestep": 1968, "ep_reward": 1018.9683227539062, "reward": 0.6574674844741821, "action": 0.8546268343925476}
{"mode": "train", "epochs": 1, "timestep": 1969, "ep_reward": 1019.57568359375, "reward": 0.6073616743087769, "action": 0.7411006689071655}
{"mode": "train", "epochs": 1, "timestep": 1970, "ep_reward": 1020.1235961914062, "reward": 0.5479119420051575, "action": 0.8316292762756348}
{"mode": "train", "epochs": 1, "timestep": 1971, "ep_reward": 1020.6060791015625, "reward": 0.4824800491333008, "action": 1.15770423412323}
{"mode": "train", "epochs": 1, "timestep": 1972, "ep_reward": 1021.0226440429688, "reward": 0.4165581464767456, "action": 0.39561766386032104}
{"mode": "train", "epochs": 1, "timestep": 1973, "ep_reward": 1021.3665771484375, "reward": 0.3439174294471741, "action": 0.7379311323165894}
{"mode": "train", "epochs": 1, "timestep": 1974, "ep_reward": 1021.698486328125, "reward": 0.33190834522247314, "action": 1.20599365234375}
{"mode": "train", "epochs": 1, "timestep": 1975, "ep_reward": 1022.1023559570312, "reward": 0.40388792753219604, "action": 1.3108839988708496}
{"mode": "train", "epochs": 1, "timestep": 1976, "ep_reward": 1022.572998046875, "reward": 0.470619261264801, "action": 0.9933272004127502}
{"mode": "train", "epochs": 1, "timestep": 1977, "ep_reward": 1023.1007080078125, "reward": 0.5276916027069092, "action": 0.28386151790618896}
{"mode": "train", "epochs": 1, "timestep": 1978, "ep_reward": 1023.674072265625, "reward": 0.5733813047409058, "action": 0.9101956486701965}
{"mode": "train", "epochs": 1, "timestep": 1979, "ep_reward": 1024.2841796875, "reward": 0.6101598143577576, "action": 1.355384349822998}
{"mode": "train", "epochs": 1, "timestep": 1980, "ep_reward": 1024.91748046875, "reward": 0.6333125829696655, "action": 1.3093160390853882}
{"mode": "train", "epochs": 1, "timestep": 1981, "ep_reward": 1025.5576171875, "reward": 0.640148401260376, "action": 0.19595104455947876}
{"mode": "train", "epochs": 1, "timestep": 1982, "ep_reward": 1026.1910400390625, "reward": 0.6334406733512878, "action": 1.789024829864502}
{"mode": "train", "epochs": 1, "timestep": 1983, "ep_reward": 1026.7998046875, "reward": 0.6087455749511719, "action": 0.9102252721786499}
{"mode": "train", "epochs": 1, "timestep": 1984, "ep_reward": 1027.3701171875, "reward": 0.5703670978546143, "action": 1.1191387176513672}
{"mode": "train", "epochs": 1, "timestep": 1985, "ep_reward": 1027.8876953125, "reward": 0.5175673961639404, "action": 1.1466444730758667}
{"mode": "train", "epochs": 1, "timestep": 1986, "ep_reward": 1028.34033203125, "reward": 0.45265382528305054, "action": 0.160791277885437}
{"mode": "train", "epochs": 1, "timestep": 1987, "ep_reward": 1028.7271728515625, "reward": 0.38686859607696533, "action": 1.4099540710449219}
{"mode": "train", "epochs": 1, "timestep": 1988, "ep_reward": 1029.038818359375, "reward": 0.3116644024848938, "action": 0.32042908668518066}
{"mode": "train", "epochs": 1, "timestep": 1989, "ep_reward": 1029.4146728515625, "reward": 0.37585747241973877, "action": 1.1969871520996094}
{"mode": "train", "epochs": 1, "timestep": 1990, "ep_reward": 1029.851806640625, "reward": 0.43714261054992676, "action": 0.3444240093231201}
{"mode": "train", "epochs": 1, "timestep": 1991, "ep_reward": 1030.3536376953125, "reward": 0.5018507838249207, "action": 1.5524269342422485}
{"mode": "train", "epochs": 1, "timestep": 1992, "ep_reward": 1030.91162109375, "reward": 0.5579668283462524, "action": 1.0434668064117432}
{"mode": "train", "epochs": 1, "timestep": 1993, "ep_reward": 1031.52392578125, "reward": 0.612362265586853, "action": 1.7691457271575928}
{"mode": "train", "epochs": 1, "timestep": 1994, "ep_reward": 1032.1822509765625, "reward": 0.6583628058433533, "action": 1.1692328453063965}
{"mode": "train", "epochs": 1, "timestep": 1995, "ep_reward": 1032.882080078125, "reward": 0.6997811794281006, "action": 0.6477602124214172}
{"mode": "train", "epochs": 1, "timestep": 1996, "ep_reward": 1033.614990234375, "reward": 0.7328863143920898, "action": 0.9781009554862976}
{"mode": "train", "epochs": 1, "timestep": 1997, "ep_reward": 1034.36962890625, "reward": 0.7546539306640625, "action": 0.6520093679428101}
{"mode": "train", "epochs": 1, "timestep": 1998, "ep_reward": 1035.1353759765625, "reward": 0.7657094597816467, "action": 0.7302601933479309}
{"mode": "train", "epochs": 1, "timestep": 1999, "ep_reward": 1035.9005126953125, "reward": 0.7650790214538574, "action": 1.1492407321929932}
{"mode": "train", "epochs": 1, "timestep": 2000, "ep_reward": 1036.65478515625, "reward": 0.7542686462402344, "action": 0.6896864175796509}
{"mode": "train", "epochs": 2, "timestep": 2001, "ep_reward": 0.4268893003463745, "reward": 0.4268893003463745, "action": 0.8772794604301453}
{"mode": "train", "epochs": 2, "timestep": 2002, "ep_reward": 0.8525277376174927, "reward": 0.42563843727111816, "action": 0.6059222221374512}
{"mode": "train", "epochs": 2, "timestep": 2003, "ep_reward": 1.2731704711914062, "reward": 0.4206427335739136, "action": 0.262776255607605}
{"mode": "train", "epochs": 2, "timestep": 2004, "ep_reward": 1.686490535736084, "reward": 0.4133201241493225, "action": 0.9509439468383789}
{"mode": "train", "epochs": 2, "timestep": 2005, "ep_reward": 2.087834358215332, "reward": 0.4013438820838928, "action": 1.1121057271957397}
{"mode": "train", "epochs": 2, "timestep": 2006, "ep_reward": 2.4725098609924316, "reward": 0.38467538356781006, "action": 1.4541549682617188}
{"mode": "train", "epochs": 2, "timestep": 2007, "ep_reward": 2.863579750061035, "reward": 0.39107000827789307, "action": 0.225375235080719}
{"mode": "train", "epochs": 2, "timestep": 2008, "ep_reward": 3.273853063583374, "reward": 0.41027337312698364, "action": 0.398485004901886}
{"mode": "train", "epochs": 2, "timestep": 2009, "ep_reward": 3.7030601501464844, "reward": 0.4292071461677551, "action": 0.6406193971633911}
{"mode": "train", "epochs": 2, "timestep": 2010, "ep_reward": 4.1507415771484375, "reward": 0.4476816654205322, "action": 1.2330584526062012}
{"mode": "train", "epochs": 2, "timestep": 2011, "ep_reward": 4.616796970367432, "reward": 0.4660552144050598, "action": 1.5044167041778564}
{"mode": "train", "epochs": 2, "timestep": 2012, "ep_reward": 5.101870536804199, "reward": 0.4850738048553467, "action": 0.5443048477172852}
{"mode": "train", "epochs": 2, "timestep": 2013, "ep_reward": 5.605473518371582, "reward": 0.5036028027534485, "action": 0.7153842449188232}
{"mode": "train", "epochs": 2, "timestep": 2014, "ep_reward": 6.124597072601318, "reward": 0.5191234350204468, "action": 1.660873532295227}
{"mode": "train", "epochs": 2, "timestep": 2015, "ep_reward": 6.657469749450684, "reward": 0.5328725576400757, "action": 1.2775307893753052}
{"mode": "train", "epochs": 2, "timestep": 2016, "ep_reward": 7.202730655670166, "reward": 0.5452609658241272, "action": 0.7240201234817505}
{"mode": "train", "epochs": 2, "timestep": 2017, "ep_reward": 7.757019519805908, "reward": 0.5542888045310974, "action": 0.7688814997673035}
{"mode": "train", "epochs": 2, "timestep": 2018, "ep_reward": 8.315766334533691, "reward": 0.5587470531463623, "action": 1.7845194339752197}
{"mode": "train", "epochs": 2, "timestep": 2019, "ep_reward": 8.877091407775879, "reward": 0.5613248944282532, "action": 1.216517448425293}
{"mode": "train", "epochs": 2, "timestep": 2020, "ep_reward": 9.438040733337402, "reward": 0.560949444770813, "action": 0.3571701645851135}
{"mode": "train", "epochs": 2, "timestep": 2021, "ep_reward": 9.992595672607422, "reward": 0.5545549392700195, "action": 1.5386202335357666}
{"mode": "train", "epochs": 2, "timestep": 2022, "ep_reward": 10.539142608642578, "reward": 0.5465468764305115, "action": 1.46863853931427}
{"mode": "train", "epochs": 2, "timestep": 2023, "ep_reward": 11.075736045837402, "reward": 0.5365933179855347, "action": 0.9623762369155884}
{"mode": "train", "epochs": 2, "timestep": 2024, "ep_reward": 11.598647117614746, "reward": 0.5229110717773438, "action": 1.5534573793411255}
{"mode": "train", "epochs": 2, "timestep": 2025, "ep_reward": 12.107860565185547, "reward": 0.5092132687568665, "action": 0.7965642213821411}
{"mode": "train", "epochs": 2, "timestep": 2026, "ep_reward": 12.59953784942627, "reward": 0.491677463054657, "action": 1.671676516532898}
{"mode": "train", "epochs": 2, "timestep": 2027, "ep_reward": 13.075923919677734, "reward": 0.47638577222824097, "action": 0.2297876477241516}
{"mode": "train", "epochs": 2, "timestep": 2028, "ep_reward": 13.531400680541992, "reward": 0.45547717809677124, "action": 1.29123854637146}
{"mode": "train", "epochs": 2, "timestep": 2029, "ep_reward": 13.96870231628418, "reward": 0.4373013377189636, "action": 1.9875023365020752}
{"mode": "train", "epochs": 2, "timestep": 2030, "ep_reward": 14.39273452758789, "reward": 0.4240320324897766, "action": 1.44830322265625}
{"mode": "train", "epochs": 2, "timestep": 2031, "ep_reward": 14.80488109588623, "reward": 0.41214650869369507, "action": 1.08079195022583}
{"mode": "train", "epochs": 2, "timestep": 2032, "ep_reward": 15.206504821777344, "reward": 0.4016237258911133, "action": 0.49775534868240356}
{"mode": "train", "epochs": 2, "timestep": 2033, "ep_reward": 15.597514152526855, "reward": 0.3910096287727356, "action": 1.016961693763733}
{"mode": "train", "epochs": 2, "timestep": 2034, "ep_reward": 15.981118202209473, "reward": 0.3836042284965515, "action": 0.05084884166717529}
{"mode": "train", "epochs": 2, "timestep": 2035, "ep_reward": 16.369792938232422, "reward": 0.38867491483688354, "action": 0.4799315929412842}
{"mode": "train", "epochs": 2, "timestep": 2036, "ep_reward": 16.765382766723633, "reward": 0.3955899477005005, "action": 0.5747196674346924}
{"mode": "train", "epochs": 2, "timestep": 2037, "ep_reward": 17.165578842163086, "reward": 0.40019696950912476, "action": 1.4620317220687866}
{"mode": "train", "epochs": 2, "timestep": 2038, "ep_reward": 17.56561279296875, "reward": 0.4000343084335327, "action": 0.6958448886871338}
{"mode": "train", "epochs": 2, "timestep": 2039, "ep_reward": 17.962158203125, "reward": 0.3965451717376709, "action": 1.4083300828933716}
{"mode": "train", "epochs": 2, "timestep": 2040, "ep_reward": 18.35003089904785, "reward": 0.38787323236465454, "action": 1.1255557537078857}
{"mode": "train", "epochs": 2, "timestep": 2041, "ep_reward": 18.73648452758789, "reward": 0.3864544630050659, "action": 1.7011370658874512}
{"mode": "train", "epochs": 2, "timestep": 2042, "ep_reward": 19.136964797973633, "reward": 0.4004809856414795, "action": 1.1384756565093994}
{"mode": "train", "epochs": 2, "timestep": 2043, "ep_reward": 19.55438804626465, "reward": 0.4174234867095947, "action": 0.570216178894043}
{"mode": "train", "epochs": 2, "timestep": 2044, "ep_reward": 19.98976707458496, "reward": 0.43537938594818115, "action": 1.5617187023162842}
{"mode": "train", "epochs": 2, "timestep": 2045, "ep_reward": 20.443828582763672, "reward": 0.4540618062019348, "action": 0.7158008813858032}
{"mode": "train", "epochs": 2, "timestep": 2046, "ep_reward": 20.917373657226562, "reward": 0.4735448956489563, "action": 1.0754332542419434}
{"mode": "train", "epochs": 2, "timestep": 2047, "ep_reward": 21.409379959106445, "reward": 0.49200600385665894, "action": 0.7517476677894592}
{"mode": "train", "epochs": 2, "timestep": 2048, "ep_reward": 21.918466567993164, "reward": 0.5090858340263367, "action": 0.8074657917022705}
{"mode": "train", "epochs": 2, "timestep": 2049, "ep_reward": 22.441984176635742, "reward": 0.5235176086425781, "action": 1.417377233505249}
{"mode": "train", "epochs": 2, "timestep": 2050, "ep_reward": 22.9779052734375, "reward": 0.5359219312667847, "action": 0.8563219308853149}
{"mode": "train", "epochs": 2, "timestep": 2051, "ep_reward": 23.523666381835938, "reward": 0.545760452747345, "action": 0.6516121625900269}
{"mode": "train", "epochs": 2, "timestep": 2052, "ep_reward": 24.07513427734375, "reward": 0.5514686703681946, "action": 0.30745160579681396}
{"mode": "train", "epochs": 2, "timestep": 2053, "ep_reward": 24.626676559448242, "reward": 0.5515426993370056, "action": 1.3729568719863892}
{"mode": "train", "epochs": 2, "timestep": 2054, "ep_reward": 25.175722122192383, "reward": 0.5490447282791138, "action": 0.8001049757003784}
{"mode": "train", "epochs": 2, "timestep": 2055, "ep_reward": 25.718135833740234, "reward": 0.5424138307571411, "action": 0.4857495427131653}
{"mode": "train", "epochs": 2, "timestep": 2056, "ep_reward": 26.248865127563477, "reward": 0.5307291150093079, "action": 0.4517076015472412}
{"mode": "train", "epochs": 2, "timestep": 2057, "ep_reward": 26.763029098510742, "reward": 0.5141644477844238, "action": 1.8247954845428467}
{"mode": "train", "epochs": 2, "timestep": 2058, "ep_reward": 27.26294708251953, "reward": 0.4999174475669861, "action": 1.0308876037597656}
{"mode": "train", "epochs": 2, "timestep": 2059, "ep_reward": 27.745702743530273, "reward": 0.48275554180145264, "action": 1.4560757875442505}
{"mode": "train", "epochs": 2, "timestep": 2060, "ep_reward": 28.212446212768555, "reward": 0.4667426347732544, "action": 0.8898493051528931}
{"mode": "train", "epochs": 2, "timestep": 2061, "ep_reward": 28.661453247070312, "reward": 0.44900715351104736, "action": 1.1415987014770508}
{"mode": "train", "epochs": 2, "timestep": 2062, "ep_reward": 29.09398078918457, "reward": 0.43252694606781006, "action": -0.21393537521362305}
{"mode": "train", "epochs": 2, "timestep": 2063, "ep_reward": 29.50493049621582, "reward": 0.4109501838684082, "action": 1.0709493160247803}
{"mode": "train", "epochs": 2, "timestep": 2064, "ep_reward": 29.898590087890625, "reward": 0.39366036653518677, "action": 1.713792324066162}
{"mode": "train", "epochs": 2, "timestep": 2065, "ep_reward": 30.280580520629883, "reward": 0.38199084997177124, "action": 0.6093025207519531}
{"mode": "train", "epochs": 2, "timestep": 2066, "ep_reward": 30.671356201171875, "reward": 0.3907758593559265, "action": 1.642345666885376}
{"mode": "train", "epochs": 2, "timestep": 2067, "ep_reward": 31.071237564086914, "reward": 0.3998810052871704, "action": 0.8274219036102295}
{"mode": "train", "epochs": 2, "timestep": 2068, "ep_reward": 31.475894927978516, "reward": 0.4046570658683777, "action": 0.9031066298484802}
{"mode": "train", "epochs": 2, "timestep": 2069, "ep_reward": 31.8815975189209, "reward": 0.4057018756866455, "action": 0.9671891927719116}
{"mode": "train", "epochs": 2, "timestep": 2070, "ep_reward": 32.28434371948242, "reward": 0.40274709463119507, "action": 0.43921273946762085}
{"mode": "train", "epochs": 2, "timestep": 2071, "ep_reward": 32.681888580322266, "reward": 0.39754384756088257, "action": 0.993595540523529}
{"mode": "train", "epochs": 2, "timestep": 2072, "ep_reward": 33.070350646972656, "reward": 0.3884626030921936, "action": 0.36909228563308716}
{"mode": "train", "epochs": 2, "timestep": 2073, "ep_reward": 33.45510482788086, "reward": 0.3847535252571106, "action": 1.4160796403884888}
{"mode": "train", "epochs": 2, "timestep": 2074, "ep_reward": 33.852088928222656, "reward": 0.3969848155975342, "action": 0.9677701592445374}
{"mode": "train", "epochs": 2, "timestep": 2075, "ep_reward": 34.263763427734375, "reward": 0.41167378425598145, "action": 0.40253525972366333}
{"mode": "train", "epochs": 2, "timestep": 2076, "ep_reward": 34.690860748291016, "reward": 0.42709821462631226, "action": 1.0016355514526367}
{"mode": "train", "epochs": 2, "timestep": 2077, "ep_reward": 35.133506774902344, "reward": 0.44264650344848633, "action": 1.8410253524780273}
{"mode": "train", "epochs": 2, "timestep": 2078, "ep_reward": 35.5933723449707, "reward": 0.4598672389984131, "action": 0.5618866682052612}
{"mode": "train", "epochs": 2, "timestep": 2079, "ep_reward": 36.071266174316406, "reward": 0.4778953194618225, "action": 0.5776470899581909}
{"mode": "train", "epochs": 2, "timestep": 2080, "ep_reward": 36.56514358520508, "reward": 0.4938760995864868, "action": 1.1776459217071533}
{"mode": "train", "epochs": 2, "timestep": 2081, "ep_reward": 37.073326110839844, "reward": 0.5081806182861328, "action": 0.3207857608795166}
{"mode": "train", "epochs": 2, "timestep": 2082, "ep_reward": 37.593135833740234, "reward": 0.5198097229003906, "action": 1.1027110815048218}
{"mode": "train", "epochs": 2, "timestep": 2083, "ep_reward": 38.1216926574707, "reward": 0.5285572409629822, "action": -0.21903729438781738}
{"mode": "train", "epochs": 2, "timestep": 2084, "ep_reward": 38.653778076171875, "reward": 0.5320863723754883, "action": 0.986501932144165}
{"mode": "train", "epochs": 2, "timestep": 2085, "ep_reward": 39.18581771850586, "reward": 0.5320380926132202, "action": 0.98249351978302}
{"mode": "train", "epochs": 2, "timestep": 2086, "ep_reward": 39.71501541137695, "reward": 0.5291988849639893, "action": 0.7259728312492371}
{"mode": "train", "epochs": 2, "timestep": 2087, "ep_reward": 40.23778533935547, "reward": 0.5227683186531067, "action": 0.9282377362251282}
{"mode": "train", "epochs": 2, "timestep": 2088, "ep_reward": 40.75153732299805, "reward": 0.5137531757354736, "action": 0.9159857630729675}
{"mode": "train", "epochs": 2, "timestep": 2089, "ep_reward": 41.25383377075195, "reward": 0.502297580242157, "action": 1.2924610376358032}
{"mode": "train", "epochs": 2, "timestep": 2090, "ep_reward": 41.744144439697266, "reward": 0.49030929803848267, "action": 1.8850409984588623}
{"mode": "train", "epochs": 2, "timestep": 2091, "ep_reward": 42.22469711303711, "reward": 0.48055219650268555, "action": 0.6320232152938843}
{"mode": "train", "epochs": 2, "timestep": 2092, "ep_reward": 42.69193649291992, "reward": 0.46724021434783936, "action": 1.397502064704895}
{"mode": "train", "epochs": 2, "timestep": 2093, "ep_reward": 43.14773178100586, "reward": 0.4557969570159912, "action": 0.7425373792648315}
{"mode": "train", "epochs": 2, "timestep": 2094, "ep_reward": 43.590606689453125, "reward": 0.4428732991218567, "action": 0.20728933811187744}
{"mode": "train", "epochs": 2, "timestep": 2095, "ep_reward": 44.01807403564453, "reward": 0.4274667501449585, "action": 0.9699021577835083}
{"mode": "train", "epochs": 2, "timestep": 2096, "ep_reward": 44.43231201171875, "reward": 0.4142361879348755, "action": 0.9833714365959167}
{"mode": "train", "epochs": 2, "timestep": 2097, "ep_reward": 44.8348274230957, "reward": 0.4025152325630188, "action": 1.5722051858901978}
{"mode": "train", "epochs": 2, "timestep": 2098, "ep_reward": 45.230072021484375, "reward": 0.39524632692337036, "action": 0.9316629767417908}
{"mode": "train", "epochs": 2, "timestep": 2099, "ep_reward": 45.61931610107422, "reward": 0.3892442584037781, "action": 1.2164140939712524}
{"mode": "train", "epochs": 2, "timestep": 2100, "ep_reward": 46.005882263183594, "reward": 0.3865673542022705, "action": 0.9799445867538452}
{"mode": "train", "epochs": 2, "timestep": 2101, "ep_reward": 46.39211654663086, "reward": 0.3862341642379761, "action": 0.9629479646682739}
{"mode": "train", "epochs": 2, "timestep": 2102, "ep_reward": 46.78053283691406, "reward": 0.38841569423675537, "action": 0.34627407789230347}
{"mode": "train", "epochs": 2, "timestep": 2103, "ep_reward": 47.17190170288086, "reward": 0.3913685083389282, "action": 0.11428606510162354}
{"mode": "train", "epochs": 2, "timestep": 2104, "ep_reward": 47.5661506652832, "reward": 0.3942502737045288, "action": 1.5327715873718262}
{"mode": "train", "epochs": 2, "timestep": 2105, "ep_reward": 47.96682357788086, "reward": 0.4006727337837219, "action": 1.277617335319519}
{"mode": "train", "epochs": 2, "timestep": 2106, "ep_reward": 48.37671661376953, "reward": 0.40989410877227783, "action": 0.6676396131515503}
{"mode": "train", "epochs": 2, "timestep": 2107, "ep_reward": 48.79710006713867, "reward": 0.4203844666481018, "action": 0.4928221106529236}
{"mode": "train", "epochs": 2, "timestep": 2108, "ep_reward": 49.228050231933594, "reward": 0.43095076084136963, "action": 1.3148465156555176}
{"mode": "train", "epochs": 2, "timestep": 2109, "ep_reward": 49.67074203491211, "reward": 0.4426933526992798, "action": 0.405460000038147}
{"mode": "train", "epochs": 2, "timestep": 2110, "ep_reward": 50.12507247924805, "reward": 0.454328715801239, "action": 0.41569507122039795}
{"mode": "train", "epochs": 2, "timestep": 2111, "ep_reward": 50.58953094482422, "reward": 0.4644581079483032, "action": 0.35756272077560425}
{"mode": "train", "epochs": 2, "timestep": 2112, "ep_reward": 51.06208419799805, "reward": 0.4725525379180908, "action": 0.7931333780288696}
{"mode": "train", "epochs": 2, "timestep": 2113, "ep_reward": 51.541282653808594, "reward": 0.47919994592666626, "action": 0.8606038689613342}
{"mode": "train", "epochs": 2, "timestep": 2114, "ep_reward": 52.025962829589844, "reward": 0.4846803545951843, "action": 0.8152757287025452}
{"mode": "train", "epochs": 2, "timestep": 2115, "ep_reward": 52.51472473144531, "reward": 0.4887601137161255, "action": 0.022684216499328613}
{"mode": "train", "epochs": 2, "timestep": 2116, "ep_reward": 53.00386047363281, "reward": 0.489135205745697, "action": 0.4880601167678833}
{"mode": "train", "epochs": 2, "timestep": 2117, "ep_reward": 53.490577697753906, "reward": 0.4867178797721863, "action": 0.281491219997406}
{"mode": "train", "epochs": 2, "timestep": 2118, "ep_reward": 53.97145462036133, "reward": 0.4808768630027771, "action": 1.6688464879989624}
{"mode": "train", "epochs": 2, "timestep": 2119, "ep_reward": 54.44841003417969, "reward": 0.4769536852836609, "action": 0.7181931734085083}
{"mode": "train", "epochs": 2, "timestep": 2120, "ep_reward": 54.91939163208008, "reward": 0.4709819555282593, "action": 0.9723814725875854}
{"mode": "train", "epochs": 2, "timestep": 2121, "ep_reward": 55.383914947509766, "reward": 0.46452200412750244, "action": 1.7013169527053833}
{"mode": "train", "epochs": 2, "timestep": 2122, "ep_reward": 55.844329833984375, "reward": 0.4604148864746094, "action": 1.2323228120803833}
{"mode": "train", "epochs": 2, "timestep": 2123, "ep_reward": 56.300941467285156, "reward": 0.4566107988357544, "action": 0.7308322191238403}
{"mode": "train", "epochs": 2, "timestep": 2124, "ep_reward": 56.752769470214844, "reward": 0.45182836055755615, "action": 1.2361074686050415}
{"mode": "train", "epochs": 2, "timestep": 2125, "ep_reward": 57.20106506347656, "reward": 0.44829535484313965, "action": 0.9978465437889099}
{"mode": "train", "epochs": 2, "timestep": 2126, "ep_reward": 57.646141052246094, "reward": 0.4450758099555969, "action": 0.5553860664367676}
{"mode": "train", "epochs": 2, "timestep": 2127, "ep_reward": 58.087093353271484, "reward": 0.44095373153686523, "action": 0.46913284063339233}
{"mode": "train", "epochs": 2, "timestep": 2128, "ep_reward": 58.522884368896484, "reward": 0.4357905387878418, "action": 1.7699865102767944}
{"mode": "train", "epochs": 2, "timestep": 2129, "ep_reward": 58.95738220214844, "reward": 0.4344967007637024, "action": 0.5875126123428345}
{"mode": "train", "epochs": 2, "timestep": 2130, "ep_reward": 59.389793395996094, "reward": 0.4324113130569458, "action": 0.7537972927093506}
{"mode": "train", "epochs": 2, "timestep": 2131, "ep_reward": 59.82046890258789, "reward": 0.43067657947540283, "action": 0.9284189343452454}
{"mode": "train", "epochs": 2, "timestep": 2132, "ep_reward": 60.250282287597656, "reward": 0.42981529235839844, "action": 1.2433252334594727}
{"mode": "train", "epochs": 2, "timestep": 2133, "ep_reward": 60.68103790283203, "reward": 0.4307546019554138, "action": 1.2662971019744873}
{"mode": "train", "epochs": 2, "timestep": 2134, "ep_reward": 61.11437225341797, "reward": 0.4333329200744629, "action": 1.6837842464447021}
{"mode": "train", "epochs": 2, "timestep": 2135, "ep_reward": 61.55305480957031, "reward": 0.4386807084083557, "action": 0.9620459079742432}
{"mode": "train", "epochs": 2, "timestep": 2136, "ep_reward": 61.99790954589844, "reward": 0.44485658407211304, "action": 0.6400447487831116}
{"mode": "train", "epochs": 2, "timestep": 2137, "ep_reward": 62.448604583740234, "reward": 0.4506961703300476, "action": 0.97239750623703}
{"mode": "train", "epochs": 2, "timestep": 2138, "ep_reward": 62.905250549316406, "reward": 0.4566444158554077, "action": 0.6833610534667969}
{"mode": "train", "epochs": 2, "timestep": 2139, "ep_reward": 63.36715316772461, "reward": 0.46190398931503296, "action": 1.1501950025558472}
{"mode": "train", "epochs": 2, "timestep": 2140, "ep_reward": 63.83427047729492, "reward": 0.46711820363998413, "action": 1.9738062620162964}
{"mode": "train", "epochs": 2, "timestep": 2141, "ep_reward": 64.30879974365234, "reward": 0.47453242540359497, "action": 0.0017675161361694336}
{"mode": "train", "epochs": 2, "timestep": 2142, "ep_reward": 64.7884292602539, "reward": 0.4796258807182312, "action": 1.258061170578003}
{"mode": "train", "epochs": 2, "timestep": 2143, "ep_reward": 65.27240753173828, "reward": 0.48397618532180786, "action": 1.4153072834014893}
{"mode": "train", "epochs": 2, "timestep": 2144, "ep_reward": 65.76103210449219, "reward": 0.4886229634284973, "action": 0.4922385811805725}
{"mode": "train", "epochs": 2, "timestep": 2145, "ep_reward": 66.2520980834961, "reward": 0.49106258153915405, "action": 0.8142098784446716}
{"mode": "train", "epochs": 2, "timestep": 2146, "ep_reward": 66.74371337890625, "reward": 0.4916178584098816, "action": 1.2130231857299805}
{"mode": "train", "epochs": 2, "timestep": 2147, "ep_reward": 67.23512268066406, "reward": 0.4914083480834961, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2148, "ep_reward": 67.72816467285156, "reward": 0.4930388927459717, "action": 0.8739169239997864}
{"mode": "train", "epochs": 2, "timestep": 2149, "ep_reward": 68.22119140625, "reward": 0.49302512407302856, "action": 0.814049243927002}
{"mode": "train", "epochs": 2, "timestep": 2150, "ep_reward": 68.71237182617188, "reward": 0.49118363857269287, "action": 1.0427175760269165}
{"mode": "train", "epochs": 2, "timestep": 2151, "ep_reward": 69.20075225830078, "reward": 0.4883790612220764, "action": 0.24017977714538574}
{"mode": "train", "epochs": 2, "timestep": 2152, "ep_reward": 69.6826400756836, "reward": 0.4818844199180603, "action": 1.3070286512374878}
{"mode": "train", "epochs": 2, "timestep": 2153, "ep_reward": 70.15859985351562, "reward": 0.47596073150634766, "action": 1.406779408454895}
{"mode": "train", "epochs": 2, "timestep": 2154, "ep_reward": 70.629150390625, "reward": 0.47055166959762573, "action": 1.7208244800567627}
{"mode": "train", "epochs": 2, "timestep": 2155, "ep_reward": 71.09612274169922, "reward": 0.4669725298881531, "action": 1.3050554990768433}
{"mode": "train", "epochs": 2, "timestep": 2156, "ep_reward": 71.5597152709961, "reward": 0.46359139680862427, "action": 1.6663241386413574}
{"mode": "train", "epochs": 2, "timestep": 2157, "ep_reward": 72.02184295654297, "reward": 0.46212905645370483, "action": 1.0647261142730713}
{"mode": "train", "epochs": 2, "timestep": 2158, "ep_reward": 72.4822769165039, "reward": 0.4604334831237793, "action": 1.4326807260513306}
{"mode": "train", "epochs": 2, "timestep": 2159, "ep_reward": 72.94239044189453, "reward": 0.46011680364608765, "action": 0.2393161654472351}
{"mode": "train", "epochs": 2, "timestep": 2160, "ep_reward": 73.39969635009766, "reward": 0.45730602741241455, "action": 1.2079401016235352}
{"mode": "train", "epochs": 2, "timestep": 2161, "ep_reward": 73.85514831542969, "reward": 0.4554482102394104, "action": 0.9018099308013916}
{"mode": "train", "epochs": 2, "timestep": 2162, "ep_reward": 74.30850982666016, "reward": 0.45336347818374634, "action": 0.8940953016281128}
{"mode": "train", "epochs": 2, "timestep": 2163, "ep_reward": 74.75975799560547, "reward": 0.4512450098991394, "action": 0.529220700263977}
{"mode": "train", "epochs": 2, "timestep": 2164, "ep_reward": 75.20773315429688, "reward": 0.44797635078430176, "action": 0.7800190448760986}
{"mode": "train", "epochs": 2, "timestep": 2165, "ep_reward": 75.6523208618164, "reward": 0.44459033012390137, "action": 0.9288152456283569}
{"mode": "train", "epochs": 2, "timestep": 2166, "ep_reward": 76.0938491821289, "reward": 0.441530704498291, "action": 1.5425100326538086}
{"mode": "train", "epochs": 2, "timestep": 2167, "ep_reward": 76.53472137451172, "reward": 0.4408702254295349, "action": 1.4616742134094238}
{"mode": "train", "epochs": 2, "timestep": 2168, "ep_reward": 76.97677612304688, "reward": 0.4420563578605652, "action": 1.256394386291504}
{"mode": "train", "epochs": 2, "timestep": 2169, "ep_reward": 77.42123413085938, "reward": 0.44445616006851196, "action": 1.4817031621932983}
{"mode": "train", "epochs": 2, "timestep": 2170, "ep_reward": 77.86997985839844, "reward": 0.44874757528305054, "action": 0.6610064506530762}
{"mode": "train", "epochs": 2, "timestep": 2171, "ep_reward": 78.32257843017578, "reward": 0.4525989890098572, "action": 1.3303014039993286}
{"mode": "train", "epochs": 2, "timestep": 2172, "ep_reward": 78.77992248535156, "reward": 0.45734328031539917, "action": 1.6742002964019775}
{"mode": "train", "epochs": 2, "timestep": 2173, "ep_reward": 79.24388122558594, "reward": 0.463961124420166, "action": 0.6089749932289124}
{"mode": "train", "epochs": 2, "timestep": 2174, "ep_reward": 79.7137451171875, "reward": 0.4698665738105774, "action": 0.12281322479248047}
{"mode": "train", "epochs": 2, "timestep": 2175, "ep_reward": 80.18665313720703, "reward": 0.4729052186012268, "action": 1.73073148727417}
{"mode": "train", "epochs": 2, "timestep": 2176, "ep_reward": 80.66375732421875, "reward": 0.4771023988723755, "action": 0.965640127658844}
{"mode": "train", "epochs": 2, "timestep": 2177, "ep_reward": 81.14448547363281, "reward": 0.4807246923446655, "action": 0.9877952337265015}
{"mode": "train", "epochs": 2, "timestep": 2178, "ep_reward": 81.62805938720703, "reward": 0.48357337713241577, "action": 0.4100940227508545}
{"mode": "train", "epochs": 2, "timestep": 2179, "ep_reward": 82.11181640625, "reward": 0.48375946283340454, "action": 1.8178627490997314}
{"mode": "train", "epochs": 2, "timestep": 2180, "ep_reward": 82.59729766845703, "reward": 0.485481858253479, "action": 0.3204054832458496}
{"mode": "train", "epochs": 2, "timestep": 2181, "ep_reward": 83.0814437866211, "reward": 0.48414456844329834, "action": 1.662664771080017}
{"mode": "train", "epochs": 2, "timestep": 2182, "ep_reward": 83.56547546386719, "reward": 0.4840348958969116, "action": 0.4451623558998108}
{"mode": "train", "epochs": 2, "timestep": 2183, "ep_reward": 84.04666900634766, "reward": 0.48119181394577026, "action": 0.8684045076370239}
{"mode": "train", "epochs": 2, "timestep": 2184, "ep_reward": 84.52392578125, "reward": 0.47725504636764526, "action": 0.5660044550895691}
{"mode": "train", "epochs": 2, "timestep": 2185, "ep_reward": 84.9950942993164, "reward": 0.4711717367172241, "action": 1.296004295349121}
{"mode": "train", "epochs": 2, "timestep": 2186, "ep_reward": 85.4610595703125, "reward": 0.46596604585647583, "action": 0.9197139739990234}
{"mode": "train", "epochs": 2, "timestep": 2187, "ep_reward": 85.92107391357422, "reward": 0.46001166105270386, "action": 1.0967730283737183}
{"mode": "train", "epochs": 2, "timestep": 2188, "ep_reward": 86.37541198730469, "reward": 0.45433956384658813, "action": 1.6017109155654907}
{"mode": "train", "epochs": 2, "timestep": 2189, "ep_reward": 86.82638549804688, "reward": 0.4509745240211487, "action": 0.6002768278121948}
{"mode": "train", "epochs": 2, "timestep": 2190, "ep_reward": 87.27236938476562, "reward": 0.4459869861602783, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2191, "ep_reward": 87.71759033203125, "reward": 0.44521886110305786, "action": -0.11604112386703491}
{"mode": "train", "epochs": 2, "timestep": 2192, "ep_reward": 88.15857696533203, "reward": 0.4409855604171753, "action": 0.613520622253418}
{"mode": "train", "epochs": 2, "timestep": 2193, "ep_reward": 88.59505462646484, "reward": 0.4364791512489319, "action": 1.2241268157958984}
{"mode": "train", "epochs": 2, "timestep": 2194, "ep_reward": 89.02890014648438, "reward": 0.4338493347167969, "action": -0.3326725959777832}
{"mode": "train", "epochs": 2, "timestep": 2195, "ep_reward": 89.45648956298828, "reward": 0.4275869131088257, "action": 1.3692901134490967}
{"mode": "train", "epochs": 2, "timestep": 2196, "ep_reward": 89.88095092773438, "reward": 0.4244609475135803, "action": 1.16055428981781}
{"mode": "train", "epochs": 2, "timestep": 2197, "ep_reward": 90.3038558959961, "reward": 0.42290282249450684, "action": 0.889332115650177}
{"mode": "train", "epochs": 2, "timestep": 2198, "ep_reward": 90.72615814208984, "reward": 0.42230600118637085, "action": -0.10350018739700317}
{"mode": "train", "epochs": 2, "timestep": 2199, "ep_reward": 91.14588928222656, "reward": 0.41972845792770386, "action": 0.9280152320861816}
{"mode": "train", "epochs": 2, "timestep": 2200, "ep_reward": 91.56451416015625, "reward": 0.41862672567367554, "action": 1.2508418560028076}
{"mode": "train", "epochs": 2, "timestep": 2201, "ep_reward": 91.9842300415039, "reward": 0.4197174906730652, "action": 1.4533941745758057}
{"mode": "train", "epochs": 2, "timestep": 2202, "ep_reward": 92.4077377319336, "reward": 0.4235045909881592, "action": 0.5054118633270264}
{"mode": "train", "epochs": 2, "timestep": 2203, "ep_reward": 92.83506774902344, "reward": 0.4273304343223572, "action": 0.8290818929672241}
{"mode": "train", "epochs": 2, "timestep": 2204, "ep_reward": 93.2668685913086, "reward": 0.43179887533187866, "action": 0.526975691318512}
{"mode": "train", "epochs": 2, "timestep": 2205, "ep_reward": 93.70295715332031, "reward": 0.43608540296554565, "action": 0.22740912437438965}
{"mode": "train", "epochs": 2, "timestep": 2206, "ep_reward": 94.1421127319336, "reward": 0.43915289640426636, "action": 0.3733624219894409}
{"mode": "train", "epochs": 2, "timestep": 2207, "ep_reward": 94.58324432373047, "reward": 0.44113051891326904, "action": 0.5505465865135193}
{"mode": "train", "epochs": 2, "timestep": 2208, "ep_reward": 95.02560424804688, "reward": 0.44235676527023315, "action": 1.5669457912445068}
{"mode": "train", "epochs": 2, "timestep": 2209, "ep_reward": 95.47132110595703, "reward": 0.4457195997238159, "action": 1.5088908672332764}
{"mode": "train", "epochs": 2, "timestep": 2210, "ep_reward": 95.92215728759766, "reward": 0.4508358836174011, "action": 1.6247875690460205}
{"mode": "train", "epochs": 2, "timestep": 2211, "ep_reward": 96.38011169433594, "reward": 0.45795512199401855, "action": 0.5032697916030884}
{"mode": "train", "epochs": 2, "timestep": 2212, "ep_reward": 96.84442901611328, "reward": 0.46431779861450195, "action": 0.905171275138855}
{"mode": "train", "epochs": 2, "timestep": 2213, "ep_reward": 97.31439208984375, "reward": 0.46996378898620605, "action": 1.1223069429397583}
{"mode": "train", "epochs": 2, "timestep": 2214, "ep_reward": 97.7898178100586, "reward": 0.4754219651222229, "action": 1.3561893701553345}
{"mode": "train", "epochs": 2, "timestep": 2215, "ep_reward": 98.27094268798828, "reward": 0.4811229705810547, "action": 1.5761984586715698}
{"mode": "train", "epochs": 2, "timestep": 2216, "ep_reward": 98.75852966308594, "reward": 0.4875861406326294, "action": 0.8850334882736206}
{"mode": "train", "epochs": 2, "timestep": 2217, "ep_reward": 99.25144958496094, "reward": 0.49291712045669556, "action": 1.7242143154144287}
{"mode": "train", "epochs": 2, "timestep": 2218, "ep_reward": 99.75016021728516, "reward": 0.49870848655700684, "action": 1.1884568929672241}
{"mode": "train", "epochs": 2, "timestep": 2219, "ep_reward": 100.25396728515625, "reward": 0.5038042068481445, "action": 1.235731601715088}
{"mode": "train", "epochs": 2, "timestep": 2220, "ep_reward": 100.76181030273438, "reward": 0.5078400373458862, "action": 1.5850024223327637}
{"mode": "train", "epochs": 2, "timestep": 2221, "ep_reward": 101.27342224121094, "reward": 0.5116105079650879, "action": 1.5450866222381592}
{"mode": "train", "epochs": 2, "timestep": 2222, "ep_reward": 101.7885513305664, "reward": 0.5151273012161255, "action": 0.17200428247451782}
{"mode": "train", "epochs": 2, "timestep": 2223, "ep_reward": 102.30298614501953, "reward": 0.5144358277320862, "action": 1.2479591369628906}
{"mode": "train", "epochs": 2, "timestep": 2224, "ep_reward": 102.81531524658203, "reward": 0.5123284459114075, "action": 0.8283625841140747}
{"mode": "train", "epochs": 2, "timestep": 2225, "ep_reward": 103.32289123535156, "reward": 0.5075735449790955, "action": 1.2011504173278809}
{"mode": "train", "epochs": 2, "timestep": 2226, "ep_reward": 103.82456970214844, "reward": 0.5016767978668213, "action": 1.5134193897247314}
{"mode": "train", "epochs": 2, "timestep": 2227, "ep_reward": 104.320556640625, "reward": 0.49598580598831177, "action": 0.17435556650161743}
{"mode": "train", "epochs": 2, "timestep": 2228, "ep_reward": 104.80592346191406, "reward": 0.48536884784698486, "action": 1.749190330505371}
{"mode": "train", "epochs": 2, "timestep": 2229, "ep_reward": 105.28333282470703, "reward": 0.4774123430252075, "action": 1.0832325220108032}
{"mode": "train", "epochs": 2, "timestep": 2230, "ep_reward": 105.7516098022461, "reward": 0.46827536821365356, "action": 1.1602132320404053}
{"mode": "train", "epochs": 2, "timestep": 2231, "ep_reward": 106.21100616455078, "reward": 0.4593992233276367, "action": 0.19161415100097656}
{"mode": "train", "epochs": 2, "timestep": 2232, "ep_reward": 106.65813446044922, "reward": 0.4471283555030823, "action": 1.0603342056274414}
{"mode": "train", "epochs": 2, "timestep": 2233, "ep_reward": 107.0946273803711, "reward": 0.4364951252937317, "action": 0.28912580013275146}
{"mode": "train", "epochs": 2, "timestep": 2234, "ep_reward": 107.51812744140625, "reward": 0.4235001802444458, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2235, "ep_reward": 107.93502044677734, "reward": 0.41689419746398926, "action": 1.0350837707519531}
{"mode": "train", "epochs": 2, "timestep": 2236, "ep_reward": 108.34577941894531, "reward": 0.41075533628463745, "action": 0.08325004577636719}
{"mode": "train", "epochs": 2, "timestep": 2237, "ep_reward": 108.74879455566406, "reward": 0.4030131697654724, "action": 0.9981526732444763}
{"mode": "train", "epochs": 2, "timestep": 2238, "ep_reward": 109.1468276977539, "reward": 0.39803558588027954, "action": 1.1997469663619995}
{"mode": "train", "epochs": 2, "timestep": 2239, "ep_reward": 109.54264068603516, "reward": 0.3958107829093933, "action": 1.739870548248291}
{"mode": "train", "epochs": 2, "timestep": 2240, "ep_reward": 109.9406967163086, "reward": 0.3980531692504883, "action": 0.9218595027923584}
{"mode": "train", "epochs": 2, "timestep": 2241, "ep_reward": 110.34272766113281, "reward": 0.40203213691711426, "action": 0.7916810512542725}
{"mode": "train", "epochs": 2, "timestep": 2242, "ep_reward": 110.75006103515625, "reward": 0.4073314070701599, "action": 1.8865485191345215}
{"mode": "train", "epochs": 2, "timestep": 2243, "ep_reward": 111.16650390625, "reward": 0.41644060611724854, "action": 1.2501388788223267}
{"mode": "train", "epochs": 2, "timestep": 2244, "ep_reward": 111.59444427490234, "reward": 0.42794251441955566, "action": 1.1472946405410767}
{"mode": "train", "epochs": 2, "timestep": 2245, "ep_reward": 112.03540802001953, "reward": 0.44096338748931885, "action": 1.242456078529358}
{"mode": "train", "epochs": 2, "timestep": 2246, "ep_reward": 112.490478515625, "reward": 0.45506930351257324, "action": 1.4856460094451904}
{"mode": "train", "epochs": 2, "timestep": 2247, "ep_reward": 112.96073913574219, "reward": 0.47026222944259644, "action": 1.2601304054260254}
{"mode": "train", "epochs": 2, "timestep": 2248, "ep_reward": 113.44676208496094, "reward": 0.48602020740509033, "action": 1.1608521938323975}
{"mode": "train", "epochs": 2, "timestep": 2249, "ep_reward": 113.94799041748047, "reward": 0.5012301206588745, "action": 1.7907729148864746}
{"mode": "train", "epochs": 2, "timestep": 2250, "ep_reward": 114.4642333984375, "reward": 0.5162397623062134, "action": 0.8879899978637695}
{"mode": "train", "epochs": 2, "timestep": 2251, "ep_reward": 114.99430084228516, "reward": 0.5300682783126831, "action": 1.4183251857757568}
{"mode": "train", "epochs": 2, "timestep": 2252, "ep_reward": 115.53604888916016, "reward": 0.5417503118515015, "action": 1.066972255706787}
{"mode": "train", "epochs": 2, "timestep": 2253, "ep_reward": 116.08696746826172, "reward": 0.55091792345047, "action": 1.3462445735931396}
{"mode": "train", "epochs": 2, "timestep": 2254, "ep_reward": 116.64437103271484, "reward": 0.5574020147323608, "action": 1.2606879472732544}
{"mode": "train", "epochs": 2, "timestep": 2255, "ep_reward": 117.20539093017578, "reward": 0.5610213279724121, "action": 1.3470677137374878}
{"mode": "train", "epochs": 2, "timestep": 2256, "ep_reward": 117.76705932617188, "reward": 0.5616682767868042, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2257, "ep_reward": 118.32847595214844, "reward": 0.5614173412322998, "action": 1.5810625553131104}
{"mode": "train", "epochs": 2, "timestep": 2258, "ep_reward": 118.88755798339844, "reward": 0.5590842962265015, "action": 1.0469293594360352}
{"mode": "train", "epochs": 2, "timestep": 2259, "ep_reward": 119.44044494628906, "reward": 0.5528879165649414, "action": 1.6160821914672852}
{"mode": "train", "epochs": 2, "timestep": 2260, "ep_reward": 119.98582458496094, "reward": 0.5453829169273376, "action": 0.4086954593658447}
{"mode": "train", "epochs": 2, "timestep": 2261, "ep_reward": 120.517578125, "reward": 0.5317549109458923, "action": 0.91350919008255}
{"mode": "train", "epochs": 2, "timestep": 2262, "ep_reward": 121.03302001953125, "reward": 0.515442967414856, "action": 0.8432276248931885}
{"mode": "train", "epochs": 2, "timestep": 2263, "ep_reward": 121.52920532226562, "reward": 0.4961845874786377, "action": 1.2859073877334595}
{"mode": "train", "epochs": 2, "timestep": 2264, "ep_reward": 122.00633239746094, "reward": 0.4771243929862976, "action": 0.24202340841293335}
{"mode": "train", "epochs": 2, "timestep": 2265, "ep_reward": 122.45915985107422, "reward": 0.4528266191482544, "action": 1.2214888334274292}
{"mode": "train", "epochs": 2, "timestep": 2266, "ep_reward": 122.89048767089844, "reward": 0.4313250184059143, "action": 1.6858634948730469}
{"mode": "train", "epochs": 2, "timestep": 2267, "ep_reward": 123.30436706542969, "reward": 0.41387587785720825, "action": 0.4363899827003479}
{"mode": "train", "epochs": 2, "timestep": 2268, "ep_reward": 123.69805908203125, "reward": 0.39369040727615356, "action": 0.9189410209655762}
{"mode": "train", "epochs": 2, "timestep": 2269, "ep_reward": 124.07647705078125, "reward": 0.3784205913543701, "action": 1.419568657875061}
{"mode": "train", "epochs": 2, "timestep": 2270, "ep_reward": 124.47138977050781, "reward": 0.3949161767959595, "action": 0.6093857288360596}
{"mode": "train", "epochs": 2, "timestep": 2271, "ep_reward": 124.87895965576172, "reward": 0.4075733423233032, "action": 0.8953108787536621}
{"mode": "train", "epochs": 2, "timestep": 2272, "ep_reward": 125.2957763671875, "reward": 0.4168184995651245, "action": 0.6038002967834473}
{"mode": "train", "epochs": 2, "timestep": 2273, "ep_reward": 125.71825408935547, "reward": 0.4224742650985718, "action": 0.5157710313796997}
{"mode": "train", "epochs": 2, "timestep": 2274, "ep_reward": 126.14311981201172, "reward": 0.4248692989349365, "action": 0.3840028643608093}
{"mode": "train", "epochs": 2, "timestep": 2275, "ep_reward": 126.56744384765625, "reward": 0.4243226647377014, "action": 0.5974987745285034}
{"mode": "train", "epochs": 2, "timestep": 2276, "ep_reward": 126.9876708984375, "reward": 0.4202274680137634, "action": 0.8928576707839966}
{"mode": "train", "epochs": 2, "timestep": 2277, "ep_reward": 127.39927673339844, "reward": 0.41160595417022705, "action": 1.3073036670684814}
{"mode": "train", "epochs": 2, "timestep": 2278, "ep_reward": 127.7965087890625, "reward": 0.3972287178039551, "action": 1.03651762008667}
{"mode": "train", "epochs": 2, "timestep": 2279, "ep_reward": 128.17543029785156, "reward": 0.37892770767211914, "action": 0.8920949697494507}
{"mode": "train", "epochs": 2, "timestep": 2280, "ep_reward": 128.57119750976562, "reward": 0.3957679271697998, "action": 1.645930290222168}
{"mode": "train", "epochs": 2, "timestep": 2281, "ep_reward": 128.9869384765625, "reward": 0.4157419800758362, "action": 1.72015380859375}
{"mode": "train", "epochs": 2, "timestep": 2282, "ep_reward": 129.42567443847656, "reward": 0.43873459100723267, "action": 0.9051831364631653}
{"mode": "train", "epochs": 2, "timestep": 2283, "ep_reward": 129.8895263671875, "reward": 0.4638534188270569, "action": 0.8723058700561523}
{"mode": "train", "epochs": 2, "timestep": 2284, "ep_reward": 130.37794494628906, "reward": 0.48841220140457153, "action": 0.8094159364700317}
{"mode": "train", "epochs": 2, "timestep": 2285, "ep_reward": 130.88912963867188, "reward": 0.5111886262893677, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2286, "ep_reward": 131.42138671875, "reward": 0.5322599411010742, "action": 0.6237260699272156}
{"mode": "train", "epochs": 2, "timestep": 2287, "ep_reward": 131.97390747070312, "reward": 0.5525246858596802, "action": 0.21116751432418823}
{"mode": "train", "epochs": 2, "timestep": 2288, "ep_reward": 132.54144287109375, "reward": 0.5675330758094788, "action": -0.0656810998916626}
{"mode": "train", "epochs": 2, "timestep": 2289, "ep_reward": 133.1165008544922, "reward": 0.5750529766082764, "action": 1.494370698928833}
{"mode": "train", "epochs": 2, "timestep": 2290, "ep_reward": 133.69473266601562, "reward": 0.5782308578491211, "action": 0.8224389553070068}
{"mode": "train", "epochs": 2, "timestep": 2291, "ep_reward": 134.27134704589844, "reward": 0.5766186714172363, "action": 0.807530403137207}
{"mode": "train", "epochs": 2, "timestep": 2292, "ep_reward": 134.84112548828125, "reward": 0.5697709321975708, "action": 1.1667811870574951}
{"mode": "train", "epochs": 2, "timestep": 2293, "ep_reward": 135.4004364013672, "reward": 0.5593174695968628, "action": 0.805171012878418}
{"mode": "train", "epochs": 2, "timestep": 2294, "ep_reward": 135.94442749023438, "reward": 0.543992280960083, "action": 0.32601678371429443}
{"mode": "train", "epochs": 2, "timestep": 2295, "ep_reward": 136.4667510986328, "reward": 0.5223273038864136, "action": 0.9998226165771484}
{"mode": "train", "epochs": 2, "timestep": 2296, "ep_reward": 136.9659423828125, "reward": 0.49919843673706055, "action": 0.1554408073425293}
{"mode": "train", "epochs": 2, "timestep": 2297, "ep_reward": 137.43551635742188, "reward": 0.469573974609375, "action": 1.8459482192993164}
{"mode": "train", "epochs": 2, "timestep": 2298, "ep_reward": 137.8818817138672, "reward": 0.4463624358177185, "action": 0.10885447263717651}
{"mode": "train", "epochs": 2, "timestep": 2299, "ep_reward": 138.2980194091797, "reward": 0.41614341735839844, "action": 0.46653711795806885}
{"mode": "train", "epochs": 2, "timestep": 2300, "ep_reward": 138.6847686767578, "reward": 0.38674795627593994, "action": 0.579496443271637}
{"mode": "train", "epochs": 2, "timestep": 2301, "ep_reward": 139.0650634765625, "reward": 0.3802958130836487, "action": 0.6341992616653442}
{"mode": "train", "epochs": 2, "timestep": 2302, "ep_reward": 139.4733428955078, "reward": 0.4082794785499573, "action": 0.8944065570831299}
{"mode": "train", "epochs": 2, "timestep": 2303, "ep_reward": 139.90643310546875, "reward": 0.433083713054657, "action": 0.6464154124259949}
{"mode": "train", "epochs": 2, "timestep": 2304, "ep_reward": 140.35948181152344, "reward": 0.4530482888221741, "action": 1.3208892345428467}
{"mode": "train", "epochs": 2, "timestep": 2305, "ep_reward": 140.82666015625, "reward": 0.4671841859817505, "action": 0.6337155103683472}
{"mode": "train", "epochs": 2, "timestep": 2306, "ep_reward": 141.3011016845703, "reward": 0.47443830966949463, "action": 1.5615260601043701}
{"mode": "train", "epochs": 2, "timestep": 2307, "ep_reward": 141.7744903564453, "reward": 0.47338587045669556, "action": 1.4987986087799072}
{"mode": "train", "epochs": 2, "timestep": 2308, "ep_reward": 142.23744201660156, "reward": 0.4629557728767395, "action": 1.1703423261642456}
{"mode": "train", "epochs": 2, "timestep": 2309, "ep_reward": 142.68234252929688, "reward": 0.44490087032318115, "action": 1.1014307737350464}
{"mode": "train", "epochs": 2, "timestep": 2310, "ep_reward": 143.10264587402344, "reward": 0.4202992916107178, "action": 0.6220465302467346}
{"mode": "train", "epochs": 2, "timestep": 2311, "ep_reward": 143.49525451660156, "reward": 0.3926162123680115, "action": 0.6018462181091309}
{"mode": "train", "epochs": 2, "timestep": 2312, "ep_reward": 143.87326049804688, "reward": 0.3780028820037842, "action": 1.4073452949523926}
{"mode": "train", "epochs": 2, "timestep": 2313, "ep_reward": 144.27896118164062, "reward": 0.4057046175003052, "action": 0.9604499340057373}
{"mode": "train", "epochs": 2, "timestep": 2314, "ep_reward": 144.71498107910156, "reward": 0.4360160231590271, "action": 1.543776273727417}
{"mode": "train", "epochs": 2, "timestep": 2315, "ep_reward": 145.18165588378906, "reward": 0.4666697382926941, "action": 0.9227929711341858}
{"mode": "train", "epochs": 2, "timestep": 2316, "ep_reward": 145.68023681640625, "reward": 0.4985882639884949, "action": 0.4516577124595642}
{"mode": "train", "epochs": 2, "timestep": 2317, "ep_reward": 146.2089385986328, "reward": 0.5287072658538818, "action": 1.1177284717559814}
{"mode": "train", "epochs": 2, "timestep": 2318, "ep_reward": 146.76336669921875, "reward": 0.5544266104698181, "action": 0.8672568798065186}
{"mode": "train", "epochs": 2, "timestep": 2319, "ep_reward": 147.340087890625, "reward": 0.5767251253128052, "action": 0.6913016438484192}
{"mode": "train", "epochs": 2, "timestep": 2320, "ep_reward": 147.93399047851562, "reward": 0.5939040184020996, "action": 0.6986861228942871}
{"mode": "train", "epochs": 2, "timestep": 2321, "ep_reward": 148.53887939453125, "reward": 0.6048833131790161, "action": 0.630123496055603}
{"mode": "train", "epochs": 2, "timestep": 2322, "ep_reward": 149.1477508544922, "reward": 0.6088703870773315, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2323, "ep_reward": 149.7573699951172, "reward": 0.6096208691596985, "action": 0.911711573600769}
{"mode": "train", "epochs": 2, "timestep": 2324, "ep_reward": 150.36199951171875, "reward": 0.6046267151832581, "action": 0.11652344465255737}
{"mode": "train", "epochs": 2, "timestep": 2325, "ep_reward": 150.95254516601562, "reward": 0.590548038482666, "action": 1.6174771785736084}
{"mode": "train", "epochs": 2, "timestep": 2326, "ep_reward": 151.5271453857422, "reward": 0.5745971202850342, "action": 1.0889830589294434}
{"mode": "train", "epochs": 2, "timestep": 2327, "ep_reward": 152.08065795898438, "reward": 0.5535056591033936, "action": 0.7413479089736938}
{"mode": "train", "epochs": 2, "timestep": 2328, "ep_reward": 152.60752868652344, "reward": 0.5268678665161133, "action": 1.3593071699142456}
{"mode": "train", "epochs": 2, "timestep": 2329, "ep_reward": 153.10739135742188, "reward": 0.4998604655265808, "action": 1.0888175964355469}
{"mode": "train", "epochs": 2, "timestep": 2330, "ep_reward": 153.5779571533203, "reward": 0.4705730080604553, "action": 0.4028123617172241}
{"mode": "train", "epochs": 2, "timestep": 2331, "ep_reward": 154.01458740234375, "reward": 0.43663084506988525, "action": 1.3955886363983154}
{"mode": "train", "epochs": 2, "timestep": 2332, "ep_reward": 154.422119140625, "reward": 0.40752601623535156, "action": 1.452722191810608}
{"mode": "train", "epochs": 2, "timestep": 2333, "ep_reward": 154.8037109375, "reward": 0.38159650564193726, "action": 1.147512674331665}
{"mode": "train", "epochs": 2, "timestep": 2334, "ep_reward": 155.1893310546875, "reward": 0.3856227993965149, "action": 0.5624310970306396}
{"mode": "train", "epochs": 2, "timestep": 2335, "ep_reward": 155.60037231445312, "reward": 0.41104573011398315, "action": 1.3279798030853271}
{"mode": "train", "epochs": 2, "timestep": 2336, "ep_reward": 156.03335571289062, "reward": 0.43298161029815674, "action": 1.1093688011169434}
{"mode": "train", "epochs": 2, "timestep": 2337, "ep_reward": 156.48204040527344, "reward": 0.44868403673171997, "action": 0.43786168098449707}
{"mode": "train", "epochs": 2, "timestep": 2338, "ep_reward": 156.94102478027344, "reward": 0.45899128913879395, "action": 1.635096788406372}
{"mode": "train", "epochs": 2, "timestep": 2339, "ep_reward": 157.40325927734375, "reward": 0.4622381925582886, "action": 0.5874694585800171}
{"mode": "train", "epochs": 2, "timestep": 2340, "ep_reward": 157.86256408691406, "reward": 0.4593088626861572, "action": 0.9420201182365417}
{"mode": "train", "epochs": 2, "timestep": 2341, "ep_reward": 158.31265258789062, "reward": 0.45009225606918335, "action": 0.27653825283050537}
{"mode": "train", "epochs": 2, "timestep": 2342, "ep_reward": 158.74998474121094, "reward": 0.4373350143432617, "action": 1.2106775045394897}
{"mode": "train", "epochs": 2, "timestep": 2343, "ep_reward": 159.16741943359375, "reward": 0.41742807626724243, "action": 0.8419055938720703}
{"mode": "train", "epochs": 2, "timestep": 2344, "ep_reward": 159.5608673095703, "reward": 0.39345186948776245, "action": 1.3548574447631836}
{"mode": "train", "epochs": 2, "timestep": 2345, "ep_reward": 159.94073486328125, "reward": 0.3798750042915344, "action": 1.0546718835830688}
{"mode": "train", "epochs": 2, "timestep": 2346, "ep_reward": 160.34690856933594, "reward": 0.4061742424964905, "action": 0.6212989091873169}
{"mode": "train", "epochs": 2, "timestep": 2347, "ep_reward": 160.7811279296875, "reward": 0.4342249035835266, "action": 0.9664415121078491}
{"mode": "train", "epochs": 2, "timestep": 2348, "ep_reward": 161.2430419921875, "reward": 0.46191835403442383, "action": 1.390352487564087}
{"mode": "train", "epochs": 2, "timestep": 2349, "ep_reward": 161.73239135742188, "reward": 0.48934364318847656, "action": 0.08302968740463257}
{"mode": "train", "epochs": 2, "timestep": 2350, "ep_reward": 162.2489013671875, "reward": 0.516503095626831, "action": 0.9993589520454407}
{"mode": "train", "epochs": 2, "timestep": 2351, "ep_reward": 162.78775024414062, "reward": 0.5388421416282654, "action": 1.5233421325683594}
{"mode": "train", "epochs": 2, "timestep": 2352, "ep_reward": 163.3463134765625, "reward": 0.5585585832595825, "action": 0.7440433502197266}
{"mode": "train", "epochs": 2, "timestep": 2353, "ep_reward": 163.92169189453125, "reward": 0.5753709077835083, "action": 0.4101634621620178}
{"mode": "train", "epochs": 2, "timestep": 2354, "ep_reward": 164.50802612304688, "reward": 0.5863378047943115, "action": 1.090909719467163}
{"mode": "train", "epochs": 2, "timestep": 2355, "ep_reward": 165.09970092773438, "reward": 0.5916799306869507, "action": 1.7889184951782227}
{"mode": "train", "epochs": 2, "timestep": 2356, "ep_reward": 165.69369506835938, "reward": 0.593998908996582, "action": 1.5600719451904297}
{"mode": "train", "epochs": 2, "timestep": 2357, "ep_reward": 166.28672790527344, "reward": 0.5930402874946594, "action": 1.4475672245025635}
{"mode": "train", "epochs": 2, "timestep": 2358, "ep_reward": 166.87515258789062, "reward": 0.5884320735931396, "action": 1.0951268672943115}
{"mode": "train", "epochs": 2, "timestep": 2359, "ep_reward": 167.4541778564453, "reward": 0.5790315866470337, "action": 0.9817178249359131}
{"mode": "train", "epochs": 2, "timestep": 2360, "ep_reward": 168.0189208984375, "reward": 0.56473708152771, "action": 1.086364984512329}
{"mode": "train", "epochs": 2, "timestep": 2361, "ep_reward": 168.56541442871094, "reward": 0.5464943051338196, "action": 1.6132457256317139}
{"mode": "train", "epochs": 2, "timestep": 2362, "ep_reward": 169.09298706054688, "reward": 0.5275768041610718, "action": 0.7562234401702881}
{"mode": "train", "epochs": 2, "timestep": 2363, "ep_reward": 169.59619140625, "reward": 0.5032051801681519, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2364, "ep_reward": 170.0791015625, "reward": 0.482913076877594, "action": 0.16087830066680908}
{"mode": "train", "epochs": 2, "timestep": 2365, "ep_reward": 170.5337677001953, "reward": 0.4546642303466797, "action": 0.8369045257568359}
{"mode": "train", "epochs": 2, "timestep": 2366, "ep_reward": 170.96109008789062, "reward": 0.4273281693458557, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2367, "ep_reward": 171.36819458007812, "reward": 0.40710747241973877, "action": 1.4828948974609375}
{"mode": "train", "epochs": 2, "timestep": 2368, "ep_reward": 171.75677490234375, "reward": 0.38858455419540405, "action": 0.7920430898666382}
{"mode": "train", "epochs": 2, "timestep": 2369, "ep_reward": 172.1402130126953, "reward": 0.38344472646713257, "action": 1.2879925966262817}
{"mode": "train", "epochs": 2, "timestep": 2370, "ep_reward": 172.54124450683594, "reward": 0.4010348320007324, "action": 0.8669880628585815}
{"mode": "train", "epochs": 2, "timestep": 2371, "ep_reward": 172.95535278320312, "reward": 0.4141121506690979, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2372, "ep_reward": 173.3763885498047, "reward": 0.421043336391449, "action": 0.6378796100616455}
{"mode": "train", "epochs": 2, "timestep": 2373, "ep_reward": 173.7991485595703, "reward": 0.4227546453475952, "action": 1.602876901626587}
{"mode": "train", "epochs": 2, "timestep": 2374, "ep_reward": 174.2172088623047, "reward": 0.4180542230606079, "action": 0.12692034244537354}
{"mode": "train", "epochs": 2, "timestep": 2375, "ep_reward": 174.62864685058594, "reward": 0.41144049167633057, "action": 1.0933499336242676}
{"mode": "train", "epochs": 2, "timestep": 2376, "ep_reward": 175.02828979492188, "reward": 0.39964091777801514, "action": 1.6087276935577393}
{"mode": "train", "epochs": 2, "timestep": 2377, "ep_reward": 175.40969848632812, "reward": 0.38140225410461426, "action": 0.39665454626083374}
{"mode": "train", "epochs": 2, "timestep": 2378, "ep_reward": 175.80271911621094, "reward": 0.3930181860923767, "action": 0.8408549427986145}
{"mode": "train", "epochs": 2, "timestep": 2379, "ep_reward": 176.21337890625, "reward": 0.4106559753417969, "action": 1.8628828525543213}
{"mode": "train", "epochs": 2, "timestep": 2380, "ep_reward": 176.6439208984375, "reward": 0.43053609132766724, "action": 1.1191259622573853}
{"mode": "train", "epochs": 2, "timestep": 2381, "ep_reward": 177.09690856933594, "reward": 0.452995240688324, "action": 0.30533361434936523}
{"mode": "train", "epochs": 2, "timestep": 2382, "ep_reward": 177.57235717773438, "reward": 0.47544634342193604, "action": 0.44847261905670166}
{"mode": "train", "epochs": 2, "timestep": 2383, "ep_reward": 178.0675048828125, "reward": 0.495151162147522, "action": 1.5780633687973022}
{"mode": "train", "epochs": 2, "timestep": 2384, "ep_reward": 178.58055114746094, "reward": 0.5130494236946106, "action": 0.6307926177978516}
{"mode": "train", "epochs": 2, "timestep": 2385, "ep_reward": 179.10995483398438, "reward": 0.5294082164764404, "action": 1.715577483177185}
{"mode": "train", "epochs": 2, "timestep": 2386, "ep_reward": 179.65341186523438, "reward": 0.5434519052505493, "action": 1.3565007448196411}
{"mode": "train", "epochs": 2, "timestep": 2387, "ep_reward": 180.2093505859375, "reward": 0.5559391975402832, "action": 0.9722616076469421}
{"mode": "train", "epochs": 2, "timestep": 2388, "ep_reward": 180.77450561523438, "reward": 0.5651538372039795, "action": 1.3300185203552246}
{"mode": "train", "epochs": 2, "timestep": 2389, "ep_reward": 181.34556579589844, "reward": 0.5710636973381042, "action": 0.7610222101211548}
{"mode": "train", "epochs": 2, "timestep": 2390, "ep_reward": 181.9178466796875, "reward": 0.5722873210906982, "action": 1.4518111944198608}
{"mode": "train", "epochs": 2, "timestep": 2391, "ep_reward": 182.48834228515625, "reward": 0.57049560546875, "action": 0.1954745054244995}
{"mode": "train", "epochs": 2, "timestep": 2392, "ep_reward": 183.0498504638672, "reward": 0.5615067481994629, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2393, "ep_reward": 183.6027069091797, "reward": 0.5528546571731567, "action": 0.14685678482055664}
{"mode": "train", "epochs": 2, "timestep": 2394, "ep_reward": 184.13877868652344, "reward": 0.5360661745071411, "action": 1.1584370136260986}
{"mode": "train", "epochs": 2, "timestep": 2395, "ep_reward": 184.65667724609375, "reward": 0.5178980231285095, "action": 0.9206555485725403}
{"mode": "train", "epochs": 2, "timestep": 2396, "ep_reward": 185.1533203125, "reward": 0.4966467618942261, "action": 0.9588831663131714}
{"mode": "train", "epochs": 2, "timestep": 2397, "ep_reward": 185.6269989013672, "reward": 0.4736826419830322, "action": 1.2763200998306274}
{"mode": "train", "epochs": 2, "timestep": 2398, "ep_reward": 186.07862854003906, "reward": 0.45162391662597656, "action": 0.3146686553955078}
{"mode": "train", "epochs": 2, "timestep": 2399, "ep_reward": 186.5039825439453, "reward": 0.4253581762313843, "action": 1.2496341466903687}
{"mode": "train", "epochs": 2, "timestep": 2400, "ep_reward": 186.90731811523438, "reward": 0.40333491563796997, "action": 0.5025829076766968}
{"mode": "train", "epochs": 2, "timestep": 2401, "ep_reward": 187.28726196289062, "reward": 0.37994956970214844, "action": 1.2820652723312378}
{"mode": "train", "epochs": 2, "timestep": 2402, "ep_reward": 187.6777801513672, "reward": 0.39051353931427, "action": 0.249875009059906}
{"mode": "train", "epochs": 2, "timestep": 2403, "ep_reward": 188.08779907226562, "reward": 0.4100263714790344, "action": 0.8835194706916809}
{"mode": "train", "epochs": 2, "timestep": 2404, "ep_reward": 188.5147705078125, "reward": 0.4269784092903137, "action": 0.07982689142227173}
{"mode": "train", "epochs": 2, "timestep": 2405, "ep_reward": 188.95530700683594, "reward": 0.4405295252799988, "action": 0.5470267534255981}
{"mode": "train", "epochs": 2, "timestep": 2406, "ep_reward": 189.40606689453125, "reward": 0.4507632851600647, "action": 0.3819747567176819}
{"mode": "train", "epochs": 2, "timestep": 2407, "ep_reward": 189.86279296875, "reward": 0.4567252993583679, "action": 1.5110535621643066}
{"mode": "train", "epochs": 2, "timestep": 2408, "ep_reward": 190.31838989257812, "reward": 0.45559072494506836, "action": 0.8394278287887573}
{"mode": "train", "epochs": 2, "timestep": 2409, "ep_reward": 190.76646423339844, "reward": 0.44807517528533936, "action": 1.639615774154663}
{"mode": "train", "epochs": 2, "timestep": 2410, "ep_reward": 191.1984100341797, "reward": 0.43195152282714844, "action": 0.7715137600898743}
{"mode": "train", "epochs": 2, "timestep": 2411, "ep_reward": 191.6100311279297, "reward": 0.41162413358688354, "action": 1.080721139907837}
{"mode": "train", "epochs": 2, "timestep": 2412, "ep_reward": 191.99581909179688, "reward": 0.3857842683792114, "action": 1.5788357257843018}
{"mode": "train", "epochs": 2, "timestep": 2413, "ep_reward": 192.38259887695312, "reward": 0.38678544759750366, "action": 0.6739085912704468}
{"mode": "train", "epochs": 2, "timestep": 2414, "ep_reward": 192.7968292236328, "reward": 0.4142254590988159, "action": 1.561588168144226}
{"mode": "train", "epochs": 2, "timestep": 2415, "ep_reward": 193.23904418945312, "reward": 0.4422212839126587, "action": 1.1831239461898804}
{"mode": "train", "epochs": 2, "timestep": 2416, "ep_reward": 193.7109832763672, "reward": 0.47193658351898193, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2417, "ep_reward": 194.2123565673828, "reward": 0.5013749003410339, "action": 0.4046403765678406}
{"mode": "train", "epochs": 2, "timestep": 2418, "ep_reward": 194.7446746826172, "reward": 0.5323238372802734, "action": 1.0163170099258423}
{"mode": "train", "epochs": 2, "timestep": 2419, "ep_reward": 195.30319213867188, "reward": 0.5585198402404785, "action": 0.8156430721282959}
{"mode": "train", "epochs": 2, "timestep": 2420, "ep_reward": 195.88401794433594, "reward": 0.5808193683624268, "action": 0.8386794328689575}
{"mode": "train", "epochs": 2, "timestep": 2421, "ep_reward": 196.48179626464844, "reward": 0.5977773666381836, "action": 1.2956883907318115}
{"mode": "train", "epochs": 2, "timestep": 2422, "ep_reward": 197.0912322998047, "reward": 0.6094413995742798, "action": 1.6805461645126343}
{"mode": "train", "epochs": 2, "timestep": 2423, "ep_reward": 197.70840454101562, "reward": 0.6171698570251465, "action": 0.8215252757072449}
{"mode": "train", "epochs": 2, "timestep": 2424, "ep_reward": 198.3274688720703, "reward": 0.6190671920776367, "action": 1.547438144683838}
{"mode": "train", "epochs": 2, "timestep": 2425, "ep_reward": 198.94386291503906, "reward": 0.6163948774337769, "action": 0.5682773590087891}
{"mode": "train", "epochs": 2, "timestep": 2426, "ep_reward": 199.5499725341797, "reward": 0.6061115264892578, "action": 1.0340890884399414}
{"mode": "train", "epochs": 2, "timestep": 2427, "ep_reward": 200.1402587890625, "reward": 0.5902934670448303, "action": 1.290397047996521}
{"mode": "train", "epochs": 2, "timestep": 2428, "ep_reward": 200.7107696533203, "reward": 0.5705092549324036, "action": 0.6560297608375549}
{"mode": "train", "epochs": 2, "timestep": 2429, "ep_reward": 201.25462341308594, "reward": 0.5438477993011475, "action": 0.44620001316070557}
{"mode": "train", "epochs": 2, "timestep": 2430, "ep_reward": 201.765625, "reward": 0.5109988451004028, "action": 1.3416444063186646}
{"mode": "train", "epochs": 2, "timestep": 2431, "ep_reward": 202.24484252929688, "reward": 0.47921109199523926, "action": 1.5506411790847778}
{"mode": "train", "epochs": 2, "timestep": 2432, "ep_reward": 202.69346618652344, "reward": 0.4486263394355774, "action": 1.2493385076522827}
{"mode": "train", "epochs": 2, "timestep": 2433, "ep_reward": 203.11117553710938, "reward": 0.41770291328430176, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2434, "ep_reward": 203.5045623779297, "reward": 0.3933801054954529, "action": 1.6134614944458008}
{"mode": "train", "epochs": 2, "timestep": 2435, "ep_reward": 203.8781280517578, "reward": 0.3735589385032654, "action": 0.5197513103485107}
{"mode": "train", "epochs": 2, "timestep": 2436, "ep_reward": 204.27645874023438, "reward": 0.3983355760574341, "action": 1.3173288106918335}
{"mode": "train", "epochs": 2, "timestep": 2437, "ep_reward": 204.69667053222656, "reward": 0.4202042818069458, "action": 1.3474925756454468}
{"mode": "train", "epochs": 2, "timestep": 2438, "ep_reward": 205.13279724121094, "reward": 0.436129093170166, "action": 0.8189032673835754}
{"mode": "train", "epochs": 2, "timestep": 2439, "ep_reward": 205.5789794921875, "reward": 0.4461851716041565, "action": 1.173722743988037}
{"mode": "train", "epochs": 2, "timestep": 2440, "ep_reward": 206.02914428710938, "reward": 0.4501592516899109, "action": 0.968166172504425}
{"mode": "train", "epochs": 2, "timestep": 2441, "ep_reward": 206.47708129882812, "reward": 0.44793206453323364, "action": 0.25874191522598267}
{"mode": "train", "epochs": 2, "timestep": 2442, "ep_reward": 206.9191436767578, "reward": 0.44206881523132324, "action": 0.557184100151062}
{"mode": "train", "epochs": 2, "timestep": 2443, "ep_reward": 207.3510284423828, "reward": 0.43189066648483276, "action": 0.6966614723205566}
{"mode": "train", "epochs": 2, "timestep": 2444, "ep_reward": 207.7681427001953, "reward": 0.41710907220840454, "action": 1.8075895309448242}
{"mode": "train", "epochs": 2, "timestep": 2445, "ep_reward": 208.16175842285156, "reward": 0.39361971616744995, "action": 1.2740439176559448}
{"mode": "train", "epochs": 2, "timestep": 2446, "ep_reward": 208.542236328125, "reward": 0.3804779648780823, "action": 1.0387426614761353}
{"mode": "train", "epochs": 2, "timestep": 2447, "ep_reward": 208.9473419189453, "reward": 0.4051017165184021, "action": 1.506284475326538}
{"mode": "train", "epochs": 2, "timestep": 2448, "ep_reward": 209.37899780273438, "reward": 0.43166273832321167, "action": 0.7916303873062134}
{"mode": "train", "epochs": 2, "timestep": 2449, "ep_reward": 209.83917236328125, "reward": 0.4601806402206421, "action": 1.6901463270187378}
{"mode": "train", "epochs": 2, "timestep": 2450, "ep_reward": 210.32704162597656, "reward": 0.48787635564804077, "action": 1.30283522605896}
{"mode": "train", "epochs": 2, "timestep": 2451, "ep_reward": 210.84332275390625, "reward": 0.5162835121154785, "action": 0.9545811414718628}
{"mode": "train", "epochs": 2, "timestep": 2452, "ep_reward": 211.386474609375, "reward": 0.5431486964225769, "action": 1.8054897785186768}
{"mode": "train", "epochs": 2, "timestep": 2453, "ep_reward": 211.9534149169922, "reward": 0.5669400691986084, "action": -0.2039981484413147}
{"mode": "train", "epochs": 2, "timestep": 2454, "ep_reward": 212.5413818359375, "reward": 0.58797287940979, "action": 1.0283042192459106}
{"mode": "train", "epochs": 2, "timestep": 2455, "ep_reward": 213.1427459716797, "reward": 0.601361870765686, "action": 0.3158051371574402}
{"mode": "train", "epochs": 2, "timestep": 2456, "ep_reward": 213.7508544921875, "reward": 0.6081076264381409, "action": 0.6941206455230713}
{"mode": "train", "epochs": 2, "timestep": 2457, "ep_reward": 214.3583984375, "reward": 0.6075489521026611, "action": 1.3334494829177856}
{"mode": "train", "epochs": 2, "timestep": 2458, "ep_reward": 214.96060180664062, "reward": 0.6022065877914429, "action": 1.101527214050293}
{"mode": "train", "epochs": 2, "timestep": 2459, "ep_reward": 215.55218505859375, "reward": 0.5915862321853638, "action": 0.8692580461502075}
{"mode": "train", "epochs": 2, "timestep": 2460, "ep_reward": 216.12716674804688, "reward": 0.5749801397323608, "action": 1.5129737854003906}
{"mode": "train", "epochs": 2, "timestep": 2461, "ep_reward": 216.68344116210938, "reward": 0.5562717914581299, "action": 0.8918827176094055}
{"mode": "train", "epochs": 2, "timestep": 2462, "ep_reward": 217.21556091308594, "reward": 0.5321142673492432, "action": 0.8217601776123047}
{"mode": "train", "epochs": 2, "timestep": 2463, "ep_reward": 217.7195281982422, "reward": 0.5039608478546143, "action": 1.5491929054260254}
{"mode": "train", "epochs": 2, "timestep": 2464, "ep_reward": 218.1969451904297, "reward": 0.4774131178855896, "action": 0.8154205679893494}
{"mode": "train", "epochs": 2, "timestep": 2465, "ep_reward": 218.64418029785156, "reward": 0.4472346901893616, "action": 1.2242274284362793}
{"mode": "train", "epochs": 2, "timestep": 2466, "ep_reward": 219.0631866455078, "reward": 0.419009804725647, "action": 1.8198816776275635}
{"mode": "train", "epochs": 2, "timestep": 2467, "ep_reward": 219.4595184326172, "reward": 0.39633214473724365, "action": 0.34361743927001953}
{"mode": "train", "epochs": 2, "timestep": 2468, "ep_reward": 219.83265686035156, "reward": 0.37313520908355713, "action": 0.378598690032959}
{"mode": "train", "epochs": 2, "timestep": 2469, "ep_reward": 220.23211669921875, "reward": 0.39945900440216064, "action": 0.5971466302871704}
{"mode": "train", "epochs": 2, "timestep": 2470, "ep_reward": 220.65586853027344, "reward": 0.42375272512435913, "action": 0.9291921257972717}
{"mode": "train", "epochs": 2, "timestep": 2471, "ep_reward": 221.10008239746094, "reward": 0.4442114233970642, "action": 0.7532377243041992}
{"mode": "train", "epochs": 2, "timestep": 2472, "ep_reward": 221.55943298339844, "reward": 0.4593501687049866, "action": 0.21734559535980225}
{"mode": "train", "epochs": 2, "timestep": 2473, "ep_reward": 222.02902221679688, "reward": 0.4695914387702942, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2474, "ep_reward": 222.50079345703125, "reward": 0.47177839279174805, "action": 1.0202505588531494}
{"mode": "train", "epochs": 2, "timestep": 2475, "ep_reward": 222.96649169921875, "reward": 0.46570056676864624, "action": 1.0252608060836792}
{"mode": "train", "epochs": 2, "timestep": 2476, "ep_reward": 223.41891479492188, "reward": 0.4524294137954712, "action": 1.4685871601104736}
{"mode": "train", "epochs": 2, "timestep": 2477, "ep_reward": 223.84947204589844, "reward": 0.4305512309074402, "action": 1.5981245040893555}
{"mode": "train", "epochs": 2, "timestep": 2478, "ep_reward": 224.2500457763672, "reward": 0.4005711078643799, "action": 0.9817377328872681}
{"mode": "train", "epochs": 2, "timestep": 2479, "ep_reward": 224.61978149414062, "reward": 0.36973536014556885, "action": 0.8241119980812073}
{"mode": "train", "epochs": 2, "timestep": 2480, "ep_reward": 225.01893615722656, "reward": 0.3991577625274658, "action": 1.3508516550064087}
{"mode": "train", "epochs": 2, "timestep": 2481, "ep_reward": 225.4487762451172, "reward": 0.429834246635437, "action": 1.1861498355865479}
{"mode": "train", "epochs": 2, "timestep": 2482, "ep_reward": 225.9110870361328, "reward": 0.46231257915496826, "action": 0.5233949422836304}
{"mode": "train", "epochs": 2, "timestep": 2483, "ep_reward": 226.40631103515625, "reward": 0.49522334337234497, "action": 1.2986938953399658}
{"mode": "train", "epochs": 2, "timestep": 2484, "ep_reward": 226.93128967285156, "reward": 0.5249719619750977, "action": 0.99100261926651}
{"mode": "train", "epochs": 2, "timestep": 2485, "ep_reward": 227.48426818847656, "reward": 0.5529800653457642, "action": 1.201190710067749}
{"mode": "train", "epochs": 2, "timestep": 2486, "ep_reward": 228.06158447265625, "reward": 0.5773171186447144, "action": 1.1250489950180054}
{"mode": "train", "epochs": 2, "timestep": 2487, "ep_reward": 228.6593017578125, "reward": 0.5977246761322021, "action": 0.627590537071228}
{"mode": "train", "epochs": 2, "timestep": 2488, "ep_reward": 229.2719268798828, "reward": 0.6126271486282349, "action": 1.2961757183074951}
{"mode": "train", "epochs": 2, "timestep": 2489, "ep_reward": 229.89337158203125, "reward": 0.6214491128921509, "action": 1.3941174745559692}
{"mode": "train", "epochs": 2, "timestep": 2490, "ep_reward": 230.51870727539062, "reward": 0.6253379583358765, "action": 1.021520733833313}
{"mode": "train", "epochs": 2, "timestep": 2491, "ep_reward": 231.14193725585938, "reward": 0.6232345104217529, "action": 0.6970358490943909}
{"mode": "train", "epochs": 2, "timestep": 2492, "ep_reward": 231.7555694580078, "reward": 0.6136363744735718, "action": 1.5273466110229492}
{"mode": "train", "epochs": 2, "timestep": 2493, "ep_reward": 232.35585021972656, "reward": 0.6002852916717529, "action": -0.23239833116531372}
{"mode": "train", "epochs": 2, "timestep": 2494, "ep_reward": 232.93089294433594, "reward": 0.575035810470581, "action": 0.3982788920402527}
{"mode": "train", "epochs": 2, "timestep": 2495, "ep_reward": 233.47445678710938, "reward": 0.5435599088668823, "action": 0.8244266510009766}
{"mode": "train", "epochs": 2, "timestep": 2496, "ep_reward": 233.98313903808594, "reward": 0.5086782574653625, "action": 0.8384081721305847}
{"mode": "train", "epochs": 2, "timestep": 2497, "ep_reward": 234.45396423339844, "reward": 0.47082167863845825, "action": 0.8227710127830505}
{"mode": "train", "epochs": 2, "timestep": 2498, "ep_reward": 234.88539123535156, "reward": 0.4314286708831787, "action": 0.17936193943023682}
{"mode": "train", "epochs": 2, "timestep": 2499, "ep_reward": 235.2730712890625, "reward": 0.38768458366394043, "action": 0.615847110748291}
{"mode": "train", "epochs": 2, "timestep": 2500, "ep_reward": 235.6351318359375, "reward": 0.36205756664276123, "action": 1.5471153259277344}
{"mode": "train", "epochs": 2, "timestep": 2501, "ep_reward": 236.03964233398438, "reward": 0.40451663732528687, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2502, "ep_reward": 236.48062133789062, "reward": 0.44098228216171265, "action": 1.319014549255371}
{"mode": "train", "epochs": 2, "timestep": 2503, "ep_reward": 236.94857788085938, "reward": 0.4679597020149231, "action": 1.3526848554611206}
{"mode": "train", "epochs": 2, "timestep": 2504, "ep_reward": 237.4353485107422, "reward": 0.48677271604537964, "action": 0.6260415315628052}
{"mode": "train", "epochs": 2, "timestep": 2505, "ep_reward": 237.93292236328125, "reward": 0.4975748658180237, "action": 0.8685329556465149}
{"mode": "train", "epochs": 2, "timestep": 2506, "ep_reward": 238.4338836669922, "reward": 0.5009664297103882, "action": 0.35409408807754517}
{"mode": "train", "epochs": 2, "timestep": 2507, "ep_reward": 238.93167114257812, "reward": 0.4977877736091614, "action": 0.9148368239402771}
{"mode": "train", "epochs": 2, "timestep": 2508, "ep_reward": 239.41822814941406, "reward": 0.4865533113479614, "action": 1.5048680305480957}
{"mode": "train", "epochs": 2, "timestep": 2509, "ep_reward": 239.88333129882812, "reward": 0.46510058641433716, "action": 0.7687045335769653}
{"mode": "train", "epochs": 2, "timestep": 2510, "ep_reward": 240.3213348388672, "reward": 0.43800872564315796, "action": 0.43743693828582764}
{"mode": "train", "epochs": 2, "timestep": 2511, "ep_reward": 240.72877502441406, "reward": 0.40743792057037354, "action": 1.1332364082336426}
{"mode": "train", "epochs": 2, "timestep": 2512, "ep_reward": 241.09878540039062, "reward": 0.3700135350227356, "action": 1.2406989336013794}
{"mode": "train", "epochs": 2, "timestep": 2513, "ep_reward": 241.49143981933594, "reward": 0.39265626668930054, "action": 0.26280057430267334}
{"mode": "train", "epochs": 2, "timestep": 2514, "ep_reward": 241.91970825195312, "reward": 0.42826831340789795, "action": 0.765217661857605}
{"mode": "train", "epochs": 2, "timestep": 2515, "ep_reward": 242.38194274902344, "reward": 0.4622420072555542, "action": 1.7326953411102295}
{"mode": "train", "epochs": 2, "timestep": 2516, "ep_reward": 242.87657165527344, "reward": 0.49462413787841797, "action": 1.3471077680587769}
{"mode": "train", "epochs": 2, "timestep": 2517, "ep_reward": 243.40426635742188, "reward": 0.5277012586593628, "action": 1.1341801881790161}
{"mode": "train", "epochs": 2, "timestep": 2518, "ep_reward": 243.96328735351562, "reward": 0.5590204000473022, "action": 1.6068353652954102}
{"mode": "train", "epochs": 2, "timestep": 2519, "ep_reward": 244.54994201660156, "reward": 0.5866563320159912, "action": 1.525712013244629}
{"mode": "train", "epochs": 2, "timestep": 2520, "ep_reward": 245.16122436523438, "reward": 0.6112799644470215, "action": 0.6788210868835449}
{"mode": "train", "epochs": 2, "timestep": 2521, "ep_reward": 245.79234313964844, "reward": 0.6311240196228027, "action": 1.850096344947815}
{"mode": "train", "epochs": 2, "timestep": 2522, "ep_reward": 246.43714904785156, "reward": 0.6447992920875549, "action": 0.042684972286224365}
{"mode": "train", "epochs": 2, "timestep": 2523, "ep_reward": 247.08839416503906, "reward": 0.6512448191642761, "action": 0.38817161321640015}
{"mode": "train", "epochs": 2, "timestep": 2524, "ep_reward": 247.73599243164062, "reward": 0.6475940346717834, "action": 0.23436814546585083}
{"mode": "train", "epochs": 2, "timestep": 2525, "ep_reward": 248.36972045898438, "reward": 0.6337331533432007, "action": 0.1429920792579651}
{"mode": "train", "epochs": 2, "timestep": 2526, "ep_reward": 248.97903442382812, "reward": 0.6093132495880127, "action": 1.6203839778900146}
{"mode": "train", "epochs": 2, "timestep": 2527, "ep_reward": 249.5623321533203, "reward": 0.5833029747009277, "action": 0.8090396523475647}
{"mode": "train", "epochs": 2, "timestep": 2528, "ep_reward": 250.11154174804688, "reward": 0.5492148399353027, "action": 1.3878545761108398}
{"mode": "train", "epochs": 2, "timestep": 2529, "ep_reward": 250.6255340576172, "reward": 0.5139948129653931, "action": 0.6241245269775391}
{"mode": "train", "epochs": 2, "timestep": 2530, "ep_reward": 251.09771728515625, "reward": 0.4721860885620117, "action": 0.6191930174827576}
{"mode": "train", "epochs": 2, "timestep": 2531, "ep_reward": 251.5255889892578, "reward": 0.42786818742752075, "action": 1.4797132015228271}
{"mode": "train", "epochs": 2, "timestep": 2532, "ep_reward": 251.91482543945312, "reward": 0.38923895359039307, "action": 1.3718953132629395}
{"mode": "train", "epochs": 2, "timestep": 2533, "ep_reward": 252.2755889892578, "reward": 0.3607661724090576, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2534, "ep_reward": 252.67713928222656, "reward": 0.40154576301574707, "action": 0.8105978965759277}
{"mode": "train", "epochs": 2, "timestep": 2535, "ep_reward": 253.11146545410156, "reward": 0.4343242645263672, "action": 0.7829219102859497}
{"mode": "train", "epochs": 2, "timestep": 2536, "ep_reward": 253.57374572753906, "reward": 0.46228164434432983, "action": 0.987108588218689}
{"mode": "train", "epochs": 2, "timestep": 2537, "ep_reward": 254.0579071044922, "reward": 0.4841594099998474, "action": 1.217502474784851}
{"mode": "train", "epochs": 2, "timestep": 2538, "ep_reward": 254.5559844970703, "reward": 0.49808019399642944, "action": 1.056601881980896}
{"mode": "train", "epochs": 2, "timestep": 2539, "ep_reward": 255.05914306640625, "reward": 0.5031538009643555, "action": 0.17921662330627441}
{"mode": "train", "epochs": 2, "timestep": 2540, "ep_reward": 255.5609588623047, "reward": 0.5018180012702942, "action": 0.24080491065979004}
{"mode": "train", "epochs": 2, "timestep": 2541, "ep_reward": 256.0556335449219, "reward": 0.49468159675598145, "action": 1.270965814590454}
{"mode": "train", "epochs": 2, "timestep": 2542, "ep_reward": 256.53375244140625, "reward": 0.47811800241470337, "action": 0.6984032392501831}
{"mode": "train", "epochs": 2, "timestep": 2543, "ep_reward": 256.9890441894531, "reward": 0.4553057551383972, "action": 0.5679703950881958}
{"mode": "train", "epochs": 2, "timestep": 2544, "ep_reward": 257.4165344238281, "reward": 0.42749518156051636, "action": 0.3897223472595215}
{"mode": "train", "epochs": 2, "timestep": 2545, "ep_reward": 257.8131408691406, "reward": 0.3966018557548523, "action": 1.004599690437317}
{"mode": "train", "epochs": 2, "timestep": 2546, "ep_reward": 258.1842346191406, "reward": 0.37108367681503296, "action": 0.3340846300125122}
{"mode": "train", "epochs": 2, "timestep": 2547, "ep_reward": 258.5875549316406, "reward": 0.4033339023590088, "action": 0.38509273529052734}
{"mode": "train", "epochs": 2, "timestep": 2548, "ep_reward": 259.02313232421875, "reward": 0.4355628490447998, "action": 0.04789614677429199}
{"mode": "train", "epochs": 2, "timestep": 2549, "ep_reward": 259.4897766113281, "reward": 0.46664756536483765, "action": 1.742951512336731}
{"mode": "train", "epochs": 2, "timestep": 2550, "ep_reward": 259.9841003417969, "reward": 0.49431437253952026, "action": 1.749915361404419}
{"mode": "train", "epochs": 2, "timestep": 2551, "ep_reward": 260.5067443847656, "reward": 0.5226307511329651, "action": 0.2169933319091797}
{"mode": "train", "epochs": 2, "timestep": 2552, "ep_reward": 261.0574645996094, "reward": 0.5507074594497681, "action": 0.7382466793060303}
{"mode": "train", "epochs": 2, "timestep": 2553, "ep_reward": 261.6303405761719, "reward": 0.5728657841682434, "action": 0.5045450925827026}
{"mode": "train", "epochs": 2, "timestep": 2554, "ep_reward": 262.2198791503906, "reward": 0.5895463228225708, "action": 0.7506936192512512}
{"mode": "train", "epochs": 2, "timestep": 2555, "ep_reward": 262.8197937011719, "reward": 0.5999045372009277, "action": 0.7602967023849487}
{"mode": "train", "epochs": 2, "timestep": 2556, "ep_reward": 263.4238586425781, "reward": 0.6040747165679932, "action": -0.1846368908882141}
{"mode": "train", "epochs": 2, "timestep": 2557, "ep_reward": 264.02301025390625, "reward": 0.5991569757461548, "action": 0.6235920190811157}
{"mode": "train", "epochs": 2, "timestep": 2558, "ep_reward": 264.61004638671875, "reward": 0.5870381593704224, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2559, "ep_reward": 265.1844177246094, "reward": 0.574385404586792, "action": 1.0866529941558838}
{"mode": "train", "epochs": 2, "timestep": 2560, "ep_reward": 265.7406921386719, "reward": 0.5562718510627747, "action": 0.8747209906578064}
{"mode": "train", "epochs": 2, "timestep": 2561, "ep_reward": 266.27410888671875, "reward": 0.533428430557251, "action": 0.7173672318458557}
{"mode": "train", "epochs": 2, "timestep": 2562, "ep_reward": 266.7803039550781, "reward": 0.5061897039413452, "action": 0.39910709857940674}
{"mode": "train", "epochs": 2, "timestep": 2563, "ep_reward": 267.2541809082031, "reward": 0.47386491298675537, "action": 1.8735618591308594}
{"mode": "train", "epochs": 2, "timestep": 2564, "ep_reward": 267.70184326171875, "reward": 0.4476523995399475, "action": 1.0251872539520264}
{"mode": "train", "epochs": 2, "timestep": 2565, "ep_reward": 268.1209716796875, "reward": 0.4191162586212158, "action": 1.0479475259780884}
{"mode": "train", "epochs": 2, "timestep": 2566, "ep_reward": 268.5129089355469, "reward": 0.39192479848861694, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2567, "ep_reward": 268.8878173828125, "reward": 0.37490516901016235, "action": 0.7665520906448364}
{"mode": "train", "epochs": 2, "timestep": 2568, "ep_reward": 269.2857666015625, "reward": 0.3979488015174866, "action": 1.4912595748901367}
{"mode": "train", "epochs": 2, "timestep": 2569, "ep_reward": 269.7030944824219, "reward": 0.41732317209243774, "action": -0.04465126991271973}
{"mode": "train", "epochs": 2, "timestep": 2570, "ep_reward": 270.1353454589844, "reward": 0.4322599172592163, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2571, "ep_reward": 270.5774841308594, "reward": 0.4421425461769104, "action": 0.8404484987258911}
{"mode": "train", "epochs": 2, "timestep": 2572, "ep_reward": 271.0226135253906, "reward": 0.4451281428337097, "action": 1.0211249589920044}
{"mode": "train", "epochs": 2, "timestep": 2573, "ep_reward": 271.46490478515625, "reward": 0.4422810673713684, "action": -0.4304026961326599}
{"mode": "train", "epochs": 2, "timestep": 2574, "ep_reward": 271.9031982421875, "reward": 0.4382861256599426, "action": 1.14204740524292}
{"mode": "train", "epochs": 2, "timestep": 2575, "ep_reward": 272.3311462402344, "reward": 0.4279518723487854, "action": 1.4368863105773926}
{"mode": "train", "epochs": 2, "timestep": 2576, "ep_reward": 272.7417297363281, "reward": 0.4105865955352783, "action": 1.0771377086639404}
{"mode": "train", "epochs": 2, "timestep": 2577, "ep_reward": 273.13037109375, "reward": 0.3886285424232483, "action": 0.6906589269638062}
{"mode": "train", "epochs": 2, "timestep": 2578, "ep_reward": 273.5155334472656, "reward": 0.38514816761016846, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2579, "ep_reward": 273.9237060546875, "reward": 0.40817445516586304, "action": 0.7732563018798828}
{"mode": "train", "epochs": 2, "timestep": 2580, "ep_reward": 274.3585205078125, "reward": 0.43480896949768066, "action": 1.187483787536621}
{"mode": "train", "epochs": 2, "timestep": 2581, "ep_reward": 274.82012939453125, "reward": 0.46161597967147827, "action": 0.9051568508148193}
{"mode": "train", "epochs": 2, "timestep": 2582, "ep_reward": 275.30877685546875, "reward": 0.4886578321456909, "action": 0.9602513909339905}
{"mode": "train", "epochs": 2, "timestep": 2583, "ep_reward": 275.8229675292969, "reward": 0.5141927599906921, "action": 1.124901294708252}
{"mode": "train", "epochs": 2, "timestep": 2584, "ep_reward": 276.36053466796875, "reward": 0.5375648736953735, "action": 0.4657025933265686}
{"mode": "train", "epochs": 2, "timestep": 2585, "ep_reward": 276.9183654785156, "reward": 0.5578289031982422, "action": 1.0576813220977783}
{"mode": "train", "epochs": 2, "timestep": 2586, "ep_reward": 277.4916076660156, "reward": 0.5732274651527405, "action": 0.8861479759216309}
{"mode": "train", "epochs": 2, "timestep": 2587, "ep_reward": 278.07574462890625, "reward": 0.5841217041015625, "action": 1.454877495765686}
{"mode": "train", "epochs": 2, "timestep": 2588, "ep_reward": 278.666748046875, "reward": 0.5910167694091797, "action": 1.1706464290618896}
{"mode": "train", "epochs": 2, "timestep": 2589, "ep_reward": 279.2605285644531, "reward": 0.5937716960906982, "action": 0.2585439085960388}
{"mode": "train", "epochs": 2, "timestep": 2590, "ep_reward": 279.849609375, "reward": 0.5890864133834839, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2591, "ep_reward": 280.4325256347656, "reward": 0.5829198360443115, "action": 0.9849359393119812}
{"mode": "train", "epochs": 2, "timestep": 2592, "ep_reward": 281.0037841796875, "reward": 0.571255087852478, "action": 1.3531118631362915}
{"mode": "train", "epochs": 2, "timestep": 2593, "ep_reward": 281.5603942871094, "reward": 0.5565956830978394, "action": 1.3837757110595703}
{"mode": "train", "epochs": 2, "timestep": 2594, "ep_reward": 282.0997009277344, "reward": 0.5392962694168091, "action": 1.2163387537002563}
{"mode": "train", "epochs": 2, "timestep": 2595, "ep_reward": 282.61883544921875, "reward": 0.5191292762756348, "action": 1.1711835861206055}
{"mode": "train", "epochs": 2, "timestep": 2596, "ep_reward": 283.1158142089844, "reward": 0.49697643518447876, "action": 0.18324583768844604}
{"mode": "train", "epochs": 2, "timestep": 2597, "ep_reward": 283.584228515625, "reward": 0.4684104323387146, "action": 1.0613784790039062}
{"mode": "train", "epochs": 2, "timestep": 2598, "ep_reward": 284.025634765625, "reward": 0.44140779972076416, "action": 1.9925258159637451}
{"mode": "train", "epochs": 2, "timestep": 2599, "ep_reward": 284.4460144042969, "reward": 0.4203898310661316, "action": 1.2077419757843018}
{"mode": "train", "epochs": 2, "timestep": 2600, "ep_reward": 284.8450622558594, "reward": 0.3990371823310852, "action": 1.4601893424987793}
{"mode": "train", "epochs": 2, "timestep": 2601, "ep_reward": 285.226806640625, "reward": 0.38174307346343994, "action": 0.5089001655578613}
{"mode": "train", "epochs": 2, "timestep": 2602, "ep_reward": 285.61767578125, "reward": 0.39087235927581787, "action": 1.390693187713623}
{"mode": "train", "epochs": 2, "timestep": 2603, "ep_reward": 286.02496337890625, "reward": 0.4072856903076172, "action": 0.681557297706604}
{"mode": "train", "epochs": 2, "timestep": 2604, "ep_reward": 286.4442138671875, "reward": 0.41925495862960815, "action": 1.0274972915649414}
{"mode": "train", "epochs": 2, "timestep": 2605, "ep_reward": 286.8710021972656, "reward": 0.42678362131118774, "action": 1.6873064041137695}
{"mode": "train", "epochs": 2, "timestep": 2606, "ep_reward": 287.298583984375, "reward": 0.42757171392440796, "action": 0.4653548002243042}
{"mode": "train", "epochs": 2, "timestep": 2607, "ep_reward": 287.7228698730469, "reward": 0.4242958426475525, "action": 1.2262417078018188}
{"mode": "train", "epochs": 2, "timestep": 2608, "ep_reward": 288.1380310058594, "reward": 0.41515588760375977, "action": 1.7449086904525757}
{"mode": "train", "epochs": 2, "timestep": 2609, "ep_reward": 288.5365295410156, "reward": 0.3985024094581604, "action": 0.627369225025177}
{"mode": "train", "epochs": 2, "timestep": 2610, "ep_reward": 288.91656494140625, "reward": 0.38004130125045776, "action": 0.058206379413604736}
{"mode": "train", "epochs": 2, "timestep": 2611, "ep_reward": 289.31036376953125, "reward": 0.3937838077545166, "action": 1.0640085935592651}
{"mode": "train", "epochs": 2, "timestep": 2612, "ep_reward": 289.72222900390625, "reward": 0.41187161207199097, "action": 1.2125844955444336}
{"mode": "train", "epochs": 2, "timestep": 2613, "ep_reward": 290.1540222167969, "reward": 0.4317784309387207, "action": 1.3332993984222412}
{"mode": "train", "epochs": 2, "timestep": 2614, "ep_reward": 290.6070556640625, "reward": 0.4530457854270935, "action": 1.864138126373291}
{"mode": "train", "epochs": 2, "timestep": 2615, "ep_reward": 291.082763671875, "reward": 0.4756927490234375, "action": 0.550337016582489}
{"mode": "train", "epochs": 2, "timestep": 2616, "ep_reward": 291.5820007324219, "reward": 0.4992240071296692, "action": 1.7262980937957764}
{"mode": "train", "epochs": 2, "timestep": 2617, "ep_reward": 292.1025695800781, "reward": 0.5205655097961426, "action": 1.3806908130645752}
{"mode": "train", "epochs": 2, "timestep": 2618, "ep_reward": 292.64404296875, "reward": 0.541464626789093, "action": 0.5079959034919739}
{"mode": "train", "epochs": 2, "timestep": 2619, "ep_reward": 293.2037048339844, "reward": 0.5596528649330139, "action": 0.37264591455459595}
{"mode": "train", "epochs": 2, "timestep": 2620, "ep_reward": 293.77581787109375, "reward": 0.5721208453178406, "action": 1.1172964572906494}
{"mode": "train", "epochs": 2, "timestep": 2621, "ep_reward": 294.35528564453125, "reward": 0.5794706344604492, "action": 1.638727068901062}
{"mode": "train", "epochs": 2, "timestep": 2622, "ep_reward": 294.939208984375, "reward": 0.5839112997055054, "action": 0.6768187284469604}
{"mode": "train", "epochs": 2, "timestep": 2623, "ep_reward": 295.5223083496094, "reward": 0.5831096172332764, "action": 0.9732996821403503}
{"mode": "train", "epochs": 2, "timestep": 2624, "ep_reward": 296.09967041015625, "reward": 0.5773680210113525, "action": 0.7317209243774414}
{"mode": "train", "epochs": 2, "timestep": 2625, "ep_reward": 296.6656799316406, "reward": 0.5660171508789062, "action": 0.8865450620651245}
{"mode": "train", "epochs": 2, "timestep": 2626, "ep_reward": 297.2157897949219, "reward": 0.5501167178153992, "action": 1.0743471384048462}
{"mode": "train", "epochs": 2, "timestep": 2627, "ep_reward": 297.74676513671875, "reward": 0.5309674739837646, "action": 1.314235806465149}
{"mode": "train", "epochs": 2, "timestep": 2628, "ep_reward": 298.2569885253906, "reward": 0.5102232694625854, "action": 1.448072910308838}
{"mode": "train", "epochs": 2, "timestep": 2629, "ep_reward": 298.7460021972656, "reward": 0.4890183210372925, "action": 0.9836074113845825}
{"mode": "train", "epochs": 2, "timestep": 2630, "ep_reward": 299.21142578125, "reward": 0.4654349088668823, "action": 0.8519385457038879}
{"mode": "train", "epochs": 2, "timestep": 2631, "ep_reward": 299.652099609375, "reward": 0.4406589865684509, "action": 1.1691380739212036}
{"mode": "train", "epochs": 2, "timestep": 2632, "ep_reward": 300.06988525390625, "reward": 0.4177934527397156, "action": 0.2455064058303833}
{"mode": "train", "epochs": 2, "timestep": 2633, "ep_reward": 300.4617919921875, "reward": 0.3919132947921753, "action": 0.24754178524017334}
{"mode": "train", "epochs": 2, "timestep": 2634, "ep_reward": 300.8402404785156, "reward": 0.37843483686447144, "action": 0.5984553694725037}
{"mode": "train", "epochs": 2, "timestep": 2635, "ep_reward": 301.2436828613281, "reward": 0.40343642234802246, "action": 0.8990110158920288}
{"mode": "train", "epochs": 2, "timestep": 2636, "ep_reward": 301.66912841796875, "reward": 0.42545920610427856, "action": 1.0201141834259033}
{"mode": "train", "epochs": 2, "timestep": 2637, "ep_reward": 302.1117858886719, "reward": 0.44266796112060547, "action": 1.0372364521026611}
{"mode": "train", "epochs": 2, "timestep": 2638, "ep_reward": 302.5658264160156, "reward": 0.4540313482284546, "action": 0.5644141435623169}
{"mode": "train", "epochs": 2, "timestep": 2639, "ep_reward": 303.0257263183594, "reward": 0.45989298820495605, "action": 1.3660893440246582}
{"mode": "train", "epochs": 2, "timestep": 2640, "ep_reward": 303.484375, "reward": 0.4586455225944519, "action": 1.1434872150421143}
{"mode": "train", "epochs": 2, "timestep": 2641, "ep_reward": 303.9344787597656, "reward": 0.450115442276001, "action": 0.7034910917282104}
{"mode": "train", "epochs": 2, "timestep": 2642, "ep_reward": 304.3708190917969, "reward": 0.43633103370666504, "action": 1.5245659351348877}
{"mode": "train", "epochs": 2, "timestep": 2643, "ep_reward": 304.7851867675781, "reward": 0.4143545627593994, "action": 0.7766677141189575}
{"mode": "train", "epochs": 2, "timestep": 2644, "ep_reward": 305.17437744140625, "reward": 0.389202356338501, "action": 0.8584117293357849}
{"mode": "train", "epochs": 2, "timestep": 2645, "ep_reward": 305.5576477050781, "reward": 0.38327890634536743, "action": 0.9676076173782349}
{"mode": "train", "epochs": 2, "timestep": 2646, "ep_reward": 305.9668273925781, "reward": 0.4091797471046448, "action": 0.2797333002090454}
{"mode": "train", "epochs": 2, "timestep": 2647, "ep_reward": 306.40313720703125, "reward": 0.43630772829055786, "action": 1.7654507160186768}
{"mode": "train", "epochs": 2, "timestep": 2648, "ep_reward": 306.8656005859375, "reward": 0.46247398853302, "action": 0.6555131673812866}
{"mode": "train", "epochs": 2, "timestep": 2649, "ep_reward": 307.3559875488281, "reward": 0.4903731942176819, "action": 0.48582524061203003}
{"mode": "train", "epochs": 2, "timestep": 2650, "ep_reward": 307.8719177246094, "reward": 0.5159398317337036, "action": 0.6490086317062378}
{"mode": "train", "epochs": 2, "timestep": 2651, "ep_reward": 308.4096984863281, "reward": 0.5377867817878723, "action": 0.6935855150222778}
{"mode": "train", "epochs": 2, "timestep": 2652, "ep_reward": 308.9652099609375, "reward": 0.5555154085159302, "action": 1.001905083656311}
{"mode": "train", "epochs": 2, "timestep": 2653, "ep_reward": 309.5342102050781, "reward": 0.5690110325813293, "action": 0.669533371925354}
{"mode": "train", "epochs": 2, "timestep": 2654, "ep_reward": 310.1117858886719, "reward": 0.5775628685951233, "action": 1.9174522161483765}
{"mode": "train", "epochs": 2, "timestep": 2655, "ep_reward": 310.6950378417969, "reward": 0.5832486748695374, "action": 1.5692346096038818}
{"mode": "train", "epochs": 2, "timestep": 2656, "ep_reward": 311.2813415527344, "reward": 0.5863098502159119, "action": 0.9054856300354004}
{"mode": "train", "epochs": 2, "timestep": 2657, "ep_reward": 311.8658447265625, "reward": 0.5844946503639221, "action": 1.1554839611053467}
{"mode": "train", "epochs": 2, "timestep": 2658, "ep_reward": 312.4442138671875, "reward": 0.5783637762069702, "action": 0.7115001678466797}
{"mode": "train", "epochs": 2, "timestep": 2659, "ep_reward": 313.01055908203125, "reward": 0.5663527846336365, "action": 1.4221965074539185}
{"mode": "train", "epochs": 2, "timestep": 2660, "ep_reward": 313.5627136230469, "reward": 0.5521659255027771, "action": 0.44962286949157715}
{"mode": "train", "epochs": 2, "timestep": 2661, "ep_reward": 314.0937194824219, "reward": 0.5310192108154297, "action": 1.7000322341918945}
{"mode": "train", "epochs": 2, "timestep": 2662, "ep_reward": 314.6051330566406, "reward": 0.5114047527313232, "action": -0.2603899836540222}
{"mode": "train", "epochs": 2, "timestep": 2663, "ep_reward": 315.086669921875, "reward": 0.4815499782562256, "action": 0.8423115611076355}
{"mode": "train", "epochs": 2, "timestep": 2664, "ep_reward": 315.53924560546875, "reward": 0.45256859064102173, "action": 1.0115971565246582}
{"mode": "train", "epochs": 2, "timestep": 2665, "ep_reward": 315.9633483886719, "reward": 0.4241132140159607, "action": 1.0226351022720337}
{"mode": "train", "epochs": 2, "timestep": 2666, "ep_reward": 316.3602600097656, "reward": 0.3968997597694397, "action": 0.9305656552314758}
{"mode": "train", "epochs": 2, "timestep": 2667, "ep_reward": 316.73162841796875, "reward": 0.37138235569000244, "action": 1.0357924699783325}
{"mode": "train", "epochs": 2, "timestep": 2668, "ep_reward": 317.1286926269531, "reward": 0.3970504403114319, "action": 1.5869390964508057}
{"mode": "train", "epochs": 2, "timestep": 2669, "ep_reward": 317.5480041503906, "reward": 0.41930460929870605, "action": 0.9612029790878296}
{"mode": "train", "epochs": 2, "timestep": 2670, "ep_reward": 317.9834899902344, "reward": 0.4354751706123352, "action": 0.6401195526123047}
{"mode": "train", "epochs": 2, "timestep": 2671, "ep_reward": 318.4303283691406, "reward": 0.4468286633491516, "action": 1.1547489166259766}
{"mode": "train", "epochs": 2, "timestep": 2672, "ep_reward": 318.8827209472656, "reward": 0.4523969292640686, "action": 1.211026668548584}
{"mode": "train", "epochs": 2, "timestep": 2673, "ep_reward": 319.3337097167969, "reward": 0.4509906768798828, "action": 0.7422106266021729}
{"mode": "train", "epochs": 2, "timestep": 2674, "ep_reward": 319.7778015136719, "reward": 0.4441002607345581, "action": 0.17729425430297852}
{"mode": "train", "epochs": 2, "timestep": 2675, "ep_reward": 320.2120666503906, "reward": 0.4342723488807678, "action": 0.5318732261657715}
{"mode": "train", "epochs": 2, "timestep": 2676, "ep_reward": 320.6324462890625, "reward": 0.4203656315803528, "action": 0.6889220476150513}
{"mode": "train", "epochs": 2, "timestep": 2677, "ep_reward": 321.03485107421875, "reward": 0.4023897051811218, "action": 1.2174195051193237}
{"mode": "train", "epochs": 2, "timestep": 2678, "ep_reward": 321.4136047363281, "reward": 0.37876832485198975, "action": 1.0814876556396484}
{"mode": "train", "epochs": 2, "timestep": 2679, "ep_reward": 321.8083801269531, "reward": 0.3947780132293701, "action": 0.3431198000907898}
{"mode": "train", "epochs": 2, "timestep": 2680, "ep_reward": 322.2269287109375, "reward": 0.4185370206832886, "action": 0.7554118037223816}
{"mode": "train", "epochs": 2, "timestep": 2681, "ep_reward": 322.66900634765625, "reward": 0.44207799434661865, "action": 0.5873477458953857}
{"mode": "train", "epochs": 2, "timestep": 2682, "ep_reward": 323.1343688964844, "reward": 0.46535563468933105, "action": 0.8797640204429626}
{"mode": "train", "epochs": 2, "timestep": 2683, "ep_reward": 323.62152099609375, "reward": 0.4871572256088257, "action": 1.8208866119384766}
{"mode": "train", "epochs": 2, "timestep": 2684, "ep_reward": 324.1297302246094, "reward": 0.5082069635391235, "action": 0.9798843264579773}
{"mode": "train", "epochs": 2, "timestep": 2685, "ep_reward": 324.6589050292969, "reward": 0.529168963432312, "action": 0.05763518810272217}
{"mode": "train", "epochs": 2, "timestep": 2686, "ep_reward": 325.2054138183594, "reward": 0.5465006828308105, "action": 0.8427590131759644}
{"mode": "train", "epochs": 2, "timestep": 2687, "ep_reward": 325.763916015625, "reward": 0.5585149526596069, "action": 0.791297972202301}
{"mode": "train", "epochs": 2, "timestep": 2688, "ep_reward": 326.3300476074219, "reward": 0.5661359429359436, "action": 0.9585439562797546}
{"mode": "train", "epochs": 2, "timestep": 2689, "ep_reward": 326.8994445800781, "reward": 0.5694026350975037, "action": 0.7669783234596252}
{"mode": "train", "epochs": 2, "timestep": 2690, "ep_reward": 327.4672546386719, "reward": 0.5677959322929382, "action": 0.738000214099884}
{"mode": "train", "epochs": 2, "timestep": 2691, "ep_reward": 328.02838134765625, "reward": 0.5611391067504883, "action": 0.4944901466369629}
{"mode": "train", "epochs": 2, "timestep": 2692, "ep_reward": 328.5770568847656, "reward": 0.5486716032028198, "action": 0.8436156511306763}
{"mode": "train", "epochs": 2, "timestep": 2693, "ep_reward": 329.10931396484375, "reward": 0.5322686433792114, "action": 1.6808885335922241}
{"mode": "train", "epochs": 2, "timestep": 2694, "ep_reward": 329.6255798339844, "reward": 0.5162712931632996, "action": 1.2916003465652466}
{"mode": "train", "epochs": 2, "timestep": 2695, "ep_reward": 330.1238098144531, "reward": 0.49822908639907837, "action": 0.7840235829353333}
{"mode": "train", "epochs": 2, "timestep": 2696, "ep_reward": 330.6007080078125, "reward": 0.4769127368927002, "action": 1.3305330276489258}
{"mode": "train", "epochs": 2, "timestep": 2697, "ep_reward": 331.0575866699219, "reward": 0.45686691999435425, "action": 1.3105705976486206}
{"mode": "train", "epochs": 2, "timestep": 2698, "ep_reward": 331.4952697753906, "reward": 0.43767422437667847, "action": 0.9789475202560425}
{"mode": "train", "epochs": 2, "timestep": 2699, "ep_reward": 331.9136962890625, "reward": 0.41841381788253784, "action": 1.0648248195648193}
{"mode": "train", "epochs": 2, "timestep": 2700, "ep_reward": 332.3146667480469, "reward": 0.4009813070297241, "action": 0.8746155500411987}
{"mode": "train", "epochs": 2, "timestep": 2701, "ep_reward": 332.6995849609375, "reward": 0.38493216037750244, "action": 0.673710823059082}
{"mode": "train", "epochs": 2, "timestep": 2702, "ep_reward": 333.0876770019531, "reward": 0.3880768418312073, "action": 0.010689258575439453}
{"mode": "train", "epochs": 2, "timestep": 2703, "ep_reward": 333.4908447265625, "reward": 0.403181254863739, "action": 0.8428555727005005}
{"mode": "train", "epochs": 2, "timestep": 2704, "ep_reward": 333.9069519042969, "reward": 0.4161032438278198, "action": 1.2740943431854248}
{"mode": "train", "epochs": 2, "timestep": 2705, "ep_reward": 334.3310852050781, "reward": 0.42412662506103516, "action": 1.159885287284851}
{"mode": "train", "epochs": 2, "timestep": 2706, "ep_reward": 334.7575988769531, "reward": 0.42650896310806274, "action": 0.3464553952217102}
{"mode": "train", "epochs": 2, "timestep": 2707, "ep_reward": 335.1830749511719, "reward": 0.4254780411720276, "action": 1.3507542610168457}
{"mode": "train", "epochs": 2, "timestep": 2708, "ep_reward": 335.6015625, "reward": 0.4184808135032654, "action": 0.9111179709434509}
{"mode": "train", "epochs": 2, "timestep": 2709, "ep_reward": 336.008544921875, "reward": 0.4069739580154419, "action": 0.9467369318008423}
{"mode": "train", "epochs": 2, "timestep": 2710, "ep_reward": 336.39984130859375, "reward": 0.3912944197654724, "action": 0.6290152072906494}
{"mode": "train", "epochs": 2, "timestep": 2711, "ep_reward": 336.7833251953125, "reward": 0.38348573446273804, "action": 1.9632070064544678}
{"mode": "train", "epochs": 2, "timestep": 2712, "ep_reward": 337.18536376953125, "reward": 0.4020480513572693, "action": 1.4614992141723633}
{"mode": "train", "epochs": 2, "timestep": 2713, "ep_reward": 337.609619140625, "reward": 0.4242604970932007, "action": 1.2984492778778076}
{"mode": "train", "epochs": 2, "timestep": 2714, "ep_reward": 338.0582580566406, "reward": 0.4486303925514221, "action": 1.0949212312698364}
{"mode": "train", "epochs": 2, "timestep": 2715, "ep_reward": 338.5322265625, "reward": 0.4739609360694885, "action": 1.0099902153015137}
{"mode": "train", "epochs": 2, "timestep": 2716, "ep_reward": 339.0310974121094, "reward": 0.4988582730293274, "action": 1.0055395364761353}
{"mode": "train", "epochs": 2, "timestep": 2717, "ep_reward": 339.5532531738281, "reward": 0.5221704840660095, "action": 1.2319724559783936}
{"mode": "train", "epochs": 2, "timestep": 2718, "ep_reward": 340.096435546875, "reward": 0.5431818962097168, "action": 1.208211064338684}
{"mode": "train", "epochs": 2, "timestep": 2719, "ep_reward": 340.6580810546875, "reward": 0.5616586208343506, "action": 1.1130647659301758}
{"mode": "train", "epochs": 2, "timestep": 2720, "ep_reward": 341.23486328125, "reward": 0.5767954587936401, "action": 0.8128467798233032}
{"mode": "train", "epochs": 2, "timestep": 2721, "ep_reward": 341.82220458984375, "reward": 0.5873546600341797, "action": 0.8028824925422668}
{"mode": "train", "epochs": 2, "timestep": 2722, "ep_reward": 342.41455078125, "reward": 0.5923476219177246, "action": 0.9708170890808105}
{"mode": "train", "epochs": 2, "timestep": 2723, "ep_reward": 343.0065612792969, "reward": 0.5920169949531555, "action": 0.7738069295883179}
{"mode": "train", "epochs": 2, "timestep": 2724, "ep_reward": 343.5924072265625, "reward": 0.5858566164970398, "action": 0.5140600800514221}
{"mode": "train", "epochs": 2, "timestep": 2725, "ep_reward": 344.1654052734375, "reward": 0.5729872584342957, "action": -0.21007460355758667}
{"mode": "train", "epochs": 2, "timestep": 2726, "ep_reward": 344.7159729003906, "reward": 0.5505598783493042, "action": 1.027768611907959}
{"mode": "train", "epochs": 2, "timestep": 2727, "ep_reward": 345.2421569824219, "reward": 0.5261932611465454, "action": 1.248277187347412}
{"mode": "train", "epochs": 2, "timestep": 2728, "ep_reward": 345.74224853515625, "reward": 0.500084638595581, "action": 1.8315480947494507}
{"mode": "train", "epochs": 2, "timestep": 2729, "ep_reward": 346.2184753417969, "reward": 0.47622597217559814, "action": 1.1146697998046875}
{"mode": "train", "epochs": 2, "timestep": 2730, "ep_reward": 346.66827392578125, "reward": 0.44978559017181396, "action": 1.7283515930175781}
{"mode": "train", "epochs": 2, "timestep": 2731, "ep_reward": 347.09564208984375, "reward": 0.42736750841140747, "action": 0.931014358997345}
{"mode": "train", "epochs": 2, "timestep": 2732, "ep_reward": 347.4992980957031, "reward": 0.40366828441619873, "action": 0.8486043214797974}
{"mode": "train", "epochs": 2, "timestep": 2733, "ep_reward": 347.8806457519531, "reward": 0.3813436031341553, "action": 0.2279266119003296}
{"mode": "train", "epochs": 2, "timestep": 2734, "ep_reward": 348.2705993652344, "reward": 0.3899468779563904, "action": 1.896215558052063}
{"mode": "train", "epochs": 2, "timestep": 2735, "ep_reward": 348.681640625, "reward": 0.4110453128814697, "action": 1.0634881258010864}
{"mode": "train", "epochs": 2, "timestep": 2736, "ep_reward": 349.10723876953125, "reward": 0.4256121516227722, "action": 1.002914309501648}
{"mode": "train", "epochs": 2, "timestep": 2737, "ep_reward": 349.542236328125, "reward": 0.4350091814994812, "action": 1.1896659135818481}
{"mode": "train", "epochs": 2, "timestep": 2738, "ep_reward": 349.98065185546875, "reward": 0.4384077787399292, "action": 1.6536602973937988}
{"mode": "train", "epochs": 2, "timestep": 2739, "ep_reward": 350.4146423339844, "reward": 0.43399274349212646, "action": 1.8738102912902832}
{"mode": "train", "epochs": 2, "timestep": 2740, "ep_reward": 350.8354187011719, "reward": 0.4207885265350342, "action": 0.9824768900871277}
{"mode": "train", "epochs": 2, "timestep": 2741, "ep_reward": 351.2381896972656, "reward": 0.4027560353279114, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2742, "ep_reward": 351.614013671875, "reward": 0.3758201599121094, "action": 0.6273268461227417}
{"mode": "train", "epochs": 2, "timestep": 2743, "ep_reward": 352.0104064941406, "reward": 0.3963918685913086, "action": 1.0759412050247192}
{"mode": "train", "epochs": 2, "timestep": 2744, "ep_reward": 352.4313049316406, "reward": 0.4209120273590088, "action": 0.8115309476852417}
{"mode": "train", "epochs": 2, "timestep": 2745, "ep_reward": 352.8780212402344, "reward": 0.44671404361724854, "action": 1.1362661123275757}
{"mode": "train", "epochs": 2, "timestep": 2746, "ep_reward": 353.3503723144531, "reward": 0.4723637104034424, "action": 1.1777021884918213}
{"mode": "train", "epochs": 2, "timestep": 2747, "ep_reward": 353.84820556640625, "reward": 0.4978354573249817, "action": 0.46946460008621216}
{"mode": "train", "epochs": 2, "timestep": 2748, "ep_reward": 354.3702087402344, "reward": 0.5220047235488892, "action": 1.085015058517456}
{"mode": "train", "epochs": 2, "timestep": 2749, "ep_reward": 354.9127502441406, "reward": 0.5425376892089844, "action": 0.5188988447189331}
{"mode": "train", "epochs": 2, "timestep": 2750, "ep_reward": 355.4722900390625, "reward": 0.5595481395721436, "action": 1.1671448945999146}
{"mode": "train", "epochs": 2, "timestep": 2751, "ep_reward": 356.0444030761719, "reward": 0.5721173286437988, "action": 0.5593539476394653}
{"mode": "train", "epochs": 2, "timestep": 2752, "ep_reward": 356.6241760253906, "reward": 0.5797661542892456, "action": 1.2375746965408325}
{"mode": "train", "epochs": 2, "timestep": 2753, "ep_reward": 357.2071533203125, "reward": 0.582979142665863, "action": 0.19538754224777222}
{"mode": "train", "epochs": 2, "timestep": 2754, "ep_reward": 357.7864685058594, "reward": 0.579308032989502, "action": 0.6303366422653198}
{"mode": "train", "epochs": 2, "timestep": 2755, "ep_reward": 358.3560485839844, "reward": 0.5695774555206299, "action": 0.9314098954200745}
{"mode": "train", "epochs": 2, "timestep": 2756, "ep_reward": 358.91143798828125, "reward": 0.5554037094116211, "action": 0.9902649521827698}
{"mode": "train", "epochs": 2, "timestep": 2757, "ep_reward": 359.4488525390625, "reward": 0.5374162197113037, "action": 0.6741540431976318}
{"mode": "train", "epochs": 2, "timestep": 2758, "ep_reward": 359.9635314941406, "reward": 0.51466965675354, "action": 0.3345392942428589}
{"mode": "train", "epochs": 2, "timestep": 2759, "ep_reward": 360.4501647949219, "reward": 0.4866189956665039, "action": 1.051185131072998}
{"mode": "train", "epochs": 2, "timestep": 2760, "ep_reward": 360.9093322753906, "reward": 0.4591543674468994, "action": 0.6068872213363647}
{"mode": "train", "epochs": 2, "timestep": 2761, "ep_reward": 361.3384094238281, "reward": 0.4290887713432312, "action": -0.041598498821258545}
{"mode": "train", "epochs": 2, "timestep": 2762, "ep_reward": 361.7332458496094, "reward": 0.3948426842689514, "action": 1.1947683095932007}
{"mode": "train", "epochs": 2, "timestep": 2763, "ep_reward": 362.1020812988281, "reward": 0.3688321113586426, "action": 1.1873421669006348}
{"mode": "train", "epochs": 2, "timestep": 2764, "ep_reward": 362.50079345703125, "reward": 0.39872509241104126, "action": 1.2286570072174072}
{"mode": "train", "epochs": 2, "timestep": 2765, "ep_reward": 362.92474365234375, "reward": 0.42394310235977173, "action": 1.6039671897888184}
{"mode": "train", "epochs": 2, "timestep": 2766, "ep_reward": 363.36785888671875, "reward": 0.4431007504463196, "action": -0.15367424488067627}
{"mode": "train", "epochs": 2, "timestep": 2767, "ep_reward": 363.82476806640625, "reward": 0.4569118022918701, "action": 0.4982714056968689}
{"mode": "train", "epochs": 2, "timestep": 2768, "ep_reward": 364.2919006347656, "reward": 0.4671449661254883, "action": 0.9037598967552185}
{"mode": "train", "epochs": 2, "timestep": 2769, "ep_reward": 364.7632751464844, "reward": 0.4713834524154663, "action": 1.1365463733673096}
{"mode": "train", "epochs": 2, "timestep": 2770, "ep_reward": 365.2313232421875, "reward": 0.4680381417274475, "action": 1.7690843343734741}
{"mode": "train", "epochs": 2, "timestep": 2771, "ep_reward": 365.6860656738281, "reward": 0.4547528624534607, "action": 1.743079423904419}
{"mode": "train", "epochs": 2, "timestep": 2772, "ep_reward": 366.1178894042969, "reward": 0.43182480335235596, "action": 1.3529813289642334}
{"mode": "train", "epochs": 2, "timestep": 2773, "ep_reward": 366.5201416015625, "reward": 0.40223973989486694, "action": 0.6353214979171753}
{"mode": "train", "epochs": 2, "timestep": 2774, "ep_reward": 366.8910217285156, "reward": 0.3708692789077759, "action": 0.5680001974105835}
{"mode": "train", "epochs": 2, "timestep": 2775, "ep_reward": 367.2877197265625, "reward": 0.39668983221054077, "action": 1.273650884628296}
{"mode": "train", "epochs": 2, "timestep": 2776, "ep_reward": 367.7138366699219, "reward": 0.4261099696159363, "action": 1.323683261871338}
{"mode": "train", "epochs": 2, "timestep": 2777, "ep_reward": 368.1710205078125, "reward": 0.4571946859359741, "action": 0.4938198924064636}
{"mode": "train", "epochs": 2, "timestep": 2778, "ep_reward": 368.6602478027344, "reward": 0.48922860622406006, "action": 1.5543681383132935}
{"mode": "train", "epochs": 2, "timestep": 2779, "ep_reward": 369.1784973144531, "reward": 0.5182458162307739, "action": 1.1616945266723633}
{"mode": "train", "epochs": 2, "timestep": 2780, "ep_reward": 369.7250671386719, "reward": 0.546582818031311, "action": 0.6987070441246033}
{"mode": "train", "epochs": 2, "timestep": 2781, "ep_reward": 370.296875, "reward": 0.5717968940734863, "action": 1.6425457000732422}
{"mode": "train", "epochs": 2, "timestep": 2782, "ep_reward": 370.8890380859375, "reward": 0.5921727418899536, "action": 1.4981496334075928}
{"mode": "train", "epochs": 2, "timestep": 2783, "ep_reward": 371.4983825683594, "reward": 0.6093476414680481, "action": 1.3476637601852417}
{"mode": "train", "epochs": 2, "timestep": 2784, "ep_reward": 372.1206359863281, "reward": 0.6222504377365112, "action": 1.0547997951507568}
{"mode": "train", "epochs": 2, "timestep": 2785, "ep_reward": 372.75018310546875, "reward": 0.6295463442802429, "action": 1.3319900035858154}
{"mode": "train", "epochs": 2, "timestep": 2786, "ep_reward": 373.3812561035156, "reward": 0.631069540977478, "action": 1.8404502868652344}
{"mode": "train", "epochs": 2, "timestep": 2787, "ep_reward": 374.0098876953125, "reward": 0.6286263465881348, "action": 1.5812323093414307}
{"mode": "train", "epochs": 2, "timestep": 2788, "ep_reward": 374.6315612792969, "reward": 0.6216874122619629, "action": 0.7634555101394653}
{"mode": "train", "epochs": 2, "timestep": 2789, "ep_reward": 375.2386779785156, "reward": 0.6071252822875977, "action": 1.4951341152191162}
{"mode": "train", "epochs": 2, "timestep": 2790, "ep_reward": 375.82781982421875, "reward": 0.5891327857971191, "action": 0.42531919479370117}
{"mode": "train", "epochs": 2, "timestep": 2791, "ep_reward": 376.38995361328125, "reward": 0.5621321797370911, "action": 0.6115512847900391}
{"mode": "train", "epochs": 2, "timestep": 2792, "ep_reward": 376.91949462890625, "reward": 0.5295467376708984, "action": 1.321223497390747}
{"mode": "train", "epochs": 2, "timestep": 2793, "ep_reward": 377.41619873046875, "reward": 0.49670010805130005, "action": 1.2293152809143066}
{"mode": "train", "epochs": 2, "timestep": 2794, "ep_reward": 377.8785705566406, "reward": 0.46236616373062134, "action": 1.0350275039672852}
{"mode": "train", "epochs": 2, "timestep": 2795, "ep_reward": 378.3055419921875, "reward": 0.4269741177558899, "action": 0.7254417538642883}
{"mode": "train", "epochs": 2, "timestep": 2796, "ep_reward": 378.6960144042969, "reward": 0.39047473669052124, "action": 1.4064345359802246}
{"mode": "train", "epochs": 2, "timestep": 2797, "ep_reward": 379.0638122558594, "reward": 0.3678089380264282, "action": 0.5732333064079285}
{"mode": "train", "epochs": 2, "timestep": 2798, "ep_reward": 379.4656677246094, "reward": 0.4018649458885193, "action": 0.4366811513900757}
{"mode": "train", "epochs": 2, "timestep": 2799, "ep_reward": 379.89886474609375, "reward": 0.43320661783218384, "action": 0.8551580309867859}
{"mode": "train", "epochs": 2, "timestep": 2800, "ep_reward": 380.3598937988281, "reward": 0.4610412120819092, "action": 0.06505447626113892}
{"mode": "train", "epochs": 2, "timestep": 2801, "ep_reward": 380.84320068359375, "reward": 0.4832940101623535, "action": 0.628021240234375}
{"mode": "train", "epochs": 2, "timestep": 2802, "ep_reward": 381.34393310546875, "reward": 0.5007305145263672, "action": 0.2632901668548584}
{"mode": "train", "epochs": 2, "timestep": 2803, "ep_reward": 381.85565185546875, "reward": 0.5117260813713074, "action": 0.69743812084198}
{"mode": "train", "epochs": 2, "timestep": 2804, "ep_reward": 382.37115478515625, "reward": 0.5155128240585327, "action": 1.3138480186462402}
{"mode": "train", "epochs": 2, "timestep": 2805, "ep_reward": 382.880615234375, "reward": 0.5094631910324097, "action": 0.6533584594726562}
{"mode": "train", "epochs": 2, "timestep": 2806, "ep_reward": 383.3760986328125, "reward": 0.4954848885536194, "action": 0.6897387504577637}
{"mode": "train", "epochs": 2, "timestep": 2807, "ep_reward": 383.8502197265625, "reward": 0.4741278290748596, "action": 0.6468427181243896}
{"mode": "train", "epochs": 2, "timestep": 2808, "ep_reward": 384.2966613769531, "reward": 0.4464483857154846, "action": 0.91951984167099}
{"mode": "train", "epochs": 2, "timestep": 2809, "ep_reward": 384.70867919921875, "reward": 0.4120303988456726, "action": 0.9002169966697693}
{"mode": "train", "epochs": 2, "timestep": 2810, "ep_reward": 385.0814514160156, "reward": 0.37276285886764526, "action": 1.8867363929748535}
{"mode": "train", "epochs": 2, "timestep": 2811, "ep_reward": 385.4678649902344, "reward": 0.38641852140426636, "action": 0.7745548486709595}
{"mode": "train", "epochs": 2, "timestep": 2812, "ep_reward": 385.8931884765625, "reward": 0.42531830072402954, "action": 1.3445758819580078}
{"mode": "train", "epochs": 2, "timestep": 2813, "ep_reward": 386.3569030761719, "reward": 0.4637163281440735, "action": 1.5795944929122925}
{"mode": "train", "epochs": 2, "timestep": 2814, "ep_reward": 386.85894775390625, "reward": 0.5020478963851929, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2815, "ep_reward": 387.3985595703125, "reward": 0.539615273475647, "action": -0.25316953659057617}
{"mode": "train", "epochs": 2, "timestep": 2816, "ep_reward": 387.9779052734375, "reward": 0.5793545246124268, "action": 0.5457277297973633}
{"mode": "train", "epochs": 2, "timestep": 2817, "ep_reward": 388.58740234375, "reward": 0.6095016002655029, "action": 0.4438701272010803}
{"mode": "train", "epochs": 2, "timestep": 2818, "ep_reward": 389.21942138671875, "reward": 0.6320273876190186, "action": 1.4417527914047241}
{"mode": "train", "epochs": 2, "timestep": 2819, "ep_reward": 389.8663635253906, "reward": 0.646945595741272, "action": 1.2059009075164795}
{"mode": "train", "epochs": 2, "timestep": 2820, "ep_reward": 390.522216796875, "reward": 0.6558651924133301, "action": 1.2931243181228638}
{"mode": "train", "epochs": 2, "timestep": 2821, "ep_reward": 391.180419921875, "reward": 0.6582147479057312, "action": 1.4597008228302002}
{"mode": "train", "epochs": 2, "timestep": 2822, "ep_reward": 391.8349609375, "reward": 0.6545473337173462, "action": 1.0697962045669556}
{"mode": "train", "epochs": 2, "timestep": 2823, "ep_reward": 392.4783935546875, "reward": 0.6434224843978882, "action": 2.0}
{"mode": "train", "epochs": 2, "timestep": 2824, "ep_reward": 393.10772705078125, "reward": 0.629331648349762, "action": 0.40539222955703735}
{"mode": "train", "epochs": 2, "timestep": 2825, "ep_reward": 393.71197509765625, "reward": 0.60425865650177, "action": 1.4280636310577393}
{"mode": "train", "epochs": 2, "timestep": 2826, "ep_reward": 394.2884521484375, "reward": 0.5764703750610352, "action": 0.3702840805053711}
{"mode": "train", "epochs": 2, "timestep": 2827, "ep_reward": 394.8270568847656, "reward": 0.5386066436767578, "action": 1.0945873260498047}
{"mode": "train", "epochs": 2, "timestep": 2828, "ep_reward": 395.3264465332031, "reward": 0.499386191368103, "action": 1.1581629514694214}
{"mode": "train", "epochs": 2, "timestep": 2829, "ep_reward": 395.7851257324219, "reward": 0.45867210626602173, "action": 0.9102262258529663}
{"mode": "train", "epochs": 2, "timestep": 2830, "ep_reward": 396.201171875, "reward": 0.4160327911376953, "action": 1.5177035331726074}
{"mode": "train", "epochs": 2, "timestep": 2831, "ep_reward": 396.5799255371094, "reward": 0.3787631392478943, "action": -0.053201258182525635}
{"mode": "train", "epochs": 2, "timestep": 2832, "ep_reward": 396.9519348144531, "reward": 0.37200695276260376, "action": 0.8084989786148071}
{"mode": "train", "epochs": 2, "timestep": 2833, "ep_reward": 397.36651611328125, "reward": 0.41458314657211304, "action": 0.8511601686477661}
{"mode": "train", "epochs": 2, "timestep": 2834, "ep_reward": 397.8196716308594, "reward": 0.453163743019104, "action": -0.02377164363861084}
{"mode": "train", "epochs": 2, "timestep": 2835, "ep_reward": 398.30523681640625, "reward": 0.4855680465698242, "action": 1.1277178525924683}
{"mode": "train", "epochs": 2, "timestep": 2836, "ep_reward": 398.8189392089844, "reward": 0.5136908292770386, "action": 1.371232509613037}
{"mode": "train", "epochs": 2, "timestep": 2837, "ep_reward": 399.3509216308594, "reward": 0.5319944620132446, "action": 0.7924855351448059}
{"mode": "train", "epochs": 2, "timestep": 2838, "ep_reward": 399.890625, "reward": 0.5397166013717651, "action": 1.520002841949463}
{"mode": "train", "epochs": 2, "timestep": 2839, "ep_reward": 400.4266357421875, "reward": 0.5360132455825806, "action": -0.2861526608467102}
{"mode": "train", "epochs": 2, "timestep": 2840, "ep_reward": 400.9527893066406, "reward": 0.5261421203613281, "action": 1.3443193435668945}
{"mode": "train", "epochs": 2, "timestep": 2841, "ep_reward": 401.45721435546875, "reward": 0.5044305324554443, "action": 1.4346271753311157}
{"mode": "train", "epochs": 2, "timestep": 2842, "ep_reward": 401.9288024902344, "reward": 0.47157686948776245, "action": 0.5634628534317017}
{"mode": "train", "epochs": 2, "timestep": 2843, "ep_reward": 402.3627624511719, "reward": 0.43396759033203125, "action": 1.7829878330230713}
{"mode": "train", "epochs": 2, "timestep": 2844, "ep_reward": 402.74664306640625, "reward": 0.3838791251182556, "action": 0.9769250750541687}
{"mode": "train", "epochs": 2, "timestep": 2845, "ep_reward": 403.1113586425781, "reward": 0.364715039730072, "action": 0.38935989141464233}
{"mode": "train", "epochs": 2, "timestep": 2846, "ep_reward": 403.5204162597656, "reward": 0.4090586304664612, "action": 0.7996521592140198}
{"mode": "train", "epochs": 2, "timestep": 2847, "ep_reward": 403.9728698730469, "reward": 0.45243942737579346, "action": 1.0919338464736938}
{"mode": "train", "epochs": 2, "timestep": 2848, "ep_reward": 404.4674072265625, "reward": 0.49453669786453247, "action": 1.6127419471740723}
{"mode": "train", "epochs": 2, "timestep": 2849, "ep_reward": 405.00177001953125, "reward": 0.53436678647995, "action": 1.509713888168335}
{"mode": "train", "epochs": 2, "timestep": 2850, "ep_reward": 405.57464599609375, "reward": 0.5728808045387268, "action": 1.3350496292114258}
{"mode": "train", "epochs": 2, "timestep": 2851, "ep_reward": 406.1831359863281, "reward": 0.6084825992584229, "action": 1.0848512649536133}
{"mode": "train", "epochs": 2, "timestep": 2852, "ep_reward": 406.8224792480469, "reward": 0.6393312215805054, "action": 1.122571349143982}
{"mode": "train", "epochs": 2, "timestep": 2853, "ep_reward": 407.4859619140625, "reward": 0.6634969711303711, "action": 0.424832820892334}
