{"mode": "train", "epochs": 1, "timestep": 1, "ep_reward": 0.5399378538131714, "reward": 0.5399378538131714, "action": -0.0928351879119873}
{"mode": "train", "epochs": 1, "timestep": 2, "ep_reward": 1.0665926933288574, "reward": 0.526654839515686, "action": 0.051077380776405334}
{"mode": "train", "epochs": 1, "timestep": 3, "ep_reward": 1.5740858316421509, "reward": 0.5074931383132935, "action": 0.5775449275970459}
{"mode": "train", "epochs": 1, "timestep": 4, "ep_reward": 2.05977725982666, "reward": 0.4856914281845093, "action": 0.30620184540748596}
{"mode": "train", "epochs": 1, "timestep": 5, "ep_reward": 2.5197644233703613, "reward": 0.45998716354370117, "action": 0.0778297409415245}
{"mode": "train", "epochs": 1, "timestep": 6, "ep_reward": 2.950392246246338, "reward": 0.43062788248062134, "action": 0.48704802989959717}
{"mode": "train", "epochs": 1, "timestep": 7, "ep_reward": 3.3520736694335938, "reward": 0.4016813635826111, "action": -0.03852640092372894}
{"mode": "train", "epochs": 1, "timestep": 8, "ep_reward": 3.722280979156494, "reward": 0.3702072501182556, "action": -0.11912528425455093}
{"mode": "train", "epochs": 1, "timestep": 9, "ep_reward": 4.118253231048584, "reward": 0.3959720730781555, "action": 0.5318905115127563}
{"mode": "train", "epochs": 1, "timestep": 10, "ep_reward": 4.544191360473633, "reward": 0.4259380102157593, "action": 0.28658902645111084}
{"mode": "train", "epochs": 1, "timestep": 11, "ep_reward": 4.996707916259766, "reward": 0.4525166153907776, "action": 0.015353158116340637}
{"mode": "train", "epochs": 1, "timestep": 12, "ep_reward": 5.472228527069092, "reward": 0.47552067041397095, "action": -0.35361430048942566}
{"mode": "train", "epochs": 1, "timestep": 13, "ep_reward": 5.967322826385498, "reward": 0.495094358921051, "action": 0.04923347756266594}
{"mode": "train", "epochs": 1, "timestep": 14, "ep_reward": 6.478085994720459, "reward": 0.5107630491256714, "action": 1.2500743865966797}
{"mode": "train", "epochs": 1, "timestep": 15, "ep_reward": 6.997132778167725, "reward": 0.5190467834472656, "action": -0.16260607540607452}
{"mode": "train", "epochs": 1, "timestep": 16, "ep_reward": 7.517693996429443, "reward": 0.5205612182617188, "action": -0.1920904815196991}
{"mode": "train", "epochs": 1, "timestep": 17, "ep_reward": 8.03476333618164, "reward": 0.5170688629150391, "action": 0.7070578932762146}
{"mode": "train", "epochs": 1, "timestep": 18, "ep_reward": 8.540337562561035, "reward": 0.5055740475654602, "action": 0.3384752869606018}
{"mode": "train", "epochs": 1, "timestep": 19, "ep_reward": 9.028128623962402, "reward": 0.4877907633781433, "action": -0.2779766619205475}
{"mode": "train", "epochs": 1, "timestep": 20, "ep_reward": 9.495307922363281, "reward": 0.4671793580055237, "action": -0.6742662191390991}
{"mode": "train", "epochs": 1, "timestep": 21, "ep_reward": 9.941186904907227, "reward": 0.44587934017181396, "action": 0.17600572109222412}
{"mode": "train", "epochs": 1, "timestep": 22, "ep_reward": 10.360852241516113, "reward": 0.41966521739959717, "action": 0.12862607836723328}
{"mode": "train", "epochs": 1, "timestep": 23, "ep_reward": 10.75229549407959, "reward": 0.3914429545402527, "action": -0.1275341510772705}
{"mode": "train", "epochs": 1, "timestep": 24, "ep_reward": 11.130250930786133, "reward": 0.3779558539390564, "action": 0.3501074016094208}
{"mode": "train", "epochs": 1, "timestep": 25, "ep_reward": 11.535276412963867, "reward": 0.4050259590148926, "action": -0.9603867530822754}
{"mode": "train", "epochs": 1, "timestep": 26, "ep_reward": 11.967040061950684, "reward": 0.4317634701728821, "action": -1.0401586294174194}
{"mode": "train", "epochs": 1, "timestep": 27, "ep_reward": 12.420352935791016, "reward": 0.4533125162124634, "action": 0.31529754400253296}
{"mode": "train", "epochs": 1, "timestep": 28, "ep_reward": 12.890499114990234, "reward": 0.4701462984085083, "action": 0.17318706214427948}
{"mode": "train", "epochs": 1, "timestep": 29, "ep_reward": 13.37483024597168, "reward": 0.48433107137680054, "action": 0.4443845748901367}
{"mode": "train", "epochs": 1, "timestep": 30, "ep_reward": 13.870340347290039, "reward": 0.495510458946228, "action": -0.3663531243801117}
{"mode": "train", "epochs": 1, "timestep": 31, "ep_reward": 14.372369766235352, "reward": 0.5020291805267334, "action": -0.43337732553482056}
{"mode": "train", "epochs": 1, "timestep": 32, "ep_reward": 14.874582290649414, "reward": 0.5022120475769043, "action": -0.7863180041313171}
{"mode": "train", "epochs": 1, "timestep": 33, "ep_reward": 15.369391441345215, "reward": 0.49480903148651123, "action": -0.7466372847557068}
{"mode": "train", "epochs": 1, "timestep": 34, "ep_reward": 15.849401473999023, "reward": 0.4800105094909668, "action": 0.049684882164001465}
{"mode": "train", "epochs": 1, "timestep": 35, "ep_reward": 16.31130027770996, "reward": 0.46189844608306885, "action": -0.5850536227226257}
{"mode": "train", "epochs": 1, "timestep": 36, "ep_reward": 16.748868942260742, "reward": 0.4375684857368469, "action": -0.24053043127059937}
{"mode": "train", "epochs": 1, "timestep": 37, "ep_reward": 17.159465789794922, "reward": 0.41059648990631104, "action": -0.0471297949552536}
{"mode": "train", "epochs": 1, "timestep": 38, "ep_reward": 17.54204559326172, "reward": 0.3825797438621521, "action": 0.2590010464191437}
{"mode": "train", "epochs": 1, "timestep": 39, "ep_reward": 17.928741455078125, "reward": 0.38669490814208984, "action": -0.7757313251495361}
{"mode": "train", "epochs": 1, "timestep": 40, "ep_reward": 18.34181785583496, "reward": 0.41307663917541504, "action": -0.4881907105445862}
{"mode": "train", "epochs": 1, "timestep": 41, "ep_reward": 18.782133102416992, "reward": 0.4403151869773865, "action": -0.2885582447052002}
{"mode": "train", "epochs": 1, "timestep": 42, "ep_reward": 19.24876594543457, "reward": 0.4666327238082886, "action": -0.5410890579223633}
{"mode": "train", "epochs": 1, "timestep": 43, "ep_reward": 19.73935317993164, "reward": 0.4905869960784912, "action": -0.6801705956459045}
{"mode": "train", "epochs": 1, "timestep": 44, "ep_reward": 20.251399993896484, "reward": 0.512046754360199, "action": -0.26583924889564514}
{"mode": "train", "epochs": 1, "timestep": 45, "ep_reward": 20.781539916992188, "reward": 0.5301403403282166, "action": 0.1283624917268753}
{"mode": "train", "epochs": 1, "timestep": 46, "ep_reward": 21.324121475219727, "reward": 0.5425807237625122, "action": -0.5888574719429016}
{"mode": "train", "epochs": 1, "timestep": 47, "ep_reward": 21.873584747314453, "reward": 0.5494627952575684, "action": -0.26511794328689575}
{"mode": "train", "epochs": 1, "timestep": 48, "ep_reward": 22.42434310913086, "reward": 0.5507588982582092, "action": 0.6707395315170288}
{"mode": "train", "epochs": 1, "timestep": 49, "ep_reward": 22.96750259399414, "reward": 0.543158769607544, "action": -0.34686046838760376}
{"mode": "train", "epochs": 1, "timestep": 50, "ep_reward": 23.49761962890625, "reward": 0.5301172733306885, "action": 0.27405068278312683}
{"mode": "train", "epochs": 1, "timestep": 51, "ep_reward": 24.00693702697754, "reward": 0.5093165636062622, "action": -0.18394997715950012}
{"mode": "train", "epochs": 1, "timestep": 52, "ep_reward": 24.491201400756836, "reward": 0.4842645525932312, "action": -0.2116532176733017}
{"mode": "train", "epochs": 1, "timestep": 53, "ep_reward": 24.946718215942383, "reward": 0.4555167555809021, "action": 0.024597734212875366}
{"mode": "train", "epochs": 1, "timestep": 54, "ep_reward": 25.369543075561523, "reward": 0.42282557487487793, "action": 0.15071570873260498}
{"mode": "train", "epochs": 1, "timestep": 55, "ep_reward": 25.75684356689453, "reward": 0.3873000144958496, "action": 0.6790326237678528}
{"mode": "train", "epochs": 1, "timestep": 56, "ep_reward": 26.13175392150879, "reward": 0.3749094605445862, "action": 0.5562174320220947}
{"mode": "train", "epochs": 1, "timestep": 57, "ep_reward": 26.54218292236328, "reward": 0.41042983531951904, "action": 0.20001845061779022}
{"mode": "train", "epochs": 1, "timestep": 58, "ep_reward": 26.988685607910156, "reward": 0.44650185108184814, "action": 0.21218642592430115}
{"mode": "train", "epochs": 1, "timestep": 59, "ep_reward": 27.46920394897461, "reward": 0.4805184006690979, "action": 0.06875710934400558}
{"mode": "train", "epochs": 1, "timestep": 60, "ep_reward": 27.980436325073242, "reward": 0.5112330317497253, "action": 0.14908692240715027}
{"mode": "train", "epochs": 1, "timestep": 61, "ep_reward": 28.517351150512695, "reward": 0.53691565990448, "action": -0.40069150924682617}
{"mode": "train", "epochs": 1, "timestep": 62, "ep_reward": 29.073678970336914, "reward": 0.5563274621963501, "action": -0.8734404444694519}
{"mode": "train", "epochs": 1, "timestep": 63, "ep_reward": 29.639976501464844, "reward": 0.5662965774536133, "action": 0.7487899661064148}
{"mode": "train", "epochs": 1, "timestep": 64, "ep_reward": 30.20908546447754, "reward": 0.5691096782684326, "action": -0.5662041902542114}
{"mode": "train", "epochs": 1, "timestep": 65, "ep_reward": 30.772085189819336, "reward": 0.5629996061325073, "action": -0.8944337368011475}
{"mode": "train", "epochs": 1, "timestep": 66, "ep_reward": 31.317798614501953, "reward": 0.5457130670547485, "action": -0.353938490152359}
{"mode": "train", "epochs": 1, "timestep": 67, "ep_reward": 31.83803367614746, "reward": 0.5202344655990601, "action": 0.8046361804008484}
{"mode": "train", "epochs": 1, "timestep": 68, "ep_reward": 32.33156967163086, "reward": 0.49353480339050293, "action": -0.31296733021736145}
{"mode": "train", "epochs": 1, "timestep": 69, "ep_reward": 32.789794921875, "reward": 0.4582269787788391, "action": -0.2555701732635498}
{"mode": "train", "epochs": 1, "timestep": 70, "ep_reward": 33.20831298828125, "reward": 0.4185184836387634, "action": -0.6566587090492249}
{"mode": "train", "epochs": 1, "timestep": 71, "ep_reward": 33.58161544799805, "reward": 0.37330251932144165, "action": 0.1829279065132141}
{"mode": "train", "epochs": 1, "timestep": 72, "ep_reward": 33.960269927978516, "reward": 0.3786541819572449, "action": -0.009716153144836426}
{"mode": "train", "epochs": 1, "timestep": 73, "ep_reward": 34.37915802001953, "reward": 0.41888636350631714, "action": 0.2651129961013794}
{"mode": "train", "epochs": 1, "timestep": 74, "ep_reward": 34.836910247802734, "reward": 0.45775318145751953, "action": 0.3786315321922302}
{"mode": "train", "epochs": 1, "timestep": 75, "ep_reward": 35.32958984375, "reward": 0.4926803708076477, "action": -0.010731257498264313}
{"mode": "train", "epochs": 1, "timestep": 76, "ep_reward": 35.85133361816406, "reward": 0.5217437744140625, "action": 0.07195977866649628}
{"mode": "train", "epochs": 1, "timestep": 77, "ep_reward": 36.39642333984375, "reward": 0.5450892448425293, "action": 0.38652583956718445}
{"mode": "train", "epochs": 1, "timestep": 78, "ep_reward": 36.95756912231445, "reward": 0.5611457824707031, "action": -0.48022744059562683}
{"mode": "train", "epochs": 1, "timestep": 79, "ep_reward": 37.527305603027344, "reward": 0.5697349309921265, "action": -1.7816325426101685}
{"mode": "train", "epochs": 1, "timestep": 80, "ep_reward": 38.10270309448242, "reward": 0.5753960609436035, "action": -0.019984062761068344}
{"mode": "train", "epochs": 1, "timestep": 81, "ep_reward": 38.67742156982422, "reward": 0.5747169256210327, "action": -0.008315511047840118}
{"mode": "train", "epochs": 1, "timestep": 82, "ep_reward": 39.24342346191406, "reward": 0.5660003423690796, "action": 0.23147639632225037}
{"mode": "train", "epochs": 1, "timestep": 83, "ep_reward": 39.79193115234375, "reward": 0.5485081076622009, "action": -0.41263264417648315}
{"mode": "train", "epochs": 1, "timestep": 84, "ep_reward": 40.3178825378418, "reward": 0.5259523987770081, "action": -0.3292602300643921}
{"mode": "train", "epochs": 1, "timestep": 85, "ep_reward": 40.81601333618164, "reward": 0.4981291890144348, "action": 0.02938205748796463}
{"mode": "train", "epochs": 1, "timestep": 86, "ep_reward": 41.28022003173828, "reward": 0.4642060399055481, "action": -0.18008776009082794}
{"mode": "train", "epochs": 1, "timestep": 87, "ep_reward": 41.707855224609375, "reward": 0.4276357889175415, "action": -0.20194515585899353}
{"mode": "train", "epochs": 1, "timestep": 88, "ep_reward": 42.09739303588867, "reward": 0.3895376920700073, "action": -0.21709918975830078}
{"mode": "train", "epochs": 1, "timestep": 89, "ep_reward": 42.46583938598633, "reward": 0.36844658851623535, "action": -0.07251826673746109}
{"mode": "train", "epochs": 1, "timestep": 90, "ep_reward": 42.871334075927734, "reward": 0.4054960012435913, "action": -0.6300878524780273}
{"mode": "train", "epochs": 1, "timestep": 91, "ep_reward": 43.31292724609375, "reward": 0.4415919780731201, "action": -0.14550378918647766}
{"mode": "train", "epochs": 1, "timestep": 92, "ep_reward": 43.785953521728516, "reward": 0.4730262756347656, "action": -0.9058552980422974}
{"mode": "train", "epochs": 1, "timestep": 93, "ep_reward": 44.286128997802734, "reward": 0.5001752376556396, "action": 0.6111649870872498}
{"mode": "train", "epochs": 1, "timestep": 94, "ep_reward": 44.80659866333008, "reward": 0.520471453666687, "action": -0.6488736271858215}
{"mode": "train", "epochs": 1, "timestep": 95, "ep_reward": 45.342411041259766, "reward": 0.535813570022583, "action": 0.5323817729949951}
{"mode": "train", "epochs": 1, "timestep": 96, "ep_reward": 45.88706970214844, "reward": 0.5446577072143555, "action": -0.2206447571516037}
{"mode": "train", "epochs": 1, "timestep": 97, "ep_reward": 46.434043884277344, "reward": 0.546972393989563, "action": -0.8462696075439453}
{"mode": "train", "epochs": 1, "timestep": 98, "ep_reward": 46.9737663269043, "reward": 0.5397242307662964, "action": 0.54786217212677}
{"mode": "train", "epochs": 1, "timestep": 99, "ep_reward": 47.50157165527344, "reward": 0.5278036594390869, "action": -1.333508014678955}
{"mode": "train", "epochs": 1, "timestep": 100, "ep_reward": 48.00513458251953, "reward": 0.5035644173622131, "action": -0.17241746187210083}
{"mode": "train", "epochs": 1, "timestep": 101, "ep_reward": 48.47990036010742, "reward": 0.47476398944854736, "action": -0.3953135311603546}
{"mode": "train", "epochs": 1, "timestep": 102, "ep_reward": 48.9197883605957, "reward": 0.43988776206970215, "action": 0.25909557938575745}
{"mode": "train", "epochs": 1, "timestep": 103, "ep_reward": 49.324668884277344, "reward": 0.4048786759376526, "action": -0.7694085836410522}
{"mode": "train", "epochs": 1, "timestep": 104, "ep_reward": 49.68758010864258, "reward": 0.3629113435745239, "action": -0.010103538632392883}
{"mode": "train", "epochs": 1, "timestep": 105, "ep_reward": 50.0813102722168, "reward": 0.3937310576438904, "action": 0.23476478457450867}
{"mode": "train", "epochs": 1, "timestep": 106, "ep_reward": 50.51226043701172, "reward": 0.43095123767852783, "action": -0.11863185465335846}
{"mode": "train", "epochs": 1, "timestep": 107, "ep_reward": 50.97744369506836, "reward": 0.46518194675445557, "action": -0.5636682510375977}
{"mode": "train", "epochs": 1, "timestep": 108, "ep_reward": 51.473670959472656, "reward": 0.49622654914855957, "action": 0.9122675061225891}
{"mode": "train", "epochs": 1, "timestep": 109, "ep_reward": 51.99811935424805, "reward": 0.5244483351707458, "action": -0.06214404106140137}
{"mode": "train", "epochs": 1, "timestep": 110, "ep_reward": 52.54233169555664, "reward": 0.5442134737968445, "action": -0.20427989959716797}
{"mode": "train", "epochs": 1, "timestep": 111, "ep_reward": 53.1000862121582, "reward": 0.5577529668807983, "action": -0.5819187760353088}
{"mode": "train", "epochs": 1, "timestep": 112, "ep_reward": 53.665611267089844, "reward": 0.5655231475830078, "action": -0.8293372988700867}
{"mode": "train", "epochs": 1, "timestep": 113, "ep_reward": 54.23406219482422, "reward": 0.5684525966644287, "action": 0.4164651036262512}
{"mode": "train", "epochs": 1, "timestep": 114, "ep_reward": 54.7971076965332, "reward": 0.5630472898483276, "action": -0.1260250210762024}
{"mode": "train", "epochs": 1, "timestep": 115, "ep_reward": 55.34749984741211, "reward": 0.5503929257392883, "action": -0.13718988001346588}
{"mode": "train", "epochs": 1, "timestep": 116, "ep_reward": 55.878501892089844, "reward": 0.5310036540031433, "action": -0.9720330238342285}
{"mode": "train", "epochs": 1, "timestep": 117, "ep_reward": 56.38822937011719, "reward": 0.5097277164459229, "action": -0.910557210445404}
{"mode": "train", "epochs": 1, "timestep": 118, "ep_reward": 56.874149322509766, "reward": 0.4859207272529602, "action": -0.674338698387146}
{"mode": "train", "epochs": 1, "timestep": 119, "ep_reward": 57.333518981933594, "reward": 0.4593707323074341, "action": 0.010163240134716034}
{"mode": "train", "epochs": 1, "timestep": 120, "ep_reward": 57.761253356933594, "reward": 0.42773348093032837, "action": -0.721197783946991}
{"mode": "train", "epochs": 1, "timestep": 121, "ep_reward": 58.15952682495117, "reward": 0.3982742428779602, "action": 0.45339882373809814}
{"mode": "train", "epochs": 1, "timestep": 122, "ep_reward": 58.527469635009766, "reward": 0.36794376373291016, "action": -0.061682987958192825}
{"mode": "train", "epochs": 1, "timestep": 123, "ep_reward": 58.92783737182617, "reward": 0.40036606788635254, "action": -0.7614738941192627}
{"mode": "train", "epochs": 1, "timestep": 124, "ep_reward": 59.35973358154297, "reward": 0.43189460039138794, "action": -0.361356258392334}
{"mode": "train", "epochs": 1, "timestep": 125, "ep_reward": 59.81869888305664, "reward": 0.4589654803276062, "action": 0.9677499532699585}
{"mode": "train", "epochs": 1, "timestep": 126, "ep_reward": 60.301151275634766, "reward": 0.4824538826942444, "action": -0.8632290363311768}
{"mode": "train", "epochs": 1, "timestep": 127, "ep_reward": 60.80490493774414, "reward": 0.5037552118301392, "action": -0.9798749685287476}
{"mode": "train", "epochs": 1, "timestep": 128, "ep_reward": 61.3217658996582, "reward": 0.5168601274490356, "action": -0.16324134171009064}
{"mode": "train", "epochs": 1, "timestep": 129, "ep_reward": 61.84431457519531, "reward": 0.5225479602813721, "action": 0.11255978047847748}
{"mode": "train", "epochs": 1, "timestep": 130, "ep_reward": 62.36692428588867, "reward": 0.5226097106933594, "action": -0.9560235142707825}
{"mode": "train", "epochs": 1, "timestep": 131, "ep_reward": 62.880836486816406, "reward": 0.5139140486717224, "action": 0.6431392431259155}
{"mode": "train", "epochs": 1, "timestep": 132, "ep_reward": 63.38319778442383, "reward": 0.5023597478866577, "action": -0.3190821409225464}
{"mode": "train", "epochs": 1, "timestep": 133, "ep_reward": 63.867122650146484, "reward": 0.4839237928390503, "action": -0.24223782122135162}
{"mode": "train", "epochs": 1, "timestep": 134, "ep_reward": 64.32745361328125, "reward": 0.4603337049484253, "action": 0.8032972812652588}
{"mode": "train", "epochs": 1, "timestep": 135, "ep_reward": 64.7654037475586, "reward": 0.43795156478881836, "action": -0.41537609696388245}
{"mode": "train", "epochs": 1, "timestep": 136, "ep_reward": 65.17466735839844, "reward": 0.4092637896537781, "action": 0.626883327960968}
{"mode": "train", "epochs": 1, "timestep": 137, "ep_reward": 65.55841827392578, "reward": 0.38375306129455566, "action": 0.11216357350349426}
{"mode": "train", "epochs": 1, "timestep": 138, "ep_reward": 65.9446029663086, "reward": 0.3861871361732483, "action": -0.48344576358795166}
{"mode": "train", "epochs": 1, "timestep": 139, "ep_reward": 66.3568344116211, "reward": 0.4122288227081299, "action": 0.0011936277151107788}
{"mode": "train", "epochs": 1, "timestep": 140, "ep_reward": 66.79512023925781, "reward": 0.43828314542770386, "action": -0.2535455822944641}
{"mode": "train", "epochs": 1, "timestep": 141, "ep_reward": 67.25733947753906, "reward": 0.4622159004211426, "action": 0.5851519703865051}
{"mode": "train", "epochs": 1, "timestep": 142, "ep_reward": 67.74052429199219, "reward": 0.48318421840667725, "action": -0.28857481479644775}
{"mode": "train", "epochs": 1, "timestep": 143, "ep_reward": 68.23970031738281, "reward": 0.49917882680892944, "action": 0.15614458918571472}
{"mode": "train", "epochs": 1, "timestep": 144, "ep_reward": 68.75045776367188, "reward": 0.5107601881027222, "action": -0.6170644760131836}
{"mode": "train", "epochs": 1, "timestep": 145, "ep_reward": 69.26866912841797, "reward": 0.518214225769043, "action": -0.12524858117103577}
{"mode": "train", "epochs": 1, "timestep": 146, "ep_reward": 69.78978729248047, "reward": 0.5211185812950134, "action": -0.09112915396690369}
{"mode": "train", "epochs": 1, "timestep": 147, "ep_reward": 70.30843353271484, "reward": 0.5186445713043213, "action": -1.0559561252593994}
{"mode": "train", "epochs": 1, "timestep": 148, "ep_reward": 70.82256317138672, "reward": 0.5141304731369019, "action": 0.2659115195274353}
{"mode": "train", "epochs": 1, "timestep": 149, "ep_reward": 71.32559967041016, "reward": 0.5030384659767151, "action": 0.1864832043647766}
{"mode": "train", "epochs": 1, "timestep": 150, "ep_reward": 71.81184387207031, "reward": 0.4862450361251831, "action": 0.533074140548706}
{"mode": "train", "epochs": 1, "timestep": 151, "ep_reward": 72.27458953857422, "reward": 0.46274590492248535, "action": -0.5648103952407837}
{"mode": "train", "epochs": 1, "timestep": 152, "ep_reward": 72.71412658691406, "reward": 0.43953442573547363, "action": 0.014958858489990234}
{"mode": "train", "epochs": 1, "timestep": 153, "ep_reward": 73.12672424316406, "reward": 0.4125974178314209, "action": 0.11484915763139725}
{"mode": "train", "epochs": 1, "timestep": 154, "ep_reward": 73.51038360595703, "reward": 0.38365912437438965, "action": 0.19920411705970764}
{"mode": "train", "epochs": 1, "timestep": 155, "ep_reward": 73.89557647705078, "reward": 0.38519155979156494, "action": 0.450749009847641}
{"mode": "train", "epochs": 1, "timestep": 156, "ep_reward": 74.30906677246094, "reward": 0.4134923219680786, "action": -0.037254348397254944}
{"mode": "train", "epochs": 1, "timestep": 157, "ep_reward": 74.75081634521484, "reward": 0.44175004959106445, "action": -0.28741663694381714}
{"mode": "train", "epochs": 1, "timestep": 158, "ep_reward": 75.21824645996094, "reward": 0.4674314260482788, "action": -0.18785499036312103}
{"mode": "train", "epochs": 1, "timestep": 159, "ep_reward": 75.70707702636719, "reward": 0.4888305068016052, "action": -0.3258226811885834}
{"mode": "train", "epochs": 1, "timestep": 160, "ep_reward": 76.21221923828125, "reward": 0.5051427483558655, "action": -0.7632954716682434}
{"mode": "train", "epochs": 1, "timestep": 161, "ep_reward": 76.72685241699219, "reward": 0.5146349668502808, "action": -0.04561803489923477}
{"mode": "train", "epochs": 1, "timestep": 162, "ep_reward": 77.24449157714844, "reward": 0.5176360011100769, "action": -0.2279985249042511}
{"mode": "train", "epochs": 1, "timestep": 163, "ep_reward": 77.75892639160156, "reward": 0.5144349336624146, "action": 0.22388696670532227}
{"mode": "train", "epochs": 1, "timestep": 164, "ep_reward": 78.26541900634766, "reward": 0.5064932107925415, "action": -0.751878023147583}
{"mode": "train", "epochs": 1, "timestep": 165, "ep_reward": 78.75576782226562, "reward": 0.49035006761550903, "action": -0.9430599212646484}
{"mode": "train", "epochs": 1, "timestep": 166, "ep_reward": 79.22171783447266, "reward": 0.46594738960266113, "action": 0.24149860441684723}
{"mode": "train", "epochs": 1, "timestep": 167, "ep_reward": 79.66230773925781, "reward": 0.44059234857559204, "action": -0.36809349060058594}
{"mode": "train", "epochs": 1, "timestep": 168, "ep_reward": 80.07244873046875, "reward": 0.4101388454437256, "action": 0.3019268214702606}
{"mode": "train", "epochs": 1, "timestep": 169, "ep_reward": 80.45339965820312, "reward": 0.3809536099433899, "action": 0.5818424820899963}
{"mode": "train", "epochs": 1, "timestep": 170, "ep_reward": 80.84001159667969, "reward": 0.38660991191864014, "action": 0.5744893550872803}
{"mode": "train", "epochs": 1, "timestep": 171, "ep_reward": 81.25363159179688, "reward": 0.41362375020980835, "action": 0.5133246779441833}
{"mode": "train", "epochs": 1, "timestep": 172, "ep_reward": 81.69124603271484, "reward": 0.4376108646392822, "action": 0.049529604613780975}
{"mode": "train", "epochs": 1, "timestep": 173, "ep_reward": 82.1493911743164, "reward": 0.4581443667411804, "action": -0.36941948533058167}
{"mode": "train", "epochs": 1, "timestep": 174, "ep_reward": 82.62538146972656, "reward": 0.4759926199913025, "action": -0.1909618228673935}
{"mode": "train", "epochs": 1, "timestep": 175, "ep_reward": 83.11648559570312, "reward": 0.4911046624183655, "action": -0.02068857103586197}
{"mode": "train", "epochs": 1, "timestep": 176, "ep_reward": 83.61872100830078, "reward": 0.502238392829895, "action": -0.47363874316215515}
{"mode": "train", "epochs": 1, "timestep": 177, "ep_reward": 84.12828826904297, "reward": 0.5095683932304382, "action": -0.4054373800754547}
{"mode": "train", "epochs": 1, "timestep": 178, "ep_reward": 84.64151763916016, "reward": 0.5132311582565308, "action": 0.22113969922065735}
{"mode": "train", "epochs": 1, "timestep": 179, "ep_reward": 85.15277099609375, "reward": 0.5112558603286743, "action": 0.2348363697528839}
{"mode": "train", "epochs": 1, "timestep": 180, "ep_reward": 85.65591430664062, "reward": 0.5031416416168213, "action": -0.4180489480495453}
{"mode": "train", "epochs": 1, "timestep": 181, "ep_reward": 86.14761352539062, "reward": 0.4916973114013672, "action": -0.43222129344940186}
{"mode": "train", "epochs": 1, "timestep": 182, "ep_reward": 86.62474060058594, "reward": 0.4771274924278259, "action": -1.1907703876495361}
{"mode": "train", "epochs": 1, "timestep": 183, "ep_reward": 87.08819580078125, "reward": 0.4634549021720886, "action": -0.0955478772521019}
{"mode": "train", "epochs": 1, "timestep": 184, "ep_reward": 87.53350067138672, "reward": 0.445307195186615, "action": 0.08530900627374649}
{"mode": "train", "epochs": 1, "timestep": 185, "ep_reward": 87.95748138427734, "reward": 0.42398250102996826, "action": -0.1960706263780594}
{"mode": "train", "epochs": 1, "timestep": 186, "ep_reward": 88.3594741821289, "reward": 0.4019964337348938, "action": -0.47386398911476135}
{"mode": "train", "epochs": 1, "timestep": 187, "ep_reward": 88.74061584472656, "reward": 0.3811454772949219, "action": 0.5438271760940552}
{"mode": "train", "epochs": 1, "timestep": 188, "ep_reward": 89.13265991210938, "reward": 0.39204680919647217, "action": -0.11798835545778275}
{"mode": "train", "epochs": 1, "timestep": 189, "ep_reward": 89.54710388183594, "reward": 0.4144434928894043, "action": -0.6073272228240967}
{"mode": "train", "epochs": 1, "timestep": 190, "ep_reward": 89.98190307617188, "reward": 0.43480217456817627, "action": -0.24035030603408813}
{"mode": "train", "epochs": 1, "timestep": 191, "ep_reward": 90.43347930908203, "reward": 0.451579749584198, "action": -0.2907026410102844}
{"mode": "train", "epochs": 1, "timestep": 192, "ep_reward": 90.89827728271484, "reward": 0.4647952914237976, "action": 0.3884803354740143}
{"mode": "train", "epochs": 1, "timestep": 193, "ep_reward": 91.3733139038086, "reward": 0.4750370979309082, "action": 0.6347634792327881}
{"mode": "train", "epochs": 1, "timestep": 194, "ep_reward": 91.85669708251953, "reward": 0.4833828806877136, "action": 0.5234174132347107}
{"mode": "train", "epochs": 1, "timestep": 195, "ep_reward": 92.34623718261719, "reward": 0.4895419478416443, "action": -0.29381367564201355}
{"mode": "train", "epochs": 1, "timestep": 196, "ep_reward": 92.8373794555664, "reward": 0.491144061088562, "action": 0.09226783365011215}
{"mode": "train", "epochs": 1, "timestep": 197, "ep_reward": 93.32585906982422, "reward": 0.48847824335098267, "action": 0.3750510811805725}
{"mode": "train", "epochs": 1, "timestep": 198, "ep_reward": 93.80864715576172, "reward": 0.48278647661209106, "action": -0.2592698633670807}
{"mode": "train", "epochs": 1, "timestep": 199, "ep_reward": 94.28062438964844, "reward": 0.4719792604446411, "action": -0.3080606460571289}
{"mode": "train", "epochs": 1, "timestep": 200, "ep_reward": 94.73701477050781, "reward": 0.4563925266265869, "action": -0.041787467896938324}
{"mode": "train", "epochs": 1, "timestep": 201, "ep_reward": 95.17485809326172, "reward": 0.4378429651260376, "action": -0.6553048491477966}
{"mode": "train", "epochs": 1, "timestep": 202, "ep_reward": 95.58872985839844, "reward": 0.4138683080673218, "action": -0.654609203338623}
{"mode": "train", "epochs": 1, "timestep": 203, "ep_reward": 95.97500610351562, "reward": 0.3862752914428711, "action": -0.31304216384887695}
{"mode": "train", "epochs": 1, "timestep": 204, "ep_reward": 96.35946655273438, "reward": 0.3844618797302246, "action": 0.5112161040306091}
{"mode": "train", "epochs": 1, "timestep": 205, "ep_reward": 96.77006530761719, "reward": 0.4105985164642334, "action": 0.5406292676925659}
{"mode": "train", "epochs": 1, "timestep": 206, "ep_reward": 97.20405578613281, "reward": 0.43399322032928467, "action": -0.0527133010327816}
{"mode": "train", "epochs": 1, "timestep": 207, "ep_reward": 97.658203125, "reward": 0.45414483547210693, "action": 0.01588573306798935}
{"mode": "train", "epochs": 1, "timestep": 208, "ep_reward": 98.12977600097656, "reward": 0.47157156467437744, "action": 0.2257010042667389}
{"mode": "train", "epochs": 1, "timestep": 209, "ep_reward": 98.61490631103516, "reward": 0.48513084650039673, "action": 0.1424504518508911}
{"mode": "train", "epochs": 1, "timestep": 210, "ep_reward": 99.10887145996094, "reward": 0.4939659833908081, "action": 0.6673872470855713}
{"mode": "train", "epochs": 1, "timestep": 211, "ep_reward": 99.60550689697266, "reward": 0.4966323971748352, "action": -0.24317315220832825}
{"mode": "train", "epochs": 1, "timestep": 212, "ep_reward": 100.10041809082031, "reward": 0.494912326335907, "action": -0.44833481311798096}
{"mode": "train", "epochs": 1, "timestep": 213, "ep_reward": 100.59056091308594, "reward": 0.49014145135879517, "action": -0.23194721341133118}
{"mode": "train", "epochs": 1, "timestep": 214, "ep_reward": 101.07229614257812, "reward": 0.48173677921295166, "action": -0.423498272895813}
{"mode": "train", "epochs": 1, "timestep": 215, "ep_reward": 101.54310607910156, "reward": 0.4708097577095032, "action": 0.1309230476617813}
{"mode": "train", "epochs": 1, "timestep": 216, "ep_reward": 101.99840545654297, "reward": 0.45529884099960327, "action": 1.2090578079223633}
{"mode": "train", "epochs": 1, "timestep": 217, "ep_reward": 102.42984771728516, "reward": 0.43143975734710693, "action": 0.2264937162399292}
{"mode": "train", "epochs": 1, "timestep": 218, "ep_reward": 102.83599090576172, "reward": 0.40614306926727295, "action": -0.225651815533638}
{"mode": "train", "epochs": 1, "timestep": 219, "ep_reward": 103.21741485595703, "reward": 0.38142162561416626, "action": 0.31031370162963867}
{"mode": "train", "epochs": 1, "timestep": 220, "ep_reward": 103.60728454589844, "reward": 0.3898671269416809, "action": -0.07667308300733566}
{"mode": "train", "epochs": 1, "timestep": 221, "ep_reward": 104.02227020263672, "reward": 0.4149852991104126, "action": 0.5054914355278015}
{"mode": "train", "epochs": 1, "timestep": 222, "ep_reward": 104.46115112304688, "reward": 0.43887823820114136, "action": 0.010405510663986206}
{"mode": "train", "epochs": 1, "timestep": 223, "ep_reward": 104.92292022705078, "reward": 0.4617653489112854, "action": -0.1372959464788437}
{"mode": "train", "epochs": 1, "timestep": 224, "ep_reward": 105.40422821044922, "reward": 0.4813092350959778, "action": -1.3185173273086548}
{"mode": "train", "epochs": 1, "timestep": 225, "ep_reward": 105.899169921875, "reward": 0.4949414134025574, "action": 0.14286839962005615}
{"mode": "train", "epochs": 1, "timestep": 226, "ep_reward": 106.40132904052734, "reward": 0.5021612644195557, "action": -0.04165232554078102}
{"mode": "train", "epochs": 1, "timestep": 227, "ep_reward": 106.90586853027344, "reward": 0.5045375227928162, "action": -1.1368670463562012}
{"mode": "train", "epochs": 1, "timestep": 228, "ep_reward": 107.40447998046875, "reward": 0.49861323833465576, "action": 0.017742976546287537}
{"mode": "train", "epochs": 1, "timestep": 229, "ep_reward": 107.89234161376953, "reward": 0.48785901069641113, "action": 0.45530039072036743}
{"mode": "train", "epochs": 1, "timestep": 230, "ep_reward": 108.366943359375, "reward": 0.47460079193115234, "action": -0.04643945395946503}
{"mode": "train", "epochs": 1, "timestep": 231, "ep_reward": 108.82379913330078, "reward": 0.4568544626235962, "action": -0.4967882037162781}
{"mode": "train", "epochs": 1, "timestep": 232, "ep_reward": 109.25747680664062, "reward": 0.433674693107605, "action": -0.5728242993354797}
{"mode": "train", "epochs": 1, "timestep": 233, "ep_reward": 109.66365051269531, "reward": 0.4061722755432129, "action": -0.0014140605926513672}
{"mode": "train", "epochs": 1, "timestep": 234, "ep_reward": 110.04235076904297, "reward": 0.3786986470222473, "action": -0.9379458427429199}
{"mode": "train", "epochs": 1, "timestep": 235, "ep_reward": 110.43341064453125, "reward": 0.39106112718582153, "action": -0.7209189534187317}
{"mode": "train", "epochs": 1, "timestep": 236, "ep_reward": 110.85335540771484, "reward": 0.41994839906692505, "action": 0.5355495810508728}
{"mode": "train", "epochs": 1, "timestep": 237, "ep_reward": 111.30271911621094, "reward": 0.4493662118911743, "action": 0.4542805552482605}
{"mode": "train", "epochs": 1, "timestep": 238, "ep_reward": 111.77704620361328, "reward": 0.4743257164955139, "action": 0.8531458973884583}
{"mode": "train", "epochs": 1, "timestep": 239, "ep_reward": 112.2707748413086, "reward": 0.4937254786491394, "action": -0.4823708236217499}
{"mode": "train", "epochs": 1, "timestep": 240, "ep_reward": 112.7783203125, "reward": 0.5075472593307495, "action": -0.0803476870059967}
{"mode": "train", "epochs": 1, "timestep": 241, "ep_reward": 113.29559326171875, "reward": 0.517271101474762, "action": 0.2005908191204071}
{"mode": "train", "epochs": 1, "timestep": 242, "ep_reward": 113.8167724609375, "reward": 0.5211813449859619, "action": -0.5054152011871338}
{"mode": "train", "epochs": 1, "timestep": 243, "ep_reward": 114.33744812011719, "reward": 0.5206763744354248, "action": 0.30123159289360046}
{"mode": "train", "epochs": 1, "timestep": 244, "ep_reward": 114.85115051269531, "reward": 0.5137014389038086, "action": 0.297782301902771}
{"mode": "train", "epochs": 1, "timestep": 245, "ep_reward": 115.35132598876953, "reward": 0.5001755952835083, "action": 0.010946638882160187}
{"mode": "train", "epochs": 1, "timestep": 246, "ep_reward": 115.83318328857422, "reward": 0.4818539023399353, "action": -0.19404326379299164}
{"mode": "train", "epochs": 1, "timestep": 247, "ep_reward": 116.29342651367188, "reward": 0.46024268865585327, "action": -0.2221774011850357}
{"mode": "train", "epochs": 1, "timestep": 248, "ep_reward": 116.7295150756836, "reward": 0.4360911250114441, "action": 0.21329887211322784}
{"mode": "train", "epochs": 1, "timestep": 249, "ep_reward": 117.13749694824219, "reward": 0.4079837203025818, "action": -0.5430007576942444}
{"mode": "train", "epochs": 1, "timestep": 250, "ep_reward": 117.51966094970703, "reward": 0.38216710090637207, "action": 0.5789392590522766}
{"mode": "train", "epochs": 1, "timestep": 251, "ep_reward": 117.90753936767578, "reward": 0.38787829875946045, "action": 0.22798052430152893}
{"mode": "train", "epochs": 1, "timestep": 252, "ep_reward": 118.32322692871094, "reward": 0.4156838059425354, "action": -0.9156442284584045}
{"mode": "train", "epochs": 1, "timestep": 253, "ep_reward": 118.76576232910156, "reward": 0.44253551959991455, "action": 0.27129223942756653}
{"mode": "train", "epochs": 1, "timestep": 254, "ep_reward": 119.23051452636719, "reward": 0.4647523760795593, "action": -0.21161627769470215}
{"mode": "train", "epochs": 1, "timestep": 255, "ep_reward": 119.71466064453125, "reward": 0.48414576053619385, "action": -0.3188313841819763}
{"mode": "train", "epochs": 1, "timestep": 256, "ep_reward": 120.21328735351562, "reward": 0.4986259341239929, "action": 0.28310900926589966}
{"mode": "train", "epochs": 1, "timestep": 257, "ep_reward": 120.72171020507812, "reward": 0.5084199905395508, "action": 0.2391251027584076}
{"mode": "train", "epochs": 1, "timestep": 258, "ep_reward": 121.23564910888672, "reward": 0.5139371156692505, "action": -1.204979658126831}
{"mode": "train", "epochs": 1, "timestep": 259, "ep_reward": 121.74681854248047, "reward": 0.5111703872680664, "action": -0.2539331316947937}
{"mode": "train", "epochs": 1, "timestep": 260, "ep_reward": 122.24857330322266, "reward": 0.5017572045326233, "action": 0.11769977957010269}
{"mode": "train", "epochs": 1, "timestep": 261, "ep_reward": 122.73651885986328, "reward": 0.4879448413848877, "action": 0.30625835061073303}
{"mode": "train", "epochs": 1, "timestep": 262, "ep_reward": 123.20747375488281, "reward": 0.4709523916244507, "action": 0.34265512228012085}
{"mode": "train", "epochs": 1, "timestep": 263, "ep_reward": 123.65892028808594, "reward": 0.4514455199241638, "action": -0.3093605041503906}
{"mode": "train", "epochs": 1, "timestep": 264, "ep_reward": 124.0858154296875, "reward": 0.42689234018325806, "action": 0.8703700304031372}
{"mode": "train", "epochs": 1, "timestep": 265, "ep_reward": 124.4913558959961, "reward": 0.40554332733154297, "action": -0.34881019592285156}
{"mode": "train", "epochs": 1, "timestep": 266, "ep_reward": 124.87083435058594, "reward": 0.3794761300086975, "action": -0.03327547013759613}
{"mode": "train", "epochs": 1, "timestep": 267, "ep_reward": 125.26240539550781, "reward": 0.39156943559646606, "action": 0.7610906958580017}
{"mode": "train", "epochs": 1, "timestep": 268, "ep_reward": 125.67786407470703, "reward": 0.4154570698738098, "action": -0.6247760653495789}
{"mode": "train", "epochs": 1, "timestep": 269, "ep_reward": 126.1146011352539, "reward": 0.4367348551750183, "action": 0.7620755434036255}
{"mode": "train", "epochs": 1, "timestep": 270, "ep_reward": 126.57118225097656, "reward": 0.4565780758857727, "action": 0.3871029317378998}
{"mode": "train", "epochs": 1, "timestep": 271, "ep_reward": 127.0426025390625, "reward": 0.47141772508621216, "action": 0.27439549565315247}
{"mode": "train", "epochs": 1, "timestep": 272, "ep_reward": 127.52421569824219, "reward": 0.48161184787750244, "action": -0.5893096923828125}
{"mode": "train", "epochs": 1, "timestep": 273, "ep_reward": 128.01300048828125, "reward": 0.48878931999206543, "action": -0.1959165632724762}
{"mode": "train", "epochs": 1, "timestep": 274, "ep_reward": 128.50572204589844, "reward": 0.4927196502685547, "action": 0.69078129529953}
{"mode": "train", "epochs": 1, "timestep": 275, "ep_reward": 128.99620056152344, "reward": 0.490473210811615, "action": -0.10316954553127289}
{"mode": "train", "epochs": 1, "timestep": 276, "ep_reward": 129.48019409179688, "reward": 0.4839860796928406, "action": 0.363150030374527}
{"mode": "train", "epochs": 1, "timestep": 277, "ep_reward": 129.95217895507812, "reward": 0.471985399723053, "action": -0.201667919754982}
{"mode": "train", "epochs": 1, "timestep": 278, "ep_reward": 130.40956115722656, "reward": 0.45737898349761963, "action": -0.11510251462459564}
{"mode": "train", "epochs": 1, "timestep": 279, "ep_reward": 130.84950256347656, "reward": 0.4399433135986328, "action": 0.6432462930679321}
{"mode": "train", "epochs": 1, "timestep": 280, "ep_reward": 131.2664337158203, "reward": 0.41692590713500977, "action": -0.19244155287742615}
{"mode": "train", "epochs": 1, "timestep": 281, "ep_reward": 131.66090393066406, "reward": 0.3944692015647888, "action": -0.27037274837493896}
{"mode": "train", "epochs": 1, "timestep": 282, "ep_reward": 132.0386962890625, "reward": 0.3777947425842285, "action": -0.7011346817016602}
{"mode": "train", "epochs": 1, "timestep": 283, "ep_reward": 132.4378662109375, "reward": 0.399175763130188, "action": 0.14761105179786682}
{"mode": "train", "epochs": 1, "timestep": 284, "ep_reward": 132.8564453125, "reward": 0.4185749888420105, "action": 0.33117416501045227}
{"mode": "train", "epochs": 1, "timestep": 285, "ep_reward": 133.2936553955078, "reward": 0.43720608949661255, "action": 0.04925601929426193}
{"mode": "train", "epochs": 1, "timestep": 286, "ep_reward": 133.74803161621094, "reward": 0.4543834328651428, "action": -0.39738357067108154}
{"mode": "train", "epochs": 1, "timestep": 287, "ep_reward": 134.21630859375, "reward": 0.4682772755622864, "action": -0.337846964597702}
{"mode": "train", "epochs": 1, "timestep": 288, "ep_reward": 134.69384765625, "reward": 0.4775456190109253, "action": -0.4888498783111572}
{"mode": "train", "epochs": 1, "timestep": 289, "ep_reward": 135.17539978027344, "reward": 0.48154711723327637, "action": -0.22949349880218506}
{"mode": "train", "epochs": 1, "timestep": 290, "ep_reward": 135.65599060058594, "reward": 0.4805872440338135, "action": 0.4038732647895813}
{"mode": "train", "epochs": 1, "timestep": 291, "ep_reward": 136.13284301757812, "reward": 0.4768468141555786, "action": -1.008293867111206}
{"mode": "train", "epochs": 1, "timestep": 292, "ep_reward": 136.5986328125, "reward": 0.4657871723175049, "action": 0.048640936613082886}
{"mode": "train", "epochs": 1, "timestep": 293, "ep_reward": 137.0505828857422, "reward": 0.45194828510284424, "action": -0.5771211981773376}
{"mode": "train", "epochs": 1, "timestep": 294, "ep_reward": 137.48324584960938, "reward": 0.4326630234718323, "action": 0.6200428009033203}
{"mode": "train", "epochs": 1, "timestep": 295, "ep_reward": 137.8982391357422, "reward": 0.4149988889694214, "action": -0.11953803896903992}
{"mode": "train", "epochs": 1, "timestep": 296, "ep_reward": 138.2926025390625, "reward": 0.3943634629249573, "action": 0.11018252372741699}
{"mode": "train", "epochs": 1, "timestep": 297, "ep_reward": 138.6715545654297, "reward": 0.3789560794830322, "action": -0.08388471603393555}
{"mode": "train", "epochs": 1, "timestep": 298, "ep_reward": 139.0706787109375, "reward": 0.39913082122802734, "action": 0.04664452746510506}
{"mode": "train", "epochs": 1, "timestep": 299, "ep_reward": 139.4894256591797, "reward": 0.41874396800994873, "action": -0.2992146611213684}
{"mode": "train", "epochs": 1, "timestep": 300, "ep_reward": 139.92654418945312, "reward": 0.4371124505996704, "action": -1.0301016569137573}
{"mode": "train", "epochs": 1, "timestep": 301, "ep_reward": 140.38165283203125, "reward": 0.45511531829833984, "action": -0.12581637501716614}
{"mode": "train", "epochs": 1, "timestep": 302, "ep_reward": 140.8539276123047, "reward": 0.47227948904037476, "action": 0.9758433103561401}
{"mode": "train", "epochs": 1, "timestep": 303, "ep_reward": 141.338623046875, "reward": 0.4846998453140259, "action": -0.7402410507202148}
{"mode": "train", "epochs": 1, "timestep": 304, "ep_reward": 141.83169555664062, "reward": 0.49306899309158325, "action": -0.4233908951282501}
{"mode": "train", "epochs": 1, "timestep": 305, "ep_reward": 142.33038330078125, "reward": 0.4986848831176758, "action": -1.0174124240875244}
{"mode": "train", "epochs": 1, "timestep": 306, "ep_reward": 142.83294677734375, "reward": 0.5025690793991089, "action": 0.26909154653549194}
{"mode": "train", "epochs": 1, "timestep": 307, "ep_reward": 143.33438110351562, "reward": 0.5014359951019287, "action": -0.9888466000556946}
{"mode": "train", "epochs": 1, "timestep": 308, "ep_reward": 143.8329315185547, "reward": 0.49855130910873413, "action": 0.06016127020120621}
{"mode": "train", "epochs": 1, "timestep": 309, "ep_reward": 144.32359313964844, "reward": 0.4906548857688904, "action": -0.5378746390342712}
{"mode": "train", "epochs": 1, "timestep": 310, "ep_reward": 144.80397033691406, "reward": 0.48037004470825195, "action": -0.6570703983306885}
{"mode": "train", "epochs": 1, "timestep": 311, "ep_reward": 145.27230834960938, "reward": 0.46833592653274536, "action": 0.5544369220733643}
{"mode": "train", "epochs": 1, "timestep": 312, "ep_reward": 145.72206115722656, "reward": 0.4497530460357666, "action": 0.5577399134635925}
{"mode": "train", "epochs": 1, "timestep": 313, "ep_reward": 146.14842224121094, "reward": 0.42636263370513916, "action": 0.5371180176734924}
{"mode": "train", "epochs": 1, "timestep": 314, "ep_reward": 146.54766845703125, "reward": 0.3992486000061035, "action": 0.38245677947998047}
{"mode": "train", "epochs": 1, "timestep": 315, "ep_reward": 146.91928100585938, "reward": 0.37161028385162354, "action": 0.7661241292953491}
{"mode": "train", "epochs": 1, "timestep": 316, "ep_reward": 147.31809997558594, "reward": 0.3988185524940491, "action": 0.07942403852939606}
{"mode": "train", "epochs": 1, "timestep": 317, "ep_reward": 147.7454376220703, "reward": 0.42733240127563477, "action": 0.2590576112270355}
{"mode": "train", "epochs": 1, "timestep": 318, "ep_reward": 148.1996307373047, "reward": 0.45419639348983765, "action": -1.3140374422073364}
{"mode": "train", "epochs": 1, "timestep": 319, "ep_reward": 148.677978515625, "reward": 0.4783492088317871, "action": 0.440957248210907}
{"mode": "train", "epochs": 1, "timestep": 320, "ep_reward": 149.17384338378906, "reward": 0.4958707094192505, "action": 0.4858356714248657}
{"mode": "train", "epochs": 1, "timestep": 321, "ep_reward": 149.68421936035156, "reward": 0.510370135307312, "action": 0.49849408864974976}
{"mode": "train", "epochs": 1, "timestep": 322, "ep_reward": 150.20559692382812, "reward": 0.5213848352432251, "action": 0.41564953327178955}
{"mode": "train", "epochs": 1, "timestep": 323, "ep_reward": 150.73391723632812, "reward": 0.5283205509185791, "action": -0.43966251611709595}
{"mode": "train", "epochs": 1, "timestep": 324, "ep_reward": 151.26254272460938, "reward": 0.5286217927932739, "action": -0.7182875871658325}
{"mode": "train", "epochs": 1, "timestep": 325, "ep_reward": 151.78282165527344, "reward": 0.520273745059967, "action": -1.1446239948272705}
{"mode": "train", "epochs": 1, "timestep": 326, "ep_reward": 152.28448486328125, "reward": 0.50166916847229, "action": -0.8466358184814453}
{"mode": "train", "epochs": 1, "timestep": 327, "ep_reward": 152.75938415527344, "reward": 0.4749016761779785, "action": -0.3614575266838074}
{"mode": "train", "epochs": 1, "timestep": 328, "ep_reward": 153.20285034179688, "reward": 0.44347262382507324, "action": -0.7411383390426636}
{"mode": "train", "epochs": 1, "timestep": 329, "ep_reward": 153.60841369628906, "reward": 0.405556321144104, "action": -1.4840810298919678}
{"mode": "train", "epochs": 1, "timestep": 330, "ep_reward": 153.96734619140625, "reward": 0.3589293956756592, "action": -1.000825047492981}
{"mode": "train", "epochs": 1, "timestep": 331, "ep_reward": 154.36056518554688, "reward": 0.39321237802505493, "action": -1.179100513458252}
{"mode": "train", "epochs": 1, "timestep": 332, "ep_reward": 154.7938995361328, "reward": 0.43333566188812256, "action": -0.8818353414535522}
{"mode": "train", "epochs": 1, "timestep": 333, "ep_reward": 155.2687530517578, "reward": 0.4748530387878418, "action": -1.1041326522827148}
{"mode": "train", "epochs": 1, "timestep": 334, "ep_reward": 155.7835693359375, "reward": 0.5148186683654785, "action": -0.6877681016921997}
{"mode": "train", "epochs": 1, "timestep": 335, "ep_reward": 156.33668518066406, "reward": 0.5531165599822998, "action": -1.0147331953048706}
{"mode": "train", "epochs": 1, "timestep": 336, "ep_reward": 156.9230499267578, "reward": 0.5863717198371887, "action": -0.38722294569015503}
{"mode": "train", "epochs": 1, "timestep": 337, "ep_reward": 157.53770446777344, "reward": 0.6146594285964966, "action": -1.3557066917419434}
{"mode": "train", "epochs": 1, "timestep": 338, "ep_reward": 158.1728973388672, "reward": 0.6351966857910156, "action": -1.1319661140441895}
{"mode": "train", "epochs": 1, "timestep": 339, "ep_reward": 158.8229522705078, "reward": 0.6500551700592041, "action": 0.24984818696975708}
{"mode": "train", "epochs": 1, "timestep": 340, "ep_reward": 159.47866821289062, "reward": 0.6557198166847229, "action": -0.2638325095176697}
{"mode": "train", "epochs": 1, "timestep": 341, "ep_reward": 160.1290283203125, "reward": 0.6503623723983765, "action": -0.6161001920700073}
{"mode": "train", "epochs": 1, "timestep": 342, "ep_reward": 160.7650909423828, "reward": 0.6360579133033752, "action": 0.24468863010406494}
{"mode": "train", "epochs": 1, "timestep": 343, "ep_reward": 161.3742218017578, "reward": 0.6091281175613403, "action": -0.9209502339363098}
{"mode": "train", "epochs": 1, "timestep": 344, "ep_reward": 161.95167541503906, "reward": 0.5774509906768799, "action": -0.239272803068161}
{"mode": "train", "epochs": 1, "timestep": 345, "ep_reward": 162.4875030517578, "reward": 0.5358321666717529, "action": -0.8716526031494141}
{"mode": "train", "epochs": 1, "timestep": 346, "ep_reward": 162.9794464111328, "reward": 0.4919375777244568, "action": -0.7616018652915955}
{"mode": "train", "epochs": 1, "timestep": 347, "ep_reward": 163.42405700683594, "reward": 0.4446079134941101, "action": -1.4314923286437988}
{"mode": "train", "epochs": 1, "timestep": 348, "ep_reward": 163.8255615234375, "reward": 0.40150660276412964, "action": -0.6174722909927368}
{"mode": "train", "epochs": 1, "timestep": 349, "ep_reward": 164.18081665039062, "reward": 0.3552547097206116, "action": -0.5089874267578125}
{"mode": "train", "epochs": 1, "timestep": 350, "ep_reward": 164.56703186035156, "reward": 0.3862096667289734, "action": -0.20013028383255005}
{"mode": "train", "epochs": 1, "timestep": 351, "ep_reward": 164.99781799316406, "reward": 0.4307866096496582, "action": -1.3475160598754883}
{"mode": "train", "epochs": 1, "timestep": 352, "ep_reward": 165.47169494628906, "reward": 0.47387558221817017, "action": -1.2415223121643066}
{"mode": "train", "epochs": 1, "timestep": 353, "ep_reward": 165.97996520996094, "reward": 0.5082707405090332, "action": -0.25062286853790283}
{"mode": "train", "epochs": 1, "timestep": 354, "ep_reward": 166.5131378173828, "reward": 0.5331777334213257, "action": -0.5046166777610779}
{"mode": "train", "epochs": 1, "timestep": 355, "ep_reward": 167.0637664794922, "reward": 0.5506287813186646, "action": -1.4712882041931152}
{"mode": "train", "epochs": 1, "timestep": 356, "ep_reward": 167.6212921142578, "reward": 0.557519793510437, "action": -0.987491250038147}
{"mode": "train", "epochs": 1, "timestep": 357, "ep_reward": 168.1737518310547, "reward": 0.5524554252624512, "action": -0.38090962171554565}
{"mode": "train", "epochs": 1, "timestep": 358, "ep_reward": 168.71217346191406, "reward": 0.5384230613708496, "action": -1.216852068901062}
{"mode": "train", "epochs": 1, "timestep": 359, "ep_reward": 169.224609375, "reward": 0.51243656873703, "action": -0.6251611709594727}
{"mode": "train", "epochs": 1, "timestep": 360, "ep_reward": 169.70346069335938, "reward": 0.47885847091674805, "action": -1.3847460746765137}
{"mode": "train", "epochs": 1, "timestep": 361, "ep_reward": 170.13720703125, "reward": 0.43374717235565186, "action": -0.8696913123130798}
{"mode": "train", "epochs": 1, "timestep": 362, "ep_reward": 170.5213165283203, "reward": 0.3841168284416199, "action": -0.8768746256828308}
{"mode": "train", "epochs": 1, "timestep": 363, "ep_reward": 170.88165283203125, "reward": 0.3603341579437256, "action": -1.0936864614486694}
{"mode": "train", "epochs": 1, "timestep": 364, "ep_reward": 171.28688049316406, "reward": 0.4052222967147827, "action": -0.6691802740097046}
{"mode": "train", "epochs": 1, "timestep": 365, "ep_reward": 171.7394561767578, "reward": 0.4525824189186096, "action": -0.8047447204589844}
{"mode": "train", "epochs": 1, "timestep": 366, "ep_reward": 172.23797607421875, "reward": 0.49852269887924194, "action": -0.8239926099777222}
{"mode": "train", "epochs": 1, "timestep": 367, "ep_reward": 172.77989196777344, "reward": 0.5419131517410278, "action": -0.983045220375061}
{"mode": "train", "epochs": 1, "timestep": 368, "ep_reward": 173.36090087890625, "reward": 0.5810052156448364, "action": -0.8607341647148132}
{"mode": "train", "epochs": 1, "timestep": 369, "ep_reward": 173.97605895996094, "reward": 0.6151577830314636, "action": -0.8760345578193665}
{"mode": "train", "epochs": 1, "timestep": 370, "ep_reward": 174.6187286376953, "reward": 0.6426702737808228, "action": -0.5077269077301025}
{"mode": "train", "epochs": 1, "timestep": 371, "ep_reward": 175.28102111816406, "reward": 0.662291407585144, "action": -1.7637789249420166}
{"mode": "train", "epochs": 1, "timestep": 372, "ep_reward": 175.95518493652344, "reward": 0.6741708517074585, "action": -0.18809664249420166}
{"mode": "train", "epochs": 1, "timestep": 373, "ep_reward": 176.63267517089844, "reward": 0.677485466003418, "action": -1.6113700866699219}
{"mode": "train", "epochs": 1, "timestep": 374, "ep_reward": 177.30625915527344, "reward": 0.6735788583755493, "action": -1.1508718729019165}
{"mode": "train", "epochs": 1, "timestep": 375, "ep_reward": 177.96826171875, "reward": 0.6620099544525146, "action": -1.2200742959976196}
{"mode": "train", "epochs": 1, "timestep": 376, "ep_reward": 178.61143493652344, "reward": 0.6431694030761719, "action": -1.8456448316574097}
{"mode": "train", "epochs": 1, "timestep": 377, "ep_reward": 179.2322540283203, "reward": 0.6208164095878601, "action": -1.0486558675765991}
{"mode": "train", "epochs": 1, "timestep": 378, "ep_reward": 179.82252502441406, "reward": 0.5902718901634216, "action": -0.32489562034606934}
{"mode": "train", "epochs": 1, "timestep": 379, "ep_reward": 180.3719024658203, "reward": 0.5493737459182739, "action": -1.814164161682129}
{"mode": "train", "epochs": 1, "timestep": 380, "ep_reward": 180.88369750976562, "reward": 0.5117921829223633, "action": -1.1503713130950928}
{"mode": "train", "epochs": 1, "timestep": 381, "ep_reward": 181.35296630859375, "reward": 0.4692763686180115, "action": -1.3135151863098145}
{"mode": "train", "epochs": 1, "timestep": 382, "ep_reward": 181.78038024902344, "reward": 0.42740869522094727, "action": -0.46445780992507935}
{"mode": "train", "epochs": 1, "timestep": 383, "ep_reward": 182.1613006591797, "reward": 0.38091403245925903, "action": -1.0562485456466675}
{"mode": "train", "epochs": 1, "timestep": 384, "ep_reward": 182.5239715576172, "reward": 0.3626646399497986, "action": -0.42274755239486694}
{"mode": "train", "epochs": 1, "timestep": 385, "ep_reward": 182.93052673339844, "reward": 0.40656185150146484, "action": -0.05384492874145508}
{"mode": "train", "epochs": 1, "timestep": 386, "ep_reward": 183.37803649902344, "reward": 0.44751060009002686, "action": -0.6852092742919922}
{"mode": "train", "epochs": 1, "timestep": 387, "ep_reward": 183.86410522460938, "reward": 0.4860714077949524, "action": -0.2518526315689087}
{"mode": "train", "epochs": 1, "timestep": 388, "ep_reward": 184.38180541992188, "reward": 0.5177032947540283, "action": -1.3781356811523438}
{"mode": "train", "epochs": 1, "timestep": 389, "ep_reward": 184.92431640625, "reward": 0.5425087213516235, "action": -0.8576867580413818}
{"mode": "train", "epochs": 1, "timestep": 390, "ep_reward": 185.48020935058594, "reward": 0.5558898448944092, "action": -1.0523115396499634}
{"mode": "train", "epochs": 1, "timestep": 391, "ep_reward": 186.0385284423828, "reward": 0.5583216547966003, "action": -0.3673080801963806}
{"mode": "train", "epochs": 1, "timestep": 392, "ep_reward": 186.58984375, "reward": 0.5513168573379517, "action": -0.07361626625061035}
{"mode": "train", "epochs": 1, "timestep": 393, "ep_reward": 187.1266326904297, "reward": 0.5367868542671204, "action": -1.2377865314483643}
{"mode": "train", "epochs": 1, "timestep": 394, "ep_reward": 187.63650512695312, "reward": 0.5098692774772644, "action": -1.7097666263580322}
{"mode": "train", "epochs": 1, "timestep": 395, "ep_reward": 188.1060791015625, "reward": 0.46957969665527344, "action": -1.2353241443634033}
{"mode": "train", "epochs": 1, "timestep": 396, "ep_reward": 188.52734375, "reward": 0.4212633967399597, "action": -0.4368526339530945}
{"mode": "train", "epochs": 1, "timestep": 397, "ep_reward": 188.89895629882812, "reward": 0.3716062903404236, "action": -1.5400621891021729}
{"mode": "train", "epochs": 1, "timestep": 398, "ep_reward": 189.26768493652344, "reward": 0.36873388290405273, "action": -1.142958402633667}
{"mode": "train", "epochs": 1, "timestep": 399, "ep_reward": 189.68359375, "reward": 0.4159056544303894, "action": -0.9947910308837891}
{"mode": "train", "epochs": 1, "timestep": 400, "ep_reward": 190.1481475830078, "reward": 0.46455639600753784, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 401, "ep_reward": 190.65835571289062, "reward": 0.5102091431617737, "action": -1.2782845497131348}
{"mode": "train", "epochs": 1, "timestep": 402, "ep_reward": 191.21604919433594, "reward": 0.55769282579422, "action": -1.3918925523757935}
{"mode": "train", "epochs": 1, "timestep": 403, "ep_reward": 191.8175506591797, "reward": 0.6014950275421143, "action": -0.9393976926803589}
{"mode": "train", "epochs": 1, "timestep": 404, "ep_reward": 192.45883178710938, "reward": 0.6412869691848755, "action": -0.6993744969367981}
{"mode": "train", "epochs": 1, "timestep": 405, "ep_reward": 193.1324920654297, "reward": 0.6736539006233215, "action": -1.2939975261688232}
{"mode": "train", "epochs": 1, "timestep": 406, "ep_reward": 193.82916259765625, "reward": 0.6966652870178223, "action": -1.2939203977584839}
{"mode": "train", "epochs": 1, "timestep": 407, "ep_reward": 194.54107666015625, "reward": 0.7119174599647522, "action": -0.9391677975654602}
{"mode": "train", "epochs": 1, "timestep": 408, "ep_reward": 195.259521484375, "reward": 0.7184470891952515, "action": -0.8395517468452454}
{"mode": "train", "epochs": 1, "timestep": 409, "ep_reward": 195.97451782226562, "reward": 0.7149986028671265, "action": -1.1228201389312744}
{"mode": "train", "epochs": 1, "timestep": 410, "ep_reward": 196.67697143554688, "reward": 0.7024610042572021, "action": -0.86057049036026}
{"mode": "train", "epochs": 1, "timestep": 411, "ep_reward": 197.35671997070312, "reward": 0.6797471046447754, "action": -1.5388834476470947}
{"mode": "train", "epochs": 1, "timestep": 412, "ep_reward": 198.00791931152344, "reward": 0.6512030363082886, "action": -0.8541474938392639}
{"mode": "train", "epochs": 1, "timestep": 413, "ep_reward": 198.61997985839844, "reward": 0.6120650768280029, "action": -1.4821951389312744}
{"mode": "train", "epochs": 1, "timestep": 414, "ep_reward": 199.18948364257812, "reward": 0.5695057511329651, "action": -1.074015736579895}
{"mode": "train", "epochs": 1, "timestep": 415, "ep_reward": 199.70938110351562, "reward": 0.519904375076294, "action": -1.2751373052597046}
{"mode": "train", "epochs": 1, "timestep": 416, "ep_reward": 200.17770385742188, "reward": 0.46832746267318726, "action": -1.684278964996338}
{"mode": "train", "epochs": 1, "timestep": 417, "ep_reward": 200.59727478027344, "reward": 0.4195718765258789, "action": -0.9108009338378906}
{"mode": "train", "epochs": 1, "timestep": 418, "ep_reward": 200.96449279785156, "reward": 0.3672252893447876, "action": -1.122987985610962}
{"mode": "train", "epochs": 1, "timestep": 419, "ep_reward": 201.32383728027344, "reward": 0.35934972763061523, "action": -0.700161337852478}
{"mode": "train", "epochs": 1, "timestep": 420, "ep_reward": 201.7350616455078, "reward": 0.4112263321876526, "action": -0.9983531832695007}
{"mode": "train", "epochs": 1, "timestep": 421, "ep_reward": 202.19491577148438, "reward": 0.45985764265060425, "action": -1.0386168956756592}
{"mode": "train", "epochs": 1, "timestep": 422, "ep_reward": 202.69644165039062, "reward": 0.5015296936035156, "action": -1.9282273054122925}
{"mode": "train", "epochs": 1, "timestep": 423, "ep_reward": 203.231201171875, "reward": 0.5347639918327332, "action": 0.007611513137817383}
{"mode": "train", "epochs": 1, "timestep": 424, "ep_reward": 203.7865447998047, "reward": 0.5553464293479919, "action": -0.2939583659172058}
{"mode": "train", "epochs": 1, "timestep": 425, "ep_reward": 204.35496520996094, "reward": 0.5684177875518799, "action": -0.6933781504631042}
{"mode": "train", "epochs": 1, "timestep": 426, "ep_reward": 204.92669677734375, "reward": 0.5717279314994812, "action": -1.2477326393127441}
{"mode": "train", "epochs": 1, "timestep": 427, "ep_reward": 205.4893341064453, "reward": 0.5626412630081177, "action": -0.5256563425064087}
{"mode": "train", "epochs": 1, "timestep": 428, "ep_reward": 206.03277587890625, "reward": 0.5434449911117554, "action": -1.7495691776275635}
{"mode": "train", "epochs": 1, "timestep": 429, "ep_reward": 206.54176330566406, "reward": 0.5089816451072693, "action": -1.0159438848495483}
{"mode": "train", "epochs": 1, "timestep": 430, "ep_reward": 207.00750732421875, "reward": 0.4657461643218994, "action": -0.7689669132232666}
{"mode": "train", "epochs": 1, "timestep": 431, "ep_reward": 207.42349243164062, "reward": 0.41598832607269287, "action": -1.1896849870681763}
{"mode": "train", "epochs": 1, "timestep": 432, "ep_reward": 207.78160095214844, "reward": 0.35810649394989014, "action": -1.1153675317764282}
{"mode": "train", "epochs": 1, "timestep": 433, "ep_reward": 208.1543426513672, "reward": 0.37274372577667236, "action": -0.8957705497741699}
{"mode": "train", "epochs": 1, "timestep": 434, "ep_reward": 208.57749938964844, "reward": 0.4231613278388977, "action": -0.2574513554573059}
{"mode": "train", "epochs": 1, "timestep": 435, "ep_reward": 209.05300903320312, "reward": 0.4755129814147949, "action": -1.0329747200012207}
{"mode": "train", "epochs": 1, "timestep": 436, "ep_reward": 209.5758056640625, "reward": 0.5227981805801392, "action": -1.300926685333252}
{"mode": "train", "epochs": 1, "timestep": 437, "ep_reward": 210.142578125, "reward": 0.566771388053894, "action": -0.9154945611953735}
{"mode": "train", "epochs": 1, "timestep": 438, "ep_reward": 210.75030517578125, "reward": 0.6077330112457275, "action": 0.23643356561660767}
{"mode": "train", "epochs": 1, "timestep": 439, "ep_reward": 211.39352416992188, "reward": 0.6432263851165771, "action": -1.3921235799789429}
{"mode": "train", "epochs": 1, "timestep": 440, "ep_reward": 212.060546875, "reward": 0.6670191287994385, "action": -0.7289371490478516}
{"mode": "train", "epochs": 1, "timestep": 441, "ep_reward": 212.74436950683594, "reward": 0.6838300824165344, "action": -0.5327249765396118}
{"mode": "train", "epochs": 1, "timestep": 442, "ep_reward": 213.43515014648438, "reward": 0.6907864212989807, "action": -1.3889572620391846}
{"mode": "train", "epochs": 1, "timestep": 443, "ep_reward": 214.1245880126953, "reward": 0.6894332766532898, "action": -1.5573267936706543}
{"mode": "train", "epochs": 1, "timestep": 444, "ep_reward": 214.8059844970703, "reward": 0.681393563747406, "action": -1.3099939823150635}
{"mode": "train", "epochs": 1, "timestep": 445, "ep_reward": 215.4718780517578, "reward": 0.6658934354782104, "action": -0.7972412109375}
{"mode": "train", "epochs": 1, "timestep": 446, "ep_reward": 216.1126708984375, "reward": 0.6407891511917114, "action": -1.2297357320785522}
{"mode": "train", "epochs": 1, "timestep": 447, "ep_reward": 216.72239685058594, "reward": 0.6097302436828613, "action": 0.07179111242294312}
{"mode": "train", "epochs": 1, "timestep": 448, "ep_reward": 217.2869415283203, "reward": 0.5645480751991272, "action": -0.5450162887573242}
{"mode": "train", "epochs": 1, "timestep": 449, "ep_reward": 217.80126953125, "reward": 0.5143303871154785, "action": -0.5086519122123718}
{"mode": "train", "epochs": 1, "timestep": 450, "ep_reward": 218.2599639892578, "reward": 0.45870113372802734, "action": -1.3380050659179688}
{"mode": "train", "epochs": 1, "timestep": 451, "ep_reward": 218.66714477539062, "reward": 0.4071848392486572, "action": -0.816115140914917}
{"mode": "train", "epochs": 1, "timestep": 452, "ep_reward": 219.02069091796875, "reward": 0.3535517454147339, "action": -0.9739277362823486}
{"mode": "train", "epochs": 1, "timestep": 453, "ep_reward": 219.3911590576172, "reward": 0.37047499418258667, "action": -0.5702724456787109}
{"mode": "train", "epochs": 1, "timestep": 454, "ep_reward": 219.81411743164062, "reward": 0.4229568839073181, "action": -0.864640474319458}
{"mode": "train", "epochs": 1, "timestep": 455, "ep_reward": 220.28628540039062, "reward": 0.4721675515174866, "action": -0.6509819030761719}
{"mode": "train", "epochs": 1, "timestep": 456, "ep_reward": 220.80052185058594, "reward": 0.5142346620559692, "action": -0.5360201597213745}
{"mode": "train", "epochs": 1, "timestep": 457, "ep_reward": 221.34877014160156, "reward": 0.5482475757598877, "action": -1.2272605895996094}
{"mode": "train", "epochs": 1, "timestep": 458, "ep_reward": 221.9218292236328, "reward": 0.5730533003807068, "action": -1.3011475801467896}
{"mode": "train", "epochs": 1, "timestep": 459, "ep_reward": 222.50656127929688, "reward": 0.5847383737564087, "action": -1.4183919429779053}
{"mode": "train", "epochs": 1, "timestep": 460, "ep_reward": 223.0888214111328, "reward": 0.5822526216506958, "action": -0.5241086483001709}
{"mode": "train", "epochs": 1, "timestep": 461, "ep_reward": 223.65719604492188, "reward": 0.5683811902999878, "action": -1.403386116027832}
{"mode": "train", "epochs": 1, "timestep": 462, "ep_reward": 224.197509765625, "reward": 0.5403095483779907, "action": -0.7854998111724854}
{"mode": "train", "epochs": 1, "timestep": 463, "ep_reward": 224.70004272460938, "reward": 0.5025281310081482, "action": -1.4225963354110718}
{"mode": "train", "epochs": 1, "timestep": 464, "ep_reward": 225.1517333984375, "reward": 0.4516938328742981, "action": -1.129760980606079}
{"mode": "train", "epochs": 1, "timestep": 465, "ep_reward": 225.54525756835938, "reward": 0.39352160692214966, "action": -1.1420270204544067}
{"mode": "train", "epochs": 1, "timestep": 466, "ep_reward": 225.88067626953125, "reward": 0.33542025089263916, "action": -1.4582927227020264}
{"mode": "train", "epochs": 1, "timestep": 467, "ep_reward": 226.26669311523438, "reward": 0.38601154088974, "action": -1.187769889831543}
{"mode": "train", "epochs": 1, "timestep": 468, "ep_reward": 226.70703125, "reward": 0.44033050537109375, "action": -0.7370373010635376}
{"mode": "train", "epochs": 1, "timestep": 469, "ep_reward": 227.2034149169922, "reward": 0.49638038873672485, "action": -1.2770671844482422}
{"mode": "train", "epochs": 1, "timestep": 470, "ep_reward": 227.75149536132812, "reward": 0.5480740070343018, "action": -0.9379663467407227}
{"mode": "train", "epochs": 1, "timestep": 471, "ep_reward": 228.34877014160156, "reward": 0.5972800254821777, "action": -1.0828332901000977}
{"mode": "train", "epochs": 1, "timestep": 472, "ep_reward": 228.98883056640625, "reward": 0.6400611400604248, "action": -0.9713561534881592}
{"mode": "train", "epochs": 1, "timestep": 473, "ep_reward": 229.66465759277344, "reward": 0.675820529460907, "action": -1.2384653091430664}
{"mode": "train", "epochs": 1, "timestep": 474, "ep_reward": 230.36761474609375, "reward": 0.7029550075531006, "action": -0.9792612791061401}
{"mode": "train", "epochs": 1, "timestep": 475, "ep_reward": 231.08934020996094, "reward": 0.7217245101928711, "action": -1.070867657661438}
{"mode": "train", "epochs": 1, "timestep": 476, "ep_reward": 231.8202667236328, "reward": 0.7309281229972839, "action": -1.546323537826538}
{"mode": "train", "epochs": 1, "timestep": 477, "ep_reward": 232.5521240234375, "reward": 0.7318511605262756, "action": -0.1087222695350647}
{"mode": "train", "epochs": 1, "timestep": 478, "ep_reward": 233.27261352539062, "reward": 0.7204855680465698, "action": 0.1699463129043579}
{"mode": "train", "epochs": 1, "timestep": 479, "ep_reward": 233.96681213378906, "reward": 0.6942019462585449, "action": -1.3440308570861816}
{"mode": "train", "epochs": 1, "timestep": 480, "ep_reward": 234.6288299560547, "reward": 0.662010908126831, "action": -0.7915757894515991}
{"mode": "train", "epochs": 1, "timestep": 481, "ep_reward": 235.24725341796875, "reward": 0.6184220314025879, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 482, "ep_reward": 235.82244873046875, "reward": 0.5751928091049194, "action": -0.597861647605896}
{"mode": "train", "epochs": 1, "timestep": 483, "ep_reward": 236.34072875976562, "reward": 0.5182757377624512, "action": -1.8514068126678467}
{"mode": "train", "epochs": 1, "timestep": 484, "ep_reward": 236.80714416503906, "reward": 0.4664115309715271, "action": -1.4335362911224365}
{"mode": "train", "epochs": 1, "timestep": 485, "ep_reward": 237.21926879882812, "reward": 0.4121188521385193, "action": -1.2020779848098755}
{"mode": "train", "epochs": 1, "timestep": 486, "ep_reward": 237.57723999023438, "reward": 0.35797178745269775, "action": -1.3484338521957397}
{"mode": "train", "epochs": 1, "timestep": 487, "ep_reward": 237.93771362304688, "reward": 0.3604661822319031, "action": -0.44335663318634033}
{"mode": "train", "epochs": 1, "timestep": 488, "ep_reward": 238.35215759277344, "reward": 0.41445034742355347, "action": -0.5508522987365723}
{"mode": "train", "epochs": 1, "timestep": 489, "ep_reward": 238.8177032470703, "reward": 0.4655473828315735, "action": -0.8754711151123047}
{"mode": "train", "epochs": 1, "timestep": 490, "ep_reward": 239.32925415039062, "reward": 0.511553168296814, "action": -1.1185617446899414}
{"mode": "train", "epochs": 1, "timestep": 491, "ep_reward": 239.87826538085938, "reward": 0.5490072965621948, "action": -0.9297831654548645}
{"mode": "train", "epochs": 1, "timestep": 492, "ep_reward": 240.4531707763672, "reward": 0.5749126672744751, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 493, "ep_reward": 241.04100036621094, "reward": 0.5878362059593201, "action": -0.6273476481437683}
{"mode": "train", "epochs": 1, "timestep": 494, "ep_reward": 241.62791442871094, "reward": 0.5869065523147583, "action": -0.30793213844299316}
{"mode": "train", "epochs": 1, "timestep": 495, "ep_reward": 242.2037353515625, "reward": 0.5758168697357178, "action": -0.967487096786499}
{"mode": "train", "epochs": 1, "timestep": 496, "ep_reward": 242.7560272216797, "reward": 0.5522953271865845, "action": -0.7803676128387451}
{"mode": "train", "epochs": 1, "timestep": 497, "ep_reward": 243.2740936279297, "reward": 0.5180644989013672, "action": -1.356454849243164}
{"mode": "train", "epochs": 1, "timestep": 498, "ep_reward": 243.7448272705078, "reward": 0.47072768211364746, "action": -1.043858289718628}
{"mode": "train", "epochs": 1, "timestep": 499, "ep_reward": 244.1604461669922, "reward": 0.41562241315841675, "action": -0.050061047077178955}
{"mode": "train", "epochs": 1, "timestep": 500, "ep_reward": 244.5224609375, "reward": 0.3620145916938782, "action": -0.6153762936592102}
{"mode": "train", "epochs": 1, "timestep": 501, "ep_reward": 244.89100646972656, "reward": 0.3685484528541565, "action": -1.0533791780471802}
{"mode": "train", "epochs": 1, "timestep": 502, "ep_reward": 245.30894470214844, "reward": 0.41794508695602417, "action": -1.1427457332611084}
{"mode": "train", "epochs": 1, "timestep": 503, "ep_reward": 245.77711486816406, "reward": 0.46817106008529663, "action": -0.5656481981277466}
{"mode": "train", "epochs": 1, "timestep": 504, "ep_reward": 246.29635620117188, "reward": 0.5192345380783081, "action": -0.7991346120834351}
{"mode": "train", "epochs": 1, "timestep": 505, "ep_reward": 246.8618621826172, "reward": 0.5655115842819214, "action": -1.6508979797363281}
{"mode": "train", "epochs": 1, "timestep": 506, "ep_reward": 247.46719360351562, "reward": 0.6053320169448853, "action": -0.5699841976165771}
{"mode": "train", "epochs": 1, "timestep": 507, "ep_reward": 248.10971069335938, "reward": 0.6425137519836426, "action": -0.23051339387893677}
{"mode": "train", "epochs": 1, "timestep": 508, "ep_reward": 248.78062438964844, "reward": 0.6709116697311401, "action": -1.0727896690368652}
{"mode": "train", "epochs": 1, "timestep": 509, "ep_reward": 249.46929931640625, "reward": 0.6886755228042603, "action": -1.8322081565856934}
{"mode": "train", "epochs": 1, "timestep": 510, "ep_reward": 250.1685333251953, "reward": 0.6992365121841431, "action": -1.2570481300354004}
{"mode": "train", "epochs": 1, "timestep": 511, "ep_reward": 250.87127685546875, "reward": 0.7027472257614136, "action": -1.19692862033844}
{"mode": "train", "epochs": 1, "timestep": 512, "ep_reward": 251.5693359375, "reward": 0.6980643272399902, "action": -0.7334425449371338}
{"mode": "train", "epochs": 1, "timestep": 513, "ep_reward": 252.2527313232422, "reward": 0.6833984851837158, "action": -0.641583263874054}
{"mode": "train", "epochs": 1, "timestep": 514, "ep_reward": 252.91111755371094, "reward": 0.6583860516548157, "action": -1.0199953317642212}
{"mode": "train", "epochs": 1, "timestep": 515, "ep_reward": 253.53677368164062, "reward": 0.6256574392318726, "action": -1.5295350551605225}
{"mode": "train", "epochs": 1, "timestep": 516, "ep_reward": 254.1255645751953, "reward": 0.588797926902771, "action": -1.1914119720458984}
{"mode": "train", "epochs": 1, "timestep": 517, "ep_reward": 254.67086791992188, "reward": 0.5453093647956848, "action": -1.0644594430923462}
{"mode": "train", "epochs": 1, "timestep": 518, "ep_reward": 255.16786193847656, "reward": 0.49699854850769043, "action": -0.9079409837722778}
{"mode": "train", "epochs": 1, "timestep": 519, "ep_reward": 255.61294555664062, "reward": 0.4450903534889221, "action": -0.9190391898155212}
{"mode": "train", "epochs": 1, "timestep": 520, "ep_reward": 256.0055847167969, "reward": 0.392633318901062, "action": -0.33089280128479004}
{"mode": "train", "epochs": 1, "timestep": 521, "ep_reward": 256.342529296875, "reward": 0.33693885803222656, "action": -0.7390084266662598}
{"mode": "train", "epochs": 1, "timestep": 522, "ep_reward": 256.7294006347656, "reward": 0.38688379526138306, "action": -1.0306549072265625}
{"mode": "train", "epochs": 1, "timestep": 523, "ep_reward": 257.16943359375, "reward": 0.44003939628601074, "action": -0.246687650680542}
{"mode": "train", "epochs": 1, "timestep": 524, "ep_reward": 257.6552734375, "reward": 0.48585450649261475, "action": -0.505363941192627}
{"mode": "train", "epochs": 1, "timestep": 525, "ep_reward": 258.18182373046875, "reward": 0.5265353322029114, "action": -1.6366333961486816}
{"mode": "train", "epochs": 1, "timestep": 526, "ep_reward": 258.7415466308594, "reward": 0.5597358345985413, "action": -0.826546311378479}
{"mode": "train", "epochs": 1, "timestep": 527, "ep_reward": 259.3210144042969, "reward": 0.5794639587402344, "action": -0.22044473886489868}
{"mode": "train", "epochs": 1, "timestep": 528, "ep_reward": 259.90972900390625, "reward": 0.588706374168396, "action": -0.09062528610229492}
{"mode": "train", "epochs": 1, "timestep": 529, "ep_reward": 260.49847412109375, "reward": 0.588739812374115, "action": -1.0551121234893799}
{"mode": "train", "epochs": 1, "timestep": 530, "ep_reward": 261.07501220703125, "reward": 0.5765349864959717, "action": -0.2749086618423462}
{"mode": "train", "epochs": 1, "timestep": 531, "ep_reward": 261.62994384765625, "reward": 0.5549267530441284, "action": -0.34256547689437866}
{"mode": "train", "epochs": 1, "timestep": 532, "ep_reward": 262.1540222167969, "reward": 0.5240721702575684, "action": -1.51310133934021}
{"mode": "train", "epochs": 1, "timestep": 533, "ep_reward": 262.6323547363281, "reward": 0.4783470630645752, "action": -0.5503321886062622}
{"mode": "train", "epochs": 1, "timestep": 534, "ep_reward": 263.060546875, "reward": 0.42818182706832886, "action": -1.514580249786377}
{"mode": "train", "epochs": 1, "timestep": 535, "ep_reward": 263.4264831542969, "reward": 0.36593377590179443, "action": -1.2293251752853394}
{"mode": "train", "epochs": 1, "timestep": 536, "ep_reward": 263.78472900390625, "reward": 0.3582558035850525, "action": -1.7743536233901978}
{"mode": "train", "epochs": 1, "timestep": 537, "ep_reward": 264.19354248046875, "reward": 0.408814013004303, "action": -1.95637845993042}
{"mode": "train", "epochs": 1, "timestep": 538, "ep_reward": 264.6551818847656, "reward": 0.4616406559944153, "action": -1.5239813327789307}
{"mode": "train", "epochs": 1, "timestep": 539, "ep_reward": 265.17266845703125, "reward": 0.5174846053123474, "action": -0.4981112480163574}
{"mode": "train", "epochs": 1, "timestep": 540, "ep_reward": 265.74737548828125, "reward": 0.5746927857398987, "action": -1.8400089740753174}
{"mode": "train", "epochs": 1, "timestep": 541, "ep_reward": 266.36907958984375, "reward": 0.6216943860054016, "action": -0.9745403528213501}
{"mode": "train", "epochs": 1, "timestep": 542, "ep_reward": 267.03521728515625, "reward": 0.6661350131034851, "action": -1.3148099184036255}
{"mode": "train", "epochs": 1, "timestep": 543, "ep_reward": 267.7369384765625, "reward": 0.7017316222190857, "action": -0.2741752862930298}
{"mode": "train", "epochs": 1, "timestep": 544, "ep_reward": 268.4665832519531, "reward": 0.7296416163444519, "action": -0.535873532295227}
{"mode": "train", "epochs": 1, "timestep": 545, "ep_reward": 269.2115173339844, "reward": 0.7449318170547485, "action": -1.4400969743728638}
{"mode": "train", "epochs": 1, "timestep": 546, "ep_reward": 269.96142578125, "reward": 0.749901533126831, "action": -1.4901084899902344}
{"mode": "train", "epochs": 1, "timestep": 547, "ep_reward": 270.7078552246094, "reward": 0.7464311122894287, "action": -1.6575677394866943}
{"mode": "train", "epochs": 1, "timestep": 548, "ep_reward": 271.4430847167969, "reward": 0.7352300882339478, "action": -1.092653751373291}
{"mode": "train", "epochs": 1, "timestep": 549, "ep_reward": 272.1569519042969, "reward": 0.7138788104057312, "action": -0.7335494756698608}
{"mode": "train", "epochs": 1, "timestep": 550, "ep_reward": 272.8377990722656, "reward": 0.6808339357376099, "action": -1.2907636165618896}
{"mode": "train", "epochs": 1, "timestep": 551, "ep_reward": 273.47845458984375, "reward": 0.6406411528587341, "action": -1.4650629758834839}
{"mode": "train", "epochs": 1, "timestep": 552, "ep_reward": 274.0727233886719, "reward": 0.594255805015564, "action": -0.7489367723464966}
{"mode": "train", "epochs": 1, "timestep": 553, "ep_reward": 274.6094665527344, "reward": 0.5367570519447327, "action": -1.4039711952209473}
{"mode": "train", "epochs": 1, "timestep": 554, "ep_reward": 275.08831787109375, "reward": 0.47884660959243774, "action": -1.5568718910217285}
{"mode": "train", "epochs": 1, "timestep": 555, "ep_reward": 275.5096130371094, "reward": 0.42129236459732056, "action": -0.7398837208747864}
{"mode": "train", "epochs": 1, "timestep": 556, "ep_reward": 275.8680114746094, "reward": 0.35838931798934937, "action": -0.6746057271957397}
{"mode": "train", "epochs": 1, "timestep": 557, "ep_reward": 276.2091064453125, "reward": 0.3410818576812744, "action": -0.4843480587005615}
{"mode": "train", "epochs": 1, "timestep": 558, "ep_reward": 276.61260986328125, "reward": 0.4034919738769531, "action": -0.9580364227294922}
{"mode": "train", "epochs": 1, "timestep": 559, "ep_reward": 277.0768127441406, "reward": 0.46421515941619873, "action": -1.2328810691833496}
{"mode": "train", "epochs": 1, "timestep": 560, "ep_reward": 277.5950622558594, "reward": 0.5182632207870483, "action": -1.6586135625839233}
{"mode": "train", "epochs": 1, "timestep": 561, "ep_reward": 278.1573181152344, "reward": 0.5622640252113342, "action": -0.5758557319641113}
{"mode": "train", "epochs": 1, "timestep": 562, "ep_reward": 278.7489013671875, "reward": 0.5915834903717041, "action": -1.5166068077087402}
{"mode": "train", "epochs": 1, "timestep": 563, "ep_reward": 279.3579406738281, "reward": 0.6090397238731384, "action": -1.0882586240768433}
{"mode": "train", "epochs": 1, "timestep": 564, "ep_reward": 279.96929931640625, "reward": 0.6113601922988892, "action": -0.5826878547668457}
{"mode": "train", "epochs": 1, "timestep": 565, "ep_reward": 280.5702819824219, "reward": 0.6009854674339294, "action": -0.3694606423377991}
{"mode": "train", "epochs": 1, "timestep": 566, "ep_reward": 281.14984130859375, "reward": 0.5795563459396362, "action": -1.167629361152649}
{"mode": "train", "epochs": 1, "timestep": 567, "ep_reward": 281.6933288574219, "reward": 0.5434932708740234, "action": -1.6259334087371826}
{"mode": "train", "epochs": 1, "timestep": 568, "ep_reward": 282.1852722167969, "reward": 0.4919561743736267, "action": -0.6005209684371948}
{"mode": "train", "epochs": 1, "timestep": 569, "ep_reward": 282.6206359863281, "reward": 0.43537092208862305, "action": -1.0219355821609497}
{"mode": "train", "epochs": 1, "timestep": 570, "ep_reward": 282.9903259277344, "reward": 0.3696902394294739, "action": -1.248732089996338}
{"mode": "train", "epochs": 1, "timestep": 571, "ep_reward": 283.3320007324219, "reward": 0.34167689085006714, "action": -1.0976507663726807}
{"mode": "train", "epochs": 1, "timestep": 572, "ep_reward": 283.7307434082031, "reward": 0.3987507224082947, "action": -0.5801557302474976}
{"mode": "train", "epochs": 1, "timestep": 573, "ep_reward": 284.189697265625, "reward": 0.45896798372268677, "action": -1.8339731693267822}
{"mode": "train", "epochs": 1, "timestep": 574, "ep_reward": 284.70294189453125, "reward": 0.5132336616516113, "action": -0.9228247404098511}
{"mode": "train", "epochs": 1, "timestep": 575, "ep_reward": 285.272705078125, "reward": 0.5697498321533203, "action": -0.9295187592506409}
{"mode": "train", "epochs": 1, "timestep": 576, "ep_reward": 285.8934326171875, "reward": 0.6207407712936401, "action": -1.5565986633300781}
{"mode": "train", "epochs": 1, "timestep": 577, "ep_reward": 286.5567626953125, "reward": 0.663322389125824, "action": -1.0284456014633179}
{"mode": "train", "epochs": 1, "timestep": 578, "ep_reward": 287.25701904296875, "reward": 0.7002650499343872, "action": -0.5827888250350952}
{"mode": "train", "epochs": 1, "timestep": 579, "ep_reward": 287.9852600097656, "reward": 0.7282507419586182, "action": -0.7545331120491028}
{"mode": "train", "epochs": 1, "timestep": 580, "ep_reward": 288.73004150390625, "reward": 0.74479079246521, "action": -1.6311055421829224}
{"mode": "train", "epochs": 1, "timestep": 581, "ep_reward": 289.4818115234375, "reward": 0.751778244972229, "action": -0.9664265513420105}
{"mode": "train", "epochs": 1, "timestep": 582, "ep_reward": 290.23114013671875, "reward": 0.7493323087692261, "action": -0.895684003829956}
{"mode": "train", "epochs": 1, "timestep": 583, "ep_reward": 290.96722412109375, "reward": 0.7360953092575073, "action": -1.6670961380004883}
{"mode": "train", "epochs": 1, "timestep": 584, "ep_reward": 291.6828918457031, "reward": 0.7156750559806824, "action": -1.2068086862564087}
{"mode": "train", "epochs": 1, "timestep": 585, "ep_reward": 292.3680725097656, "reward": 0.6851668953895569, "action": -1.582728385925293}
{"mode": "train", "epochs": 1, "timestep": 586, "ep_reward": 293.0162658691406, "reward": 0.6481904983520508, "action": -1.1891207695007324}
{"mode": "train", "epochs": 1, "timestep": 587, "ep_reward": 293.61822509765625, "reward": 0.601954996585846, "action": -0.5826148390769958}
{"mode": "train", "epochs": 1, "timestep": 588, "ep_reward": 294.1625671386719, "reward": 0.5443493127822876, "action": -0.58963942527771}
{"mode": "train", "epochs": 1, "timestep": 589, "ep_reward": 294.6423645019531, "reward": 0.47981178760528564, "action": -1.0668034553527832}
{"mode": "train", "epochs": 1, "timestep": 590, "ep_reward": 295.0578308105469, "reward": 0.4154772162437439, "action": -0.8729480504989624}
{"mode": "train", "epochs": 1, "timestep": 591, "ep_reward": 295.40765380859375, "reward": 0.34981000423431396, "action": -0.8973183631896973}
{"mode": "train", "epochs": 1, "timestep": 592, "ep_reward": 295.74700927734375, "reward": 0.33934491872787476, "action": -0.5403077006340027}
{"mode": "train", "epochs": 1, "timestep": 593, "ep_reward": 296.1517028808594, "reward": 0.4047009348869324, "action": -0.6610044240951538}
{"mode": "train", "epochs": 1, "timestep": 594, "ep_reward": 296.6188659667969, "reward": 0.4671581983566284, "action": -0.7407224178314209}
{"mode": "train", "epochs": 1, "timestep": 595, "ep_reward": 297.1423645019531, "reward": 0.5234880447387695, "action": -1.0643055438995361}
{"mode": "train", "epochs": 1, "timestep": 596, "ep_reward": 297.7137145996094, "reward": 0.5713468194007874, "action": -0.7036522626876831}
{"mode": "train", "epochs": 1, "timestep": 597, "ep_reward": 298.3202209472656, "reward": 0.6065112352371216, "action": -1.1719001531600952}
{"mode": "train", "epochs": 1, "timestep": 598, "ep_reward": 298.94940185546875, "reward": 0.629193902015686, "action": 0.03165733814239502}
{"mode": "train", "epochs": 1, "timestep": 599, "ep_reward": 299.5876770019531, "reward": 0.6382614374160767, "action": -1.7587898969650269}
{"mode": "train", "epochs": 1, "timestep": 600, "ep_reward": 300.2198181152344, "reward": 0.6321384906768799, "action": -0.9673265218734741}
{"mode": "train", "epochs": 1, "timestep": 601, "ep_reward": 300.8302917480469, "reward": 0.6104724407196045, "action": 0.023620903491973877}
{"mode": "train", "epochs": 1, "timestep": 602, "ep_reward": 301.4097900390625, "reward": 0.5794879198074341, "action": -1.0365294218063354}
{"mode": "train", "epochs": 1, "timestep": 603, "ep_reward": 301.94268798828125, "reward": 0.5328894853591919, "action": -0.9900604486465454}
{"mode": "train", "epochs": 1, "timestep": 604, "ep_reward": 302.41729736328125, "reward": 0.4746003746986389, "action": -0.714363694190979}
{"mode": "train", "epochs": 1, "timestep": 605, "ep_reward": 302.8264465332031, "reward": 0.4091455936431885, "action": -1.0593458414077759}
{"mode": "train", "epochs": 1, "timestep": 606, "ep_reward": 303.161865234375, "reward": 0.3354233503341675, "action": -1.0521906614303589}
{"mode": "train", "epochs": 1, "timestep": 607, "ep_reward": 303.5180969238281, "reward": 0.3562377691268921, "action": -0.5911825299263}
{"mode": "train", "epochs": 1, "timestep": 608, "ep_reward": 303.93780517578125, "reward": 0.41970574855804443, "action": -0.4326121211051941}
{"mode": "train", "epochs": 1, "timestep": 609, "ep_reward": 304.4209899902344, "reward": 0.48319298028945923, "action": -0.3419349789619446}
{"mode": "train", "epochs": 1, "timestep": 610, "ep_reward": 304.9643249511719, "reward": 0.5433378219604492, "action": -1.4328640699386597}
{"mode": "train", "epochs": 1, "timestep": 611, "ep_reward": 305.5586242675781, "reward": 0.5943039655685425, "action": -0.9587329030036926}
{"mode": "train", "epochs": 1, "timestep": 612, "ep_reward": 306.20025634765625, "reward": 0.6416370868682861, "action": -1.5842434167861938}
{"mode": "train", "epochs": 1, "timestep": 613, "ep_reward": 306.88055419921875, "reward": 0.680305004119873, "action": -0.4860804080963135}
{"mode": "train", "epochs": 1, "timestep": 614, "ep_reward": 307.59381103515625, "reward": 0.7132707834243774, "action": -0.7234512567520142}
{"mode": "train", "epochs": 1, "timestep": 615, "ep_reward": 308.32861328125, "reward": 0.7348122596740723, "action": -0.4329169988632202}
{"mode": "train", "epochs": 1, "timestep": 616, "ep_reward": 309.07366943359375, "reward": 0.7450677752494812, "action": -0.46498388051986694}
{"mode": "train", "epochs": 1, "timestep": 617, "ep_reward": 309.8166198730469, "reward": 0.7429624199867249, "action": -1.305951476097107}
{"mode": "train", "epochs": 1, "timestep": 618, "ep_reward": 310.54791259765625, "reward": 0.7312918901443481, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 619, "ep_reward": 311.2616271972656, "reward": 0.7137057781219482, "action": -1.6012603044509888}
{"mode": "train", "epochs": 1, "timestep": 620, "ep_reward": 311.9496154785156, "reward": 0.6880013942718506, "action": -0.5125781297683716}
{"mode": "train", "epochs": 1, "timestep": 621, "ep_reward": 312.5981750488281, "reward": 0.648573637008667, "action": -1.2683122158050537}
{"mode": "train", "epochs": 1, "timestep": 622, "ep_reward": 313.20172119140625, "reward": 0.6035507917404175, "action": -1.8042654991149902}
{"mode": "train", "epochs": 1, "timestep": 623, "ep_reward": 313.7578430175781, "reward": 0.5561325550079346, "action": -1.9872856140136719}
{"mode": "train", "epochs": 1, "timestep": 624, "ep_reward": 314.265380859375, "reward": 0.5075243711471558, "action": -1.4053611755371094}
{"mode": "train", "epochs": 1, "timestep": 625, "ep_reward": 314.719482421875, "reward": 0.45411473512649536, "action": -0.2675739526748657}
{"mode": "train", "epochs": 1, "timestep": 626, "ep_reward": 315.1106872558594, "reward": 0.3912188410758972, "action": -1.5846970081329346}
{"mode": "train", "epochs": 1, "timestep": 627, "ep_reward": 315.4498291015625, "reward": 0.33914250135421753, "action": -1.4598815441131592}
{"mode": "train", "epochs": 1, "timestep": 628, "ep_reward": 315.8280334472656, "reward": 0.3781944513320923, "action": -1.5427011251449585}
{"mode": "train", "epochs": 1, "timestep": 629, "ep_reward": 316.2618408203125, "reward": 0.4337962865829468, "action": -0.9786924719810486}
{"mode": "train", "epochs": 1, "timestep": 630, "ep_reward": 316.7425537109375, "reward": 0.48072123527526855, "action": -1.3590357303619385}
{"mode": "train", "epochs": 1, "timestep": 631, "ep_reward": 317.2628173828125, "reward": 0.5202505588531494, "action": -1.3106515407562256}
{"mode": "train", "epochs": 1, "timestep": 632, "ep_reward": 317.8116760253906, "reward": 0.5488574504852295, "action": -0.19223612546920776}
{"mode": "train", "epochs": 1, "timestep": 633, "ep_reward": 318.3780822753906, "reward": 0.5664067268371582, "action": -1.0212849378585815}
{"mode": "train", "epochs": 1, "timestep": 634, "ep_reward": 318.9523010253906, "reward": 0.5742106437683105, "action": -0.6510229706764221}
{"mode": "train", "epochs": 1, "timestep": 635, "ep_reward": 319.52301025390625, "reward": 0.5707241296768188, "action": -1.5060124397277832}
{"mode": "train", "epochs": 1, "timestep": 636, "ep_reward": 320.0763854980469, "reward": 0.5533871054649353, "action": -1.630772352218628}
{"mode": "train", "epochs": 1, "timestep": 637, "ep_reward": 320.597900390625, "reward": 0.5215175151824951, "action": -1.342350959777832}
{"mode": "train", "epochs": 1, "timestep": 638, "ep_reward": 321.0760192871094, "reward": 0.4781178832054138, "action": 0.03654682636260986}
{"mode": "train", "epochs": 1, "timestep": 639, "ep_reward": 321.5098876953125, "reward": 0.4338752031326294, "action": -1.0569746494293213}
{"mode": "train", "epochs": 1, "timestep": 640, "ep_reward": 321.8888854980469, "reward": 0.37899720668792725, "action": -1.3503150939941406}
{"mode": "train", "epochs": 1, "timestep": 641, "ep_reward": 322.2451171875, "reward": 0.3562241196632385, "action": -0.9886842370033264}
{"mode": "train", "epochs": 1, "timestep": 642, "ep_reward": 322.6509094238281, "reward": 0.4057806134223938, "action": -0.9188966155052185}
{"mode": "train", "epochs": 1, "timestep": 643, "ep_reward": 323.1076965332031, "reward": 0.4567728042602539, "action": -0.8272370100021362}
{"mode": "train", "epochs": 1, "timestep": 644, "ep_reward": 323.6148681640625, "reward": 0.5071620941162109, "action": -1.4772354364395142}
{"mode": "train", "epochs": 1, "timestep": 645, "ep_reward": 324.16815185546875, "reward": 0.5532894134521484, "action": -0.8563964366912842}
{"mode": "train", "epochs": 1, "timestep": 646, "ep_reward": 324.7660827636719, "reward": 0.5979176759719849, "action": -0.5770547389984131}
{"mode": "train", "epochs": 1, "timestep": 647, "ep_reward": 325.4027099609375, "reward": 0.6366312503814697, "action": -0.4891308546066284}
{"mode": "train", "epochs": 1, "timestep": 648, "ep_reward": 326.0694885253906, "reward": 0.6667662858963013, "action": -0.7080435156822205}
{"mode": "train", "epochs": 1, "timestep": 649, "ep_reward": 326.75653076171875, "reward": 0.6870272755622864, "action": -1.2902650833129883}
{"mode": "train", "epochs": 1, "timestep": 650, "ep_reward": 327.4549560546875, "reward": 0.698430061340332, "action": -0.8546617031097412}
{"mode": "train", "epochs": 1, "timestep": 651, "ep_reward": 328.1561279296875, "reward": 0.7011775970458984, "action": -0.7665983438491821}
{"mode": "train", "epochs": 1, "timestep": 652, "ep_reward": 328.8501281738281, "reward": 0.6940006017684937, "action": -1.4736257791519165}
{"mode": "train", "epochs": 1, "timestep": 653, "ep_reward": 329.5299377441406, "reward": 0.679816484451294, "action": -0.3592553734779358}
{"mode": "train", "epochs": 1, "timestep": 654, "ep_reward": 330.18341064453125, "reward": 0.6534757614135742, "action": -0.5429764986038208}
{"mode": "train", "epochs": 1, "timestep": 655, "ep_reward": 330.80059814453125, "reward": 0.617195725440979, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 656, "ep_reward": 331.3821105957031, "reward": 0.5815229415893555, "action": -1.1821651458740234}
{"mode": "train", "epochs": 1, "timestep": 657, "ep_reward": 331.919921875, "reward": 0.537818193435669, "action": 0.1519913673400879}
{"mode": "train", "epochs": 1, "timestep": 658, "ep_reward": 332.4004211425781, "reward": 0.48050355911254883, "action": -0.5814697742462158}
{"mode": "train", "epochs": 1, "timestep": 659, "ep_reward": 332.8232727050781, "reward": 0.4228578805923462, "action": -1.2176423072814941}
{"mode": "train", "epochs": 1, "timestep": 660, "ep_reward": 333.1929626464844, "reward": 0.3696809411048889, "action": -0.7723587155342102}
{"mode": "train", "epochs": 1, "timestep": 661, "ep_reward": 333.5426025390625, "reward": 0.3496360778808594, "action": -1.7214561700820923}
{"mode": "train", "epochs": 1, "timestep": 662, "ep_reward": 333.9503479003906, "reward": 0.40773630142211914, "action": -0.2836267948150635}
{"mode": "train", "epochs": 1, "timestep": 663, "ep_reward": 334.4064025878906, "reward": 0.4560573101043701, "action": -0.6324793696403503}
{"mode": "train", "epochs": 1, "timestep": 664, "ep_reward": 334.9071350097656, "reward": 0.5007191896438599, "action": -0.34339720010757446}
{"mode": "train", "epochs": 1, "timestep": 665, "ep_reward": 335.4449768066406, "reward": 0.5378548502922058, "action": -0.7728920578956604}
{"mode": "train", "epochs": 1, "timestep": 666, "ep_reward": 336.0122375488281, "reward": 0.5672668218612671, "action": -0.5544021725654602}
{"mode": "train", "epochs": 1, "timestep": 667, "ep_reward": 336.5982360839844, "reward": 0.5859926342964172, "action": -1.512243628501892}
{"mode": "train", "epochs": 1, "timestep": 668, "ep_reward": 337.1905212402344, "reward": 0.5922943353652954, "action": -1.4273260831832886}
{"mode": "train", "epochs": 1, "timestep": 669, "ep_reward": 337.7740478515625, "reward": 0.5835303664207458, "action": -0.7445101141929626}
{"mode": "train", "epochs": 1, "timestep": 670, "ep_reward": 338.3367919921875, "reward": 0.5627392530441284, "action": -1.171404242515564}
{"mode": "train", "epochs": 1, "timestep": 671, "ep_reward": 338.865478515625, "reward": 0.5286924839019775, "action": -0.5710641145706177}
{"mode": "train", "epochs": 1, "timestep": 672, "ep_reward": 339.35205078125, "reward": 0.48656779527664185, "action": -1.090535044670105}
{"mode": "train", "epochs": 1, "timestep": 673, "ep_reward": 339.7854309082031, "reward": 0.43337780237197876, "action": -1.4017523527145386}
{"mode": "train", "epochs": 1, "timestep": 674, "ep_reward": 340.156005859375, "reward": 0.3705841898918152, "action": -0.6077309846878052}
{"mode": "train", "epochs": 1, "timestep": 675, "ep_reward": 340.50897216796875, "reward": 0.35295569896698, "action": -1.4182348251342773}
{"mode": "train", "epochs": 1, "timestep": 676, "ep_reward": 340.9131774902344, "reward": 0.404219388961792, "action": -0.26233500242233276}
{"mode": "train", "epochs": 1, "timestep": 677, "ep_reward": 341.3742370605469, "reward": 0.46106308698654175, "action": -0.9062780141830444}
{"mode": "train", "epochs": 1, "timestep": 678, "ep_reward": 341.88751220703125, "reward": 0.5132647156715393, "action": -1.3801007270812988}
{"mode": "train", "epochs": 1, "timestep": 679, "ep_reward": 342.4489440917969, "reward": 0.5614334344863892, "action": -0.5830768346786499}
{"mode": "train", "epochs": 1, "timestep": 680, "ep_reward": 343.0567626953125, "reward": 0.6078163385391235, "action": -1.0270459651947021}
{"mode": "train", "epochs": 1, "timestep": 681, "ep_reward": 343.7027282714844, "reward": 0.6459707021713257, "action": -0.7198165655136108}
{"mode": "train", "epochs": 1, "timestep": 682, "ep_reward": 344.379638671875, "reward": 0.6769133806228638, "action": -1.1403133869171143}
{"mode": "train", "epochs": 1, "timestep": 683, "ep_reward": 345.078125, "reward": 0.6984779834747314, "action": -1.5611547231674194}
{"mode": "train", "epochs": 1, "timestep": 684, "ep_reward": 345.7903137207031, "reward": 0.7121753692626953, "action": -0.5616965293884277}
{"mode": "train", "epochs": 1, "timestep": 685, "ep_reward": 346.5071105957031, "reward": 0.7167891263961792, "action": -1.6128981113433838}
{"mode": "train", "epochs": 1, "timestep": 686, "ep_reward": 347.2204284667969, "reward": 0.7133052945137024, "action": -0.22356873750686646}
{"mode": "train", "epochs": 1, "timestep": 687, "ep_reward": 347.91796875, "reward": 0.6975456476211548, "action": -1.5169703960418701}
{"mode": "train", "epochs": 1, "timestep": 688, "ep_reward": 348.5934143066406, "reward": 0.6754522323608398, "action": -1.1239515542984009}
{"mode": "train", "epochs": 1, "timestep": 689, "ep_reward": 349.2376403808594, "reward": 0.6442188024520874, "action": -1.4246128797531128}
{"mode": "train", "epochs": 1, "timestep": 690, "ep_reward": 349.84490966796875, "reward": 0.6072604656219482, "action": -0.6637586951255798}
{"mode": "train", "epochs": 1, "timestep": 691, "ep_reward": 350.40447998046875, "reward": 0.5595794916152954, "action": -0.9449573159217834}
{"mode": "train", "epochs": 1, "timestep": 692, "ep_reward": 350.9117126464844, "reward": 0.5072289705276489, "action": -1.918076992034912}
{"mode": "train", "epochs": 1, "timestep": 693, "ep_reward": 351.3709411621094, "reward": 0.4592154026031494, "action": -1.9232505559921265}
{"mode": "train", "epochs": 1, "timestep": 694, "ep_reward": 351.7840576171875, "reward": 0.41312122344970703, "action": -0.9219701290130615}
{"mode": "train", "epochs": 1, "timestep": 695, "ep_reward": 352.1467590332031, "reward": 0.3626953363418579, "action": -0.9551357626914978}
{"mode": "train", "epochs": 1, "timestep": 696, "ep_reward": 352.514404296875, "reward": 0.36763960123062134, "action": -1.832452654838562}
{"mode": "train", "epochs": 1, "timestep": 697, "ep_reward": 352.93426513671875, "reward": 0.41985052824020386, "action": -1.1931442022323608}
{"mode": "train", "epochs": 1, "timestep": 698, "ep_reward": 353.39727783203125, "reward": 0.463007390499115, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 699, "ep_reward": 353.8963317871094, "reward": 0.4990478754043579, "action": -0.6294917464256287}
{"mode": "train", "epochs": 1, "timestep": 700, "ep_reward": 354.4193420410156, "reward": 0.5230210423469543, "action": -1.5915260314941406}
{"mode": "train", "epochs": 1, "timestep": 701, "ep_reward": 354.9571533203125, "reward": 0.537811279296875, "action": -1.061741590499878}
{"mode": "train", "epochs": 1, "timestep": 702, "ep_reward": 355.4980773925781, "reward": 0.5409146547317505, "action": -1.134491205215454}
{"mode": "train", "epochs": 1, "timestep": 703, "ep_reward": 356.03106689453125, "reward": 0.5329761505126953, "action": -1.0837981700897217}
{"mode": "train", "epochs": 1, "timestep": 704, "ep_reward": 356.5453796386719, "reward": 0.5143071413040161, "action": -1.0671515464782715}
{"mode": "train", "epochs": 1, "timestep": 705, "ep_reward": 357.0309753417969, "reward": 0.4855942130088806, "action": -1.5271844863891602}
{"mode": "train", "epochs": 1, "timestep": 706, "ep_reward": 357.4764709472656, "reward": 0.44550907611846924, "action": -0.3629685640335083}
{"mode": "train", "epochs": 1, "timestep": 707, "ep_reward": 357.88037109375, "reward": 0.403897762298584, "action": -0.7834576964378357}
{"mode": "train", "epochs": 1, "timestep": 708, "ep_reward": 358.2371520996094, "reward": 0.35679006576538086, "action": -0.777191162109375}
{"mode": "train", "epochs": 1, "timestep": 709, "ep_reward": 358.6285095214844, "reward": 0.3913498520851135, "action": -0.9236150979995728}
{"mode": "train", "epochs": 1, "timestep": 710, "ep_reward": 359.06195068359375, "reward": 0.43345409631729126, "action": -0.6304985284805298}
{"mode": "train", "epochs": 1, "timestep": 711, "ep_reward": 359.53826904296875, "reward": 0.47630584239959717, "action": -0.9064534902572632}
{"mode": "train", "epochs": 1, "timestep": 712, "ep_reward": 360.0549621582031, "reward": 0.5166794061660767, "action": -1.1137635707855225}
{"mode": "train", "epochs": 1, "timestep": 713, "ep_reward": 360.6089782714844, "reward": 0.5540016889572144, "action": -1.2769534587860107}
{"mode": "train", "epochs": 1, "timestep": 714, "ep_reward": 361.19671630859375, "reward": 0.5877243876457214, "action": -0.3240280747413635}
{"mode": "train", "epochs": 1, "timestep": 715, "ep_reward": 361.814208984375, "reward": 0.6174870133399963, "action": -1.2239840030670166}
{"mode": "train", "epochs": 1, "timestep": 716, "ep_reward": 362.4532165527344, "reward": 0.6390219926834106, "action": -0.87684565782547}
{"mode": "train", "epochs": 1, "timestep": 717, "ep_reward": 363.1073303222656, "reward": 0.6541067361831665, "action": -0.9229742884635925}
{"mode": "train", "epochs": 1, "timestep": 718, "ep_reward": 363.76873779296875, "reward": 0.6614219546318054, "action": -0.9334554076194763}
{"mode": "train", "epochs": 1, "timestep": 719, "ep_reward": 364.4295654296875, "reward": 0.6608200669288635, "action": -0.825935959815979}
{"mode": "train", "epochs": 1, "timestep": 720, "ep_reward": 365.0815124511719, "reward": 0.6519334316253662, "action": 0.015123188495635986}
{"mode": "train", "epochs": 1, "timestep": 721, "ep_reward": 365.71282958984375, "reward": 0.6313077211380005, "action": -0.8100770115852356}
{"mode": "train", "epochs": 1, "timestep": 722, "ep_reward": 366.31658935546875, "reward": 0.6037614345550537, "action": -1.009863257408142}
{"mode": "train", "epochs": 1, "timestep": 723, "ep_reward": 366.8869323730469, "reward": 0.5703509449958801, "action": -1.23322594165802}
{"mode": "train", "epochs": 1, "timestep": 724, "ep_reward": 367.4200439453125, "reward": 0.5331000685691833, "action": -1.9975296258926392}
{"mode": "train", "epochs": 1, "timestep": 725, "ep_reward": 367.9182434082031, "reward": 0.49820476770401, "action": -1.0352998971939087}
{"mode": "train", "epochs": 1, "timestep": 726, "ep_reward": 368.37579345703125, "reward": 0.45756399631500244, "action": -1.6310253143310547}
{"mode": "train", "epochs": 1, "timestep": 727, "ep_reward": 368.7964782714844, "reward": 0.4206717014312744, "action": -1.582942008972168}
{"mode": "train", "epochs": 1, "timestep": 728, "ep_reward": 369.18267822265625, "reward": 0.3861891031265259, "action": -1.8708903789520264}
{"mode": "train", "epochs": 1, "timestep": 729, "ep_reward": 369.5531005859375, "reward": 0.3704267740249634, "action": -1.075189471244812}
{"mode": "train", "epochs": 1, "timestep": 730, "ep_reward": 369.95745849609375, "reward": 0.4043431282043457, "action": -0.8460912108421326}
{"mode": "train", "epochs": 1, "timestep": 731, "ep_reward": 370.39129638671875, "reward": 0.43382829427719116, "action": -0.8675418496131897}
{"mode": "train", "epochs": 1, "timestep": 732, "ep_reward": 370.8497009277344, "reward": 0.45840638875961304, "action": -0.9892134666442871}
{"mode": "train", "epochs": 1, "timestep": 733, "ep_reward": 371.3265686035156, "reward": 0.4768790006637573, "action": -0.5617747902870178}
{"mode": "train", "epochs": 1, "timestep": 734, "ep_reward": 371.815185546875, "reward": 0.4886155128479004, "action": -1.5066156387329102}
{"mode": "train", "epochs": 1, "timestep": 735, "ep_reward": 372.3070983886719, "reward": 0.4919143319129944, "action": -1.932992696762085}
{"mode": "train", "epochs": 1, "timestep": 736, "ep_reward": 372.79083251953125, "reward": 0.48374390602111816, "action": -0.893879234790802}
{"mode": "train", "epochs": 1, "timestep": 737, "ep_reward": 373.2586975097656, "reward": 0.46786636114120483, "action": -0.7841002345085144}
{"mode": "train", "epochs": 1, "timestep": 738, "ep_reward": 373.7043151855469, "reward": 0.4456055760383606, "action": -0.8211376667022705}
{"mode": "train", "epochs": 1, "timestep": 739, "ep_reward": 374.1219482421875, "reward": 0.417624831199646, "action": -0.6452683210372925}
{"mode": "train", "epochs": 1, "timestep": 740, "ep_reward": 374.5080871582031, "reward": 0.38613855838775635, "action": -0.29042351245880127}
{"mode": "train", "epochs": 1, "timestep": 741, "ep_reward": 374.8896484375, "reward": 0.3815748691558838, "action": -1.4312725067138672}
{"mode": "train", "epochs": 1, "timestep": 742, "ep_reward": 375.3008117675781, "reward": 0.4111561179161072, "action": -0.8078891634941101}
{"mode": "train", "epochs": 1, "timestep": 743, "ep_reward": 375.7441711425781, "reward": 0.4433544874191284, "action": -1.6136283874511719}
{"mode": "train", "epochs": 1, "timestep": 744, "ep_reward": 376.21923828125, "reward": 0.47505974769592285, "action": -0.6739691495895386}
{"mode": "train", "epochs": 1, "timestep": 745, "ep_reward": 376.72735595703125, "reward": 0.5081295371055603, "action": -0.7234067916870117}
{"mode": "train", "epochs": 1, "timestep": 746, "ep_reward": 377.26531982421875, "reward": 0.5379682183265686, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 747, "ep_reward": 377.8291931152344, "reward": 0.5638723969459534, "action": -1.3623545169830322}
{"mode": "train", "epochs": 1, "timestep": 748, "ep_reward": 378.4178161621094, "reward": 0.5886275172233582, "action": -0.8501195907592773}
{"mode": "train", "epochs": 1, "timestep": 749, "ep_reward": 379.0270080566406, "reward": 0.6091877222061157, "action": -1.4523404836654663}
{"mode": "train", "epochs": 1, "timestep": 750, "ep_reward": 379.6510009765625, "reward": 0.6239997148513794, "action": -1.8737461566925049}
{"mode": "train", "epochs": 1, "timestep": 751, "ep_reward": 380.28582763671875, "reward": 0.6348364949226379, "action": -0.24222594499588013}
{"mode": "train", "epochs": 1, "timestep": 752, "ep_reward": 380.9243469238281, "reward": 0.6385238170623779, "action": -1.7252106666564941}
{"mode": "train", "epochs": 1, "timestep": 753, "ep_reward": 381.5610656738281, "reward": 0.636714518070221, "action": -1.3429031372070312}
{"mode": "train", "epochs": 1, "timestep": 754, "ep_reward": 382.190185546875, "reward": 0.6291312575340271, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 755, "ep_reward": 382.8088684082031, "reward": 0.6186854839324951, "action": -1.223022222518921}
{"mode": "train", "epochs": 1, "timestep": 756, "ep_reward": 383.410888671875, "reward": 0.6020298600196838, "action": -0.7272194623947144}
{"mode": "train", "epochs": 1, "timestep": 757, "ep_reward": 383.98876953125, "reward": 0.5778742432594299, "action": -1.2185678482055664}
{"mode": "train", "epochs": 1, "timestep": 758, "ep_reward": 384.53912353515625, "reward": 0.5503481030464172, "action": -1.0903527736663818}
{"mode": "train", "epochs": 1, "timestep": 759, "ep_reward": 385.057861328125, "reward": 0.5187357068061829, "action": -1.290766716003418}
{"mode": "train", "epochs": 1, "timestep": 760, "ep_reward": 385.54376220703125, "reward": 0.48590219020843506, "action": -0.629571795463562}
{"mode": "train", "epochs": 1, "timestep": 761, "ep_reward": 385.991943359375, "reward": 0.4481964111328125, "action": -1.411625862121582}
{"mode": "train", "epochs": 1, "timestep": 762, "ep_reward": 386.406494140625, "reward": 0.41455167531967163, "action": -0.9264344573020935}
{"mode": "train", "epochs": 1, "timestep": 763, "ep_reward": 386.7867736816406, "reward": 0.3802827000617981, "action": -1.1390959024429321}
{"mode": "train", "epochs": 1, "timestep": 764, "ep_reward": 387.1665344238281, "reward": 0.37975597381591797, "action": -1.2965521812438965}
{"mode": "train", "epochs": 1, "timestep": 765, "ep_reward": 387.5791320800781, "reward": 0.4126020073890686, "action": -1.1851003170013428}
{"mode": "train", "epochs": 1, "timestep": 766, "ep_reward": 388.01904296875, "reward": 0.43989723920822144, "action": -1.0428990125656128}
{"mode": "train", "epochs": 1, "timestep": 767, "ep_reward": 388.48004150390625, "reward": 0.46099168062210083, "action": -0.3545018434524536}
{"mode": "train", "epochs": 1, "timestep": 768, "ep_reward": 388.95611572265625, "reward": 0.4760848879814148, "action": -1.635316252708435}
{"mode": "train", "epochs": 1, "timestep": 769, "ep_reward": 389.4401550292969, "reward": 0.4840403199195862, "action": -0.3194984197616577}
{"mode": "train", "epochs": 1, "timestep": 770, "ep_reward": 389.9252014160156, "reward": 0.4850386381149292, "action": -1.3597564697265625}
{"mode": "train", "epochs": 1, "timestep": 771, "ep_reward": 390.402587890625, "reward": 0.4773815870285034, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 772, "ep_reward": 390.86083984375, "reward": 0.4582422971725464, "action": -0.6914314031600952}
{"mode": "train", "epochs": 1, "timestep": 773, "ep_reward": 391.2951965332031, "reward": 0.43436872959136963, "action": 0.11404824256896973}
{"mode": "train", "epochs": 1, "timestep": 774, "ep_reward": 391.7051696777344, "reward": 0.4099804162979126, "action": -0.44742584228515625}
{"mode": "train", "epochs": 1, "timestep": 775, "ep_reward": 392.0867614746094, "reward": 0.38159412145614624, "action": -1.4155299663543701}
{"mode": "train", "epochs": 1, "timestep": 776, "ep_reward": 392.4749450683594, "reward": 0.3881717324256897, "action": -1.5862846374511719}
{"mode": "train", "epochs": 1, "timestep": 777, "ep_reward": 392.89276123046875, "reward": 0.4178277850151062, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 778, "ep_reward": 393.34259033203125, "reward": 0.4498399496078491, "action": -1.4083998203277588}
{"mode": "train", "epochs": 1, "timestep": 779, "ep_reward": 393.82745361328125, "reward": 0.48487699031829834, "action": -0.9611334800720215}
{"mode": "train", "epochs": 1, "timestep": 780, "ep_reward": 394.3475341796875, "reward": 0.5200774669647217, "action": -1.6522622108459473}
{"mode": "train", "epochs": 1, "timestep": 781, "ep_reward": 394.89984130859375, "reward": 0.5522927045822144, "action": -0.2788047194480896}
{"mode": "train", "epochs": 1, "timestep": 782, "ep_reward": 395.48309326171875, "reward": 0.5832513570785522, "action": -1.253165364265442}
{"mode": "train", "epochs": 1, "timestep": 783, "ep_reward": 396.0901794433594, "reward": 0.6070989370346069, "action": -0.7106660604476929}
{"mode": "train", "epochs": 1, "timestep": 784, "ep_reward": 396.7159118652344, "reward": 0.6257405281066895, "action": -0.19805145263671875}
{"mode": "train", "epochs": 1, "timestep": 785, "ep_reward": 397.3521423339844, "reward": 0.6362349987030029, "action": -0.564355194568634}
{"mode": "train", "epochs": 1, "timestep": 786, "ep_reward": 397.9898986816406, "reward": 0.6377476453781128, "action": -1.0110352039337158}
{"mode": "train", "epochs": 1, "timestep": 787, "ep_reward": 398.6220703125, "reward": 0.6321801543235779, "action": -0.48758363723754883}
{"mode": "train", "epochs": 1, "timestep": 788, "ep_reward": 399.239990234375, "reward": 0.6179345846176147, "action": -0.5129311084747314}
{"mode": "train", "epochs": 1, "timestep": 789, "ep_reward": 399.8354187011719, "reward": 0.5954408645629883, "action": -0.9566043615341187}
{"mode": "train", "epochs": 1, "timestep": 790, "ep_reward": 400.4031982421875, "reward": 0.5677815675735474, "action": -0.6288353204727173}
{"mode": "train", "epochs": 1, "timestep": 791, "ep_reward": 400.9364929199219, "reward": 0.5332869291305542, "action": -0.606579601764679}
{"mode": "train", "epochs": 1, "timestep": 792, "ep_reward": 401.4303283691406, "reward": 0.49384796619415283, "action": -0.36512839794158936}
{"mode": "train", "epochs": 1, "timestep": 793, "ep_reward": 401.8797607421875, "reward": 0.4494261145591736, "action": -0.738648533821106}
{"mode": "train", "epochs": 1, "timestep": 794, "ep_reward": 402.2851257324219, "reward": 0.40536051988601685, "action": -1.1236127614974976}
{"mode": "train", "epochs": 1, "timestep": 795, "ep_reward": 402.6500549316406, "reward": 0.3649161458015442, "action": -0.8815431594848633}
{"mode": "train", "epochs": 1, "timestep": 796, "ep_reward": 403.0340881347656, "reward": 0.3840221166610718, "action": 0.025531411170959473}
{"mode": "train", "epochs": 1, "timestep": 797, "ep_reward": 403.4578857421875, "reward": 0.42378729581832886, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 798, "ep_reward": 403.9214172363281, "reward": 0.4635247588157654, "action": -0.7417864799499512}
{"mode": "train", "epochs": 1, "timestep": 799, "ep_reward": 404.41400146484375, "reward": 0.49257147312164307, "action": -0.6959810256958008}
{"mode": "train", "epochs": 1, "timestep": 800, "ep_reward": 404.9284973144531, "reward": 0.5145102739334106, "action": -0.8555364608764648}
{"mode": "train", "epochs": 1, "timestep": 801, "ep_reward": 405.4568176269531, "reward": 0.5283340215682983, "action": -0.4442932605743408}
{"mode": "train", "epochs": 1, "timestep": 802, "ep_reward": 405.99053955078125, "reward": 0.533716082572937, "action": -1.268369197845459}
{"mode": "train", "epochs": 1, "timestep": 803, "ep_reward": 406.5194396972656, "reward": 0.5289120078086853, "action": -0.7870041728019714}
{"mode": "train", "epochs": 1, "timestep": 804, "ep_reward": 407.0340576171875, "reward": 0.5146265029907227, "action": -1.2886830568313599}
{"mode": "train", "epochs": 1, "timestep": 805, "ep_reward": 407.5234680175781, "reward": 0.489423930644989, "action": -0.5392410755157471}
{"mode": "train", "epochs": 1, "timestep": 806, "ep_reward": 407.9819030761719, "reward": 0.45842623710632324, "action": -0.6340903043746948}
{"mode": "train", "epochs": 1, "timestep": 807, "ep_reward": 408.4032287597656, "reward": 0.4213314652442932, "action": -1.2748541831970215}
{"mode": "train", "epochs": 1, "timestep": 808, "ep_reward": 408.7791442871094, "reward": 0.37591588497161865, "action": -0.6363507509231567}
{"mode": "train", "epochs": 1, "timestep": 809, "ep_reward": 409.15667724609375, "reward": 0.37754619121551514, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 810, "ep_reward": 409.57257080078125, "reward": 0.415902316570282, "action": -0.9996516704559326}
{"mode": "train", "epochs": 1, "timestep": 811, "ep_reward": 410.0319519042969, "reward": 0.4593777060508728, "action": -0.41739827394485474}
{"mode": "train", "epochs": 1, "timestep": 812, "ep_reward": 410.53515625, "reward": 0.5032138824462891, "action": -1.7151321172714233}
{"mode": "train", "epochs": 1, "timestep": 813, "ep_reward": 411.0767822265625, "reward": 0.5416361093521118, "action": -0.3078548312187195}
{"mode": "train", "epochs": 1, "timestep": 814, "ep_reward": 411.656982421875, "reward": 0.5802099704742432, "action": -1.5842628479003906}
{"mode": "train", "epochs": 1, "timestep": 815, "ep_reward": 412.26788330078125, "reward": 0.6109023094177246, "action": -0.6796272993087769}
{"mode": "train", "epochs": 1, "timestep": 816, "ep_reward": 412.90557861328125, "reward": 0.6376829147338867, "action": -0.3039438724517822}
{"mode": "train", "epochs": 1, "timestep": 817, "ep_reward": 413.56170654296875, "reward": 0.6561357975006104, "action": -0.8791261911392212}
{"mode": "train", "epochs": 1, "timestep": 818, "ep_reward": 414.22705078125, "reward": 0.6653491854667664, "action": -0.9370267987251282}
{"mode": "train", "epochs": 1, "timestep": 819, "ep_reward": 414.8934631347656, "reward": 0.6664181351661682, "action": -1.1814762353897095}
{"mode": "train", "epochs": 1, "timestep": 820, "ep_reward": 415.5536193847656, "reward": 0.6601442694664001, "action": -0.7775815725326538}
{"mode": "train", "epochs": 1, "timestep": 821, "ep_reward": 416.1988220214844, "reward": 0.645208477973938, "action": -0.6225770115852356}
{"mode": "train", "epochs": 1, "timestep": 822, "ep_reward": 416.8198547363281, "reward": 0.6210410594940186, "action": -1.8414806127548218}
{"mode": "train", "epochs": 1, "timestep": 823, "ep_reward": 417.4151306152344, "reward": 0.595271110534668, "action": -1.2821602821350098}
{"mode": "train", "epochs": 1, "timestep": 824, "ep_reward": 417.9784240722656, "reward": 0.5632878541946411, "action": -0.12164199352264404}
{"mode": "train", "epochs": 1, "timestep": 825, "ep_reward": 418.49853515625, "reward": 0.520123302936554, "action": -0.14753687381744385}
{"mode": "train", "epochs": 1, "timestep": 826, "ep_reward": 418.9692077636719, "reward": 0.47067415714263916, "action": -0.6468374729156494}
{"mode": "train", "epochs": 1, "timestep": 827, "ep_reward": 419.3897399902344, "reward": 0.42054420709609985, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 828, "ep_reward": 419.7704162597656, "reward": 0.3806864619255066, "action": -1.0104718208312988}
{"mode": "train", "epochs": 1, "timestep": 829, "ep_reward": 420.132080078125, "reward": 0.3616636395454407, "action": -1.488139271736145}
{"mode": "train", "epochs": 1, "timestep": 830, "ep_reward": 420.5396423339844, "reward": 0.4075530171394348, "action": -1.0206360816955566}
{"mode": "train", "epochs": 1, "timestep": 831, "ep_reward": 420.98651123046875, "reward": 0.4468690752983093, "action": -1.0104745626449585}
{"mode": "train", "epochs": 1, "timestep": 832, "ep_reward": 421.466552734375, "reward": 0.48005354404449463, "action": -0.31885409355163574}
{"mode": "train", "epochs": 1, "timestep": 833, "ep_reward": 421.9722595214844, "reward": 0.5057008266448975, "action": -1.7115788459777832}
{"mode": "train", "epochs": 1, "timestep": 834, "ep_reward": 422.4962463378906, "reward": 0.5239967107772827, "action": -1.1520392894744873}
{"mode": "train", "epochs": 1, "timestep": 835, "ep_reward": 423.0269470214844, "reward": 0.53070467710495, "action": -1.214864730834961}
{"mode": "train", "epochs": 1, "timestep": 836, "ep_reward": 423.5536193847656, "reward": 0.5266596078872681, "action": -0.33396267890930176}
{"mode": "train", "epochs": 1, "timestep": 837, "ep_reward": 424.0684814453125, "reward": 0.5148580074310303, "action": -1.5277013778686523}
{"mode": "train", "epochs": 1, "timestep": 838, "ep_reward": 424.5595397949219, "reward": 0.4910563826560974, "action": -1.143595576286316}
{"mode": "train", "epochs": 1, "timestep": 839, "ep_reward": 425.0179748535156, "reward": 0.45842444896698, "action": -0.5046038627624512}
{"mode": "train", "epochs": 1, "timestep": 840, "ep_reward": 425.4396057128906, "reward": 0.4216219186782837, "action": -1.4073455333709717}
{"mode": "train", "epochs": 1, "timestep": 841, "ep_reward": 425.8148193359375, "reward": 0.37520503997802734, "action": -1.3353142738342285}
{"mode": "train", "epochs": 1, "timestep": 842, "ep_reward": 426.19158935546875, "reward": 0.37676388025283813, "action": -0.7368406057357788}
{"mode": "train", "epochs": 1, "timestep": 843, "ep_reward": 426.6106872558594, "reward": 0.4190836548805237, "action": -0.8472767472267151}
{"mode": "train", "epochs": 1, "timestep": 844, "ep_reward": 427.0722351074219, "reward": 0.46153324842453003, "action": -1.0666569471359253}
{"mode": "train", "epochs": 1, "timestep": 845, "ep_reward": 427.5750427246094, "reward": 0.502801775932312, "action": -0.445420503616333}
{"mode": "train", "epochs": 1, "timestep": 846, "ep_reward": 428.1181335449219, "reward": 0.5431010723114014, "action": 0.026232361793518066}
{"mode": "train", "epochs": 1, "timestep": 847, "ep_reward": 428.69659423828125, "reward": 0.5784757137298584, "action": -0.5075619220733643}
{"mode": "train", "epochs": 1, "timestep": 848, "ep_reward": 429.30206298828125, "reward": 0.6054622530937195, "action": -0.7243676781654358}
{"mode": "train", "epochs": 1, "timestep": 849, "ep_reward": 429.9270324707031, "reward": 0.6249682903289795, "action": -1.9336848258972168}
{"mode": "train", "epochs": 1, "timestep": 850, "ep_reward": 430.5657958984375, "reward": 0.6387726664543152, "action": 0.017173051834106445}
{"mode": "train", "epochs": 1, "timestep": 851, "ep_reward": 431.21142578125, "reward": 0.6456440687179565, "action": -0.040203630924224854}
{"mode": "train", "epochs": 1, "timestep": 852, "ep_reward": 431.85302734375, "reward": 0.6415883302688599, "action": -0.33176130056381226}
{"mode": "train", "epochs": 1, "timestep": 853, "ep_reward": 432.4806823730469, "reward": 0.6276649236679077, "action": -1.30821692943573}
{"mode": "train", "epochs": 1, "timestep": 854, "ep_reward": 433.08941650390625, "reward": 0.6087275743484497, "action": -1.6249688863754272}
{"mode": "train", "epochs": 1, "timestep": 855, "ep_reward": 433.6757507324219, "reward": 0.5863388180732727, "action": -1.0160809755325317}
{"mode": "train", "epochs": 1, "timestep": 856, "ep_reward": 434.2331848144531, "reward": 0.5574219226837158, "action": -0.4919350743293762}
{"mode": "train", "epochs": 1, "timestep": 857, "ep_reward": 434.754150390625, "reward": 0.5209572911262512, "action": -1.3428040742874146}
{"mode": "train", "epochs": 1, "timestep": 858, "ep_reward": 435.2394104003906, "reward": 0.48524802923202515, "action": -0.8697788119316101}
{"mode": "train", "epochs": 1, "timestep": 859, "ep_reward": 435.6851501464844, "reward": 0.4457501173019409, "action": -1.8547669649124146}
{"mode": "train", "epochs": 1, "timestep": 860, "ep_reward": 436.0977783203125, "reward": 0.4126168489456177, "action": -1.5467331409454346}
{"mode": "train", "epochs": 1, "timestep": 861, "ep_reward": 436.47906494140625, "reward": 0.3812735080718994, "action": -0.9076540470123291}
{"mode": "train", "epochs": 1, "timestep": 862, "ep_reward": 436.8586730957031, "reward": 0.3796001672744751, "action": -0.41570818424224854}
{"mode": "train", "epochs": 1, "timestep": 863, "ep_reward": 437.2710876464844, "reward": 0.41240394115448, "action": -0.9511489272117615}
{"mode": "train", "epochs": 1, "timestep": 864, "ep_reward": 437.71356201171875, "reward": 0.4424731135368347, "action": -1.8634370565414429}
{"mode": "train", "epochs": 1, "timestep": 865, "ep_reward": 438.1800537109375, "reward": 0.466488242149353, "action": -1.029006838798523}
{"mode": "train", "epochs": 1, "timestep": 866, "ep_reward": 438.661376953125, "reward": 0.48133790493011475, "action": -0.543073296546936}
{"mode": "train", "epochs": 1, "timestep": 867, "ep_reward": 439.1508483886719, "reward": 0.4894593358039856, "action": -0.5698128342628479}
{"mode": "train", "epochs": 1, "timestep": 868, "ep_reward": 439.64215087890625, "reward": 0.4913060665130615, "action": -0.42071497440338135}
{"mode": "train", "epochs": 1, "timestep": 869, "ep_reward": 440.1291809082031, "reward": 0.48701637983322144, "action": -1.5614802837371826}
{"mode": "train", "epochs": 1, "timestep": 870, "ep_reward": 440.60211181640625, "reward": 0.47291839122772217, "action": -0.5769977569580078}
{"mode": "train", "epochs": 1, "timestep": 871, "ep_reward": 441.055419921875, "reward": 0.453316867351532, "action": -1.1170934438705444}
{"mode": "train", "epochs": 1, "timestep": 872, "ep_reward": 441.4813537597656, "reward": 0.42592084407806396, "action": -1.440955400466919}
{"mode": "train", "epochs": 1, "timestep": 873, "ep_reward": 441.8720397949219, "reward": 0.39069032669067383, "action": -1.3729774951934814}
{"mode": "train", "epochs": 1, "timestep": 874, "ep_reward": 442.2471008300781, "reward": 0.375052273273468, "action": -0.6133853197097778}
{"mode": "train", "epochs": 1, "timestep": 875, "ep_reward": 442.65643310546875, "reward": 0.4093230962753296, "action": -1.427854061126709}
{"mode": "train", "epochs": 1, "timestep": 876, "ep_reward": 443.0999755859375, "reward": 0.4435434937477112, "action": -0.7330110669136047}
{"mode": "train", "epochs": 1, "timestep": 877, "ep_reward": 443.5796203613281, "reward": 0.47963863611221313, "action": -1.4636774063110352}
{"mode": "train", "epochs": 1, "timestep": 878, "ep_reward": 444.0930480957031, "reward": 0.5134152770042419, "action": -1.1620306968688965}
{"mode": "train", "epochs": 1, "timestep": 879, "ep_reward": 444.6395263671875, "reward": 0.5464820861816406, "action": -0.7583262324333191}
{"mode": "train", "epochs": 1, "timestep": 880, "ep_reward": 445.2160339355469, "reward": 0.5765054821968079, "action": -1.895329475402832}
{"mode": "train", "epochs": 1, "timestep": 881, "ep_reward": 445.8172607421875, "reward": 0.6012234687805176, "action": -1.4214485883712769}
{"mode": "train", "epochs": 1, "timestep": 882, "ep_reward": 446.4404296875, "reward": 0.6231701374053955, "action": -0.5269883871078491}
{"mode": "train", "epochs": 1, "timestep": 883, "ep_reward": 447.079833984375, "reward": 0.6393910050392151, "action": -1.2369099855422974}
{"mode": "train", "epochs": 1, "timestep": 884, "ep_reward": 447.72808837890625, "reward": 0.6482439041137695, "action": -0.4267895221710205}
{"mode": "train", "epochs": 1, "timestep": 885, "ep_reward": 448.3768615722656, "reward": 0.6487691402435303, "action": -1.51498281955719}
{"mode": "train", "epochs": 1, "timestep": 886, "ep_reward": 449.0201721191406, "reward": 0.6433099508285522, "action": -0.9963154196739197}
{"mode": "train", "epochs": 1, "timestep": 887, "ep_reward": 449.6507263183594, "reward": 0.6305497884750366, "action": -1.2156580686569214}
{"mode": "train", "epochs": 1, "timestep": 888, "ep_reward": 450.26251220703125, "reward": 0.6117875576019287, "action": -1.668260931968689}
{"mode": "train", "epochs": 1, "timestep": 889, "ep_reward": 450.8522644042969, "reward": 0.5897537469863892, "action": -1.3935186862945557}
{"mode": "train", "epochs": 1, "timestep": 890, "ep_reward": 451.415283203125, "reward": 0.5630316734313965, "action": -0.9275122284889221}
{"mode": "train", "epochs": 1, "timestep": 891, "ep_reward": 451.94549560546875, "reward": 0.5302097797393799, "action": -1.8629405498504639}
{"mode": "train", "epochs": 1, "timestep": 892, "ep_reward": 452.4452209472656, "reward": 0.4997186064720154, "action": -0.9393944144248962}
{"mode": "train", "epochs": 1, "timestep": 893, "ep_reward": 452.9090576171875, "reward": 0.46382367610931396, "action": -1.9789694547653198}
{"mode": "train", "epochs": 1, "timestep": 894, "ep_reward": 453.3430480957031, "reward": 0.43398863077163696, "action": -0.9260923266410828}
{"mode": "train", "epochs": 1, "timestep": 895, "ep_reward": 453.743896484375, "reward": 0.4008379578590393, "action": -1.2917063236236572}
{"mode": "train", "epochs": 1, "timestep": 896, "ep_reward": 454.1156921386719, "reward": 0.37178748846054077, "action": -0.6175858974456787}
{"mode": "train", "epochs": 1, "timestep": 897, "ep_reward": 454.50836181640625, "reward": 0.3926583528518677, "action": -1.1265720129013062}
{"mode": "train", "epochs": 1, "timestep": 898, "ep_reward": 454.9305114746094, "reward": 0.42216408252716064, "action": -1.369681477546692}
{"mode": "train", "epochs": 1, "timestep": 899, "ep_reward": 455.3767395019531, "reward": 0.4462386965751648, "action": 0.39799535274505615}
{"mode": "train", "epochs": 1, "timestep": 900, "ep_reward": 455.84161376953125, "reward": 0.4648723006248474, "action": -0.8012040257453918}
{"mode": "train", "epochs": 1, "timestep": 901, "ep_reward": 456.3216552734375, "reward": 0.48002952337265015, "action": -0.8014652132987976}
{"mode": "train", "epochs": 1, "timestep": 902, "ep_reward": 456.8100280761719, "reward": 0.48836755752563477, "action": -1.3767035007476807}
{"mode": "train", "epochs": 1, "timestep": 903, "ep_reward": 457.298095703125, "reward": 0.4880558252334595, "action": -1.4281911849975586}
{"mode": "train", "epochs": 1, "timestep": 904, "ep_reward": 457.77618408203125, "reward": 0.47810351848602295, "action": -0.3126399517059326}
{"mode": "train", "epochs": 1, "timestep": 905, "ep_reward": 458.2393798828125, "reward": 0.46319907903671265, "action": -1.2733385562896729}
{"mode": "train", "epochs": 1, "timestep": 906, "ep_reward": 458.6788635253906, "reward": 0.43949198722839355, "action": -1.034585952758789}
{"mode": "train", "epochs": 1, "timestep": 907, "ep_reward": 459.0885925292969, "reward": 0.4097291827201843, "action": -1.6137863397598267}
{"mode": "train", "epochs": 1, "timestep": 908, "ep_reward": 459.4602966308594, "reward": 0.37170255184173584, "action": -0.9883421659469604}
{"mode": "train", "epochs": 1, "timestep": 909, "ep_reward": 459.8519592285156, "reward": 0.3916701674461365, "action": -1.2746049165725708}
{"mode": "train", "epochs": 1, "timestep": 910, "ep_reward": 460.27728271484375, "reward": 0.425337016582489, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 911, "ep_reward": 460.73736572265625, "reward": 0.46006929874420166, "action": -0.2029377818107605}
{"mode": "train", "epochs": 1, "timestep": 912, "ep_reward": 461.23626708984375, "reward": 0.4989140033721924, "action": -0.8571145534515381}
{"mode": "train", "epochs": 1, "timestep": 913, "ep_reward": 461.76934814453125, "reward": 0.5330801606178284, "action": -0.9499139785766602}
{"mode": "train", "epochs": 1, "timestep": 914, "ep_reward": 462.33306884765625, "reward": 0.5637328624725342, "action": -1.1640560626983643}
{"mode": "train", "epochs": 1, "timestep": 915, "ep_reward": 462.9230651855469, "reward": 0.5900101661682129, "action": -1.5163182020187378}
{"mode": "train", "epochs": 1, "timestep": 916, "ep_reward": 463.53497314453125, "reward": 0.6118943691253662, "action": -1.0794652700424194}
{"mode": "train", "epochs": 1, "timestep": 917, "ep_reward": 464.16424560546875, "reward": 0.6292672157287598, "action": -0.9121344089508057}
{"mode": "train", "epochs": 1, "timestep": 918, "ep_reward": 464.804443359375, "reward": 0.6402043700218201, "action": -0.6714451909065247}
{"mode": "train", "epochs": 1, "timestep": 919, "ep_reward": 465.44775390625, "reward": 0.6433188915252686, "action": -1.456763505935669}
{"mode": "train", "epochs": 1, "timestep": 920, "ep_reward": 466.08819580078125, "reward": 0.6404433846473694, "action": -1.1175020933151245}
{"mode": "train", "epochs": 1, "timestep": 921, "ep_reward": 466.7192077636719, "reward": 0.6310058832168579, "action": -1.0138911008834839}
{"mode": "train", "epochs": 1, "timestep": 922, "ep_reward": 467.3338623046875, "reward": 0.6146522760391235, "action": -1.6982362270355225}
{"mode": "train", "epochs": 1, "timestep": 923, "ep_reward": 467.9292297363281, "reward": 0.5953527688980103, "action": -0.5730049014091492}
{"mode": "train", "epochs": 1, "timestep": 924, "ep_reward": 468.4961242675781, "reward": 0.5668942928314209, "action": -1.3085317611694336}
{"mode": "train", "epochs": 1, "timestep": 925, "ep_reward": 469.0325012207031, "reward": 0.536383867263794, "action": -1.4154402017593384}
{"mode": "train", "epochs": 1, "timestep": 926, "ep_reward": 469.53656005859375, "reward": 0.5040645599365234, "action": -0.7277093529701233}
{"mode": "train", "epochs": 1, "timestep": 927, "ep_reward": 470.0030212402344, "reward": 0.4664728045463562, "action": -0.5283992290496826}
{"mode": "train", "epochs": 1, "timestep": 928, "ep_reward": 470.4289245605469, "reward": 0.42589354515075684, "action": -0.9134831428527832}
{"mode": "train", "epochs": 1, "timestep": 929, "ep_reward": 470.8161926269531, "reward": 0.3872709274291992, "action": -1.5187041759490967}
{"mode": "train", "epochs": 1, "timestep": 930, "ep_reward": 471.1832275390625, "reward": 0.3670451045036316, "action": -0.23520946502685547}
{"mode": "train", "epochs": 1, "timestep": 931, "ep_reward": 471.58660888671875, "reward": 0.40338391065597534, "action": -0.9722695350646973}
{"mode": "train", "epochs": 1, "timestep": 932, "ep_reward": 472.02496337890625, "reward": 0.4383552670478821, "action": -0.818421483039856}
{"mode": "train", "epochs": 1, "timestep": 933, "ep_reward": 472.49267578125, "reward": 0.46772080659866333, "action": -1.142663598060608}
{"mode": "train", "epochs": 1, "timestep": 934, "ep_reward": 472.9832763671875, "reward": 0.49060022830963135, "action": -1.0894447565078735}
{"mode": "train", "epochs": 1, "timestep": 935, "ep_reward": 473.48822021484375, "reward": 0.5049436688423157, "action": -1.283746361732483}
{"mode": "train", "epochs": 1, "timestep": 936, "ep_reward": 473.9980163574219, "reward": 0.509799599647522, "action": -1.2858672142028809}
{"mode": "train", "epochs": 1, "timestep": 937, "ep_reward": 474.50250244140625, "reward": 0.5044865608215332, "action": -0.9782056212425232}
{"mode": "train", "epochs": 1, "timestep": 938, "ep_reward": 474.99261474609375, "reward": 0.49012476205825806, "action": -1.715317726135254}
{"mode": "train", "epochs": 1, "timestep": 939, "ep_reward": 475.4568176269531, "reward": 0.464216411113739, "action": -0.9443935751914978}
{"mode": "train", "epochs": 1, "timestep": 940, "ep_reward": 475.88885498046875, "reward": 0.43202900886535645, "action": -1.3952218294143677}
{"mode": "train", "epochs": 1, "timestep": 941, "ep_reward": 476.2802429199219, "reward": 0.39138948917388916, "action": -1.0498120784759521}
{"mode": "train", "epochs": 1, "timestep": 942, "ep_reward": 476.6487121582031, "reward": 0.3684709668159485, "action": -0.8342195153236389}
{"mode": "train", "epochs": 1, "timestep": 943, "ep_reward": 477.05487060546875, "reward": 0.4061736464500427, "action": -1.1613647937774658}
{"mode": "train", "epochs": 1, "timestep": 944, "ep_reward": 477.4994201660156, "reward": 0.44455355405807495, "action": -1.2449188232421875}
{"mode": "train", "epochs": 1, "timestep": 945, "ep_reward": 477.9828796386719, "reward": 0.48346221446990967, "action": -0.6954936385154724}
{"mode": "train", "epochs": 1, "timestep": 946, "ep_reward": 478.50531005859375, "reward": 0.5224317908287048, "action": -1.144780158996582}
{"mode": "train", "epochs": 1, "timestep": 947, "ep_reward": 479.062744140625, "reward": 0.5574382543563843, "action": -0.6118435859680176}
{"mode": "train", "epochs": 1, "timestep": 948, "ep_reward": 479.6519775390625, "reward": 0.5892300605773926, "action": -0.4445691704750061}
{"mode": "train", "epochs": 1, "timestep": 949, "ep_reward": 480.26654052734375, "reward": 0.6145753860473633, "action": 0.06650084257125854}
{"mode": "train", "epochs": 1, "timestep": 950, "ep_reward": 480.8978576660156, "reward": 0.6313318014144897, "action": -1.6217561960220337}
{"mode": "train", "epochs": 1, "timestep": 951, "ep_reward": 481.5382995605469, "reward": 0.6404383182525635, "action": -0.8149406909942627}
{"mode": "train", "epochs": 1, "timestep": 952, "ep_reward": 482.1813659667969, "reward": 0.6430550813674927, "action": -0.5472298264503479}
{"mode": "train", "epochs": 1, "timestep": 953, "ep_reward": 482.8185119628906, "reward": 0.637158989906311, "action": -0.4191817045211792}
{"mode": "train", "epochs": 1, "timestep": 954, "ep_reward": 483.44061279296875, "reward": 0.6220872402191162, "action": -0.7807957530021667}
{"mode": "train", "epochs": 1, "timestep": 955, "ep_reward": 484.04052734375, "reward": 0.5999289751052856, "action": -0.4108049273490906}
{"mode": "train", "epochs": 1, "timestep": 956, "ep_reward": 484.6094970703125, "reward": 0.5689661502838135, "action": -1.4218138456344604}
{"mode": "train", "epochs": 1, "timestep": 957, "ep_reward": 485.1465759277344, "reward": 0.5370692014694214, "action": -0.6644136905670166}
{"mode": "train", "epochs": 1, "timestep": 958, "ep_reward": 485.64471435546875, "reward": 0.4981342554092407, "action": -0.5802788734436035}
{"mode": "train", "epochs": 1, "timestep": 959, "ep_reward": 486.1000061035156, "reward": 0.45528775453567505, "action": -1.106988787651062}
{"mode": "train", "epochs": 1, "timestep": 960, "ep_reward": 486.5144348144531, "reward": 0.4144304394721985, "action": -0.6624182462692261}
{"mode": "train", "epochs": 1, "timestep": 961, "ep_reward": 486.88641357421875, "reward": 0.3719748258590698, "action": -0.9084277749061584}
{"mode": "train", "epochs": 1, "timestep": 962, "ep_reward": 487.2635192871094, "reward": 0.3771006464958191, "action": -0.4955969452857971}
{"mode": "train", "epochs": 1, "timestep": 963, "ep_reward": 487.681396484375, "reward": 0.41787582635879517, "action": -0.05536240339279175}
{"mode": "train", "epochs": 1, "timestep": 964, "ep_reward": 488.13653564453125, "reward": 0.45512527227401733, "action": -0.8790650963783264}
{"mode": "train", "epochs": 1, "timestep": 965, "ep_reward": 488.62603759765625, "reward": 0.4894868731498718, "action": -1.2796416282653809}
{"mode": "train", "epochs": 1, "timestep": 966, "ep_reward": 489.14227294921875, "reward": 0.5162431597709656, "action": -0.7430258393287659}
{"mode": "train", "epochs": 1, "timestep": 967, "ep_reward": 489.6755065917969, "reward": 0.5332364439964294, "action": -0.32009512186050415}
{"mode": "train", "epochs": 1, "timestep": 968, "ep_reward": 490.217529296875, "reward": 0.5420094728469849, "action": -0.33685487508773804}
{"mode": "train", "epochs": 1, "timestep": 969, "ep_reward": 490.7605285644531, "reward": 0.5429931879043579, "action": 0.09295380115509033}
{"mode": "train", "epochs": 1, "timestep": 970, "ep_reward": 491.29779052734375, "reward": 0.5372750759124756, "action": -1.3778083324432373}
{"mode": "train", "epochs": 1, "timestep": 971, "ep_reward": 491.8177185058594, "reward": 0.5199235081672668, "action": 0.1010403037071228}
{"mode": "train", "epochs": 1, "timestep": 972, "ep_reward": 492.31573486328125, "reward": 0.49800264835357666, "action": -0.9204130172729492}
{"mode": "train", "epochs": 1, "timestep": 973, "ep_reward": 492.78173828125, "reward": 0.4660133123397827, "action": -1.2108173370361328}
{"mode": "train", "epochs": 1, "timestep": 974, "ep_reward": 493.2066955566406, "reward": 0.4249705672264099, "action": -0.732100784778595}
{"mode": "train", "epochs": 1, "timestep": 975, "ep_reward": 493.5870666503906, "reward": 0.38036417961120605, "action": -0.2764386534690857}
{"mode": "train", "epochs": 1, "timestep": 976, "ep_reward": 493.9593505859375, "reward": 0.37229084968566895, "action": -1.3090108633041382}
{"mode": "train", "epochs": 1, "timestep": 977, "ep_reward": 494.37103271484375, "reward": 0.41168898344039917, "action": -0.7381380796432495}
{"mode": "train", "epochs": 1, "timestep": 978, "ep_reward": 494.8249816894531, "reward": 0.4539543390274048, "action": -0.786046028137207}
{"mode": "train", "epochs": 1, "timestep": 979, "ep_reward": 495.3202209472656, "reward": 0.495241641998291, "action": -0.7588623762130737}
{"mode": "train", "epochs": 1, "timestep": 980, "ep_reward": 495.8543701171875, "reward": 0.5341635942459106, "action": -1.3825584650039673}
{"mode": "train", "epochs": 1, "timestep": 981, "ep_reward": 496.4228515625, "reward": 0.5684887170791626, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 982, "ep_reward": 497.0221862792969, "reward": 0.5993385910987854, "action": -0.5765813589096069}
{"mode": "train", "epochs": 1, "timestep": 983, "ep_reward": 497.65045166015625, "reward": 0.6282557249069214, "action": -0.48851197957992554}
{"mode": "train", "epochs": 1, "timestep": 984, "ep_reward": 498.29949951171875, "reward": 0.6490445733070374, "action": -0.5319013595581055}
{"mode": "train", "epochs": 1, "timestep": 985, "ep_reward": 498.96026611328125, "reward": 0.6607620120048523, "action": -0.34411418437957764}
{"mode": "train", "epochs": 1, "timestep": 986, "ep_reward": 499.6227111816406, "reward": 0.6624329686164856, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 987, "ep_reward": 500.2817077636719, "reward": 0.6590000987052917, "action": -0.557058572769165}
{"mode": "train", "epochs": 1, "timestep": 988, "ep_reward": 500.9279479980469, "reward": 0.6462306976318359, "action": -0.9903620481491089}
{"mode": "train", "epochs": 1, "timestep": 989, "ep_reward": 501.5539855957031, "reward": 0.6260369420051575, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 990, "ep_reward": 502.1579284667969, "reward": 0.6039530038833618, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 991, "ep_reward": 502.7371520996094, "reward": 0.579208493232727, "action": -1.1287930011749268}
{"mode": "train", "epochs": 1, "timestep": 992, "ep_reward": 503.2847900390625, "reward": 0.5476299524307251, "action": -0.026479482650756836}
{"mode": "train", "epochs": 1, "timestep": 993, "ep_reward": 503.790283203125, "reward": 0.5054836869239807, "action": -0.6139324903488159}
{"mode": "train", "epochs": 1, "timestep": 994, "ep_reward": 504.25164794921875, "reward": 0.46137022972106934, "action": -0.8521546721458435}
{"mode": "train", "epochs": 1, "timestep": 995, "ep_reward": 504.6684875488281, "reward": 0.416847825050354, "action": -1.6807878017425537}
{"mode": "train", "epochs": 1, "timestep": 996, "ep_reward": 505.0474853515625, "reward": 0.37900036573410034, "action": -1.6246368885040283}
{"mode": "train", "epochs": 1, "timestep": 997, "ep_reward": 505.4187316894531, "reward": 0.37125468254089355, "action": -0.14238309860229492}
{"mode": "train", "epochs": 1, "timestep": 998, "ep_reward": 505.8282470703125, "reward": 0.40950876474380493, "action": -1.1807516813278198}
{"mode": "train", "epochs": 1, "timestep": 999, "ep_reward": 506.2749938964844, "reward": 0.44674181938171387, "action": -1.0585126876831055}
{"mode": "train", "epochs": 1, "timestep": 1000, "ep_reward": 506.7522277832031, "reward": 0.47724783420562744, "action": -0.8316043019294739}
{"mode": "train", "epochs": 1, "timestep": 1001, "ep_reward": 507.2525329589844, "reward": 0.5002933144569397, "action": -0.30160218477249146}
{"mode": "train", "epochs": 1, "timestep": 1002, "ep_reward": 507.7685546875, "reward": 0.5160099267959595, "action": -1.7507376670837402}
{"mode": "train", "epochs": 1, "timestep": 1003, "ep_reward": 508.29119873046875, "reward": 0.5226435661315918, "action": -0.8845125436782837}
{"mode": "train", "epochs": 1, "timestep": 1004, "ep_reward": 508.8101501464844, "reward": 0.5189593434333801, "action": -0.13641607761383057}
{"mode": "train", "epochs": 1, "timestep": 1005, "ep_reward": 509.31903076171875, "reward": 0.5088824033737183, "action": -0.3417700529098511}
{"mode": "train", "epochs": 1, "timestep": 1006, "ep_reward": 509.8111267089844, "reward": 0.4920874238014221, "action": -1.2466018199920654}
{"mode": "train", "epochs": 1, "timestep": 1007, "ep_reward": 510.2762145996094, "reward": 0.46510183811187744, "action": -0.9122726917266846}
{"mode": "train", "epochs": 1, "timestep": 1008, "ep_reward": 510.7076416015625, "reward": 0.43142378330230713, "action": -1.3859158754348755}
{"mode": "train", "epochs": 1, "timestep": 1009, "ep_reward": 511.0968933105469, "reward": 0.38926613330841064, "action": -0.2510296106338501}
{"mode": "train", "epochs": 1, "timestep": 1010, "ep_reward": 511.46624755859375, "reward": 0.36936020851135254, "action": -0.9489090442657471}
{"mode": "train", "epochs": 1, "timestep": 1011, "ep_reward": 511.8723449707031, "reward": 0.4060916304588318, "action": -0.7967628836631775}
{"mode": "train", "epochs": 1, "timestep": 1012, "ep_reward": 512.3165893554688, "reward": 0.44426268339157104, "action": -1.5631897449493408}
{"mode": "train", "epochs": 1, "timestep": 1013, "ep_reward": 512.7979125976562, "reward": 0.48132777214050293, "action": -0.653626561164856}
{"mode": "train", "epochs": 1, "timestep": 1014, "ep_reward": 513.3177490234375, "reward": 0.5198251605033875, "action": -0.6066853404045105}
{"mode": "train", "epochs": 1, "timestep": 1015, "ep_reward": 513.8724365234375, "reward": 0.554693341255188, "action": -1.0699336528778076}
{"mode": "train", "epochs": 1, "timestep": 1016, "ep_reward": 514.456787109375, "reward": 0.5843254923820496, "action": -0.587887167930603}
{"mode": "train", "epochs": 1, "timestep": 1017, "ep_reward": 515.0659790039062, "reward": 0.6091717481613159, "action": -1.0878448486328125}
{"mode": "train", "epochs": 1, "timestep": 1018, "ep_reward": 515.693115234375, "reward": 0.6271421909332275, "action": -1.0920804738998413}
{"mode": "train", "epochs": 1, "timestep": 1019, "ep_reward": 516.3320922851562, "reward": 0.6389787197113037, "action": -1.1773886680603027}
{"mode": "train", "epochs": 1, "timestep": 1020, "ep_reward": 516.9766235351562, "reward": 0.6445047855377197, "action": -0.7199044823646545}
{"mode": "train", "epochs": 1, "timestep": 1021, "ep_reward": 517.6190185546875, "reward": 0.6423934698104858, "action": -0.7690377235412598}
{"mode": "train", "epochs": 1, "timestep": 1022, "ep_reward": 518.2512817382812, "reward": 0.6322705745697021, "action": -1.1800788640975952}
{"mode": "train", "epochs": 1, "timestep": 1023, "ep_reward": 518.8673095703125, "reward": 0.6160058975219727, "action": -1.8166565895080566}
{"mode": "train", "epochs": 1, "timestep": 1024, "ep_reward": 519.4644165039062, "reward": 0.5970782041549683, "action": -1.0337367057800293}
{"mode": "train", "epochs": 1, "timestep": 1025, "ep_reward": 520.0355834960938, "reward": 0.5711599588394165, "action": -1.202895164489746}
{"mode": "train", "epochs": 1, "timestep": 1026, "ep_reward": 520.5769653320312, "reward": 0.5413897037506104, "action": -1.5174927711486816}
{"mode": "train", "epochs": 1, "timestep": 1027, "ep_reward": 521.0875244140625, "reward": 0.5105420351028442, "action": -0.6766620874404907}
{"mode": "train", "epochs": 1, "timestep": 1028, "ep_reward": 521.5610961914062, "reward": 0.4735497236251831, "action": -1.2418638467788696}
{"mode": "train", "epochs": 1, "timestep": 1029, "ep_reward": 521.9993896484375, "reward": 0.4382724165916443, "action": -0.14723730087280273}
{"mode": "train", "epochs": 1, "timestep": 1030, "ep_reward": 522.3961791992188, "reward": 0.39676475524902344, "action": -1.4542713165283203}
{"mode": "train", "epochs": 1, "timestep": 1031, "ep_reward": 522.7598266601562, "reward": 0.36362189054489136, "action": -1.0213996171951294}
{"mode": "train", "epochs": 1, "timestep": 1032, "ep_reward": 523.1546020507812, "reward": 0.39479249715805054, "action": -0.5456468462944031}
{"mode": "train", "epochs": 1, "timestep": 1033, "ep_reward": 523.5828247070312, "reward": 0.42825043201446533, "action": -0.3065337538719177}
{"mode": "train", "epochs": 1, "timestep": 1034, "ep_reward": 524.0408935546875, "reward": 0.45806825160980225, "action": 0.16021054983139038}
{"mode": "train", "epochs": 1, "timestep": 1035, "ep_reward": 524.5248413085938, "reward": 0.483953058719635, "action": -0.5260467529296875}
{"mode": "train", "epochs": 1, "timestep": 1036, "ep_reward": 525.0305786132812, "reward": 0.5057334899902344, "action": -1.5051523447036743}
{"mode": "train", "epochs": 1, "timestep": 1037, "ep_reward": 525.550048828125, "reward": 0.5194496512413025, "action": 0.12478208541870117}
{"mode": "train", "epochs": 1, "timestep": 1038, "ep_reward": 526.0753173828125, "reward": 0.525238037109375, "action": 0.2347216010093689}
{"mode": "train", "epochs": 1, "timestep": 1039, "ep_reward": 526.6012573242188, "reward": 0.5259426832199097, "action": 0.09160065650939941}
{"mode": "train", "epochs": 1, "timestep": 1040, "ep_reward": 527.1224365234375, "reward": 0.5211582183837891, "action": 0.12183451652526855}
{"mode": "train", "epochs": 1, "timestep": 1041, "ep_reward": 527.6334838867188, "reward": 0.5110472440719604, "action": -0.5972208380699158}
{"mode": "train", "epochs": 1, "timestep": 1042, "ep_reward": 528.1264038085938, "reward": 0.49292653799057007, "action": -1.3926708698272705}
{"mode": "train", "epochs": 1, "timestep": 1043, "ep_reward": 528.5904541015625, "reward": 0.46403050422668457, "action": -0.6173219084739685}
{"mode": "train", "epochs": 1, "timestep": 1044, "ep_reward": 529.0208740234375, "reward": 0.43045008182525635, "action": -0.5333942174911499}
{"mode": "train", "epochs": 1, "timestep": 1045, "ep_reward": 529.4137573242188, "reward": 0.3928956389427185, "action": -0.1929759979248047}
{"mode": "train", "epochs": 1, "timestep": 1046, "ep_reward": 529.7821655273438, "reward": 0.3683987855911255, "action": -0.9756101369857788}
{"mode": "train", "epochs": 1, "timestep": 1047, "ep_reward": 530.185546875, "reward": 0.4034028649330139, "action": -0.2569120228290558}
{"mode": "train", "epochs": 1, "timestep": 1048, "ep_reward": 530.6261596679688, "reward": 0.44062352180480957, "action": -0.19838547706604004}
{"mode": "train", "epochs": 1, "timestep": 1049, "ep_reward": 531.1023559570312, "reward": 0.4761708974838257, "action": -0.8381179571151733}
{"mode": "train", "epochs": 1, "timestep": 1050, "ep_reward": 531.610595703125, "reward": 0.5082281231880188, "action": -0.3596372902393341}
{"mode": "train", "epochs": 1, "timestep": 1051, "ep_reward": 532.1484985351562, "reward": 0.5378977656364441, "action": -0.6058274507522583}
{"mode": "train", "epochs": 1, "timestep": 1052, "ep_reward": 532.7109985351562, "reward": 0.5624840259552002, "action": 0.07622569799423218}
{"mode": "train", "epochs": 1, "timestep": 1053, "ep_reward": 533.292236328125, "reward": 0.5812612771987915, "action": -0.17689573764801025}
{"mode": "train", "epochs": 1, "timestep": 1054, "ep_reward": 533.8841552734375, "reward": 0.5919020175933838, "action": -0.11334508657455444}
{"mode": "train", "epochs": 1, "timestep": 1055, "ep_reward": 534.4783935546875, "reward": 0.5942506790161133, "action": -1.4004353284835815}
{"mode": "train", "epochs": 1, "timestep": 1056, "ep_reward": 535.0704345703125, "reward": 0.5920331478118896, "action": -0.5862219333648682}
{"mode": "train", "epochs": 1, "timestep": 1057, "ep_reward": 535.6537475585938, "reward": 0.5833104848861694, "action": -0.34048992395401}
{"mode": "train", "epochs": 1, "timestep": 1058, "ep_reward": 536.2208862304688, "reward": 0.567166268825531, "action": -1.1117303371429443}
{"mode": "train", "epochs": 1, "timestep": 1059, "ep_reward": 536.7687377929688, "reward": 0.5478333830833435, "action": -1.1411117315292358}
{"mode": "train", "epochs": 1, "timestep": 1060, "ep_reward": 537.2940673828125, "reward": 0.5253474712371826, "action": -0.9822041392326355}
{"mode": "train", "epochs": 1, "timestep": 1061, "ep_reward": 537.7936401367188, "reward": 0.4995615482330322, "action": -1.5236129760742188}
{"mode": "train", "epochs": 1, "timestep": 1062, "ep_reward": 538.2685546875, "reward": 0.47490251064300537, "action": -1.2615318298339844}
{"mode": "train", "epochs": 1, "timestep": 1063, "ep_reward": 538.7180786132812, "reward": 0.4495336413383484, "action": -0.9638987183570862}
{"mode": "train", "epochs": 1, "timestep": 1064, "ep_reward": 539.1414794921875, "reward": 0.42339861392974854, "action": -1.3068605661392212}
{"mode": "train", "epochs": 1, "timestep": 1065, "ep_reward": 539.5418090820312, "reward": 0.40032774209976196, "action": -0.638329029083252}
{"mode": "train", "epochs": 1, "timestep": 1066, "ep_reward": 539.918212890625, "reward": 0.3763898015022278, "action": -1.7743498086929321}
{"mode": "train", "epochs": 1, "timestep": 1067, "ep_reward": 540.3112182617188, "reward": 0.39300787448883057, "action": -0.8956104516983032}
{"mode": "train", "epochs": 1, "timestep": 1068, "ep_reward": 540.7222290039062, "reward": 0.41102200746536255, "action": -0.5513877868652344}
{"mode": "train", "epochs": 1, "timestep": 1069, "ep_reward": 541.1477661132812, "reward": 0.4255334734916687, "action": 0.5470232367515564}
{"mode": "train", "epochs": 1, "timestep": 1070, "ep_reward": 541.5862426757812, "reward": 0.43846774101257324, "action": 0.1462661623954773}
{"mode": "train", "epochs": 1, "timestep": 1071, "ep_reward": 542.0363159179688, "reward": 0.4500558376312256, "action": -1.645385503768921}
{"mode": "train", "epochs": 1, "timestep": 1072, "ep_reward": 542.4923706054688, "reward": 0.456035315990448, "action": -0.027999281883239746}
{"mode": "train", "epochs": 1, "timestep": 1073, "ep_reward": 542.9498291015625, "reward": 0.4574362635612488, "action": -0.5054521560668945}
{"mode": "train", "epochs": 1, "timestep": 1074, "ep_reward": 543.4041748046875, "reward": 0.45434755086898804, "action": -0.9495030641555786}
{"mode": "train", "epochs": 1, "timestep": 1075, "ep_reward": 543.849365234375, "reward": 0.4451867938041687, "action": -0.06774663925170898}
{"mode": "train", "epochs": 1, "timestep": 1076, "ep_reward": 544.282958984375, "reward": 0.43361037969589233, "action": -0.04845148324966431}
{"mode": "train", "epochs": 1, "timestep": 1077, "ep_reward": 544.7026977539062, "reward": 0.41976654529571533, "action": -1.0845203399658203}
{"mode": "train", "epochs": 1, "timestep": 1078, "ep_reward": 545.1024169921875, "reward": 0.3997494578361511, "action": 0.596836507320404}
{"mode": "train", "epochs": 1, "timestep": 1079, "ep_reward": 545.4856567382812, "reward": 0.3832606077194214, "action": -0.7649089694023132}
{"mode": "train", "epochs": 1, "timestep": 1080, "ep_reward": 545.8771362304688, "reward": 0.3914879560470581, "action": -0.36400070786476135}
{"mode": "train", "epochs": 1, "timestep": 1081, "ep_reward": 546.2880249023438, "reward": 0.4109065532684326, "action": 0.23795169591903687}
{"mode": "train", "epochs": 1, "timestep": 1082, "ep_reward": 546.7175903320312, "reward": 0.42958664894104004, "action": -1.0720689296722412}
{"mode": "train", "epochs": 1, "timestep": 1083, "ep_reward": 547.1648559570312, "reward": 0.447265088558197, "action": -0.6078652143478394}
{"mode": "train", "epochs": 1, "timestep": 1084, "ep_reward": 547.6298828125, "reward": 0.4650431275367737, "action": -0.1753106713294983}
{"mode": "train", "epochs": 1, "timestep": 1085, "ep_reward": 548.1107788085938, "reward": 0.4809260964393616, "action": -0.46163809299468994}
{"mode": "train", "epochs": 1, "timestep": 1086, "ep_reward": 548.6046142578125, "reward": 0.49386364221572876, "action": -1.0382136106491089}
{"mode": "train", "epochs": 1, "timestep": 1087, "ep_reward": 549.1094360351562, "reward": 0.5048092603683472, "action": -1.3745028972625732}
{"mode": "train", "epochs": 1, "timestep": 1088, "ep_reward": 549.624267578125, "reward": 0.5148477554321289, "action": -0.6664938926696777}
{"mode": "train", "epochs": 1, "timestep": 1089, "ep_reward": 550.1467895507812, "reward": 0.5224971771240234, "action": -1.1179893016815186}
{"mode": "train", "epochs": 1, "timestep": 1090, "ep_reward": 550.6746215820312, "reward": 0.5278171300888062, "action": -0.010242640972137451}
{"mode": "train", "epochs": 1, "timestep": 1091, "ep_reward": 551.2027587890625, "reward": 0.5281386375427246, "action": -0.3183334469795227}
{"mode": "train", "epochs": 1, "timestep": 1092, "ep_reward": 551.7261962890625, "reward": 0.5234458446502686, "action": -0.6389719247817993}
{"mode": "train", "epochs": 1, "timestep": 1093, "ep_reward": 552.2413330078125, "reward": 0.5151486992835999, "action": -0.9208140969276428}
{"mode": "train", "epochs": 1, "timestep": 1094, "ep_reward": 552.7459716796875, "reward": 0.5046583414077759, "action": -0.31187278032302856}
{"mode": "train", "epochs": 1, "timestep": 1095, "ep_reward": 553.235595703125, "reward": 0.48964089155197144, "action": -0.7441872358322144}
{"mode": "train", "epochs": 1, "timestep": 1096, "ep_reward": 553.7086791992188, "reward": 0.47310709953308105, "action": -0.8482317328453064}
{"mode": "train", "epochs": 1, "timestep": 1097, "ep_reward": 554.1642456054688, "reward": 0.45559340715408325, "action": -1.4480164051055908}
{"mode": "train", "epochs": 1, "timestep": 1098, "ep_reward": 554.6048583984375, "reward": 0.44060468673706055, "action": -0.2581525444984436}
{"mode": "train", "epochs": 1, "timestep": 1099, "ep_reward": 555.0269165039062, "reward": 0.4220660924911499, "action": -0.06092667579650879}
{"mode": "train", "epochs": 1, "timestep": 1100, "ep_reward": 555.4286499023438, "reward": 0.40174204111099243, "action": -0.3267197608947754}
{"mode": "train", "epochs": 1, "timestep": 1101, "ep_reward": 555.8106689453125, "reward": 0.38204342126846313, "action": -0.6900839805603027}
{"mode": "train", "epochs": 1, "timestep": 1102, "ep_reward": 556.2010498046875, "reward": 0.39035940170288086, "action": -1.4875893592834473}
{"mode": "train", "epochs": 1, "timestep": 1103, "ep_reward": 556.6070556640625, "reward": 0.40599673986434937, "action": -0.2816908359527588}
{"mode": "train", "epochs": 1, "timestep": 1104, "ep_reward": 557.0248413085938, "reward": 0.41780251264572144, "action": -1.0347142219543457}
{"mode": "train", "epochs": 1, "timestep": 1105, "ep_reward": 557.4508056640625, "reward": 0.4259427785873413, "action": -0.5052460432052612}
{"mode": "train", "epochs": 1, "timestep": 1106, "ep_reward": 557.8809814453125, "reward": 0.43018245697021484, "action": -0.6653499603271484}
{"mode": "train", "epochs": 1, "timestep": 1107, "ep_reward": 558.3114013671875, "reward": 0.4304147958755493, "action": -1.3255707025527954}
{"mode": "train", "epochs": 1, "timestep": 1108, "ep_reward": 558.7357177734375, "reward": 0.42433470487594604, "action": -2.0}
{"mode": "train", "epochs": 1, "timestep": 1109, "ep_reward": 559.145263671875, "reward": 0.40957027673721313, "action": 0.08083319664001465}
{"mode": "train", "epochs": 1, "timestep": 1110, "ep_reward": 559.5407104492188, "reward": 0.3954293131828308, "action": -0.6202402114868164}
{"mode": "train", "epochs": 1, "timestep": 1111, "ep_reward": 559.9202880859375, "reward": 0.37956660985946655, "action": -0.8762341141700745}
{"mode": "train", "epochs": 1, "timestep": 1112, "ep_reward": 560.3171997070312, "reward": 0.3969253897666931, "action": -0.5826178193092346}
{"mode": "train", "epochs": 1, "timestep": 1113, "ep_reward": 560.7329711914062, "reward": 0.41576576232910156, "action": -0.4433720111846924}
{"mode": "train", "epochs": 1, "timestep": 1114, "ep_reward": 561.167724609375, "reward": 0.4347342252731323, "action": -1.3383734226226807}
{"mode": "train", "epochs": 1, "timestep": 1115, "ep_reward": 561.6216430664062, "reward": 0.45393961668014526, "action": -0.18964165449142456}
{"mode": "train", "epochs": 1, "timestep": 1116, "ep_reward": 562.0947875976562, "reward": 0.47316986322402954, "action": -0.13939940929412842}
{"mode": "train", "epochs": 1, "timestep": 1117, "ep_reward": 562.5841674804688, "reward": 0.48936885595321655, "action": -0.10177069902420044}
{"mode": "train", "epochs": 1, "timestep": 1118, "ep_reward": 563.0858764648438, "reward": 0.5017006397247314, "action": -0.6041959524154663}
{"mode": "train", "epochs": 1, "timestep": 1119, "ep_reward": 563.596435546875, "reward": 0.5105783343315125, "action": 0.12393331527709961}
{"mode": "train", "epochs": 1, "timestep": 1120, "ep_reward": 564.1111450195312, "reward": 0.5146938562393188, "action": -0.6260274648666382}
{"mode": "train", "epochs": 1, "timestep": 1121, "ep_reward": 564.6260986328125, "reward": 0.51496821641922, "action": -1.2375130653381348}
{"mode": "train", "epochs": 1, "timestep": 1122, "ep_reward": 565.1397094726562, "reward": 0.513626217842102, "action": -1.9657995700836182}
{"mode": "train", "epochs": 1, "timestep": 1123, "ep_reward": 565.6530151367188, "reward": 0.5133000016212463, "action": -0.8361767530441284}
{"mode": "train", "epochs": 1, "timestep": 1124, "ep_reward": 566.1632690429688, "reward": 0.510282576084137, "action": -0.7669036388397217}
{"mode": "train", "epochs": 1, "timestep": 1125, "ep_reward": 566.6678466796875, "reward": 0.504576563835144, "action": -1.0086034536361694}
{"mode": "train", "epochs": 1, "timestep": 1126, "ep_reward": 567.1650390625, "reward": 0.4971676468849182, "action": -1.675654649734497}
{"mode": "train", "epochs": 1, "timestep": 1127, "ep_reward": 567.6559448242188, "reward": 0.49088382720947266, "action": -0.808343768119812}
{"mode": "train", "epochs": 1, "timestep": 1128, "ep_reward": 568.1381225585938, "reward": 0.4821805953979492, "action": -0.490291953086853}
{"mode": "train", "epochs": 1, "timestep": 1129, "ep_reward": 568.6087646484375, "reward": 0.4706510305404663, "action": -1.6289701461791992}
{"mode": "train", "epochs": 1, "timestep": 1130, "ep_reward": 569.070556640625, "reward": 0.4618077874183655, "action": -0.8413176536560059}
{"mode": "train", "epochs": 1, "timestep": 1131, "ep_reward": 569.5220336914062, "reward": 0.451485812664032, "action": -0.9741909503936768}
{"mode": "train", "epochs": 1, "timestep": 1132, "ep_reward": 569.9635009765625, "reward": 0.4414799213409424, "action": -1.2244987487792969}
{"mode": "train", "epochs": 1, "timestep": 1133, "ep_reward": 570.3966064453125, "reward": 0.43307965993881226, "action": -0.7562946677207947}
{"mode": "train", "epochs": 1, "timestep": 1134, "ep_reward": 570.8211059570312, "reward": 0.42446959018707275, "action": -0.7273431420326233}
{"mode": "train", "epochs": 1, "timestep": 1135, "ep_reward": 571.2374877929688, "reward": 0.416376531124115, "action": -0.5204587578773499}
{"mode": "train", "epochs": 1, "timestep": 1136, "ep_reward": 571.6458129882812, "reward": 0.4083121418952942, "action": -0.8771095871925354}
{"mode": "train", "epochs": 1, "timestep": 1137, "ep_reward": 572.0479736328125, "reward": 0.4021531343460083, "action": -0.2516094446182251}
{"mode": "train", "epochs": 1, "timestep": 1138, "ep_reward": 572.4434814453125, "reward": 0.39548957347869873, "action": -0.7571945786476135}
{"mode": "train", "epochs": 1, "timestep": 1139, "ep_reward": 572.8343505859375, "reward": 0.39084768295288086, "action": -1.0263035297393799}
{"mode": "train", "epochs": 1, "timestep": 1140, "ep_reward": 573.22314453125, "reward": 0.3888239860534668, "action": -1.5631814002990723}
{"mode": "train", "epochs": 1, "timestep": 1141, "ep_reward": 573.6141967773438, "reward": 0.3910564184188843, "action": -0.715526282787323}
{"mode": "train", "epochs": 1, "timestep": 1142, "ep_reward": 574.0089721679688, "reward": 0.3947872519493103, "action": -0.4289739429950714}
{"mode": "train", "epochs": 1, "timestep": 1143, "ep_reward": 574.4082641601562, "reward": 0.3992719054222107, "action": -1.2089221477508545}
{"mode": "train", "epochs": 1, "timestep": 1144, "ep_reward": 574.8145751953125, "reward": 0.4063127040863037, "action": -0.16200250387191772}
{"mode": "train", "epochs": 1, "timestep": 1145, "ep_reward": 575.22802734375, "reward": 0.4134714603424072, "action": -0.5214885473251343}
{"mode": "train", "epochs": 1, "timestep": 1146, "ep_reward": 575.6488037109375, "reward": 0.4207710027694702, "action": -0.10082405805587769}
{"mode": "train", "epochs": 1, "timestep": 1147, "ep_reward": 576.075927734375, "reward": 0.4271122217178345, "action": -1.3880815505981445}
{"mode": "train", "epochs": 1, "timestep": 1148, "ep_reward": 576.510986328125, "reward": 0.43503057956695557, "action": -0.9452791213989258}
{"mode": "train", "epochs": 1, "timestep": 1149, "ep_reward": 576.9548950195312, "reward": 0.4438810348510742, "action": -1.083125352859497}
{"mode": "train", "epochs": 1, "timestep": 1150, "ep_reward": 577.4083251953125, "reward": 0.45343828201293945, "action": -0.681193470954895}
{"mode": "train", "epochs": 1, "timestep": 1151, "ep_reward": 577.8709106445312, "reward": 0.46259385347366333, "action": -1.2283892631530762}
{"mode": "train", "epochs": 1, "timestep": 1152, "ep_reward": 578.3427124023438, "reward": 0.47183042764663696, "action": -0.9600965976715088}
{"mode": "train", "epochs": 1, "timestep": 1153, "ep_reward": 578.8234252929688, "reward": 0.48068904876708984, "action": -1.1141579151153564}
{"mode": "train", "epochs": 1, "timestep": 1154, "ep_reward": 579.3123779296875, "reward": 0.4889574646949768, "action": -1.0500205755233765}
{"mode": "train", "epochs": 1, "timestep": 1155, "ep_reward": 579.8087158203125, "reward": 0.496338427066803, "action": -0.8992871046066284}
{"mode": "train", "epochs": 1, "timestep": 1156, "ep_reward": 580.3109130859375, "reward": 0.5022104978561401, "action": -0.27584415674209595}
{"mode": "train", "epochs": 1, "timestep": 1157, "ep_reward": 580.8154296875, "reward": 0.5045456290245056, "action": -1.532097339630127}
{"mode": "train", "epochs": 1, "timestep": 1158, "ep_reward": 581.3218994140625, "reward": 0.5064606070518494, "action": -0.5271310806274414}
{"mode": "train", "epochs": 1, "timestep": 1159, "ep_reward": 581.8271484375, "reward": 0.5052216053009033, "action": -1.6095688343048096}
{"mode": "train", "epochs": 1, "timestep": 1160, "ep_reward": 582.3313598632812, "reward": 0.5042331218719482, "action": 0.34193527698516846}
{"mode": "train", "epochs": 1, "timestep": 1161, "ep_reward": 582.8284912109375, "reward": 0.4971058964729309, "action": -1.1621472835540771}
{"mode": "train", "epochs": 1, "timestep": 1162, "ep_reward": 583.3180541992188, "reward": 0.48955750465393066, "action": -1.3726863861083984}
{"mode": "train", "epochs": 1, "timestep": 1163, "ep_reward": 583.8002319335938, "reward": 0.48219794034957886, "action": -0.4602190852165222}
{"mode": "train", "epochs": 1, "timestep": 1164, "ep_reward": 584.2718505859375, "reward": 0.4716155529022217, "action": -0.517548680305481}
{"mode": "train", "epochs": 1, "timestep": 1165, "ep_reward": 584.7307739257812, "reward": 0.4589071273803711, "action": -1.9932639598846436}
{"mode": "train", "epochs": 1, "timestep": 1166, "ep_reward": 585.181640625, "reward": 0.4508857727050781, "action": -1.4000329971313477}
{"mode": "train", "epochs": 1, "timestep": 1167, "ep_reward": 585.6251831054688, "reward": 0.4435562491416931, "action": -0.2848673462867737}
{"mode": "train", "epochs": 1, "timestep": 1168, "ep_reward": 586.0588989257812, "reward": 0.4336977005004883, "action": -0.7173455953598022}
{"mode": "train", "epochs": 1, "timestep": 1169, "ep_reward": 586.4832763671875, "reward": 0.42439424991607666, "action": -0.6585778594017029}
{"mode": "train", "epochs": 1, "timestep": 1170, "ep_reward": 586.8986206054688, "reward": 0.41535037755966187, "action": -0.8394336104393005}
{"mode": "train", "epochs": 1, "timestep": 1171, "ep_reward": 587.3060913085938, "reward": 0.4074960947036743, "action": -1.8483083248138428}
{"mode": "train", "epochs": 1, "timestep": 1172, "ep_reward": 587.7109985351562, "reward": 0.40488022565841675, "action": -0.5179919004440308}
{"mode": "train", "epochs": 1, "timestep": 1173, "ep_reward": 588.1129760742188, "reward": 0.4019574522972107, "action": -0.3435555100440979}
{"mode": "train", "epochs": 1, "timestep": 1174, "ep_reward": 588.51220703125, "reward": 0.39922261238098145, "action": -0.8505568504333496}
{"mode": "train", "epochs": 1, "timestep": 1175, "ep_reward": 588.9107055664062, "reward": 0.3984771966934204, "action": -0.8106144666671753}
